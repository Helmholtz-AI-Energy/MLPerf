/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/docker/deepcam_optimized-21.09_2.sif
configs/best_configs/config_DGXA100_512GPU_BS1024_graph.sh
#!/bin/bash

# hyperparameters
export LOCAL_BATCH_SIZE=2
export START_LR=0.004
export OPTIMIZER="LAMB"
export LR_SCHEDULE_TYPE="multistep"
export LR_MILESTONES="1100 4096"
export LR_DECAY_RATE="0.1"
export LR_WARMUP_STEPS=200
export LR_WARMUP_FACTOR=1.
export WEIGHT_DECAY=0.01
export BATCHNORM_GROUP_SIZE=1

# data parameters
export SHUFFLE_MODE="global"
export DATA_FORMAT="dali-es/hdf5"
export PRECISION_MODE="amp"
export LOCAL_VALIDATION_BATCH_SIZE=8

# output parameters
#export OUTPUT_ROOT=/results/best

export TRAINING_INSTANCE_SIZE=$((128*4))

# auxiliary parameters
export LOGGING_FREQUENCY=10

# misc args
export ADDITIONAL_ARGS="--enable_jit --enable_graph"
#--disable_comm_overlap
# system parameters
#export DGXNGPU=8
#export DGXNNODES=64
#export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
#export WALLTIME=00:30:00
export DGXNGPU=4
export DGXNNODES=128
export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
export WALLTIME=01:00:00
 41: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 35: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
232: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
466: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 47: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 68: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
122: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 21: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
142: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 32: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
489: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
336: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 43: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
471: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 31: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 70: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
490: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
472: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
148: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
218: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
447: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
318: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
502: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 18: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 59: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 83: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 63: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
143: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 40: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
234: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
339: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 22: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
220: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  3: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 15: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: Running Multi Instance Training
 41: Running Multi Instance Training
 43: Running Multi Instance Training
 40: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 41: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 43: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
467: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 34: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
219: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
479: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
166: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
503: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 19: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: Running Multi Instance Training
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: Running Multi Instance Training
232: Running Multi Instance Training
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: Running Multi Instance Training
234: Running Multi Instance Training
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: Running Multi Instance Training
 32: Running Multi Instance Training
 21: Running Multi Instance Training
 70: Running Multi Instance Training
 22: Running Multi Instance Training
 15: Running Multi Instance Training
 34: Running Multi Instance Training
 59: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 35: Running Multi Instance Training
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
232: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
234: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 68: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 21: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: Running Multi Instance Training
 34: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
142: Running Multi Instance Training
 35: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 15: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
143: Running Multi Instance Training
 70: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
102: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
241: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  3: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
318: Running Multi Instance Training
142: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
415: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: Running Multi Instance Training
339: Running Multi Instance Training
471: Running Multi Instance Training
318: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: Running Multi Instance Training
336: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
471: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
447: Running Multi Instance Training
220: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 83: Running Multi Instance Training
447: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: Running Multi Instance Training
 83: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: Running Multi Instance Training
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: Running Multi Instance Training
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: Running Multi Instance Training
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: Running Multi Instance Training
218: Running Multi Instance Training
 63: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: Running Multi Instance Training
489: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
466: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: Running Multi Instance Training
467: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
502: Running Multi Instance Training
503: Running Multi Instance Training
218: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: Running Multi Instance Training
 47: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
148: Running Multi Instance Training
502: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
479: Running Multi Instance Training
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: Running Multi Instance Training
 18: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: Running Multi Instance Training
148: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
479: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 19: Running Multi Instance Training
 31: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 19: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: Running Multi Instance Training
 29: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
444: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: Running Multi Instance Training
121: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
415: Running Multi Instance Training
 45: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: Running Multi Instance Training
 45: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
102: Running Multi Instance Training
185: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
241: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: Running Multi Instance Training
 62: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
391: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
206: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: Running Multi Instance Training
 29: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
233: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
409: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
337: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
337: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: Running Multi Instance Training
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 45: Running Multi Instance Training
 45: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: Running Multi Instance Training
185: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: Running Multi Instance Training
233: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
337: Running Multi Instance Training
391: Running Multi Instance Training
206: Running Multi Instance Training
337: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
391: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
206: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: Running Multi Instance Training
409: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
464: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 71: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
150: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
262: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
393: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: Running Multi Instance Training
 71: Running Multi Instance Training
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
150: Running Multi Instance Training
 71: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
150: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 80: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: Running Multi Instance Training
129: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: Running Multi Instance Training
262: Running Multi Instance Training
316: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
262: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: Running Multi Instance Training
463: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
412: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: Running Multi Instance Training
 80: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
140: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
488: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
239: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: Running Multi Instance Training
243: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: Running Multi Instance Training
412: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: Running Multi Instance Training
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: Running Multi Instance Training
140: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
205: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
205: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
463: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
488: Running Multi Instance Training
 44: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 44: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: Running Multi Instance Training
123: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
243: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
239: Running Multi Instance Training
239: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: Running Multi Instance Training
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: Running Multi Instance Training
426: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
205: Running Multi Instance Training
223: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
205: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: Running Multi Instance Training
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: Running Multi Instance Training
408: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 44: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: Running Multi Instance Training
123: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 61: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
223: Running Multi Instance Training
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
223: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
418: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
277: Running Multi Instance Training
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
208: Running Multi Instance Training
277: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
208: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
149: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
451: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: Running Multi Instance Training
 14: Running Multi Instance Training
389: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
165: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 14: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
360: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: Running Multi Instance Training
477: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
149: Running Multi Instance Training
255: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
149: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: Running Multi Instance Training
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: Running Multi Instance Training
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
165: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
418: Running Multi Instance Training
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: Running Multi Instance Training
451: Running Multi Instance Training
451: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: Running Multi Instance Training
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: Running Multi Instance Training
360: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
477: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
468: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
186: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: Running Multi Instance Training
217: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 30: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 30: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
425: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: Running Multi Instance Training
468: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
445: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: Running Multi Instance Training
186: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: Running Multi Instance Training
 30: Running Multi Instance Training
217: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 30: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: Running Multi Instance Training
237: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
425: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: Running Multi Instance Training
211: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
211: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
445: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: Running Multi Instance Training
397: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
237: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  2: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 16: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
500: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 36: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
211: Running Multi Instance Training
211: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
103: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
128: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
279: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
224: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 58: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
319: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: Running Multi Instance Training
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: Running Multi Instance Training
  2: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
500: Running Multi Instance Training
475: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 16: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
500: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: Running Multi Instance Training
397: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: Running Multi Instance Training
 36: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: Running Multi Instance Training
279: Running Multi Instance Training
128: Running Multi Instance Training
103: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
279: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
128: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
460: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
460: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: Running Multi Instance Training
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: Running Multi Instance Training
 58: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
319: Running Multi Instance Training
 81: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
224: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
319: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: Running Multi Instance Training
432: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
475: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  5: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
377: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
460: Running Multi Instance Training
460: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: Running Multi Instance Training
 81: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
380: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
432: Running Multi Instance Training
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  5: Running Multi Instance Training
498: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  5: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: Running Multi Instance Training
164: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
377: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
380: Running Multi Instance Training
380: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
222: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
240: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: Running Multi Instance Training
164: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: Running Multi Instance Training
285: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: Running Multi Instance Training
498: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: Running Multi Instance Training
390: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
363: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
363: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: Running Multi Instance Training
222: Running Multi Instance Training
240: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
222: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
399: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
225: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
413: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
363: Running Multi Instance Training
 13: Running Multi Instance Training
157: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
363: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 13: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
399: Running Multi Instance Training
253: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
253: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
260: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: Running Multi Instance Training
225: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
478: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  0: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: Running Multi Instance Training
413: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: Running Multi Instance Training
  6: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
253: Running Multi Instance Training
157: Running Multi Instance Training
157: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
253: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
260: Running Multi Instance Training
260: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 86: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: Running Multi Instance Training
  0: Using bindings from SLURM: mask_cpu:
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: Running Multi Instance Training
462: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  0: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
410: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
184: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: Running Multi Instance Training
  6: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
204: Running Multi Instance Training
204: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
419: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
448: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: Running Multi Instance Training
168: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 65: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
462: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: Running Multi Instance Training
 86: Running Multi Instance Training
184: Running Multi Instance Training
410: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 86: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
184: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
349: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
419: Running Multi Instance Training
419: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: Running Multi Instance Training
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: Running Multi Instance Training
448: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
230: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: Running Multi Instance Training
168: Running Multi Instance Training
 65: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
168: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
392: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
202: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
236: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: Running Multi Instance Training
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
349: Running Multi Instance Training
 73: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
349: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: Running Multi Instance Training
372: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: Running Multi Instance Training
381: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
392: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: Running Multi Instance Training
236: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: Running Multi Instance Training
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: Running Multi Instance Training
101: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
202: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
378: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
427: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: Running Multi Instance Training
276: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
261: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: Running Multi Instance Training
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: Running Multi Instance Training
406: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
427: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: Running Multi Instance Training
276: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: Running Multi Instance Training
131: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
210: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
286: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 54: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
133: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 66: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
170: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 85: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
131: Running Multi Instance Training
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: Running Multi Instance Training
131: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: Running Multi Instance Training
492: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
286: Running Multi Instance Training
406: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
286: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
497: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: Running Multi Instance Training
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: Running Multi Instance Training
 90: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
170: Running Multi Instance Training
 54: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
170: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 85: Running Multi Instance Training
 85: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: Running Multi Instance Training
400: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
133: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
179: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: Running Multi Instance Training
492: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: Running Multi Instance Training
497: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
158: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: Running Multi Instance Training
 90: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: Running Multi Instance Training
400: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
254: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
111: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: Running Multi Instance Training
179: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
114: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
450: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
417: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: Running Multi Instance Training
350: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
350: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: Running Multi Instance Training
307: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
254: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
361: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: Running Multi Instance Training
111: Running Multi Instance Training
417: Running Multi Instance Training
282: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
111: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
114: Running Multi Instance Training
396: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: Running Multi Instance Training
114: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
350: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 39: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
433: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
342: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: Running Multi Instance Training
361: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: Running Multi Instance Training
373: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
307: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: Running Multi Instance Training
396: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: Running Multi Instance Training
135: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 39: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: Running Multi Instance Training
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
282: Running Multi Instance Training
 42: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
282: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 72: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
493: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: Running Multi Instance Training
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: Running Multi Instance Training
373: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: Running Multi Instance Training
135: Running Multi Instance Training
231: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
135: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: Running Multi Instance Training
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: Running Multi Instance Training
 42: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 72: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: Running Multi Instance Training
493: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
403: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: Running Multi Instance Training
226: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
334: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: Running Multi Instance Training
  4: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
403: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
313: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
156: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
175: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 52: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: Running Multi Instance Training
  4: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: Running Multi Instance Training
334: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
331: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
405: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: Running Multi Instance Training
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
156: Running Multi Instance Training
156: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: Running Multi Instance Training
506: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 52: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
301: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: Running Multi Instance Training
175: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
340: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: Running Multi Instance Training
284: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
435: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
139: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
405: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: Running Multi Instance Training
331: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: Running Multi Instance Training
376: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
281: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: Running Multi Instance Training
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: Running Multi Instance Training
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
301: Running Multi Instance Training
340: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
301: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: Running Multi Instance Training
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: Running Multi Instance Training
284: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
112: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
112: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: Running Multi Instance Training
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: Running Multi Instance Training
376: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
139: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
176: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
382: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
382: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 84: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
495: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 91: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: Running Multi Instance Training
112: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
235: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: Running Multi Instance Training
382: Running Multi Instance Training
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: Running Multi Instance Training
499: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
382: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: Running Multi Instance Training
495: Running Multi Instance Training
110: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
495: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
176: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: Running Multi Instance Training
200: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
200: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: Running Multi Instance Training
120: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
120: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: Running Multi Instance Training
 23: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
110: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
351: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: Running Multi Instance Training
200: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: Running Multi Instance Training
172: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
120: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
317: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 67: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: Running Multi Instance Training
171: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
482: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 23: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: Running Multi Instance Training
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: Running Multi Instance Training
302: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
351: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
346: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
332: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: Running Multi Instance Training
172: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: Running Multi Instance Training
317: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 99: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: Running Multi Instance Training
 67: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: Running Multi Instance Training
171: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: Running Multi Instance Training
302: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: Running Multi Instance Training
228: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
507: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
332: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: Running Multi Instance Training
404: Running Multi Instance Training
482: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 33: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
141: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: Running Multi Instance Training
 69: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
374: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: Running Multi Instance Training
507: Running Multi Instance Training
193: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
228: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
507: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: Running Multi Instance Training
 33: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: Running Multi Instance Training
141: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: Running Multi Instance Training
 69: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: Running Multi Instance Training
374: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
177: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: Running Multi Instance Training
 75: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
193: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
201: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
465: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
109: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: Running Multi Instance Training
251: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
251: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
177: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 46: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 46: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: Running Multi Instance Training
 75: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
201: Running Multi Instance Training
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: Running Multi Instance Training
201: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
109: Running Multi Instance Training
465: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
109: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 49: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 46: Running Multi Instance Training
 46: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: Running Multi Instance Training
251: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
330: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
136: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 55: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
473: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
132: Running Multi Instance Training
132: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 96: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: Running Multi Instance Training
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: Running Multi Instance Training
 60: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
188: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 49: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
401: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: Running Multi Instance Training
136: Running Multi Instance Training
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: Running Multi Instance Training
330: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: Running Multi Instance Training
 55: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
359: Running Multi Instance Training
359: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: Running Multi Instance Training
 57: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 96: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: Running Multi Instance Training
491: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
256: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 60: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 82: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: Running Multi Instance Training
401: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
367: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: Running Multi Instance Training
304: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
213: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 57: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 12: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: Running Multi Instance Training
 89: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 27: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
491: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: Running Multi Instance Training
 82: Running Multi Instance Training
256: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 82: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 17: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: Running Multi Instance Training
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
367: Running Multi Instance Training
304: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
367: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: Running Multi Instance Training
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 89: Running Multi Instance Training
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: Running Multi Instance Training
 89: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
283: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
213: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
341: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
315: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: Running Multi Instance Training
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: Running Multi Instance Training
297: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 17: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 27: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: Running Multi Instance Training
221: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: Running Multi Instance Training
333: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
481: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: Running Multi Instance Training
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: Running Multi Instance Training
283: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
315: Running Multi Instance Training
315: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: Running Multi Instance Training
338: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
501: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: Running Multi Instance Training
297: Running Multi Instance Training
481: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
297: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
356: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
355: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
288: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: Running Multi Instance Training
338: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: Running Multi Instance Training
501: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: Running Multi Instance Training
115: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
216: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
294: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
508: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
250: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: Running Multi Instance Training
356: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 28: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 28: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: Running Multi Instance Training
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: Running Multi Instance Training
288: Running Multi Instance Training
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: Running Multi Instance Training
355: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
115: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
446: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
446: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
250: Running Multi Instance Training
250: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
174: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
504: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
214: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: Running Multi Instance Training
508: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
151: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: Running Multi Instance Training
 28: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  1: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
470: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
306: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: Running Multi Instance Training
446: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: Running Multi Instance Training
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: Running Multi Instance Training
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
214: Running Multi Instance Training
504: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
214: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
187: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: Running Multi Instance Training
300: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: Running Multi Instance Training
 50: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
242: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
476: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
242: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: Running Multi Instance Training
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: Running Multi Instance Training
470: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  1: Running Multi Instance Training
  1: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 77: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
314: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: Running Multi Instance Training
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: Running Multi Instance Training
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: Running Multi Instance Training
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: Running Multi Instance Training
300: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 24: Running Multi Instance Training
 93: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
242: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 93: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
441: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: Running Multi Instance Training
 11: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
480: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: Running Multi Instance Training
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: Running Multi Instance Training
299: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
314: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
347: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
370: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
320: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: Running Multi Instance Training
 93: Running Multi Instance Training
 77: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
137: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 93: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
352: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: Running Multi Instance Training
480: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: Running Multi Instance Training
328: Running Multi Instance Training
441: Running Multi Instance Training
328: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
299: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
441: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
414: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
511: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: Running Multi Instance Training
137: Running Multi Instance Training
370: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
357: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
357: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
352: Running Multi Instance Training
153: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
352: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: Running Multi Instance Training
320: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: Running Multi Instance Training
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
511: Running Multi Instance Training
414: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
511: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: Running Multi Instance Training
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: Running Multi Instance Training
357: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
244: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
194: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: Running Multi Instance Training
125: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: Running Multi Instance Training
153: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: Running Multi Instance Training
191: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
182: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: Running Multi Instance Training
194: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
395: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
167: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
100: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 78: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 78: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: Running Multi Instance Training
207: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: Running Multi Instance Training
395: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
182: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
249: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 98: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: Running Multi Instance Training
 98: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
167: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
345: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
100: Running Multi Instance Training
292: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 78: Running Multi Instance Training
 78: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
388: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
411: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: Running Multi Instance Training
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
249: Running Multi Instance Training
249: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
144: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
291: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 98: Running Multi Instance Training
 98: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: Running Multi Instance Training
292: Running Multi Instance Training
275: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
345: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
292: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
371: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: Running Multi Instance Training
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
411: Running Multi Instance Training
411: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: Running Multi Instance Training
323: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
291: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: Running Multi Instance Training
263: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
144: Running Multi Instance Training
371: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
144: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: Running Multi Instance Training
257: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
275: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: Running Multi Instance Training
323: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
364: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: Running Multi Instance Training
263: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
195: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: Running Multi Instance Training
257: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: Running Multi Instance Training
387: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
364: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
130: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
195: Running Multi Instance Training
195: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
105: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
152: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
424: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: Running Multi Instance Training
449: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: Running Multi Instance Training
130: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
387: Running Multi Instance Training
278: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  8: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
387: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
461: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 26: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: Running Multi Instance Training
189: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
152: Running Multi Instance Training
105: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: Running Multi Instance Training
152: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
449: Running Multi Instance Training
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: Running Multi Instance Training
449: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
238: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
278: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
442: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: Running Multi Instance Training
461: Running Multi Instance Training
442: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
227: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
461: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
487: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
124: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 26: Running Multi Instance Training
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
252: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
189: Running Multi Instance Training
189: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: Running Multi Instance Training
 51: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
209: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
209: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: Running Multi Instance Training
198: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
290: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: Running Multi Instance Training
442: Running Multi Instance Training
238: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
146: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
442: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
428: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: Running Multi Instance Training
421: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
124: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
296: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
296: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: Running Multi Instance Training
252: Running Multi Instance Training
487: Running Multi Instance Training
212: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
252: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
487: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
274: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
209: Running Multi Instance Training
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: Running Multi Instance Training
209: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
290: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
271: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
259: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: Running Multi Instance Training
198: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
362: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
296: Running Multi Instance Training
296: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
365: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: Running Multi Instance Training
421: Running Multi Instance Training
274: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
421: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
368: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 95: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
259: Running Multi Instance Training
259: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
398: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: Running Multi Instance Training
271: Running Multi Instance Training
362: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
271: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: Running Multi Instance Training
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: Running Multi Instance Training
180: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
353: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
365: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: Running Multi Instance Training
 95: Running Multi Instance Training
368: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 95: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: Running Multi Instance Training
267: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
246: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: Running Multi Instance Training
398: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
416: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: Running Multi Instance Training
509: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: Running Multi Instance Training
353: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
107: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
383: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
295: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: Running Multi Instance Training
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
509: Running Multi Instance Training
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
267: Running Multi Instance Training
434: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
267: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
484: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: Running Multi Instance Training
 38: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: Running Multi Instance Training
295: Running Multi Instance Training
383: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
295: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
452: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: Running Multi Instance Training
434: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: Running Multi Instance Training
 87: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
484: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: Running Multi Instance Training
 38: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: Running Multi Instance Training
452: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: Running Multi Instance Training
 87: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 79: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
322: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 79: Running Multi Instance Training
  9: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 79: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  7: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
178: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: Running Multi Instance Training
322: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
496: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: Running Multi Instance Training
385: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: Running Multi Instance Training
181: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  9: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: Running Multi Instance Training
178: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: Running Multi Instance Training
  7: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 64: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: Running Multi Instance Training
287: Running Multi Instance Training
385: Running Multi Instance Training
496: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
287: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
385: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
443: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
379: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
196: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
196: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
159: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: Running Multi Instance Training
 64: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
126: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: Running Multi Instance Training
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
379: Running Multi Instance Training
494: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
196: Running Multi Instance Training
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: Running Multi Instance Training
196: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
443: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: Running Multi Instance Training
159: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: Running Multi Instance Training
126: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: Running Multi Instance Training
428: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
431: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: Running Multi Instance Training
494: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
155: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
147: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
272: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
455: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
407: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: Running Multi Instance Training
311: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
266: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
247: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 74: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
134: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: Running Multi Instance Training
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: Running Multi Instance Training
272: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: Running Multi Instance Training
147: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: Running Multi Instance Training
455: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: Running Multi Instance Training
407: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
268: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
247: Running Multi Instance Training
247: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: Running Multi Instance Training
311: Running Multi Instance Training
 74: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
311: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
134: Running Multi Instance Training
106: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
134: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
229: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: Running Multi Instance Training
268: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
203: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
375: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
348: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: Running Multi Instance Training
439: Running Multi Instance Training
169: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
439: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: Running Multi Instance Training
229: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: Running Multi Instance Training
203: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: Running Multi Instance Training
325: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: Running Multi Instance Training
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: Running Multi Instance Training
375: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
459: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
108: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
280: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
423: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: Running Multi Instance Training
325: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: Running Multi Instance Training
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
280: Running Multi Instance Training
308: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
423: Running Multi Instance Training
423: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 88: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
113: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
485: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: Running Multi Instance Training
335: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
308: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: Running Multi Instance Training
 88: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
343: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: Running Multi Instance Training
386: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: Running Multi Instance Training
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: Running Multi Instance Training
113: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
485: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: Running Multi Instance Training
335: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
199: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: Running Multi Instance Training
343: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
303: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: Running Multi Instance Training
199: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
326: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: Running Multi Instance Training
303: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
431: Running Multi Instance Training
431: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
430: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: Running Multi Instance Training
430: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
116: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: Running Multi Instance Training
326: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
422: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: Running Multi Instance Training
116: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 53: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
264: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: Running Multi Instance Training
422: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: Running Multi Instance Training
505: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: Running Multi Instance Training
 53: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
138: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: Running Multi Instance Training
264: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
269: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
269: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
173: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: Running Multi Instance Training
138: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: Running Multi Instance Training
269: Running Multi Instance Training
402: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
269: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
312: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: Running Multi Instance Training
173: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
190: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: Running Multi Instance Training
312: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
329: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
453: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
344: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: Running Multi Instance Training
190: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
162: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: Running Multi Instance Training
119: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
329: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: Running Multi Instance Training
305: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
453: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: Running Multi Instance Training
438: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
344: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: Running Multi Instance Training
119: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: Running Multi Instance Training
305: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: Running Multi Instance Training
162: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: Running Multi Instance Training
438: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
483: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
248: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
309: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: Running Multi Instance Training
459: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 97: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: Running Multi Instance Training
483: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: Running Multi Instance Training
248: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
192: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
457: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: Running Multi Instance Training
309: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: Running Multi Instance Training
 76: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 97: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: Running Multi Instance Training
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: Running Multi Instance Training
192: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
457: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
298: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 76: Running Multi Instance Training
 76: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 48: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
215: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
215: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
258: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: Running Multi Instance Training
354: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
298: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: Running Multi Instance Training
 48: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: Running Multi Instance Training
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
215: Running Multi Instance Training
215: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
324: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: Running Multi Instance Training
354: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 94: STARTING TIMING RUN AT 2021-10-05 08:07:28 AM
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: Running Multi Instance Training
324: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
366: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
366: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: Running Multi Instance Training
 94: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
510: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
366: Running Multi Instance Training
163: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
366: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: Running Multi Instance Training
510: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: Running Multi Instance Training
163: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
358: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
456: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: Running Multi Instance Training
358: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: Running Multi Instance Training
456: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
273: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: Running Multi Instance Training
273: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 10: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: Running Multi Instance Training
321: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 10: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
440: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 25: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: Running Multi Instance Training
369: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
369: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
321: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: Running Multi Instance Training
440: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: Running Multi Instance Training
 25: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
369: Running Multi Instance Training
369: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
127: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
104: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: Running Multi Instance Training
127: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
154: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: Running Multi Instance Training
104: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
293: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: Running Multi Instance Training
154: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: Running Multi Instance Training
293: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
161: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
289: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: Running Multi Instance Training
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
289: Running Multi Instance Training
289: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
145: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: Running Multi Instance Training
384: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: Running Multi Instance Training
197: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
197: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
183: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
429: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
197: Running Multi Instance Training
197: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: Running Multi Instance Training
183: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
486: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: Running Multi Instance Training
429: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
245: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: Running Multi Instance Training
486: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: Running Multi Instance Training
245: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
265: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: Running Multi Instance Training
265: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
117: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: Running Multi Instance Training
117: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
270: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: Running Multi Instance Training
270: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
454: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: Running Multi Instance Training
454: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
420: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: Running Multi Instance Training
420: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: Running Multi Instance Training
436: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
327: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: Running Multi Instance Training
327: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
310: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: Running Multi Instance Training
310: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
458: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: Running Multi Instance Training
458: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
160: STARTING TIMING RUN AT 2021-10-05 08:07:29 AM
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: Running Multi Instance Training
160: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483000 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483000 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 12: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 76: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 32: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 46: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 69: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 12: creating process group
 28: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 16: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 40: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 64: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  5: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 26: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 72: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 77: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: creating process group
 47: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 47: creating process group
 70: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  2: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  2: creating process group
 29: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 29: creating process group
 17: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 17: creating process group
 42: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 42: creating process group
100: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 65: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  6: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  6: creating process group
 26: creating process group
 73: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 96: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 78: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 78: creating process group
 34: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 34: creating process group
 46: creating process group
 69: creating process group
  3: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: creating process group
120: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 28: creating process group
 18: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 18: creating process group
 43: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 43: creating process group
102: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
102: creating process group
 66: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  7: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  7: creating process group
 24: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 74: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 74: creating process group
 97: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 76: creating process group
 35: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 35: creating process group
 44: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 71: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  0: creating process group
 31: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: creating process group
 40: creating process group
103: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
103: creating process group
 67: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
112: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  5: creating process group
 92: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 27: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 75: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 75: creating process group
 84: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 77: creating process group
 32: creating process group
 21: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 45: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 70: creating process group
  1: creating process group
 31: creating process group
 16: creating process group
 41: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
100: creating process group
 64: creating process group
113: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  4: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 25: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 72: creating process group
 85: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: creating process group
 79: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
108: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 82: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 44: creating process group
 71: creating process group
120: creating process group
 30: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 41: creating process group
101: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 65: creating process group
115: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 94: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 27: creating process group
 73: creating process group
 86: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 86: creating process group
 96: creating process group
 79: creating process group
 88: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
109: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
140: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 83: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 83: creating process group
 22: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 45: creating process group
129: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
164: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 68: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 13: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
168: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 30: creating process group
101: creating process group
174: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
148: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 66: creating process group
112: creating process group
  4: creating process group
136: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: creating process group
152: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 24: creating process group
 87: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 87: creating process group
 97: creating process group
160: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 91: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
144: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
110: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
142: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 82: creating process group
 23: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
130: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
165: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 14: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 36: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
169: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
175: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
148: creating process group
 67: creating process group
113: creating process group
137: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: creating process group
 92: creating process group
153: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
153: creating process group
 25: creating process group
 84: creating process group
 98: creating process group
 88: creating process group
145: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: creating process group
109: creating process group
140: creating process group
 81: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 21: creating process group
131: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
131: creating process group
224: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 68: creating process group
 15: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 37: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 37: creating process group
216: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
170: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
204: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
209: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
220: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
174: creating process group
114: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
138: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
138: creating process group
237: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
201: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: creating process group
212: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
154: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
154: creating process group
192: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 85: creating process group
229: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
196: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 91: creating process group
146: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
146: creating process group
110: creating process group
142: creating process group
 80: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 22: creating process group
129: creating process group
225: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
225: creating process group
167: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 13: creating process group
 39: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 39: creating process group
218: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: creating process group
205: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
221: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
175: creating process group
149: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
114: creating process group
139: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
139: creating process group
238: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
238: creating process group
202: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 94: creating process group
213: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
155: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
155: creating process group
193: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
193: creating process group
230: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
162: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
198: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
198: creating process group
 89: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
147: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
147: creating process group
108: creating process group
141: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 81: creating process group
 23: creating process group
130: creating process group
226: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
226: creating process group
164: creating process group
 14: creating process group
121: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 36: creating process group
219: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
168: creating process group
252: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
207: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
240: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
209: creating process group
222: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
173: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
149: creating process group
115: creating process group
136: creating process group
244: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
239: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
189: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
248: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
203: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
203: creating process group
176: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
212: creating process group
152: creating process group
194: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
194: creating process group
231: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
231: creating process group
163: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
199: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
199: creating process group
 90: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
144: creating process group
111: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
181: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
143: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: creating process group
 20: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
128: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
227: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
227: creating process group
165: creating process group
 15: creating process group
122: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 38: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
216: creating process group
169: creating process group
204: creating process group
241: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: creating process group
232: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
223: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
172: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
150: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
184: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
184: creating process group
245: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
237: creating process group
190: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
250: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
201: creating process group
177: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
177: creating process group
213: creating process group
156: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: creating process group
229: creating process group
160: creating process group
196: creating process group
 89: creating process group
111: creating process group
182: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
141: creating process group
 20: creating process group
128: creating process group
224: creating process group
166: creating process group
123: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
218: creating process group
170: creating process group
253: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
205: creating process group
242: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
210: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
220: creating process group
173: creating process group
151: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
185: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
185: creating process group
246: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
246: creating process group
239: creating process group
191: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
191: creating process group
251: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
202: creating process group
178: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
178: creating process group
214: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
156: creating process group
192: creating process group
133: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
230: creating process group
161: creating process group
197: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 90: creating process group
183: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 10: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
143: creating process group
167: creating process group
121: creating process group
 38: creating process group
219: creating process group
254: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
207: creating process group
243: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
243: creating process group
208: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
233: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
233: creating process group
221: creating process group
172: creating process group
150: creating process group
187: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
187: creating process group
247: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
247: creating process group
236: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
189: creating process group
248: creating process group
200: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
176: creating process group
215: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
158: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
134: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
228: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
162: creating process group
197: creating process group
181: creating process group
 11: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 11: creating process group
392: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
260: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
122: creating process group
217: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
255: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
255: creating process group
206: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
432: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
240: creating process group
210: creating process group
235: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
222: creating process group
151: creating process group
186: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
244: creating process group
236: creating process group
285: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
190: creating process group
249: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
200: creating process group
179: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
214: creating process group
276: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
159: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
133: creating process group
228: creating process group
163: creating process group
182: creating process group
325: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: creating process group
394: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
261: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
261: creating process group
123: creating process group
444: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
217: creating process group
253: creating process group
206: creating process group
374: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
241: creating process group
424: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
208: creating process group
232: creating process group
223: creating process group
388: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
340: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 53: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
186: creating process group
256: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
364: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
292: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
245: creating process group
 56: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
416: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
286: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
188: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
250: creating process group
380: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
332: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
179: creating process group
215: creating process group
344: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
336: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
396: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
157: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
134: creating process group
360: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
280: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
268: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
352: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
328: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
384: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
183: creating process group
325: creating process group
264: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
303: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
288: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
357: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
296: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
272: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: creating process group
320: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
420: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
438: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
440: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
428: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
467: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
395: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
262: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
468: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
445: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
445: creating process group
254: creating process group
433: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: creating process group
242: creating process group
425: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
425: creating process group
234: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
342: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
342: creating process group
376: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
257: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
257: creating process group
316: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
293: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
293: creating process group
286: creating process group
188: creating process group
251: creating process group
381: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
333: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
345: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 61: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
338: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
276: creating process group
397: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
158: creating process group
132: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
361: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
348: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
281: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
270: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
124: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
353: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
353: creating process group
329: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
385: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
180: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
324: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 48: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
265: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: creating process group
289: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
310: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
358: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
358: creating process group
297: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
273: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: creating process group
 10: creating process group
369: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
422: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
481: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
438: creating process group
441: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
453: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
476: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
467: creating process group
500: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
392: creating process group
489: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
263: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
263: creating process group
492: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
409: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
471: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
471: creating process group
446: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
446: creating process group
252: creating process group
434: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
374: creating process group
426: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
426: creating process group
473: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
412: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
496: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
235: creating process group
448: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
448: creating process group
389: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
389: creating process group
343: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
377: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
461: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 54: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: creating process group
318: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
365: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
365: creating process group
294: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
304: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 57: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
285: creating process group
404: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
249: creating process group
382: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: creating process group
334: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
347: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 62: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
339: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
504: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
278: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
398: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
159: creating process group
135: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
362: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
362: creating process group
349: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
349: creating process group
282: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
282: creating process group
271: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
125: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
125: creating process group
400: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: creating process group
330: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
330: creating process group
386: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
180: creating process group
324: creating process group
 49: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
266: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
266: creating process group
303: creating process group
290: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
290: creating process group
309: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
359: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
359: creating process group
298: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
274: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
274: creating process group
105: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
105: creating process group
117: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
370: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: creating process group
484: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
420: creating process group
482: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
437: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
442: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
454: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
454: creating process group
457: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
429: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
429: creating process group
477: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
477: creating process group
464: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
501: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
394: creating process group
490: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
260: creating process group
494: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
410: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
468: creating process group
447: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
447: creating process group
435: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
435: creating process group
373: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: creating process group
474: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
497: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
497: creating process group
234: creating process group
449: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
449: creating process group
390: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
390: creating process group
340: creating process group
378: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
462: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 55: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: creating process group
316: creating process group
366: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
366: creating process group
295: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
295: creating process group
305: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 58: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
418: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
287: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
383: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
335: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
335: creating process group
344: creating process group
 63: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
336: creating process group
506: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
399: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
157: creating process group
132: creating process group
363: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
363: creating process group
350: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
283: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
283: creating process group
268: creating process group
126: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
402: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
402: creating process group
355: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
331: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
387: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
326: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 50: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
267: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
267: creating process group
302: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
291: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
291: creating process group
313: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
310: creating process group
357: creating process group
299: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
299: creating process group
275: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
106: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
106: creating process group
118: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
118: creating process group
369: creating process group
322: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
485: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
422: creating process group
483: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
509: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
439: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
443: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
455: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
458: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
430: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
430: creating process group
478: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
478: creating process group
464: creating process group
503: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
395: creating process group
491: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
262: creating process group
494: creating process group
411: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
469: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
444: creating process group
432: creating process group
372: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
424: creating process group
475: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
498: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
498: creating process group
450: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
450: creating process group
391: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
391: creating process group
341: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: creating process group
460: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 53: creating process group
256: creating process group
318: creating process group
367: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
367: creating process group
292: creating process group
306: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 56: creating process group
416: creating process group
284: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
406: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
380: creating process group
332: creating process group
345: creating process group
 62: creating process group
337: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
507: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
278: creating process group
396: creating process group
135: creating process group
360: creating process group
351: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
280: creating process group
269: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
124: creating process group
403: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
403: creating process group
352: creating process group
328: creating process group
384: creating process group
327: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 48: creating process group
264: creating process group
301: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
288: creating process group
315: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
308: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
356: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
296: creating process group
272: creating process group
107: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
107: creating process group
117: creating process group
370: creating process group
323: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
323: creating process group
486: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
481: creating process group
510: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
440: creating process group
453: creating process group
459: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
431: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
431: creating process group
476: creating process group
466: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
500: creating process group
393: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
489: creating process group
492: creating process group
409: creating process group
470: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
433: creating process group
373: creating process group
473: creating process group
412: creating process group
499: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
451: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
451: creating process group
388: creating process group
343: creating process group
376: creating process group
461: creating process group
 54: creating process group
317: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
364: creating process group
294: creating process group
307: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 57: creating process group
417: creating process group
287: creating process group
407: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
407: creating process group
381: creating process group
333: creating process group
347: creating process group
 63: creating process group
338: creating process group
504: creating process group
277: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
397: creating process group
361: creating process group
348: creating process group
281: creating process group
270: creating process group
126: creating process group
400: creating process group
355: creating process group
329: creating process group
385: creating process group
326: creating process group
 49: creating process group
265: creating process group
302: creating process group
289: creating process group
315: creating process group
309: creating process group
356: creating process group
297: creating process group
273: creating process group
116: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
368: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
320: creating process group
487: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
423: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
482: creating process group
511: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: creating process group
441: creating process group
455: creating process group
457: creating process group
428: creating process group
479: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
465: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
501: creating process group
393: creating process group
490: creating process group
493: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
410: creating process group
469: creating process group
434: creating process group
372: creating process group
474: creating process group
413: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
496: creating process group
341: creating process group
377: creating process group
462: creating process group
 55: creating process group
319: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
304: creating process group
 58: creating process group
418: creating process group
284: creating process group
404: creating process group
383: creating process group
334: creating process group
346: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 61: creating process group
339: creating process group
505: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: creating process group
398: creating process group
350: creating process group
271: creating process group
127: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
401: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
331: creating process group
386: creating process group
327: creating process group
 50: creating process group
301: creating process group
313: creating process group
311: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
298: creating process group
275: creating process group
119: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
371: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
322: creating process group
484: creating process group
421: creating process group
483: creating process group
508: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
437: creating process group
442: creating process group
452: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
458: creating process group
479: creating process group
465: creating process group
502: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
491: creating process group
495: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
411: creating process group
470: creating process group
475: creating process group
414: creating process group
499: creating process group
378: creating process group
463: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 52: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
317: creating process group
305: creating process group
 59: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
419: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: creating process group
346: creating process group
 60: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
337: creating process group
506: creating process group
277: creating process group
399: creating process group
351: creating process group
269: creating process group
127: creating process group
401: creating process group
387: creating process group
 51: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
312: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
308: creating process group
116: creating process group
368: creating process group
485: creating process group
423: creating process group
480: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
509: creating process group
439: creating process group
443: creating process group
452: creating process group
459: creating process group
466: creating process group
503: creating process group
488: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
493: creating process group
408: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
472: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: creating process group
460: creating process group
 52: creating process group
319: creating process group
306: creating process group
 59: creating process group
419: creating process group
406: creating process group
 60: creating process group
507: creating process group
 51: creating process group
314: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
311: creating process group
119: creating process group
371: creating process group
486: creating process group
480: creating process group
511: creating process group
456: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
502: creating process group
488: creating process group
495: creating process group
408: creating process group
472: creating process group
413: creating process group
463: creating process group
307: creating process group
505: creating process group
312: creating process group
487: creating process group
510: creating process group
456: creating process group
314: creating process group
508: creating process group
  0: Process group successfully created for rank 0 . Now a global mpi barrier...
 14: Process group successfully created for rank 14 . Now a global mpi barrier...
205: Process group successfully created for rank 205 . Now a global mpi barrier...
208: Process group successfully created for rank 208 . Now a global mpi barrier...
202: Process group successfully created for rank 202 . Now a global mpi barrier...
111: Process group successfully created for rank 111 . Now a global mpi barrier...
207: Process group successfully created for rank 207 . Now a global mpi barrier...
210: Process group successfully created for rank 210 . Now a global mpi barrier...
158: Process group successfully created for rank 158 . Now a global mpi barrier...
216: Process group successfully created for rank 216 . Now a global mpi barrier...
211: Process group successfully created for rank 211 . Now a global mpi barrier...
226: Process group successfully created for rank 226 . Now a global mpi barrier...
217: Process group successfully created for rank 217 . Now a global mpi barrier...
220: Process group successfully created for rank 220 . Now a global mpi barrier...
175: Process group successfully created for rank 175 . Now a global mpi barrier...
159: Process group successfully created for rank 159 . Now a global mpi barrier...
182: Process group successfully created for rank 182 . Now a global mpi barrier...
227: Process group successfully created for rank 227 . Now a global mpi barrier...
218: Process group successfully created for rank 218 . Now a global mpi barrier...
203: Process group successfully created for rank 203 . Now a global mpi barrier...
212: Process group successfully created for rank 212 . Now a global mpi barrier...
229: Process group successfully created for rank 229 . Now a global mpi barrier...
219: Process group successfully created for rank 219 . Now a global mpi barrier...
232: Process group successfully created for rank 232 . Now a global mpi barrier...
221: Process group successfully created for rank 221 . Now a global mpi barrier...
244: Process group successfully created for rank 244 . Now a global mpi barrier...
213: Process group successfully created for rank 213 . Now a global mpi barrier...
230: Process group successfully created for rank 230 . Now a global mpi barrier...
242: Process group successfully created for rank 242 . Now a global mpi barrier...
245: Process group successfully created for rank 245 . Now a global mpi barrier...
236: Process group successfully created for rank 236 . Now a global mpi barrier...
249: Process group successfully created for rank 249 . Now a global mpi barrier...
214: Process group successfully created for rank 214 . Now a global mpi barrier...
231: Process group successfully created for rank 231 . Now a global mpi barrier...
253: Process group successfully created for rank 253 . Now a global mpi barrier...
243: Process group successfully created for rank 243 . Now a global mpi barrier...
233: Process group successfully created for rank 233 . Now a global mpi barrier...
251: Process group successfully created for rank 251 . Now a global mpi barrier...
215: Process group successfully created for rank 215 . Now a global mpi barrier...
264: Process group successfully created for rank 264 . Now a global mpi barrier...
254: Process group successfully created for rank 254 . Now a global mpi barrier...
256: Process group successfully created for rank 256 . Now a global mpi barrier...
267: Process group successfully created for rank 267 . Now a global mpi barrier...
255: Process group successfully created for rank 255 . Now a global mpi barrier...
234: Process group successfully created for rank 234 . Now a global mpi barrier...
257: Process group successfully created for rank 257 . Now a global mpi barrier...
292: Process group successfully created for rank 292 . Now a global mpi barrier...
280: Process group successfully created for rank 280 . Now a global mpi barrier...
268: Process group successfully created for rank 268 . Now a global mpi barrier...
266: Process group successfully created for rank 266 . Now a global mpi barrier...
289: Process group successfully created for rank 289 . Now a global mpi barrier...
299: Process group successfully created for rank 299 . Now a global mpi barrier...
293: Process group successfully created for rank 293 . Now a global mpi barrier...
279: Process group successfully created for rank 279 . Now a global mpi barrier...
269: Process group successfully created for rank 269 . Now a global mpi barrier...
300: Process group successfully created for rank 300 . Now a global mpi barrier...
290: Process group successfully created for rank 290 . Now a global mpi barrier...
304: Process group successfully created for rank 304 . Now a global mpi barrier...
302: Process group successfully created for rank 302 . Now a global mpi barrier...
291: Process group successfully created for rank 291 . Now a global mpi barrier...
303: Process group successfully created for rank 303 . Now a global mpi barrier...
314: Process group successfully created for rank 314 . Now a global mpi barrier...
323: Process group successfully created for rank 323 . Now a global mpi barrier...
318: Process group successfully created for rank 318 . Now a global mpi barrier...
311: Process group successfully created for rank 311 . Now a global mpi barrier...
328: Process group successfully created for rank 328 . Now a global mpi barrier...
332: Process group successfully created for rank 332 . Now a global mpi barrier...
336: Process group successfully created for rank 336 . Now a global mpi barrier...
329: Process group successfully created for rank 329 . Now a global mpi barrier...
324: Process group successfully created for rank 324 . Now a global mpi barrier...
341: Process group successfully created for rank 341 . Now a global mpi barrier...
333: Process group successfully created for rank 333 . Now a global mpi barrier...
344: Process group successfully created for rank 344 . Now a global mpi barrier...
337: Process group successfully created for rank 337 . Now a global mpi barrier...
331: Process group successfully created for rank 331 . Now a global mpi barrier...
326: Process group successfully created for rank 326 . Now a global mpi barrier...
343: Process group successfully created for rank 343 . Now a global mpi barrier...
335: Process group successfully created for rank 335 . Now a global mpi barrier...
330: Process group successfully created for rank 330 . Now a global mpi barrier...
342: Process group successfully created for rank 342 . Now a global mpi barrier...
334: Process group successfully created for rank 334 . Now a global mpi barrier...
345: Process group successfully created for rank 345 . Now a global mpi barrier...
320: Process group successfully created for rank 320 . Now a global mpi barrier...
347: Process group successfully created for rank 347 . Now a global mpi barrier...
352: Process group successfully created for rank 352 . Now a global mpi barrier...
346: Process group successfully created for rank 346 . Now a global mpi barrier...
363: Process group successfully created for rank 363 . Now a global mpi barrier...
356: Process group successfully created for rank 356 . Now a global mpi barrier...
364: Process group successfully created for rank 364 . Now a global mpi barrier...
353: Process group successfully created for rank 353 . Now a global mpi barrier...
360: Process group successfully created for rank 360 . Now a global mpi barrier...
354: Process group successfully created for rank 354 . Now a global mpi barrier...
358: Process group successfully created for rank 358 . Now a global mpi barrier...
365: Process group successfully created for rank 365 . Now a global mpi barrier...
355: Process group successfully created for rank 355 . Now a global mpi barrier...
357: Process group successfully created for rank 357 . Now a global mpi barrier...
369: Process group successfully created for rank 369 . Now a global mpi barrier...
367: Process group successfully created for rank 367 . Now a global mpi barrier...
366: Process group successfully created for rank 366 . Now a global mpi barrier...
388: Process group successfully created for rank 388 . Now a global mpi barrier...
400: Process group successfully created for rank 400 . Now a global mpi barrier...
402: Process group successfully created for rank 402 . Now a global mpi barrier...
403: Process group successfully created for rank 403 . Now a global mpi barrier...
411: Process group successfully created for rank 411 . Now a global mpi barrier...
414: Process group successfully created for rank 414 . Now a global mpi barrier...
404: Process group successfully created for rank 404 . Now a global mpi barrier...
433: Process group successfully created for rank 433 . Now a global mpi barrier...
422: Process group successfully created for rank 422 . Now a global mpi barrier...
434: Process group successfully created for rank 434 . Now a global mpi barrier...
424: Process group successfully created for rank 424 . Now a global mpi barrier...
405: Process group successfully created for rank 405 . Now a global mpi barrier...
437: Process group successfully created for rank 437 . Now a global mpi barrier...
454: Process group successfully created for rank 454 . Now a global mpi barrier...
444: Process group successfully created for rank 444 . Now a global mpi barrier...
455: Process group successfully created for rank 455 . Now a global mpi barrier...
466: Process group successfully created for rank 466 . Now a global mpi barrier...
475: Process group successfully created for rank 475 . Now a global mpi barrier...
476: Process group successfully created for rank 476 . Now a global mpi barrier...
469: Process group successfully created for rank 469 . Now a global mpi barrier...
474: Process group successfully created for rank 474 . Now a global mpi barrier...
492: Process group successfully created for rank 492 . Now a global mpi barrier...
468: Process group successfully created for rank 468 . Now a global mpi barrier...
477: Process group successfully created for rank 477 . Now a global mpi barrier...
491: Process group successfully created for rank 491 . Now a global mpi barrier...
493: Process group successfully created for rank 493 . Now a global mpi barrier...
483: Process group successfully created for rank 483 . Now a global mpi barrier...
500: Process group successfully created for rank 500 . Now a global mpi barrier...
501: Process group successfully created for rank 501 . Now a global mpi barrier...
502: Process group successfully created for rank 502 . Now a global mpi barrier...
313: Process group successfully created for rank 313 . Now a global mpi barrier...
316: Process group successfully created for rank 316 . Now a global mpi barrier...
315: Process group successfully created for rank 315 . Now a global mpi barrier...
198: Process group successfully created for rank 198 . Now a global mpi barrier...
368: Process group successfully created for rank 368 . Now a global mpi barrier...
378: Process group successfully created for rank 378 . Now a global mpi barrier...
380: Process group successfully created for rank 380 . Now a global mpi barrier...
386: Process group successfully created for rank 386 . Now a global mpi barrier...
389: Process group successfully created for rank 389 . Now a global mpi barrier...
410: Process group successfully created for rank 410 . Now a global mpi barrier...
398: Process group successfully created for rank 398 . Now a global mpi barrier...
409: Process group successfully created for rank 409 . Now a global mpi barrier...
511: Process group successfully created for rank 511 . Now a global mpi barrier...
  9: Process group successfully created for rank 9 . Now a global mpi barrier...
317: Process group successfully created for rank 317 . Now a global mpi barrier...
325: Process group successfully created for rank 325 . Now a global mpi barrier...
258: Process group successfully created for rank 258 . Now a global mpi barrier...
338: Process group successfully created for rank 338 . Now a global mpi barrier...
281: Process group successfully created for rank 281 . Now a global mpi barrier...
327: Process group successfully created for rank 327 . Now a global mpi barrier...
340: Process group successfully created for rank 340 . Now a global mpi barrier...
137: Process group successfully created for rank 137 . Now a global mpi barrier...
348: Process group successfully created for rank 348 . Now a global mpi barrier...
309: Process group successfully created for rank 309 . Now a global mpi barrier...
359: Process group successfully created for rank 359 . Now a global mpi barrier...
370: Process group successfully created for rank 370 . Now a global mpi barrier...
372: Process group successfully created for rank 372 . Now a global mpi barrier...
306: Process group successfully created for rank 306 . Now a global mpi barrier...
339: Process group successfully created for rank 339 . Now a global mpi barrier...
362: Process group successfully created for rank 362 . Now a global mpi barrier...
349: Process group successfully created for rank 349 . Now a global mpi barrier...
381: Process group successfully created for rank 381 . Now a global mpi barrier...
350: Process group successfully created for rank 350 . Now a global mpi barrier...
373: Process group successfully created for rank 373 . Now a global mpi barrier...
351: Process group successfully created for rank 351 . Now a global mpi barrier...
371: Process group successfully created for rank 371 . Now a global mpi barrier...
374: Process group successfully created for rank 374 . Now a global mpi barrier...
376: Process group successfully created for rank 376 . Now a global mpi barrier...
361: Process group successfully created for rank 361 . Now a global mpi barrier...
379: Process group successfully created for rank 379 . Now a global mpi barrier...
399: Process group successfully created for rank 399 . Now a global mpi barrier...
423: Process group successfully created for rank 423 . Now a global mpi barrier...
498: Process group successfully created for rank 498 . Now a global mpi barrier...
 82: Process group successfully created for rank 82 . Now a global mpi barrier...
377: Process group successfully created for rank 377 . Now a global mpi barrier...
383: Process group successfully created for rank 383 . Now a global mpi barrier...
384: Process group successfully created for rank 384 . Now a global mpi barrier...
375: Process group successfully created for rank 375 . Now a global mpi barrier...
382: Process group successfully created for rank 382 . Now a global mpi barrier...
385: Process group successfully created for rank 385 . Now a global mpi barrier...
392: Process group successfully created for rank 392 . Now a global mpi barrier...
387: Process group successfully created for rank 387 . Now a global mpi barrier...
396: Process group successfully created for rank 396 . Now a global mpi barrier...
401: Process group successfully created for rank 401 . Now a global mpi barrier...
395: Process group successfully created for rank 395 . Now a global mpi barrier...
415: Process group successfully created for rank 415 . Now a global mpi barrier...
408: Process group successfully created for rank 408 . Now a global mpi barrier...
391: Process group successfully created for rank 391 . Now a global mpi barrier...
425: Process group successfully created for rank 425 . Now a global mpi barrier...
412: Process group successfully created for rank 412 . Now a global mpi barrier...
417: Process group successfully created for rank 417 . Now a global mpi barrier...
397: Process group successfully created for rank 397 . Now a global mpi barrier...
426: Process group successfully created for rank 426 . Now a global mpi barrier...
413: Process group successfully created for rank 413 . Now a global mpi barrier...
418: Process group successfully created for rank 418 . Now a global mpi barrier...
407: Process group successfully created for rank 407 . Now a global mpi barrier...
428: Process group successfully created for rank 428 . Now a global mpi barrier...
419: Process group successfully created for rank 419 . Now a global mpi barrier...
406: Process group successfully created for rank 406 . Now a global mpi barrier...
429: Process group successfully created for rank 429 . Now a global mpi barrier...
499: Process group successfully created for rank 499 . Now a global mpi barrier...
  1: Process group successfully created for rank 1 . Now a global mpi barrier...
  2: Process group successfully created for rank 2 . Now a global mpi barrier...
  3: Process group successfully created for rank 3 . Now a global mpi barrier...
393: Process group successfully created for rank 393 . Now a global mpi barrier...
427: Process group successfully created for rank 427 . Now a global mpi barrier...
420: Process group successfully created for rank 420 . Now a global mpi barrier...
394: Process group successfully created for rank 394 . Now a global mpi barrier...
435: Process group successfully created for rank 435 . Now a global mpi barrier...
430: Process group successfully created for rank 430 . Now a global mpi barrier...
432: Process group successfully created for rank 432 . Now a global mpi barrier...
421: Process group successfully created for rank 421 . Now a global mpi barrier...
439: Process group successfully created for rank 439 . Now a global mpi barrier...
431: Process group successfully created for rank 431 . Now a global mpi barrier...
390: Process group successfully created for rank 390 . Now a global mpi barrier...
416: Process group successfully created for rank 416 . Now a global mpi barrier...
438: Process group successfully created for rank 438 . Now a global mpi barrier...
440: Process group successfully created for rank 440 . Now a global mpi barrier...
447: Process group successfully created for rank 447 . Now a global mpi barrier...
442: Process group successfully created for rank 442 . Now a global mpi barrier...
452: Process group successfully created for rank 452 . Now a global mpi barrier...
445: Process group successfully created for rank 445 . Now a global mpi barrier...
448: Process group successfully created for rank 448 . Now a global mpi barrier...
461: Process group successfully created for rank 461 . Now a global mpi barrier...
443: Process group successfully created for rank 443 . Now a global mpi barrier...
453: Process group successfully created for rank 453 . Now a global mpi barrier...
446: Process group successfully created for rank 446 . Now a global mpi barrier...
449: Process group successfully created for rank 449 . Now a global mpi barrier...
460: Process group successfully created for rank 460 . Now a global mpi barrier...
441: Process group successfully created for rank 441 . Now a global mpi barrier...
457: Process group successfully created for rank 457 . Now a global mpi barrier...
451: Process group successfully created for rank 451 . Now a global mpi barrier...
462: Process group successfully created for rank 462 . Now a global mpi barrier...
458: Process group successfully created for rank 458 . Now a global mpi barrier...
464: Process group successfully created for rank 464 . Now a global mpi barrier...
450: Process group successfully created for rank 450 . Now a global mpi barrier...
465: Process group successfully created for rank 465 . Now a global mpi barrier...
467: Process group successfully created for rank 467 . Now a global mpi barrier...
497: Process group successfully created for rank 497 . Now a global mpi barrier...
507: Process group successfully created for rank 507 . Now a global mpi barrier...
510: Process group successfully created for rank 510 . Now a global mpi barrier...
  6: Process group successfully created for rank 6 . Now a global mpi barrier...
 13: Process group successfully created for rank 13 . Now a global mpi barrier...
  7: Process group successfully created for rank 7 . Now a global mpi barrier...
  8: Process group successfully created for rank 8 . Now a global mpi barrier...
 15: Process group successfully created for rank 15 . Now a global mpi barrier...
  5: Process group successfully created for rank 5 . Now a global mpi barrier...
 16: Process group successfully created for rank 16 . Now a global mpi barrier...
 11: Process group successfully created for rank 11 . Now a global mpi barrier...
 12: Process group successfully created for rank 12 . Now a global mpi barrier...
 21: Process group successfully created for rank 21 . Now a global mpi barrier...
 28: Process group successfully created for rank 28 . Now a global mpi barrier...
 17: Process group successfully created for rank 17 . Now a global mpi barrier...
 18: Process group successfully created for rank 18 . Now a global mpi barrier...
 24: Process group successfully created for rank 24 . Now a global mpi barrier...
 19: Process group successfully created for rank 19 . Now a global mpi barrier...
 25: Process group successfully created for rank 25 . Now a global mpi barrier...
 34: Process group successfully created for rank 34 . Now a global mpi barrier...
 22: Process group successfully created for rank 22 . Now a global mpi barrier...
 31: Process group successfully created for rank 31 . Now a global mpi barrier...
 26: Process group successfully created for rank 26 . Now a global mpi barrier...
 23: Process group successfully created for rank 23 . Now a global mpi barrier...
 29: Process group successfully created for rank 29 . Now a global mpi barrier...
 27: Process group successfully created for rank 27 . Now a global mpi barrier...
 35: Process group successfully created for rank 35 . Now a global mpi barrier...
 20: Process group successfully created for rank 20 . Now a global mpi barrier...
 32: Process group successfully created for rank 32 . Now a global mpi barrier...
463: Process group successfully created for rank 463 . Now a global mpi barrier...
473: Process group successfully created for rank 473 . Now a global mpi barrier...
471: Process group successfully created for rank 471 . Now a global mpi barrier...
456: Process group successfully created for rank 456 . Now a global mpi barrier...
472: Process group successfully created for rank 472 . Now a global mpi barrier...
480: Process group successfully created for rank 480 . Now a global mpi barrier...
436: Process group successfully created for rank 436 . Now a global mpi barrier...
478: Process group successfully created for rank 478 . Now a global mpi barrier...
459: Process group successfully created for rank 459 . Now a global mpi barrier...
488: Process group successfully created for rank 488 . Now a global mpi barrier...
496: Process group successfully created for rank 496 . Now a global mpi barrier...
506: Process group successfully created for rank 506 . Now a global mpi barrier...
486: Process group successfully created for rank 486 . Now a global mpi barrier...
509: Process group successfully created for rank 509 . Now a global mpi barrier...
490: Process group successfully created for rank 490 . Now a global mpi barrier...
 30: Process group successfully created for rank 30 . Now a global mpi barrier...
 33: Process group successfully created for rank 33 . Now a global mpi barrier...
  4: Process group successfully created for rank 4 . Now a global mpi barrier...
 36: Process group successfully created for rank 36 . Now a global mpi barrier...
 41: Process group successfully created for rank 41 . Now a global mpi barrier...
 44: Process group successfully created for rank 44 . Now a global mpi barrier...
 37: Process group successfully created for rank 37 . Now a global mpi barrier...
 42: Process group successfully created for rank 42 . Now a global mpi barrier...
 48: Process group successfully created for rank 48 . Now a global mpi barrier...
 38: Process group successfully created for rank 38 . Now a global mpi barrier...
 40: Process group successfully created for rank 40 . Now a global mpi barrier...
 49: Process group successfully created for rank 49 . Now a global mpi barrier...
 39: Process group successfully created for rank 39 . Now a global mpi barrier...
 43: Process group successfully created for rank 43 . Now a global mpi barrier...
 57: Process group successfully created for rank 57 . Now a global mpi barrier...
 50: Process group successfully created for rank 50 . Now a global mpi barrier...
 46: Process group successfully created for rank 46 . Now a global mpi barrier...
 58: Process group successfully created for rank 58 . Now a global mpi barrier...
 51: Process group successfully created for rank 51 . Now a global mpi barrier...
 45: Process group successfully created for rank 45 . Now a global mpi barrier...
 52: Process group successfully created for rank 52 . Now a global mpi barrier...
 56: Process group successfully created for rank 56 . Now a global mpi barrier...
 60: Process group successfully created for rank 60 . Now a global mpi barrier...
 47: Process group successfully created for rank 47 . Now a global mpi barrier...
 68: Process group successfully created for rank 68 . Now a global mpi barrier...
 64: Process group successfully created for rank 64 . Now a global mpi barrier...
 53: Process group successfully created for rank 53 . Now a global mpi barrier...
 59: Process group successfully created for rank 59 . Now a global mpi barrier...
 61: Process group successfully created for rank 61 . Now a global mpi barrier...
 70: Process group successfully created for rank 70 . Now a global mpi barrier...
 66: Process group successfully created for rank 66 . Now a global mpi barrier...
 55: Process group successfully created for rank 55 . Now a global mpi barrier...
 62: Process group successfully created for rank 62 . Now a global mpi barrier...
 76: Process group successfully created for rank 76 . Now a global mpi barrier...
 80: Process group successfully created for rank 80 . Now a global mpi barrier...
 71: Process group successfully created for rank 71 . Now a global mpi barrier...
 67: Process group successfully created for rank 67 . Now a global mpi barrier...
 54: Process group successfully created for rank 54 . Now a global mpi barrier...
 63: Process group successfully created for rank 63 . Now a global mpi barrier...
 72: Process group successfully created for rank 72 . Now a global mpi barrier...
 81: Process group successfully created for rank 81 . Now a global mpi barrier...
 69: Process group successfully created for rank 69 . Now a global mpi barrier...
 65: Process group successfully created for rank 65 . Now a global mpi barrier...
 73: Process group successfully created for rank 73 . Now a global mpi barrier...
 84: Process group successfully created for rank 84 . Now a global mpi barrier...
 78: Process group successfully created for rank 78 . Now a global mpi barrier...
 83: Process group successfully created for rank 83 . Now a global mpi barrier...
 74: Process group successfully created for rank 74 . Now a global mpi barrier...
 85: Process group successfully created for rank 85 . Now a global mpi barrier...
 79: Process group successfully created for rank 79 . Now a global mpi barrier...
 91: Process group successfully created for rank 91 . Now a global mpi barrier...
 75: Process group successfully created for rank 75 . Now a global mpi barrier...
 86: Process group successfully created for rank 86 . Now a global mpi barrier...
 89: Process group successfully created for rank 89 . Now a global mpi barrier...
 87: Process group successfully created for rank 87 . Now a global mpi barrier...
 90: Process group successfully created for rank 90 . Now a global mpi barrier...
 92: Process group successfully created for rank 92 . Now a global mpi barrier...
100: Process group successfully created for rank 100 . Now a global mpi barrier...
 93: Process group successfully created for rank 93 . Now a global mpi barrier...
 96: Process group successfully created for rank 96 . Now a global mpi barrier...
 88: Process group successfully created for rank 88 . Now a global mpi barrier...
 95: Process group successfully created for rank 95 . Now a global mpi barrier...
104: Process group successfully created for rank 104 . Now a global mpi barrier...
101: Process group successfully created for rank 101 . Now a global mpi barrier...
 94: Process group successfully created for rank 94 . Now a global mpi barrier...
 97: Process group successfully created for rank 97 . Now a global mpi barrier...
102: Process group successfully created for rank 102 . Now a global mpi barrier...
 98: Process group successfully created for rank 98 . Now a global mpi barrier...
103: Process group successfully created for rank 103 . Now a global mpi barrier...
 99: Process group successfully created for rank 99 . Now a global mpi barrier...
105: Process group successfully created for rank 105 . Now a global mpi barrier...
470: Process group successfully created for rank 470 . Now a global mpi barrier...
479: Process group successfully created for rank 479 . Now a global mpi barrier...
487: Process group successfully created for rank 487 . Now a global mpi barrier...
481: Process group successfully created for rank 481 . Now a global mpi barrier...
489: Process group successfully created for rank 489 . Now a global mpi barrier...
508: Process group successfully created for rank 508 . Now a global mpi barrier...
484: Process group successfully created for rank 484 . Now a global mpi barrier...
485: Process group successfully created for rank 485 . Now a global mpi barrier...
108: Process group successfully created for rank 108 . Now a global mpi barrier...
106: Process group successfully created for rank 106 . Now a global mpi barrier...
109: Process group successfully created for rank 109 . Now a global mpi barrier...
107: Process group successfully created for rank 107 . Now a global mpi barrier...
113: Process group successfully created for rank 113 . Now a global mpi barrier...
 10: Process group successfully created for rank 10 . Now a global mpi barrier...
121: Process group successfully created for rank 121 . Now a global mpi barrier...
114: Process group successfully created for rank 114 . Now a global mpi barrier...
116: Process group successfully created for rank 116 . Now a global mpi barrier...
120: Process group successfully created for rank 120 . Now a global mpi barrier...
115: Process group successfully created for rank 115 . Now a global mpi barrier...
 77: Process group successfully created for rank 77 . Now a global mpi barrier...
110: Process group successfully created for rank 110 . Now a global mpi barrier...
122: Process group successfully created for rank 122 . Now a global mpi barrier...
117: Process group successfully created for rank 117 . Now a global mpi barrier...
123: Process group successfully created for rank 123 . Now a global mpi barrier...
124: Process group successfully created for rank 124 . Now a global mpi barrier...
118: Process group successfully created for rank 118 . Now a global mpi barrier...
128: Process group successfully created for rank 128 . Now a global mpi barrier...
132: Process group successfully created for rank 132 . Now a global mpi barrier...
119: Process group successfully created for rank 119 . Now a global mpi barrier...
129: Process group successfully created for rank 129 . Now a global mpi barrier...
133: Process group successfully created for rank 133 . Now a global mpi barrier...
125: Process group successfully created for rank 125 . Now a global mpi barrier...
126: Process group successfully created for rank 126 . Now a global mpi barrier...
140: Process group successfully created for rank 140 . Now a global mpi barrier...
136: Process group successfully created for rank 136 . Now a global mpi barrier...
135: Process group successfully created for rank 135 . Now a global mpi barrier...
127: Process group successfully created for rank 127 . Now a global mpi barrier...
144: Process group successfully created for rank 144 . Now a global mpi barrier...
142: Process group successfully created for rank 142 . Now a global mpi barrier...
130: Process group successfully created for rank 130 . Now a global mpi barrier...
145: Process group successfully created for rank 145 . Now a global mpi barrier...
141: Process group successfully created for rank 141 . Now a global mpi barrier...
131: Process group successfully created for rank 131 . Now a global mpi barrier...
148: Process group successfully created for rank 148 . Now a global mpi barrier...
138: Process group successfully created for rank 138 . Now a global mpi barrier...
154: Process group successfully created for rank 154 . Now a global mpi barrier...
156: Process group successfully created for rank 156 . Now a global mpi barrier...
146: Process group successfully created for rank 146 . Now a global mpi barrier...
149: Process group successfully created for rank 149 . Now a global mpi barrier...
157: Process group successfully created for rank 157 . Now a global mpi barrier...
160: Process group successfully created for rank 160 . Now a global mpi barrier...
147: Process group successfully created for rank 147 . Now a global mpi barrier...
150: Process group successfully created for rank 150 . Now a global mpi barrier...
155: Process group successfully created for rank 155 . Now a global mpi barrier...
164: Process group successfully created for rank 164 . Now a global mpi barrier...
152: Process group successfully created for rank 152 . Now a global mpi barrier...
161: Process group successfully created for rank 161 . Now a global mpi barrier...
165: Process group successfully created for rank 165 . Now a global mpi barrier...
168: Process group successfully created for rank 168 . Now a global mpi barrier...
172: Process group successfully created for rank 172 . Now a global mpi barrier...
177: Process group successfully created for rank 177 . Now a global mpi barrier...
153: Process group successfully created for rank 153 . Now a global mpi barrier...
162: Process group successfully created for rank 162 . Now a global mpi barrier...
167: Process group successfully created for rank 167 . Now a global mpi barrier...
169: Process group successfully created for rank 169 . Now a global mpi barrier...
163: Process group successfully created for rank 163 . Now a global mpi barrier...
170: Process group successfully created for rank 170 . Now a global mpi barrier...
171: Process group successfully created for rank 171 . Now a global mpi barrier...
174: Process group successfully created for rank 174 . Now a global mpi barrier...
184: Process group successfully created for rank 184 . Now a global mpi barrier...
224: Process group successfully created for rank 224 . Now a global mpi barrier...
223: Process group successfully created for rank 223 . Now a global mpi barrier...
235: Process group successfully created for rank 235 . Now a global mpi barrier...
238: Process group successfully created for rank 238 . Now a global mpi barrier...
237: Process group successfully created for rank 237 . Now a global mpi barrier...
248: Process group successfully created for rank 248 . Now a global mpi barrier...
228: Process group successfully created for rank 228 . Now a global mpi barrier...
246: Process group successfully created for rank 246 . Now a global mpi barrier...
247: Process group successfully created for rank 247 . Now a global mpi barrier...
239: Process group successfully created for rank 239 . Now a global mpi barrier...
240: Process group successfully created for rank 240 . Now a global mpi barrier...
241: Process group successfully created for rank 241 . Now a global mpi barrier...
504: Process group successfully created for rank 504 . Now a global mpi barrier...
495: Process group successfully created for rank 495 . Now a global mpi barrier...
505: Process group successfully created for rank 505 . Now a global mpi barrier...
494: Process group successfully created for rank 494 . Now a global mpi barrier...
112: Process group successfully created for rank 112 . Now a global mpi barrier...
134: Process group successfully created for rank 134 . Now a global mpi barrier...
143: Process group successfully created for rank 143 . Now a global mpi barrier...
166: Process group successfully created for rank 166 . Now a global mpi barrier...
151: Process group successfully created for rank 151 . Now a global mpi barrier...
186: Process group successfully created for rank 186 . Now a global mpi barrier...
180: Process group successfully created for rank 180 . Now a global mpi barrier...
173: Process group successfully created for rank 173 . Now a global mpi barrier...
139: Process group successfully created for rank 139 . Now a global mpi barrier...
178: Process group successfully created for rank 178 . Now a global mpi barrier...
185: Process group successfully created for rank 185 . Now a global mpi barrier...
189: Process group successfully created for rank 189 . Now a global mpi barrier...
181: Process group successfully created for rank 181 . Now a global mpi barrier...
187: Process group successfully created for rank 187 . Now a global mpi barrier...
196: Process group successfully created for rank 196 . Now a global mpi barrier...
183: Process group successfully created for rank 183 . Now a global mpi barrier...
190: Process group successfully created for rank 190 . Now a global mpi barrier...
200: Process group successfully created for rank 200 . Now a global mpi barrier...
176: Process group successfully created for rank 176 . Now a global mpi barrier...
225: Process group successfully created for rank 225 . Now a global mpi barrier...
188: Process group successfully created for rank 188 . Now a global mpi barrier...
179: Process group successfully created for rank 179 . Now a global mpi barrier...
192: Process group successfully created for rank 192 . Now a global mpi barrier...
252: Process group successfully created for rank 252 . Now a global mpi barrier...
209: Process group successfully created for rank 209 . Now a global mpi barrier...
259: Process group successfully created for rank 259 . Now a global mpi barrier...
191: Process group successfully created for rank 191 . Now a global mpi barrier...
201: Process group successfully created for rank 201 . Now a global mpi barrier...
199: Process group successfully created for rank 199 . Now a global mpi barrier...
260: Process group successfully created for rank 260 . Now a global mpi barrier...
204: Process group successfully created for rank 204 . Now a global mpi barrier...
222: Process group successfully created for rank 222 . Now a global mpi barrier...
250: Process group successfully created for rank 250 . Now a global mpi barrier...
271: Process group successfully created for rank 271 . Now a global mpi barrier...
197: Process group successfully created for rank 197 . Now a global mpi barrier...
206: Process group successfully created for rank 206 . Now a global mpi barrier...
193: Process group successfully created for rank 193 . Now a global mpi barrier...
270: Process group successfully created for rank 270 . Now a global mpi barrier...
261: Process group successfully created for rank 261 . Now a global mpi barrier...
276: Process group successfully created for rank 276 . Now a global mpi barrier...
194: Process group successfully created for rank 194 . Now a global mpi barrier...
282: Process group successfully created for rank 282 . Now a global mpi barrier...
262: Process group successfully created for rank 262 . Now a global mpi barrier...
195: Process group successfully created for rank 195 . Now a global mpi barrier...
283: Process group successfully created for rank 283 . Now a global mpi barrier...
265: Process group successfully created for rank 265 . Now a global mpi barrier...
263: Process group successfully created for rank 263 . Now a global mpi barrier...
295: Process group successfully created for rank 295 . Now a global mpi barrier...
278: Process group successfully created for rank 278 . Now a global mpi barrier...
294: Process group successfully created for rank 294 . Now a global mpi barrier...
284: Process group successfully created for rank 284 . Now a global mpi barrier...
277: Process group successfully created for rank 277 . Now a global mpi barrier...
288: Process group successfully created for rank 288 . Now a global mpi barrier...
296: Process group successfully created for rank 296 . Now a global mpi barrier...
272: Process group successfully created for rank 272 . Now a global mpi barrier...
301: Process group successfully created for rank 301 . Now a global mpi barrier...
305: Process group successfully created for rank 305 . Now a global mpi barrier...
285: Process group successfully created for rank 285 . Now a global mpi barrier...
312: Process group successfully created for rank 312 . Now a global mpi barrier...
308: Process group successfully created for rank 308 . Now a global mpi barrier...
273: Process group successfully created for rank 273 . Now a global mpi barrier...
322: Process group successfully created for rank 322 . Now a global mpi barrier...
503: Process group successfully created for rank 503 . Now a global mpi barrier...
319: Process group successfully created for rank 319 . Now a global mpi barrier...
286: Process group successfully created for rank 286 . Now a global mpi barrier...
310: Process group successfully created for rank 310 . Now a global mpi barrier...
274: Process group successfully created for rank 274 . Now a global mpi barrier...
482: Process group successfully created for rank 482 . Now a global mpi barrier...
287: Process group successfully created for rank 287 . Now a global mpi barrier...
275: Process group successfully created for rank 275 . Now a global mpi barrier...
307: Process group successfully created for rank 307 . Now a global mpi barrier...
297: Process group successfully created for rank 297 . Now a global mpi barrier...
298: Process group successfully created for rank 298 . Now a global mpi barrier...
321: Process group successfully created for rank 321 . Now a global mpi barrier...
 52: ... barrier passed on rank  52 .
180: ... barrier passed on rank  180 .
308: ... barrier passed on rank  308 .
436: ... barrier passed on rank  436 .
 46: ... barrier passed on rank  46 .
174: ... barrier passed on rank  174 .
302: ... barrier passed on rank  302 .
430: ... barrier passed on rank  430 .
 54: ... barrier passed on rank  54 .
182: ... barrier passed on rank  182 .
310: ... barrier passed on rank  310 .
438: ... barrier passed on rank  438 .
500: ... barrier passed on rank  500 .
372: ... barrier passed on rank  372 .
244: ... barrier passed on rank  244 .
116: ... barrier passed on rank  116 .
 44: ... barrier passed on rank  44 .
172: ... barrier passed on rank  172 .
300: ... barrier passed on rank  300 .
428: ... barrier passed on rank  428 .
238: ... barrier passed on rank  238 .
502: ... barrier passed on rank  502 .
164: ... barrier passed on rank  164 .
494: ... barrier passed on rank  494 .
374: ... barrier passed on rank  374 .
366: ... barrier passed on rank  366 .
246: ... barrier passed on rank  246 .
110: ... barrier passed on rank  110 .
118: ... barrier passed on rank  118 .
420: ... barrier passed on rank  420 .
166: ... barrier passed on rank  166 .
468: ... barrier passed on rank  468 .
 38: ... barrier passed on rank  38 .
340: ... barrier passed on rank  340 .
292: ... barrier passed on rank  292 .
250: ... barrier passed on rank  250 .
506: ... barrier passed on rank  506 .
 84: ... barrier passed on rank  84 .
422: ... barrier passed on rank  422 .
492: ... barrier passed on rank  492 .
122: ... barrier passed on rank  122 .
 36: ... barrier passed on rank  36 .
378: ... barrier passed on rank  378 .
364: ... barrier passed on rank  364 .
294: ... barrier passed on rank  294 .
 58: ... barrier passed on rank  58 .
236: ... barrier passed on rank  236 .
212: ... barrier passed on rank  212 .
108: ... barrier passed on rank  108 .
314: ... barrier passed on rank  314 .
170: ... barrier passed on rank  170 .
206: ... barrier passed on rank  206 .
426: ... barrier passed on rank  426 .
 42: ... barrier passed on rank  42 .
234: ... barrier passed on rank  234 .
462: ... barrier passed on rank  462 .
186: ... barrier passed on rank  186 .
316: ... barrier passed on rank  316 .
286: ... barrier passed on rank  286 .
188: ... barrier passed on rank  188 .
334: ... barrier passed on rank  334 .
362: ... barrier passed on rank  362 .
228: ... barrier passed on rank  228 .
298: ... barrier passed on rank  298 .
106: ... barrier passed on rank  106 .
442: ... barrier passed on rank  442 .
470: ... barrier passed on rank  470 .
254: ... barrier passed on rank  254 .
204: ... barrier passed on rank  204 .
414: ... barrier passed on rank  414 .
 30: ... barrier passed on rank  30 .
100: ... barrier passed on rank  100 .
342: ... barrier passed on rank  342 .
460: ... barrier passed on rank  460 .
382: ... barrier passed on rank  382 .
332: ... barrier passed on rank  332 .
214: ... barrier passed on rank  214 .
 60: ... barrier passed on rank  60 .
158: ... barrier passed on rank  158 .
 86: ... barrier passed on rank  86 .
126: ... barrier passed on rank  126 .
 78: ... barrier passed on rank  78 .
356: ... barrier passed on rank  356 .
484: ... barrier passed on rank  484 .
510: ... barrier passed on rank  510 .
490: ... barrier passed on rank  490 .
444: ... barrier passed on rank  444 .
 28: ... barrier passed on rank  28 .
102: ... barrier passed on rank  102 .
318: ... barrier passed on rank  318 .
190: ... barrier passed on rank  190 .
230: ... barrier passed on rank  230 .
 76: ... barrier passed on rank  76 .
358: ... barrier passed on rank  358 .
446: ... barrier passed on rank  446 .
252: ... barrier passed on rank  252 .
474: ... barrier passed on rank  474 .
412: ... barrier passed on rank  412 .
284: ... barrier passed on rank  284 .
380: ... barrier passed on rank  380 .
346: ... barrier passed on rank  346 .
 62: ... barrier passed on rank  62 .
156: ... barrier passed on rank  156 .
124: ... barrier passed on rank  124 .
 90: ... barrier passed on rank  90 .
508: ... barrier passed on rank  508 .
410: ... barrier passed on rank  410 .
218: ... barrier passed on rank  218 .
434: ... barrier passed on rank  434 .
450: ... barrier passed on rank  450 .
 66: ... barrier passed on rank  66 .
306: ... barrier passed on rank  306 .
178: ... barrier passed on rank  178 .
154: ... barrier passed on rank  154 .
 26: ... barrier passed on rank  26 .
194: ... barrier passed on rank  194 .
282: ... barrier passed on rank  282 .
 50: ... barrier passed on rank  50 .
322: ... barrier passed on rank  322 .
486: ... barrier passed on rank  486 .
 20: ... barrier passed on rank  20 .
 68: ... barrier passed on rank  68 .
120: ... barrier passed on rank  120 .
432: ... barrier passed on rank  432 .
 18: ... barrier passed on rank  18 .
148: ... barrier passed on rank  148 .
376: ... barrier passed on rank  376 .
184: ... barrier passed on rank  184 .
 56: ... barrier passed on rank  56 .
404: ... barrier passed on rank  404 .
504: ... barrier passed on rank  504 .
276: ... barrier passed on rank  276 .
402: ... barrier passed on rank  402 .
196: ... barrier passed on rank  196 .
324: ... barrier passed on rank  324 .
 48: ... barrier passed on rank  48 .
312: ... barrier passed on rank  312 .
274: ... barrier passed on rank  274 .
440: ... barrier passed on rank  440 .
452: ... barrier passed on rank  452 .
142: ... barrier passed on rank  142 .
167: ... barrier passed on rank  167 .
 70: ... barrier passed on rank  70 .
 39: ... barrier passed on rank  39 .
150: ... barrier passed on rank  150 .
295: ... barrier passed on rank  295 .
304: ... barrier passed on rank  304 .
406: ... barrier passed on rank  406 .
248: ... barrier passed on rank  248 .
278: ... barrier passed on rank  278 .
398: ... barrier passed on rank  398 .
 74: ... barrier passed on rank  74 .
270: ... barrier passed on rank  270 .
330: ... barrier passed on rank  330 .
146: ... barrier passed on rank  146 .
326: ... barrier passed on rank  326 .
423: ... barrier passed on rank  423 .
454: ... barrier passed on rank  454 .
458: ... barrier passed on rank  458 .
478: ... barrier passed on rank  478 .
140: ... barrier passed on rank  140 .
395: ... barrier passed on rank  395 .
 22: ... barrier passed on rank  22 .
495: ... barrier passed on rank  495 .
 14: ... barrier passed on rank  14 .
171: ... barrier passed on rank  171 .
375: ... barrier passed on rank  375 .
427: ... barrier passed on rank  427 .
472: ... barrier passed on rank  472 .
 43: ... barrier passed on rank  43 .
222: ... barrier passed on rank  222 .
173: ... barrier passed on rank  173 .
 55: ... barrier passed on rank  55 .
139: ... barrier passed on rank  139 .
367: ... barrier passed on rank  367 .
247: ... barrier passed on rank  247 .
239: ... barrier passed on rank  239 .
202: ... barrier passed on rank  202 .
176: ... barrier passed on rank  176 .
 94: ... barrier passed on rank  94 .
344: ... barrier passed on rank  344 .
396: ... barrier passed on rank  396 .
350: ... barrier passed on rank  350 .
268: ... barrier passed on rank  268 .
198: ... barrier passed on rank  198 .
 88: ... barrier passed on rank  88 .
111: ... barrier passed on rank  111 .
183: ... barrier passed on rank  183 .
267: ... barrier passed on rank  267 .
301: ... barrier passed on rank  301 .
311: ... barrier passed on rank  311 .
 11: ... barrier passed on rank  11 .
119: ... barrier passed on rank  119 .
476: ... barrier passed on rank  476 .
503: ... barrier passed on rank  503 .
 82: ... barrier passed on rank  82 .
 23: ... barrier passed on rank  23 .
 45: ... barrier passed on rank  45 .
130: ... barrier passed on rank  130 .
165: ... barrier passed on rank  165 .
  2: ... barrier passed on rank  2 .
 12: ... barrier passed on rank  12 .
 37: ... barrier passed on rank  37 .
447: ... barrier passed on rank  447 .
216: ... barrier passed on rank  216 .
253: ... barrier passed on rank  253 .
373: ... barrier passed on rank  373 .
240: ... barrier passed on rank  240 .
496: ... barrier passed on rank  496 .
210: ... barrier passed on rank  210 .
220: ... barrier passed on rank  220 .
101: ... barrier passed on rank  101 .
175: ... barrier passed on rank  175 .
151: ... barrier passed on rank  151 .
112: ... barrier passed on rank  112 .
 53: ... barrier passed on rank  53 .
258: ... barrier passed on rank  258 .
319: ... barrier passed on rank  319 .
293: ... barrier passed on rank  293 .
307: ... barrier passed on rank  307 .
245: ... barrier passed on rank  245 .
191: ... barrier passed on rank  191 .
407: ... barrier passed on rank  407 .
381: ... barrier passed on rank  381 .
 92: ... barrier passed on rank  92 .
 63: ... barrier passed on rank  63 .
338: ... barrier passed on rank  338 .
279: ... barrier passed on rank  279 .
348: ... barrier passed on rank  348 .
229: ... barrier passed on rank  229 .
125: ... barrier passed on rank  125 .
386: ... barrier passed on rank  386 .
181: ... barrier passed on rank  181 .
303: ... barrier passed on rank  303 .
309: ... barrier passed on rank  309 .
357: ... barrier passed on rank  357 .
299: ... barrier passed on rank  299 .
117: ... barrier passed on rank  117 .
368: ... barrier passed on rank  368 .
485: ... barrier passed on rank  485 .
421: ... barrier passed on rank  421 .
509: ... barrier passed on rank  509 .
439: ... barrier passed on rank  439 .
429: ... barrier passed on rank  429 .
466: ... barrier passed on rank  466 .
501: ... barrier passed on rank  501 .
394: ... barrier passed on rank  394 .
 80: ... barrier passed on rank  80 .
 34: ... barrier passed on rank  34 .
488: ... barrier passed on rank  488 .
 47: ... barrier passed on rank  47 .
260: ... barrier passed on rank  260 .
 71: ... barrier passed on rank  71 .
493: ... barrier passed on rank  493 .
445: ... barrier passed on rank  445 .
168: ... barrier passed on rank  168 .
255: ... barrier passed on rank  255 .
205: ... barrier passed on rank  205 .
435: ... barrier passed on rank  435 .
242: ... barrier passed on rank  242 .
424: ... barrier passed on rank  424 .
498: ... barrier passed on rank  498 .
208: ... barrier passed on rank  208 .
 19: ... barrier passed on rank  19 .
 40: ... barrier passed on rank  40 .
232: ... barrier passed on rank  232 .
103: ... barrier passed on rank  103 .
451: ... barrier passed on rank  451 .
388: ... barrier passed on rank  388 .
 67: ... barrier passed on rank  67 .
114: ... barrier passed on rank  114 .
461: ... barrier passed on rank  461 .
  4: ... barrier passed on rank  4 .
138: ... barrier passed on rank  138 .
317: ... barrier passed on rank  317 .
365: ... barrier passed on rank  365 .
419: ... barrier passed on rank  419 .
237: ... barrier passed on rank  237 .
189: ... barrier passed on rank  189 .
383: ... barrier passed on rank  383 .
333: ... barrier passed on rank  333 .
179: ... barrier passed on rank  179 .
 61: ... barrier passed on rank  61 .
336: ... barrier passed on rank  336 .
195: ... barrier passed on rank  195 .
132: ... barrier passed on rank  132 .
231: ... barrier passed on rank  231 .
163: ... barrier passed on rank  163 .
127: ... barrier passed on rank  127 .
403: ... barrier passed on rank  403 .
199: ... barrier passed on rank  199 .
 77: ... barrier passed on rank  77 .
147: ... barrier passed on rank  147 .
109: ... barrier passed on rank  109 .
327: ... barrier passed on rank  327 .
 51: ... barrier passed on rank  51 .
266: ... barrier passed on rank  266 .
290: ... barrier passed on rank  290 .
359: ... barrier passed on rank  359 .
296: ... barrier passed on rank  296 .
275: ... barrier passed on rank  275 .
104: ... barrier passed on rank  104 .
 10: ... barrier passed on rank  10 .
370: ... barrier passed on rank  370 .
511: ... barrier passed on rank  511 .
437: ... barrier passed on rank  437 .
455: ... barrier passed on rank  455 .
431: ... barrier passed on rank  431 .
464: ... barrier passed on rank  464 .
 35: ... barrier passed on rank  35 .
491: ... barrier passed on rank  491 .
 21: ... barrier passed on rank  21 .
262: ... barrier passed on rank  262 .
131: ... barrier passed on rank  131 .
 69: ... barrier passed on rank  69 .
  3: ... barrier passed on rank  3 .
411: ... barrier passed on rank  411 .
471: ... barrier passed on rank  471 .
207: ... barrier passed on rank  207 .
243: ... barrier passed on rank  243 .
413: ... barrier passed on rank  413 .
499: ... barrier passed on rank  499 .
 29: ... barrier passed on rank  29 .
 16: ... barrier passed on rank  16 .
235: ... barrier passed on rank  235 .
448: ... barrier passed on rank  448 .
149: ... barrier passed on rank  149 .
390: ... barrier passed on rank  390 .
115: ... barrier passed on rank  115 .
343: ... barrier passed on rank  343 .
463: ... barrier passed on rank  463 .
  6: ... barrier passed on rank  6 .
187: ... barrier passed on rank  187 .
259: ... barrier passed on rank  259 .
 59: ... barrier passed on rank  59 .
418: ... barrier passed on rank  418 .
285: ... barrier passed on rank  285 .
405: ... barrier passed on rank  405 .
335: ... barrier passed on rank  335 .
203: ... barrier passed on rank  203 .
215: ... barrier passed on rank  215 .
155: ... barrier passed on rank  155 .
277: ... barrier passed on rank  277 .
 27: ... barrier passed on rank  27 .
157: ... barrier passed on rank  157 .
 75: ... barrier passed on rank  75 .
134: ... barrier passed on rank  134 .
360: ... barrier passed on rank  360 .
 87: ... barrier passed on rank  87 .
283: ... barrier passed on rank  283 .
162: ... barrier passed on rank  162 .
400: ... barrier passed on rank  400 .
331: ... barrier passed on rank  331 .
 79: ... barrier passed on rank  79 .
144: ... barrier passed on rank  144 .
387: ... barrier passed on rank  387 .
325: ... barrier passed on rank  325 .
291: ... barrier passed on rank  291 .
315: ... barrier passed on rank  315 .
272: ... barrier passed on rank  272 .
107: ... barrier passed on rank  107 .
371: ... barrier passed on rank  371 .
323: ... barrier passed on rank  323 .
487: ... barrier passed on rank  487 .
443: ... barrier passed on rank  443 .
453: ... barrier passed on rank  453 .
459: ... barrier passed on rank  459 .
479: ... barrier passed on rank  479 .
467: ... barrier passed on rank  467 .
141: ... barrier passed on rank  141 .
 83: ... barrier passed on rank  83 .
 32: ... barrier passed on rank  32 .
263: ... barrier passed on rank  263 .
 13: ... barrier passed on rank  13 .
408: ... barrier passed on rank  408 .
123: ... barrier passed on rank  123 .
469: ... barrier passed on rank  469 .
433: ... barrier passed on rank  433 .
415: ... barrier passed on rank  415 .
211: ... barrier passed on rank  211 .
 31: ... barrier passed on rank  31 .
223: ... barrier passed on rank  223 .
391: ... barrier passed on rank  391 .
 64: ... barrier passed on rank  64 .
341: ... barrier passed on rank  341 .
379: ... barrier passed on rank  379 .
  7: ... barrier passed on rank  7 .
416: ... barrier passed on rank  416 .
287: ... barrier passed on rank  287 .
251: ... barrier passed on rank  251 .
200: ... barrier passed on rank  200 .
177: ... barrier passed on rank  177 .
 95: ... barrier passed on rank  95 .
213: ... barrier passed on rank  213 .
152: ... barrier passed on rank  152 .
339: ... barrier passed on rank  339 .
507: ... barrier passed on rank  507 .
 24: ... barrier passed on rank  24 .
397: ... barrier passed on rank  397 .
159: ... barrier passed on rank  159 .
 72: ... barrier passed on rank  72 .
192: ... barrier passed on rank  192 .
135: ... barrier passed on rank  135 .
363: ... barrier passed on rank  363 .
 85: ... barrier passed on rank  85 .
351: ... barrier passed on rank  351 .
280: ... barrier passed on rank  280 .
269: ... barrier passed on rank  269 .
160: ... barrier passed on rank  160 .
197: ... barrier passed on rank  197 .
 49: ... barrier passed on rank  49 .
288: ... barrier passed on rank  288 .
320: ... barrier passed on rank  320 .
456: ... barrier passed on rank  456 .
477: ... barrier passed on rank  477 .
143: ... barrier passed on rank  143 .
261: ... barrier passed on rank  261 .
 15: ... barrier passed on rank  15 .
219: ... barrier passed on rank  219 .
169: ... barrier passed on rank  169 .
425: ... barrier passed on rank  425 .
475: ... barrier passed on rank  475 .
 41: ... barrier passed on rank  41 .
221: ... barrier passed on rank  221 .
389: ... barrier passed on rank  389 .
  5: ... barrier passed on rank  5 .
305: ... barrier passed on rank  305 .
 93: ... barrier passed on rank  93 .
347: ... barrier passed on rank  347 .
399: ... barrier passed on rank  399 .
133: ... barrier passed on rank  133 .
349: ... barrier passed on rank  349 .
271: ... barrier passed on rank  271 .
 91: ... barrier passed on rank  91 .
227: ... barrier passed on rank  227 .
121: ... barrier passed on rank  121 .
377: ... barrier passed on rank  377 .
 57: ... barrier passed on rank  57 .
249: ... barrier passed on rank  249 .
505: ... barrier passed on rank  505 .
 99: ... barrier passed on rank  99 .
355: ... barrier passed on rank  355 .
328: ... barrier passed on rank  328 .
313: ... barrier passed on rank  313 .
297: ... barrier passed on rank  297 .
483: ... barrier passed on rank  483 .
489: ... barrier passed on rank  489 .
226: ... barrier passed on rank  226 .
233: ... barrier passed on rank  233 .
185: ... barrier passed on rank  185 .
361: ... barrier passed on rank  361 .
 98: ... barrier passed on rank  98 .
354: ... barrier passed on rank  354 .
105: ... barrier passed on rank  105 .
482: ... barrier passed on rank  482 .
441: ... barrier passed on rank  441 .
224: ... barrier passed on rank  224 .
209: ... barrier passed on rank  209 .
 25: ... barrier passed on rank  25 .
 96: ... barrier passed on rank  96 .
352: ... barrier passed on rank  352 .
465: ... barrier passed on rank  465 .
 81: ... barrier passed on rank  81 .
128: ... barrier passed on rank  128 .
  0: ... barrier passed on rank  0 .
409: ... barrier passed on rank  409 .
256: ... barrier passed on rank  256 .
153: ... barrier passed on rank  153 .
281: ... barrier passed on rank  281 .
384: ... barrier passed on rank  384 .
480: ... barrier passed on rank  480 .
392: ... barrier passed on rank  392 .
241: ... barrier passed on rank  241 .
497: ... barrier passed on rank  497 .
113: ... barrier passed on rank  113 .
264: ... barrier passed on rank  264 .
  8: ... barrier passed on rank  8 .
369: ... barrier passed on rank  369 .
 17: ... barrier passed on rank  17 .
136: ... barrier passed on rank  136 .
337: ... barrier passed on rank  337 .
401: ... barrier passed on rank  401 .
 73: ... barrier passed on rank  73 .
329: ... barrier passed on rank  329 .
145: ... barrier passed on rank  145 .
273: ... barrier passed on rank  273 .
457: ... barrier passed on rank  457 .
201: ... barrier passed on rank  201 .
449: ... barrier passed on rank  449 .
345: ... barrier passed on rank  345 .
193: ... barrier passed on rank  193 .
 89: ... barrier passed on rank  89 .
217: ... barrier passed on rank  217 .
473: ... barrier passed on rank  473 .
 65: ... barrier passed on rank  65 .
321: ... barrier passed on rank  321 .
 33: ... barrier passed on rank  33 .
161: ... barrier passed on rank  161 .
289: ... barrier passed on rank  289 .
417: ... barrier passed on rank  417 .
393: ... barrier passed on rank  393 .
  9: ... barrier passed on rank  9 .
137: ... barrier passed on rank  137 .
265: ... barrier passed on rank  265 .
225: ... barrier passed on rank  225 .
 97: ... barrier passed on rank  97 .
353: ... barrier passed on rank  353 .
481: ... barrier passed on rank  481 .
  1: ... barrier passed on rank  1 .
129: ... barrier passed on rank  129 .
257: ... barrier passed on rank  257 .
385: ... barrier passed on rank  385 .
  0: hkn0403:1763942:1763942 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  0: hkn0403:1763942:1763942 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  0: hkn0403:1763942:1763942 [0] NCCL INFO P2P plugin IBext
  0: hkn0403:1763942:1763942 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  0: hkn0403:1763942:1763942 [0] NCCL INFO Using network IBext
  0: NCCL version 2.11.4+cuda11.4
  1: hkn0403:1763954:1763954 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  3: hkn0403:1763926:1763926 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  2: hkn0403:1763934:1763934 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
316: hkn0632:1758503:1758503 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
317: hkn0632:1758522:1758522 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
  1: hkn0403:1763954:1763954 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  1: hkn0403:1763954:1763954 [1] NCCL INFO P2P plugin IBext
  3: hkn0403:1763926:1763926 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  3: hkn0403:1763926:1763926 [3] NCCL INFO P2P plugin IBext
  2: hkn0403:1763934:1763934 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  2: hkn0403:1763934:1763934 [2] NCCL INFO P2P plugin IBext
316: hkn0632:1758503:1758503 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
316: hkn0632:1758503:1758503 [0] NCCL INFO P2P plugin IBext
318: hkn0632:1758495:1758495 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
319: hkn0632:1758511:1758511 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
  1: hkn0403:1763954:1763954 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  3: hkn0403:1763926:1763926 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  1: hkn0403:1763954:1763954 [1] NCCL INFO Using network IBext
  2: hkn0403:1763934:1763934 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  3: hkn0403:1763926:1763926 [3] NCCL INFO Using network IBext
  2: hkn0403:1763934:1763934 [2] NCCL INFO Using network IBext
317: hkn0632:1758522:1758522 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
317: hkn0632:1758522:1758522 [1] NCCL INFO P2P plugin IBext
318: hkn0632:1758495:1758495 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
318: hkn0632:1758495:1758495 [2] NCCL INFO P2P plugin IBext
319: hkn0632:1758511:1758511 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
319: hkn0632:1758511:1758511 [3] NCCL INFO P2P plugin IBext
 99: hkn0501:1327769:1327769 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 98: hkn0501:1327785:1327785 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 96: hkn0501:1327777:1327777 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 16: hkn0408:2890655:2890655 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
 17: hkn0408:2890667:2890667 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
317: hkn0632:1758522:1758522 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
317: hkn0632:1758522:1758522 [1] NCCL INFO Using network IBext
318: hkn0632:1758495:1758495 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
318: hkn0632:1758495:1758495 [2] NCCL INFO Using network IBext
 19: hkn0408:2890647:2890647 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
331: hkn0635:1225445:1225445 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
319: hkn0632:1758511:1758511 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
319: hkn0632:1758511:1758511 [3] NCCL INFO Using network IBext
 97: hkn0501:1327797:1327797 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 18: hkn0408:2890646:2890646 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
328: hkn0635:1225461:1225461 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
316: hkn0632:1758503:1758503 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
316: hkn0632:1758503:1758503 [0] NCCL INFO Using network IBext
329: hkn0635:1225473:1225473 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
258: hkn0612:916880:916880 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
 99: hkn0501:1327769:1327769 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 99: hkn0501:1327769:1327769 [3] NCCL INFO P2P plugin IBext
 96: hkn0501:1327777:1327777 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 96: hkn0501:1327777:1327777 [0] NCCL INFO P2P plugin IBext
 98: hkn0501:1327785:1327785 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 98: hkn0501:1327785:1327785 [2] NCCL INFO P2P plugin IBext
256: hkn0612:916852:916852 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
 19: hkn0408:2890647:2890647 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 19: hkn0408:2890647:2890647 [3] NCCL INFO P2P plugin IBext
 16: hkn0408:2890655:2890655 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 16: hkn0408:2890655:2890655 [0] NCCL INFO P2P plugin IBext
 97: hkn0501:1327797:1327797 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 97: hkn0501:1327797:1327797 [1] NCCL INFO P2P plugin IBext
331: hkn0635:1225445:1225445 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
331: hkn0635:1225445:1225445 [3] NCCL INFO P2P plugin IBext
 17: hkn0408:2890667:2890667 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 17: hkn0408:2890667:2890667 [1] NCCL INFO P2P plugin IBext
502: hkn0814:675720:675720 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
 18: hkn0408:2890646:2890646 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 18: hkn0408:2890646:2890646 [2] NCCL INFO P2P plugin IBext
328: hkn0635:1225461:1225461 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
328: hkn0635:1225461:1225461 [0] NCCL INFO P2P plugin IBext
435: hkn0730:1401622:1401622 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
330: hkn0635:1225453:1225453 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
259: hkn0612:916868:916868 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
329: hkn0635:1225473:1225473 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
329: hkn0635:1225473:1225473 [1] NCCL INFO P2P plugin IBext
500: hkn0814:675728:675728 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
503: hkn0814:675719:675719 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
258: hkn0612:916880:916880 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
258: hkn0612:916880:916880 [2] NCCL INFO P2P plugin IBext
434: hkn0730:1401634:1401634 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
501: hkn0814:675740:675740 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
433: hkn0730:1401614:1401614 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
 97: hkn0501:1327797:1327797 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 97: hkn0501:1327797:1327797 [1] NCCL INFO Using network IBext
 98: hkn0501:1327785:1327785 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 98: hkn0501:1327785:1327785 [2] NCCL INFO Using network IBext
256: hkn0612:916852:916852 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
256: hkn0612:916852:916852 [0] NCCL INFO P2P plugin IBext
502: hkn0814:675720:675720 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
502: hkn0814:675720:675720 [2] NCCL INFO P2P plugin IBext
330: hkn0635:1225453:1225453 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
330: hkn0635:1225453:1225453 [2] NCCL INFO P2P plugin IBext
329: hkn0635:1225473:1225473 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
329: hkn0635:1225473:1225473 [1] NCCL INFO Using network IBext
435: hkn0730:1401622:1401622 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
435: hkn0730:1401622:1401622 [3] NCCL INFO P2P plugin IBext
259: hkn0612:916868:916868 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
259: hkn0612:916868:916868 [3] NCCL INFO P2P plugin IBext
500: hkn0814:675728:675728 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
500: hkn0814:675728:675728 [0] NCCL INFO P2P plugin IBext
503: hkn0814:675719:675719 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
503: hkn0814:675719:675719 [3] NCCL INFO P2P plugin IBext
257: hkn0612:916860:916860 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
434: hkn0730:1401634:1401634 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
434: hkn0730:1401634:1401634 [2] NCCL INFO P2P plugin IBext
433: hkn0730:1401614:1401614 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
433: hkn0730:1401614:1401614 [1] NCCL INFO P2P plugin IBext
 96: hkn0501:1327777:1327777 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 96: hkn0501:1327777:1327777 [0] NCCL INFO Using network IBext
 99: hkn0501:1327769:1327769 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 99: hkn0501:1327769:1327769 [3] NCCL INFO Using network IBext
501: hkn0814:675740:675740 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
501: hkn0814:675740:675740 [1] NCCL INFO P2P plugin IBext
330: hkn0635:1225453:1225453 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
330: hkn0635:1225453:1225453 [2] NCCL INFO Using network IBext
432: hkn0730:1401606:1401606 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
109: hkn0504:40731:40731 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
256: hkn0612:916852:916852 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
256: hkn0612:916852:916852 [0] NCCL INFO Using network IBext
111: hkn0504:40715:40715 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
259: hkn0612:916868:916868 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
259: hkn0612:916868:916868 [3] NCCL INFO Using network IBext
108: hkn0504:40743:40743 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
110: hkn0504:40723:40723 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
331: hkn0635:1225445:1225445 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
328: hkn0635:1225461:1225461 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
331: hkn0635:1225445:1225445 [3] NCCL INFO Using network IBext
328: hkn0635:1225461:1225461 [0] NCCL INFO Using network IBext
262: hkn0613:902573:902573 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
260: hkn0613:902581:902581 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
261: hkn0613:902589:902589 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
263: hkn0613:902601:902601 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
 18: hkn0408:2890646:2890646 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 18: hkn0408:2890646:2890646 [2] NCCL INFO Using network IBext
 16: hkn0408:2890655:2890655 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 19: hkn0408:2890647:2890647 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 19: hkn0408:2890647:2890647 [3] NCCL INFO Using network IBext
500: hkn0814:675728:675728 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
 16: hkn0408:2890655:2890655 [0] NCCL INFO Using network IBext
500: hkn0814:675728:675728 [0] NCCL INFO Using network IBext
 17: hkn0408:2890667:2890667 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 17: hkn0408:2890667:2890667 [1] NCCL INFO Using network IBext
503: hkn0814:675719:675719 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
503: hkn0814:675719:675719 [3] NCCL INFO Using network IBext
501: hkn0814:675740:675740 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
501: hkn0814:675740:675740 [1] NCCL INFO Using network IBext
258: hkn0612:916880:916880 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
258: hkn0612:916880:916880 [2] NCCL INFO Using network IBext
257: hkn0612:916860:916860 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
257: hkn0612:916860:916860 [1] NCCL INFO P2P plugin IBext
434: hkn0730:1401634:1401634 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
433: hkn0730:1401614:1401614 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
434: hkn0730:1401634:1401634 [2] NCCL INFO Using network IBext
433: hkn0730:1401614:1401614 [1] NCCL INFO Using network IBext
432: hkn0730:1401606:1401606 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
432: hkn0730:1401606:1401606 [0] NCCL INFO P2P plugin IBext
109: hkn0504:40731:40731 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
109: hkn0504:40731:40731 [1] NCCL INFO P2P plugin IBext
152: hkn0515:2896675:2896675 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
110: hkn0504:40723:40723 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
110: hkn0504:40723:40723 [2] NCCL INFO P2P plugin IBext
108: hkn0504:40743:40743 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
108: hkn0504:40743:40743 [0] NCCL INFO P2P plugin IBext
111: hkn0504:40715:40715 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
111: hkn0504:40715:40715 [3] NCCL INFO P2P plugin IBext
502: hkn0814:675720:675720 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
502: hkn0814:675720:675720 [2] NCCL INFO Using network IBext
262: hkn0613:902573:902573 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
262: hkn0613:902573:902573 [2] NCCL INFO P2P plugin IBext
261: hkn0613:902589:902589 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
261: hkn0613:902589:902589 [1] NCCL INFO P2P plugin IBext
257: hkn0612:916860:916860 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
257: hkn0612:916860:916860 [1] NCCL INFO Using network IBext
260: hkn0613:902581:902581 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
260: hkn0613:902581:902581 [0] NCCL INFO P2P plugin IBext
263: hkn0613:902601:902601 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
263: hkn0613:902601:902601 [3] NCCL INFO P2P plugin IBext
142: hkn0512:3044033:3044033 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
435: hkn0730:1401622:1401622 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
435: hkn0730:1401622:1401622 [3] NCCL INFO Using network IBext
154: hkn0515:2896695:2896695 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
432: hkn0730:1401606:1401606 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
432: hkn0730:1401606:1401606 [0] NCCL INFO Using network IBext
140: hkn0512:3044041:3044041 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
153: hkn0515:2896667:2896667 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
152: hkn0515:2896675:2896675 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
152: hkn0515:2896675:2896675 [0] NCCL INFO P2P plugin IBext
141: hkn0512:3044053:3044053 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
108: hkn0504:40743:40743 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
110: hkn0504:40723:40723 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
108: hkn0504:40743:40743 [0] NCCL INFO Using network IBext
110: hkn0504:40723:40723 [2] NCCL INFO Using network IBext
111: hkn0504:40715:40715 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
111: hkn0504:40715:40715 [3] NCCL INFO Using network IBext
143: hkn0512:3044032:3044032 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
263: hkn0613:902601:902601 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
263: hkn0613:902601:902601 [3] NCCL INFO Using network IBext
142: hkn0512:3044033:3044033 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
142: hkn0512:3044033:3044033 [2] NCCL INFO P2P plugin IBext
154: hkn0515:2896695:2896695 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
154: hkn0515:2896695:2896695 [2] NCCL INFO P2P plugin IBext
140: hkn0512:3044041:3044041 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
140: hkn0512:3044041:3044041 [0] NCCL INFO P2P plugin IBext
155: hkn0515:2896683:2896683 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
153: hkn0515:2896667:2896667 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
153: hkn0515:2896667:2896667 [1] NCCL INFO P2P plugin IBext
109: hkn0504:40731:40731 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
109: hkn0504:40731:40731 [1] NCCL INFO Using network IBext
141: hkn0512:3044053:3044053 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
141: hkn0512:3044053:3044053 [1] NCCL INFO P2P plugin IBext
135: hkn0510:2761936:2761936 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
143: hkn0512:3044032:3044032 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
143: hkn0512:3044032:3044032 [3] NCCL INFO P2P plugin IBext
260: hkn0613:902581:902581 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
262: hkn0613:902573:902573 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
260: hkn0613:902581:902581 [0] NCCL INFO Using network IBext
261: hkn0613:902589:902589 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
261: hkn0613:902589:902589 [1] NCCL INFO Using network IBext
262: hkn0613:902573:902573 [2] NCCL INFO Using network IBext
133: hkn0510:2761928:2761928 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
154: hkn0515:2896695:2896695 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
154: hkn0515:2896695:2896695 [2] NCCL INFO Using network IBext
153: hkn0515:2896667:2896667 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
140: hkn0512:3044041:3044041 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
153: hkn0515:2896667:2896667 [1] NCCL INFO Using network IBext
140: hkn0512:3044041:3044041 [0] NCCL INFO Using network IBext
141: hkn0512:3044053:3044053 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
141: hkn0512:3044053:3044053 [1] NCCL INFO Using network IBext
155: hkn0515:2896683:2896683 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
155: hkn0515:2896683:2896683 [3] NCCL INFO P2P plugin IBext
143: hkn0512:3044032:3044032 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
143: hkn0512:3044032:3044032 [3] NCCL INFO Using network IBext
 54: hkn0418:1869045:1869045 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
152: hkn0515:2896675:2896675 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
152: hkn0515:2896675:2896675 [0] NCCL INFO Using network IBext
 55: hkn0418:1869061:1869061 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
135: hkn0510:2761936:2761936 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
135: hkn0510:2761936:2761936 [3] NCCL INFO P2P plugin IBext
133: hkn0510:2761928:2761928 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
133: hkn0510:2761928:2761928 [1] NCCL INFO P2P plugin IBext
134: hkn0510:2761956:2761956 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
155: hkn0515:2896683:2896683 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
155: hkn0515:2896683:2896683 [3] NCCL INFO Using network IBext
142: hkn0512:3044033:3044033 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
142: hkn0512:3044033:3044033 [2] NCCL INFO Using network IBext
 53: hkn0418:1869083:1869083 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
 54: hkn0418:1869045:1869045 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 54: hkn0418:1869045:1869045 [2] NCCL INFO P2P plugin IBext
 55: hkn0418:1869061:1869061 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 55: hkn0418:1869061:1869061 [3] NCCL INFO P2P plugin IBext
 52: hkn0418:1869053:1869053 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
133: hkn0510:2761928:2761928 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
133: hkn0510:2761928:2761928 [1] NCCL INFO Using network IBext
134: hkn0510:2761956:2761956 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
134: hkn0510:2761956:2761956 [2] NCCL INFO P2P plugin IBext
 53: hkn0418:1869083:1869083 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 53: hkn0418:1869083:1869083 [1] NCCL INFO P2P plugin IBext
132: hkn0510:2761944:2761944 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
 55: hkn0418:1869061:1869061 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 55: hkn0418:1869061:1869061 [3] NCCL INFO Using network IBext
135: hkn0510:2761936:2761936 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
135: hkn0510:2761936:2761936 [3] NCCL INFO Using network IBext
 52: hkn0418:1869053:1869053 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 52: hkn0418:1869053:1869053 [0] NCCL INFO P2P plugin IBext
134: hkn0510:2761956:2761956 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
134: hkn0510:2761956:2761956 [2] NCCL INFO Using network IBext
 53: hkn0418:1869083:1869083 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 53: hkn0418:1869083:1869083 [1] NCCL INFO Using network IBext
207: hkn0532:924627:924627 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
 52: hkn0418:1869053:1869053 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 52: hkn0418:1869053:1869053 [0] NCCL INFO Using network IBext
445: hkn0733:1389278:1389278 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
 54: hkn0418:1869045:1869045 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 54: hkn0418:1869045:1869045 [2] NCCL INFO Using network IBext
132: hkn0510:2761944:2761944 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
132: hkn0510:2761944:2761944 [0] NCCL INFO P2P plugin IBext
  7: hkn0404:1339294:1339294 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
199: hkn0530:1258050:1258050 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
402: hkn0720:5397:5397 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
118: hkn0506:837941:837941 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
197: hkn0530:1258062:1258062 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
116: hkn0506:837949:837949 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
400: hkn0720:5369:5369 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
189: hkn0528:1301571:1301571 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
132: hkn0510:2761944:2761944 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
447: hkn0733:1389269:1389269 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
132: hkn0510:2761944:2761944 [0] NCCL INFO Using network IBext
207: hkn0532:924627:924627 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
207: hkn0532:924627:924627 [3] NCCL INFO P2P plugin IBext
445: hkn0733:1389278:1389278 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
445: hkn0733:1389278:1389278 [1] NCCL INFO P2P plugin IBext
196: hkn0530:1258042:1258042 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
206: hkn0532:924599:924599 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
 29: hkn0411:2315755:2315755 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
 31: hkn0411:2315753:2315753 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
227: hkn0603:1413135:1413135 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
191: hkn0528:1301563:1301563 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
205: hkn0532:924607:924607 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
190: hkn0528:1301582:1301582 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
444: hkn0733:1389270:1389270 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
446: hkn0733:1389290:1389290 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
  7: hkn0404:1339294:1339294 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  7: hkn0404:1339294:1339294 [3] NCCL INFO P2P plugin IBext
119: hkn0506:837957:837957 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 30: hkn0411:2315763:2315763 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
199: hkn0530:1258050:1258050 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
199: hkn0530:1258050:1258050 [3] NCCL INFO P2P plugin IBext
402: hkn0720:5397:5397 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
402: hkn0720:5397:5397 [2] NCCL INFO P2P plugin IBext
226: hkn0603:1413123:1413123 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
 38: hkn0413:2366608:2366608 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
118: hkn0506:837941:837941 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
118: hkn0506:837941:837941 [2] NCCL INFO P2P plugin IBext
198: hkn0530:1258034:1258034 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
117: hkn0506:837969:837969 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
197: hkn0530:1258062:1258062 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
197: hkn0530:1258062:1258062 [1] NCCL INFO P2P plugin IBext
395: hkn0718:3916925:3916925 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
156: hkn0516:2915863:2915863 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
116: hkn0506:837949:837949 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
116: hkn0506:837949:837949 [0] NCCL INFO P2P plugin IBext
224: hkn0603:1413107:1413107 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
394: hkn0718:3916905:3916905 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
157: hkn0516:2915847:2915847 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
393: hkn0718:3916897:3916897 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
400: hkn0720:5369:5369 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
400: hkn0720:5369:5369 [0] NCCL INFO P2P plugin IBext
225: hkn0603:1413115:1413115 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
 39: hkn0413:2366596:2366596 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
392: hkn0718:3916913:3916913 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
189: hkn0528:1301571:1301571 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
189: hkn0528:1301571:1301571 [1] NCCL INFO P2P plugin IBext
447: hkn0733:1389269:1389269 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
447: hkn0733:1389269:1389269 [3] NCCL INFO P2P plugin IBext
204: hkn0532:924615:924615 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
188: hkn0528:1301555:1301555 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
196: hkn0530:1258042:1258042 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
196: hkn0530:1258042:1258042 [0] NCCL INFO P2P plugin IBext
206: hkn0532:924599:924599 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
206: hkn0532:924599:924599 [2] NCCL INFO P2P plugin IBext
227: hkn0603:1413135:1413135 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
227: hkn0603:1413135:1413135 [3] NCCL INFO P2P plugin IBext
190: hkn0528:1301582:1301582 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
190: hkn0528:1301582:1301582 [2] NCCL INFO P2P plugin IBext
191: hkn0528:1301563:1301563 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
191: hkn0528:1301563:1301563 [3] NCCL INFO P2P plugin IBext
205: hkn0532:924607:924607 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
205: hkn0532:924607:924607 [1] NCCL INFO P2P plugin IBext
 29: hkn0411:2315755:2315755 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 29: hkn0411:2315755:2315755 [1] NCCL INFO P2P plugin IBext
 31: hkn0411:2315753:2315753 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 31: hkn0411:2315753:2315753 [3] NCCL INFO P2P plugin IBext
119: hkn0506:837957:837957 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
119: hkn0506:837957:837957 [3] NCCL INFO P2P plugin IBext
444: hkn0733:1389270:1389270 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
444: hkn0733:1389270:1389270 [0] NCCL INFO P2P plugin IBext
 38: hkn0413:2366608:2366608 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 38: hkn0413:2366608:2366608 [2] NCCL INFO P2P plugin IBext
446: hkn0733:1389290:1389290 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
226: hkn0603:1413123:1413123 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
226: hkn0603:1413123:1413123 [2] NCCL INFO P2P plugin IBext
446: hkn0733:1389290:1389290 [2] NCCL INFO P2P plugin IBext
197: hkn0530:1258062:1258062 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
197: hkn0530:1258062:1258062 [1] NCCL INFO Using network IBext
 30: hkn0411:2315763:2315763 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 30: hkn0411:2315763:2315763 [2] NCCL INFO P2P plugin IBext
198: hkn0530:1258034:1258034 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
198: hkn0530:1258034:1258034 [2] NCCL INFO P2P plugin IBext
116: hkn0506:837949:837949 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
116: hkn0506:837949:837949 [0] NCCL INFO Using network IBext
117: hkn0506:837969:837969 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
117: hkn0506:837969:837969 [1] NCCL INFO P2P plugin IBext
395: hkn0718:3916925:3916925 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
395: hkn0718:3916925:3916925 [3] NCCL INFO P2P plugin IBext
400: hkn0720:5369:5369 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
400: hkn0720:5369:5369 [0] NCCL INFO Using network IBext
224: hkn0603:1413107:1413107 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
224: hkn0603:1413107:1413107 [0] NCCL INFO P2P plugin IBext
156: hkn0516:2915863:2915863 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
156: hkn0516:2915863:2915863 [0] NCCL INFO P2P plugin IBext
157: hkn0516:2915847:2915847 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
157: hkn0516:2915847:2915847 [1] NCCL INFO P2P plugin IBext
394: hkn0718:3916905:3916905 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
394: hkn0718:3916905:3916905 [2] NCCL INFO P2P plugin IBext
159: hkn0516:2915875:2915875 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 39: hkn0413:2366596:2366596 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 39: hkn0413:2366596:2366596 [3] NCCL INFO P2P plugin IBext
225: hkn0603:1413115:1413115 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
225: hkn0603:1413115:1413115 [1] NCCL INFO P2P plugin IBext
 28: hkn0411:2315775:2315775 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
447: hkn0733:1389269:1389269 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
447: hkn0733:1389269:1389269 [3] NCCL INFO Using network IBext
196: hkn0530:1258042:1258042 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
196: hkn0530:1258042:1258042 [0] NCCL INFO Using network IBext
392: hkn0718:3916913:3916913 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
392: hkn0718:3916913:3916913 [0] NCCL INFO P2P plugin IBext
 36: hkn0413:2366580:2366580 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
393: hkn0718:3916897:3916897 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
393: hkn0718:3916897:3916897 [1] NCCL INFO P2P plugin IBext
204: hkn0532:924615:924615 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
204: hkn0532:924615:924615 [0] NCCL INFO P2P plugin IBext
188: hkn0528:1301555:1301555 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
188: hkn0528:1301555:1301555 [0] NCCL INFO P2P plugin IBext
119: hkn0506:837957:837957 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
119: hkn0506:837957:837957 [3] NCCL INFO Using network IBext
207: hkn0532:924627:924627 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
207: hkn0532:924627:924627 [3] NCCL INFO Using network IBext
205: hkn0532:924607:924607 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
205: hkn0532:924607:924607 [1] NCCL INFO Using network IBext
206: hkn0532:924599:924599 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
198: hkn0530:1258034:1258034 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
206: hkn0532:924599:924599 [2] NCCL INFO Using network IBext
445: hkn0733:1389278:1389278 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
198: hkn0530:1258034:1258034 [2] NCCL INFO Using network IBext
446: hkn0733:1389290:1389290 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
446: hkn0733:1389290:1389290 [2] NCCL INFO Using network IBext
445: hkn0733:1389278:1389278 [1] NCCL INFO Using network IBext
444: hkn0733:1389270:1389270 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
444: hkn0733:1389270:1389270 [0] NCCL INFO Using network IBext
190: hkn0528:1301582:1301582 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
190: hkn0528:1301582:1301582 [2] NCCL INFO Using network IBext
117: hkn0506:837969:837969 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
191: hkn0528:1301563:1301563 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
117: hkn0506:837969:837969 [1] NCCL INFO Using network IBext
191: hkn0528:1301563:1301563 [3] NCCL INFO Using network IBext
224: hkn0603:1413107:1413107 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
  5: hkn0404:1339266:1339266 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
224: hkn0603:1413107:1413107 [0] NCCL INFO Using network IBext
226: hkn0603:1413123:1413123 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
226: hkn0603:1413123:1413123 [2] NCCL INFO Using network IBext
 30: hkn0411:2315763:2315763 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 30: hkn0411:2315763:2315763 [2] NCCL INFO Using network IBext
225: hkn0603:1413115:1413115 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
225: hkn0603:1413115:1413115 [1] NCCL INFO Using network IBext
199: hkn0530:1258050:1258050 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
199: hkn0530:1258050:1258050 [3] NCCL INFO Using network IBext
118: hkn0506:837941:837941 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
118: hkn0506:837941:837941 [2] NCCL INFO Using network IBext
158: hkn0516:2915855:2915855 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
402: hkn0720:5397:5397 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
402: hkn0720:5397:5397 [2] NCCL INFO Using network IBext
  4: hkn0404:1339282:1339282 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
 39: hkn0413:2366596:2366596 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 39: hkn0413:2366596:2366596 [3] NCCL INFO Using network IBext
204: hkn0532:924615:924615 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
204: hkn0532:924615:924615 [0] NCCL INFO Using network IBext
  6: hkn0404:1339274:1339274 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
188: hkn0528:1301555:1301555 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
188: hkn0528:1301555:1301555 [0] NCCL INFO Using network IBext
  7: hkn0404:1339294:1339294 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  7: hkn0404:1339294:1339294 [3] NCCL INFO Using network IBext
159: hkn0516:2915875:2915875 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
159: hkn0516:2915875:2915875 [3] NCCL INFO P2P plugin IBext
392: hkn0718:3916913:3916913 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
392: hkn0718:3916913:3916913 [0] NCCL INFO Using network IBext
393: hkn0718:3916897:3916897 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
 28: hkn0411:2315775:2315775 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 28: hkn0411:2315775:2315775 [0] NCCL INFO P2P plugin IBext
393: hkn0718:3916897:3916897 [1] NCCL INFO Using network IBext
 37: hkn0413:2366588:2366588 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
 36: hkn0413:2366580:2366580 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 36: hkn0413:2366580:2366580 [0] NCCL INFO P2P plugin IBext
 35: hkn0412:2262278:2262278 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
371: hkn0712:294948:294948 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
189: hkn0528:1301571:1301571 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
189: hkn0528:1301571:1301571 [1] NCCL INFO Using network IBext
227: hkn0603:1413135:1413135 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
227: hkn0603:1413135:1413135 [3] NCCL INFO Using network IBext
 29: hkn0411:2315755:2315755 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 29: hkn0411:2315755:2315755 [1] NCCL INFO Using network IBext
 31: hkn0411:2315753:2315753 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 31: hkn0411:2315753:2315753 [3] NCCL INFO Using network IBext
  5: hkn0404:1339266:1339266 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  5: hkn0404:1339266:1339266 [1] NCCL INFO P2P plugin IBext
 28: hkn0411:2315775:2315775 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 28: hkn0411:2315775:2315775 [0] NCCL INFO Using network IBext
158: hkn0516:2915855:2915855 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
158: hkn0516:2915855:2915855 [2] NCCL INFO P2P plugin IBext
 36: hkn0413:2366580:2366580 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 38: hkn0413:2366608:2366608 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
  4: hkn0404:1339282:1339282 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  4: hkn0404:1339282:1339282 [0] NCCL INFO P2P plugin IBext
 38: hkn0413:2366608:2366608 [2] NCCL INFO Using network IBext
 36: hkn0413:2366580:2366580 [0] NCCL INFO Using network IBext
122: hkn0507:3186958:3186958 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
  6: hkn0404:1339274:1339274 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  6: hkn0404:1339274:1339274 [2] NCCL INFO P2P plugin IBext
395: hkn0718:3916925:3916925 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
394: hkn0718:3916905:3916905 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
395: hkn0718:3916925:3916925 [3] NCCL INFO Using network IBext
394: hkn0718:3916905:3916905 [2] NCCL INFO Using network IBext
157: hkn0516:2915847:2915847 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
159: hkn0516:2915875:2915875 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
157: hkn0516:2915847:2915847 [1] NCCL INFO Using network IBext
159: hkn0516:2915875:2915875 [3] NCCL INFO Using network IBext
120: hkn0507:3186982:3186982 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
156: hkn0516:2915863:2915863 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
156: hkn0516:2915863:2915863 [0] NCCL INFO Using network IBext
 37: hkn0413:2366588:2366588 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 37: hkn0413:2366588:2366588 [1] NCCL INFO P2P plugin IBext
 35: hkn0412:2262278:2262278 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 35: hkn0412:2262278:2262278 [3] NCCL INFO P2P plugin IBext
371: hkn0712:294948:294948 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
371: hkn0712:294948:294948 [3] NCCL INFO P2P plugin IBext
511: hkn0816:375492:375492 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
121: hkn0507:3186962:3186962 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
  5: hkn0404:1339266:1339266 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  5: hkn0404:1339266:1339266 [1] NCCL INFO Using network IBext
158: hkn0516:2915855:2915855 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
158: hkn0516:2915855:2915855 [2] NCCL INFO Using network IBext
  4: hkn0404:1339282:1339282 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  4: hkn0404:1339282:1339282 [0] NCCL INFO Using network IBext
403: hkn0720:5377:5377 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
  6: hkn0404:1339274:1339274 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  6: hkn0404:1339274:1339274 [2] NCCL INFO Using network IBext
 37: hkn0413:2366588:2366588 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 37: hkn0413:2366588:2366588 [1] NCCL INFO Using network IBext
510: hkn0816:375512:375512 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
202: hkn0531:1230513:1230513 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
122: hkn0507:3186958:3186958 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
122: hkn0507:3186958:3186958 [2] NCCL INFO P2P plugin IBext
 22: hkn0409:2585544:2585544 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
120: hkn0507:3186982:3186982 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
120: hkn0507:3186982:3186982 [0] NCCL INFO P2P plugin IBext
200: hkn0531:1230521:1230521 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
123: hkn0507:3186970:3186970 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
508: hkn0816:375484:375484 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
272: hkn0617:2294566:2294566 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
511: hkn0816:375492:375492 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
511: hkn0816:375492:375492 [3] NCCL INFO P2P plugin IBext
121: hkn0507:3186962:3186962 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
121: hkn0507:3186962:3186962 [1] NCCL INFO P2P plugin IBext
 23: hkn0409:2585564:2585564 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
201: hkn0531:1230529:1230529 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
273: hkn0617:2294577:2294577 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
510: hkn0816:375512:375512 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
510: hkn0816:375512:375512 [2] NCCL INFO P2P plugin IBext
 59: hkn0419:1544187:1544187 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
202: hkn0531:1230513:1230513 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
202: hkn0531:1230513:1230513 [2] NCCL INFO P2P plugin IBext
 32: hkn0412:2262276:2262276 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
403: hkn0720:5377:5377 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
403: hkn0720:5377:5377 [3] NCCL INFO P2P plugin IBext
 21: hkn0409:2585543:2585543 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
200: hkn0531:1230521:1230521 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
200: hkn0531:1230521:1230521 [0] NCCL INFO P2P plugin IBext
 20: hkn0409:2585552:2585552 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
123: hkn0507:3186970:3186970 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
123: hkn0507:3186970:3186970 [3] NCCL INFO P2P plugin IBext
 22: hkn0409:2585544:2585544 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 22: hkn0409:2585544:2585544 [2] NCCL INFO P2P plugin IBext
508: hkn0816:375484:375484 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
508: hkn0816:375484:375484 [0] NCCL INFO P2P plugin IBext
272: hkn0617:2294566:2294566 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
272: hkn0617:2294566:2294566 [0] NCCL INFO P2P plugin IBext
275: hkn0617:2294550:2294550 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
121: hkn0507:3186962:3186962 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
121: hkn0507:3186962:3186962 [1] NCCL INFO Using network IBext
274: hkn0617:2294558:2294558 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
 33: hkn0412:2262290:2262290 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
509: hkn0816:375500:375500 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
 35: hkn0412:2262278:2262278 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 35: hkn0412:2262278:2262278 [3] NCCL INFO Using network IBext
 34: hkn0412:2262277:2262277 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
370: hkn0712:294940:294940 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
371: hkn0712:294948:294948 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
371: hkn0712:294948:294948 [3] NCCL INFO Using network IBext
 23: hkn0409:2585564:2585564 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 23: hkn0409:2585564:2585564 [3] NCCL INFO P2P plugin IBext
203: hkn0531:1230541:1230541 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
368: hkn0712:294956:294956 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
 56: hkn0419:1544195:1544195 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
 57: hkn0419:1544215:1544215 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
201: hkn0531:1230529:1230529 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
201: hkn0531:1230529:1230529 [1] NCCL INFO P2P plugin IBext
273: hkn0617:2294577:2294577 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
273: hkn0617:2294577:2294577 [1] NCCL INFO P2P plugin IBext
510: hkn0816:375512:375512 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
510: hkn0816:375512:375512 [2] NCCL INFO Using network IBext
369: hkn0712:294968:294968 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
 58: hkn0419:1544203:1544203 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
 59: hkn0419:1544187:1544187 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 59: hkn0419:1544187:1544187 [3] NCCL INFO P2P plugin IBext
123: hkn0507:3186970:3186970 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
123: hkn0507:3186970:3186970 [3] NCCL INFO Using network IBext
 32: hkn0412:2262276:2262276 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 32: hkn0412:2262276:2262276 [0] NCCL INFO P2P plugin IBext
508: hkn0816:375484:375484 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
508: hkn0816:375484:375484 [0] NCCL INFO Using network IBext
 21: hkn0409:2585543:2585543 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 21: hkn0409:2585543:2585543 [1] NCCL INFO P2P plugin IBext
403: hkn0720:5377:5377 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
403: hkn0720:5377:5377 [3] NCCL INFO Using network IBext
200: hkn0531:1230521:1230521 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
200: hkn0531:1230521:1230521 [0] NCCL INFO Using network IBext
122: hkn0507:3186958:3186958 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
122: hkn0507:3186958:3186958 [2] NCCL INFO Using network IBext
120: hkn0507:3186982:3186982 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
120: hkn0507:3186982:3186982 [0] NCCL INFO Using network IBext
401: hkn0720:5385:5385 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
275: hkn0617:2294550:2294550 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
275: hkn0617:2294550:2294550 [3] NCCL INFO P2P plugin IBext
301: hkn0628:671751:671751 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
 20: hkn0409:2585552:2585552 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 20: hkn0409:2585552:2585552 [0] NCCL INFO P2P plugin IBext
274: hkn0617:2294558:2294558 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
274: hkn0617:2294558:2294558 [2] NCCL INFO P2P plugin IBext
 33: hkn0412:2262290:2262290 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 33: hkn0412:2262290:2262290 [1] NCCL INFO P2P plugin IBext
201: hkn0531:1230529:1230529 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
509: hkn0816:375500:375500 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
509: hkn0816:375500:375500 [1] NCCL INFO P2P plugin IBext
201: hkn0531:1230529:1230529 [1] NCCL INFO Using network IBext
 34: hkn0412:2262277:2262277 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 34: hkn0412:2262277:2262277 [2] NCCL INFO P2P plugin IBext
511: hkn0816:375492:375492 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
511: hkn0816:375492:375492 [3] NCCL INFO Using network IBext
370: hkn0712:294940:294940 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
370: hkn0712:294940:294940 [2] NCCL INFO P2P plugin IBext
 23: hkn0409:2585564:2585564 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 23: hkn0409:2585564:2585564 [3] NCCL INFO Using network IBext
203: hkn0531:1230541:1230541 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
203: hkn0531:1230541:1230541 [3] NCCL INFO P2P plugin IBext
 32: hkn0412:2262276:2262276 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 32: hkn0412:2262276:2262276 [0] NCCL INFO Using network IBext
300: hkn0628:671767:671767 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
273: hkn0617:2294577:2294577 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
273: hkn0617:2294577:2294577 [1] NCCL INFO Using network IBext
 21: hkn0409:2585543:2585543 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 21: hkn0409:2585543:2585543 [1] NCCL INFO Using network IBext
302: hkn0628:671759:671759 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
368: hkn0712:294956:294956 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
368: hkn0712:294956:294956 [0] NCCL INFO P2P plugin IBext
 57: hkn0419:1544215:1544215 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 57: hkn0419:1544215:1544215 [1] NCCL INFO P2P plugin IBext
 56: hkn0419:1544195:1544195 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 56: hkn0419:1544195:1544195 [0] NCCL INFO P2P plugin IBext
 58: hkn0419:1544203:1544203 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 58: hkn0419:1544203:1544203 [2] NCCL INFO P2P plugin IBext
303: hkn0628:671779:671779 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
369: hkn0712:294968:294968 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
369: hkn0712:294968:294968 [1] NCCL INFO P2P plugin IBext
 20: hkn0409:2585552:2585552 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 20: hkn0409:2585552:2585552 [0] NCCL INFO Using network IBext
274: hkn0617:2294558:2294558 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
274: hkn0617:2294558:2294558 [2] NCCL INFO Using network IBext
275: hkn0617:2294550:2294550 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
275: hkn0617:2294550:2294550 [3] NCCL INFO Using network IBext
202: hkn0531:1230513:1230513 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
202: hkn0531:1230513:1230513 [2] NCCL INFO Using network IBext
 33: hkn0412:2262290:2262290 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 33: hkn0412:2262290:2262290 [1] NCCL INFO Using network IBext
509: hkn0816:375500:375500 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
509: hkn0816:375500:375500 [1] NCCL INFO Using network IBext
 34: hkn0412:2262277:2262277 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 34: hkn0412:2262277:2262277 [2] NCCL INFO Using network IBext
203: hkn0531:1230541:1230541 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
203: hkn0531:1230541:1230541 [3] NCCL INFO Using network IBext
 22: hkn0409:2585544:2585544 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 22: hkn0409:2585544:2585544 [2] NCCL INFO Using network IBext
370: hkn0712:294940:294940 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
370: hkn0712:294940:294940 [2] NCCL INFO Using network IBext
272: hkn0617:2294566:2294566 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
272: hkn0617:2294566:2294566 [0] NCCL INFO Using network IBext
368: hkn0712:294956:294956 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
368: hkn0712:294956:294956 [0] NCCL INFO Using network IBext
301: hkn0628:671751:671751 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
301: hkn0628:671751:671751 [1] NCCL INFO P2P plugin IBext
401: hkn0720:5385:5385 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
401: hkn0720:5385:5385 [1] NCCL INFO P2P plugin IBext
369: hkn0712:294968:294968 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
369: hkn0712:294968:294968 [1] NCCL INFO Using network IBext
 58: hkn0419:1544203:1544203 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 58: hkn0419:1544203:1544203 [2] NCCL INFO Using network IBext
 56: hkn0419:1544195:1544195 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 57: hkn0419:1544215:1544215 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 56: hkn0419:1544195:1544195 [0] NCCL INFO Using network IBext
 57: hkn0419:1544215:1544215 [1] NCCL INFO Using network IBext
300: hkn0628:671767:671767 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
300: hkn0628:671767:671767 [0] NCCL INFO P2P plugin IBext
302: hkn0628:671759:671759 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
302: hkn0628:671759:671759 [2] NCCL INFO P2P plugin IBext
 59: hkn0419:1544187:1544187 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 59: hkn0419:1544187:1544187 [3] NCCL INFO Using network IBext
303: hkn0628:671779:671779 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
303: hkn0628:671779:671779 [3] NCCL INFO P2P plugin IBext
358: hkn0708:413122:413122 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
285: hkn0623:1872640:1872640 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
401: hkn0720:5385:5385 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
401: hkn0720:5385:5385 [1] NCCL INFO Using network IBext
300: hkn0628:671767:671767 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
300: hkn0628:671767:671767 [0] NCCL INFO Using network IBext
302: hkn0628:671759:671759 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
303: hkn0628:671779:671779 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
303: hkn0628:671779:671779 [3] NCCL INFO Using network IBext
302: hkn0628:671759:671759 [2] NCCL INFO Using network IBext
145: hkn0513:3012872:3012872 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
286: hkn0623:1872648:1872648 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
287: hkn0623:1872668:1872668 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
284: hkn0623:1872656:1872656 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
147: hkn0513:3012860:3012860 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
146: hkn0513:3012852:3012852 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
356: hkn0708:413102:413102 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
144: hkn0513:3012844:3012844 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
358: hkn0708:413122:413122 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
358: hkn0708:413122:413122 [2] NCCL INFO P2P plugin IBext
475: hkn0805:1112010:1112010 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
301: hkn0628:671751:671751 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
301: hkn0628:671751:671751 [1] NCCL INFO Using network IBext
474: hkn0805:1112002:1112002 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
285: hkn0623:1872640:1872640 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
285: hkn0623:1872640:1872640 [1] NCCL INFO P2P plugin IBext
472: hkn0805:1111994:1111994 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
448: hkn0734:1156433:1156433 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
449: hkn0734:1156453:1156453 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
473: hkn0805:1112022:1112022 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
145: hkn0513:3012872:3012872 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
145: hkn0513:3012872:3012872 [1] NCCL INFO P2P plugin IBext
286: hkn0623:1872648:1872648 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
286: hkn0623:1872648:1872648 [2] NCCL INFO P2P plugin IBext
287: hkn0623:1872668:1872668 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
287: hkn0623:1872668:1872668 [3] NCCL INFO P2P plugin IBext
284: hkn0623:1872656:1872656 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
284: hkn0623:1872656:1872656 [0] NCCL INFO P2P plugin IBext
450: hkn0734:1156441:1156441 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
146: hkn0513:3012852:3012852 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
146: hkn0513:3012852:3012852 [2] NCCL INFO P2P plugin IBext
420: hkn0726:1548019:1548019 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
356: hkn0708:413102:413102 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
356: hkn0708:413102:413102 [0] NCCL INFO P2P plugin IBext
147: hkn0513:3012860:3012860 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
147: hkn0513:3012860:3012860 [3] NCCL INFO P2P plugin IBext
475: hkn0805:1112010:1112010 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
475: hkn0805:1112010:1112010 [3] NCCL INFO P2P plugin IBext
422: hkn0726:1548007:1548007 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
144: hkn0513:3012844:3012844 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
144: hkn0513:3012844:3012844 [0] NCCL INFO P2P plugin IBext
 83: hkn0425:2083899:2083899 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
451: hkn0734:1156425:1156425 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
357: hkn0708:413110:413110 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
423: hkn0726:1547999:1547999 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
472: hkn0805:1111994:1111994 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
472: hkn0805:1111994:1111994 [0] NCCL INFO P2P plugin IBext
421: hkn0726:1547991:1547991 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
474: hkn0805:1112002:1112002 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
474: hkn0805:1112002:1112002 [2] NCCL INFO P2P plugin IBext
 81: hkn0425:2083915:2083915 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
473: hkn0805:1112022:1112022 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
473: hkn0805:1112022:1112022 [1] NCCL INFO P2P plugin IBext
449: hkn0734:1156453:1156453 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
449: hkn0734:1156453:1156453 [1] NCCL INFO P2P plugin IBext
448: hkn0734:1156433:1156433 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
448: hkn0734:1156433:1156433 [0] NCCL INFO P2P plugin IBext
 82: hkn0425:2083927:2083927 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
284: hkn0623:1872656:1872656 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
284: hkn0623:1872656:1872656 [0] NCCL INFO Using network IBext
286: hkn0623:1872648:1872648 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
286: hkn0623:1872648:1872648 [2] NCCL INFO Using network IBext
287: hkn0623:1872668:1872668 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
287: hkn0623:1872668:1872668 [3] NCCL INFO Using network IBext
359: hkn0708:413094:413094 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
 80: hkn0425:2083907:2083907 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
450: hkn0734:1156441:1156441 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
450: hkn0734:1156441:1156441 [2] NCCL INFO P2P plugin IBext
420: hkn0726:1548019:1548019 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
420: hkn0726:1548019:1548019 [0] NCCL INFO P2P plugin IBext
144: hkn0513:3012844:3012844 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
147: hkn0513:3012860:3012860 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
144: hkn0513:3012844:3012844 [0] NCCL INFO Using network IBext
356: hkn0708:413102:413102 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
146: hkn0513:3012852:3012852 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
147: hkn0513:3012860:3012860 [3] NCCL INFO Using network IBext
356: hkn0708:413102:413102 [0] NCCL INFO Using network IBext
146: hkn0513:3012852:3012852 [2] NCCL INFO Using network IBext
114: hkn0505:2303656:2303656 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
386: hkn0716:108398:108398 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
387: hkn0716:108382:108382 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
358: hkn0708:413122:413122 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
422: hkn0726:1548007:1548007 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
422: hkn0726:1548007:1548007 [2] NCCL INFO P2P plugin IBext
358: hkn0708:413122:413122 [2] NCCL INFO Using network IBext
451: hkn0734:1156425:1156425 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
451: hkn0734:1156425:1156425 [3] NCCL INFO P2P plugin IBext
357: hkn0708:413110:413110 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
357: hkn0708:413110:413110 [1] NCCL INFO P2P plugin IBext
 83: hkn0425:2083899:2083899 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 83: hkn0425:2083899:2083899 [3] NCCL INFO P2P plugin IBext
472: hkn0805:1111994:1111994 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
472: hkn0805:1111994:1111994 [0] NCCL INFO Using network IBext
474: hkn0805:1112002:1112002 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
473: hkn0805:1112022:1112022 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
474: hkn0805:1112002:1112002 [2] NCCL INFO Using network IBext
473: hkn0805:1112022:1112022 [1] NCCL INFO Using network IBext
423: hkn0726:1547999:1547999 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
423: hkn0726:1547999:1547999 [3] NCCL INFO P2P plugin IBext
285: hkn0623:1872640:1872640 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
285: hkn0623:1872640:1872640 [1] NCCL INFO Using network IBext
421: hkn0726:1547991:1547991 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
421: hkn0726:1547991:1547991 [1] NCCL INFO P2P plugin IBext
115: hkn0505:2303672:2303672 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
384: hkn0716:108410:108410 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
 81: hkn0425:2083915:2083915 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 81: hkn0425:2083915:2083915 [1] NCCL INFO P2P plugin IBext
385: hkn0716:108390:108390 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
 82: hkn0425:2083927:2083927 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 82: hkn0425:2083927:2083927 [2] NCCL INFO P2P plugin IBext
359: hkn0708:413094:413094 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
359: hkn0708:413094:413094 [3] NCCL INFO P2P plugin IBext
145: hkn0513:3012872:3012872 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
145: hkn0513:3012872:3012872 [1] NCCL INFO Using network IBext
231: hkn0604:689125:689125 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
 80: hkn0425:2083907:2083907 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 80: hkn0425:2083907:2083907 [0] NCCL INFO P2P plugin IBext
450: hkn0734:1156441:1156441 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
450: hkn0734:1156441:1156441 [2] NCCL INFO Using network IBext
451: hkn0734:1156425:1156425 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
451: hkn0734:1156425:1156425 [3] NCCL INFO Using network IBext
357: hkn0708:413110:413110 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
357: hkn0708:413110:413110 [1] NCCL INFO Using network IBext
422: hkn0726:1548007:1548007 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
422: hkn0726:1548007:1548007 [2] NCCL INFO Using network IBext
423: hkn0726:1547999:1547999 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
421: hkn0726:1547991:1547991 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
423: hkn0726:1547999:1547999 [3] NCCL INFO Using network IBext
421: hkn0726:1547991:1547991 [1] NCCL INFO Using network IBext
114: hkn0505:2303656:2303656 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
114: hkn0505:2303656:2303656 [2] NCCL INFO P2P plugin IBext
475: hkn0805:1112010:1112010 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
475: hkn0805:1112010:1112010 [3] NCCL INFO Using network IBext
387: hkn0716:108382:108382 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
387: hkn0716:108382:108382 [3] NCCL INFO P2P plugin IBext
386: hkn0716:108398:108398 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
386: hkn0716:108398:108398 [2] NCCL INFO P2P plugin IBext
228: hkn0604:689133:689133 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
244: hkn0608:485608:485608 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
115: hkn0505:2303672:2303672 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
115: hkn0505:2303672:2303672 [3] NCCL INFO P2P plugin IBext
359: hkn0708:413094:413094 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
359: hkn0708:413094:413094 [3] NCCL INFO Using network IBext
 81: hkn0425:2083915:2083915 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 82: hkn0425:2083927:2083927 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 81: hkn0425:2083915:2083915 [1] NCCL INFO Using network IBext
 82: hkn0425:2083927:2083927 [2] NCCL INFO Using network IBext
 80: hkn0425:2083907:2083907 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 80: hkn0425:2083907:2083907 [0] NCCL INFO Using network IBext
384: hkn0716:108410:108410 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
384: hkn0716:108410:108410 [0] NCCL INFO P2P plugin IBext
113: hkn0505:2303684:2303684 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
230: hkn0604:689117:689117 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
385: hkn0716:108390:108390 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
385: hkn0716:108390:108390 [1] NCCL INFO P2P plugin IBext
112: hkn0505:2303664:2303664 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
247: hkn0608:485624:485624 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
448: hkn0734:1156433:1156433 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
448: hkn0734:1156433:1156433 [0] NCCL INFO Using network IBext
229: hkn0604:689145:689145 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
231: hkn0604:689125:689125 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
231: hkn0604:689125:689125 [3] NCCL INFO P2P plugin IBext
217: hkn0601:117600:117600 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
449: hkn0734:1156453:1156453 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
449: hkn0734:1156453:1156453 [1] NCCL INFO Using network IBext
420: hkn0726:1548019:1548019 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
420: hkn0726:1548019:1548019 [0] NCCL INFO Using network IBext
219: hkn0601:117592:117592 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
115: hkn0505:2303672:2303672 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
115: hkn0505:2303672:2303672 [3] NCCL INFO Using network IBext
 83: hkn0425:2083899:2083899 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 83: hkn0425:2083899:2083899 [3] NCCL INFO Using network IBext
244: hkn0608:485608:485608 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
244: hkn0608:485608:485608 [0] NCCL INFO P2P plugin IBext
228: hkn0604:689133:689133 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
228: hkn0604:689133:689133 [0] NCCL INFO P2P plugin IBext
245: hkn0608:485636:485636 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
246: hkn0608:485616:485616 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
385: hkn0716:108390:108390 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
385: hkn0716:108390:108390 [1] NCCL INFO Using network IBext
384: hkn0716:108410:108410 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
384: hkn0716:108410:108410 [0] NCCL INFO Using network IBext
230: hkn0604:689117:689117 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
230: hkn0604:689117:689117 [2] NCCL INFO P2P plugin IBext
113: hkn0505:2303684:2303684 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
113: hkn0505:2303684:2303684 [1] NCCL INFO P2P plugin IBext
112: hkn0505:2303664:2303664 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
112: hkn0505:2303664:2303664 [0] NCCL INFO P2P plugin IBext
247: hkn0608:485624:485624 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
247: hkn0608:485624:485624 [3] NCCL INFO P2P plugin IBext
217: hkn0601:117600:117600 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
217: hkn0601:117600:117600 [1] NCCL INFO P2P plugin IBext
229: hkn0604:689145:689145 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
229: hkn0604:689145:689145 [1] NCCL INFO P2P plugin IBext
216: hkn0601:117612:117612 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
219: hkn0601:117592:117592 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
219: hkn0601:117592:117592 [3] NCCL INFO P2P plugin IBext
218: hkn0601:117591:117591 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
114: hkn0505:2303656:2303656 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
114: hkn0505:2303656:2303656 [2] NCCL INFO Using network IBext
112: hkn0505:2303664:2303664 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
112: hkn0505:2303664:2303664 [0] NCCL INFO Using network IBext
113: hkn0505:2303684:2303684 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
113: hkn0505:2303684:2303684 [1] NCCL INFO Using network IBext
387: hkn0716:108382:108382 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
230: hkn0604:689117:689117 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
230: hkn0604:689117:689117 [2] NCCL INFO Using network IBext
387: hkn0716:108382:108382 [3] NCCL INFO Using network IBext
228: hkn0604:689133:689133 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
386: hkn0716:108398:108398 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
228: hkn0604:689133:689133 [0] NCCL INFO Using network IBext
386: hkn0716:108398:108398 [2] NCCL INFO Using network IBext
229: hkn0604:689145:689145 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
229: hkn0604:689145:689145 [1] NCCL INFO Using network IBext
247: hkn0608:485624:485624 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
247: hkn0608:485624:485624 [3] NCCL INFO Using network IBext
245: hkn0608:485636:485636 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
245: hkn0608:485636:485636 [1] NCCL INFO P2P plugin IBext
246: hkn0608:485616:485616 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
246: hkn0608:485616:485616 [2] NCCL INFO P2P plugin IBext
221: hkn0602:3362307:3362307 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
222: hkn0602:3362295:3362295 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
231: hkn0604:689125:689125 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
231: hkn0604:689125:689125 [3] NCCL INFO Using network IBext
297: hkn0627:1787808:1787808 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
216: hkn0601:117612:117612 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
216: hkn0601:117612:117612 [0] NCCL INFO P2P plugin IBext
223: hkn0602:3362287:3362287 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
219: hkn0601:117592:117592 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
219: hkn0601:117592:117592 [3] NCCL INFO Using network IBext
218: hkn0601:117591:117591 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
218: hkn0601:117591:117591 [2] NCCL INFO P2P plugin IBext
 63: hkn0420:3210091:3210091 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
 62: hkn0420:3210093:3210093 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
220: hkn0602:3362279:3362279 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
245: hkn0608:485636:485636 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
246: hkn0608:485616:485616 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
245: hkn0608:485636:485636 [1] NCCL INFO Using network IBext
246: hkn0608:485616:485616 [2] NCCL INFO Using network IBext
244: hkn0608:485608:485608 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
244: hkn0608:485608:485608 [0] NCCL INFO Using network IBext
495: hkn0810:939425:939425 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
 60: hkn0420:3210113:3210113 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
494: hkn0810:939437:939437 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
179: hkn0525:986681:986681 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
 61: hkn0420:3210101:3210101 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
221: hkn0602:3362307:3362307 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
221: hkn0602:3362307:3362307 [1] NCCL INFO P2P plugin IBext
222: hkn0602:3362295:3362295 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
222: hkn0602:3362295:3362295 [2] NCCL INFO P2P plugin IBext
492: hkn0810:939409:939409 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
399: hkn0719:1305603:1305603 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
297: hkn0627:1787808:1787808 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
297: hkn0627:1787808:1787808 [1] NCCL INFO P2P plugin IBext
493: hkn0810:939417:939417 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
217: hkn0601:117600:117600 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
217: hkn0601:117600:117600 [1] NCCL INFO Using network IBext
177: hkn0525:986697:986697 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
216: hkn0601:117612:117612 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
216: hkn0601:117612:117612 [0] NCCL INFO Using network IBext
218: hkn0601:117591:117591 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
218: hkn0601:117591:117591 [2] NCCL INFO Using network IBext
176: hkn0525:986689:986689 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
223: hkn0602:3362287:3362287 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
223: hkn0602:3362287:3362287 [3] NCCL INFO P2P plugin IBext
299: hkn0627:1787816:1787816 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
 63: hkn0420:3210091:3210091 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 63: hkn0420:3210091:3210091 [3] NCCL INFO P2P plugin IBext
 62: hkn0420:3210093:3210093 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 62: hkn0420:3210093:3210093 [2] NCCL INFO P2P plugin IBext
220: hkn0602:3362279:3362279 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
220: hkn0602:3362279:3362279 [0] NCCL INFO P2P plugin IBext
495: hkn0810:939425:939425 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
495: hkn0810:939425:939425 [3] NCCL INFO P2P plugin IBext
 60: hkn0420:3210113:3210113 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 60: hkn0420:3210113:3210113 [0] NCCL INFO P2P plugin IBext
296: hkn0627:1787824:1787824 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
178: hkn0525:986708:986708 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
298: hkn0627:1787836:1787836 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
494: hkn0810:939437:939437 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
494: hkn0810:939437:939437 [2] NCCL INFO P2P plugin IBext
179: hkn0525:986681:986681 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
179: hkn0525:986681:986681 [3] NCCL INFO P2P plugin IBext
492: hkn0810:939409:939409 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
492: hkn0810:939409:939409 [0] NCCL INFO P2P plugin IBext
399: hkn0719:1305603:1305603 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
399: hkn0719:1305603:1305603 [3] NCCL INFO P2P plugin IBext
177: hkn0525:986697:986697 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
177: hkn0525:986697:986697 [1] NCCL INFO P2P plugin IBext
493: hkn0810:939417:939417 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
493: hkn0810:939417:939417 [1] NCCL INFO P2P plugin IBext
 61: hkn0420:3210101:3210101 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 61: hkn0420:3210101:3210101 [1] NCCL INFO P2P plugin IBext
169: hkn0523:1547989:1547989 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
488: hkn0809:937239:937239 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
176: hkn0525:986689:986689 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
176: hkn0525:986689:986689 [0] NCCL INFO P2P plugin IBext
223: hkn0602:3362287:3362287 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
220: hkn0602:3362279:3362279 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
223: hkn0602:3362287:3362287 [3] NCCL INFO Using network IBext
220: hkn0602:3362279:3362279 [0] NCCL INFO Using network IBext
299: hkn0627:1787816:1787816 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
299: hkn0627:1787816:1787816 [3] NCCL INFO P2P plugin IBext
 15: hkn0407:1816151:1816151 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
397: hkn0719:1305595:1305595 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
398: hkn0719:1305623:1305623 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
 60: hkn0420:3210113:3210113 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 60: hkn0420:3210113:3210113 [0] NCCL INFO Using network IBext
 61: hkn0420:3210101:3210101 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 61: hkn0420:3210101:3210101 [1] NCCL INFO Using network IBext
296: hkn0627:1787824:1787824 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
296: hkn0627:1787824:1787824 [0] NCCL INFO P2P plugin IBext
396: hkn0719:1305611:1305611 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
298: hkn0627:1787836:1787836 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
298: hkn0627:1787836:1787836 [2] NCCL INFO P2P plugin IBext
178: hkn0525:986708:986708 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
178: hkn0525:986708:986708 [2] NCCL INFO P2P plugin IBext
492: hkn0810:939409:939409 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
492: hkn0810:939409:939409 [0] NCCL INFO Using network IBext
489: hkn0809:937231:937231 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
493: hkn0810:939417:939417 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
494: hkn0810:939437:939437 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
493: hkn0810:939417:939417 [1] NCCL INFO Using network IBext
494: hkn0810:939437:939437 [2] NCCL INFO Using network IBext
 13: hkn0407:1816167:1816167 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
490: hkn0809:937230:937230 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
 12: hkn0407:1816178:1816178 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
491: hkn0809:937251:937251 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
176: hkn0525:986689:986689 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
177: hkn0525:986697:986697 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
176: hkn0525:986689:986689 [0] NCCL INFO Using network IBext
177: hkn0525:986697:986697 [1] NCCL INFO Using network IBext
169: hkn0523:1547989:1547989 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
169: hkn0523:1547989:1547989 [1] NCCL INFO P2P plugin IBext
497: hkn0812:693675:693675 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
222: hkn0602:3362295:3362295 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
222: hkn0602:3362295:3362295 [2] NCCL INFO Using network IBext
221: hkn0602:3362307:3362307 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
221: hkn0602:3362307:3362307 [1] NCCL INFO Using network IBext
 14: hkn0407:1816159:1816159 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
297: hkn0627:1787808:1787808 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
299: hkn0627:1787816:1787816 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
297: hkn0627:1787808:1787808 [1] NCCL INFO Using network IBext
299: hkn0627:1787816:1787816 [3] NCCL INFO Using network IBext
488: hkn0809:937239:937239 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
488: hkn0809:937239:937239 [0] NCCL INFO P2P plugin IBext
 15: hkn0407:1816151:1816151 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 15: hkn0407:1816151:1816151 [3] NCCL INFO P2P plugin IBext
296: hkn0627:1787824:1787824 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
397: hkn0719:1305595:1305595 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
397: hkn0719:1305595:1305595 [1] NCCL INFO P2P plugin IBext
296: hkn0627:1787824:1787824 [0] NCCL INFO Using network IBext
298: hkn0627:1787836:1787836 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
298: hkn0627:1787836:1787836 [2] NCCL INFO Using network IBext
398: hkn0719:1305623:1305623 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
398: hkn0719:1305623:1305623 [2] NCCL INFO P2P plugin IBext
 63: hkn0420:3210091:3210091 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 63: hkn0420:3210091:3210091 [3] NCCL INFO Using network IBext
 62: hkn0420:3210093:3210093 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 62: hkn0420:3210093:3210093 [2] NCCL INFO Using network IBext
178: hkn0525:986708:986708 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
178: hkn0525:986708:986708 [2] NCCL INFO Using network IBext
170: hkn0523:1547969:1547969 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
396: hkn0719:1305611:1305611 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
396: hkn0719:1305611:1305611 [0] NCCL INFO P2P plugin IBext
495: hkn0810:939425:939425 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
495: hkn0810:939425:939425 [3] NCCL INFO Using network IBext
171: hkn0523:1547977:1547977 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
489: hkn0809:937231:937231 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
489: hkn0809:937231:937231 [1] NCCL INFO P2P plugin IBext
179: hkn0525:986681:986681 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
179: hkn0525:986681:986681 [3] NCCL INFO Using network IBext
 13: hkn0407:1816167:1816167 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 13: hkn0407:1816167:1816167 [1] NCCL INFO P2P plugin IBext
168: hkn0523:1547961:1547961 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
 73: hkn0423:1704793:1704793 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
490: hkn0809:937230:937230 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
490: hkn0809:937230:937230 [2] NCCL INFO P2P plugin IBext
295: hkn0626:1298345:1298345 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
 12: hkn0407:1816178:1816178 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 12: hkn0407:1816178:1816178 [0] NCCL INFO P2P plugin IBext
497: hkn0812:693675:693675 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
497: hkn0812:693675:693675 [1] NCCL INFO P2P plugin IBext
491: hkn0809:937251:937251 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
491: hkn0809:937251:937251 [3] NCCL INFO P2P plugin IBext
294: hkn0626:1298329:1298329 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
499: hkn0812:693683:693683 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
 14: hkn0407:1816159:1816159 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 14: hkn0407:1816159:1816159 [2] NCCL INFO P2P plugin IBext
496: hkn0812:693695:693695 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
399: hkn0719:1305603:1305603 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
399: hkn0719:1305603:1305603 [3] NCCL INFO Using network IBext
397: hkn0719:1305595:1305595 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
398: hkn0719:1305623:1305623 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
397: hkn0719:1305595:1305595 [1] NCCL INFO Using network IBext
398: hkn0719:1305623:1305623 [2] NCCL INFO Using network IBext
396: hkn0719:1305611:1305611 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
396: hkn0719:1305611:1305611 [0] NCCL INFO Using network IBext
498: hkn0812:693667:693667 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
170: hkn0523:1547969:1547969 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
170: hkn0523:1547969:1547969 [2] NCCL INFO P2P plugin IBext
 74: hkn0423:1704821:1704821 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
171: hkn0523:1547977:1547977 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
171: hkn0523:1547977:1547977 [3] NCCL INFO P2P plugin IBext
 13: hkn0407:1816167:1816167 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 12: hkn0407:1816178:1816178 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 13: hkn0407:1816167:1816167 [1] NCCL INFO Using network IBext
 12: hkn0407:1816178:1816178 [0] NCCL INFO Using network IBext
168: hkn0523:1547961:1547961 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
168: hkn0523:1547961:1547961 [0] NCCL INFO P2P plugin IBext
 75: hkn0423:1704809:1704809 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 14: hkn0407:1816159:1816159 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 14: hkn0407:1816159:1816159 [2] NCCL INFO Using network IBext
491: hkn0809:937251:937251 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
491: hkn0809:937251:937251 [3] NCCL INFO Using network IBext
489: hkn0809:937231:937231 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
489: hkn0809:937231:937231 [1] NCCL INFO Using network IBext
490: hkn0809:937230:937230 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
490: hkn0809:937230:937230 [2] NCCL INFO Using network IBext
 73: hkn0423:1704793:1704793 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 73: hkn0423:1704793:1704793 [1] NCCL INFO P2P plugin IBext
295: hkn0626:1298345:1298345 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
295: hkn0626:1298345:1298345 [3] NCCL INFO P2P plugin IBext
294: hkn0626:1298329:1298329 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
294: hkn0626:1298329:1298329 [2] NCCL INFO P2P plugin IBext
499: hkn0812:693683:693683 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
499: hkn0812:693683:693683 [3] NCCL INFO P2P plugin IBext
292: hkn0626:1298337:1298337 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
 72: hkn0423:1704801:1704801 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
496: hkn0812:693695:693695 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
496: hkn0812:693695:693695 [0] NCCL INFO P2P plugin IBext
169: hkn0523:1547989:1547989 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
169: hkn0523:1547989:1547989 [1] NCCL INFO Using network IBext
170: hkn0523:1547969:1547969 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
170: hkn0523:1547969:1547969 [2] NCCL INFO Using network IBext
488: hkn0809:937239:937239 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
488: hkn0809:937239:937239 [0] NCCL INFO Using network IBext
293: hkn0626:1298357:1298357 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
171: hkn0523:1547977:1547977 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
171: hkn0523:1547977:1547977 [3] NCCL INFO Using network IBext
322: hkn0633:1526218:1526218 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
 15: hkn0407:1816151:1816151 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 15: hkn0407:1816151:1816151 [3] NCCL INFO Using network IBext
168: hkn0523:1547961:1547961 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
321: hkn0633:1526230:1526230 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
168: hkn0523:1547961:1547961 [0] NCCL INFO Using network IBext
498: hkn0812:693667:693667 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
498: hkn0812:693667:693667 [2] NCCL INFO P2P plugin IBext
 74: hkn0423:1704821:1704821 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 74: hkn0423:1704821:1704821 [2] NCCL INFO P2P plugin IBext
107: hkn0503:2899572:2899572 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
323: hkn0633:1526210:1526210 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
 75: hkn0423:1704809:1704809 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 75: hkn0423:1704809:1704809 [3] NCCL INFO P2P plugin IBext
320: hkn0633:1526202:1526202 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
496: hkn0812:693695:693695 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
496: hkn0812:693695:693695 [0] NCCL INFO Using network IBext
292: hkn0626:1298337:1298337 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
292: hkn0626:1298337:1298337 [0] NCCL INFO P2P plugin IBext
497: hkn0812:693675:693675 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
497: hkn0812:693675:693675 [1] NCCL INFO Using network IBext
499: hkn0812:693683:693683 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
499: hkn0812:693683:693683 [3] NCCL INFO Using network IBext
498: hkn0812:693667:693667 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
498: hkn0812:693667:693667 [2] NCCL INFO Using network IBext
 72: hkn0423:1704801:1704801 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 72: hkn0423:1704801:1704801 [0] NCCL INFO P2P plugin IBext
293: hkn0626:1298357:1298357 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
293: hkn0626:1298357:1298357 [1] NCCL INFO P2P plugin IBext
322: hkn0633:1526218:1526218 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
322: hkn0633:1526218:1526218 [2] NCCL INFO P2P plugin IBext
105: hkn0503:2899564:2899564 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
321: hkn0633:1526230:1526230 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
321: hkn0633:1526230:1526230 [1] NCCL INFO P2P plugin IBext
 74: hkn0423:1704821:1704821 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 75: hkn0423:1704809:1704809 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 74: hkn0423:1704821:1704821 [2] NCCL INFO Using network IBext
 75: hkn0423:1704809:1704809 [3] NCCL INFO Using network IBext
107: hkn0503:2899572:2899572 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
107: hkn0503:2899572:2899572 [3] NCCL INFO P2P plugin IBext
323: hkn0633:1526210:1526210 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
323: hkn0633:1526210:1526210 [3] NCCL INFO P2P plugin IBext
106: hkn0503:2899580:2899580 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
 72: hkn0423:1704801:1704801 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 72: hkn0423:1704801:1704801 [0] NCCL INFO Using network IBext
104: hkn0503:2899591:2899591 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
 73: hkn0423:1704793:1704793 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 73: hkn0423:1704793:1704793 [1] NCCL INFO Using network IBext
320: hkn0633:1526202:1526202 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
320: hkn0633:1526202:1526202 [0] NCCL INFO P2P plugin IBext
 47: hkn0415:2496310:2496310 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
292: hkn0626:1298337:1298337 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
292: hkn0626:1298337:1298337 [0] NCCL INFO Using network IBext
295: hkn0626:1298345:1298345 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
294: hkn0626:1298329:1298329 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
295: hkn0626:1298345:1298345 [3] NCCL INFO Using network IBext
294: hkn0626:1298329:1298329 [2] NCCL INFO Using network IBext
293: hkn0626:1298357:1298357 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
293: hkn0626:1298357:1298357 [1] NCCL INFO Using network IBext
105: hkn0503:2899564:2899564 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
105: hkn0503:2899564:2899564 [1] NCCL INFO P2P plugin IBext
363: hkn0710:355437:355437 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
360: hkn0710:355429:355429 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
174: hkn0524:1133687:1133687 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
 44: hkn0415:2496321:2496321 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
175: hkn0524:1133671:1133671 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
323: hkn0633:1526210:1526210 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
323: hkn0633:1526210:1526210 [3] NCCL INFO Using network IBext
173: hkn0524:1133699:1133699 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
362: hkn0710:355457:355457 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
320: hkn0633:1526202:1526202 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
320: hkn0633:1526202:1526202 [0] NCCL INFO Using network IBext
 45: hkn0415:2496313:2496313 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
106: hkn0503:2899580:2899580 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
106: hkn0503:2899580:2899580 [2] NCCL INFO P2P plugin IBext
104: hkn0503:2899591:2899591 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
104: hkn0503:2899591:2899591 [0] NCCL INFO P2P plugin IBext
172: hkn0524:1133679:1133679 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
 47: hkn0415:2496310:2496310 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 47: hkn0415:2496310:2496310 [3] NCCL INFO P2P plugin IBext
361: hkn0710:355445:355445 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
105: hkn0503:2899564:2899564 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
105: hkn0503:2899564:2899564 [1] NCCL INFO Using network IBext
 46: hkn0415:2496333:2496333 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
363: hkn0710:355437:355437 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
363: hkn0710:355437:355437 [3] NCCL INFO P2P plugin IBext
322: hkn0633:1526218:1526218 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
322: hkn0633:1526218:1526218 [2] NCCL INFO Using network IBext
321: hkn0633:1526230:1526230 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
321: hkn0633:1526230:1526230 [1] NCCL INFO Using network IBext
106: hkn0503:2899580:2899580 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
106: hkn0503:2899580:2899580 [2] NCCL INFO Using network IBext
174: hkn0524:1133687:1133687 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
174: hkn0524:1133687:1133687 [2] NCCL INFO P2P plugin IBext
360: hkn0710:355429:355429 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
360: hkn0710:355429:355429 [0] NCCL INFO P2P plugin IBext
104: hkn0503:2899591:2899591 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
104: hkn0503:2899591:2899591 [0] NCCL INFO Using network IBext
175: hkn0524:1133671:1133671 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
175: hkn0524:1133671:1133671 [3] NCCL INFO P2P plugin IBext
107: hkn0503:2899572:2899572 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
107: hkn0503:2899572:2899572 [3] NCCL INFO Using network IBext
 44: hkn0415:2496321:2496321 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 44: hkn0415:2496321:2496321 [0] NCCL INFO P2P plugin IBext
173: hkn0524:1133699:1133699 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
173: hkn0524:1133699:1133699 [1] NCCL INFO P2P plugin IBext
 45: hkn0415:2496313:2496313 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 45: hkn0415:2496313:2496313 [1] NCCL INFO P2P plugin IBext
362: hkn0710:355457:355457 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
362: hkn0710:355457:355457 [2] NCCL INFO P2P plugin IBext
102: hkn0502:228938:228938 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
427: hkn0727:1345680:1345680 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
471: hkn0804:1205505:1205505 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
100: hkn0502:228966:228966 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
172: hkn0524:1133679:1133679 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
172: hkn0524:1133679:1133679 [0] NCCL INFO P2P plugin IBext
 64: hkn0421:2180612:2180612 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
425: hkn0727:1345672:1345672 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
101: hkn0502:228954:228954 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
361: hkn0710:355445:355445 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
361: hkn0710:355445:355445 [1] NCCL INFO P2P plugin IBext
424: hkn0727:1345692:1345692 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
426: hkn0727:1345664:1345664 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
 46: hkn0415:2496333:2496333 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 46: hkn0415:2496333:2496333 [2] NCCL INFO P2P plugin IBext
103: hkn0502:228946:228946 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
239: hkn0606:2371961:2371961 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
468: hkn0804:1205515:1205515 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
 44: hkn0415:2496321:2496321 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 44: hkn0415:2496321:2496321 [0] NCCL INFO Using network IBext
 45: hkn0415:2496313:2496313 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 45: hkn0415:2496313:2496313 [1] NCCL INFO Using network IBext
172: hkn0524:1133679:1133679 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
173: hkn0524:1133699:1133699 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
172: hkn0524:1133679:1133679 [0] NCCL INFO Using network IBext
237: hkn0606:2371969:2371969 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
173: hkn0524:1133699:1133699 [1] NCCL INFO Using network IBext
362: hkn0710:355457:355457 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
362: hkn0710:355457:355457 [2] NCCL INFO Using network IBext
240: hkn0607:904254:904254 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
102: hkn0502:228938:228938 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
102: hkn0502:228938:228938 [2] NCCL INFO P2P plugin IBext
469: hkn0804:1205507:1205507 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
361: hkn0710:355445:355445 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
100: hkn0502:228966:228966 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
100: hkn0502:228966:228966 [0] NCCL INFO P2P plugin IBext
361: hkn0710:355445:355445 [1] NCCL INFO Using network IBext
427: hkn0727:1345680:1345680 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
427: hkn0727:1345680:1345680 [3] NCCL INFO P2P plugin IBext
 46: hkn0415:2496333:2496333 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 46: hkn0415:2496333:2496333 [2] NCCL INFO Using network IBext
325: hkn0634:1520753:1520753 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
 47: hkn0415:2496310:2496310 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 64: hkn0421:2180612:2180612 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 64: hkn0421:2180612:2180612 [0] NCCL INFO P2P plugin IBext
 47: hkn0415:2496310:2496310 [3] NCCL INFO Using network IBext
243: hkn0607:904246:904246 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
 67: hkn0421:2180600:2180600 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
471: hkn0804:1205505:1205505 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
471: hkn0804:1205505:1205505 [3] NCCL INFO P2P plugin IBext
425: hkn0727:1345672:1345672 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
425: hkn0727:1345672:1345672 [1] NCCL INFO P2P plugin IBext
101: hkn0502:228954:228954 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
101: hkn0502:228954:228954 [1] NCCL INFO P2P plugin IBext
 65: hkn0421:2180584:2180584 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
 66: hkn0421:2180592:2180592 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
470: hkn0804:1205535:1205535 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
424: hkn0727:1345692:1345692 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
424: hkn0727:1345692:1345692 [0] NCCL INFO P2P plugin IBext
426: hkn0727:1345664:1345664 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
426: hkn0727:1345664:1345664 [2] NCCL INFO P2P plugin IBext
103: hkn0502:228946:228946 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
103: hkn0502:228946:228946 [3] NCCL INFO P2P plugin IBext
468: hkn0804:1205515:1205515 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
468: hkn0804:1205515:1205515 [0] NCCL INFO P2P plugin IBext
239: hkn0606:2371961:2371961 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
239: hkn0606:2371961:2371961 [3] NCCL INFO P2P plugin IBext
363: hkn0710:355437:355437 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
241: hkn0607:904238:904238 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
363: hkn0710:355437:355437 [3] NCCL INFO Using network IBext
360: hkn0710:355429:355429 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
360: hkn0710:355429:355429 [0] NCCL INFO Using network IBext
175: hkn0524:1133671:1133671 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
175: hkn0524:1133671:1133671 [3] NCCL INFO Using network IBext
174: hkn0524:1133687:1133687 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
174: hkn0524:1133687:1133687 [2] NCCL INFO Using network IBext
237: hkn0606:2371969:2371969 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
237: hkn0606:2371969:2371969 [1] NCCL INFO P2P plugin IBext
240: hkn0607:904254:904254 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
240: hkn0607:904254:904254 [0] NCCL INFO P2P plugin IBext
469: hkn0804:1205507:1205507 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
469: hkn0804:1205507:1205507 [1] NCCL INFO P2P plugin IBext
 26: hkn0410:1159602:1159602 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
325: hkn0634:1520753:1520753 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
325: hkn0634:1520753:1520753 [1] NCCL INFO P2P plugin IBext
 67: hkn0421:2180600:2180600 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 67: hkn0421:2180600:2180600 [3] NCCL INFO P2P plugin IBext
243: hkn0607:904246:904246 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
243: hkn0607:904246:904246 [3] NCCL INFO P2P plugin IBext
101: hkn0502:228954:228954 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
103: hkn0502:228946:228946 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
101: hkn0502:228954:228954 [1] NCCL INFO Using network IBext
103: hkn0502:228946:228946 [3] NCCL INFO Using network IBext
 27: hkn0410:1159586:1159586 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 65: hkn0421:2180584:2180584 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 65: hkn0421:2180584:2180584 [1] NCCL INFO P2P plugin IBext
425: hkn0727:1345672:1345672 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
425: hkn0727:1345672:1345672 [1] NCCL INFO Using network IBext
426: hkn0727:1345664:1345664 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
424: hkn0727:1345692:1345692 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
426: hkn0727:1345664:1345664 [2] NCCL INFO Using network IBext
424: hkn0727:1345692:1345692 [0] NCCL INFO Using network IBext
238: hkn0606:2371989:2371989 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
 66: hkn0421:2180592:2180592 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 66: hkn0421:2180592:2180592 [2] NCCL INFO P2P plugin IBext
470: hkn0804:1205535:1205535 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
470: hkn0804:1205535:1205535 [2] NCCL INFO P2P plugin IBext
236: hkn0606:2371977:2371977 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
468: hkn0804:1205515:1205515 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
468: hkn0804:1205515:1205515 [0] NCCL INFO Using network IBext
242: hkn0607:904266:904266 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
327: hkn0634:1520781:1520781 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
  9: hkn0405:3206758:3206758 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 24: hkn0410:1159594:1159594 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 25: hkn0410:1159614:1159614 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
241: hkn0607:904238:904238 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
241: hkn0607:904238:904238 [1] NCCL INFO P2P plugin IBext
469: hkn0804:1205507:1205507 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
469: hkn0804:1205507:1205507 [1] NCCL INFO Using network IBext
237: hkn0606:2371969:2371969 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
237: hkn0606:2371969:2371969 [1] NCCL INFO Using network IBext
 10: hkn0405:3206770:3206770 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
102: hkn0502:228938:228938 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
102: hkn0502:228938:228938 [2] NCCL INFO Using network IBext
100: hkn0502:228966:228966 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
100: hkn0502:228966:228966 [0] NCCL INFO Using network IBext
470: hkn0804:1205535:1205535 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
470: hkn0804:1205535:1205535 [2] NCCL INFO Using network IBext
 26: hkn0410:1159602:1159602 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 26: hkn0410:1159602:1159602 [2] NCCL INFO P2P plugin IBext
243: hkn0607:904246:904246 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
243: hkn0607:904246:904246 [3] NCCL INFO Using network IBext
 11: hkn0405:3206742:3206742 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 65: hkn0421:2180584:2180584 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 66: hkn0421:2180592:2180592 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 67: hkn0421:2180600:2180600 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 65: hkn0421:2180584:2180584 [1] NCCL INFO Using network IBext
 66: hkn0421:2180592:2180592 [2] NCCL INFO Using network IBext
 67: hkn0421:2180600:2180600 [3] NCCL INFO Using network IBext
 27: hkn0410:1159586:1159586 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 27: hkn0410:1159586:1159586 [3] NCCL INFO P2P plugin IBext
427: hkn0727:1345680:1345680 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
427: hkn0727:1345680:1345680 [3] NCCL INFO Using network IBext
238: hkn0606:2371989:2371989 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
238: hkn0606:2371989:2371989 [2] NCCL INFO P2P plugin IBext
236: hkn0606:2371977:2371977 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
236: hkn0606:2371977:2371977 [0] NCCL INFO P2P plugin IBext
 64: hkn0421:2180612:2180612 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
471: hkn0804:1205505:1205505 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
 64: hkn0421:2180612:2180612 [0] NCCL INFO Using network IBext
471: hkn0804:1205505:1205505 [3] NCCL INFO Using network IBext
241: hkn0607:904238:904238 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
241: hkn0607:904238:904238 [1] NCCL INFO Using network IBext
242: hkn0607:904266:904266 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
242: hkn0607:904266:904266 [2] NCCL INFO P2P plugin IBext
239: hkn0606:2371961:2371961 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
239: hkn0606:2371961:2371961 [3] NCCL INFO Using network IBext
327: hkn0634:1520781:1520781 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
327: hkn0634:1520781:1520781 [3] NCCL INFO P2P plugin IBext
  9: hkn0405:3206758:3206758 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  9: hkn0405:3206758:3206758 [1] NCCL INFO P2P plugin IBext
 25: hkn0410:1159614:1159614 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 25: hkn0410:1159614:1159614 [1] NCCL INFO P2P plugin IBext
 10: hkn0405:3206770:3206770 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 10: hkn0405:3206770:3206770 [2] NCCL INFO P2P plugin IBext
  8: hkn0405:3206750:3206750 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 24: hkn0410:1159594:1159594 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 24: hkn0410:1159594:1159594 [0] NCCL INFO P2P plugin IBext
240: hkn0607:904254:904254 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
240: hkn0607:904254:904254 [0] NCCL INFO Using network IBext
238: hkn0606:2371989:2371989 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
238: hkn0606:2371989:2371989 [2] NCCL INFO Using network IBext
236: hkn0606:2371977:2371977 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
236: hkn0606:2371977:2371977 [0] NCCL INFO Using network IBext
242: hkn0607:904266:904266 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
242: hkn0607:904266:904266 [2] NCCL INFO Using network IBext
326: hkn0634:1520761:1520761 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
 11: hkn0405:3206742:3206742 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 11: hkn0405:3206742:3206742 [3] NCCL INFO P2P plugin IBext
 27: hkn0410:1159586:1159586 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 27: hkn0410:1159586:1159586 [3] NCCL INFO Using network IBext
 25: hkn0410:1159614:1159614 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 25: hkn0410:1159614:1159614 [1] NCCL INFO Using network IBext
327: hkn0634:1520781:1520781 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
325: hkn0634:1520753:1520753 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
327: hkn0634:1520781:1520781 [3] NCCL INFO Using network IBext
325: hkn0634:1520753:1520753 [1] NCCL INFO Using network IBext
 24: hkn0410:1159594:1159594 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 24: hkn0410:1159594:1159594 [0] NCCL INFO Using network IBext
 10: hkn0405:3206770:3206770 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 10: hkn0405:3206770:3206770 [2] NCCL INFO Using network IBext
279: hkn0621:1991468:1991468 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
  8: hkn0405:3206750:3206750 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  8: hkn0405:3206750:3206750 [0] NCCL INFO P2P plugin IBext
 11: hkn0405:3206742:3206742 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 11: hkn0405:3206742:3206742 [3] NCCL INFO Using network IBext
324: hkn0634:1520769:1520769 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
308: hkn0630:1598339:1598339 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
339: hkn0703:740935:740935 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
326: hkn0634:1520761:1520761 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
326: hkn0634:1520761:1520761 [2] NCCL INFO P2P plugin IBext
 26: hkn0410:1159602:1159602 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 26: hkn0410:1159602:1159602 [2] NCCL INFO Using network IBext
  8: hkn0405:3206750:3206750 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  8: hkn0405:3206750:3206750 [0] NCCL INFO Using network IBext
  9: hkn0405:3206758:3206758 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  9: hkn0405:3206758:3206758 [1] NCCL INFO Using network IBext
279: hkn0621:1991468:1991468 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
279: hkn0621:1991468:1991468 [3] NCCL INFO P2P plugin IBext
277: hkn0621:1991460:1991460 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
326: hkn0634:1520761:1520761 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
326: hkn0634:1520761:1520761 [2] NCCL INFO Using network IBext
278: hkn0621:1991488:1991488 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
233: hkn0605:712002:712002 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
324: hkn0634:1520769:1520769 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
324: hkn0634:1520769:1520769 [0] NCCL INFO P2P plugin IBext
309: hkn0630:1598347:1598347 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
308: hkn0630:1598339:1598339 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
308: hkn0630:1598339:1598339 [0] NCCL INFO P2P plugin IBext
339: hkn0703:740935:740935 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
339: hkn0703:740935:740935 [3] NCCL INFO P2P plugin IBext
276: hkn0621:1991476:1991476 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
441: hkn0732:1211535:1211535 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
234: hkn0605:711998:711998 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
443: hkn0732:1211551:1211551 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
324: hkn0634:1520769:1520769 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
324: hkn0634:1520769:1520769 [0] NCCL INFO Using network IBext
338: hkn0703:740952:740952 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
233: hkn0605:712002:712002 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
233: hkn0605:712002:712002 [1] NCCL INFO P2P plugin IBext
277: hkn0621:1991460:1991460 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
277: hkn0621:1991460:1991460 [1] NCCL INFO P2P plugin IBext
278: hkn0621:1991488:1991488 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
278: hkn0621:1991488:1991488 [2] NCCL INFO P2P plugin IBext
309: hkn0630:1598347:1598347 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
309: hkn0630:1598347:1598347 [1] NCCL INFO P2P plugin IBext
310: hkn0630:1598359:1598359 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
276: hkn0621:1991476:1991476 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
276: hkn0621:1991476:1991476 [0] NCCL INFO P2P plugin IBext
441: hkn0732:1211535:1211535 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
441: hkn0732:1211535:1211535 [1] NCCL INFO P2P plugin IBext
442: hkn0732:1211543:1211543 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
288: hkn0624:1772822:1772822 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
289: hkn0624:1772850:1772850 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
440: hkn0732:1211563:1211563 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
232: hkn0605:711997:711997 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
443: hkn0732:1211551:1211551 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
443: hkn0732:1211551:1211551 [3] NCCL INFO P2P plugin IBext
290: hkn0624:1772838:1772838 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
291: hkn0624:1772830:1772830 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
311: hkn0630:1598331:1598331 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
234: hkn0605:711998:711998 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
234: hkn0605:711998:711998 [2] NCCL INFO P2P plugin IBext
372: hkn0713:470112:470112 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
338: hkn0703:740952:740952 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
338: hkn0703:740952:740952 [2] NCCL INFO P2P plugin IBext
309: hkn0630:1598347:1598347 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
309: hkn0630:1598347:1598347 [1] NCCL INFO Using network IBext
235: hkn0605:712014:712014 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
277: hkn0621:1991460:1991460 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
278: hkn0621:1991488:1991488 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
277: hkn0621:1991460:1991460 [1] NCCL INFO Using network IBext
278: hkn0621:1991488:1991488 [2] NCCL INFO Using network IBext
279: hkn0621:1991468:1991468 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
276: hkn0621:1991476:1991476 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
279: hkn0621:1991468:1991468 [3] NCCL INFO Using network IBext
276: hkn0621:1991476:1991476 [0] NCCL INFO Using network IBext
310: hkn0630:1598359:1598359 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
310: hkn0630:1598359:1598359 [2] NCCL INFO P2P plugin IBext
308: hkn0630:1598339:1598339 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
308: hkn0630:1598339:1598339 [0] NCCL INFO Using network IBext
442: hkn0732:1211543:1211543 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
442: hkn0732:1211543:1211543 [2] NCCL INFO P2P plugin IBext
440: hkn0732:1211563:1211563 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
440: hkn0732:1211563:1211563 [0] NCCL INFO P2P plugin IBext
288: hkn0624:1772822:1772822 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
288: hkn0624:1772822:1772822 [0] NCCL INFO P2P plugin IBext
232: hkn0605:711997:711997 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
232: hkn0605:711997:711997 [0] NCCL INFO P2P plugin IBext
339: hkn0703:740935:740935 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
373: hkn0713:470120:470120 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
339: hkn0703:740935:740935 [3] NCCL INFO Using network IBext
375: hkn0713:470140:470140 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
166: hkn0521:1197663:1197663 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
289: hkn0624:1772850:1772850 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
289: hkn0624:1772850:1772850 [1] NCCL INFO P2P plugin IBext
374: hkn0713:470128:470128 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
443: hkn0732:1211551:1211551 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
443: hkn0732:1211551:1211551 [3] NCCL INFO Using network IBext
338: hkn0703:740952:740952 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
338: hkn0703:740952:740952 [2] NCCL INFO Using network IBext
234: hkn0605:711998:711998 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
234: hkn0605:711998:711998 [2] NCCL INFO Using network IBext
311: hkn0630:1598331:1598331 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
311: hkn0630:1598331:1598331 [3] NCCL INFO P2P plugin IBext
336: hkn0703:740936:740936 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
310: hkn0630:1598359:1598359 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
310: hkn0630:1598359:1598359 [2] NCCL INFO Using network IBext
460: hkn0802:1200224:1200224 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
291: hkn0624:1772830:1772830 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
291: hkn0624:1772830:1772830 [3] NCCL INFO P2P plugin IBext
290: hkn0624:1772838:1772838 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
290: hkn0624:1772838:1772838 [2] NCCL INFO P2P plugin IBext
 85: hkn0426:813954:813954 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
372: hkn0713:470112:470112 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
372: hkn0713:470112:470112 [0] NCCL INFO P2P plugin IBext
442: hkn0732:1211543:1211543 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
442: hkn0732:1211543:1211543 [2] NCCL INFO Using network IBext
233: hkn0605:712002:712002 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
233: hkn0605:712002:712002 [1] NCCL INFO Using network IBext
235: hkn0605:712014:712014 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
235: hkn0605:712014:712014 [3] NCCL INFO P2P plugin IBext
232: hkn0605:711997:711997 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
232: hkn0605:711997:711997 [0] NCCL INFO Using network IBext
440: hkn0732:1211563:1211563 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
440: hkn0732:1211563:1211563 [0] NCCL INFO Using network IBext
164: hkn0521:1197679:1197679 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
462: hkn0802:1200232:1200232 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
248: hkn0609:710728:710728 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
 49: hkn0417:2267523:2267523 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
441: hkn0732:1211535:1211535 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
441: hkn0732:1211535:1211535 [1] NCCL INFO Using network IBext
311: hkn0630:1598331:1598331 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
311: hkn0630:1598331:1598331 [3] NCCL INFO Using network IBext
373: hkn0713:470120:470120 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
373: hkn0713:470120:470120 [1] NCCL INFO P2P plugin IBext
167: hkn0521:1197691:1197691 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
166: hkn0521:1197663:1197663 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
166: hkn0521:1197663:1197663 [2] NCCL INFO P2P plugin IBext
375: hkn0713:470140:470140 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
375: hkn0713:470140:470140 [3] NCCL INFO P2P plugin IBext
374: hkn0713:470128:470128 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
374: hkn0713:470128:470128 [2] NCCL INFO P2P plugin IBext
211: hkn0534:1148272:1148272 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
235: hkn0605:712014:712014 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
235: hkn0605:712014:712014 [3] NCCL INFO Using network IBext
165: hkn0521:1197671:1197671 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
163: hkn0520:2712757:2712757 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
290: hkn0624:1772838:1772838 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
 86: hkn0426:813946:813946 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
291: hkn0624:1772830:1772830 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
290: hkn0624:1772838:1772838 [2] NCCL INFO Using network IBext
291: hkn0624:1772830:1772830 [3] NCCL INFO Using network IBext
460: hkn0802:1200224:1200224 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
460: hkn0802:1200224:1200224 [0] NCCL INFO P2P plugin IBext
 85: hkn0426:813954:813954 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 85: hkn0426:813954:813954 [1] NCCL INFO P2P plugin IBext
251: hkn0609:710700:710700 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
 84: hkn0426:813962:813962 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
336: hkn0703:740936:740936 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
336: hkn0703:740936:740936 [0] NCCL INFO P2P plugin IBext
250: hkn0609:710708:710708 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
 51: hkn0417:2267539:2267539 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
210: hkn0534:1148280:1148280 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
161: hkn0520:2712765:2712765 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
462: hkn0802:1200232:1200232 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
462: hkn0802:1200232:1200232 [2] NCCL INFO P2P plugin IBext
248: hkn0609:710728:710728 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
248: hkn0609:710728:710728 [0] NCCL INFO P2P plugin IBext
 87: hkn0426:813974:813974 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
463: hkn0802:1200216:1200216 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
249: hkn0609:710716:710716 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
164: hkn0521:1197679:1197679 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
164: hkn0521:1197679:1197679 [0] NCCL INFO P2P plugin IBext
 49: hkn0417:2267523:2267523 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 49: hkn0417:2267523:2267523 [1] NCCL INFO P2P plugin IBext
208: hkn0534:1148264:1148264 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
 48: hkn0417:2267551:2267551 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
160: hkn0520:2712777:2712777 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
162: hkn0520:2712749:2712749 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
461: hkn0802:1200244:1200244 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
374: hkn0713:470128:470128 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
375: hkn0713:470140:470140 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
374: hkn0713:470128:470128 [2] NCCL INFO Using network IBext
375: hkn0713:470140:470140 [3] NCCL INFO Using network IBext
373: hkn0713:470120:470120 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
373: hkn0713:470120:470120 [1] NCCL INFO Using network IBext
288: hkn0624:1772822:1772822 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
288: hkn0624:1772822:1772822 [0] NCCL INFO Using network IBext
167: hkn0521:1197691:1197691 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
167: hkn0521:1197691:1197691 [3] NCCL INFO P2P plugin IBext
211: hkn0534:1148272:1148272 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
211: hkn0534:1148272:1148272 [3] NCCL INFO P2P plugin IBext
209: hkn0534:1148292:1148292 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
289: hkn0624:1772850:1772850 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
289: hkn0624:1772850:1772850 [1] NCCL INFO Using network IBext
 50: hkn0417:2267531:2267531 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
269: hkn0616:404794:404794 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
163: hkn0520:2712757:2712757 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
163: hkn0520:2712757:2712757 [3] NCCL INFO P2P plugin IBext
337: hkn0703:740940:740940 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
 86: hkn0426:813946:813946 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 86: hkn0426:813946:813946 [2] NCCL INFO P2P plugin IBext
251: hkn0609:710700:710700 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
251: hkn0609:710700:710700 [3] NCCL INFO P2P plugin IBext
372: hkn0713:470112:470112 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
372: hkn0713:470112:470112 [0] NCCL INFO Using network IBext
165: hkn0521:1197671:1197671 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
165: hkn0521:1197671:1197671 [1] NCCL INFO P2P plugin IBext
 84: hkn0426:813962:813962 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 84: hkn0426:813962:813962 [0] NCCL INFO P2P plugin IBext
250: hkn0609:710708:710708 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
250: hkn0609:710708:710708 [2] NCCL INFO P2P plugin IBext
336: hkn0703:740936:740936 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
336: hkn0703:740936:740936 [0] NCCL INFO Using network IBext
 51: hkn0417:2267539:2267539 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 51: hkn0417:2267539:2267539 [3] NCCL INFO P2P plugin IBext
462: hkn0802:1200232:1200232 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
462: hkn0802:1200232:1200232 [2] NCCL INFO Using network IBext
210: hkn0534:1148280:1148280 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
210: hkn0534:1148280:1148280 [2] NCCL INFO P2P plugin IBext
164: hkn0521:1197679:1197679 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
 87: hkn0426:813974:813974 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
164: hkn0521:1197679:1197679 [0] NCCL INFO Using network IBext
 87: hkn0426:813974:813974 [3] NCCL INFO P2P plugin IBext
167: hkn0521:1197691:1197691 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
463: hkn0802:1200216:1200216 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
463: hkn0802:1200216:1200216 [3] NCCL INFO P2P plugin IBext
167: hkn0521:1197691:1197691 [3] NCCL INFO Using network IBext
268: hkn0616:404786:404786 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
161: hkn0520:2712765:2712765 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
161: hkn0520:2712765:2712765 [1] NCCL INFO P2P plugin IBext
249: hkn0609:710716:710716 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
249: hkn0609:710716:710716 [1] NCCL INFO P2P plugin IBext
270: hkn0616:404806:404806 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
208: hkn0534:1148264:1148264 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
208: hkn0534:1148264:1148264 [0] NCCL INFO P2P plugin IBext
160: hkn0520:2712777:2712777 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
160: hkn0520:2712777:2712777 [0] NCCL INFO P2P plugin IBext
 48: hkn0417:2267551:2267551 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 48: hkn0417:2267551:2267551 [0] NCCL INFO P2P plugin IBext
162: hkn0520:2712749:2712749 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
162: hkn0520:2712749:2712749 [2] NCCL INFO P2P plugin IBext
461: hkn0802:1200244:1200244 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
461: hkn0802:1200244:1200244 [1] NCCL INFO P2P plugin IBext
209: hkn0534:1148292:1148292 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
209: hkn0534:1148292:1148292 [1] NCCL INFO P2P plugin IBext
 50: hkn0417:2267531:2267531 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 50: hkn0417:2267531:2267531 [2] NCCL INFO P2P plugin IBext
166: hkn0521:1197663:1197663 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
166: hkn0521:1197663:1197663 [2] NCCL INFO Using network IBext
165: hkn0521:1197671:1197671 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
271: hkn0616:404778:404778 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
165: hkn0521:1197671:1197671 [1] NCCL INFO Using network IBext
269: hkn0616:404794:404794 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
269: hkn0616:404794:404794 [1] NCCL INFO P2P plugin IBext
 84: hkn0426:813962:813962 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 84: hkn0426:813962:813962 [0] NCCL INFO Using network IBext
 86: hkn0426:813946:813946 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 86: hkn0426:813946:813946 [2] NCCL INFO Using network IBext
250: hkn0609:710708:710708 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
251: hkn0609:710700:710700 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
250: hkn0609:710708:710708 [2] NCCL INFO Using network IBext
251: hkn0609:710700:710700 [3] NCCL INFO Using network IBext
313: hkn0631:1021707:1021707 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
 87: hkn0426:813974:813974 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 87: hkn0426:813974:813974 [3] NCCL INFO Using network IBext
 85: hkn0426:813954:813954 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 85: hkn0426:813954:813954 [1] NCCL INFO Using network IBext
460: hkn0802:1200224:1200224 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
460: hkn0802:1200224:1200224 [0] NCCL INFO Using network IBext
210: hkn0534:1148280:1148280 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
210: hkn0534:1148280:1148280 [2] NCCL INFO Using network IBext
249: hkn0609:710716:710716 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
249: hkn0609:710716:710716 [1] NCCL INFO Using network IBext
337: hkn0703:740940:740940 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
337: hkn0703:740940:740940 [1] NCCL INFO P2P plugin IBext
 51: hkn0417:2267539:2267539 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 51: hkn0417:2267539:2267539 [3] NCCL INFO Using network IBext
208: hkn0534:1148264:1148264 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
208: hkn0534:1148264:1148264 [0] NCCL INFO Using network IBext
461: hkn0802:1200244:1200244 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
461: hkn0802:1200244:1200244 [1] NCCL INFO Using network IBext
315: hkn0631:1021715:1021715 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
 48: hkn0417:2267551:2267551 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 48: hkn0417:2267551:2267551 [0] NCCL INFO Using network IBext
463: hkn0802:1200216:1200216 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
463: hkn0802:1200216:1200216 [3] NCCL INFO Using network IBext
209: hkn0534:1148292:1148292 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
209: hkn0534:1148292:1148292 [1] NCCL INFO Using network IBext
248: hkn0609:710728:710728 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
248: hkn0609:710728:710728 [0] NCCL INFO Using network IBext
 50: hkn0417:2267531:2267531 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 50: hkn0417:2267531:2267531 [2] NCCL INFO Using network IBext
268: hkn0616:404786:404786 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
268: hkn0616:404786:404786 [0] NCCL INFO P2P plugin IBext
270: hkn0616:404806:404806 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
270: hkn0616:404806:404806 [2] NCCL INFO P2P plugin IBext
 49: hkn0417:2267523:2267523 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 49: hkn0417:2267523:2267523 [1] NCCL INFO Using network IBext
160: hkn0520:2712777:2712777 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
161: hkn0520:2712765:2712765 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
161: hkn0520:2712765:2712765 [1] NCCL INFO Using network IBext
162: hkn0520:2712749:2712749 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
162: hkn0520:2712749:2712749 [2] NCCL INFO Using network IBext
160: hkn0520:2712777:2712777 [0] NCCL INFO Using network IBext
271: hkn0616:404778:404778 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
271: hkn0616:404778:404778 [3] NCCL INFO P2P plugin IBext
211: hkn0534:1148272:1148272 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
211: hkn0534:1148272:1148272 [3] NCCL INFO Using network IBext
163: hkn0520:2712757:2712757 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
163: hkn0520:2712757:2712757 [3] NCCL INFO Using network IBext
314: hkn0631:1021723:1021723 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
313: hkn0631:1021707:1021707 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
313: hkn0631:1021707:1021707 [1] NCCL INFO P2P plugin IBext
312: hkn0631:1021735:1021735 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
337: hkn0703:740940:740940 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
337: hkn0703:740940:740940 [1] NCCL INFO Using network IBext
315: hkn0631:1021715:1021715 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
315: hkn0631:1021715:1021715 [3] NCCL INFO P2P plugin IBext
270: hkn0616:404806:404806 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
270: hkn0616:404806:404806 [2] NCCL INFO Using network IBext
268: hkn0616:404786:404786 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
271: hkn0616:404778:404778 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
268: hkn0616:404786:404786 [0] NCCL INFO Using network IBext
271: hkn0616:404778:404778 [3] NCCL INFO Using network IBext
455: hkn0736:1508224:1508224 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
127: hkn0508:3139037:3139037 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
269: hkn0616:404794:404794 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
269: hkn0616:404794:404794 [1] NCCL INFO Using network IBext
314: hkn0631:1021723:1021723 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
314: hkn0631:1021723:1021723 [2] NCCL INFO P2P plugin IBext
312: hkn0631:1021735:1021735 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
312: hkn0631:1021735:1021735 [0] NCCL INFO P2P plugin IBext
315: hkn0631:1021715:1021715 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
315: hkn0631:1021715:1021715 [3] NCCL INFO Using network IBext
124: hkn0508:3139017:3139017 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
504: hkn0815:395016:395016 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
455: hkn0736:1508224:1508224 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
455: hkn0736:1508224:1508224 [3] NCCL INFO P2P plugin IBext
454: hkn0736:1508244:1508244 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
127: hkn0508:3139037:3139037 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
127: hkn0508:3139037:3139037 [3] NCCL INFO P2P plugin IBext
453: hkn0736:1508232:1508232 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
314: hkn0631:1021723:1021723 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
314: hkn0631:1021723:1021723 [2] NCCL INFO Using network IBext
312: hkn0631:1021735:1021735 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
312: hkn0631:1021735:1021735 [0] NCCL INFO Using network IBext
126: hkn0508:3139025:3139025 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
452: hkn0736:1508216:1508216 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
125: hkn0508:3139009:3139009 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
348: hkn0706:752164:752164 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
350: hkn0706:752144:752144 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
313: hkn0631:1021707:1021707 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
313: hkn0631:1021707:1021707 [1] NCCL INFO Using network IBext
351: hkn0706:752152:752152 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
505: hkn0815:395028:395028 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
507: hkn0815:395008:395008 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
340: hkn0704:791895:791895 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
124: hkn0508:3139017:3139017 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
124: hkn0508:3139017:3139017 [0] NCCL INFO P2P plugin IBext
213: hkn0535:2398861:2398861 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
349: hkn0706:752136:752136 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
504: hkn0815:395016:395016 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
504: hkn0815:395016:395016 [0] NCCL INFO P2P plugin IBext
454: hkn0736:1508244:1508244 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
454: hkn0736:1508244:1508244 [2] NCCL INFO P2P plugin IBext
453: hkn0736:1508232:1508232 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
453: hkn0736:1508232:1508232 [1] NCCL INFO P2P plugin IBext
215: hkn0535:2398889:2398889 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
126: hkn0508:3139025:3139025 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
126: hkn0508:3139025:3139025 [2] NCCL INFO P2P plugin IBext
125: hkn0508:3139009:3139009 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
125: hkn0508:3139009:3139009 [1] NCCL INFO P2P plugin IBext
452: hkn0736:1508216:1508216 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
452: hkn0736:1508216:1508216 [0] NCCL INFO P2P plugin IBext
214: hkn0535:2398869:2398869 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
348: hkn0706:752164:752164 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
348: hkn0706:752164:752164 [0] NCCL INFO P2P plugin IBext
506: hkn0815:395000:395000 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
350: hkn0706:752144:752144 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
350: hkn0706:752144:752144 [2] NCCL INFO P2P plugin IBext
342: hkn0704:791887:791887 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
351: hkn0706:752152:752152 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
351: hkn0706:752152:752152 [3] NCCL INFO P2P plugin IBext
124: hkn0508:3139017:3139017 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
124: hkn0508:3139017:3139017 [0] NCCL INFO Using network IBext
340: hkn0704:791895:791895 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
340: hkn0704:791895:791895 [0] NCCL INFO P2P plugin IBext
341: hkn0704:791903:791903 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
213: hkn0535:2398861:2398861 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
213: hkn0535:2398861:2398861 [1] NCCL INFO P2P plugin IBext
126: hkn0508:3139025:3139025 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
126: hkn0508:3139025:3139025 [2] NCCL INFO Using network IBext
507: hkn0815:395008:395008 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
507: hkn0815:395008:395008 [3] NCCL INFO P2P plugin IBext
505: hkn0815:395028:395028 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
505: hkn0815:395028:395028 [1] NCCL INFO P2P plugin IBext
125: hkn0508:3139009:3139009 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
125: hkn0508:3139009:3139009 [1] NCCL INFO Using network IBext
349: hkn0706:752136:752136 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
349: hkn0706:752136:752136 [1] NCCL INFO P2P plugin IBext
343: hkn0704:791915:791915 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
453: hkn0736:1508232:1508232 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
453: hkn0736:1508232:1508232 [1] NCCL INFO Using network IBext
454: hkn0736:1508244:1508244 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
454: hkn0736:1508244:1508244 [2] NCCL INFO Using network IBext
452: hkn0736:1508216:1508216 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
452: hkn0736:1508216:1508216 [0] NCCL INFO Using network IBext
455: hkn0736:1508224:1508224 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
455: hkn0736:1508224:1508224 [3] NCCL INFO Using network IBext
127: hkn0508:3139037:3139037 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
215: hkn0535:2398889:2398889 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
215: hkn0535:2398889:2398889 [3] NCCL INFO P2P plugin IBext
127: hkn0508:3139037:3139037 [3] NCCL INFO Using network IBext
214: hkn0535:2398869:2398869 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
214: hkn0535:2398869:2398869 [2] NCCL INFO P2P plugin IBext
506: hkn0815:395000:395000 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
506: hkn0815:395000:395000 [2] NCCL INFO P2P plugin IBext
212: hkn0535:2398877:2398877 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
351: hkn0706:752152:752152 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
349: hkn0706:752136:752136 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
351: hkn0706:752152:752152 [3] NCCL INFO Using network IBext
349: hkn0706:752136:752136 [1] NCCL INFO Using network IBext
342: hkn0704:791887:791887 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
342: hkn0704:791887:791887 [2] NCCL INFO P2P plugin IBext
414: hkn0724:1715886:1715886 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
341: hkn0704:791903:791903 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
341: hkn0704:791903:791903 [1] NCCL INFO P2P plugin IBext
505: hkn0815:395028:395028 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
507: hkn0815:395008:395008 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
505: hkn0815:395028:395028 [1] NCCL INFO Using network IBext
507: hkn0815:395008:395008 [3] NCCL INFO Using network IBext
343: hkn0704:791915:791915 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
343: hkn0704:791915:791915 [3] NCCL INFO P2P plugin IBext
377: hkn0714:431907:431907 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
378: hkn0714:431915:431915 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
215: hkn0535:2398889:2398889 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
215: hkn0535:2398889:2398889 [3] NCCL INFO Using network IBext
379: hkn0714:431935:431935 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
214: hkn0535:2398869:2398869 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
214: hkn0535:2398869:2398869 [2] NCCL INFO Using network IBext
413: hkn0724:1715874:1715874 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
412: hkn0724:1715866:1715866 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
415: hkn0724:1715858:1715858 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
136: hkn0511:3066274:3066274 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
506: hkn0815:395000:395000 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
506: hkn0815:395000:395000 [2] NCCL INFO Using network IBext
504: hkn0815:395016:395016 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
504: hkn0815:395016:395016 [0] NCCL INFO Using network IBext
376: hkn0714:431923:431923 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
348: hkn0706:752164:752164 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
348: hkn0706:752164:752164 [0] NCCL INFO Using network IBext
350: hkn0706:752144:752144 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
350: hkn0706:752144:752144 [2] NCCL INFO Using network IBext
212: hkn0535:2398877:2398877 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
212: hkn0535:2398877:2398877 [0] NCCL INFO P2P plugin IBext
139: hkn0511:3066266:3066266 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
346: hkn0705:783101:783101 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
341: hkn0704:791903:791903 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
341: hkn0704:791903:791903 [1] NCCL INFO Using network IBext
343: hkn0704:791915:791915 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
343: hkn0704:791915:791915 [3] NCCL INFO Using network IBext
342: hkn0704:791887:791887 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
342: hkn0704:791887:791887 [2] NCCL INFO Using network IBext
306: hkn0629:1591947:1591947 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
340: hkn0704:791895:791895 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
340: hkn0704:791895:791895 [0] NCCL INFO Using network IBext
414: hkn0724:1715886:1715886 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
414: hkn0724:1715886:1715886 [2] NCCL INFO P2P plugin IBext
213: hkn0535:2398861:2398861 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
213: hkn0535:2398861:2398861 [1] NCCL INFO Using network IBext
377: hkn0714:431907:431907 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
377: hkn0714:431907:431907 [1] NCCL INFO P2P plugin IBext
413: hkn0724:1715874:1715874 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
413: hkn0724:1715874:1715874 [1] NCCL INFO P2P plugin IBext
379: hkn0714:431935:431935 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
379: hkn0714:431935:431935 [3] NCCL INFO P2P plugin IBext
136: hkn0511:3066274:3066274 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
136: hkn0511:3066274:3066274 [0] NCCL INFO P2P plugin IBext
378: hkn0714:431915:431915 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
378: hkn0714:431915:431915 [2] NCCL INFO P2P plugin IBext
347: hkn0705:783109:783109 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
415: hkn0724:1715858:1715858 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
415: hkn0724:1715858:1715858 [3] NCCL INFO P2P plugin IBext
 76: hkn0424:2947881:2947881 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
212: hkn0535:2398877:2398877 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
212: hkn0535:2398877:2398877 [0] NCCL INFO Using network IBext
138: hkn0511:3066294:3066294 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
 79: hkn0424:2947870:2947870 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
137: hkn0511:3066282:3066282 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
412: hkn0724:1715866:1715866 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
412: hkn0724:1715866:1715866 [0] NCCL INFO P2P plugin IBext
 77: hkn0424:2947854:2947854 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
304: hkn0629:1591939:1591939 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
376: hkn0714:431923:431923 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
376: hkn0714:431923:431923 [0] NCCL INFO P2P plugin IBext
346: hkn0705:783101:783101 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
346: hkn0705:783101:783101 [2] NCCL INFO P2P plugin IBext
139: hkn0511:3066266:3066266 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
139: hkn0511:3066266:3066266 [3] NCCL INFO P2P plugin IBext
307: hkn0629:1591931:1591931 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
306: hkn0629:1591947:1591947 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
306: hkn0629:1591947:1591947 [2] NCCL INFO P2P plugin IBext
345: hkn0705:783117:783117 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
413: hkn0724:1715874:1715874 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
413: hkn0724:1715874:1715874 [1] NCCL INFO Using network IBext
415: hkn0724:1715858:1715858 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
415: hkn0724:1715858:1715858 [3] NCCL INFO Using network IBext
305: hkn0629:1591959:1591959 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
412: hkn0724:1715866:1715866 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
412: hkn0724:1715866:1715866 [0] NCCL INFO Using network IBext
344: hkn0705:783129:783129 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
347: hkn0705:783109:783109 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
347: hkn0705:783109:783109 [3] NCCL INFO P2P plugin IBext
 76: hkn0424:2947881:2947881 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 76: hkn0424:2947881:2947881 [0] NCCL INFO P2P plugin IBext
 78: hkn0424:2947862:2947862 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
138: hkn0511:3066294:3066294 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
138: hkn0511:3066294:3066294 [2] NCCL INFO P2P plugin IBext
137: hkn0511:3066282:3066282 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
137: hkn0511:3066282:3066282 [1] NCCL INFO P2P plugin IBext
 79: hkn0424:2947870:2947870 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 79: hkn0424:2947870:2947870 [3] NCCL INFO P2P plugin IBext
376: hkn0714:431923:431923 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
376: hkn0714:431923:431923 [0] NCCL INFO Using network IBext
304: hkn0629:1591939:1591939 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
304: hkn0629:1591939:1591939 [0] NCCL INFO P2P plugin IBext
139: hkn0511:3066266:3066266 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
 77: hkn0424:2947854:2947854 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 77: hkn0424:2947854:2947854 [1] NCCL INFO P2P plugin IBext
139: hkn0511:3066266:3066266 [3] NCCL INFO Using network IBext
409: hkn0723:207893:207893 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
307: hkn0629:1591931:1591931 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
307: hkn0629:1591931:1591931 [3] NCCL INFO P2P plugin IBext
 93: hkn0428:667227:667227 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
467: hkn0803:876457:876457 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
414: hkn0724:1715886:1715886 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
414: hkn0724:1715886:1715886 [2] NCCL INFO Using network IBext
345: hkn0705:783117:783117 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
345: hkn0705:783117:783117 [1] NCCL INFO P2P plugin IBext
138: hkn0511:3066294:3066294 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
138: hkn0511:3066294:3066294 [2] NCCL INFO Using network IBext
137: hkn0511:3066282:3066282 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
137: hkn0511:3066282:3066282 [1] NCCL INFO Using network IBext
305: hkn0629:1591959:1591959 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
305: hkn0629:1591959:1591959 [1] NCCL INFO P2P plugin IBext
136: hkn0511:3066274:3066274 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
136: hkn0511:3066274:3066274 [0] NCCL INFO Using network IBext
344: hkn0705:783129:783129 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
344: hkn0705:783129:783129 [0] NCCL INFO P2P plugin IBext
379: hkn0714:431935:431935 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
379: hkn0714:431935:431935 [3] NCCL INFO Using network IBext
347: hkn0705:783109:783109 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
347: hkn0705:783109:783109 [3] NCCL INFO Using network IBext
377: hkn0714:431907:431907 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
378: hkn0714:431915:431915 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
377: hkn0714:431907:431907 [1] NCCL INFO Using network IBext
378: hkn0714:431915:431915 [2] NCCL INFO Using network IBext
411: hkn0723:207921:207921 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 78: hkn0424:2947862:2947862 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 78: hkn0424:2947862:2947862 [2] NCCL INFO P2P plugin IBext
 94: hkn0428:667247:667247 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
464: hkn0803:876465:876465 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
 77: hkn0424:2947854:2947854 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 77: hkn0424:2947854:2947854 [1] NCCL INFO Using network IBext
304: hkn0629:1591939:1591939 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
465: hkn0803:876477:876477 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
304: hkn0629:1591939:1591939 [0] NCCL INFO Using network IBext
307: hkn0629:1591931:1591931 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
307: hkn0629:1591931:1591931 [3] NCCL INFO Using network IBext
264: hkn0615:414213:414213 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
 95: hkn0428:667235:667235 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
409: hkn0723:207893:207893 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
409: hkn0723:207893:207893 [1] NCCL INFO P2P plugin IBext
346: hkn0705:783101:783101 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
346: hkn0705:783101:783101 [2] NCCL INFO Using network IBext
345: hkn0705:783117:783117 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
345: hkn0705:783117:783117 [1] NCCL INFO Using network IBext
305: hkn0629:1591959:1591959 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
305: hkn0629:1591959:1591959 [1] NCCL INFO Using network IBext
344: hkn0705:783129:783129 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
182: hkn0526:1428290:1428290 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
344: hkn0705:783129:783129 [0] NCCL INFO Using network IBext
410: hkn0723:207909:207909 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
408: hkn0723:207901:207901 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 93: hkn0428:667227:667227 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 93: hkn0428:667227:667227 [1] NCCL INFO P2P plugin IBext
467: hkn0803:876457:876457 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
467: hkn0803:876457:876457 [3] NCCL INFO P2P plugin IBext
306: hkn0629:1591947:1591947 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
306: hkn0629:1591947:1591947 [2] NCCL INFO Using network IBext
 92: hkn0428:667219:667219 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
 78: hkn0424:2947862:2947862 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 78: hkn0424:2947862:2947862 [2] NCCL INFO Using network IBext
265: hkn0615:414225:414225 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
466: hkn0803:876456:876456 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
477: hkn0806:1054230:1054230 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
476: hkn0806:1054250:1054250 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
266: hkn0615:414205:414205 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
411: hkn0723:207921:207921 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
478: hkn0806:1054238:1054238 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
411: hkn0723:207921:207921 [3] NCCL INFO P2P plugin IBext
181: hkn0526:1428306:1428306 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
183: hkn0526:1428318:1428318 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
180: hkn0526:1428298:1428298 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
 76: hkn0424:2947881:2947881 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 76: hkn0424:2947881:2947881 [0] NCCL INFO Using network IBext
 94: hkn0428:667247:667247 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 94: hkn0428:667247:667247 [2] NCCL INFO P2P plugin IBext
 79: hkn0424:2947870:2947870 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 79: hkn0424:2947870:2947870 [3] NCCL INFO Using network IBext
464: hkn0803:876465:876465 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
464: hkn0803:876465:876465 [0] NCCL INFO P2P plugin IBext
264: hkn0615:414213:414213 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
264: hkn0615:414213:414213 [0] NCCL INFO P2P plugin IBext
465: hkn0803:876477:876477 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
465: hkn0803:876477:876477 [1] NCCL INFO P2P plugin IBext
 95: hkn0428:667235:667235 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 95: hkn0428:667235:667235 [3] NCCL INFO P2P plugin IBext
479: hkn0806:1054222:1054222 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
182: hkn0526:1428290:1428290 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
182: hkn0526:1428290:1428290 [2] NCCL INFO P2P plugin IBext
366: hkn0711:583820:583820 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
410: hkn0723:207909:207909 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
410: hkn0723:207909:207909 [2] NCCL INFO P2P plugin IBext
408: hkn0723:207901:207901 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
408: hkn0723:207901:207901 [0] NCCL INFO P2P plugin IBext
 92: hkn0428:667219:667219 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 92: hkn0428:667219:667219 [0] NCCL INFO P2P plugin IBext
267: hkn0615:414197:414197 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
265: hkn0615:414225:414225 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
265: hkn0615:414225:414225 [1] NCCL INFO P2P plugin IBext
466: hkn0803:876456:876456 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
466: hkn0803:876456:876456 [2] NCCL INFO P2P plugin IBext
477: hkn0806:1054230:1054230 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
477: hkn0806:1054230:1054230 [1] NCCL INFO P2P plugin IBext
365: hkn0711:583808:583808 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
364: hkn0711:583800:583800 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
411: hkn0723:207921:207921 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
411: hkn0723:207921:207921 [3] NCCL INFO Using network IBext
476: hkn0806:1054250:1054250 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
476: hkn0806:1054250:1054250 [0] NCCL INFO P2P plugin IBext
266: hkn0615:414205:414205 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
266: hkn0615:414205:414205 [2] NCCL INFO P2P plugin IBext
478: hkn0806:1054238:1054238 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
478: hkn0806:1054238:1054238 [2] NCCL INFO P2P plugin IBext
 94: hkn0428:667247:667247 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 94: hkn0428:667247:667247 [2] NCCL INFO Using network IBext
180: hkn0526:1428298:1428298 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
180: hkn0526:1428298:1428298 [0] NCCL INFO P2P plugin IBext
 95: hkn0428:667235:667235 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 95: hkn0428:667235:667235 [3] NCCL INFO Using network IBext
464: hkn0803:876465:876465 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
464: hkn0803:876465:876465 [0] NCCL INFO Using network IBext
465: hkn0803:876477:876477 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
181: hkn0526:1428306:1428306 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
181: hkn0526:1428306:1428306 [1] NCCL INFO P2P plugin IBext
465: hkn0803:876477:876477 [1] NCCL INFO Using network IBext
410: hkn0723:207909:207909 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
410: hkn0723:207909:207909 [2] NCCL INFO Using network IBext
183: hkn0526:1428318:1428318 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
183: hkn0526:1428318:1428318 [3] NCCL INFO P2P plugin IBext
408: hkn0723:207901:207901 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
408: hkn0723:207901:207901 [0] NCCL INFO Using network IBext
 92: hkn0428:667219:667219 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 92: hkn0428:667219:667219 [0] NCCL INFO Using network IBext
466: hkn0803:876456:876456 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
466: hkn0803:876456:876456 [2] NCCL INFO Using network IBext
479: hkn0806:1054222:1054222 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
479: hkn0806:1054222:1054222 [3] NCCL INFO P2P plugin IBext
409: hkn0723:207893:207893 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
409: hkn0723:207893:207893 [1] NCCL INFO Using network IBext
366: hkn0711:583820:583820 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
366: hkn0711:583820:583820 [2] NCCL INFO P2P plugin IBext
467: hkn0803:876457:876457 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
467: hkn0803:876457:876457 [3] NCCL INFO Using network IBext
367: hkn0711:583792:583792 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
265: hkn0615:414225:414225 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
265: hkn0615:414225:414225 [1] NCCL INFO Using network IBext
266: hkn0615:414205:414205 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
266: hkn0615:414205:414205 [2] NCCL INFO Using network IBext
 93: hkn0428:667227:667227 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 93: hkn0428:667227:667227 [1] NCCL INFO Using network IBext
355: hkn0707:4019792:4019792 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
267: hkn0615:414197:414197 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
267: hkn0615:414197:414197 [3] NCCL INFO P2P plugin IBext
354: hkn0707:4019820:4019820 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
478: hkn0806:1054238:1054238 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
478: hkn0806:1054238:1054238 [2] NCCL INFO Using network IBext
365: hkn0711:583808:583808 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
365: hkn0711:583808:583808 [1] NCCL INFO P2P plugin IBext
364: hkn0711:583800:583800 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
364: hkn0711:583800:583800 [0] NCCL INFO P2P plugin IBext
352: hkn0707:4019800:4019800 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
180: hkn0526:1428298:1428298 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
181: hkn0526:1428306:1428306 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
183: hkn0526:1428318:1428318 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
183: hkn0526:1428318:1428318 [3] NCCL INFO Using network IBext
180: hkn0526:1428298:1428298 [0] NCCL INFO Using network IBext
181: hkn0526:1428306:1428306 [1] NCCL INFO Using network IBext
479: hkn0806:1054222:1054222 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
479: hkn0806:1054222:1054222 [3] NCCL INFO Using network IBext
264: hkn0615:414213:414213 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
264: hkn0615:414213:414213 [0] NCCL INFO Using network IBext
267: hkn0615:414197:414197 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
267: hkn0615:414197:414197 [3] NCCL INFO Using network IBext
182: hkn0526:1428290:1428290 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
182: hkn0526:1428290:1428290 [2] NCCL INFO Using network IBext
353: hkn0707:4019808:4019808 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
283: hkn0622:2020400:2020400 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
282: hkn0622:2020384:2020384 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
367: hkn0711:583792:583792 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
367: hkn0711:583792:583792 [3] NCCL INFO P2P plugin IBext
355: hkn0707:4019792:4019792 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
280: hkn0622:2020412:2020412 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
355: hkn0707:4019792:4019792 [3] NCCL INFO P2P plugin IBext
354: hkn0707:4019820:4019820 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
354: hkn0707:4019820:4019820 [2] NCCL INFO P2P plugin IBext
 88: hkn0427:1135037:1135037 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
476: hkn0806:1054250:1054250 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
476: hkn0806:1054250:1054250 [0] NCCL INFO Using network IBext
364: hkn0711:583800:583800 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
365: hkn0711:583808:583808 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
364: hkn0711:583800:583800 [0] NCCL INFO Using network IBext
365: hkn0711:583808:583808 [1] NCCL INFO Using network IBext
281: hkn0622:2020392:2020392 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
477: hkn0806:1054230:1054230 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
477: hkn0806:1054230:1054230 [1] NCCL INFO Using network IBext
352: hkn0707:4019800:4019800 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
352: hkn0707:4019800:4019800 [0] NCCL INFO P2P plugin IBext
184: hkn0527:1348838:1348838 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
 89: hkn0427:1135025:1135025 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
367: hkn0711:583792:583792 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
367: hkn0711:583792:583792 [3] NCCL INFO Using network IBext
353: hkn0707:4019808:4019808 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
353: hkn0707:4019808:4019808 [1] NCCL INFO P2P plugin IBext
 91: hkn0427:1135017:1135017 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
283: hkn0622:2020400:2020400 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
282: hkn0622:2020384:2020384 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
283: hkn0622:2020400:2020400 [3] NCCL INFO P2P plugin IBext
282: hkn0622:2020384:2020384 [2] NCCL INFO P2P plugin IBext
 90: hkn0427:1135009:1135009 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
366: hkn0711:583820:583820 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
366: hkn0711:583820:583820 [2] NCCL INFO Using network IBext
 88: hkn0427:1135037:1135037 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 88: hkn0427:1135037:1135037 [0] NCCL INFO P2P plugin IBext
280: hkn0622:2020412:2020412 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
280: hkn0622:2020412:2020412 [0] NCCL INFO P2P plugin IBext
281: hkn0622:2020392:2020392 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
281: hkn0622:2020392:2020392 [1] NCCL INFO P2P plugin IBext
353: hkn0707:4019808:4019808 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
353: hkn0707:4019808:4019808 [1] NCCL INFO Using network IBext
184: hkn0527:1348838:1348838 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
184: hkn0527:1348838:1348838 [0] NCCL INFO P2P plugin IBext
352: hkn0707:4019800:4019800 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
352: hkn0707:4019800:4019800 [0] NCCL INFO Using network IBext
 89: hkn0427:1135025:1135025 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 89: hkn0427:1135025:1135025 [1] NCCL INFO P2P plugin IBext
334: hkn0636:1654143:1654143 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
 69: hkn0422:4153025:4153025 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 91: hkn0427:1135017:1135017 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 91: hkn0427:1135017:1135017 [3] NCCL INFO P2P plugin IBext
185: hkn0527:1348822:1348822 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
 68: hkn0422:4153004:4153004 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 90: hkn0427:1135009:1135009 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 90: hkn0427:1135009:1135009 [2] NCCL INFO P2P plugin IBext
280: hkn0622:2020412:2020412 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
281: hkn0622:2020392:2020392 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
280: hkn0622:2020412:2020412 [0] NCCL INFO Using network IBext
281: hkn0622:2020392:2020392 [1] NCCL INFO Using network IBext
 71: hkn0422:4153013:4153013 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
332: hkn0636:1654151:1654151 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
355: hkn0707:4019792:4019792 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
355: hkn0707:4019792:4019792 [3] NCCL INFO Using network IBext
354: hkn0707:4019820:4019820 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
354: hkn0707:4019820:4019820 [2] NCCL INFO Using network IBext
187: hkn0527:1348850:1348850 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
186: hkn0527:1348830:1348830 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
 70: hkn0422:4153005:4153005 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 89: hkn0427:1135025:1135025 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 91: hkn0427:1135017:1135017 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 89: hkn0427:1135025:1135025 [1] NCCL INFO Using network IBext
 91: hkn0427:1135017:1135017 [3] NCCL INFO Using network IBext
334: hkn0636:1654143:1654143 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
334: hkn0636:1654143:1654143 [2] NCCL INFO P2P plugin IBext
185: hkn0527:1348822:1348822 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
185: hkn0527:1348822:1348822 [1] NCCL INFO P2P plugin IBext
 90: hkn0427:1135009:1135009 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 90: hkn0427:1135009:1135009 [2] NCCL INFO Using network IBext
 69: hkn0422:4153025:4153025 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 69: hkn0422:4153025:4153025 [1] NCCL INFO P2P plugin IBext
282: hkn0622:2020384:2020384 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
282: hkn0622:2020384:2020384 [2] NCCL INFO Using network IBext
283: hkn0622:2020400:2020400 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
283: hkn0622:2020400:2020400 [3] NCCL INFO Using network IBext
 68: hkn0422:4153004:4153004 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 68: hkn0422:4153004:4153004 [0] NCCL INFO P2P plugin IBext
332: hkn0636:1654151:1654151 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
332: hkn0636:1654151:1654151 [0] NCCL INFO P2P plugin IBext
 71: hkn0422:4153013:4153013 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 71: hkn0422:4153013:4153013 [3] NCCL INFO P2P plugin IBext
187: hkn0527:1348850:1348850 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
187: hkn0527:1348850:1348850 [3] NCCL INFO P2P plugin IBext
 88: hkn0427:1135037:1135037 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 88: hkn0427:1135037:1135037 [0] NCCL INFO Using network IBext
186: hkn0527:1348830:1348830 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
186: hkn0527:1348830:1348830 [2] NCCL INFO P2P plugin IBext
 70: hkn0422:4153005:4153005 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 70: hkn0422:4153005:4153005 [2] NCCL INFO P2P plugin IBext
436: hkn0731:1386645:1386645 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
439: hkn0731:1386625:1386625 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
185: hkn0527:1348822:1348822 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
185: hkn0527:1348822:1348822 [1] NCCL INFO Using network IBext
184: hkn0527:1348838:1348838 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
184: hkn0527:1348838:1348838 [0] NCCL INFO Using network IBext
187: hkn0527:1348850:1348850 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
187: hkn0527:1348850:1348850 [3] NCCL INFO Using network IBext
438: hkn0731:1386633:1386633 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
186: hkn0527:1348830:1348830 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
186: hkn0527:1348830:1348830 [2] NCCL INFO Using network IBext
437: hkn0731:1386617:1386617 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
383: hkn0715:401800:401800 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
332: hkn0636:1654151:1654151 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
332: hkn0636:1654151:1654151 [0] NCCL INFO Using network IBext
 71: hkn0422:4153013:4153013 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 71: hkn0422:4153013:4153013 [3] NCCL INFO Using network IBext
458: hkn0801:2239916:2239916 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
457: hkn0801:2239896:2239896 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
 70: hkn0422:4153005:4153005 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 70: hkn0422:4153005:4153005 [2] NCCL INFO Using network IBext
436: hkn0731:1386645:1386645 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
436: hkn0731:1386645:1386645 [0] NCCL INFO P2P plugin IBext
439: hkn0731:1386625:1386625 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
439: hkn0731:1386625:1386625 [3] NCCL INFO P2P plugin IBext
334: hkn0636:1654143:1654143 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
334: hkn0636:1654143:1654143 [2] NCCL INFO Using network IBext
 69: hkn0422:4153025:4153025 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 69: hkn0422:4153025:4153025 [1] NCCL INFO Using network IBext
438: hkn0731:1386633:1386633 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
438: hkn0731:1386633:1386633 [2] NCCL INFO P2P plugin IBext
 68: hkn0422:4153004:4153004 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 68: hkn0422:4153004:4153004 [0] NCCL INFO Using network IBext
437: hkn0731:1386617:1386617 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
437: hkn0731:1386617:1386617 [1] NCCL INFO P2P plugin IBext
383: hkn0715:401800:401800 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
383: hkn0715:401800:401800 [3] NCCL INFO P2P plugin IBext
458: hkn0801:2239916:2239916 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
458: hkn0801:2239916:2239916 [2] NCCL INFO P2P plugin IBext
457: hkn0801:2239896:2239896 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
457: hkn0801:2239896:2239896 [1] NCCL INFO P2P plugin IBext
456: hkn0801:2239904:2239904 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
380: hkn0715:401772:401772 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
438: hkn0731:1386633:1386633 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
438: hkn0731:1386633:1386633 [2] NCCL INFO Using network IBext
437: hkn0731:1386617:1386617 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
437: hkn0731:1386617:1386617 [1] NCCL INFO Using network IBext
459: hkn0801:2239888:2239888 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
335: hkn0636:1654171:1654171 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
382: hkn0715:401788:401788 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
381: hkn0715:401780:401780 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
333: hkn0636:1654159:1654159 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
456: hkn0801:2239904:2239904 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
456: hkn0801:2239904:2239904 [0] NCCL INFO P2P plugin IBext
480: hkn0807:1018966:1018966 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
255: hkn0611:709694:709694 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
439: hkn0731:1386625:1386625 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
439: hkn0731:1386625:1386625 [3] NCCL INFO Using network IBext
436: hkn0731:1386645:1386645 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
436: hkn0731:1386645:1386645 [0] NCCL INFO Using network IBext
483: hkn0807:1018978:1018978 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
459: hkn0801:2239888:2239888 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
459: hkn0801:2239888:2239888 [3] NCCL INFO P2P plugin IBext
380: hkn0715:401772:401772 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
380: hkn0715:401772:401772 [0] NCCL INFO P2P plugin IBext
382: hkn0715:401788:401788 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
382: hkn0715:401788:401788 [2] NCCL INFO P2P plugin IBext
335: hkn0636:1654171:1654171 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
335: hkn0636:1654171:1654171 [3] NCCL INFO P2P plugin IBext
383: hkn0715:401800:401800 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
383: hkn0715:401800:401800 [3] NCCL INFO Using network IBext
381: hkn0715:401780:401780 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
381: hkn0715:401780:401780 [1] NCCL INFO P2P plugin IBext
252: hkn0611:709722:709722 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
333: hkn0636:1654159:1654159 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
333: hkn0636:1654159:1654159 [1] NCCL INFO P2P plugin IBext
380: hkn0715:401772:401772 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
380: hkn0715:401772:401772 [0] NCCL INFO Using network IBext
130: hkn0509:3124308:3124308 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
254: hkn0611:709710:709710 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
456: hkn0801:2239904:2239904 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
458: hkn0801:2239916:2239916 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
458: hkn0801:2239916:2239916 [2] NCCL INFO Using network IBext
459: hkn0801:2239888:2239888 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
456: hkn0801:2239904:2239904 [0] NCCL INFO Using network IBext
457: hkn0801:2239896:2239896 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
459: hkn0801:2239888:2239888 [3] NCCL INFO Using network IBext
457: hkn0801:2239896:2239896 [1] NCCL INFO Using network IBext
480: hkn0807:1018966:1018966 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
480: hkn0807:1018966:1018966 [0] NCCL INFO P2P plugin IBext
255: hkn0611:709694:709694 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
255: hkn0611:709694:709694 [3] NCCL INFO P2P plugin IBext
483: hkn0807:1018978:1018978 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
483: hkn0807:1018978:1018978 [3] NCCL INFO P2P plugin IBext
482: hkn0807:1018950:1018950 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
382: hkn0715:401788:401788 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
151: hkn0514:2950630:2950630 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
382: hkn0715:401788:401788 [2] NCCL INFO Using network IBext
335: hkn0636:1654171:1654171 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
335: hkn0636:1654171:1654171 [3] NCCL INFO Using network IBext
128: hkn0509:3124288:3124288 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
381: hkn0715:401780:401780 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
381: hkn0715:401780:401780 [1] NCCL INFO Using network IBext
150: hkn0514:2950610:2950610 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
388: hkn0717:4187551:4187551 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
333: hkn0636:1654159:1654159 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
333: hkn0636:1654159:1654159 [1] NCCL INFO Using network IBext
481: hkn0807:1018958:1018958 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
131: hkn0509:3124296:3124296 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
252: hkn0611:709722:709722 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
252: hkn0611:709722:709722 [0] NCCL INFO P2P plugin IBext
148: hkn0514:2950603:2950603 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
130: hkn0509:3124308:3124308 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
130: hkn0509:3124308:3124308 [2] NCCL INFO P2P plugin IBext
391: hkn0717:4187523:4187523 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
254: hkn0611:709710:709710 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
254: hkn0611:709710:709710 [2] NCCL INFO P2P plugin IBext
390: hkn0717:4187539:4187539 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
482: hkn0807:1018950:1018950 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
482: hkn0807:1018950:1018950 [2] NCCL INFO P2P plugin IBext
151: hkn0514:2950630:2950630 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
151: hkn0514:2950630:2950630 [3] NCCL INFO P2P plugin IBext
128: hkn0509:3124288:3124288 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
128: hkn0509:3124288:3124288 [0] NCCL INFO P2P plugin IBext
405: hkn0721:2299079:2299079 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
388: hkn0717:4187551:4187551 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
388: hkn0717:4187551:4187551 [0] NCCL INFO P2P plugin IBext
150: hkn0514:2950610:2950610 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
150: hkn0514:2950610:2950610 [2] NCCL INFO P2P plugin IBext
253: hkn0611:709702:709702 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
149: hkn0514:2950618:2950618 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
389: hkn0717:4187531:4187531 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
129: hkn0509:3124280:3124280 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
481: hkn0807:1018958:1018958 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
481: hkn0807:1018958:1018958 [1] NCCL INFO P2P plugin IBext
131: hkn0509:3124296:3124296 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
131: hkn0509:3124296:3124296 [3] NCCL INFO P2P plugin IBext
254: hkn0611:709710:709710 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
254: hkn0611:709710:709710 [2] NCCL INFO Using network IBext
252: hkn0611:709722:709722 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
252: hkn0611:709722:709722 [0] NCCL INFO Using network IBext
148: hkn0514:2950603:2950603 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
148: hkn0514:2950603:2950603 [0] NCCL INFO P2P plugin IBext
391: hkn0717:4187523:4187523 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
391: hkn0717:4187523:4187523 [3] NCCL INFO P2P plugin IBext
390: hkn0717:4187539:4187539 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
390: hkn0717:4187539:4187539 [2] NCCL INFO P2P plugin IBext
255: hkn0611:709694:709694 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
255: hkn0611:709694:709694 [3] NCCL INFO Using network IBext
482: hkn0807:1018950:1018950 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
482: hkn0807:1018950:1018950 [2] NCCL INFO Using network IBext
483: hkn0807:1018978:1018978 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
483: hkn0807:1018978:1018978 [3] NCCL INFO Using network IBext
480: hkn0807:1018966:1018966 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
480: hkn0807:1018966:1018966 [0] NCCL INFO Using network IBext
481: hkn0807:1018958:1018958 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
481: hkn0807:1018958:1018958 [1] NCCL INFO Using network IBext
405: hkn0721:2299079:2299079 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
405: hkn0721:2299079:2299079 [1] NCCL INFO P2P plugin IBext
128: hkn0509:3124288:3124288 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
131: hkn0509:3124296:3124296 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
128: hkn0509:3124288:3124288 [0] NCCL INFO Using network IBext
131: hkn0509:3124296:3124296 [3] NCCL INFO Using network IBext
150: hkn0514:2950610:2950610 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
150: hkn0514:2950610:2950610 [2] NCCL INFO Using network IBext
148: hkn0514:2950603:2950603 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
148: hkn0514:2950603:2950603 [0] NCCL INFO Using network IBext
404: hkn0721:2299087:2299087 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
253: hkn0611:709702:709702 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
253: hkn0611:709702:709702 [1] NCCL INFO P2P plugin IBext
389: hkn0717:4187531:4187531 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
149: hkn0514:2950618:2950618 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
149: hkn0514:2950618:2950618 [1] NCCL INFO P2P plugin IBext
389: hkn0717:4187531:4187531 [1] NCCL INFO P2P plugin IBext
129: hkn0509:3124280:3124280 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
129: hkn0509:3124280:3124280 [1] NCCL INFO P2P plugin IBext
417: hkn0725:3111825:3111825 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
416: hkn0725:3111837:3111837 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
390: hkn0717:4187539:4187539 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
391: hkn0717:4187523:4187523 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
390: hkn0717:4187539:4187539 [2] NCCL INFO Using network IBext
391: hkn0717:4187523:4187523 [3] NCCL INFO Using network IBext
485: hkn0808:970565:970565 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
431: hkn0728:1323883:1323883 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
130: hkn0509:3124308:3124308 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
130: hkn0509:3124308:3124308 [2] NCCL INFO Using network IBext
419: hkn0725:3111817:3111817 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
407: hkn0721:2299099:2299099 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
418: hkn0725:3111809:3111809 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
389: hkn0717:4187531:4187531 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
389: hkn0717:4187531:4187531 [1] NCCL INFO Using network IBext
253: hkn0611:709702:709702 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
253: hkn0611:709702:709702 [1] NCCL INFO Using network IBext
149: hkn0514:2950618:2950618 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
149: hkn0514:2950618:2950618 [1] NCCL INFO Using network IBext
129: hkn0509:3124280:3124280 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
129: hkn0509:3124280:3124280 [1] NCCL INFO Using network IBext
151: hkn0514:2950630:2950630 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
151: hkn0514:2950630:2950630 [3] NCCL INFO Using network IBext
406: hkn0721:2299071:2299071 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
484: hkn0808:970557:970557 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
404: hkn0721:2299087:2299087 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
404: hkn0721:2299087:2299087 [0] NCCL INFO P2P plugin IBext
429: hkn0728:1323903:1323903 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
430: hkn0728:1323891:1323891 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
388: hkn0717:4187551:4187551 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
388: hkn0717:4187551:4187551 [0] NCCL INFO Using network IBext
486: hkn0808:970577:970577 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
431: hkn0728:1323883:1323883 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
431: hkn0728:1323883:1323883 [3] NCCL INFO P2P plugin IBext
485: hkn0808:970565:970565 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
417: hkn0725:3111825:3111825 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
417: hkn0725:3111825:3111825 [1] NCCL INFO P2P plugin IBext
485: hkn0808:970565:970565 [1] NCCL INFO P2P plugin IBext
 42: hkn0414:1981511:1981511 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
416: hkn0725:3111837:3111837 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
416: hkn0725:3111837:3111837 [0] NCCL INFO P2P plugin IBext
 40: hkn0414:1981497:1981497 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
487: hkn0808:970549:970549 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
407: hkn0721:2299099:2299099 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
407: hkn0721:2299099:2299099 [3] NCCL INFO P2P plugin IBext
 41: hkn0414:1981499:1981499 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
419: hkn0725:3111817:3111817 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
419: hkn0725:3111817:3111817 [3] NCCL INFO P2P plugin IBext
418: hkn0725:3111809:3111809 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
418: hkn0725:3111809:3111809 [2] NCCL INFO P2P plugin IBext
406: hkn0721:2299071:2299071 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
406: hkn0721:2299071:2299071 [2] NCCL INFO P2P plugin IBext
404: hkn0721:2299087:2299087 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
405: hkn0721:2299079:2299079 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
405: hkn0721:2299079:2299079 [1] NCCL INFO Using network IBext
404: hkn0721:2299087:2299087 [0] NCCL INFO Using network IBext
484: hkn0808:970557:970557 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
484: hkn0808:970557:970557 [0] NCCL INFO P2P plugin IBext
429: hkn0728:1323903:1323903 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
429: hkn0728:1323903:1323903 [1] NCCL INFO P2P plugin IBext
430: hkn0728:1323891:1323891 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
430: hkn0728:1323891:1323891 [2] NCCL INFO P2P plugin IBext
486: hkn0808:970577:970577 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
486: hkn0808:970577:970577 [2] NCCL INFO P2P plugin IBext
407: hkn0721:2299099:2299099 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
407: hkn0721:2299099:2299099 [3] NCCL INFO Using network IBext
 42: hkn0414:1981511:1981511 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 42: hkn0414:1981511:1981511 [2] NCCL INFO P2P plugin IBext
 40: hkn0414:1981497:1981497 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 40: hkn0414:1981497:1981497 [0] NCCL INFO P2P plugin IBext
487: hkn0808:970549:970549 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
487: hkn0808:970549:970549 [3] NCCL INFO P2P plugin IBext
428: hkn0728:1323875:1323875 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
406: hkn0721:2299071:2299071 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
406: hkn0721:2299071:2299071 [2] NCCL INFO Using network IBext
 43: hkn0414:1981498:1981498 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
 41: hkn0414:1981499:1981499 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 41: hkn0414:1981499:1981499 [1] NCCL INFO P2P plugin IBext
419: hkn0725:3111817:3111817 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
419: hkn0725:3111817:3111817 [3] NCCL INFO Using network IBext
418: hkn0725:3111809:3111809 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
418: hkn0725:3111809:3111809 [2] NCCL INFO Using network IBext
484: hkn0808:970557:970557 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
484: hkn0808:970557:970557 [0] NCCL INFO Using network IBext
486: hkn0808:970577:970577 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
486: hkn0808:970577:970577 [2] NCCL INFO Using network IBext
429: hkn0728:1323903:1323903 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
429: hkn0728:1323903:1323903 [1] NCCL INFO Using network IBext
430: hkn0728:1323891:1323891 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
430: hkn0728:1323891:1323891 [2] NCCL INFO Using network IBext
487: hkn0808:970549:970549 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
487: hkn0808:970549:970549 [3] NCCL INFO Using network IBext
485: hkn0808:970565:970565 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
485: hkn0808:970565:970565 [1] NCCL INFO Using network IBext
428: hkn0728:1323875:1323875 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
428: hkn0728:1323875:1323875 [0] NCCL INFO P2P plugin IBext
416: hkn0725:3111837:3111837 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
416: hkn0725:3111837:3111837 [0] NCCL INFO Using network IBext
417: hkn0725:3111825:3111825 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
417: hkn0725:3111825:3111825 [1] NCCL INFO Using network IBext
431: hkn0728:1323883:1323883 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
431: hkn0728:1323883:1323883 [3] NCCL INFO Using network IBext
 41: hkn0414:1981499:1981499 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 41: hkn0414:1981499:1981499 [1] NCCL INFO Using network IBext
 43: hkn0414:1981498:1981498 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 43: hkn0414:1981498:1981498 [3] NCCL INFO P2P plugin IBext
428: hkn0728:1323875:1323875 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
428: hkn0728:1323875:1323875 [0] NCCL INFO Using network IBext
 43: hkn0414:1981498:1981498 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 43: hkn0414:1981498:1981498 [3] NCCL INFO Using network IBext
 40: hkn0414:1981497:1981497 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 40: hkn0414:1981497:1981497 [0] NCCL INFO Using network IBext
 42: hkn0414:1981511:1981511 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 42: hkn0414:1981511:1981511 [2] NCCL INFO Using network IBext
192: hkn0529:1540728:1540728 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
194: hkn0529:1540708:1540708 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
193: hkn0529:1540700:1540700 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
195: hkn0529:1540716:1540716 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
194: hkn0529:1540708:1540708 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
194: hkn0529:1540708:1540708 [2] NCCL INFO P2P plugin IBext
192: hkn0529:1540728:1540728 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
192: hkn0529:1540728:1540728 [0] NCCL INFO P2P plugin IBext
193: hkn0529:1540700:1540700 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
193: hkn0529:1540700:1540700 [1] NCCL INFO P2P plugin IBext
195: hkn0529:1540716:1540716 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
195: hkn0529:1540716:1540716 [3] NCCL INFO P2P plugin IBext
193: hkn0529:1540700:1540700 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
193: hkn0529:1540700:1540700 [1] NCCL INFO Using network IBext
195: hkn0529:1540716:1540716 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
195: hkn0529:1540716:1540716 [3] NCCL INFO Using network IBext
194: hkn0529:1540708:1540708 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
194: hkn0529:1540708:1540708 [2] NCCL INFO Using network IBext
192: hkn0529:1540728:1540728 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
192: hkn0529:1540728:1540728 [0] NCCL INFO Using network IBext
291: hkn0624:1772830:1772945 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
265: hkn0615:414225:414318 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
223: hkn0602:3362287:3362549 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 77: hkn0424:2947854:2947962 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
289: hkn0624:1772850:1772951 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
157: hkn0516:2915847:2915969 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
264: hkn0615:414213:414324 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
220: hkn0602:3362279:3362548 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
192: hkn0529:1540728:1540857 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
222: hkn0602:3362295:3362554 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 79: hkn0424:2947870:2947971 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
288: hkn0624:1772822:1772950 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
147: hkn0513:3012860:3012956 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
400: hkn0720:5369:5640 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
266: hkn0615:414205:414319 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
370: hkn0712:294940:295065 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
290: hkn0624:1772838:1772944 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
261: hkn0613:902589:902698 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
267: hkn0615:414197:414325 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
206: hkn0532:924599:924925 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
221: hkn0602:3362307:3362555 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
193: hkn0529:1540700:1540850 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
163: hkn0520:2712757:2712880 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
240: hkn0607:904254:904366 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
460: hkn0802:1200224:1200344 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
174: hkn0524:1133687:1133798 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
158: hkn0516:2915855:2915974 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
248: hkn0609:710728:710827 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
341: hkn0704:791903:792016 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
483: hkn0807:1018978:1019080 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 76: hkn0424:2947881:2947969 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 78: hkn0424:2947862:2947966 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
274: hkn0617:2294558:2294701 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
430: hkn0728:1323891:1323997 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
195: hkn0529:1540716:1540851 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 12: hkn0407:1816178:1816273 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
230: hkn0604:689117:689240 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
194: hkn0529:1540708:1540856 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
250: hkn0609:710708:710822 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
463: hkn0802:1200216:1200348 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
162: hkn0520:2712749:2712876 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
156: hkn0516:2915863:2915972 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
144: hkn0513:3012844:3012958 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
253: hkn0611:709702:709825 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 96: hkn0501:1327777:1327903 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
316: hkn0632:1758503:1758621 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
247: hkn0608:485624:485730 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
190: hkn0528:1301582:1301674 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
320: hkn0633:1526202:1526350 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
159: hkn0516:2915875:2915970 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
401: hkn0720:5385:5649 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
260: hkn0613:902581:902700 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
198: hkn0530:1258034:1258159 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
369: hkn0712:294968:295070 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
207: hkn0532:924627:924923 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
175: hkn0524:1133671:1133797 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 24: hkn0410:1159594:1159711 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
340: hkn0704:791895:792019 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
251: hkn0609:710700:710823 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
231: hkn0604:689125:689244 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
160: hkn0520:2712777:2712878 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
276: hkn0621:1991476:1991587 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
177: hkn0525:986697:986833 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
146: hkn0513:3012852:3012957 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
237: hkn0606:2371969:2372080 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
249: hkn0609:710716:710825 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
462: hkn0802:1200232:1200339 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
321: hkn0633:1526230:1526356 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
242: hkn0607:904266:904368 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
203: hkn0531:1230541:1230644 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
167: hkn0521:1197691:1197791 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
315: hkn0631:1021715:1021825 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
389: hkn0717:4187531:4187655 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 88: hkn0427:1135037:1135137 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
145: hkn0513:3012872:3012961 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
241: hkn0607:904238:904362 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
342: hkn0704:791887:792017 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
461: hkn0802:1200244:1200347 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
272: hkn0617:2294566:2294704 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
227: hkn0603:1413135:1413236 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 94: hkn0428:667247:667347 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
329: hkn0635:1225473:1225593 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
482: hkn0807:1018950:1019079 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
161: hkn0520:2712765:2712877 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
233: hkn0605:712002:712113 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
214: hkn0535:2398869:2398986 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 84: hkn0426:813962:814073 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
204: hkn0532:924615:924928 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
263: hkn0613:902601:902691 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
108: hkn0504:40743:40838 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
297: hkn0627:1787808:1787920 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
295: hkn0626:1298345:1298453 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
343: hkn0704:791915:792018 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
228: hkn0604:689133:689241 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
318: hkn0632:1758495:1758618 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
322: hkn0633:1526218:1526355 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
121: hkn0507:3186962:3187062 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
115: hkn0505:2303672:2303774 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
173: hkn0524:1133699:1133792 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
205: hkn0532:924607:924924 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
243: hkn0607:904246:904360 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
368: hkn0712:294956:295068 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
323: hkn0633:1526210:1526349 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
229: hkn0604:689145:689242 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
403: hkn0720:5377:5646 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
255: hkn0611:709694:709822 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
273: hkn0617:2294577:2294697 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 15: hkn0407:1816151:1816277 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
172: hkn0524:1133679:1133791 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
188: hkn0528:1301555:1301679 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
328: hkn0635:1225461:1225602 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
429: hkn0728:1323903:1323996 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
371: hkn0712:294948:295061 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
319: hkn0632:1758511:1758619 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
262: hkn0613:902573:902699 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
402: hkn0720:5397:5643 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
275: hkn0617:2294550:2294702 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
481: hkn0807:1018958:1019082 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
292: hkn0626:1298337:1298454 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
245: hkn0608:485636:485738 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 97: hkn0501:1327797:1327897 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
317: hkn0632:1758522:1758616 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
219: hkn0601:117592:117705 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
189: hkn0528:1301571:1301681 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
259: hkn0612:916868:916976 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
197: hkn0530:1258062:1258153 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 95: hkn0428:667235:667348 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
277: hkn0621:1991460:1991584 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 25: hkn0410:1159614:1159709 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
234: hkn0605:711998:712112 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
310: hkn0630:1598359:1598459 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
252: hkn0611:709722:709820 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 73: hkn0423:1704793:1704926 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
254: hkn0611:709710:709819 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 89: hkn0427:1135025:1135132 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 20: hkn0409:2585552:2585695 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
284: hkn0623:1872656:1872763 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
124: hkn0508:3139017:3139132 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
331: hkn0635:1225445:1225601 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
299: hkn0627:1787816:1787921 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
293: hkn0626:1298357:1298456 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
306: hkn0629:1591947:1592059 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
336: hkn0703:740936:741046 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  1: hkn0403:1763954:1764350 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
480: hkn0807:1018966:1019081 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
246: hkn0608:485616:485737 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
105: hkn0503:2899564:2899692 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
191: hkn0528:1301563:1301675 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 58: hkn0419:1544203:1544299 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  5: hkn0404:1339266:1339391 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
176: hkn0525:986689:986834 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 98: hkn0501:1327785:1327898 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
165: hkn0521:1197671:1197795 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
294: hkn0626:1298329:1298455 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
239: hkn0606:2371961:2372083 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 93: hkn0428:667227:667353 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 14: hkn0407:1816159:1816274 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 67: hkn0421:2180600:2180859 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
278: hkn0621:1991488:1991585 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
199: hkn0530:1258050:1258161 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
431: hkn0728:1323883:1324000 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
224: hkn0603:1413107:1413231 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
110: hkn0504:40723:40837 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
244: hkn0608:485608:485739 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
300: hkn0628:671767:671903 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
390: hkn0717:4187539:4187652 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 87: hkn0426:813974:814075 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 90: hkn0427:1135009:1135135 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
171: hkn0523:1547977:1548089 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
286: hkn0623:1872648:1872765 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
330: hkn0635:1225453:1225598 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
200: hkn0531:1230521:1230636 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 26: hkn0410:1159602:1159714 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 91: hkn0427:1135017:1135131 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
308: hkn0630:1598339:1598456 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
142: hkn0512:3044033:3044156 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
235: hkn0605:712014:712118 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 92: hkn0428:667219:667351 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
313: hkn0631:1021707:1021834 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
428: hkn0728:1323875:1324003 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 13: hkn0407:1816167:1816272 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 99: hkn0501:1327769:1327904 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
196: hkn0530:1258042:1258156 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
213: hkn0535:2398861:2398990 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
298: hkn0627:1787836:1787925 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
232: hkn0605:711997:712115 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
258: hkn0612:916880:916979 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 27: hkn0410:1159586:1159707 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
385: hkn0716:108390:108502 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
399: hkn0719:1305603:1305721 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
150: hkn0514:2950610:2950728 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
181: hkn0526:1428306:1428417 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
238: hkn0606:2371989:2372088 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
128: hkn0509:3124288:3124402 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
109: hkn0504:40731:40842 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
383: hkn0715:401800:401893 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
296: hkn0627:1787824:1787924 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
164: hkn0521:1197679:1197790 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
279: hkn0621:1991468:1991586 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
388: hkn0717:4187551:4187658 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
179: hkn0525:986681:986840 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
111: hkn0504:40715:40839 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
285: hkn0623:1872640:1872768 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
112: hkn0505:2303664:2303782 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 68: hkn0422:4153004:4153125 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
168: hkn0523:1547961:1548090 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
225: hkn0603:1413115:1413233 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
218: hkn0601:117591:117714 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
312: hkn0631:1021735:1021830 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
391: hkn0717:4187523:4187653 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
287: hkn0623:1872668:1872764 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
324: hkn0634:1520769:1520870 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
166: hkn0521:1197663:1197794 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  0: hkn0403:1763942:1764342 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 86: hkn0426:813946:814074 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
202: hkn0531:1230513:1230642 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
257: hkn0612:916860:916982 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
169: hkn0523:1547989:1548085 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
178: hkn0525:986708:986837 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
137: hkn0511:3066282:3066391 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
236: hkn0606:2371977:2372089 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 61: hkn0420:3210101:3210213 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
226: hkn0603:1413123:1413232 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
309: hkn0630:1598347:1598454 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 22: hkn0409:2585544:2585697 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
405: hkn0721:2299079:2299192 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
353: hkn0707:4019808:4019912 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
114: hkn0505:2303656:2303781 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
314: hkn0631:1021723:1021832 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
311: hkn0630:1598331:1598462 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
212: hkn0535:2398877:2398992 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
182: hkn0526:1428290:1428419 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
149: hkn0514:2950618:2950734 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
256: hkn0612:916852:916975 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 85: hkn0426:813954:814076 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
201: hkn0531:1230529:1230638 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 35: hkn0412:2262278:2262387 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
347: hkn0705:783109:783209 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
211: hkn0534:1148272:1148423 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
387: hkn0716:108382:108508 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
180: hkn0526:1428298:1428416 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 65: hkn0421:2180584:2180857 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
113: hkn0505:2303684:2303783 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  4: hkn0404:1339282:1339394 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
215: hkn0535:2398889:2398985 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
125: hkn0508:3139009:3139136 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
106: hkn0503:2899580:2899695 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 72: hkn0423:1704801:1704925 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 18: hkn0408:2890646:2890768 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
148: hkn0514:2950603:2950729 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
107: hkn0503:2899572:2899698 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
304: hkn0629:1591939:1592054 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
446: hkn0733:1389290:1389387 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
170: hkn0523:1547969:1548086 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
154: hkn0515:2896695:2896792 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 69: hkn0422:4153025:4153124 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
100: hkn0502:228966:229066 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
337: hkn0703:740940:741049 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
183: hkn0526:1428318:1428415 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 59: hkn0419:1544187:1544303 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
397: hkn0719:1305595:1305722 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
282: hkn0622:2020384:2020510 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
303: hkn0628:671779:671905 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
187: hkn0527:1348850:1348948 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
217: hkn0601:117600:117712 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
151: hkn0514:2950630:2950735 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 75: hkn0423:1704809:1704921 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
130: hkn0509:3124308:3124406 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
437: hkn0731:1386617:1386741 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  3: hkn0403:1763926:1764349 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
338: hkn0703:740952:741043 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 64: hkn0421:2180612:2180860 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  2: hkn0403:1763934:1764351 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  6: hkn0404:1339274:1339395 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
384: hkn0716:108410:108503 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
485: hkn0808:970565:970682 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 23: hkn0409:2585564:2585689 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
143: hkn0512:3044032:3044153 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
210: hkn0534:1148280:1148416 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
126: hkn0508:3139025:3139135 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 46: hkn0415:2496333:2496437 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
425: hkn0727:1345672:1345787 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
366: hkn0711:583820:583927 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
349: hkn0706:752136:752262 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
344: hkn0705:783129:783218 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 39: hkn0413:2366596:2366702 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
325: hkn0634:1520753:1520864 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
339: hkn0703:740935:741041 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
386: hkn0716:108398:108509 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
432: hkn0730:1401606:1401733 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 56: hkn0419:1544195:1544301 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
127: hkn0508:3139037:3139138 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
305: hkn0629:1591959:1592057 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
332: hkn0636:1654151:1654265 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  7: hkn0404:1339294:1339386 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 71: hkn0422:4153013:4153117 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
396: hkn0719:1305611:1305724 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
365: hkn0711:583808:583920 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 21: hkn0409:2585543:2585692 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
209: hkn0534:1148292:1148420 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
327: hkn0634:1520781:1520863 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
216: hkn0601:117612:117713 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 52: hkn0418:1869053:1869172 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
404: hkn0721:2299087:2299193 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
495: hkn0810:939425:939541 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
185: hkn0527:1348822:1348946 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
326: hkn0634:1520761:1520867 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 57: hkn0419:1544215:1544300 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
381: hkn0715:401780:401901 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 74: hkn0423:1704821:1704920 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
467: hkn0803:876457:876566 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
350: hkn0706:752144:752268 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
449: hkn0734:1156453:1156552 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 66: hkn0421:2180592:2180858 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
208: hkn0534:1148264:1148419 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
103: hkn0502:228946:229060 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
420: hkn0726:1548019:1548119 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
131: hkn0509:3124296:3124401 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 63: hkn0420:3210091:3210218 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
398: hkn0719:1305623:1305723 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
392: hkn0718:3916913:3917022 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 34: hkn0412:2262277:2262396 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 70: hkn0422:4153005:4153119 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
372: hkn0713:470112:470238 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
186: hkn0527:1348830:1348950 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
301: hkn0628:671751:671908 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
104: hkn0503:2899591:2899697 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
475: hkn0805:1112010:1112126 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
141: hkn0512:3044053:3044152 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
380: hkn0715:401772:401896 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
407: hkn0721:2299099:2299196 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
270: hkn0616:404806:404907 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
364: hkn0711:583800:583921 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
307: hkn0629:1591931:1592055 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 38: hkn0413:2366608:2366707 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
367: hkn0711:583792:583925 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
184: hkn0527:1348838:1348947 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
348: hkn0706:752164:752267 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
382: hkn0715:401788:401899 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
129: hkn0509:3124280:3124408 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
345: hkn0705:783117:783216 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
406: hkn0721:2299071:2299198 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
351: hkn0706:752152:752261 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
445: hkn0733:1389278:1389388 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
138: hkn0511:3066294:3066390 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
302: hkn0628:671759:671904 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
439: hkn0731:1386625:1386746 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
139: hkn0511:3066266:3066383 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
438: hkn0731:1386633:1386740 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
101: hkn0502:228954:229059 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 16: hkn0408:2890655:2890770 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
436: hkn0731:1386645:1386747 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
152: hkn0515:2896675:2896797 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 62: hkn0420:3210093:3210219 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
510: hkn0816:375512:375637 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
360: hkn0710:355429:355558 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
346: hkn0705:783101:783217 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 32: hkn0412:2262276:2262390 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
424: hkn0727:1345692:1345788 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
334: hkn0636:1654143:1654268 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
427: hkn0727:1345680:1345791 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
136: hkn0511:3066274:3066392 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
434: hkn0730:1401634:1401726 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
492: hkn0810:939409:939536 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
355: hkn0707:4019792:4019918 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
484: hkn0808:970557:970676 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
140: hkn0512:3044041:3044149 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
120: hkn0507:3186982:3187071 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 60: hkn0420:3210113:3210211 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
280: hkn0622:2020412:2020505 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
354: hkn0707:4019820:4019919 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 80: hkn0425:2083907:2084029 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 33: hkn0412:2262290:2262395 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
358: hkn0708:413122:413219 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
123: hkn0507:3186970:3187067 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
426: hkn0727:1345664:1345786 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
395: hkn0718:3916925:3917028 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 45: hkn0415:2496313:2496432 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
102: hkn0502:228938:229065 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
375: hkn0713:470140:470235 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 55: hkn0418:1869061:1869166 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 19: hkn0408:2890647:2890769 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
335: hkn0636:1654171:1654272 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
393: hkn0718:3916897:3917023 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 36: hkn0413:2366580:2366708 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 42: hkn0414:1981511:1981611 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
352: hkn0707:4019800:4019913 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
508: hkn0816:375484:375639 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
441: hkn0732:1211535:1211667 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
122: hkn0507:3186958:3187070 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
416: hkn0725:3111837:3111934 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
493: hkn0810:939417:939538 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 37: hkn0413:2366588:2366711 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
153: hkn0515:2896667:2896795 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
490: hkn0809:937230:937376 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
363: hkn0710:355437:355557 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
283: hkn0622:2020400:2020511 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 17: hkn0408:2890667:2890771 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
433: hkn0730:1401614:1401727 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
465: hkn0803:876477:876562 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
394: hkn0718:3916905:3917029 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
333: hkn0636:1654159:1654274 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 81: hkn0425:2083915:2084030 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
435: hkn0730:1401622:1401732 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 47: hkn0415:2496310:2496438 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
494: hkn0810:939437:939537 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
374: hkn0713:470128:470236 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
271: hkn0616:404778:404908 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
356: hkn0708:413102:413217 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
472: hkn0805:1111994:1112121 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
155: hkn0515:2896683:2896800 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
373: hkn0713:470120:470234 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
509: hkn0816:375500:375645 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 48: hkn0417:2267551:2267653 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 53: hkn0418:1869083:1869169 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
487: hkn0808:970549:970680 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
422: hkn0726:1548007:1548114 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
444: hkn0733:1389270:1389389 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
451: hkn0734:1156425:1156546 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
269: hkn0616:404794:404911 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
362: hkn0710:355457:355550 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
447: hkn0733:1389269:1389383 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
361: hkn0710:355445:355552 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 83: hkn0425:2083899:2084034 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
464: hkn0803:876465:876561 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
268: hkn0616:404786:404909 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
486: hkn0808:970577:970677 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 82: hkn0425:2083927:2084031 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
359: hkn0708:413094:413225 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
511: hkn0816:375492:375642 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
466: hkn0803:876456:876564 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 44: hkn0415:2496321:2496433 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
417: hkn0725:3111825:3111935 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
281: hkn0622:2020392:2020504 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
413: hkn0724:1715874:1715982 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
357: hkn0708:413110:413222 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
421: hkn0726:1547991:1548116 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
448: hkn0734:1156433:1156551 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 54: hkn0418:1869045:1869174 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 41: hkn0414:1981499:1981602 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
491: hkn0809:937251:937374 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
423: hkn0726:1547999:1548115 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
500: hkn0814:675728:675835 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 43: hkn0414:1981498:1981609 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
418: hkn0725:3111809:3111929 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
479: hkn0806:1054222:1054347 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
440: hkn0732:1211563:1211665 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
474: hkn0805:1112002:1112122 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 40: hkn0414:1981497:1981610 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
450: hkn0734:1156441:1156545 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 51: hkn0417:2267539:2267651 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
473: hkn0805:1112022:1112123 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 49: hkn0417:2267523:2267656 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
476: hkn0806:1054250:1054352 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
496: hkn0812:693695:693790 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 50: hkn0417:2267531:2267655 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
118: hkn0506:837941:838072 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
453: hkn0736:1508232:1508369 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
442: hkn0732:1211543:1211663 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
419: hkn0725:3111817:3111928 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
478: hkn0806:1054238:1054345 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
477: hkn0806:1054230:1054353 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
488: hkn0809:937239:937379 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
489: hkn0809:937231:937375 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
497: hkn0812:693675:693791 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
443: hkn0732:1211551:1211659 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
117: hkn0506:837969:838070 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
452: hkn0736:1508216:1508371 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
414: hkn0724:1715886:1715987 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
454: hkn0736:1508244:1508370 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
501: hkn0814:675740:675838 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
455: hkn0736:1508224:1508372 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 11: hkn0405:3206742:3206897 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
499: hkn0812:693683:693792 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
498: hkn0812:693667:693793 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
116: hkn0506:837949:838063 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
119: hkn0506:837957:838067 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
459: hkn0801:2239888:2240016 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
502: hkn0814:675720:675841 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
135: hkn0510:2761936:2762043 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
503: hkn0814:675719:675836 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
412: hkn0724:1715866:1715984 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
468: hkn0804:1205515:1205623 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
415: hkn0724:1715858:1715983 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 10: hkn0405:3206770:3206895 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
504: hkn0815:395016:395129 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  8: hkn0405:3206750:3206902 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  9: hkn0405:3206758:3206903 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
377: hkn0714:431907:432038 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
458: hkn0801:2239916:2240014 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
134: hkn0510:2761956:2762044 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
133: hkn0510:2761928:2762038 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
470: hkn0804:1205535:1205629 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
457: hkn0801:2239896:2240017 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
376: hkn0714:431923:432030 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
505: hkn0815:395028:395124 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
456: hkn0801:2239904:2240015 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
379: hkn0714:431935:432037 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
378: hkn0714:431915:432039 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
506: hkn0815:395000:395128 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
132: hkn0510:2761944:2762047 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
408: hkn0723:207901:208066 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
471: hkn0804:1205505:1205631 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
507: hkn0815:395008:395125 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
469: hkn0804:1205507:1205626 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
409: hkn0723:207893:208068 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
410: hkn0723:207909:208065 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 28: hkn0411:2315775:2315872 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
411: hkn0723:207921:208060 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 31: hkn0411:2315753:2315871 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 29: hkn0411:2315755:2315870 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 30: hkn0411:2315763:2315863 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 23: hkn0409:2585564:2585689 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22
 22: hkn0409:2585544:2585697 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21
 29: hkn0411:2315755:2315870 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/44/-1->29->28
 23: hkn0409:2585564:2585689 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 22: hkn0409:2585544:2585697 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 24: hkn0410:1159594:1159711 [0] NCCL INFO Trees [0] 25/28/-1->24->16 [1] 25/-1/-1->24->21
 21: hkn0409:2585543:2585692 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/24/-1->21->20
 21: hkn0409:2585543:2585692 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 29: hkn0411:2315755:2315870 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 25: hkn0410:1159614:1159709 [1] NCCL INFO Trees [0] 26/20/-1->25->24 [1] 26/-1/-1->25->24
 26: hkn0410:1159602:1159714 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25
 35: hkn0412:2262278:2262387 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34
 28: hkn0411:2315775:2315872 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/12/-1->28->60
 28: hkn0411:2315775:2315872 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 27: hkn0410:1159586:1159707 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26
 35: hkn0412:2262278:2262387 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 24: hkn0410:1159594:1159711 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 44: hkn0415:2496321:2496433 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/36/-1->44->29
 36: hkn0413:2366580:2366708 [0] NCCL INFO Trees [0] 37/-1/-1->36->41 [1] 37/32/-1->36->44
 36: hkn0413:2366580:2366708 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 63: hkn0420:3210091:3210218 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62
 25: hkn0410:1159614:1159709 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 37: hkn0413:2366588:2366711 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/40/-1->37->36
 37: hkn0413:2366588:2366711 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 58: hkn0419:1544203:1544299 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57
 26: hkn0410:1159602:1159714 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 48: hkn0417:2267551:2267653 [0] NCCL INFO Trees [0] 49/56/-1->48->32 [1] 49/-1/-1->48->52
 32: hkn0412:2262276:2262390 [0] NCCL INFO Trees [0] 33/48/-1->32->65 [1] 33/-1/-1->32->36
 32: hkn0412:2262276:2262390 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 42: hkn0414:1981511:1981611 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41
 54: hkn0418:1869045:1869174 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53
 58: hkn0419:1544203:1544299 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 63: hkn0420:3210091:3210218 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 27: hkn0410:1159586:1159707 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 33: hkn0412:2262290:2262395 [1] NCCL INFO Trees [0] 34/16/-1->33->32 [1] 34/-1/-1->33->32
 33: hkn0412:2262290:2262395 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 46: hkn0415:2496333:2496437 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45
 38: hkn0413:2366608:2366707 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37
 31: hkn0411:2315753:2315871 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30
 31: hkn0411:2315753:2315871 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 40: hkn0414:1981497:1981610 [0] NCCL INFO Trees [0] 41/44/-1->40->49 [1] 41/-1/-1->40->37
 66: hkn0421:2180592:2180858 [2] NCCL INFO Trees [0] 67/-1/-1->66->65 [1] 67/-1/-1->66->65
 61: hkn0420:3210101:3210213 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/92/-1->61->60
 50: hkn0417:2267531:2267655 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49
 34: hkn0412:2262277:2262396 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33
 34: hkn0412:2262277:2262396 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 44: hkn0415:2496321:2496433 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 69: hkn0422:4153025:4153124 [1] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 70/72/-1->69->68
 38: hkn0413:2366608:2366707 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 30: hkn0411:2315763:2315863 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29
 30: hkn0411:2315763:2315863 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 41: hkn0414:1981499:1981602 [1] NCCL INFO Trees [0] 42/36/-1->41->40 [1] 42/-1/-1->41->40
 66: hkn0421:2180592:2180858 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 54: hkn0418:1869045:1869174 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 59: hkn0419:1544187:1544303 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58
 61: hkn0420:3210101:3210213 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 46: hkn0415:2496333:2496437 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 69: hkn0422:4153025:4153124 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 39: hkn0413:2366596:2366702 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38
 42: hkn0414:1981511:1981611 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 64: hkn0421:2180612:2180860 [0] NCCL INFO Trees [0] 65/96/-1->64->129 [1] 65/-1/-1->64->68
 64: hkn0421:2180612:2180860 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 57: hkn0419:1544215:1544300 [1] NCCL INFO Trees [0] 58/52/-1->57->56 [1] 58/-1/-1->57->56
 57: hkn0419:1544215:1544300 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 62: hkn0420:3210093:3210219 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61
 48: hkn0417:2267551:2267653 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 45: hkn0415:2496313:2496432 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/52/-1->45->44
 45: hkn0415:2496313:2496432 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 70: hkn0422:4153005:4153119 [2] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 71/-1/-1->70->69
 39: hkn0413:2366596:2366702 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 43: hkn0414:1981498:1981609 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42
 65: hkn0421:2180584:2180857 [1] NCCL INFO Trees [0] 66/32/-1->65->64 [1] 66/-1/-1->65->64
 59: hkn0419:1544187:1544303 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 62: hkn0420:3210093:3210219 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 49: hkn0417:2267523:2267656 [1] NCCL INFO Trees [0] 50/40/-1->49->48 [1] 50/-1/-1->49->48
 47: hkn0415:2496310:2496438 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46
 70: hkn0422:4153005:4153119 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 40: hkn0414:1981497:1981610 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 67: hkn0421:2180600:2180859 [3] NCCL INFO Trees [0] -1/-1/-1->67->66 [1] -1/-1/-1->67->66
 53: hkn0418:1869083:1869169 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/56/-1->53->52
 53: hkn0418:1869083:1869169 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 56: hkn0419:1544195:1544301 [0] NCCL INFO Trees [0] 57/60/-1->56->48 [1] 57/-1/-1->56->53
 56: hkn0419:1544195:1544301 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 60: hkn0420:3210113:3210211 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/28/-1->60->124
 50: hkn0417:2267531:2267655 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 47: hkn0415:2496310:2496438 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 68: hkn0422:4153004:4153125 [0] NCCL INFO Trees [0] 69/-1/-1->68->73 [1] 69/64/-1->68->76
 41: hkn0414:1981499:1981602 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 65: hkn0421:2180584:2180857 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 55: hkn0418:1869061:1869166 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54
 60: hkn0420:3210113:3210211 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 49: hkn0417:2267523:2267656 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 68: hkn0422:4153004:4153125 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 43: hkn0414:1981498:1981609 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 67: hkn0421:2180600:2180859 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 52: hkn0418:1869053:1869172 [0] NCCL INFO Trees [0] 53/-1/-1->52->57 [1] 53/48/-1->52->45
 52: hkn0418:1869053:1869172 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 73: hkn0423:1704793:1704926 [1] NCCL INFO Trees [0] 74/68/-1->73->72 [1] 74/-1/-1->73->72
 51: hkn0417:2267539:2267651 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50
 71: hkn0422:4153013:4153117 [3] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] -1/-1/-1->71->70
 71: hkn0422:4153013:4153117 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 55: hkn0418:1869061:1869166 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 74: hkn0423:1704821:1704920 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] 75/-1/-1->74->73
 51: hkn0417:2267539:2267651 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 73: hkn0423:1704793:1704926 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 74: hkn0423:1704821:1704920 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 72: hkn0423:1704801:1704925 [0] NCCL INFO Trees [0] 73/76/-1->72->81 [1] 73/-1/-1->72->69
 72: hkn0423:1704801:1704925 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 20: hkn0409:2585552:2585695 [0] NCCL INFO Trees [0] 21/-1/-1->20->25 [1] 21/16/-1->20->13
 75: hkn0423:1704809:1704921 [3] NCCL INFO Trees [0] -1/-1/-1->75->74 [1] -1/-1/-1->75->74
 20: hkn0409:2585552:2585695 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 75: hkn0423:1704809:1704921 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 76: hkn0424:2947881:2947969 [0] NCCL INFO Trees [0] 77/-1/-1->76->72 [1] 77/68/-1->76->92
 76: hkn0424:2947881:2947969 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 77: hkn0424:2947854:2947962 [1] NCCL INFO Trees [0] 78/-1/-1->77->76 [1] 78/84/-1->77->76
 77: hkn0424:2947854:2947962 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 80: hkn0425:2083907:2084029 [0] NCCL INFO Trees [0] 81/88/-1->80->97 [1] 81/-1/-1->80->84
 79: hkn0424:2947870:2947971 [3] NCCL INFO Trees [0] -1/-1/-1->79->78 [1] -1/-1/-1->79->78
 80: hkn0425:2083907:2084029 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 79: hkn0424:2947870:2947971 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 83: hkn0425:2083899:2084034 [3] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] -1/-1/-1->83->82
 18: hkn0408:2890646:2890768 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17
 78: hkn0424:2947862:2947966 [2] NCCL INFO Trees [0] 79/-1/-1->78->77 [1] 79/-1/-1->78->77
 78: hkn0424:2947862:2947966 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 83: hkn0425:2083899:2084034 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 81: hkn0425:2083915:2084030 [1] NCCL INFO Trees [0] 82/72/-1->81->80 [1] 82/-1/-1->81->80
 82: hkn0425:2083927:2084031 [2] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 83/-1/-1->82->81
 82: hkn0425:2083927:2084031 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 84: hkn0426:813962:814073 [0] NCCL INFO Trees [0] 85/-1/-1->84->89 [1] 85/80/-1->84->77
 81: hkn0425:2083915:2084030 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 18: hkn0408:2890646:2890768 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 84: hkn0426:813962:814073 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 19: hkn0408:2890647:2890769 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18
 86: hkn0426:813946:814074 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] 87/-1/-1->86->85
 19: hkn0408:2890647:2890769 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 87: hkn0426:813974:814075 [3] NCCL INFO Trees [0] -1/-1/-1->87->86 [1] -1/-1/-1->87->86
 88: hkn0427:1135037:1135137 [0] NCCL INFO Trees [0] 89/92/-1->88->80 [1] 89/-1/-1->88->85
 88: hkn0427:1135037:1135137 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 17: hkn0408:2890667:2890771 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] 18/-1/-1->17->16
 86: hkn0426:813946:814074 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 17: hkn0408:2890667:2890771 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 87: hkn0426:813974:814075 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 92: hkn0428:667219:667351 [0] NCCL INFO Trees [0] 93/-1/-1->92->88 [1] 93/76/-1->92->61
 85: hkn0426:813954:814076 [1] NCCL INFO Trees [0] 86/-1/-1->85->84 [1] 86/88/-1->85->84
 85: hkn0426:813954:814076 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 89: hkn0427:1135025:1135132 [1] NCCL INFO Trees [0] 90/84/-1->89->88 [1] 90/-1/-1->89->88
 89: hkn0427:1135025:1135132 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 92: hkn0428:667219:667351 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 90: hkn0427:1135009:1135135 [2] NCCL INFO Trees [0] 91/-1/-1->90->89 [1] 91/-1/-1->90->89
 90: hkn0427:1135009:1135135 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 91: hkn0427:1135017:1135131 [3] NCCL INFO Trees [0] -1/-1/-1->91->90 [1] -1/-1/-1->91->90
 91: hkn0427:1135017:1135131 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 15: hkn0407:1816151:1816277 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
 15: hkn0407:1816151:1816277 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 10: hkn0405:3206770:3206895 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
 11: hkn0405:3206742:3206897 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10
 11: hkn0405:3206742:3206897 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 14: hkn0407:1816159:1816274 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
 14: hkn0407:1816159:1816274 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 10: hkn0405:3206770:3206895 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 12: hkn0407:1816178:1816273 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/4/-1->12->28
 12: hkn0407:1816178:1816273 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  9: hkn0405:3206758:3206903 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/-1/-1->9->8
 13: hkn0407:1816167:1816272 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/20/-1->13->12
 13: hkn0407:1816167:1816272 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  9: hkn0405:3206758:3206903 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  8: hkn0405:3206750:3206902 [0] NCCL INFO Trees [0] 9/12/-1->8->17 [1] 9/-1/-1->8->5
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 00/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
  2: hkn0403:1763934:1764351 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
  8: hkn0405:3206750:3206902 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  2: hkn0403:1763934:1764351 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  3: hkn0403:1763926:1764349 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
  5: hkn0404:1339266:1339391 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/8/-1->5->4
 94: hkn0428:667247:667347 [2] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 95/-1/-1->94->93
  3: hkn0403:1763926:1764349 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 16: hkn0408:2890655:2890770 [0] NCCL INFO Trees [0] 17/24/-1->16->33 [1] 17/-1/-1->16->20
 16: hkn0408:2890655:2890770 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  5: hkn0404:1339266:1339391 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 94: hkn0428:667247:667347 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 01/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
  6: hkn0404:1339274:1339395 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
  6: hkn0404:1339274:1339395 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 95: hkn0428:667235:667348 [3] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] -1/-1/-1->95->94
  1: hkn0403:1763954:1764350 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
  7: hkn0404:1339294:1339386 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
  7: hkn0404:1339294:1339386 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 95: hkn0428:667235:667348 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  1: hkn0403:1763954:1764350 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  4: hkn0404:1339282:1339394 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/0/-1->4->12
511: hkn0816:375492:375642 [3] NCCL INFO Trees [0] -1/-1/-1->511->510 [1] -1/-1/-1->511->510
  0: hkn0403:1763942:1764342 [0] NCCL INFO Trees [0] 1/256/-1->0->-1 [1] 1/-1/-1->0->4
  4: hkn0404:1339282:1339394 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
511: hkn0816:375492:375642 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  0: hkn0403:1763942:1764342 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
129: hkn0509:3124280:3124408 [1] NCCL INFO Trees [0] 130/64/-1->129->128 [1] 130/-1/-1->129->128
 96: hkn0501:1327777:1327903 [0] NCCL INFO Trees [0] 97/112/-1->96->64 [1] 97/-1/-1->96->100
130: hkn0509:3124308:3124406 [2] NCCL INFO Trees [0] 131/-1/-1->130->129 [1] 131/-1/-1->130->129
 96: hkn0501:1327777:1327903 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
129: hkn0509:3124280:3124408 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
130: hkn0509:3124308:3124406 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
131: hkn0509:3124296:3124401 [3] NCCL INFO Trees [0] -1/-1/-1->131->130 [1] -1/-1/-1->131->130
131: hkn0509:3124296:3124401 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 97: hkn0501:1327797:1327897 [1] NCCL INFO Trees [0] 98/80/-1->97->96 [1] 98/-1/-1->97->96
 97: hkn0501:1327797:1327897 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 98: hkn0501:1327785:1327898 [2] NCCL INFO Trees [0] 99/-1/-1->98->97 [1] 99/-1/-1->98->97
 98: hkn0501:1327785:1327898 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
510: hkn0816:375512:375637 [2] NCCL INFO Trees [0] 511/-1/-1->510->509 [1] 511/-1/-1->510->509
102: hkn0502:228938:229065 [2] NCCL INFO Trees [0] 103/-1/-1->102->101 [1] 103/-1/-1->102->101
132: hkn0510:2761944:2762047 [0] NCCL INFO Trees [0] 133/-1/-1->132->137 [1] 133/128/-1->132->140
132: hkn0510:2761944:2762047 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 99: hkn0501:1327769:1327904 [3] NCCL INFO Trees [0] -1/-1/-1->99->98 [1] -1/-1/-1->99->98
 99: hkn0501:1327769:1327904 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
510: hkn0816:375512:375637 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
102: hkn0502:228938:229065 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
137: hkn0511:3066282:3066391 [1] NCCL INFO Trees [0] 138/132/-1->137->136 [1] 138/-1/-1->137->136
137: hkn0511:3066282:3066391 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
133: hkn0510:2761928:2762038 [1] NCCL INFO Trees [0] 134/-1/-1->133->132 [1] 134/136/-1->133->132
142: hkn0512:3044033:3044156 [2] NCCL INFO Trees [0] 143/-1/-1->142->141 [1] 143/-1/-1->142->141
133: hkn0510:2761928:2762038 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
142: hkn0512:3044033:3044156 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
100: hkn0502:228966:229066 [0] NCCL INFO Trees [0] 101/-1/-1->100->105 [1] 101/96/-1->100->108
100: hkn0502:228966:229066 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
148: hkn0514:2950603:2950729 [0] NCCL INFO Trees [0] 149/-1/-1->148->153 [1] 149/144/-1->148->141
148: hkn0514:2950603:2950729 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
138: hkn0511:3066294:3066390 [2] NCCL INFO Trees [0] 139/-1/-1->138->137 [1] 139/-1/-1->138->137
138: hkn0511:3066294:3066390 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
134: hkn0510:2761956:2762044 [2] NCCL INFO Trees [0] 135/-1/-1->134->133 [1] 135/-1/-1->134->133
106: hkn0503:2899580:2899695 [2] NCCL INFO Trees [0] 107/-1/-1->106->105 [1] 107/-1/-1->106->105
106: hkn0503:2899580:2899695 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
101: hkn0502:228954:229059 [1] NCCL INFO Trees [0] 102/-1/-1->101->100 [1] 102/104/-1->101->100
101: hkn0502:228954:229059 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
149: hkn0514:2950618:2950734 [1] NCCL INFO Trees [0] 150/-1/-1->149->148 [1] 150/152/-1->149->148
149: hkn0514:2950618:2950734 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
139: hkn0511:3066266:3066383 [3] NCCL INFO Trees [0] -1/-1/-1->139->138 [1] -1/-1/-1->139->138
139: hkn0511:3066266:3066383 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
134: hkn0510:2761956:2762044 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
108: hkn0504:40743:40838 [0] NCCL INFO Trees [0] 109/-1/-1->108->104 [1] 109/100/-1->108->93
509: hkn0816:375500:375645 [1] NCCL INFO Trees [0] 510/-1/-1->509->508 [1] 510/-1/-1->509->508
140: hkn0512:3044041:3044149 [0] NCCL INFO Trees [0] 141/-1/-1->140->136 [1] 141/132/-1->140->156
140: hkn0512:3044041:3044149 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
128: hkn0509:3124288:3124402 [0] NCCL INFO Trees [0] 129/192/-1->128->257 [1] 129/-1/-1->128->132
103: hkn0502:228946:229060 [3] NCCL INFO Trees [0] -1/-1/-1->103->102 [1] -1/-1/-1->103->102
103: hkn0502:228946:229060 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
151: hkn0514:2950630:2950735 [3] NCCL INFO Trees [0] -1/-1/-1->151->150 [1] -1/-1/-1->151->150
151: hkn0514:2950630:2950735 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
136: hkn0511:3066274:3066392 [0] NCCL INFO Trees [0] 137/140/-1->136->145 [1] 137/-1/-1->136->133
135: hkn0510:2761936:2762043 [3] NCCL INFO Trees [0] -1/-1/-1->135->134 [1] -1/-1/-1->135->134
107: hkn0503:2899572:2899698 [3] NCCL INFO Trees [0] -1/-1/-1->107->106 [1] -1/-1/-1->107->106
509: hkn0816:375500:375645 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
143: hkn0512:3044032:3044153 [3] NCCL INFO Trees [0] -1/-1/-1->143->142 [1] -1/-1/-1->143->142
143: hkn0512:3044032:3044153 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
128: hkn0509:3124288:3124402 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
150: hkn0514:2950610:2950728 [2] NCCL INFO Trees [0] 151/-1/-1->150->149 [1] 151/-1/-1->150->149
150: hkn0514:2950610:2950728 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
112: hkn0505:2303664:2303782 [0] NCCL INFO Trees [0] 113/120/-1->112->96 [1] 113/-1/-1->112->116
112: hkn0505:2303664:2303782 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
136: hkn0511:3066274:3066392 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
135: hkn0510:2761936:2762043 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
144: hkn0513:3012844:3012958 [0] NCCL INFO Trees [0] 145/152/-1->144->161 [1] 145/-1/-1->144->148
110: hkn0504:40723:40837 [2] NCCL INFO Trees [0] 111/-1/-1->110->109 [1] 111/-1/-1->110->109
105: hkn0503:2899564:2899692 [1] NCCL INFO Trees [0] 106/100/-1->105->104 [1] 106/-1/-1->105->104
141: hkn0512:3044053:3044152 [1] NCCL INFO Trees [0] 142/-1/-1->141->140 [1] 142/148/-1->141->140
 93: hkn0428:667227:667353 [1] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 94/108/-1->93->92
127: hkn0508:3139037:3139138 [3] NCCL INFO Trees [0] -1/-1/-1->127->126 [1] -1/-1/-1->127->126
108: hkn0504:40743:40838 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
107: hkn0503:2899572:2899698 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
117: hkn0506:837969:838070 [1] NCCL INFO Trees [0] 118/-1/-1->117->116 [1] 118/120/-1->117->116
141: hkn0512:3044053:3044152 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
115: hkn0505:2303672:2303774 [3] NCCL INFO Trees [0] -1/-1/-1->115->114 [1] -1/-1/-1->115->114
115: hkn0505:2303672:2303774 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 93: hkn0428:667227:667353 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
145: hkn0513:3012872:3012961 [1] NCCL INFO Trees [0] 146/136/-1->145->144 [1] 146/-1/-1->145->144
145: hkn0513:3012872:3012961 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
105: hkn0503:2899564:2899692 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
118: hkn0506:837941:838072 [2] NCCL INFO Trees [0] 119/-1/-1->118->117 [1] 119/-1/-1->118->117
118: hkn0506:837941:838072 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
120: hkn0507:3186982:3187071 [0] NCCL INFO Trees [0] 121/124/-1->120->112 [1] 121/-1/-1->120->117
120: hkn0507:3186982:3187071 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
113: hkn0505:2303684:2303783 [1] NCCL INFO Trees [0] 114/104/-1->113->112 [1] 114/-1/-1->113->112
113: hkn0505:2303684:2303783 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
127: hkn0508:3139037:3139138 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
147: hkn0513:3012860:3012956 [3] NCCL INFO Trees [0] -1/-1/-1->147->146 [1] -1/-1/-1->147->146
147: hkn0513:3012860:3012956 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
104: hkn0503:2899591:2899697 [0] NCCL INFO Trees [0] 105/108/-1->104->113 [1] 105/-1/-1->104->101
117: hkn0506:837969:838070 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
121: hkn0507:3186962:3187062 [1] NCCL INFO Trees [0] 122/116/-1->121->120 [1] 122/-1/-1->121->120
114: hkn0505:2303656:2303781 [2] NCCL INFO Trees [0] 115/-1/-1->114->113 [1] 115/-1/-1->114->113
126: hkn0508:3139025:3139135 [2] NCCL INFO Trees [0] 127/-1/-1->126->125 [1] 127/-1/-1->126->125
144: hkn0513:3012844:3012958 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
110: hkn0504:40723:40837 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
116: hkn0506:837949:838063 [0] NCCL INFO Trees [0] 117/-1/-1->116->121 [1] 117/112/-1->116->109
122: hkn0507:3186958:3187070 [2] NCCL INFO Trees [0] 123/-1/-1->122->121 [1] 123/-1/-1->122->121
122: hkn0507:3186958:3187070 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
114: hkn0505:2303656:2303781 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
152: hkn0515:2896675:2896797 [0] NCCL INFO Trees [0] 153/156/-1->152->144 [1] 153/-1/-1->152->149
152: hkn0515:2896675:2896797 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
124: hkn0508:3139017:3139132 [0] NCCL INFO Trees [0] 125/-1/-1->124->120 [1] 125/60/-1->124->252
146: hkn0513:3012852:3012957 [2] NCCL INFO Trees [0] 147/-1/-1->146->145 [1] 147/-1/-1->146->145
146: hkn0513:3012852:3012957 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
109: hkn0504:40731:40842 [1] NCCL INFO Trees [0] 110/-1/-1->109->108 [1] 110/116/-1->109->108
109: hkn0504:40731:40842 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
104: hkn0503:2899591:2899697 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
119: hkn0506:837957:838067 [3] NCCL INFO Trees [0] -1/-1/-1->119->118 [1] -1/-1/-1->119->118
119: hkn0506:837957:838067 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
123: hkn0507:3186970:3187067 [3] NCCL INFO Trees [0] -1/-1/-1->123->122 [1] -1/-1/-1->123->122
126: hkn0508:3139025:3139135 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
111: hkn0504:40715:40839 [3] NCCL INFO Trees [0] -1/-1/-1->111->110 [1] -1/-1/-1->111->110
111: hkn0504:40715:40839 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
116: hkn0506:837949:838063 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
508: hkn0816:375484:375639 [0] NCCL INFO Trees [0] 509/-1/-1->508->504 [1] 509/252/-1->508->-1
121: hkn0507:3186962:3187062 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
153: hkn0515:2896667:2896795 [1] NCCL INFO Trees [0] 154/148/-1->153->152 [1] 154/-1/-1->153->152
153: hkn0515:2896667:2896795 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
507: hkn0815:395008:395125 [3] NCCL INFO Trees [0] -1/-1/-1->507->506 [1] -1/-1/-1->507->506
124: hkn0508:3139017:3139132 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
508: hkn0816:375484:375639 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
123: hkn0507:3186970:3187067 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
154: hkn0515:2896695:2896792 [2] NCCL INFO Trees [0] 155/-1/-1->154->153 [1] 155/-1/-1->154->153
154: hkn0515:2896695:2896792 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
507: hkn0815:395008:395125 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
125: hkn0508:3139009:3139136 [1] NCCL INFO Trees [0] 126/-1/-1->125->124 [1] 126/188/-1->125->124
125: hkn0508:3139009:3139136 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
155: hkn0515:2896683:2896800 [3] NCCL INFO Trees [0] -1/-1/-1->155->154 [1] -1/-1/-1->155->154
155: hkn0515:2896683:2896800 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
157: hkn0516:2915847:2915969 [1] NCCL INFO Trees [0] 158/-1/-1->157->156 [1] 158/172/-1->157->156
157: hkn0516:2915847:2915969 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
161: hkn0520:2712765:2712877 [1] NCCL INFO Trees [0] 162/144/-1->161->160 [1] 162/-1/-1->161->160
158: hkn0516:2915855:2915974 [2] NCCL INFO Trees [0] 159/-1/-1->158->157 [1] 159/-1/-1->158->157
158: hkn0516:2915855:2915974 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
162: hkn0520:2712749:2712876 [2] NCCL INFO Trees [0] 163/-1/-1->162->161 [1] 163/-1/-1->162->161
159: hkn0516:2915875:2915970 [3] NCCL INFO Trees [0] -1/-1/-1->159->158 [1] -1/-1/-1->159->158
159: hkn0516:2915875:2915970 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
160: hkn0520:2712777:2712878 [0] NCCL INFO Trees [0] 161/176/-1->160->193 [1] 161/-1/-1->160->164
156: hkn0516:2915863:2915972 [0] NCCL INFO Trees [0] 157/-1/-1->156->152 [1] 157/140/-1->156->188
156: hkn0516:2915863:2915972 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
161: hkn0520:2712765:2712877 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
162: hkn0520:2712749:2712876 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
163: hkn0520:2712757:2712880 [3] NCCL INFO Trees [0] -1/-1/-1->163->162 [1] -1/-1/-1->163->162
160: hkn0520:2712777:2712878 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
163: hkn0520:2712757:2712880 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
506: hkn0815:395000:395128 [2] NCCL INFO Trees [0] 507/-1/-1->506->505 [1] 507/-1/-1->506->505
506: hkn0815:395000:395128 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
168: hkn0523:1547961:1548090 [0] NCCL INFO Trees [0] 169/172/-1->168->177 [1] 169/-1/-1->168->165
168: hkn0523:1547961:1548090 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
505: hkn0815:395028:395124 [1] NCCL INFO Trees [0] 506/500/-1->505->504 [1] 506/-1/-1->505->504
174: hkn0524:1133687:1133798 [2] NCCL INFO Trees [0] 175/-1/-1->174->173 [1] 175/-1/-1->174->173
505: hkn0815:395028:395124 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
164: hkn0521:1197679:1197790 [0] NCCL INFO Trees [0] 165/-1/-1->164->169 [1] 165/160/-1->164->172
164: hkn0521:1197679:1197790 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
169: hkn0523:1547989:1548085 [1] NCCL INFO Trees [0] 170/164/-1->169->168 [1] 170/-1/-1->169->168
169: hkn0523:1547989:1548085 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
174: hkn0524:1133687:1133798 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
170: hkn0523:1547969:1548086 [2] NCCL INFO Trees [0] 171/-1/-1->170->169 [1] 171/-1/-1->170->169
165: hkn0521:1197671:1197795 [1] NCCL INFO Trees [0] 166/-1/-1->165->164 [1] 166/168/-1->165->164
165: hkn0521:1197671:1197795 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
170: hkn0523:1547969:1548086 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
504: hkn0815:395016:395129 [0] NCCL INFO Trees [0] 505/508/-1->504->496 [1] 505/-1/-1->504->501
503: hkn0814:675719:675836 [3] NCCL INFO Trees [0] -1/-1/-1->503->502 [1] -1/-1/-1->503->502
166: hkn0521:1197663:1197794 [2] NCCL INFO Trees [0] 167/-1/-1->166->165 [1] 167/-1/-1->166->165
171: hkn0523:1547977:1548089 [3] NCCL INFO Trees [0] -1/-1/-1->171->170 [1] -1/-1/-1->171->170
172: hkn0524:1133679:1133791 [0] NCCL INFO Trees [0] 173/-1/-1->172->168 [1] 173/164/-1->172->157
176: hkn0525:986689:986834 [0] NCCL INFO Trees [0] 177/184/-1->176->160 [1] 177/-1/-1->176->180
176: hkn0525:986689:986834 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
504: hkn0815:395016:395129 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
167: hkn0521:1197691:1197791 [3] NCCL INFO Trees [0] -1/-1/-1->167->166 [1] -1/-1/-1->167->166
167: hkn0521:1197691:1197791 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
171: hkn0523:1547977:1548089 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
177: hkn0525:986697:986833 [1] NCCL INFO Trees [0] 178/168/-1->177->176 [1] 178/-1/-1->177->176
177: hkn0525:986697:986833 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
503: hkn0814:675719:675836 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
166: hkn0521:1197663:1197794 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
173: hkn0524:1133699:1133792 [1] NCCL INFO Trees [0] 174/-1/-1->173->172 [1] 174/180/-1->173->172
502: hkn0814:675720:675841 [2] NCCL INFO Trees [0] 503/-1/-1->502->501 [1] 503/-1/-1->502->501
175: hkn0524:1133671:1133797 [3] NCCL INFO Trees [0] -1/-1/-1->175->174 [1] -1/-1/-1->175->174
181: hkn0526:1428306:1428417 [1] NCCL INFO Trees [0] 182/-1/-1->181->180 [1] 182/184/-1->181->180
502: hkn0814:675720:675841 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
172: hkn0524:1133679:1133791 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
178: hkn0525:986708:986837 [2] NCCL INFO Trees [0] 179/-1/-1->178->177 [1] 179/-1/-1->178->177
182: hkn0526:1428290:1428419 [2] NCCL INFO Trees [0] 183/-1/-1->182->181 [1] 183/-1/-1->182->181
182: hkn0526:1428290:1428419 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
500: hkn0814:675728:675835 [0] NCCL INFO Trees [0] 501/-1/-1->500->505 [1] 501/496/-1->500->493
173: hkn0524:1133699:1133792 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
185: hkn0527:1348822:1348946 [1] NCCL INFO Trees [0] 186/180/-1->185->184 [1] 186/-1/-1->185->184
179: hkn0525:986681:986840 [3] NCCL INFO Trees [0] -1/-1/-1->179->178 [1] -1/-1/-1->179->178
181: hkn0526:1428306:1428417 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
500: hkn0814:675728:675835 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
175: hkn0524:1133671:1133797 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
190: hkn0528:1301582:1301674 [2] NCCL INFO Trees [0] 191/-1/-1->190->189 [1] 191/-1/-1->190->189
178: hkn0525:986708:986837 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
180: hkn0526:1428298:1428416 [0] NCCL INFO Trees [0] 181/-1/-1->180->185 [1] 181/176/-1->180->173
501: hkn0814:675740:675838 [1] NCCL INFO Trees [0] 502/-1/-1->501->500 [1] 502/504/-1->501->500
185: hkn0527:1348822:1348946 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
179: hkn0525:986681:986840 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
183: hkn0526:1428318:1428415 [3] NCCL INFO Trees [0] -1/-1/-1->183->182 [1] -1/-1/-1->183->182
501: hkn0814:675740:675838 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
497: hkn0812:693675:693791 [1] NCCL INFO Trees [0] 498/488/-1->497->496 [1] 498/-1/-1->497->496
187: hkn0527:1348850:1348948 [3] NCCL INFO Trees [0] -1/-1/-1->187->186 [1] -1/-1/-1->187->186
190: hkn0528:1301582:1301674 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
183: hkn0526:1428318:1428415 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
187: hkn0527:1348850:1348948 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
180: hkn0526:1428298:1428416 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
498: hkn0812:693667:693793 [2] NCCL INFO Trees [0] 499/-1/-1->498->497 [1] 499/-1/-1->498->497
186: hkn0527:1348830:1348950 [2] NCCL INFO Trees [0] 187/-1/-1->186->185 [1] 187/-1/-1->186->185
186: hkn0527:1348830:1348950 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
496: hkn0812:693695:693790 [0] NCCL INFO Trees [0] 497/504/-1->496->480 [1] 497/-1/-1->496->500
184: hkn0527:1348838:1348947 [0] NCCL INFO Trees [0] 185/188/-1->184->176 [1] 185/-1/-1->184->181
497: hkn0812:693675:693791 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
184: hkn0527:1348838:1348947 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
194: hkn0529:1540708:1540856 [2] NCCL INFO Trees [0] 195/-1/-1->194->193 [1] 195/-1/-1->194->193
494: hkn0810:939437:939537 [2] NCCL INFO Trees [0] 495/-1/-1->494->493 [1] 495/-1/-1->494->493
498: hkn0812:693667:693793 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
189: hkn0528:1301571:1301681 [1] NCCL INFO Trees [0] 190/-1/-1->189->188 [1] 190/220/-1->189->188
491: hkn0809:937251:937374 [3] NCCL INFO Trees [0] -1/-1/-1->491->490 [1] -1/-1/-1->491->490
495: hkn0810:939425:939541 [3] NCCL INFO Trees [0] -1/-1/-1->495->494 [1] -1/-1/-1->495->494
496: hkn0812:693695:693790 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
189: hkn0528:1301571:1301681 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
194: hkn0529:1540708:1540856 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
494: hkn0810:939437:939537 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
499: hkn0812:693683:693792 [3] NCCL INFO Trees [0] -1/-1/-1->499->498 [1] -1/-1/-1->499->498
191: hkn0528:1301563:1301675 [3] NCCL INFO Trees [0] -1/-1/-1->191->190 [1] -1/-1/-1->191->190
191: hkn0528:1301563:1301675 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
192: hkn0529:1540728:1540857 [0] NCCL INFO Trees [0] 193/224/-1->192->128 [1] 193/-1/-1->192->196
495: hkn0810:939425:939541 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
499: hkn0812:693683:693792 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
188: hkn0528:1301555:1301679 [0] NCCL INFO Trees [0] 189/-1/-1->188->184 [1] 189/156/-1->188->125
188: hkn0528:1301555:1301679 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
193: hkn0529:1540700:1540850 [1] NCCL INFO Trees [0] 194/160/-1->193->192 [1] 194/-1/-1->193->192
193: hkn0529:1540700:1540850 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
491: hkn0809:937251:937374 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
493: hkn0810:939417:939538 [1] NCCL INFO Trees [0] 494/-1/-1->493->492 [1] 494/500/-1->493->492
195: hkn0529:1540716:1540851 [3] NCCL INFO Trees [0] -1/-1/-1->195->194 [1] -1/-1/-1->195->194
195: hkn0529:1540716:1540851 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
198: hkn0530:1258034:1258159 [2] NCCL INFO Trees [0] 199/-1/-1->198->197 [1] 199/-1/-1->198->197
493: hkn0810:939417:939538 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
192: hkn0529:1540728:1540857 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
489: hkn0809:937231:937375 [1] NCCL INFO Trees [0] 490/484/-1->489->488 [1] 490/-1/-1->489->488
492: hkn0810:939409:939536 [0] NCCL INFO Trees [0] 493/-1/-1->492->488 [1] 493/484/-1->492->477
485: hkn0808:970565:970682 [1] NCCL INFO Trees [0] 486/-1/-1->485->484 [1] 486/488/-1->485->484
485: hkn0808:970565:970682 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
492: hkn0810:939409:939536 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
198: hkn0530:1258034:1258159 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
482: hkn0807:1018950:1019079 [2] NCCL INFO Trees [0] 483/-1/-1->482->481 [1] 483/-1/-1->482->481
489: hkn0809:937231:937375 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
490: hkn0809:937230:937376 [2] NCCL INFO Trees [0] 491/-1/-1->490->489 [1] 491/-1/-1->490->489
207: hkn0532:924627:924923 [3] NCCL INFO Trees [0] -1/-1/-1->207->206 [1] -1/-1/-1->207->206
202: hkn0531:1230513:1230642 [2] NCCL INFO Trees [0] 203/-1/-1->202->201 [1] 203/-1/-1->202->201
196: hkn0530:1258042:1258156 [0] NCCL INFO Trees [0] 197/-1/-1->196->201 [1] 197/192/-1->196->204
196: hkn0530:1258042:1258156 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
486: hkn0808:970577:970677 [2] NCCL INFO Trees [0] 487/-1/-1->486->485 [1] 487/-1/-1->486->485
482: hkn0807:1018950:1019079 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
490: hkn0809:937230:937376 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
197: hkn0530:1258062:1258153 [1] NCCL INFO Trees [0] 198/-1/-1->197->196 [1] 198/200/-1->197->196
197: hkn0530:1258062:1258153 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
487: hkn0808:970549:970680 [3] NCCL INFO Trees [0] -1/-1/-1->487->486 [1] -1/-1/-1->487->486
483: hkn0807:1018978:1019080 [3] NCCL INFO Trees [0] -1/-1/-1->483->482 [1] -1/-1/-1->483->482
488: hkn0809:937239:937379 [0] NCCL INFO Trees [0] 489/492/-1->488->497 [1] 489/-1/-1->488->485
488: hkn0809:937239:937379 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
207: hkn0532:924627:924923 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
210: hkn0534:1148280:1148416 [2] NCCL INFO Trees [0] 211/-1/-1->210->209 [1] 211/-1/-1->210->209
203: hkn0531:1230541:1230644 [3] NCCL INFO Trees [0] -1/-1/-1->203->202 [1] -1/-1/-1->203->202
199: hkn0530:1258050:1258161 [3] NCCL INFO Trees [0] -1/-1/-1->199->198 [1] -1/-1/-1->199->198
484: hkn0808:970557:970676 [0] NCCL INFO Trees [0] 485/-1/-1->484->489 [1] 485/480/-1->484->492
483: hkn0807:1018978:1019080 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
261: hkn0613:902589:902698 [1] NCCL INFO Trees [0] 262/-1/-1->261->260 [1] 262/264/-1->261->260
211: hkn0534:1148272:1148423 [3] NCCL INFO Trees [0] -1/-1/-1->211->210 [1] -1/-1/-1->211->210
202: hkn0531:1230513:1230642 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
199: hkn0530:1258050:1258161 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
486: hkn0808:970577:970677 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
210: hkn0534:1148280:1148416 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
203: hkn0531:1230541:1230644 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
487: hkn0808:970549:970680 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
481: hkn0807:1018958:1019082 [1] NCCL INFO Trees [0] 482/464/-1->481->480 [1] 482/-1/-1->481->480
261: hkn0613:902589:902698 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
204: hkn0532:924615:924928 [0] NCCL INFO Trees [0] 205/-1/-1->204->200 [1] 205/196/-1->204->220
211: hkn0534:1148272:1148423 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
200: hkn0531:1230521:1230636 [0] NCCL INFO Trees [0] 201/204/-1->200->209 [1] 201/-1/-1->200->197
484: hkn0808:970557:970676 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
481: hkn0807:1018958:1019082 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
262: hkn0613:902573:902699 [2] NCCL INFO Trees [0] 263/-1/-1->262->261 [1] 263/-1/-1->262->261
206: hkn0532:924599:924925 [2] NCCL INFO Trees [0] 207/-1/-1->206->205 [1] 207/-1/-1->206->205
206: hkn0532:924599:924925 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
208: hkn0534:1148264:1148419 [0] NCCL INFO Trees [0] 209/216/-1->208->225 [1] 209/-1/-1->208->212
208: hkn0534:1148264:1148419 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
201: hkn0531:1230529:1230638 [1] NCCL INFO Trees [0] 202/196/-1->201->200 [1] 202/-1/-1->201->200
480: hkn0807:1018966:1019081 [0] NCCL INFO Trees [0] 481/496/-1->480->448 [1] 481/-1/-1->480->484
262: hkn0613:902573:902699 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
204: hkn0532:924615:924928 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
209: hkn0534:1148292:1148420 [1] NCCL INFO Trees [0] 210/200/-1->209->208 [1] 210/-1/-1->209->208
209: hkn0534:1148292:1148420 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
259: hkn0612:916868:916976 [3] NCCL INFO Trees [0] -1/-1/-1->259->258 [1] -1/-1/-1->259->258
201: hkn0531:1230529:1230638 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
480: hkn0807:1018966:1019081 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
260: hkn0613:902581:902700 [0] NCCL INFO Trees [0] 261/-1/-1->260->265 [1] 261/256/-1->260->268
205: hkn0532:924607:924924 [1] NCCL INFO Trees [0] 206/-1/-1->205->204 [1] 206/212/-1->205->204
205: hkn0532:924607:924924 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
259: hkn0612:916868:916976 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
200: hkn0531:1230521:1230636 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
264: hkn0615:414213:414324 [0] NCCL INFO Trees [0] 265/268/-1->264->273 [1] 265/-1/-1->264->261
264: hkn0615:414213:414324 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
260: hkn0613:902581:902700 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
265: hkn0615:414225:414318 [1] NCCL INFO Trees [0] 266/260/-1->265->264 [1] 266/-1/-1->265->264
265: hkn0615:414225:414318 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
263: hkn0613:902601:902691 [3] NCCL INFO Trees [0] -1/-1/-1->263->262 [1] -1/-1/-1->263->262
255: hkn0611:709694:709822 [3] NCCL INFO Trees [0] -1/-1/-1->255->254 [1] -1/-1/-1->255->254
258: hkn0612:916880:916979 [2] NCCL INFO Trees [0] 259/-1/-1->258->257 [1] 259/-1/-1->258->257
266: hkn0615:414205:414319 [2] NCCL INFO Trees [0] 267/-1/-1->266->265 [1] 267/-1/-1->266->265
266: hkn0615:414205:414319 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
478: hkn0806:1054238:1054345 [2] NCCL INFO Trees [0] 479/-1/-1->478->477 [1] 479/-1/-1->478->477
263: hkn0613:902601:902691 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
255: hkn0611:709694:709822 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
474: hkn0805:1112002:1112122 [2] NCCL INFO Trees [0] 475/-1/-1->474->473 [1] 475/-1/-1->474->473
258: hkn0612:916880:916979 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
271: hkn0616:404778:404908 [3] NCCL INFO Trees [0] -1/-1/-1->271->270 [1] -1/-1/-1->271->270
267: hkn0615:414197:414325 [3] NCCL INFO Trees [0] -1/-1/-1->267->266 [1] -1/-1/-1->267->266
267: hkn0615:414197:414325 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
476: hkn0806:1054250:1054352 [0] NCCL INFO Trees [0] 477/-1/-1->476->472 [1] 477/460/-1->476->445
476: hkn0806:1054250:1054352 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
257: hkn0612:916860:916982 [1] NCCL INFO Trees [0] 258/128/-1->257->256 [1] 258/-1/-1->257->256
270: hkn0616:404806:404907 [2] NCCL INFO Trees [0] 271/-1/-1->270->269 [1] 271/-1/-1->270->269
478: hkn0806:1054238:1054345 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
474: hkn0805:1112002:1112122 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
248: hkn0609:710728:710827 [0] NCCL INFO Trees [0] 249/252/-1->248->240 [1] 249/-1/-1->248->245
271: hkn0616:404778:404908 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
479: hkn0806:1054222:1054347 [3] NCCL INFO Trees [0] -1/-1/-1->479->478 [1] -1/-1/-1->479->478
479: hkn0806:1054222:1054347 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
475: hkn0805:1112010:1112126 [3] NCCL INFO Trees [0] -1/-1/-1->475->474 [1] -1/-1/-1->475->474
257: hkn0612:916860:916982 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
270: hkn0616:404806:404907 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
477: hkn0806:1054230:1054353 [1] NCCL INFO Trees [0] 478/-1/-1->477->476 [1] 478/492/-1->477->476
254: hkn0611:709710:709819 [2] NCCL INFO Trees [0] 255/-1/-1->254->253 [1] 255/-1/-1->254->253
472: hkn0805:1111994:1112121 [0] NCCL INFO Trees [0] 473/476/-1->472->464 [1] 473/-1/-1->472->469
472: hkn0805:1111994:1112121 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
256: hkn0612:916852:916975 [0] NCCL INFO Trees [0] 257/384/-1->256->0 [1] 257/-1/-1->256->260
250: hkn0609:710708:710822 [2] NCCL INFO Trees [0] 251/-1/-1->250->249 [1] 251/-1/-1->250->249
213: hkn0535:2398861:2398990 [1] NCCL INFO Trees [0] 214/-1/-1->213->212 [1] 214/216/-1->213->212
268: hkn0616:404786:404909 [0] NCCL INFO Trees [0] 269/-1/-1->268->264 [1] 269/260/-1->268->284
477: hkn0806:1054230:1054353 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
254: hkn0611:709710:709819 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
475: hkn0805:1112010:1112126 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
256: hkn0612:916852:916975 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
248: hkn0609:710728:710827 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
213: hkn0535:2398861:2398990 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
252: hkn0611:709722:709820 [0] NCCL INFO Trees [0] 253/-1/-1->252->248 [1] 253/124/-1->252->508
473: hkn0805:1112022:1112123 [1] NCCL INFO Trees [0] 474/468/-1->473->472 [1] 474/-1/-1->473->472
250: hkn0609:710708:710822 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
269: hkn0616:404794:404911 [1] NCCL INFO Trees [0] 270/-1/-1->269->268 [1] 270/276/-1->269->268
269: hkn0616:404794:404911 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
272: hkn0617:2294566:2294704 [0] NCCL INFO Trees [0] 273/280/-1->272->289 [1] 273/-1/-1->272->276
473: hkn0805:1112022:1112123 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
268: hkn0616:404786:404909 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
274: hkn0617:2294558:2294701 [2] NCCL INFO Trees [0] 275/-1/-1->274->273 [1] 275/-1/-1->274->273
252: hkn0611:709722:709820 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
249: hkn0609:710716:710825 [1] NCCL INFO Trees [0] 250/244/-1->249->248 [1] 250/-1/-1->249->248
212: hkn0535:2398877:2398992 [0] NCCL INFO Trees [0] 213/-1/-1->212->217 [1] 213/208/-1->212->205
272: hkn0617:2294566:2294704 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
253: hkn0611:709702:709825 [1] NCCL INFO Trees [0] 254/-1/-1->253->252 [1] 254/380/-1->253->252
251: hkn0609:710700:710823 [3] NCCL INFO Trees [0] -1/-1/-1->251->250 [1] -1/-1/-1->251->250
212: hkn0535:2398877:2398992 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
274: hkn0617:2294558:2294701 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
216: hkn0601:117612:117713 [0] NCCL INFO Trees [0] 217/220/-1->216->208 [1] 217/-1/-1->216->213
253: hkn0611:709702:709825 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
249: hkn0609:710716:710825 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
214: hkn0535:2398869:2398986 [2] NCCL INFO Trees [0] 215/-1/-1->214->213 [1] 215/-1/-1->214->213
273: hkn0617:2294577:2294697 [1] NCCL INFO Trees [0] 274/264/-1->273->272 [1] 274/-1/-1->273->272
273: hkn0617:2294577:2294697 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
216: hkn0601:117612:117713 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
251: hkn0609:710700:710823 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
215: hkn0535:2398889:2398985 [3] NCCL INFO Trees [0] -1/-1/-1->215->214 [1] -1/-1/-1->215->214
279: hkn0621:1991468:1991586 [3] NCCL INFO Trees [0] -1/-1/-1->279->278 [1] -1/-1/-1->279->278
275: hkn0617:2294550:2294702 [3] NCCL INFO Trees [0] -1/-1/-1->275->274 [1] -1/-1/-1->275->274
214: hkn0535:2398869:2398986 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
279: hkn0621:1991468:1991586 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
275: hkn0617:2294550:2294702 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
219: hkn0601:117592:117705 [3] NCCL INFO Trees [0] -1/-1/-1->219->218 [1] -1/-1/-1->219->218
215: hkn0535:2398889:2398985 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
219: hkn0601:117592:117705 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
282: hkn0622:2020384:2020510 [2] NCCL INFO Trees [0] 283/-1/-1->282->281 [1] 283/-1/-1->282->281
217: hkn0601:117600:117712 [1] NCCL INFO Trees [0] 218/212/-1->217->216 [1] 218/-1/-1->217->216
217: hkn0601:117600:117712 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
218: hkn0601:117591:117714 [2] NCCL INFO Trees [0] 219/-1/-1->218->217 [1] 219/-1/-1->218->217
218: hkn0601:117591:117714 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
247: hkn0608:485624:485730 [3] NCCL INFO Trees [0] -1/-1/-1->247->246 [1] -1/-1/-1->247->246
247: hkn0608:485624:485730 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
276: hkn0621:1991476:1991587 [0] NCCL INFO Trees [0] 277/-1/-1->276->281 [1] 277/272/-1->276->269
282: hkn0622:2020384:2020510 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
470: hkn0804:1205535:1205629 [2] NCCL INFO Trees [0] 471/-1/-1->470->469 [1] 471/-1/-1->470->469
470: hkn0804:1205535:1205629 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
277: hkn0621:1991460:1991584 [1] NCCL INFO Trees [0] 278/-1/-1->277->276 [1] 278/280/-1->277->276
277: hkn0621:1991460:1991584 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
283: hkn0622:2020400:2020511 [3] NCCL INFO Trees [0] -1/-1/-1->283->282 [1] -1/-1/-1->283->282
278: hkn0621:1991488:1991585 [2] NCCL INFO Trees [0] 279/-1/-1->278->277 [1] 279/-1/-1->278->277
220: hkn0602:3362279:3362548 [0] NCCL INFO Trees [0] 221/-1/-1->220->216 [1] 221/204/-1->220->189
276: hkn0621:1991476:1991587 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
469: hkn0804:1205507:1205626 [1] NCCL INFO Trees [0] 470/-1/-1->469->468 [1] 470/472/-1->469->468
220: hkn0602:3362279:3362548 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
278: hkn0621:1991488:1991585 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
469: hkn0804:1205507:1205626 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
221: hkn0602:3362307:3362555 [1] NCCL INFO Trees [0] 222/-1/-1->221->220 [1] 222/236/-1->221->220
283: hkn0622:2020400:2020511 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
221: hkn0602:3362307:3362555 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
281: hkn0622:2020392:2020504 [1] NCCL INFO Trees [0] 282/276/-1->281->280 [1] 282/-1/-1->281->280
222: hkn0602:3362295:3362554 [2] NCCL INFO Trees [0] 223/-1/-1->222->221 [1] 223/-1/-1->222->221
280: hkn0622:2020412:2020505 [0] NCCL INFO Trees [0] 281/284/-1->280->272 [1] 281/-1/-1->280->277
222: hkn0602:3362295:3362554 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
281: hkn0622:2020392:2020504 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
280: hkn0622:2020412:2020505 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
246: hkn0608:485616:485737 [2] NCCL INFO Trees [0] 247/-1/-1->246->245 [1] 247/-1/-1->246->245
471: hkn0804:1205505:1205631 [3] NCCL INFO Trees [0] -1/-1/-1->471->470 [1] -1/-1/-1->471->470
224: hkn0603:1413107:1413231 [0] NCCL INFO Trees [0] 225/240/-1->224->192 [1] 225/-1/-1->224->228
223: hkn0602:3362287:3362549 [3] NCCL INFO Trees [0] -1/-1/-1->223->222 [1] -1/-1/-1->223->222
246: hkn0608:485616:485737 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
224: hkn0603:1413107:1413231 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
471: hkn0804:1205505:1205631 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
240: hkn0607:904254:904366 [0] NCCL INFO Trees [0] 241/248/-1->240->224 [1] 241/-1/-1->240->244
223: hkn0602:3362287:3362549 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
227: hkn0603:1413135:1413236 [3] NCCL INFO Trees [0] -1/-1/-1->227->226 [1] -1/-1/-1->227->226
240: hkn0607:904254:904366 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
230: hkn0604:689117:689240 [2] NCCL INFO Trees [0] 231/-1/-1->230->229 [1] 231/-1/-1->230->229
227: hkn0603:1413135:1413236 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
243: hkn0607:904246:904360 [3] NCCL INFO Trees [0] -1/-1/-1->243->242 [1] -1/-1/-1->243->242
244: hkn0608:485608:485739 [0] NCCL INFO Trees [0] 245/-1/-1->244->249 [1] 245/240/-1->244->237
226: hkn0603:1413123:1413232 [2] NCCL INFO Trees [0] 227/-1/-1->226->225 [1] 227/-1/-1->226->225
241: hkn0607:904238:904362 [1] NCCL INFO Trees [0] 242/232/-1->241->240 [1] 242/-1/-1->241->240
245: hkn0608:485636:485738 [1] NCCL INFO Trees [0] 246/-1/-1->245->244 [1] 246/248/-1->245->244
245: hkn0608:485636:485738 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
230: hkn0604:689117:689240 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
467: hkn0803:876457:876566 [3] NCCL INFO Trees [0] -1/-1/-1->467->466 [1] -1/-1/-1->467->466
226: hkn0603:1413123:1413232 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
242: hkn0607:904266:904368 [2] NCCL INFO Trees [0] 243/-1/-1->242->241 [1] 243/-1/-1->242->241
242: hkn0607:904266:904368 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
244: hkn0608:485608:485739 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
231: hkn0604:689125:689244 [3] NCCL INFO Trees [0] -1/-1/-1->231->230 [1] -1/-1/-1->231->230
225: hkn0603:1413115:1413233 [1] NCCL INFO Trees [0] 226/208/-1->225->224 [1] 226/-1/-1->225->224
243: hkn0607:904246:904360 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
295: hkn0626:1298345:1298453 [3] NCCL INFO Trees [0] -1/-1/-1->295->294 [1] -1/-1/-1->295->294
231: hkn0604:689125:689244 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
467: hkn0803:876457:876566 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
225: hkn0603:1413115:1413233 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
468: hkn0804:1205515:1205623 [0] NCCL INFO Trees [0] 469/-1/-1->468->473 [1] 469/464/-1->468->461
241: hkn0607:904238:904362 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
285: hkn0623:1872640:1872768 [1] NCCL INFO Trees [0] 286/-1/-1->285->284 [1] 286/300/-1->285->284
229: hkn0604:689145:689242 [1] NCCL INFO Trees [0] 230/-1/-1->229->228 [1] 230/232/-1->229->228
289: hkn0624:1772850:1772951 [1] NCCL INFO Trees [0] 290/272/-1->289->288 [1] 290/-1/-1->289->288
289: hkn0624:1772850:1772951 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
468: hkn0804:1205515:1205623 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
295: hkn0626:1298345:1298453 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
285: hkn0623:1872640:1872768 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
228: hkn0604:689133:689241 [0] NCCL INFO Trees [0] 229/-1/-1->228->233 [1] 229/224/-1->228->236
228: hkn0604:689133:689241 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
302: hkn0628:671759:671904 [2] NCCL INFO Trees [0] 303/-1/-1->302->301 [1] 303/-1/-1->302->301
290: hkn0624:1772838:1772944 [2] NCCL INFO Trees [0] 291/-1/-1->290->289 [1] 291/-1/-1->290->289
290: hkn0624:1772838:1772944 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
233: hkn0605:712002:712113 [1] NCCL INFO Trees [0] 234/228/-1->233->232 [1] 234/-1/-1->233->232
292: hkn0626:1298337:1298454 [0] NCCL INFO Trees [0] 293/-1/-1->292->297 [1] 293/288/-1->292->300
287: hkn0623:1872668:1872764 [3] NCCL INFO Trees [0] -1/-1/-1->287->286 [1] -1/-1/-1->287->286
287: hkn0623:1872668:1872764 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
229: hkn0604:689145:689242 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
302: hkn0628:671759:671904 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
291: hkn0624:1772830:1772945 [3] NCCL INFO Trees [0] -1/-1/-1->291->290 [1] -1/-1/-1->291->290
291: hkn0624:1772830:1772945 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
297: hkn0627:1787808:1787920 [1] NCCL INFO Trees [0] 298/292/-1->297->296 [1] 298/-1/-1->297->296
 22: hkn0409:2585544:2585697 [2] NCCL INFO Channel 00 : 22[ca000] -> 21[4b000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
237: hkn0606:2371969:2372080 [1] NCCL INFO Trees [0] 238/-1/-1->237->236 [1] 238/244/-1->237->236
284: hkn0623:1872656:1872763 [0] NCCL INFO Trees [0] 285/-1/-1->284->280 [1] 285/268/-1->284->316
284: hkn0623:1872656:1872763 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
300: hkn0628:671767:671903 [0] NCCL INFO Trees [0] 301/-1/-1->300->296 [1] 301/292/-1->300->285
300: hkn0628:671767:671903 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
288: hkn0624:1772822:1772950 [0] NCCL INFO Trees [0] 289/304/-1->288->321 [1] 289/-1/-1->288->292
288: hkn0624:1772822:1772950 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
297: hkn0627:1787808:1787920 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
293: hkn0626:1298357:1298456 [1] NCCL INFO Trees [0] 294/-1/-1->293->292 [1] 294/296/-1->293->292
236: hkn0606:2371977:2372089 [0] NCCL INFO Trees [0] 237/-1/-1->236->232 [1] 237/228/-1->236->221
286: hkn0623:1872648:1872765 [2] NCCL INFO Trees [0] 287/-1/-1->286->285 [1] 287/-1/-1->286->285
286: hkn0623:1872648:1872765 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
299: hkn0627:1787816:1787921 [3] NCCL INFO Trees [0] -1/-1/-1->299->298 [1] -1/-1/-1->299->298
233: hkn0605:712002:712113 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
294: hkn0626:1298329:1298455 [2] NCCL INFO Trees [0] 295/-1/-1->294->293 [1] 295/-1/-1->294->293
237: hkn0606:2371969:2372080 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
301: hkn0628:671751:671908 [1] NCCL INFO Trees [0] 302/-1/-1->301->300 [1] 302/308/-1->301->300
301: hkn0628:671751:671908 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
232: hkn0605:711997:712115 [0] NCCL INFO Trees [0] 233/236/-1->232->241 [1] 233/-1/-1->232->229
232: hkn0605:711997:712115 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
293: hkn0626:1298357:1298456 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
236: hkn0606:2371977:2372089 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
303: hkn0628:671779:671905 [3] NCCL INFO Trees [0] -1/-1/-1->303->302 [1] -1/-1/-1->303->302
234: hkn0605:711998:712112 [2] NCCL INFO Trees [0] 235/-1/-1->234->233 [1] 235/-1/-1->234->233
234: hkn0605:711998:712112 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
294: hkn0626:1298329:1298455 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
238: hkn0606:2371989:2372088 [2] NCCL INFO Trees [0] 239/-1/-1->238->237 [1] 239/-1/-1->238->237
303: hkn0628:671779:671905 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
298: hkn0627:1787836:1787925 [2] NCCL INFO Trees [0] 299/-1/-1->298->297 [1] 299/-1/-1->298->297
235: hkn0605:712014:712118 [3] NCCL INFO Trees [0] -1/-1/-1->235->234 [1] -1/-1/-1->235->234
235: hkn0605:712014:712118 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
239: hkn0606:2371961:2372083 [3] NCCL INFO Trees [0] -1/-1/-1->239->238 [1] -1/-1/-1->239->238
299: hkn0627:1787816:1787921 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
238: hkn0606:2371989:2372088 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
298: hkn0627:1787836:1787925 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
239: hkn0606:2371961:2372083 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
296: hkn0627:1787824:1787924 [0] NCCL INFO Trees [0] 297/300/-1->296->305 [1] 297/-1/-1->296->293
465: hkn0803:876477:876562 [1] NCCL INFO Trees [0] 466/456/-1->465->464 [1] 466/-1/-1->465->464
465: hkn0803:876477:876562 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
304: hkn0629:1591939:1592054 [0] NCCL INFO Trees [0] 305/312/-1->304->288 [1] 305/-1/-1->304->308
466: hkn0803:876456:876564 [2] NCCL INFO Trees [0] 467/-1/-1->466->465 [1] 467/-1/-1->466->465
466: hkn0803:876456:876564 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 30: hkn0411:2315763:2315863 [2] NCCL INFO Channel 00 : 30[ca000] -> 29[4b000] via P2P/IPC/read
304: hkn0629:1591939:1592054 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
464: hkn0803:876465:876561 [0] NCCL INFO Trees [0] 465/472/-1->464->481 [1] 465/-1/-1->464->468
464: hkn0803:876465:876561 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
307: hkn0629:1591931:1592055 [3] NCCL INFO Trees [0] -1/-1/-1->307->306 [1] -1/-1/-1->307->306
307: hkn0629:1591931:1592055 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
296: hkn0627:1787824:1787924 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
305: hkn0629:1591959:1592057 [1] NCCL INFO Trees [0] 306/296/-1->305->304 [1] 306/-1/-1->305->304
305: hkn0629:1591959:1592057 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 62: hkn0420:3210093:3210219 [2] NCCL INFO Channel 00 : 62[ca000] -> 61[4b000] via P2P/IPC/read
 26: hkn0410:1159602:1159714 [2] NCCL INFO Channel 00 : 26[ca000] -> 25[4b000] via P2P/IPC/read
 38: hkn0413:2366608:2366707 [2] NCCL INFO Channel 00 : 38[ca000] -> 37[4b000] via P2P/IPC/read
306: hkn0629:1591947:1592059 [2] NCCL INFO Trees [0] 307/-1/-1->306->305 [1] 307/-1/-1->306->305
306: hkn0629:1591947:1592059 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 22: hkn0409:2585544:2585697 [2] NCCL INFO Channel 01 : 22[ca000] -> 21[4b000] via P2P/IPC/read
 58: hkn0419:1544203:1544299 [2] NCCL INFO Channel 00 : 58[ca000] -> 57[4b000] via P2P/IPC/read
 34: hkn0412:2262277:2262396 [2] NCCL INFO Channel 00 : 34[ca000] -> 33[4b000] via P2P/IPC/read
454: hkn0736:1508244:1508370 [2] NCCL INFO Trees [0] 455/-1/-1->454->453 [1] 455/-1/-1->454->453
313: hkn0631:1021707:1021834 [1] NCCL INFO Trees [0] 314/308/-1->313->312 [1] 314/-1/-1->313->312
311: hkn0630:1598331:1598462 [3] NCCL INFO Trees [0] -1/-1/-1->311->310 [1] -1/-1/-1->311->310
454: hkn0736:1508244:1508370 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
458: hkn0801:2239916:2240014 [2] NCCL INFO Trees [0] 459/-1/-1->458->457 [1] 459/-1/-1->458->457
463: hkn0802:1200216:1200348 [3] NCCL INFO Trees [0] -1/-1/-1->463->462 [1] -1/-1/-1->463->462
313: hkn0631:1021707:1021834 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
311: hkn0630:1598331:1598462 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
455: hkn0736:1508224:1508372 [3] NCCL INFO Trees [0] -1/-1/-1->455->454 [1] -1/-1/-1->455->454
458: hkn0801:2239916:2240014 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 70: hkn0422:4153005:4153119 [2] NCCL INFO Channel 00 : 70[ca000] -> 69[4b000] via P2P/IPC/read
 42: hkn0414:1981511:1981611 [2] NCCL INFO Channel 00 : 42[ca000] -> 41[4b000] via P2P/IPC/read
462: hkn0802:1200232:1200339 [2] NCCL INFO Trees [0] 463/-1/-1->462->461 [1] 463/-1/-1->462->461
 54: hkn0418:1869045:1869174 [2] NCCL INFO Channel 00 : 54[ca000] -> 53[4b000] via P2P/IPC/read
315: hkn0631:1021715:1021825 [3] NCCL INFO Trees [0] -1/-1/-1->315->314 [1] -1/-1/-1->315->314
455: hkn0736:1508224:1508372 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
449: hkn0734:1156453:1156552 [1] NCCL INFO Trees [0] 450/416/-1->449->448 [1] 450/-1/-1->449->448
463: hkn0802:1200216:1200348 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
315: hkn0631:1021715:1021825 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
310: hkn0630:1598359:1598459 [2] NCCL INFO Trees [0] 311/-1/-1->310->309 [1] 311/-1/-1->310->309
310: hkn0630:1598359:1598459 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
456: hkn0801:2239904:2240015 [0] NCCL INFO Trees [0] 457/460/-1->456->465 [1] 457/-1/-1->456->453
445: hkn0733:1389278:1389388 [1] NCCL INFO Trees [0] 446/-1/-1->445->444 [1] 446/476/-1->445->444
460: hkn0802:1200224:1200344 [0] NCCL INFO Trees [0] 461/-1/-1->460->456 [1] 461/452/-1->460->476
460: hkn0802:1200224:1200344 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
316: hkn0632:1758503:1758621 [0] NCCL INFO Trees [0] 317/-1/-1->316->312 [1] 317/284/-1->316->380
 74: hkn0423:1704821:1704920 [2] NCCL INFO Channel 00 : 74[ca000] -> 73[4b000] via P2P/IPC/read
312: hkn0631:1021735:1021830 [0] NCCL INFO Trees [0] 313/316/-1->312->304 [1] 313/-1/-1->312->309
312: hkn0631:1021735:1021830 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
308: hkn0630:1598339:1598456 [0] NCCL INFO Trees [0] 309/-1/-1->308->313 [1] 309/304/-1->308->301
457: hkn0801:2239896:2240017 [1] NCCL INFO Trees [0] 458/452/-1->457->456 [1] 458/-1/-1->457->456
 46: hkn0415:2496333:2496437 [2] NCCL INFO Channel 00 : 46[ca000] -> 45[4b000] via P2P/IPC/read
446: hkn0733:1389290:1389387 [2] NCCL INFO Trees [0] 447/-1/-1->446->445 [1] 447/-1/-1->446->445
446: hkn0733:1389290:1389387 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
450: hkn0734:1156441:1156545 [2] NCCL INFO Trees [0] 451/-1/-1->450->449 [1] 451/-1/-1->450->449
461: hkn0802:1200244:1200347 [1] NCCL INFO Trees [0] 462/-1/-1->461->460 [1] 462/468/-1->461->460
461: hkn0802:1200244:1200347 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
316: hkn0632:1758503:1758621 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
314: hkn0631:1021723:1021832 [2] NCCL INFO Trees [0] 315/-1/-1->314->313 [1] 315/-1/-1->314->313
314: hkn0631:1021723:1021832 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
309: hkn0630:1598347:1598454 [1] NCCL INFO Trees [0] 310/-1/-1->309->308 [1] 310/312/-1->309->308
309: hkn0630:1598347:1598454 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
453: hkn0736:1508232:1508369 [1] NCCL INFO Trees [0] 454/-1/-1->453->452 [1] 454/456/-1->453->452
459: hkn0801:2239888:2240016 [3] NCCL INFO Trees [0] -1/-1/-1->459->458 [1] -1/-1/-1->459->458
445: hkn0733:1389278:1389388 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
449: hkn0734:1156453:1156552 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
462: hkn0802:1200232:1200339 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
318: hkn0632:1758495:1758618 [2] NCCL INFO Trees [0] 319/-1/-1->318->317 [1] 319/-1/-1->318->317
308: hkn0630:1598339:1598456 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
453: hkn0736:1508232:1508369 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
456: hkn0801:2239904:2240015 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
450: hkn0734:1156441:1156545 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
318: hkn0632:1758495:1758618 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
321: hkn0633:1526230:1526356 [1] NCCL INFO Trees [0] 322/288/-1->321->320 [1] 322/-1/-1->321->320
457: hkn0801:2239896:2240017 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
447: hkn0733:1389269:1389383 [3] NCCL INFO Trees [0] -1/-1/-1->447->446 [1] -1/-1/-1->447->446
451: hkn0734:1156425:1156546 [3] NCCL INFO Trees [0] -1/-1/-1->451->450 [1] -1/-1/-1->451->450
317: hkn0632:1758522:1758616 [1] NCCL INFO Trees [0] 318/-1/-1->317->316 [1] 318/348/-1->317->316
 26: hkn0410:1159602:1159714 [2] NCCL INFO Channel 01 : 26[ca000] -> 25[4b000] via P2P/IPC/read
443: hkn0732:1211551:1211659 [3] NCCL INFO Trees [0] -1/-1/-1->443->442 [1] -1/-1/-1->443->442
443: hkn0732:1211551:1211659 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
459: hkn0801:2239888:2240016 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
447: hkn0733:1389269:1389383 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
451: hkn0734:1156425:1156546 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 66: hkn0421:2180592:2180858 [2] NCCL INFO Channel 00 : 66[ca000] -> 65[4b000] via P2P/IPC/read
319: hkn0632:1758511:1758619 [3] NCCL INFO Trees [0] -1/-1/-1->319->318 [1] -1/-1/-1->319->318
444: hkn0733:1389270:1389389 [0] NCCL INFO Trees [0] 445/-1/-1->444->440 [1] 445/412/-1->444->381
448: hkn0734:1156433:1156551 [0] NCCL INFO Trees [0] 449/480/-1->448->384 [1] 449/-1/-1->448->452
317: hkn0632:1758522:1758616 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 38: hkn0413:2366608:2366707 [2] NCCL INFO Channel 01 : 38[ca000] -> 37[4b000] via P2P/IPC/read
448: hkn0734:1156433:1156551 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
319: hkn0632:1758511:1758619 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 94: hkn0428:667247:667347 [2] NCCL INFO Channel 00 : 94[ca000] -> 93[4b000] via P2P/IPC/read
322: hkn0633:1526218:1526355 [2] NCCL INFO Trees [0] 323/-1/-1->322->321 [1] 323/-1/-1->322->321
 30: hkn0411:2315763:2315863 [2] NCCL INFO Channel 01 : 30[ca000] -> 29[4b000] via P2P/IPC/read
 58: hkn0419:1544203:1544299 [2] NCCL INFO Channel 01 : 58[ca000] -> 57[4b000] via P2P/IPC/read
 78: hkn0424:2947862:2947966 [2] NCCL INFO Channel 00 : 78[ca000] -> 77[4b000] via P2P/IPC/read
321: hkn0633:1526230:1526356 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
441: hkn0732:1211535:1211667 [1] NCCL INFO Trees [0] 442/436/-1->441->440 [1] 442/-1/-1->441->440
444: hkn0733:1389270:1389389 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 90: hkn0427:1135009:1135135 [2] NCCL INFO Channel 00 : 90[ca000] -> 89[4b000] via P2P/IPC/read
324: hkn0634:1520769:1520870 [0] NCCL INFO Trees [0] 325/-1/-1->324->329 [1] 325/320/-1->324->332
324: hkn0634:1520769:1520870 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
322: hkn0633:1526218:1526355 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
442: hkn0732:1211543:1211663 [2] NCCL INFO Trees [0] 443/-1/-1->442->441 [1] 443/-1/-1->442->441
442: hkn0732:1211543:1211663 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 82: hkn0425:2083927:2084031 [2] NCCL INFO Channel 00 : 82[ca000] -> 81[4b000] via P2P/IPC/read
 34: hkn0412:2262277:2262396 [2] NCCL INFO Channel 01 : 34[ca000] -> 33[4b000] via P2P/IPC/read
325: hkn0634:1520753:1520864 [1] NCCL INFO Trees [0] 326/-1/-1->325->324 [1] 326/328/-1->325->324
323: hkn0633:1526210:1526349 [3] NCCL INFO Trees [0] -1/-1/-1->323->322 [1] -1/-1/-1->323->322
441: hkn0732:1211535:1211667 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
452: hkn0736:1508216:1508371 [0] NCCL INFO Trees [0] 453/-1/-1->452->457 [1] 453/448/-1->452->460
 18: hkn0408:2890646:2890768 [2] NCCL INFO Channel 00 : 18[ca000] -> 17[4b000] via P2P/IPC/read
326: hkn0634:1520761:1520867 [2] NCCL INFO Trees [0] 327/-1/-1->326->325 [1] 327/-1/-1->326->325
326: hkn0634:1520761:1520867 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
323: hkn0633:1526210:1526349 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
452: hkn0736:1508216:1508371 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
325: hkn0634:1520753:1520864 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
320: hkn0633:1526202:1526350 [0] NCCL INFO Trees [0] 321/352/-1->320->385 [1] 321/-1/-1->320->324
320: hkn0633:1526202:1526350 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
327: hkn0634:1520781:1520863 [3] NCCL INFO Trees [0] -1/-1/-1->327->326 [1] -1/-1/-1->327->326
344: hkn0705:783129:783218 [0] NCCL INFO Trees [0] 345/348/-1->344->336 [1] 345/-1/-1->344->341
327: hkn0634:1520781:1520863 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 54: hkn0418:1869045:1869174 [2] NCCL INFO Channel 01 : 54[ca000] -> 53[4b000] via P2P/IPC/read
347: hkn0705:783109:783209 [3] NCCL INFO Trees [0] -1/-1/-1->347->346 [1] -1/-1/-1->347->346
353: hkn0707:4019808:4019912 [1] NCCL INFO Trees [0] 354/336/-1->353->352 [1] 354/-1/-1->353->352
344: hkn0705:783129:783218 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 62: hkn0420:3210093:3210219 [2] NCCL INFO Channel 01 : 62[ca000] -> 61[4b000] via P2P/IPC/read
363: hkn0710:355437:355557 [3] NCCL INFO Trees [0] -1/-1/-1->363->362 [1] -1/-1/-1->363->362
348: hkn0706:752164:752267 [0] NCCL INFO Trees [0] 349/-1/-1->348->344 [1] 349/332/-1->348->317
366: hkn0711:583820:583927 [2] NCCL INFO Trees [0] 367/-1/-1->366->365 [1] 367/-1/-1->366->365
347: hkn0705:783109:783209 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
330: hkn0635:1225453:1225598 [2] NCCL INFO Trees [0] 331/-1/-1->330->329 [1] 331/-1/-1->330->329
 70: hkn0422:4153005:4153119 [2] NCCL INFO Channel 01 : 70[ca000] -> 69[4b000] via P2P/IPC/read
366: hkn0711:583820:583927 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
333: hkn0636:1654159:1654274 [1] NCCL INFO Trees [0] 334/-1/-1->333->332 [1] 334/340/-1->333->332
345: hkn0705:783117:783216 [1] NCCL INFO Trees [0] 346/340/-1->345->344 [1] 346/-1/-1->345->344
351: hkn0706:752152:752261 [3] NCCL INFO Trees [0] -1/-1/-1->351->350 [1] -1/-1/-1->351->350
355: hkn0707:4019792:4019918 [3] NCCL INFO Trees [0] -1/-1/-1->355->354 [1] -1/-1/-1->355->354
358: hkn0708:413122:413219 [2] NCCL INFO Trees [0] 359/-1/-1->358->357 [1] 359/-1/-1->358->357
333: hkn0636:1654159:1654274 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
346: hkn0705:783101:783217 [2] NCCL INFO Trees [0] 347/-1/-1->346->345 [1] 347/-1/-1->346->345
346: hkn0705:783101:783217 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
348: hkn0706:752164:752267 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
353: hkn0707:4019808:4019912 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
358: hkn0708:413122:413219 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
341: hkn0704:791903:792016 [1] NCCL INFO Trees [0] 342/-1/-1->341->340 [1] 342/344/-1->341->340
364: hkn0711:583800:583921 [0] NCCL INFO Trees [0] 365/-1/-1->364->360 [1] 365/356/-1->364->349
332: hkn0636:1654151:1654265 [0] NCCL INFO Trees [0] 333/-1/-1->332->328 [1] 333/324/-1->332->348
345: hkn0705:783117:783216 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
351: hkn0706:752152:752261 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
355: hkn0707:4019792:4019918 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
356: hkn0708:413102:413217 [0] NCCL INFO Trees [0] 357/-1/-1->356->361 [1] 357/352/-1->356->364
356: hkn0708:413102:413217 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
365: hkn0711:583808:583920 [1] NCCL INFO Trees [0] 366/-1/-1->365->364 [1] 366/372/-1->365->364
365: hkn0711:583808:583920 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
332: hkn0636:1654151:1654265 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
338: hkn0703:740952:741043 [2] NCCL INFO Trees [0] 339/-1/-1->338->337 [1] 339/-1/-1->338->337
363: hkn0710:355437:355557 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
349: hkn0706:752136:752262 [1] NCCL INFO Trees [0] 350/-1/-1->349->348 [1] 350/364/-1->349->348
354: hkn0707:4019820:4019919 [2] NCCL INFO Trees [0] 355/-1/-1->354->353 [1] 355/-1/-1->354->353
330: hkn0635:1225453:1225598 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
341: hkn0704:791903:792016 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
367: hkn0711:583792:583925 [3] NCCL INFO Trees [0] -1/-1/-1->367->366 [1] -1/-1/-1->367->366
367: hkn0711:583792:583925 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
334: hkn0636:1654143:1654268 [2] NCCL INFO Trees [0] 335/-1/-1->334->333 [1] 335/-1/-1->334->333
338: hkn0703:740952:741043 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
350: hkn0706:752144:752268 [2] NCCL INFO Trees [0] 351/-1/-1->350->349 [1] 351/-1/-1->350->349
354: hkn0707:4019820:4019919 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
329: hkn0635:1225473:1225593 [1] NCCL INFO Trees [0] 330/324/-1->329->328 [1] 330/-1/-1->329->328
329: hkn0635:1225473:1225593 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
357: hkn0708:413110:413222 [1] NCCL INFO Trees [0] 358/-1/-1->357->356 [1] 358/360/-1->357->356
357: hkn0708:413110:413222 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
369: hkn0712:294968:295070 [1] NCCL INFO Trees [0] 370/360/-1->369->368 [1] 370/-1/-1->369->368
369: hkn0712:294968:295070 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
375: hkn0713:470140:470235 [3] NCCL INFO Trees [0] -1/-1/-1->375->374 [1] -1/-1/-1->375->374
343: hkn0704:791915:792018 [3] NCCL INFO Trees [0] -1/-1/-1->343->342 [1] -1/-1/-1->343->342
  6: hkn0404:1339274:1339395 [2] NCCL INFO Channel 00 : 6[ca000] -> 5[4b000] via P2P/IPC/read
364: hkn0711:583800:583921 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
334: hkn0636:1654143:1654268 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
336: hkn0703:740936:741046 [0] NCCL INFO Trees [0] 337/344/-1->336->353 [1] 337/-1/-1->336->340
361: hkn0710:355445:355552 [1] NCCL INFO Trees [0] 362/356/-1->361->360 [1] 362/-1/-1->361->360
349: hkn0706:752136:752262 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
352: hkn0707:4019800:4019913 [0] NCCL INFO Trees [0] 353/368/-1->352->320 [1] 353/-1/-1->352->356
331: hkn0635:1225445:1225601 [3] NCCL INFO Trees [0] -1/-1/-1->331->330 [1] -1/-1/-1->331->330
359: hkn0708:413094:413225 [3] NCCL INFO Trees [0] -1/-1/-1->359->358 [1] -1/-1/-1->359->358
440: hkn0732:1211563:1211665 [0] NCCL INFO Trees [0] 441/444/-1->440->432 [1] 441/-1/-1->440->437
375: hkn0713:470140:470235 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 42: hkn0414:1981511:1981611 [2] NCCL INFO Channel 01 : 42[ca000] -> 41[4b000] via P2P/IPC/read
342: hkn0704:791887:792017 [2] NCCL INFO Trees [0] 343/-1/-1->342->341 [1] 343/-1/-1->342->341
377: hkn0714:431907:432038 [1] NCCL INFO Trees [0] 378/372/-1->377->376 [1] 378/-1/-1->377->376
377: hkn0714:431907:432038 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
335: hkn0636:1654171:1654272 [3] NCCL INFO Trees [0] -1/-1/-1->335->334 [1] -1/-1/-1->335->334
336: hkn0703:740936:741046 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
362: hkn0710:355457:355550 [2] NCCL INFO Trees [0] 363/-1/-1->362->361 [1] 363/-1/-1->362->361
350: hkn0706:752144:752268 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
352: hkn0707:4019800:4019913 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
328: hkn0635:1225461:1225602 [0] NCCL INFO Trees [0] 329/332/-1->328->337 [1] 329/-1/-1->328->325
328: hkn0635:1225461:1225602 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
359: hkn0708:413094:413225 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
370: hkn0712:294940:295065 [2] NCCL INFO Trees [0] 371/-1/-1->370->369 [1] 371/-1/-1->370->369
440: hkn0732:1211563:1211665 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 82: hkn0425:2083927:2084031 [2] NCCL INFO Channel 01 : 82[ca000] -> 81[4b000] via P2P/IPC/read
373: hkn0713:470120:470234 [1] NCCL INFO Trees [0] 374/-1/-1->373->372 [1] 374/376/-1->373->372
 66: hkn0421:2180592:2180858 [2] NCCL INFO Channel 01 : 66[ca000] -> 65[4b000] via P2P/IPC/read
343: hkn0704:791915:792018 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
379: hkn0714:431935:432037 [3] NCCL INFO Trees [0] -1/-1/-1->379->378 [1] -1/-1/-1->379->378
379: hkn0714:431935:432037 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
381: hkn0715:401780:401901 [1] NCCL INFO Trees [0] 382/-1/-1->381->380 [1] 382/444/-1->381->380
335: hkn0636:1654171:1654272 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
339: hkn0703:740935:741041 [3] NCCL INFO Trees [0] -1/-1/-1->339->338 [1] -1/-1/-1->339->338
361: hkn0710:355445:355552 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 86: hkn0426:813946:814074 [2] NCCL INFO Channel 00 : 86[ca000] -> 85[4b000] via P2P/IPC/read
331: hkn0635:1225445:1225601 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
371: hkn0712:294948:295061 [3] NCCL INFO Trees [0] -1/-1/-1->371->370 [1] -1/-1/-1->371->370
371: hkn0712:294948:295061 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 46: hkn0415:2496333:2496437 [2] NCCL INFO Channel 01 : 46[ca000] -> 45[4b000] via P2P/IPC/read
374: hkn0713:470128:470236 [2] NCCL INFO Trees [0] 375/-1/-1->374->373 [1] 375/-1/-1->374->373
374: hkn0713:470128:470236 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
391: hkn0717:4187523:4187653 [3] NCCL INFO Trees [0] -1/-1/-1->391->390 [1] -1/-1/-1->391->390
342: hkn0704:791887:792017 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
376: hkn0714:431923:432030 [0] NCCL INFO Trees [0] 377/380/-1->376->368 [1] 377/-1/-1->376->373
376: hkn0714:431923:432030 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
380: hkn0715:401772:401896 [0] NCCL INFO Trees [0] 381/-1/-1->380->376 [1] 381/316/-1->380->253
337: hkn0703:740940:741049 [1] NCCL INFO Trees [0] 338/328/-1->337->336 [1] 338/-1/-1->337->336
337: hkn0703:740940:741049 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 74: hkn0423:1704821:1704920 [2] NCCL INFO Channel 01 : 74[ca000] -> 73[4b000] via P2P/IPC/read
362: hkn0710:355457:355550 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
385: hkn0716:108390:108502 [1] NCCL INFO Trees [0] 386/320/-1->385->384 [1] 386/-1/-1->385->384
368: hkn0712:294956:295068 [0] NCCL INFO Trees [0] 369/376/-1->368->352 [1] 369/-1/-1->368->372
368: hkn0712:294956:295068 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
392: hkn0718:3916913:3917022 [0] NCCL INFO Trees [0] 393/396/-1->392->401 [1] 393/-1/-1->392->389
 14: hkn0407:1816159:1816274 [2] NCCL INFO Channel 00 : 14[ca000] -> 13[4b000] via P2P/IPC/read
373: hkn0713:470120:470234 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 18: hkn0408:2890646:2890768 [2] NCCL INFO Channel 01 : 18[ca000] -> 17[4b000] via P2P/IPC/read
389: hkn0717:4187531:4187655 [1] NCCL INFO Trees [0] 390/-1/-1->389->388 [1] 390/392/-1->389->388
389: hkn0717:4187531:4187655 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
340: hkn0704:791895:792019 [0] NCCL INFO Trees [0] 341/-1/-1->340->345 [1] 341/336/-1->340->333
340: hkn0704:791895:792019 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
378: hkn0714:431915:432039 [2] NCCL INFO Trees [0] 379/-1/-1->378->377 [1] 379/-1/-1->378->377
378: hkn0714:431915:432039 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
381: hkn0715:401780:401901 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
339: hkn0703:740935:741041 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
360: hkn0710:355429:355558 [0] NCCL INFO Trees [0] 361/364/-1->360->369 [1] 361/-1/-1->360->357
387: hkn0716:108382:108508 [3] NCCL INFO Trees [0] -1/-1/-1->387->386 [1] -1/-1/-1->387->386
 10: hkn0405:3206770:3206895 [2] NCCL INFO Channel 00 : 10[ca000] -> 9[4b000] via P2P/IPC/read
370: hkn0712:294940:295065 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
392: hkn0718:3916913:3917022 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  2: hkn0403:1763934:1764351 [2] NCCL INFO Channel 00 : 2[ca000] -> 1[4b000] via P2P/IPC/read
390: hkn0717:4187539:4187652 [2] NCCL INFO Trees [0] 391/-1/-1->390->389 [1] 391/-1/-1->390->389
380: hkn0715:401772:401896 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
399: hkn0719:1305603:1305721 [3] NCCL INFO Trees [0] -1/-1/-1->399->398 [1] -1/-1/-1->399->398
360: hkn0710:355429:355558 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 98: hkn0501:1327785:1327898 [2] NCCL INFO Channel 00 : 98[ca000] -> 97[4b000] via P2P/IPC/read
402: hkn0720:5397:5643 [2] NCCL INFO Trees [0] 403/-1/-1->402->401 [1] 403/-1/-1->402->401
385: hkn0716:108390:108502 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
395: hkn0718:3916925:3917028 [3] NCCL INFO Trees [0] -1/-1/-1->395->394 [1] -1/-1/-1->395->394
395: hkn0718:3916925:3917028 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
372: hkn0713:470112:470238 [0] NCCL INFO Trees [0] 373/-1/-1->372->377 [1] 373/368/-1->372->365
391: hkn0717:4187523:4187653 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
382: hkn0715:401788:401899 [2] NCCL INFO Trees [0] 383/-1/-1->382->381 [1] 383/-1/-1->382->381
382: hkn0715:401788:401899 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
399: hkn0719:1305603:1305721 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
403: hkn0720:5377:5646 [3] NCCL INFO Trees [0] -1/-1/-1->403->402 [1] -1/-1/-1->403->402
403: hkn0720:5377:5646 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
387: hkn0716:108382:108508 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
393: hkn0718:3916897:3917023 [1] NCCL INFO Trees [0] 394/388/-1->393->392 [1] 394/-1/-1->393->392
393: hkn0718:3916897:3917023 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
130: hkn0509:3124308:3124406 [2] NCCL INFO Channel 00 : 130[ca000] -> 129[4b000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
390: hkn0717:4187539:4187652 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
383: hkn0715:401800:401893 [3] NCCL INFO Trees [0] -1/-1/-1->383->382 [1] -1/-1/-1->383->382
383: hkn0715:401800:401893 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
397: hkn0719:1305595:1305722 [1] NCCL INFO Trees [0] 398/-1/-1->397->396 [1] 398/404/-1->397->396
397: hkn0719:1305595:1305722 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
401: hkn0720:5385:5649 [1] NCCL INFO Trees [0] 402/392/-1->401->400 [1] 402/-1/-1->401->400
 90: hkn0427:1135009:1135135 [2] NCCL INFO Channel 01 : 90[ca000] -> 89[4b000] via P2P/IPC/read
384: hkn0716:108410:108503 [0] NCCL INFO Trees [0] 385/448/-1->384->256 [1] 385/-1/-1->384->388
394: hkn0718:3916905:3917029 [2] NCCL INFO Trees [0] 395/-1/-1->394->393 [1] 395/-1/-1->394->393
394: hkn0718:3916905:3917029 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
388: hkn0717:4187551:4187658 [0] NCCL INFO Trees [0] 389/-1/-1->388->393 [1] 389/384/-1->388->396
405: hkn0721:2299079:2299192 [1] NCCL INFO Trees [0] 406/-1/-1->405->404 [1] 406/408/-1->405->404
398: hkn0719:1305623:1305723 [2] NCCL INFO Trees [0] 399/-1/-1->398->397 [1] 399/-1/-1->398->397
398: hkn0719:1305623:1305723 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
402: hkn0720:5397:5643 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
386: hkn0716:108398:108509 [2] NCCL INFO Trees [0] 387/-1/-1->386->385 [1] 387/-1/-1->386->385
431: hkn0728:1323883:1324000 [3] NCCL INFO Trees [0] -1/-1/-1->431->430 [1] -1/-1/-1->431->430
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
388: hkn0717:4187551:4187658 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
396: hkn0719:1305611:1305724 [0] NCCL INFO Trees [0] 397/-1/-1->396->392 [1] 397/388/-1->396->412
396: hkn0719:1305611:1305724 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
401: hkn0720:5385:5649 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
384: hkn0716:108410:108503 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
438: hkn0731:1386633:1386740 [2] NCCL INFO Trees [0] 439/-1/-1->438->437 [1] 439/-1/-1->438->437
431: hkn0728:1323883:1324000 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
432: hkn0730:1401606:1401733 [0] NCCL INFO Trees [0] 433/440/-1->432->416 [1] 433/-1/-1->432->436
400: hkn0720:5369:5640 [0] NCCL INFO Trees [0] 401/408/-1->400->417 [1] 401/-1/-1->400->404
386: hkn0716:108398:108509 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
438: hkn0731:1386633:1386740 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
434: hkn0730:1401634:1401726 [2] NCCL INFO Trees [0] 435/-1/-1->434->433 [1] 435/-1/-1->434->433
406: hkn0721:2299071:2299198 [2] NCCL INFO Trees [0] 407/-1/-1->406->405 [1] 407/-1/-1->406->405
400: hkn0720:5369:5640 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
432: hkn0730:1401606:1401733 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
405: hkn0721:2299079:2299192 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
439: hkn0731:1386625:1386746 [3] NCCL INFO Trees [0] -1/-1/-1->439->438 [1] -1/-1/-1->439->438
434: hkn0730:1401634:1401726 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
406: hkn0721:2299071:2299198 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
436: hkn0731:1386645:1386747 [0] NCCL INFO Trees [0] 437/-1/-1->436->441 [1] 437/432/-1->436->429
436: hkn0731:1386645:1386747 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
435: hkn0730:1401622:1401732 [3] NCCL INFO Trees [0] -1/-1/-1->435->434 [1] -1/-1/-1->435->434
407: hkn0721:2299099:2299196 [3] NCCL INFO Trees [0] -1/-1/-1->407->406 [1] -1/-1/-1->407->406
437: hkn0731:1386617:1386741 [1] NCCL INFO Trees [0] 438/-1/-1->437->436 [1] 438/440/-1->437->436
437: hkn0731:1386617:1386741 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
435: hkn0730:1401622:1401732 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
404: hkn0721:2299087:2299193 [0] NCCL INFO Trees [0] 405/-1/-1->404->409 [1] 405/400/-1->404->397
404: hkn0721:2299087:2299193 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
439: hkn0731:1386625:1386746 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
429: hkn0728:1323903:1323996 [1] NCCL INFO Trees [0] 430/-1/-1->429->428 [1] 430/436/-1->429->428
429: hkn0728:1323903:1323996 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
407: hkn0721:2299099:2299196 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
134: hkn0510:2761956:2762044 [2] NCCL INFO Channel 00 : 134[ca000] -> 133[4b000] via P2P/IPC/read
 78: hkn0424:2947862:2947966 [2] NCCL INFO Channel 01 : 78[ca000] -> 77[4b000] via P2P/IPC/read
430: hkn0728:1323891:1323997 [2] NCCL INFO Trees [0] 431/-1/-1->430->429 [1] 431/-1/-1->430->429
114: hkn0505:2303656:2303781 [2] NCCL INFO Channel 00 : 114[ca000] -> 113[4b000] via P2P/IPC/read
110: hkn0504:40723:40837 [2] NCCL INFO Channel 00 : 110[ca000] -> 109[4b000] via P2P/IPC/read
430: hkn0728:1323891:1323997 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
409: hkn0723:207893:208068 [1] NCCL INFO Trees [0] 410/404/-1->409->408 [1] 410/-1/-1->409->408
413: hkn0724:1715874:1715982 [1] NCCL INFO Trees [0] 414/-1/-1->413->412 [1] 414/428/-1->413->412
409: hkn0723:207893:208068 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 10: hkn0405:3206770:3206895 [2] NCCL INFO Channel 01 : 10[ca000] -> 9[4b000] via P2P/IPC/read
 14: hkn0407:1816159:1816274 [2] NCCL INFO Channel 01 : 14[ca000] -> 13[4b000] via P2P/IPC/read
413: hkn0724:1715874:1715982 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
416: hkn0725:3111837:3111934 [0] NCCL INFO Trees [0] 417/432/-1->416->449 [1] 417/-1/-1->416->420
408: hkn0723:207901:208066 [0] NCCL INFO Trees [0] 409/412/-1->408->400 [1] 409/-1/-1->408->405
414: hkn0724:1715886:1715987 [2] NCCL INFO Trees [0] 415/-1/-1->414->413 [1] 415/-1/-1->414->413
126: hkn0508:3139025:3139135 [2] NCCL INFO Channel 00 : 126[ca000] -> 125[4b000] via P2P/IPC/read
 69: hkn0422:4153025:4153124 [1] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
408: hkn0723:207901:208066 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
412: hkn0724:1715866:1715984 [0] NCCL INFO Trees [0] 413/-1/-1->412->408 [1] 413/396/-1->412->444
150: hkn0514:2950610:2950728 [2] NCCL INFO Channel 00 : 150[ca000] -> 149[4b000] via P2P/IPC/read
416: hkn0725:3111837:3111934 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 94: hkn0428:667247:667347 [2] NCCL INFO Channel 01 : 94[ca000] -> 93[4b000] via P2P/IPC/read
  2: hkn0403:1763934:1764351 [2] NCCL INFO Channel 01 : 2[ca000] -> 1[4b000] via P2P/IPC/read
410: hkn0723:207909:208065 [2] NCCL INFO Trees [0] 411/-1/-1->410->409 [1] 411/-1/-1->410->409
410: hkn0723:207909:208065 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
414: hkn0724:1715886:1715987 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
102: hkn0502:228938:229065 [2] NCCL INFO Channel 00 : 102[ca000] -> 101[4b000] via P2P/IPC/read
419: hkn0725:3111817:3111928 [3] NCCL INFO Trees [0] -1/-1/-1->419->418 [1] -1/-1/-1->419->418
 50: hkn0417:2267531:2267655 [2] NCCL INFO Channel 00 : 50[ca000] -> 49[4b000] via P2P/IPC/read
412: hkn0724:1715866:1715984 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
419: hkn0725:3111817:3111928 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 86: hkn0426:813946:814074 [2] NCCL INFO Channel 01 : 86[ca000] -> 85[4b000] via P2P/IPC/read
420: hkn0726:1548019:1548119 [0] NCCL INFO Trees [0] 421/-1/-1->420->425 [1] 421/416/-1->420->428
415: hkn0724:1715858:1715983 [3] NCCL INFO Trees [0] -1/-1/-1->415->414 [1] -1/-1/-1->415->414
  6: hkn0404:1339274:1339395 [2] NCCL INFO Channel 01 : 6[ca000] -> 5[4b000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Trees [0] 418/400/-1->417->416 [1] 418/-1/-1->417->416
106: hkn0503:2899580:2899695 [2] NCCL INFO Channel 00 : 106[ca000] -> 105[4b000] via P2P/IPC/read
422: hkn0726:1548007:1548114 [2] NCCL INFO Trees [0] 423/-1/-1->422->421 [1] 423/-1/-1->422->421
142: hkn0512:3044033:3044156 [2] NCCL INFO Channel 00 : 142[ca000] -> 141[4b000] via P2P/IPC/read
411: hkn0723:207921:208060 [3] NCCL INFO Trees [0] -1/-1/-1->411->410 [1] -1/-1/-1->411->410
415: hkn0724:1715858:1715983 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
418: hkn0725:3111809:3111929 [2] NCCL INFO Trees [0] 419/-1/-1->418->417 [1] 419/-1/-1->418->417
420: hkn0726:1548019:1548119 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
428: hkn0728:1323875:1324003 [0] NCCL INFO Trees [0] 429/-1/-1->428->424 [1] 429/420/-1->428->413
428: hkn0728:1323875:1324003 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
411: hkn0723:207921:208060 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
417: hkn0725:3111825:3111935 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
146: hkn0513:3012852:3012957 [2] NCCL INFO Channel 00 : 146[ca000] -> 145[4b000] via P2P/IPC/read
118: hkn0506:837941:838072 [2] NCCL INFO Channel 00 : 118[ca000] -> 117[4b000] via P2P/IPC/read
422: hkn0726:1548007:1548114 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
418: hkn0725:3111809:3111929 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
421: hkn0726:1547991:1548116 [1] NCCL INFO Trees [0] 422/-1/-1->421->420 [1] 422/424/-1->421->420
158: hkn0516:2915855:2915974 [2] NCCL INFO Channel 00 : 158[ca000] -> 157[4b000] via P2P/IPC/read
423: hkn0726:1547999:1548115 [3] NCCL INFO Trees [0] -1/-1/-1->423->422 [1] -1/-1/-1->423->422
423: hkn0726:1547999:1548115 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
421: hkn0726:1547991:1548116 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
424: hkn0727:1345692:1345788 [0] NCCL INFO Trees [0] 425/428/-1->424->433 [1] 425/-1/-1->424->421
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
122: hkn0507:3186958:3187070 [2] NCCL INFO Channel 00 : 122[ca000] -> 121[4b000] via P2P/IPC/read
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
130: hkn0509:3124308:3124406 [2] NCCL INFO Channel 01 : 130[ca000] -> 129[4b000] via P2P/IPC/read
425: hkn0727:1345672:1345787 [1] NCCL INFO Trees [0] 426/420/-1->425->424 [1] 426/-1/-1->425->424
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
134: hkn0510:2761956:2762044 [2] NCCL INFO Channel 01 : 134[ca000] -> 133[4b000] via P2P/IPC/read
 98: hkn0501:1327785:1327898 [2] NCCL INFO Channel 01 : 98[ca000] -> 97[4b000] via P2P/IPC/read
426: hkn0727:1345664:1345786 [2] NCCL INFO Trees [0] 427/-1/-1->426->425 [1] 427/-1/-1->426->425
433: hkn0730:1401614:1401727 [1] NCCL INFO Trees [0] 434/424/-1->433->432 [1] 434/-1/-1->433->432
427: hkn0727:1345680:1345791 [3] NCCL INFO Trees [0] -1/-1/-1->427->426 [1] -1/-1/-1->427->426
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
433: hkn0730:1401614:1401727 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
424: hkn0727:1345692:1345788 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
425: hkn0727:1345672:1345787 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
506: hkn0815:395000:395128 [2] NCCL INFO Channel 00 : 506[ca000] -> 505[4b000] via P2P/IPC/read
170: hkn0523:1547969:1548086 [2] NCCL INFO Channel 00 : 170[ca000] -> 169[4b000] via P2P/IPC/read
426: hkn0727:1345664:1345786 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
427: hkn0727:1345680:1345791 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
102: hkn0502:228938:229065 [2] NCCL INFO Channel 01 : 102[ca000] -> 101[4b000] via P2P/IPC/read
126: hkn0508:3139025:3139135 [2] NCCL INFO Channel 01 : 126[ca000] -> 125[4b000] via P2P/IPC/read
162: hkn0520:2712749:2712876 [2] NCCL INFO Channel 00 : 162[ca000] -> 161[4b000] via P2P/IPC/read
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
142: hkn0512:3044033:3044156 [2] NCCL INFO Channel 01 : 142[ca000] -> 141[4b000] via P2P/IPC/read
154: hkn0515:2896695:2896792 [2] NCCL INFO Channel 00 : 154[ca000] -> 153[4b000] via P2P/IPC/read
 21: hkn0409:2585543:2585692 [1] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
 37: hkn0413:2366588:2366711 [1] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
114: hkn0505:2303656:2303781 [2] NCCL INFO Channel 01 : 114[ca000] -> 113[4b000] via P2P/IPC/read
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
106: hkn0503:2899580:2899695 [2] NCCL INFO Channel 01 : 106[ca000] -> 105[4b000] via P2P/IPC/read
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
110: hkn0504:40723:40837 [2] NCCL INFO Channel 01 : 110[ca000] -> 109[4b000] via P2P/IPC/read
146: hkn0513:3012852:3012957 [2] NCCL INFO Channel 01 : 146[ca000] -> 145[4b000] via P2P/IPC/read
 50: hkn0417:2267531:2267655 [2] NCCL INFO Channel 01 : 50[ca000] -> 49[4b000] via P2P/IPC/read
138: hkn0511:3066294:3066390 [2] NCCL INFO Channel 00 : 138[ca000] -> 137[4b000] via P2P/IPC/read
178: hkn0525:986708:986837 [2] NCCL INFO Channel 00 : 178[ca000] -> 177[4b000] via P2P/IPC/read
182: hkn0526:1428290:1428419 [2] NCCL INFO Channel 00 : 182[ca000] -> 181[4b000] via P2P/IPC/read
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
186: hkn0527:1348830:1348950 [2] NCCL INFO Channel 00 : 186[ca000] -> 185[4b000] via P2P/IPC/read
118: hkn0506:837941:838072 [2] NCCL INFO Channel 01 : 118[ca000] -> 117[4b000] via P2P/IPC/read
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
510: hkn0816:375512:375637 [2] NCCL INFO Channel 00 : 510[ca000] -> 509[4b000] via P2P/IPC/read
494: hkn0810:939437:939537 [2] NCCL INFO Channel 00 : 494[ca000] -> 493[4b000] via P2P/IPC/read
498: hkn0812:693667:693793 [2] NCCL INFO Channel 00 : 498[ca000] -> 497[4b000] via P2P/IPC/read
174: hkn0524:1133687:1133798 [2] NCCL INFO Channel 00 : 174[ca000] -> 173[4b000] via P2P/IPC/read
506: hkn0815:395000:395128 [2] NCCL INFO Channel 01 : 506[ca000] -> 505[4b000] via P2P/IPC/read
158: hkn0516:2915855:2915974 [2] NCCL INFO Channel 01 : 158[ca000] -> 157[4b000] via P2P/IPC/read
166: hkn0521:1197663:1197794 [2] NCCL INFO Channel 00 : 166[ca000] -> 165[4b000] via P2P/IPC/read
  5: hkn0404:1339266:1339391 [1] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
154: hkn0515:2896695:2896792 [2] NCCL INFO Channel 01 : 154[ca000] -> 153[4b000] via P2P/IPC/read
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
138: hkn0511:3066294:3066390 [2] NCCL INFO Channel 01 : 138[ca000] -> 137[4b000] via P2P/IPC/read
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
150: hkn0514:2950610:2950728 [2] NCCL INFO Channel 01 : 150[ca000] -> 149[4b000] via P2P/IPC/read
190: hkn0528:1301582:1301674 [2] NCCL INFO Channel 00 : 190[ca000] -> 189[4b000] via P2P/IPC/read
490: hkn0809:937230:937376 [2] NCCL INFO Channel 00 : 490[ca000] -> 489[4b000] via P2P/IPC/read
 85: hkn0426:813954:814076 [1] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
122: hkn0507:3186958:3187070 [2] NCCL INFO Channel 01 : 122[ca000] -> 121[4b000] via P2P/IPC/read
194: hkn0529:1540708:1540856 [2] NCCL INFO Channel 00 : 194[ca000] -> 193[4b000] via P2P/IPC/read
174: hkn0524:1133687:1133798 [2] NCCL INFO Channel 01 : 174[ca000] -> 173[4b000] via P2P/IPC/read
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
262: hkn0613:902573:902699 [2] NCCL INFO Channel 00 : 262[ca000] -> 261[4b000] via P2P/IPC/read
182: hkn0526:1428290:1428419 [2] NCCL INFO Channel 01 : 182[ca000] -> 181[4b000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
494: hkn0810:939437:939537 [2] NCCL INFO Channel 01 : 494[ca000] -> 493[4b000] via P2P/IPC/read
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
482: hkn0807:1018950:1019079 [2] NCCL INFO Channel 00 : 482[ca000] -> 481[4b000] via P2P/IPC/read
206: hkn0532:924599:924925 [2] NCCL INFO Channel 00 : 206[ca000] -> 205[4b000] via P2P/IPC/read
 53: hkn0418:1869083:1869169 [1] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
510: hkn0816:375512:375637 [2] NCCL INFO Channel 01 : 510[ca000] -> 509[4b000] via P2P/IPC/read
166: hkn0521:1197663:1197794 [2] NCCL INFO Channel 01 : 166[ca000] -> 165[4b000] via P2P/IPC/read
198: hkn0530:1258034:1258159 [2] NCCL INFO Channel 00 : 198[ca000] -> 197[4b000] via P2P/IPC/read
186: hkn0527:1348830:1348950 [2] NCCL INFO Channel 01 : 186[ca000] -> 185[4b000] via P2P/IPC/read
162: hkn0520:2712749:2712876 [2] NCCL INFO Channel 01 : 162[ca000] -> 161[4b000] via P2P/IPC/read
502: hkn0814:675720:675841 [2] NCCL INFO Channel 00 : 502[ca000] -> 501[4b000] via P2P/IPC/read
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
486: hkn0808:970577:970677 [2] NCCL INFO Channel 00 : 486[ca000] -> 485[4b000] via P2P/IPC/read
170: hkn0523:1547969:1548086 [2] NCCL INFO Channel 01 : 170[ca000] -> 169[4b000] via P2P/IPC/read
178: hkn0525:986708:986837 [2] NCCL INFO Channel 01 : 178[ca000] -> 177[4b000] via P2P/IPC/read
117: hkn0506:837969:838070 [1] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
210: hkn0534:1148280:1148416 [2] NCCL INFO Channel 00 : 210[ca000] -> 209[4b000] via P2P/IPC/read
190: hkn0528:1301582:1301674 [2] NCCL INFO Channel 01 : 190[ca000] -> 189[4b000] via P2P/IPC/read
254: hkn0611:709710:709819 [2] NCCL INFO Channel 00 : 254[ca000] -> 253[4b000] via P2P/IPC/read
108: hkn0504:40743:40838 [0] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
490: hkn0809:937230:937376 [2] NCCL INFO Channel 01 : 490[ca000] -> 489[4b000] via P2P/IPC/read
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
194: hkn0529:1540708:1540856 [2] NCCL INFO Channel 01 : 194[ca000] -> 193[4b000] via P2P/IPC/read
202: hkn0531:1230513:1230642 [2] NCCL INFO Channel 00 : 202[ca000] -> 201[4b000] via P2P/IPC/read
509: hkn0816:375500:375645 [1] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
266: hkn0615:414205:414319 [2] NCCL INFO Channel 00 : 266[ca000] -> 265[4b000] via P2P/IPC/read
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
478: hkn0806:1054238:1054345 [2] NCCL INFO Channel 00 : 478[ca000] -> 477[4b000] via P2P/IPC/read
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
470: hkn0804:1205535:1205629 [2] NCCL INFO Channel 00 : 470[ca000] -> 469[4b000] via P2P/IPC/read
214: hkn0535:2398869:2398986 [2] NCCL INFO Channel 00 : 214[ca000] -> 213[4b000] via P2P/IPC/read
498: hkn0812:693667:693793 [2] NCCL INFO Channel 01 : 498[ca000] -> 497[4b000] via P2P/IPC/read
258: hkn0612:916880:916979 [2] NCCL INFO Channel 00 : 258[ca000] -> 257[4b000] via P2P/IPC/read
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
274: hkn0617:2294558:2294701 [2] NCCL INFO Channel 00 : 274[ca000] -> 273[4b000] via P2P/IPC/read
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
482: hkn0807:1018950:1019079 [2] NCCL INFO Channel 01 : 482[ca000] -> 481[4b000] via P2P/IPC/read
206: hkn0532:924599:924925 [2] NCCL INFO Channel 01 : 206[ca000] -> 205[4b000] via P2P/IPC/read
508: hkn0816:375484:375639 [0] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
198: hkn0530:1258034:1258159 [2] NCCL INFO Channel 01 : 198[ca000] -> 197[4b000] via P2P/IPC/read
149: hkn0514:2950618:2950734 [1] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
474: hkn0805:1112002:1112122 [2] NCCL INFO Channel 00 : 474[ca000] -> 473[4b000] via P2P/IPC/read
278: hkn0621:1991488:1991585 [2] NCCL INFO Channel 00 : 278[ca000] -> 277[4b000] via P2P/IPC/read
270: hkn0616:404806:404907 [2] NCCL INFO Channel 00 : 270[ca000] -> 269[4b000] via P2P/IPC/read
486: hkn0808:970577:970677 [2] NCCL INFO Channel 01 : 486[ca000] -> 485[4b000] via P2P/IPC/read
246: hkn0608:485616:485737 [2] NCCL INFO Channel 00 : 246[ca000] -> 245[4b000] via P2P/IPC/read
254: hkn0611:709710:709819 [2] NCCL INFO Channel 01 : 254[ca000] -> 253[4b000] via P2P/IPC/read
210: hkn0534:1148280:1148416 [2] NCCL INFO Channel 01 : 210[ca000] -> 209[4b000] via P2P/IPC/read
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
262: hkn0613:902573:902699 [2] NCCL INFO Channel 01 : 262[ca000] -> 261[4b000] via P2P/IPC/read
202: hkn0531:1230513:1230642 [2] NCCL INFO Channel 01 : 202[ca000] -> 201[4b000] via P2P/IPC/read
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
109: hkn0504:40731:40842 [1] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
478: hkn0806:1054238:1054345 [2] NCCL INFO Channel 01 : 478[ca000] -> 477[4b000] via P2P/IPC/read
  1: hkn0403:1763954:1764350 [1] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
242: hkn0607:904266:904368 [2] NCCL INFO Channel 00 : 242[ca000] -> 241[4b000] via P2P/IPC/read
258: hkn0612:916880:916979 [2] NCCL INFO Channel 01 : 258[ca000] -> 257[4b000] via P2P/IPC/read
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
502: hkn0814:675720:675841 [2] NCCL INFO Channel 01 : 502[ca000] -> 501[4b000] via P2P/IPC/read
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
470: hkn0804:1205535:1205629 [2] NCCL INFO Channel 01 : 470[ca000] -> 469[4b000] via P2P/IPC/read
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
218: hkn0601:117591:117714 [2] NCCL INFO Channel 00 : 218[ca000] -> 217[4b000] via P2P/IPC/read
270: hkn0616:404806:404907 [2] NCCL INFO Channel 01 : 270[ca000] -> 269[4b000] via P2P/IPC/read
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
474: hkn0805:1112002:1112122 [2] NCCL INFO Channel 01 : 474[ca000] -> 473[4b000] via P2P/IPC/read
278: hkn0621:1991488:1991585 [2] NCCL INFO Channel 01 : 278[ca000] -> 277[4b000] via P2P/IPC/read
246: hkn0608:485616:485737 [2] NCCL INFO Channel 01 : 246[ca000] -> 245[4b000] via P2P/IPC/read
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
274: hkn0617:2294558:2294701 [2] NCCL INFO Channel 01 : 274[ca000] -> 273[4b000] via P2P/IPC/read
466: hkn0803:876456:876564 [2] NCCL INFO Channel 00 : 466[ca000] -> 465[4b000] via P2P/IPC/read
214: hkn0535:2398869:2398986 [2] NCCL INFO Channel 01 : 214[ca000] -> 213[4b000] via P2P/IPC/read
133: hkn0510:2761928:2762038 [1] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
298: hkn0627:1787836:1787925 [2] NCCL INFO Channel 00 : 298[ca000] -> 297[4b000] via P2P/IPC/read
234: hkn0605:711998:712112 [2] NCCL INFO Channel 00 : 234[ca000] -> 233[4b000] via P2P/IPC/read
222: hkn0602:3362295:3362554 [2] NCCL INFO Channel 00 : 222[ca000] -> 221[4b000] via P2P/IPC/read
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
176: hkn0525:986689:986834 [0] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
181: hkn0526:1428306:1428417 [1] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
266: hkn0615:414205:414319 [2] NCCL INFO Channel 01 : 266[ca000] -> 265[4b000] via P2P/IPC/read
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
177: hkn0525:986697:986833 [1] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
286: hkn0623:1872648:1872765 [2] NCCL INFO Channel 00 : 286[ca000] -> 285[4b000] via P2P/IPC/read
282: hkn0622:2020384:2020510 [2] NCCL INFO Channel 00 : 282[ca000] -> 281[4b000] via P2P/IPC/read
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
226: hkn0603:1413123:1413232 [2] NCCL INFO Channel 00 : 226[ca000] -> 225[4b000] via P2P/IPC/read
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
238: hkn0606:2371989:2372088 [2] NCCL INFO Channel 00 : 238[ca000] -> 237[4b000] via P2P/IPC/read
504: hkn0815:395016:395129 [0] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
230: hkn0604:689117:689240 [2] NCCL INFO Channel 00 : 230[ca000] -> 229[4b000] via P2P/IPC/read
290: hkn0624:1772838:1772944 [2] NCCL INFO Channel 00 : 290[ca000] -> 289[4b000] via P2P/IPC/read
505: hkn0815:395028:395124 [1] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
294: hkn0626:1298329:1298455 [2] NCCL INFO Channel 00 : 294[ca000] -> 293[4b000] via P2P/IPC/read
500: hkn0814:675728:675835 [0] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
242: hkn0607:904266:904368 [2] NCCL INFO Channel 01 : 242[ca000] -> 241[4b000] via P2P/IPC/read
501: hkn0814:675740:675838 [1] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
261: hkn0613:902589:902698 [1] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
218: hkn0601:117591:117714 [2] NCCL INFO Channel 01 : 218[ca000] -> 217[4b000] via P2P/IPC/read
466: hkn0803:876456:876564 [2] NCCL INFO Channel 01 : 466[ca000] -> 465[4b000] via P2P/IPC/read
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
497: hkn0812:693675:693791 [1] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
314: hkn0631:1021723:1021832 [2] NCCL INFO Channel 00 : 314[ca000] -> 313[4b000] via P2P/IPC/read
306: hkn0629:1591947:1592059 [2] NCCL INFO Channel 00 : 306[ca000] -> 305[4b000] via P2P/IPC/read
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
492: hkn0810:939409:939536 [0] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
496: hkn0812:693695:693790 [0] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
282: hkn0622:2020384:2020510 [2] NCCL INFO Channel 01 : 282[ca000] -> 281[4b000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
286: hkn0623:1872648:1872765 [2] NCCL INFO Channel 01 : 286[ca000] -> 285[4b000] via P2P/IPC/read
310: hkn0630:1598359:1598459 [2] NCCL INFO Channel 00 : 310[ca000] -> 309[4b000] via P2P/IPC/read
222: hkn0602:3362295:3362554 [2] NCCL INFO Channel 01 : 222[ca000] -> 221[4b000] via P2P/IPC/read
230: hkn0604:689117:689240 [2] NCCL INFO Channel 01 : 230[ca000] -> 229[4b000] via P2P/IPC/read
442: hkn0732:1211543:1211663 [2] NCCL INFO Channel 00 : 442[ca000] -> 441[4b000] via P2P/IPC/read
489: hkn0809:937231:937375 [1] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
234: hkn0605:711998:712112 [2] NCCL INFO Channel 01 : 234[ca000] -> 233[4b000] via P2P/IPC/read
290: hkn0624:1772838:1772944 [2] NCCL INFO Channel 01 : 290[ca000] -> 289[4b000] via P2P/IPC/read
454: hkn0736:1508244:1508370 [2] NCCL INFO Channel 00 : 454[ca000] -> 453[4b000] via P2P/IPC/read
226: hkn0603:1413123:1413232 [2] NCCL INFO Channel 01 : 226[ca000] -> 225[4b000] via P2P/IPC/read
493: hkn0810:939417:939538 [1] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
450: hkn0734:1156441:1156545 [2] NCCL INFO Channel 00 : 450[ca000] -> 449[4b000] via P2P/IPC/read
298: hkn0627:1787836:1787925 [2] NCCL INFO Channel 01 : 298[ca000] -> 297[4b000] via P2P/IPC/read
294: hkn0626:1298329:1298455 [2] NCCL INFO Channel 01 : 294[ca000] -> 293[4b000] via P2P/IPC/read
302: hkn0628:671759:671904 [2] NCCL INFO Channel 00 : 302[ca000] -> 301[4b000] via P2P/IPC/read
322: hkn0633:1526218:1526355 [2] NCCL INFO Channel 00 : 322[ca000] -> 321[4b000] via P2P/IPC/read
458: hkn0801:2239916:2240014 [2] NCCL INFO Channel 00 : 458[ca000] -> 457[4b000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
485: hkn0808:970565:970682 [1] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
260: hkn0613:902581:902700 [0] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
101: hkn0502:228954:229059 [1] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
213: hkn0535:2398861:2398990 [1] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
165: hkn0521:1197671:1197795 [1] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
248: hkn0609:710728:710827 [0] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
100: hkn0502:228966:229066 [0] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
306: hkn0629:1591947:1592059 [2] NCCL INFO Channel 01 : 306[ca000] -> 305[4b000] via P2P/IPC/read
462: hkn0802:1200232:1200339 [2] NCCL INFO Channel 00 : 462[ca000] -> 461[4b000] via P2P/IPC/read
318: hkn0632:1758495:1758618 [2] NCCL INFO Channel 00 : 318[ca000] -> 317[4b000] via P2P/IPC/read
484: hkn0808:970557:970676 [0] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
250: hkn0609:710708:710822 [2] NCCL INFO Channel 00 : 250[ca000] -> 249[4b000] via P2P/IPC/read
350: hkn0706:752144:752268 [2] NCCL INFO Channel 00 : 350[ca000] -> 349[4b000] via P2P/IPC/read
326: hkn0634:1520761:1520867 [2] NCCL INFO Channel 00 : 326[ca000] -> 325[4b000] via P2P/IPC/read
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
216: hkn0601:117612:117713 [0] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
346: hkn0705:783101:783217 [2] NCCL INFO Channel 00 : 346[ca000] -> 345[4b000] via P2P/IPC/read
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
442: hkn0732:1211543:1211663 [2] NCCL INFO Channel 01 : 442[ca000] -> 441[4b000] via P2P/IPC/read
238: hkn0606:2371989:2372088 [2] NCCL INFO Channel 01 : 238[ca000] -> 237[4b000] via P2P/IPC/read
446: hkn0733:1389290:1389387 [2] NCCL INFO Channel 00 : 446[ca000] -> 445[4b000] via P2P/IPC/read
314: hkn0631:1021723:1021832 [2] NCCL INFO Channel 01 : 314[ca000] -> 313[4b000] via P2P/IPC/read
310: hkn0630:1598359:1598459 [2] NCCL INFO Channel 01 : 310[ca000] -> 309[4b000] via P2P/IPC/read
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
458: hkn0801:2239916:2240014 [2] NCCL INFO Channel 01 : 458[ca000] -> 457[4b000] via P2P/IPC/read
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
264: hkn0615:414213:414324 [0] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
342: hkn0704:791887:792017 [2] NCCL INFO Channel 00 : 342[ca000] -> 341[4b000] via P2P/IPC/read
265: hkn0615:414225:414318 [1] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
378: hkn0714:431915:432039 [2] NCCL INFO Channel 00 : 378[ca000] -> 377[4b000] via P2P/IPC/read
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
253: hkn0611:709702:709825 [1] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
366: hkn0711:583820:583927 [2] NCCL INFO Channel 00 : 366[ca000] -> 365[4b000] via P2P/IPC/read
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
354: hkn0707:4019820:4019919 [2] NCCL INFO Channel 00 : 354[ca000] -> 353[4b000] via P2P/IPC/read
394: hkn0718:3916905:3917029 [2] NCCL INFO Channel 00 : 394[ca000] -> 393[4b000] via P2P/IPC/read
204: hkn0532:924615:924928 [0] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
450: hkn0734:1156441:1156545 [2] NCCL INFO Channel 01 : 450[ca000] -> 449[4b000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
362: hkn0710:355457:355550 [2] NCCL INFO Channel 00 : 362[ca000] -> 361[4b000] via P2P/IPC/read
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
454: hkn0736:1508244:1508370 [2] NCCL INFO Channel 01 : 454[ca000] -> 453[4b000] via P2P/IPC/read
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
252: hkn0611:709722:709820 [0] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
205: hkn0532:924607:924924 [1] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
462: hkn0802:1200232:1200339 [2] NCCL INFO Channel 01 : 462[ca000] -> 461[4b000] via P2P/IPC/read
338: hkn0703:740952:741043 [2] NCCL INFO Channel 00 : 338[ca000] -> 337[4b000] via P2P/IPC/read
250: hkn0609:710708:710822 [2] NCCL INFO Channel 01 : 250[ca000] -> 249[4b000] via P2P/IPC/read
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
249: hkn0609:710716:710825 [1] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
326: hkn0634:1520761:1520867 [2] NCCL INFO Channel 01 : 326[ca000] -> 325[4b000] via P2P/IPC/read
370: hkn0712:294940:295065 [2] NCCL INFO Channel 00 : 370[ca000] -> 369[4b000] via P2P/IPC/read
322: hkn0633:1526218:1526355 [2] NCCL INFO Channel 01 : 322[ca000] -> 321[4b000] via P2P/IPC/read
374: hkn0713:470128:470236 [2] NCCL INFO Channel 00 : 374[ca000] -> 373[4b000] via P2P/IPC/read
318: hkn0632:1758495:1758618 [2] NCCL INFO Channel 01 : 318[ca000] -> 317[4b000] via P2P/IPC/read
334: hkn0636:1654143:1654268 [2] NCCL INFO Channel 00 : 334[ca000] -> 333[4b000] via P2P/IPC/read
197: hkn0530:1258062:1258153 [1] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
358: hkn0708:413122:413219 [2] NCCL INFO Channel 00 : 358[ca000] -> 357[4b000] via P2P/IPC/read
406: hkn0721:2299071:2299198 [2] NCCL INFO Channel 00 : 406[ca000] -> 405[4b000] via P2P/IPC/read
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
330: hkn0635:1225453:1225598 [2] NCCL INFO Channel 00 : 330[ca000] -> 329[4b000] via P2P/IPC/read
302: hkn0628:671759:671904 [2] NCCL INFO Channel 01 : 302[ca000] -> 301[4b000] via P2P/IPC/read
 69: hkn0422:4153025:4153124 [1] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
382: hkn0715:401788:401899 [2] NCCL INFO Channel 00 : 382[ca000] -> 381[4b000] via P2P/IPC/read
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
350: hkn0706:752144:752268 [2] NCCL INFO Channel 01 : 350[ca000] -> 349[4b000] via P2P/IPC/read
446: hkn0733:1389290:1389387 [2] NCCL INFO Channel 01 : 446[ca000] -> 445[4b000] via P2P/IPC/read
346: hkn0705:783101:783217 [2] NCCL INFO Channel 01 : 346[ca000] -> 345[4b000] via P2P/IPC/read
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
268: hkn0616:404786:404909 [0] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
233: hkn0605:712002:712113 [1] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
366: hkn0711:583820:583927 [2] NCCL INFO Channel 01 : 366[ca000] -> 365[4b000] via P2P/IPC/read
434: hkn0730:1401634:1401726 [2] NCCL INFO Channel 00 : 434[ca000] -> 433[4b000] via P2P/IPC/read
240: hkn0607:904254:904366 [0] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
338: hkn0703:740952:741043 [2] NCCL INFO Channel 01 : 338[ca000] -> 337[4b000] via P2P/IPC/read
362: hkn0710:355457:355550 [2] NCCL INFO Channel 01 : 362[ca000] -> 361[4b000] via P2P/IPC/read
390: hkn0717:4187539:4187652 [2] NCCL INFO Channel 00 : 390[ca000] -> 389[4b000] via P2P/IPC/read
256: hkn0612:916852:916975 [0] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
269: hkn0616:404794:404911 [1] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
402: hkn0720:5397:5643 [2] NCCL INFO Channel 00 : 402[ca000] -> 401[4b000] via P2P/IPC/read
386: hkn0716:108398:108509 [2] NCCL INFO Channel 00 : 386[ca000] -> 385[4b000] via P2P/IPC/read
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
414: hkn0724:1715886:1715987 [2] NCCL INFO Channel 00 : 414[ca000] -> 413[4b000] via P2P/IPC/read
418: hkn0725:3111809:3111929 [2] NCCL INFO Channel 00 : 418[ca000] -> 417[4b000] via P2P/IPC/read
398: hkn0719:1305623:1305723 [2] NCCL INFO Channel 00 : 398[ca000] -> 397[4b000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
430: hkn0728:1323891:1323997 [2] NCCL INFO Channel 00 : 430[ca000] -> 429[4b000] via P2P/IPC/read
374: hkn0713:470128:470236 [2] NCCL INFO Channel 01 : 374[ca000] -> 373[4b000] via P2P/IPC/read
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
378: hkn0714:431915:432039 [2] NCCL INFO Channel 01 : 378[ca000] -> 377[4b000] via P2P/IPC/read
257: hkn0612:916860:916982 [1] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
334: hkn0636:1654143:1654268 [2] NCCL INFO Channel 01 : 334[ca000] -> 333[4b000] via P2P/IPC/read
358: hkn0708:413122:413219 [2] NCCL INFO Channel 01 : 358[ca000] -> 357[4b000] via P2P/IPC/read
469: hkn0804:1205507:1205626 [1] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
241: hkn0607:904238:904362 [1] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
394: hkn0718:3916905:3917029 [2] NCCL INFO Channel 01 : 394[ca000] -> 393[4b000] via P2P/IPC/read
330: hkn0635:1225453:1225598 [2] NCCL INFO Channel 01 : 330[ca000] -> 329[4b000] via P2P/IPC/read
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
277: hkn0621:1991460:1991584 [1] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
438: hkn0731:1386633:1386740 [2] NCCL INFO Channel 00 : 438[ca000] -> 437[4b000] via P2P/IPC/read
342: hkn0704:791887:792017 [2] NCCL INFO Channel 01 : 342[ca000] -> 341[4b000] via P2P/IPC/read
354: hkn0707:4019820:4019919 [2] NCCL INFO Channel 01 : 354[ca000] -> 353[4b000] via P2P/IPC/read
410: hkn0723:207909:208065 [2] NCCL INFO Channel 00 : 410[ca000] -> 409[4b000] via P2P/IPC/read
422: hkn0726:1548007:1548114 [2] NCCL INFO Channel 00 : 422[ca000] -> 421[4b000] via P2P/IPC/read
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
232: hkn0605:711997:712115 [0] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 00 : 64[31000] -> 67[e3000] via P2P/IPC/read
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
406: hkn0721:2299071:2299198 [2] NCCL INFO Channel 01 : 406[ca000] -> 405[4b000] via P2P/IPC/read
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
370: hkn0712:294940:295065 [2] NCCL INFO Channel 01 : 370[ca000] -> 369[4b000] via P2P/IPC/read
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
244: hkn0608:485608:485739 [0] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
398: hkn0719:1305623:1305723 [2] NCCL INFO Channel 01 : 398[ca000] -> 397[4b000] via P2P/IPC/read
 37: hkn0413:2366588:2366711 [1] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
245: hkn0608:485636:485738 [1] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
430: hkn0728:1323891:1323997 [2] NCCL INFO Channel 01 : 430[ca000] -> 429[4b000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
426: hkn0727:1345664:1345786 [2] NCCL INFO Channel 00 : 426[ca000] -> 425[4b000] via P2P/IPC/read
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
 21: hkn0409:2585543:2585692 [1] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
434: hkn0730:1401634:1401726 [2] NCCL INFO Channel 01 : 434[ca000] -> 433[4b000] via P2P/IPC/read
  5: hkn0404:1339266:1339391 [1] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 00 : 84[31000] -> 87[e3000] via P2P/IPC/read
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 00 : 28[31000] -> 31[e3000] via P2P/IPC/read
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 00 : 44[31000] -> 47[e3000] via P2P/IPC/read
382: hkn0715:401788:401899 [2] NCCL INFO Channel 01 : 382[ca000] -> 381[4b000] via P2P/IPC/read
438: hkn0731:1386633:1386740 [2] NCCL INFO Channel 01 : 438[ca000] -> 437[4b000] via P2P/IPC/read
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 00 : 40[31000] -> 43[e3000] via P2P/IPC/read
390: hkn0717:4187539:4187652 [2] NCCL INFO Channel 01 : 390[ca000] -> 389[4b000] via P2P/IPC/read
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 01 : 64[31000] -> 67[e3000] via P2P/IPC/read
418: hkn0725:3111809:3111929 [2] NCCL INFO Channel 01 : 418[ca000] -> 417[4b000] via P2P/IPC/read
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
414: hkn0724:1715886:1715987 [2] NCCL INFO Channel 01 : 414[ca000] -> 413[4b000] via P2P/IPC/read
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
453: hkn0736:1508232:1508369 [1] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
410: hkn0723:207909:208065 [2] NCCL INFO Channel 01 : 410[ca000] -> 409[4b000] via P2P/IPC/read
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 00 : 92[31000] -> 95[e3000] via P2P/IPC/read
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 00 : 48[31000] -> 51[e3000] via P2P/IPC/read
341: hkn0704:791903:792016 [1] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
228: hkn0604:689133:689241 [0] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
386: hkn0716:108398:108509 [2] NCCL INFO Channel 01 : 386[ca000] -> 385[4b000] via P2P/IPC/read
422: hkn0726:1548007:1548114 [2] NCCL INFO Channel 01 : 422[ca000] -> 421[4b000] via P2P/IPC/read
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 00 : 68[31000] -> 71[e3000] via P2P/IPC/read
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
 85: hkn0426:813954:814076 [1] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
402: hkn0720:5397:5643 [2] NCCL INFO Channel 01 : 402[ca000] -> 401[4b000] via P2P/IPC/read
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
348: hkn0706:752164:752267 [0] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 00 : 88[31000] -> 91[e3000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
465: hkn0803:876477:876562 [1] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
426: hkn0727:1345664:1345786 [2] NCCL INFO Channel 01 : 426[ca000] -> 425[4b000] via P2P/IPC/read
389: hkn0717:4187531:4187655 [1] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
344: hkn0705:783129:783218 [0] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 01 : 84[31000] -> 87[e3000] via P2P/IPC/read
229: hkn0604:689145:689242 [1] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 00 : 36[31000] -> 39[e3000] via P2P/IPC/read
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 01 : 44[31000] -> 47[e3000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
300: hkn0628:671767:671903 [0] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 01 : 28[31000] -> 31[e3000] via P2P/IPC/read
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
464: hkn0803:876465:876561 [0] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 01 : 40[31000] -> 43[e3000] via P2P/IPC/read
117: hkn0506:837969:838070 [1] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
377: hkn0714:431907:432038 [1] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 00 : 20[31000] -> 23[e3000] via P2P/IPC/read
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 00 : 72[31000] -> 75[e3000] via P2P/IPC/read
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 00 : 96[31000] -> 99[e3000] via P2P/IPC/read
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 01 : 92[31000] -> 95[e3000] via P2P/IPC/read
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 01 : 48[31000] -> 51[e3000] via P2P/IPC/read
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
 53: hkn0418:1869083:1869169 [1] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 00 : 60[31000] -> 63[e3000] via P2P/IPC/read
108: hkn0504:40743:40838 [0] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
349: hkn0706:752136:752262 [1] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
369: hkn0712:294968:295070 [1] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 01 : 68[31000] -> 71[e3000] via P2P/IPC/read
340: hkn0704:791895:792019 [0] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
309: hkn0630:1598347:1598454 [1] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 01 : 36[31000] -> 39[e3000] via P2P/IPC/read
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 01 : 88[31000] -> 91[e3000] via P2P/IPC/read
217: hkn0601:117600:117712 [1] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
409: hkn0723:207893:208068 [1] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
385: hkn0716:108390:108502 [1] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
368: hkn0712:294956:295068 [0] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
509: hkn0816:375500:375645 [1] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 00 : 56[31000] -> 59[e3000] via P2P/IPC/read
381: hkn0715:401780:401901 [1] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 00 : 76[31000] -> 79[e3000] via P2P/IPC/read
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 00 : 80[31000] -> 83[e3000] via P2P/IPC/read
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 01 : 20[31000] -> 23[e3000] via P2P/IPC/read
336: hkn0703:740936:741046 [0] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
405: hkn0721:2299079:2299192 [1] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 01 : 72[31000] -> 75[e3000] via P2P/IPC/read
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
376: hkn0714:431923:432030 [0] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
380: hkn0715:401772:401896 [0] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 01 : 96[31000] -> 99[e3000] via P2P/IPC/read
384: hkn0716:108410:108503 [0] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
356: hkn0708:413102:413217 [0] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
508: hkn0816:375484:375639 [0] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
345: hkn0705:783117:783216 [1] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
337: hkn0703:740940:741049 [1] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 00 : 32[31000] -> 35[e3000] via P2P/IPC/read
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
325: hkn0634:1520753:1520864 [1] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 01 : 60[31000] -> 63[e3000] via P2P/IPC/read
373: hkn0713:470120:470234 [1] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
401: hkn0720:5385:5649 [1] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
108: hkn0504:40743:40838 [0] NCCL INFO Channel 00 : 108[31000] -> 111[e3000] via P2P/IPC/read
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 00 : 112[31000] -> 115[e3000] via P2P/IPC/read
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
400: hkn0720:5369:5640 [0] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
109: hkn0504:40731:40842 [1] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
408: hkn0723:207901:208066 [0] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 01 : 56[31000] -> 59[e3000] via P2P/IPC/read
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
361: hkn0710:355445:355552 [1] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 00 : 24[31000] -> 27[e3000] via P2P/IPC/read
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 01 : 80[31000] -> 83[e3000] via P2P/IPC/read
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 00 : 148[31000] -> 151[e3000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 01 : 76[31000] -> 79[e3000] via P2P/IPC/read
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 00 : 8[31000] -> 11[e3000] via P2P/IPC/read
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
  1: hkn0403:1763954:1764350 [1] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 00 : 4[31000] -> 7[e3000] via P2P/IPC/read
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 01 : 32[31000] -> 35[e3000] via P2P/IPC/read
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
508: hkn0816:375484:375639 [0] NCCL INFO Channel 00 : 508[31000] -> 511[e3000] via P2P/IPC/read
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 00 : 12[31000] -> 15[e3000] via P2P/IPC/read
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
108: hkn0504:40743:40838 [0] NCCL INFO Channel 01 : 108[31000] -> 111[e3000] via P2P/IPC/read
181: hkn0526:1428306:1428417 [1] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
293: hkn0626:1298357:1298456 [1] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 01 : 112[31000] -> 115[e3000] via P2P/IPC/read
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 00 : 52[31000] -> 55[e3000] via P2P/IPC/read
133: hkn0510:2761928:2762038 [1] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
421: hkn0726:1547991:1548116 [1] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
437: hkn0731:1386617:1386741 [1] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 00 : 128[31000] -> 131[e3000] via P2P/IPC/read
149: hkn0514:2950618:2950734 [1] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
176: hkn0525:986689:986834 [0] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 01 : 24[31000] -> 27[e3000] via P2P/IPC/read
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 01 : 148[31000] -> 151[e3000] via P2P/IPC/read
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 01 : 8[31000] -> 11[e3000] via P2P/IPC/read
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
177: hkn0525:986697:986833 [1] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 00 : 116[31000] -> 119[e3000] via P2P/IPC/read
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
504: hkn0815:395016:395129 [0] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 01 : 4[31000] -> 7[e3000] via P2P/IPC/read
505: hkn0815:395028:395124 [1] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
261: hkn0613:902589:902698 [1] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 00 : 124[31000] -> 127[e3000] via P2P/IPC/read
508: hkn0816:375484:375639 [0] NCCL INFO Channel 01 : 508[31000] -> 511[e3000] via P2P/IPC/read
500: hkn0814:675728:675835 [0] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 01 : 12[31000] -> 15[e3000] via P2P/IPC/read
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 00 : 156[31000] -> 159[e3000] via P2P/IPC/read
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
501: hkn0814:675740:675838 [1] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 00 : 168[31000] -> 171[e3000] via P2P/IPC/read
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 00 : 0[31000] -> 3[e3000] via P2P/IPC/read
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 00 : 152[31000] -> 155[e3000] via P2P/IPC/read
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 00 : 144[31000] -> 147[e3000] via P2P/IPC/read
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 00 : 120[31000] -> 123[e3000] via P2P/IPC/read
492: hkn0810:939409:939536 [0] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
497: hkn0812:693675:693791 [1] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
 51: hkn0417:2267539:2267651 [3] NCCL INFO Channel 00 : 51[e3000] -> 50[ca000] via P2P/IPC/read
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 01 : 52[31000] -> 55[e3000] via P2P/IPC/read
496: hkn0812:693695:693790 [0] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 00 : 132[31000] -> 135[e3000] via P2P/IPC/read
489: hkn0809:937231:937375 [1] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 01 : 128[31000] -> 131[e3000] via P2P/IPC/read
 71: hkn0422:4153013:4153117 [3] NCCL INFO Channel 00 : 71[e3000] -> 70[ca000] via P2P/IPC/read
493: hkn0810:939417:939538 [1] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 01 : 116[31000] -> 119[e3000] via P2P/IPC/read
176: hkn0525:986689:986834 [0] NCCL INFO Channel 00 : 176[31000] -> 179[e3000] via P2P/IPC/read
213: hkn0535:2398861:2398990 [1] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
260: hkn0613:902581:902700 [0] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
248: hkn0609:710728:710827 [0] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 01 : 124[31000] -> 127[e3000] via P2P/IPC/read
216: hkn0601:117612:117713 [0] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
488: hkn0809:937239:937379 [0] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
504: hkn0815:395016:395129 [0] NCCL INFO Channel 00 : 504[31000] -> 507[e3000] via P2P/IPC/read
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 01 : 156[31000] -> 159[e3000] via P2P/IPC/read
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 00 : 160[31000] -> 163[e3000] via P2P/IPC/read
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 01 : 168[31000] -> 171[e3000] via P2P/IPC/read
500: hkn0814:675728:675835 [0] NCCL INFO Channel 00 : 500[31000] -> 503[e3000] via P2P/IPC/read
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 00 : 140[31000] -> 143[e3000] via P2P/IPC/read
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 01 : 0[31000] -> 3[e3000] via P2P/IPC/read
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 01 : 120[31000] -> 123[e3000] via P2P/IPC/read
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 01 : 144[31000] -> 147[e3000] via P2P/IPC/read
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 01 : 152[31000] -> 155[e3000] via P2P/IPC/read
 51: hkn0417:2267539:2267651 [3] NCCL INFO Channel 01 : 51[e3000] -> 50[ca000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 00 : 184[31000] -> 187[e3000] via P2P/IPC/read
357: hkn0708:413110:413222 [1] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
165: hkn0521:1197671:1197795 [1] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
492: hkn0810:939409:939536 [0] NCCL INFO Channel 00 : 492[31000] -> 495[e3000] via P2P/IPC/read
101: hkn0502:228954:229059 [1] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
364: hkn0711:583800:583921 [0] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 01 : 132[31000] -> 135[e3000] via P2P/IPC/read
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
 71: hkn0422:4153013:4153117 [3] NCCL INFO Channel 01 : 71[e3000] -> 70[ca000] via P2P/IPC/read
485: hkn0808:970565:970682 [1] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
496: hkn0812:693695:693790 [0] NCCL INFO Channel 00 : 496[31000] -> 499[e3000] via P2P/IPC/read
100: hkn0502:228966:229066 [0] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 00 : 180[31000] -> 183[e3000] via P2P/IPC/read
176: hkn0525:986689:986834 [0] NCCL INFO Channel 01 : 176[31000] -> 179[e3000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
484: hkn0808:970557:970676 [0] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
260: hkn0613:902581:902700 [0] NCCL INFO Channel 00 : 260[31000] -> 263[e3000] via P2P/IPC/read
 87: hkn0426:813974:814075 [3] NCCL INFO Channel 00 : 87[e3000] -> 86[ca000] via P2P/IPC/read
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 01 : 160[31000] -> 163[e3000] via P2P/IPC/read
264: hkn0615:414213:414324 [0] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
248: hkn0609:710728:710827 [0] NCCL INFO Channel 00 : 248[31000] -> 251[e3000] via P2P/IPC/read
504: hkn0815:395016:395129 [0] NCCL INFO Channel 01 : 504[31000] -> 507[e3000] via P2P/IPC/read
265: hkn0615:414225:414318 [1] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
 43: hkn0414:1981498:1981609 [3] NCCL INFO Channel 00 : 43[e3000] -> 42[ca000] via P2P/IPC/read
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
216: hkn0601:117612:117713 [0] NCCL INFO Channel 00 : 216[31000] -> 219[e3000] via P2P/IPC/read
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 01 : 140[31000] -> 143[e3000] via P2P/IPC/read
 31: hkn0411:2315753:2315871 [3] NCCL INFO Channel 00 : 31[e3000] -> 30[ca000] via P2P/IPC/read
249: hkn0609:710716:710825 [1] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
253: hkn0611:709702:709825 [1] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
500: hkn0814:675728:675835 [0] NCCL INFO Channel 01 : 500[31000] -> 503[e3000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Channel 00 : 488[31000] -> 491[e3000] via P2P/IPC/read
 67: hkn0421:2180600:2180859 [3] NCCL INFO Channel 00 : 67[e3000] -> 66[ca000] via P2P/IPC/read
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
252: hkn0611:709722:709820 [0] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
204: hkn0532:924615:924928 [0] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 01 : 184[31000] -> 187[e3000] via P2P/IPC/read
 95: hkn0428:667235:667348 [3] NCCL INFO Channel 00 : 95[e3000] -> 94[ca000] via P2P/IPC/read
492: hkn0810:939409:939536 [0] NCCL INFO Channel 01 : 492[31000] -> 495[e3000] via P2P/IPC/read
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 00 : 272[31000] -> 275[e3000] via P2P/IPC/read
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
205: hkn0532:924607:924924 [1] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
496: hkn0812:693695:693790 [0] NCCL INFO Channel 01 : 496[31000] -> 499[e3000] via P2P/IPC/read
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 01 : 180[31000] -> 183[e3000] via P2P/IPC/read
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
233: hkn0605:712002:712113 [1] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
 91: hkn0427:1135017:1135131 [3] NCCL INFO Channel 00 : 91[e3000] -> 90[ca000] via P2P/IPC/read
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 00 : 224[31000] -> 227[e3000] via P2P/IPC/read
 47: hkn0415:2496310:2496438 [3] NCCL INFO Channel 00 : 47[e3000] -> 46[ca000] via P2P/IPC/read
 39: hkn0413:2366596:2366702 [3] NCCL INFO Channel 00 : 39[e3000] -> 38[ca000] via P2P/IPC/read
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
197: hkn0530:1258062:1258153 [1] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 00 : 164[31000] -> 167[e3000] via P2P/IPC/read
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
484: hkn0808:970557:970676 [0] NCCL INFO Channel 00 : 484[31000] -> 487[e3000] via P2P/IPC/read
260: hkn0613:902581:902700 [0] NCCL INFO Channel 01 : 260[31000] -> 263[e3000] via P2P/IPC/read
 87: hkn0426:813974:814075 [3] NCCL INFO Channel 01 : 87[e3000] -> 86[ca000] via P2P/IPC/read
 43: hkn0414:1981498:1981609 [3] NCCL INFO Channel 01 : 43[e3000] -> 42[ca000] via P2P/IPC/read
248: hkn0609:710728:710827 [0] NCCL INFO Channel 01 : 248[31000] -> 251[e3000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
268: hkn0616:404786:404909 [0] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 00 : 476[31000] -> 479[e3000] via P2P/IPC/read
 23: hkn0409:2585564:2585689 [3] NCCL INFO Channel 00 : 23[e3000] -> 22[ca000] via P2P/IPC/read
216: hkn0601:117612:117713 [0] NCCL INFO Channel 01 : 216[31000] -> 219[e3000] via P2P/IPC/read
100: hkn0502:228966:229066 [0] NCCL INFO Channel 00 : 100[31000] -> 103[e3000] via P2P/IPC/read
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
 31: hkn0411:2315753:2315871 [3] NCCL INFO Channel 01 : 31[e3000] -> 30[ca000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 00 : 172[31000] -> 175[e3000] via P2P/IPC/read
264: hkn0615:414213:414324 [0] NCCL INFO Channel 00 : 264[31000] -> 267[e3000] via P2P/IPC/read
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 00 : 480[31000] -> 483[e3000] via P2P/IPC/read
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
151: hkn0514:2950630:2950735 [3] NCCL INFO Channel 00 : 151[e3000] -> 150[ca000] via P2P/IPC/read
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 00 : 212[31000] -> 215[e3000] via P2P/IPC/read
 75: hkn0423:1704809:1704921 [3] NCCL INFO Channel 00 : 75[e3000] -> 74[ca000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Channel 01 : 488[31000] -> 491[e3000] via P2P/IPC/read
 67: hkn0421:2180600:2180859 [3] NCCL INFO Channel 01 : 67[e3000] -> 66[ca000] via P2P/IPC/read
256: hkn0612:916852:916975 [0] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 00 : 192[31000] -> 195[e3000] via P2P/IPC/read
 95: hkn0428:667235:667348 [3] NCCL INFO Channel 01 : 95[e3000] -> 94[ca000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
240: hkn0607:904254:904366 [0] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
257: hkn0612:916860:916982 [1] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
 99: hkn0501:1327769:1327904 [3] NCCL INFO Channel 00 : 99[e3000] -> 98[ca000] via P2P/IPC/read
269: hkn0616:404794:404911 [1] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 01 : 272[31000] -> 275[e3000] via P2P/IPC/read
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
241: hkn0607:904238:904362 [1] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
 63: hkn0420:3210091:3210218 [3] NCCL INFO Channel 00 : 63[e3000] -> 62[ca000] via P2P/IPC/read
 51: hkn0417:2267539:2267651 [3] NCCL INFO Connected all rings
469: hkn0804:1205507:1205626 [1] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 00 : 188[31000] -> 191[e3000] via P2P/IPC/read
277: hkn0621:1991460:1991584 [1] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 00 : 196[31000] -> 199[e3000] via P2P/IPC/read
 91: hkn0427:1135017:1135131 [3] NCCL INFO Channel 01 : 91[e3000] -> 90[ca000] via P2P/IPC/read
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 01 : 224[31000] -> 227[e3000] via P2P/IPC/read
252: hkn0611:709722:709820 [0] NCCL INFO Channel 00 : 252[31000] -> 255[e3000] via P2P/IPC/read
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
 47: hkn0415:2496310:2496438 [3] NCCL INFO Channel 01 : 47[e3000] -> 46[ca000] via P2P/IPC/read
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 01 : 164[31000] -> 167[e3000] via P2P/IPC/read
204: hkn0532:924615:924928 [0] NCCL INFO Channel 00 : 204[31000] -> 207[e3000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
484: hkn0808:970557:970676 [0] NCCL INFO Channel 01 : 484[31000] -> 487[e3000] via P2P/IPC/read
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 00 : 208[31000] -> 211[e3000] via P2P/IPC/read
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
 59: hkn0419:1544187:1544303 [3] NCCL INFO Channel 00 : 59[e3000] -> 58[ca000] via P2P/IPC/read
 23: hkn0409:2585564:2585689 [3] NCCL INFO Channel 01 : 23[e3000] -> 22[ca000] via P2P/IPC/read
 71: hkn0422:4153013:4153117 [3] NCCL INFO Connected all rings
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 00 : 200[31000] -> 203[e3000] via P2P/IPC/read
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 01 : 476[31000] -> 479[e3000] via P2P/IPC/read
 39: hkn0413:2366596:2366702 [3] NCCL INFO Channel 01 : 39[e3000] -> 38[ca000] via P2P/IPC/read
100: hkn0502:228966:229066 [0] NCCL INFO Channel 01 : 100[31000] -> 103[e3000] via P2P/IPC/read
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 01 : 480[31000] -> 483[e3000] via P2P/IPC/read
453: hkn0736:1508232:1508369 [1] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
264: hkn0615:414213:414324 [0] NCCL INFO Channel 01 : 264[31000] -> 267[e3000] via P2P/IPC/read
 83: hkn0425:2083899:2084034 [3] NCCL INFO Channel 00 : 83[e3000] -> 82[ca000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 01 : 172[31000] -> 175[e3000] via P2P/IPC/read
151: hkn0514:2950630:2950735 [3] NCCL INFO Channel 01 : 151[e3000] -> 150[ca000] via P2P/IPC/read
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 01 : 212[31000] -> 215[e3000] via P2P/IPC/read
 75: hkn0423:1704809:1704921 [3] NCCL INFO Channel 01 : 75[e3000] -> 74[ca000] via P2P/IPC/read
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
268: hkn0616:404786:404909 [0] NCCL INFO Channel 00 : 268[31000] -> 271[e3000] via P2P/IPC/read
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 01 : 192[31000] -> 195[e3000] via P2P/IPC/read
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
 79: hkn0424:2947870:2947971 [3] NCCL INFO Channel 00 : 79[e3000] -> 78[ca000] via P2P/IPC/read
 99: hkn0501:1327769:1327904 [3] NCCL INFO Channel 01 : 99[e3000] -> 98[ca000] via P2P/IPC/read
244: hkn0608:485608:485739 [0] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
341: hkn0704:791903:792016 [1] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
159: hkn0516:2915875:2915970 [3] NCCL INFO Channel 00 : 159[e3000] -> 158[ca000] via P2P/IPC/read
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
245: hkn0608:485636:485738 [1] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
 63: hkn0420:3210091:3210218 [3] NCCL INFO Channel 01 : 63[e3000] -> 62[ca000] via P2P/IPC/read
232: hkn0605:711997:712115 [0] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 01 : 188[31000] -> 191[e3000] via P2P/IPC/read
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 01 : 196[31000] -> 199[e3000] via P2P/IPC/read
 35: hkn0412:2262278:2262387 [3] NCCL INFO Channel 00 : 35[e3000] -> 34[ca000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 00 : 468[31000] -> 471[e3000] via P2P/IPC/read
240: hkn0607:904254:904366 [0] NCCL INFO Channel 00 : 240[31000] -> 243[e3000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 00 : 16[31000] -> 19[e3000] via P2P/IPC/read
256: hkn0612:916852:916975 [0] NCCL INFO Channel 00 : 256[31000] -> 259[e3000] via P2P/IPC/read
252: hkn0611:709722:709820 [0] NCCL INFO Channel 01 : 252[31000] -> 255[e3000] via P2P/IPC/read
204: hkn0532:924615:924928 [0] NCCL INFO Channel 01 : 204[31000] -> 207[e3000] via P2P/IPC/read
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 00 : 316[31000] -> 319[e3000] via P2P/IPC/read
389: hkn0717:4187531:4187655 [1] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
 59: hkn0419:1544187:1544303 [3] NCCL INFO Channel 01 : 59[e3000] -> 58[ca000] via P2P/IPC/read
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 00 : 236[31000] -> 239[e3000] via P2P/IPC/read
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 00 : 472[31000] -> 475[e3000] via P2P/IPC/read
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 01 : 208[31000] -> 211[e3000] via P2P/IPC/read
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 01 : 200[31000] -> 203[e3000] via P2P/IPC/read
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
111: hkn0504:40715:40839 [3] NCCL INFO Channel 00 : 111[e3000] -> 110[ca000] via P2P/IPC/read
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 00 : 220[31000] -> 223[e3000] via P2P/IPC/read
 27: hkn0410:1159586:1159707 [3] NCCL INFO Channel 00 : 27[e3000] -> 26[ca000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 00 : 292[31000] -> 295[e3000] via P2P/IPC/read
344: hkn0705:783129:783218 [0] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 00 : 276[31000] -> 279[e3000] via P2P/IPC/read
348: hkn0706:752164:752267 [0] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
228: hkn0604:689133:689241 [0] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 00 : 304[31000] -> 307[e3000] via P2P/IPC/read
 87: hkn0426:813974:814075 [3] NCCL INFO Connected all rings
 11: hkn0405:3206742:3206897 [3] NCCL INFO Channel 00 : 11[e3000] -> 10[ca000] via P2P/IPC/read
 83: hkn0425:2083899:2084034 [3] NCCL INFO Channel 01 : 83[e3000] -> 82[ca000] via P2P/IPC/read
 43: hkn0414:1981498:1981609 [3] NCCL INFO Connected all rings
115: hkn0505:2303672:2303774 [3] NCCL INFO Channel 00 : 115[e3000] -> 114[ca000] via P2P/IPC/read
  7: hkn0404:1339294:1339386 [3] NCCL INFO Channel 00 : 7[e3000] -> 6[ca000] via P2P/IPC/read
268: hkn0616:404786:404909 [0] NCCL INFO Channel 01 : 268[31000] -> 271[e3000] via P2P/IPC/read
 79: hkn0424:2947870:2947971 [3] NCCL INFO Channel 01 : 79[e3000] -> 78[ca000] via P2P/IPC/read
465: hkn0803:876477:876562 [1] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
 31: hkn0411:2315753:2315871 [3] NCCL INFO Connected all rings
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
377: hkn0714:431907:432038 [1] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
229: hkn0604:689145:689242 [1] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
511: hkn0816:375492:375642 [3] NCCL INFO Channel 00 : 511[e3000] -> 510[ca000] via P2P/IPC/read
 67: hkn0421:2180600:2180859 [3] NCCL INFO Connected all rings
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
159: hkn0516:2915875:2915970 [3] NCCL INFO Channel 01 : 159[e3000] -> 158[ca000] via P2P/IPC/read
464: hkn0803:876465:876561 [0] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
301: hkn0628:671751:671908 [1] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 00 : 312[31000] -> 315[e3000] via P2P/IPC/read
 35: hkn0412:2262278:2262387 [3] NCCL INFO Channel 01 : 35[e3000] -> 34[ca000] via P2P/IPC/read
 15: hkn0407:1816151:1816277 [3] NCCL INFO Channel 00 : 15[e3000] -> 14[ca000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 01 : 468[31000] -> 471[e3000] via P2P/IPC/read
240: hkn0607:904254:904366 [0] NCCL INFO Channel 01 : 240[31000] -> 243[e3000] via P2P/IPC/read
340: hkn0704:791895:792019 [0] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
256: hkn0612:916852:916975 [0] NCCL INFO Channel 01 : 256[31000] -> 259[e3000] via P2P/IPC/read
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 01 : 316[31000] -> 319[e3000] via P2P/IPC/read
 95: hkn0428:667235:667348 [3] NCCL INFO Connected all rings
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 00 : 280[31000] -> 283[e3000] via P2P/IPC/read
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 01 : 236[31000] -> 239[e3000] via P2P/IPC/read
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 00 : 104[31000] -> 107[e3000] via P2P/IPC/read
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 01 : 472[31000] -> 475[e3000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 01 : 16[31000] -> 19[e3000] via P2P/IPC/read
244: hkn0608:485608:485739 [0] NCCL INFO Channel 00 : 244[31000] -> 247[e3000] via P2P/IPC/read
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
 91: hkn0427:1135017:1135131 [3] NCCL INFO Connected all rings
300: hkn0628:671767:671903 [0] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
131: hkn0509:3124296:3124401 [3] NCCL INFO Channel 00 : 131[e3000] -> 130[ca000] via P2P/IPC/read
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 01 : 220[31000] -> 223[e3000] via P2P/IPC/read
 27: hkn0410:1159586:1159707 [3] NCCL INFO Channel 01 : 27[e3000] -> 26[ca000] via P2P/IPC/read
349: hkn0706:752136:752262 [1] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
111: hkn0504:40715:40839 [3] NCCL INFO Channel 01 : 111[e3000] -> 110[ca000] via P2P/IPC/read
 47: hkn0415:2496310:2496438 [3] NCCL INFO Connected all rings
409: hkn0723:207893:208068 [1] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
232: hkn0605:711997:712115 [0] NCCL INFO Channel 00 : 232[31000] -> 235[e3000] via P2P/IPC/read
 55: hkn0418:1869061:1869166 [3] NCCL INFO Channel 00 : 55[e3000] -> 54[ca000] via P2P/IPC/read
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 00 : 288[31000] -> 291[e3000] via P2P/IPC/read
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 01 : 292[31000] -> 295[e3000] via P2P/IPC/read
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 01 : 304[31000] -> 307[e3000] via P2P/IPC/read
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
 11: hkn0405:3206742:3206897 [3] NCCL INFO Channel 01 : 11[e3000] -> 10[ca000] via P2P/IPC/read
 23: hkn0409:2585564:2585689 [3] NCCL INFO Connected all rings
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 00 : 448[31000] -> 451[e3000] via P2P/IPC/read
115: hkn0505:2303672:2303774 [3] NCCL INFO Channel 01 : 115[e3000] -> 114[ca000] via P2P/IPC/read
  7: hkn0404:1339294:1339386 [3] NCCL INFO Channel 01 : 7[e3000] -> 6[ca000] via P2P/IPC/read
119: hkn0506:837957:838067 [3] NCCL INFO Channel 00 : 119[e3000] -> 118[ca000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
 39: hkn0413:2366596:2366702 [3] NCCL INFO Connected all rings
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
344: hkn0705:783129:783218 [0] NCCL INFO Channel 00 : 344[31000] -> 347[e3000] via P2P/IPC/read
348: hkn0706:752164:752267 [0] NCCL INFO Channel 00 : 348[31000] -> 351[e3000] via P2P/IPC/read
127: hkn0508:3139037:3139138 [3] NCCL INFO Channel 00 : 127[e3000] -> 126[ca000] via P2P/IPC/read
356: hkn0708:413102:413217 [0] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 00 : 136[31000] -> 139[e3000] via P2P/IPC/read
228: hkn0604:689133:689241 [0] NCCL INFO Channel 00 : 228[31000] -> 231[e3000] via P2P/IPC/read
368: hkn0712:294956:295068 [0] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
511: hkn0816:375492:375642 [3] NCCL INFO Channel 01 : 511[e3000] -> 510[ca000] via P2P/IPC/read
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 00 : 444[31000] -> 447[e3000] via P2P/IPC/read
151: hkn0514:2950630:2950735 [3] NCCL INFO Connected all rings
381: hkn0715:401780:401901 [1] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
171: hkn0523:1547977:1548089 [3] NCCL INFO Channel 00 : 171[e3000] -> 170[ca000] via P2P/IPC/read
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 01 : 312[31000] -> 315[e3000] via P2P/IPC/read
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
 15: hkn0407:1816151:1816277 [3] NCCL INFO Channel 01 : 15[e3000] -> 14[ca000] via P2P/IPC/read
373: hkn0713:470120:470234 [1] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
336: hkn0703:740936:741046 [0] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
385: hkn0716:108390:108502 [1] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
309: hkn0630:1598347:1598454 [1] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
376: hkn0714:431923:432030 [0] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
405: hkn0721:2299079:2299192 [1] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
380: hkn0715:401772:401896 [0] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
345: hkn0705:783117:783216 [1] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 01 : 280[31000] -> 283[e3000] via P2P/IPC/read
  3: hkn0403:1763926:1764349 [3] NCCL INFO Channel 00 : 3[e3000] -> 2[ca000] via P2P/IPC/read
337: hkn0703:740940:741049 [1] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
 75: hkn0423:1704809:1704921 [3] NCCL INFO Connected all rings
 99: hkn0501:1327769:1327904 [3] NCCL INFO Connected all rings
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 00 : 432[31000] -> 435[e3000] via P2P/IPC/read
244: hkn0608:485608:485739 [0] NCCL INFO Channel 01 : 244[31000] -> 247[e3000] via P2P/IPC/read
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 00 : 284[31000] -> 287[e3000] via P2P/IPC/read
 63: hkn0420:3210091:3210218 [3] NCCL INFO Connected all rings
464: hkn0803:876465:876561 [0] NCCL INFO Channel 00 : 464[31000] -> 467[e3000] via P2P/IPC/read
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 01 : 276[31000] -> 279[e3000] via P2P/IPC/read
131: hkn0509:3124296:3124401 [3] NCCL INFO Channel 01 : 131[e3000] -> 130[ca000] via P2P/IPC/read
340: hkn0704:791895:792019 [0] NCCL INFO Channel 00 : 340[31000] -> 343[e3000] via P2P/IPC/read
135: hkn0510:2761936:2762043 [3] NCCL INFO Channel 00 : 135[e3000] -> 134[ca000] via P2P/IPC/read
408: hkn0723:207901:208066 [0] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
232: hkn0605:711997:712115 [0] NCCL INFO Channel 01 : 232[31000] -> 235[e3000] via P2P/IPC/read
384: hkn0716:108410:108503 [0] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 00 : 324[31000] -> 327[e3000] via P2P/IPC/read
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 01 : 104[31000] -> 107[e3000] via P2P/IPC/read
369: hkn0712:294968:295070 [1] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
 55: hkn0418:1869061:1869166 [3] NCCL INFO Channel 01 : 55[e3000] -> 54[ca000] via P2P/IPC/read
 59: hkn0419:1544187:1544303 [3] NCCL INFO Connected all rings
325: hkn0634:1520753:1520864 [1] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 01 : 288[31000] -> 291[e3000] via P2P/IPC/read
123: hkn0507:3186970:3187067 [3] NCCL INFO Channel 00 : 123[e3000] -> 122[ca000] via P2P/IPC/read
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
300: hkn0628:671767:671903 [0] NCCL INFO Channel 00 : 300[31000] -> 303[e3000] via P2P/IPC/read
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 00 : 320[31000] -> 323[e3000] via P2P/IPC/read
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
119: hkn0506:837957:838067 [3] NCCL INFO Channel 01 : 119[e3000] -> 118[ca000] via P2P/IPC/read
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 00 : 440[31000] -> 443[e3000] via P2P/IPC/read
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 01 : 448[31000] -> 451[e3000] via P2P/IPC/read
344: hkn0705:783129:783218 [0] NCCL INFO Channel 01 : 344[31000] -> 347[e3000] via P2P/IPC/read
348: hkn0706:752164:752267 [0] NCCL INFO Channel 01 : 348[31000] -> 351[e3000] via P2P/IPC/read
127: hkn0508:3139037:3139138 [3] NCCL INFO Channel 01 : 127[e3000] -> 126[ca000] via P2P/IPC/read
401: hkn0720:5385:5649 [1] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
228: hkn0604:689133:689241 [0] NCCL INFO Channel 01 : 228[31000] -> 231[e3000] via P2P/IPC/read
163: hkn0520:2712757:2712880 [3] NCCL INFO Channel 00 : 163[e3000] -> 162[ca000] via P2P/IPC/read
400: hkn0720:5369:5640 [0] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 00 : 456[31000] -> 459[e3000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 00 : 392[31000] -> 395[e3000] via P2P/IPC/read
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 01 : 444[31000] -> 447[e3000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
179: hkn0525:986681:986840 [3] NCCL INFO Channel 00 : 179[e3000] -> 178[ca000] via P2P/IPC/read
361: hkn0710:355445:355552 [1] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
 83: hkn0425:2083899:2084034 [3] NCCL INFO Connected all rings
171: hkn0523:1547977:1548089 [3] NCCL INFO Channel 01 : 171[e3000] -> 170[ca000] via P2P/IPC/read
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 00 : 460[31000] -> 463[e3000] via P2P/IPC/read
507: hkn0815:395008:395125 [3] NCCL INFO Channel 00 : 507[e3000] -> 506[ca000] via P2P/IPC/read
143: hkn0512:3044032:3044153 [3] NCCL INFO Channel 00 : 143[e3000] -> 142[ca000] via P2P/IPC/read
 79: hkn0424:2947870:2947971 [3] NCCL INFO Connected all rings
147: hkn0513:3012860:3012956 [3] NCCL INFO Channel 00 : 147[e3000] -> 146[ca000] via P2P/IPC/read
  3: hkn0403:1763926:1764349 [3] NCCL INFO Channel 01 : 3[e3000] -> 2[ca000] via P2P/IPC/read
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
155: hkn0515:2896683:2896800 [3] NCCL INFO Channel 00 : 155[e3000] -> 154[ca000] via P2P/IPC/read
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 00 : 308[31000] -> 311[e3000] via P2P/IPC/read
356: hkn0708:413102:413217 [0] NCCL INFO Channel 00 : 356[31000] -> 359[e3000] via P2P/IPC/read
368: hkn0712:294956:295068 [0] NCCL INFO Channel 00 : 368[31000] -> 371[e3000] via P2P/IPC/read
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 01 : 432[31000] -> 435[e3000] via P2P/IPC/read
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 01 : 284[31000] -> 287[e3000] via P2P/IPC/read
336: hkn0703:740936:741046 [0] NCCL INFO Channel 00 : 336[31000] -> 339[e3000] via P2P/IPC/read
159: hkn0516:2915875:2915970 [3] NCCL INFO Connected all rings
464: hkn0803:876465:876561 [0] NCCL INFO Channel 01 : 464[31000] -> 467[e3000] via P2P/IPC/read
495: hkn0810:939425:939541 [3] NCCL INFO Channel 00 : 495[e3000] -> 494[ca000] via P2P/IPC/read
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 00 : 388[31000] -> 391[e3000] via P2P/IPC/read
380: hkn0715:401772:401896 [0] NCCL INFO Channel 00 : 380[31000] -> 383[e3000] via P2P/IPC/read
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
135: hkn0510:2761936:2762043 [3] NCCL INFO Channel 01 : 135[e3000] -> 134[ca000] via P2P/IPC/read
 35: hkn0412:2262278:2262387 [3] NCCL INFO Connected all rings
340: hkn0704:791895:792019 [0] NCCL INFO Channel 01 : 340[31000] -> 343[e3000] via P2P/IPC/read
187: hkn0527:1348850:1348948 [3] NCCL INFO Channel 00 : 187[e3000] -> 186[ca000] via P2P/IPC/read
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 01 : 324[31000] -> 327[e3000] via P2P/IPC/read
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 00 : 396[31000] -> 399[e3000] via P2P/IPC/read
360: hkn0710:355429:355558 [0] NCCL INFO Channel 00 : 360[31000] -> 363[e3000] via P2P/IPC/read
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
503: hkn0814:675719:675836 [3] NCCL INFO Channel 00 : 503[e3000] -> 502[ca000] via P2P/IPC/read
376: hkn0714:431923:432030 [0] NCCL INFO Channel 00 : 376[31000] -> 379[e3000] via P2P/IPC/read
300: hkn0628:671767:671903 [0] NCCL INFO Channel 01 : 300[31000] -> 303[e3000] via P2P/IPC/read
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 01 : 320[31000] -> 323[e3000] via P2P/IPC/read
123: hkn0507:3186970:3187067 [3] NCCL INFO Channel 01 : 123[e3000] -> 122[ca000] via P2P/IPC/read
111: hkn0504:40715:40839 [3] NCCL INFO Connected all rings
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 00 : 420[31000] -> 423[e3000] via P2P/IPC/read
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 01 : 440[31000] -> 443[e3000] via P2P/IPC/read
421: hkn0726:1547991:1548116 [1] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
408: hkn0723:207901:208066 [0] NCCL INFO Channel 00 : 408[31000] -> 411[e3000] via P2P/IPC/read
263: hkn0613:902601:902691 [3] NCCL INFO Channel 00 : 263[e3000] -> 262[ca000] via P2P/IPC/read
183: hkn0526:1428318:1428415 [3] NCCL INFO Channel 00 : 183[e3000] -> 182[ca000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 01 : 392[31000] -> 395[e3000] via P2P/IPC/read
499: hkn0812:693683:693792 [3] NCCL INFO Channel 00 : 499[e3000] -> 498[ca000] via P2P/IPC/read
 27: hkn0410:1159586:1159707 [3] NCCL INFO Connected all rings
163: hkn0520:2712757:2712880 [3] NCCL INFO Channel 01 : 163[e3000] -> 162[ca000] via P2P/IPC/read
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 00 : 416[31000] -> 419[e3000] via P2P/IPC/read
251: hkn0609:710700:710823 [3] NCCL INFO Channel 00 : 251[e3000] -> 250[ca000] via P2P/IPC/read
179: hkn0525:986681:986840 [3] NCCL INFO Channel 01 : 179[e3000] -> 178[ca000] via P2P/IPC/read
384: hkn0716:108410:108503 [0] NCCL INFO Channel 00 : 384[31000] -> 387[e3000] via P2P/IPC/read
 11: hkn0405:3206742:3206897 [3] NCCL INFO Connected all rings
437: hkn0731:1386617:1386741 [1] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 01 : 456[31000] -> 459[e3000] via P2P/IPC/read
143: hkn0512:3044032:3044153 [3] NCCL INFO Channel 01 : 143[e3000] -> 142[ca000] via P2P/IPC/read
115: hkn0505:2303672:2303774 [3] NCCL INFO Connected all rings
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 01 : 460[31000] -> 463[e3000] via P2P/IPC/read
  7: hkn0404:1339294:1339386 [3] NCCL INFO Connected all rings
507: hkn0815:395008:395125 [3] NCCL INFO Channel 01 : 507[e3000] -> 506[ca000] via P2P/IPC/read
400: hkn0720:5369:5640 [0] NCCL INFO Channel 00 : 400[31000] -> 403[e3000] via P2P/IPC/read
147: hkn0513:3012860:3012956 [3] NCCL INFO Channel 01 : 147[e3000] -> 146[ca000] via P2P/IPC/read
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
356: hkn0708:413102:413217 [0] NCCL INFO Channel 01 : 356[31000] -> 359[e3000] via P2P/IPC/read
511: hkn0816:375492:375642 [3] NCCL INFO Connected all rings
155: hkn0515:2896683:2896800 [3] NCCL INFO Channel 01 : 155[e3000] -> 154[ca000] via P2P/IPC/read
368: hkn0712:294956:295068 [0] NCCL INFO Channel 01 : 368[31000] -> 371[e3000] via P2P/IPC/read
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 01 : 308[31000] -> 311[e3000] via P2P/IPC/read
491: hkn0809:937251:937374 [3] NCCL INFO Channel 00 : 491[e3000] -> 490[ca000] via P2P/IPC/read
495: hkn0810:939425:939541 [3] NCCL INFO Channel 01 : 495[e3000] -> 494[ca000] via P2P/IPC/read
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 00 : 332[31000] -> 335[e3000] via P2P/IPC/read
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 01 : 388[31000] -> 391[e3000] via P2P/IPC/read
187: hkn0527:1348850:1348948 [3] NCCL INFO Channel 01 : 187[e3000] -> 186[ca000] via P2P/IPC/read
380: hkn0715:401772:401896 [0] NCCL INFO Channel 01 : 380[31000] -> 383[e3000] via P2P/IPC/read
336: hkn0703:740936:741046 [0] NCCL INFO Channel 01 : 336[31000] -> 339[e3000] via P2P/IPC/read
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
 15: hkn0407:1816151:1816277 [3] NCCL INFO Connected all rings
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 01 : 396[31000] -> 399[e3000] via P2P/IPC/read
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
275: hkn0617:2294550:2294702 [3] NCCL INFO Channel 00 : 275[e3000] -> 274[ca000] via P2P/IPC/read
503: hkn0814:675719:675836 [3] NCCL INFO Channel 01 : 503[e3000] -> 502[ca000] via P2P/IPC/read
360: hkn0710:355429:355558 [0] NCCL INFO Channel 01 : 360[31000] -> 363[e3000] via P2P/IPC/read
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 00 : 412[31000] -> 415[e3000] via P2P/IPC/read
376: hkn0714:431923:432030 [0] NCCL INFO Channel 01 : 376[31000] -> 379[e3000] via P2P/IPC/read
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 01 : 136[31000] -> 139[e3000] via P2P/IPC/read
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 00 : 404[31000] -> 407[e3000] via P2P/IPC/read
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 01 : 420[31000] -> 423[e3000] via P2P/IPC/read
167: hkn0521:1197691:1197791 [3] NCCL INFO Channel 00 : 167[e3000] -> 166[ca000] via P2P/IPC/read
408: hkn0723:207901:208066 [0] NCCL INFO Channel 01 : 408[31000] -> 411[e3000] via P2P/IPC/read
183: hkn0526:1428318:1428415 [3] NCCL INFO Channel 01 : 183[e3000] -> 182[ca000] via P2P/IPC/read
487: hkn0808:970549:970680 [3] NCCL INFO Channel 00 : 487[e3000] -> 486[ca000] via P2P/IPC/read
263: hkn0613:902601:902691 [3] NCCL INFO Channel 01 : 263[e3000] -> 262[ca000] via P2P/IPC/read
227: hkn0603:1413135:1413236 [3] NCCL INFO Channel 00 : 227[e3000] -> 226[ca000] via P2P/IPC/read
499: hkn0812:693683:693792 [3] NCCL INFO Channel 01 : 499[e3000] -> 498[ca000] via P2P/IPC/read
131: hkn0509:3124296:3124401 [3] NCCL INFO Connected all rings
 55: hkn0418:1869061:1869166 [3] NCCL INFO Connected all rings
384: hkn0716:108410:108503 [0] NCCL INFO Channel 01 : 384[31000] -> 387[e3000] via P2P/IPC/read
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 01 : 416[31000] -> 419[e3000] via P2P/IPC/read
251: hkn0609:710700:710823 [3] NCCL INFO Channel 01 : 251[e3000] -> 250[ca000] via P2P/IPC/read
119: hkn0506:837957:838067 [3] NCCL INFO Connected all rings
127: hkn0508:3139037:3139138 [3] NCCL INFO Connected all rings
175: hkn0524:1133671:1133797 [3] NCCL INFO Channel 00 : 175[e3000] -> 174[ca000] via P2P/IPC/read
400: hkn0720:5369:5640 [0] NCCL INFO Channel 01 : 400[31000] -> 403[e3000] via P2P/IPC/read
483: hkn0807:1018978:1019080 [3] NCCL INFO Channel 00 : 483[e3000] -> 482[ca000] via P2P/IPC/read
223: hkn0602:3362287:3362549 [3] NCCL INFO Channel 00 : 223[e3000] -> 222[ca000] via P2P/IPC/read
267: hkn0615:414197:414325 [3] NCCL INFO Channel 00 : 267[e3000] -> 266[ca000] via P2P/IPC/read
219: hkn0601:117592:117705 [3] NCCL INFO Channel 00 : 219[e3000] -> 218[ca000] via P2P/IPC/read
171: hkn0523:1547977:1548089 [3] NCCL INFO Connected all rings
103: hkn0502:228946:229060 [3] NCCL INFO Channel 00 : 103[e3000] -> 102[ca000] via P2P/IPC/read
491: hkn0809:937251:937374 [3] NCCL INFO Channel 01 : 491[e3000] -> 490[ca000] via P2P/IPC/read
217: hkn0601:117600:117712 [1] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 01 : 332[31000] -> 335[e3000] via P2P/IPC/read
195: hkn0529:1540716:1540851 [3] NCCL INFO Channel 00 : 195[e3000] -> 194[ca000] via P2P/IPC/read
275: hkn0617:2294550:2294702 [3] NCCL INFO Channel 01 : 275[e3000] -> 274[ca000] via P2P/IPC/read
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 00 : 428[31000] -> 431[e3000] via P2P/IPC/read
479: hkn0806:1054222:1054347 [3] NCCL INFO Channel 00 : 479[e3000] -> 478[ca000] via P2P/IPC/read
  3: hkn0403:1763926:1764349 [3] NCCL INFO Connected all rings
191: hkn0528:1301563:1301675 [3] NCCL INFO Channel 00 : 191[e3000] -> 190[ca000] via P2P/IPC/read
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 01 : 404[31000] -> 407[e3000] via P2P/IPC/read
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 01 : 412[31000] -> 415[e3000] via P2P/IPC/read
199: hkn0530:1258050:1258161 [3] NCCL INFO Channel 00 : 199[e3000] -> 198[ca000] via P2P/IPC/read
207: hkn0532:924627:924923 [3] NCCL INFO Channel 00 : 207[e3000] -> 206[ca000] via P2P/IPC/read
135: hkn0510:2761936:2762043 [3] NCCL INFO Connected all rings
227: hkn0603:1413135:1413236 [3] NCCL INFO Channel 01 : 227[e3000] -> 226[ca000] via P2P/IPC/read
255: hkn0611:709694:709822 [3] NCCL INFO Channel 00 : 255[e3000] -> 254[ca000] via P2P/IPC/read
487: hkn0808:970549:970680 [3] NCCL INFO Channel 01 : 487[e3000] -> 486[ca000] via P2P/IPC/read
167: hkn0521:1197691:1197791 [3] NCCL INFO Channel 01 : 167[e3000] -> 166[ca000] via P2P/IPC/read
215: hkn0535:2398889:2398985 [3] NCCL INFO Channel 00 : 215[e3000] -> 214[ca000] via P2P/IPC/read
211: hkn0534:1148272:1148423 [3] NCCL INFO Channel 00 : 211[e3000] -> 210[ca000] via P2P/IPC/read
203: hkn0531:1230541:1230644 [3] NCCL INFO Channel 00 : 203[e3000] -> 202[ca000] via P2P/IPC/read
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 00 : 328[31000] -> 331[e3000] via P2P/IPC/read
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
123: hkn0507:3186970:3187067 [3] NCCL INFO Connected all rings
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 00 : 436[31000] -> 439[e3000] via P2P/IPC/read
175: hkn0524:1133671:1133797 [3] NCCL INFO Channel 01 : 175[e3000] -> 174[ca000] via P2P/IPC/read
483: hkn0807:1018978:1019080 [3] NCCL INFO Channel 01 : 483[e3000] -> 482[ca000] via P2P/IPC/read
179: hkn0525:986681:986840 [3] NCCL INFO Connected all rings
163: hkn0520:2712757:2712880 [3] NCCL INFO Connected all rings
267: hkn0615:414197:414325 [3] NCCL INFO Channel 01 : 267[e3000] -> 266[ca000] via P2P/IPC/read
219: hkn0601:117592:117705 [3] NCCL INFO Channel 01 : 219[e3000] -> 218[ca000] via P2P/IPC/read
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
103: hkn0502:228946:229060 [3] NCCL INFO Channel 01 : 103[e3000] -> 102[ca000] via P2P/IPC/read
507: hkn0815:395008:395125 [3] NCCL INFO Connected all rings
195: hkn0529:1540716:1540851 [3] NCCL INFO Channel 01 : 195[e3000] -> 194[ca000] via P2P/IPC/read
271: hkn0616:404778:404908 [3] NCCL INFO Channel 00 : 271[e3000] -> 270[ca000] via P2P/IPC/read
147: hkn0513:3012860:3012956 [3] NCCL INFO Connected all rings
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 01 : 428[31000] -> 431[e3000] via P2P/IPC/read
479: hkn0806:1054222:1054347 [3] NCCL INFO Channel 01 : 479[e3000] -> 478[ca000] via P2P/IPC/read
143: hkn0512:3044032:3044153 [3] NCCL INFO Connected all rings
191: hkn0528:1301563:1301675 [3] NCCL INFO Channel 01 : 191[e3000] -> 190[ca000] via P2P/IPC/read
495: hkn0810:939425:939541 [3] NCCL INFO Connected all rings
243: hkn0607:904246:904360 [3] NCCL INFO Channel 00 : 243[e3000] -> 242[ca000] via P2P/IPC/read
319: hkn0632:1758511:1758619 [3] NCCL INFO Channel 00 : 319[e3000] -> 318[ca000] via P2P/IPC/read
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
199: hkn0530:1258050:1258161 [3] NCCL INFO Channel 01 : 199[e3000] -> 198[ca000] via P2P/IPC/read
187: hkn0527:1348850:1348948 [3] NCCL INFO Connected all rings
207: hkn0532:924627:924923 [3] NCCL INFO Channel 01 : 207[e3000] -> 206[ca000] via P2P/IPC/read
255: hkn0611:709694:709822 [3] NCCL INFO Channel 01 : 255[e3000] -> 254[ca000] via P2P/IPC/read
239: hkn0606:2371961:2372083 [3] NCCL INFO Channel 00 : 239[e3000] -> 238[ca000] via P2P/IPC/read
471: hkn0804:1205505:1205631 [3] NCCL INFO Channel 00 : 471[e3000] -> 470[ca000] via P2P/IPC/read
211: hkn0534:1148272:1148423 [3] NCCL INFO Channel 01 : 211[e3000] -> 210[ca000] via P2P/IPC/read
259: hkn0612:916868:916976 [3] NCCL INFO Channel 00 : 259[e3000] -> 258[ca000] via P2P/IPC/read
215: hkn0535:2398889:2398985 [3] NCCL INFO Channel 01 : 215[e3000] -> 214[ca000] via P2P/IPC/read
503: hkn0814:675719:675836 [3] NCCL INFO Connected all rings
475: hkn0805:1112010:1112126 [3] NCCL INFO Channel 00 : 475[e3000] -> 474[ca000] via P2P/IPC/read
287: hkn0623:1872668:1872764 [3] NCCL INFO Channel 00 : 287[e3000] -> 286[ca000] via P2P/IPC/read
155: hkn0515:2896683:2896800 [3] NCCL INFO Connected all rings
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 01 : 328[31000] -> 331[e3000] via P2P/IPC/read
203: hkn0531:1230541:1230644 [3] NCCL INFO Channel 01 : 203[e3000] -> 202[ca000] via P2P/IPC/read
183: hkn0526:1428318:1428415 [3] NCCL INFO Connected all rings
263: hkn0613:902601:902691 [3] NCCL INFO Connected all rings
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 01 : 436[31000] -> 439[e3000] via P2P/IPC/read
 19: hkn0408:2890647:2890769 [3] NCCL INFO Channel 00 : 19[e3000] -> 18[ca000] via P2P/IPC/read
499: hkn0812:693683:693792 [3] NCCL INFO Connected all rings
251: hkn0609:710700:710823 [3] NCCL INFO Connected all rings
271: hkn0616:404778:404908 [3] NCCL INFO Channel 01 : 271[e3000] -> 270[ca000] via P2P/IPC/read
223: hkn0602:3362287:3362549 [3] NCCL INFO Channel 01 : 223[e3000] -> 222[ca000] via P2P/IPC/read
243: hkn0607:904246:904360 [3] NCCL INFO Channel 01 : 243[e3000] -> 242[ca000] via P2P/IPC/read
319: hkn0632:1758511:1758619 [3] NCCL INFO Channel 01 : 319[e3000] -> 318[ca000] via P2P/IPC/read
491: hkn0809:937251:937374 [3] NCCL INFO Connected all rings
239: hkn0606:2371961:2372083 [3] NCCL INFO Channel 01 : 239[e3000] -> 238[ca000] via P2P/IPC/read
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 00 : 296[31000] -> 299[e3000] via P2P/IPC/read
275: hkn0617:2294550:2294702 [3] NCCL INFO Connected all rings
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
471: hkn0804:1205505:1205631 [3] NCCL INFO Channel 01 : 471[e3000] -> 470[ca000] via P2P/IPC/read
259: hkn0612:916868:916976 [3] NCCL INFO Channel 01 : 259[e3000] -> 258[ca000] via P2P/IPC/read
293: hkn0626:1298357:1298456 [1] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
311: hkn0630:1598331:1598462 [3] NCCL INFO Channel 00 : 311[e3000] -> 310[ca000] via P2P/IPC/read
247: hkn0608:485624:485730 [3] NCCL INFO Channel 00 : 247[e3000] -> 246[ca000] via P2P/IPC/read
475: hkn0805:1112010:1112126 [3] NCCL INFO Channel 01 : 475[e3000] -> 474[ca000] via P2P/IPC/read
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 00 : 452[31000] -> 455[e3000] via P2P/IPC/read
279: hkn0621:1991468:1991586 [3] NCCL INFO Channel 00 : 279[e3000] -> 278[ca000] via P2P/IPC/read
363: hkn0710:355437:355557 [3] NCCL INFO Channel 00 : 363[e3000] -> 362[ca000] via P2P/IPC/read
315: hkn0631:1021715:1021825 [3] NCCL INFO Channel 00 : 315[e3000] -> 314[ca000] via P2P/IPC/read
227: hkn0603:1413135:1413236 [3] NCCL INFO Connected all rings
291: hkn0624:1772830:1772945 [3] NCCL INFO Channel 00 : 291[e3000] -> 290[ca000] via P2P/IPC/read
 19: hkn0408:2890647:2890769 [3] NCCL INFO Channel 01 : 19[e3000] -> 18[ca000] via P2P/IPC/read
307: hkn0629:1591931:1592055 [3] NCCL INFO Channel 00 : 307[e3000] -> 306[ca000] via P2P/IPC/read
487: hkn0808:970549:970680 [3] NCCL INFO Connected all rings
167: hkn0521:1197691:1197791 [3] NCCL INFO Connected all rings
295: hkn0626:1298345:1298453 [3] NCCL INFO Channel 00 : 295[e3000] -> 294[ca000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
347: hkn0705:783109:783209 [3] NCCL INFO Channel 00 : 347[e3000] -> 346[ca000] via P2P/IPC/read
351: hkn0706:752152:752261 [3] NCCL INFO Channel 00 : 351[e3000] -> 350[ca000] via P2P/IPC/read
107: hkn0503:2899572:2899698 [3] NCCL INFO Channel 00 : 107[e3000] -> 106[ca000] via P2P/IPC/read
235: hkn0605:712014:712118 [3] NCCL INFO Channel 00 : 235[e3000] -> 234[ca000] via P2P/IPC/read
451: hkn0734:1156425:1156546 [3] NCCL INFO Channel 00 : 451[e3000] -> 450[ca000] via P2P/IPC/read
231: hkn0604:689125:689244 [3] NCCL INFO Channel 00 : 231[e3000] -> 230[ca000] via P2P/IPC/read
175: hkn0524:1133671:1133797 [3] NCCL INFO Connected all rings
267: hkn0615:414197:414325 [3] NCCL INFO Connected all rings
483: hkn0807:1018978:1019080 [3] NCCL INFO Connected all rings
364: hkn0711:583800:583921 [0] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
219: hkn0601:117592:117705 [3] NCCL INFO Connected all rings
103: hkn0502:228946:229060 [3] NCCL INFO Connected all rings
283: hkn0622:2020400:2020511 [3] NCCL INFO Channel 00 : 283[e3000] -> 282[ca000] via P2P/IPC/read
403: hkn0720:5377:5646 [3] NCCL INFO Channel 00 : 403[e3000] -> 402[ca000] via P2P/IPC/read
447: hkn0733:1389269:1389383 [3] NCCL INFO Channel 00 : 447[e3000] -> 446[ca000] via P2P/IPC/read
479: hkn0806:1054222:1054347 [3] NCCL INFO Connected all rings
191: hkn0528:1301563:1301675 [3] NCCL INFO Connected all rings
195: hkn0529:1540716:1540851 [3] NCCL INFO Connected all rings
247: hkn0608:485624:485730 [3] NCCL INFO Channel 01 : 247[e3000] -> 246[ca000] via P2P/IPC/read
199: hkn0530:1258050:1258161 [3] NCCL INFO Connected all rings
467: hkn0803:876457:876566 [3] NCCL INFO Channel 00 : 467[e3000] -> 466[ca000] via P2P/IPC/read
435: hkn0730:1401622:1401732 [3] NCCL INFO Channel 00 : 435[e3000] -> 434[ca000] via P2P/IPC/read
343: hkn0704:791915:792018 [3] NCCL INFO Channel 00 : 343[e3000] -> 342[ca000] via P2P/IPC/read
327: hkn0634:1520781:1520863 [3] NCCL INFO Channel 00 : 327[e3000] -> 326[ca000] via P2P/IPC/read
315: hkn0631:1021715:1021825 [3] NCCL INFO Channel 01 : 315[e3000] -> 314[ca000] via P2P/IPC/read
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 01 : 296[31000] -> 299[e3000] via P2P/IPC/read
279: hkn0621:1991468:1991586 [3] NCCL INFO Channel 01 : 279[e3000] -> 278[ca000] via P2P/IPC/read
291: hkn0624:1772830:1772945 [3] NCCL INFO Channel 01 : 291[e3000] -> 290[ca000] via P2P/IPC/read
255: hkn0611:709694:709822 [3] NCCL INFO Connected all rings
323: hkn0633:1526210:1526349 [3] NCCL INFO Channel 00 : 323[e3000] -> 322[ca000] via P2P/IPC/read
207: hkn0532:924627:924923 [3] NCCL INFO Connected all rings
307: hkn0629:1591931:1592055 [3] NCCL INFO Channel 01 : 307[e3000] -> 306[ca000] via P2P/IPC/read
215: hkn0535:2398889:2398985 [3] NCCL INFO Connected all rings
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 01 : 452[31000] -> 455[e3000] via P2P/IPC/read
203: hkn0531:1230541:1230644 [3] NCCL INFO Connected all rings
107: hkn0503:2899572:2899698 [3] NCCL INFO Channel 01 : 107[e3000] -> 106[ca000] via P2P/IPC/read
443: hkn0732:1211551:1211659 [3] NCCL INFO Channel 00 : 443[e3000] -> 442[ca000] via P2P/IPC/read
211: hkn0534:1148272:1148423 [3] NCCL INFO Connected all rings
235: hkn0605:712014:712118 [3] NCCL INFO Channel 01 : 235[e3000] -> 234[ca000] via P2P/IPC/read
295: hkn0626:1298345:1298453 [3] NCCL INFO Channel 01 : 295[e3000] -> 294[ca000] via P2P/IPC/read
347: hkn0705:783109:783209 [3] NCCL INFO Channel 01 : 347[e3000] -> 346[ca000] via P2P/IPC/read
363: hkn0710:355437:355557 [3] NCCL INFO Channel 01 : 363[e3000] -> 362[ca000] via P2P/IPC/read
351: hkn0706:752152:752261 [3] NCCL INFO Channel 01 : 351[e3000] -> 350[ca000] via P2P/IPC/read
451: hkn0734:1156425:1156546 [3] NCCL INFO Channel 01 : 451[e3000] -> 450[ca000] via P2P/IPC/read
231: hkn0604:689125:689244 [3] NCCL INFO Channel 01 : 231[e3000] -> 230[ca000] via P2P/IPC/read
463: hkn0802:1200216:1200348 [3] NCCL INFO Channel 00 : 463[e3000] -> 462[ca000] via P2P/IPC/read
283: hkn0622:2020400:2020511 [3] NCCL INFO Channel 01 : 283[e3000] -> 282[ca000] via P2P/IPC/read
403: hkn0720:5377:5646 [3] NCCL INFO Channel 01 : 403[e3000] -> 402[ca000] via P2P/IPC/read
395: hkn0718:3916925:3917028 [3] NCCL INFO Channel 00 : 395[e3000] -> 394[ca000] via P2P/IPC/read
447: hkn0733:1389269:1389383 [3] NCCL INFO Channel 01 : 447[e3000] -> 446[ca000] via P2P/IPC/read
371: hkn0712:294948:295061 [3] NCCL INFO Channel 00 : 371[e3000] -> 370[ca000] via P2P/IPC/read
271: hkn0616:404778:404908 [3] NCCL INFO Connected all rings
459: hkn0801:2239888:2240016 [3] NCCL INFO Channel 00 : 459[e3000] -> 458[ca000] via P2P/IPC/read
243: hkn0607:904246:904360 [3] NCCL INFO Connected all rings
372: hkn0713:470112:470238 [0] NCCL INFO Channel 00 : 372[31000] -> 375[e3000] via P2P/IPC/read
343: hkn0704:791915:792018 [3] NCCL INFO Channel 01 : 343[e3000] -> 342[ca000] via P2P/IPC/read
339: hkn0703:740935:741041 [3] NCCL INFO Channel 00 : 339[e3000] -> 338[ca000] via P2P/IPC/read
467: hkn0803:876457:876566 [3] NCCL INFO Channel 01 : 467[e3000] -> 466[ca000] via P2P/IPC/read
435: hkn0730:1401622:1401732 [3] NCCL INFO Channel 01 : 435[e3000] -> 434[ca000] via P2P/IPC/read
319: hkn0632:1758511:1758619 [3] NCCL INFO Connected all rings
383: hkn0715:401800:401893 [3] NCCL INFO Channel 00 : 383[e3000] -> 382[ca000] via P2P/IPC/read
327: hkn0634:1520781:1520863 [3] NCCL INFO Channel 01 : 327[e3000] -> 326[ca000] via P2P/IPC/read
391: hkn0717:4187523:4187653 [3] NCCL INFO Channel 00 : 391[e3000] -> 390[ca000] via P2P/IPC/read
239: hkn0606:2371961:2372083 [3] NCCL INFO Connected all rings
323: hkn0633:1526210:1526349 [3] NCCL INFO Channel 01 : 323[e3000] -> 322[ca000] via P2P/IPC/read
287: hkn0623:1872668:1872764 [3] NCCL INFO Channel 01 : 287[e3000] -> 286[ca000] via P2P/IPC/read
357: hkn0708:413110:413222 [1] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
379: hkn0714:431935:432037 [3] NCCL INFO Channel 00 : 379[e3000] -> 378[ca000] via P2P/IPC/read
475: hkn0805:1112010:1112126 [3] NCCL INFO Connected all rings
259: hkn0612:916868:916976 [3] NCCL INFO Connected all rings
364: hkn0711:583800:583921 [0] NCCL INFO Channel 00 : 364[31000] -> 367[e3000] via P2P/IPC/read
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 00 : 352[31000] -> 355[e3000] via P2P/IPC/read
303: hkn0628:671779:671905 [3] NCCL INFO Channel 00 : 303[e3000] -> 302[ca000] via P2P/IPC/read
423: hkn0726:1547999:1548115 [3] NCCL INFO Channel 00 : 423[e3000] -> 422[ca000] via P2P/IPC/read
471: hkn0804:1205505:1205631 [3] NCCL INFO Connected all rings
411: hkn0723:207921:208060 [3] NCCL INFO Channel 00 : 411[e3000] -> 410[ca000] via P2P/IPC/read
443: hkn0732:1211551:1211659 [3] NCCL INFO Channel 01 : 443[e3000] -> 442[ca000] via P2P/IPC/read
463: hkn0802:1200216:1200348 [3] NCCL INFO Channel 01 : 463[e3000] -> 462[ca000] via P2P/IPC/read
223: hkn0602:3362287:3362549 [3] NCCL INFO Connected all rings
139: hkn0511:3066266:3066383 [3] NCCL INFO Channel 00 : 139[e3000] -> 138[ca000] via P2P/IPC/read
419: hkn0725:3111817:3111928 [3] NCCL INFO Channel 00 : 419[e3000] -> 418[ca000] via P2P/IPC/read
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
395: hkn0718:3916925:3917028 [3] NCCL INFO Channel 01 : 395[e3000] -> 394[ca000] via P2P/IPC/read
359: hkn0708:413094:413225 [3] NCCL INFO Channel 00 : 359[e3000] -> 358[ca000] via P2P/IPC/read
371: hkn0712:294948:295061 [3] NCCL INFO Channel 01 : 371[e3000] -> 370[ca000] via P2P/IPC/read
459: hkn0801:2239888:2240016 [3] NCCL INFO Channel 01 : 459[e3000] -> 458[ca000] via P2P/IPC/read
339: hkn0703:740935:741041 [3] NCCL INFO Channel 01 : 339[e3000] -> 338[ca000] via P2P/IPC/read
 19: hkn0408:2890647:2890769 [3] NCCL INFO Connected all rings
335: hkn0636:1654171:1654272 [3] NCCL INFO Channel 00 : 335[e3000] -> 334[ca000] via P2P/IPC/read
391: hkn0717:4187523:4187653 [3] NCCL INFO Channel 01 : 391[e3000] -> 390[ca000] via P2P/IPC/read
383: hkn0715:401800:401893 [3] NCCL INFO Channel 01 : 383[e3000] -> 382[ca000] via P2P/IPC/read
311: hkn0630:1598331:1598462 [3] NCCL INFO Channel 01 : 311[e3000] -> 310[ca000] via P2P/IPC/read
399: hkn0719:1305603:1305721 [3] NCCL INFO Channel 00 : 399[e3000] -> 398[ca000] via P2P/IPC/read
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
379: hkn0714:431935:432037 [3] NCCL INFO Channel 01 : 379[e3000] -> 378[ca000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Channel 01 : 372[31000] -> 375[e3000] via P2P/IPC/read
407: hkn0721:2299099:2299196 [3] NCCL INFO Channel 00 : 407[e3000] -> 406[ca000] via P2P/IPC/read
415: hkn0724:1715858:1715983 [3] NCCL INFO Channel 00 : 415[e3000] -> 414[ca000] via P2P/IPC/read
247: hkn0608:485624:485730 [3] NCCL INFO Connected all rings
315: hkn0631:1021715:1021825 [3] NCCL INFO Connected all rings
423: hkn0726:1547999:1548115 [3] NCCL INFO Channel 01 : 423[e3000] -> 422[ca000] via P2P/IPC/read
279: hkn0621:1991468:1991586 [3] NCCL INFO Connected all rings
291: hkn0624:1772830:1772945 [3] NCCL INFO Connected all rings
387: hkn0716:108382:108508 [3] NCCL INFO Channel 00 : 387[e3000] -> 386[ca000] via P2P/IPC/read
411: hkn0723:207921:208060 [3] NCCL INFO Channel 01 : 411[e3000] -> 410[ca000] via P2P/IPC/read
364: hkn0711:583800:583921 [0] NCCL INFO Channel 01 : 364[31000] -> 367[e3000] via P2P/IPC/read
307: hkn0629:1591931:1592055 [3] NCCL INFO Connected all rings
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 01 : 352[31000] -> 355[e3000] via P2P/IPC/read
303: hkn0628:671779:671905 [3] NCCL INFO Channel 01 : 303[e3000] -> 302[ca000] via P2P/IPC/read
139: hkn0511:3066266:3066383 [3] NCCL INFO Channel 01 : 139[e3000] -> 138[ca000] via P2P/IPC/read
295: hkn0626:1298345:1298453 [3] NCCL INFO Connected all rings
419: hkn0725:3111817:3111928 [3] NCCL INFO Channel 01 : 419[e3000] -> 418[ca000] via P2P/IPC/read
235: hkn0605:712014:712118 [3] NCCL INFO Connected all rings
451: hkn0734:1156425:1156546 [3] NCCL INFO Connected all rings
347: hkn0705:783109:783209 [3] NCCL INFO Connected all rings
351: hkn0706:752152:752261 [3] NCCL INFO Connected all rings
231: hkn0604:689125:689244 [3] NCCL INFO Connected all rings
107: hkn0503:2899572:2899698 [3] NCCL INFO Connected all rings
359: hkn0708:413094:413225 [3] NCCL INFO Channel 01 : 359[e3000] -> 358[ca000] via P2P/IPC/read
283: hkn0622:2020400:2020511 [3] NCCL INFO Connected all rings
335: hkn0636:1654171:1654272 [3] NCCL INFO Channel 01 : 335[e3000] -> 334[ca000] via P2P/IPC/read
363: hkn0710:355437:355557 [3] NCCL INFO Connected all rings
447: hkn0733:1389269:1389383 [3] NCCL INFO Connected all rings
399: hkn0719:1305603:1305721 [3] NCCL INFO Channel 01 : 399[e3000] -> 398[ca000] via P2P/IPC/read
415: hkn0724:1715858:1715983 [3] NCCL INFO Channel 01 : 415[e3000] -> 414[ca000] via P2P/IPC/read
407: hkn0721:2299099:2299196 [3] NCCL INFO Channel 01 : 407[e3000] -> 406[ca000] via P2P/IPC/read
435: hkn0730:1401622:1401732 [3] NCCL INFO Connected all rings
343: hkn0704:791915:792018 [3] NCCL INFO Connected all rings
 61: hkn0420:3210101:3210213 [1] NCCL INFO Connected all rings
431: hkn0728:1323883:1324000 [3] NCCL INFO Channel 00 : 431[e3000] -> 430[ca000] via P2P/IPC/read
467: hkn0803:876457:876566 [3] NCCL INFO Connected all rings
323: hkn0633:1526210:1526349 [3] NCCL INFO Connected all rings
327: hkn0634:1520781:1520863 [3] NCCL INFO Connected all rings
331: hkn0635:1225445:1225601 [3] NCCL INFO Channel 00 : 331[e3000] -> 330[ca000] via P2P/IPC/read
387: hkn0716:108382:108508 [3] NCCL INFO Channel 01 : 387[e3000] -> 386[ca000] via P2P/IPC/read
403: hkn0720:5377:5646 [3] NCCL INFO Connected all rings
439: hkn0731:1386625:1386746 [3] NCCL INFO Channel 00 : 439[e3000] -> 438[ca000] via P2P/IPC/read
443: hkn0732:1211551:1211659 [3] NCCL INFO Connected all rings
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 00 : 424[31000] -> 427[e3000] via P2P/IPC/read
287: hkn0623:1872668:1872764 [3] NCCL INFO Connected all rings
463: hkn0802:1200216:1200348 [3] NCCL INFO Connected all rings
371: hkn0712:294948:295061 [3] NCCL INFO Connected all rings
459: hkn0801:2239888:2240016 [3] NCCL INFO Connected all rings
395: hkn0718:3916925:3917028 [3] NCCL INFO Connected all rings
 84: hkn0426:813962:814073 [0] NCCL INFO Connected all rings
339: hkn0703:740935:741041 [3] NCCL INFO Connected all rings
391: hkn0717:4187523:4187653 [3] NCCL INFO Connected all rings
383: hkn0715:401800:401893 [3] NCCL INFO Connected all rings
311: hkn0630:1598331:1598462 [3] NCCL INFO Connected all rings
379: hkn0714:431935:432037 [3] NCCL INFO Connected all rings
431: hkn0728:1323883:1324000 [3] NCCL INFO Channel 01 : 431[e3000] -> 430[ca000] via P2P/IPC/read
423: hkn0726:1547999:1548115 [3] NCCL INFO Connected all rings
331: hkn0635:1225445:1225601 [3] NCCL INFO Channel 01 : 331[e3000] -> 330[ca000] via P2P/IPC/read
439: hkn0731:1386625:1386746 [3] NCCL INFO Channel 01 : 439[e3000] -> 438[ca000] via P2P/IPC/read
 36: hkn0413:2366580:2366708 [0] NCCL INFO Connected all rings
411: hkn0723:207921:208060 [3] NCCL INFO Connected all rings
419: hkn0725:3111817:3111928 [3] NCCL INFO Connected all rings
139: hkn0511:3066266:3066383 [3] NCCL INFO Connected all rings
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 01 : 424[31000] -> 427[e3000] via P2P/IPC/read
359: hkn0708:413094:413225 [3] NCCL INFO Connected all rings
303: hkn0628:671779:671905 [3] NCCL INFO Connected all rings
 88: hkn0427:1135037:1135137 [0] NCCL INFO Connected all rings
 92: hkn0428:667219:667351 [0] NCCL INFO Connected all rings
335: hkn0636:1654171:1654272 [3] NCCL INFO Connected all rings
399: hkn0719:1305603:1305721 [3] NCCL INFO Connected all rings
407: hkn0721:2299099:2299196 [3] NCCL INFO Connected all rings
415: hkn0724:1715858:1715983 [3] NCCL INFO Connected all rings
 40: hkn0414:1981497:1981610 [0] NCCL INFO Connected all rings
 81: hkn0425:2083915:2084030 [1] NCCL INFO Connected all rings
 37: hkn0413:2366588:2366711 [1] NCCL INFO Connected all rings
299: hkn0627:1787816:1787921 [3] NCCL INFO Channel 00 : 299[e3000] -> 298[ca000] via P2P/IPC/read
387: hkn0716:108382:108508 [3] NCCL INFO Connected all rings
 60: hkn0420:3210113:3210211 [0] NCCL INFO Connected all rings
 41: hkn0414:1981499:1981602 [1] NCCL INFO Connected all rings
455: hkn0736:1508224:1508372 [3] NCCL INFO Channel 00 : 455[e3000] -> 454[ca000] via P2P/IPC/read
 32: hkn0412:2262276:2262390 [0] NCCL INFO Connected all rings
 80: hkn0425:2083907:2084029 [0] NCCL INFO Connected all rings
 33: hkn0412:2262290:2262395 [1] NCCL INFO Connected all rings
 89: hkn0427:1135025:1135132 [1] NCCL INFO Connected all rings
 25: hkn0410:1159614:1159709 [1] NCCL INFO Connected all rings
 62: hkn0420:3210093:3210219 [2] NCCL INFO Connected all rings
 85: hkn0426:813954:814076 [1] NCCL INFO Connected all rings
 28: hkn0411:2315775:2315872 [0] NCCL INFO Connected all rings
 69: hkn0422:4153025:4153124 [1] NCCL INFO Connected all rings
108: hkn0504:40743:40838 [0] NCCL INFO Connected all rings
431: hkn0728:1323883:1324000 [3] NCCL INFO Connected all rings
331: hkn0635:1225445:1225601 [3] NCCL INFO Connected all rings
 72: hkn0423:1704801:1704925 [0] NCCL INFO Connected all rings
 76: hkn0424:2947881:2947969 [0] NCCL INFO Connected all rings
439: hkn0731:1386625:1386746 [3] NCCL INFO Connected all rings
 56: hkn0419:1544195:1544301 [0] NCCL INFO Connected all rings
299: hkn0627:1787816:1787921 [3] NCCL INFO Channel 01 : 299[e3000] -> 298[ca000] via P2P/IPC/read
455: hkn0736:1508224:1508372 [3] NCCL INFO Channel 01 : 455[e3000] -> 454[ca000] via P2P/IPC/read
 73: hkn0423:1704793:1704926 [1] NCCL INFO Connected all rings
 20: hkn0409:2585552:2585695 [0] NCCL INFO Connected all rings
 93: hkn0428:667227:667353 [1] NCCL INFO Connected all rings
112: hkn0505:2303664:2303782 [0] NCCL INFO Connected all rings
 53: hkn0418:1869083:1869169 [1] NCCL INFO Connected all rings
 24: hkn0410:1159594:1159711 [0] NCCL INFO Connected all rings
375: hkn0713:470140:470235 [3] NCCL INFO Channel 00 : 375[e3000] -> 374[ca000] via P2P/IPC/read
 29: hkn0411:2315755:2315870 [1] NCCL INFO Connected all rings
 77: hkn0424:2947854:2947962 [1] NCCL INFO Connected all rings
367: hkn0711:583792:583925 [3] NCCL INFO Channel 00 : 367[e3000] -> 366[ca000] via P2P/IPC/read
355: hkn0707:4019792:4019918 [3] NCCL INFO Channel 00 : 355[e3000] -> 354[ca000] via P2P/IPC/read
 64: hkn0421:2180612:2180860 [0] NCCL INFO Connected all rings
508: hkn0816:375484:375639 [0] NCCL INFO Connected all rings
 52: hkn0418:1869053:1869172 [0] NCCL INFO Connected all rings
124: hkn0508:3139017:3139132 [0] NCCL INFO Connected all rings
  0: hkn0403:1763942:1764342 [0] NCCL INFO Connected all rings
120: hkn0507:3186982:3187071 [0] NCCL INFO Connected all rings
  8: hkn0405:3206750:3206902 [0] NCCL INFO Connected all rings
121: hkn0507:3186962:3187062 [1] NCCL INFO Connected all rings
 26: hkn0410:1159602:1159714 [2] NCCL INFO Connected all rings
 49: hkn0417:2267523:2267656 [1] NCCL INFO Connected all rings
 17: hkn0408:2890667:2890771 [1] NCCL INFO Connected all rings
375: hkn0713:470140:470235 [3] NCCL INFO Channel 01 : 375[e3000] -> 374[ca000] via P2P/IPC/read
  4: hkn0404:1339282:1339394 [0] NCCL INFO Connected all rings
109: hkn0504:40731:40842 [1] NCCL INFO Connected all rings
116: hkn0506:837949:838063 [0] NCCL INFO Connected all rings
 57: hkn0419:1544215:1544300 [1] NCCL INFO Connected all rings
128: hkn0509:3124288:3124402 [0] NCCL INFO Connected all rings
 82: hkn0425:2083927:2084031 [2] NCCL INFO Connected all rings
505: hkn0815:395028:395124 [1] NCCL INFO Connected all rings
  5: hkn0404:1339266:1339391 [1] NCCL INFO Connected all rings
299: hkn0627:1787816:1787921 [3] NCCL INFO Connected all rings
140: hkn0512:3044041:3044149 [0] NCCL INFO Connected all rings
367: hkn0711:583792:583925 [3] NCCL INFO Channel 01 : 367[e3000] -> 366[ca000] via P2P/IPC/read
355: hkn0707:4019792:4019918 [3] NCCL INFO Channel 01 : 355[e3000] -> 354[ca000] via P2P/IPC/read
 48: hkn0417:2267551:2267653 [0] NCCL INFO Connected all rings
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 00 : 60[31000] -> 61[4b000] via P2P/IPC/read
180: hkn0526:1428298:1428416 [0] NCCL INFO Connected all rings
 44: hkn0415:2496321:2496433 [0] NCCL INFO Connected all rings
 38: hkn0413:2366608:2366707 [2] NCCL INFO Connected all rings
117: hkn0506:837969:838070 [1] NCCL INFO Connected all rings
455: hkn0736:1508224:1508372 [3] NCCL INFO Connected all rings
  1: hkn0403:1763954:1764350 [1] NCCL INFO Connected all rings
 70: hkn0422:4153005:4153119 [2] NCCL INFO Connected all rings
504: hkn0815:395016:395129 [0] NCCL INFO Connected all rings
 21: hkn0409:2585543:2585692 [1] NCCL INFO Connected all rings
105: hkn0503:2899564:2899692 [1] NCCL INFO Connected all rings
 42: hkn0414:1981511:1981611 [2] NCCL INFO Connected all rings
125: hkn0508:3139009:3139136 [1] NCCL INFO Connected all rings
113: hkn0505:2303684:2303783 [1] NCCL INFO Connected all rings
 74: hkn0423:1704821:1704920 [2] NCCL INFO Connected all rings
 34: hkn0412:2262277:2262396 [2] NCCL INFO Connected all rings
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 00 : 36[31000] -> 37[4b000] via P2P/IPC/read
 90: hkn0427:1135009:1135135 [2] NCCL INFO Connected all rings
  9: hkn0405:3206758:3206903 [1] NCCL INFO Connected all rings
484: hkn0808:970557:970676 [0] NCCL INFO Connected all rings
496: hkn0812:693695:693790 [0] NCCL INFO Connected all rings
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 00 : 64[31000] -> 65[4b000] via P2P/IPC/read
492: hkn0810:939409:939536 [0] NCCL INFO Connected all rings
165: hkn0521:1197671:1197795 [1] NCCL INFO Connected all rings
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 00 : 84[31000] -> 85[4b000] via P2P/IPC/read
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 00 : 88[31000] -> 89[4b000] via P2P/IPC/read
509: hkn0816:375500:375645 [1] NCCL INFO Connected all rings
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 00 : 80[31000] -> 81[4b000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Connected all rings
173: hkn0524:1133699:1133792 [1] NCCL INFO Connected all rings
 86: hkn0426:813946:814074 [2] NCCL INFO Connected all rings
500: hkn0814:675728:675835 [0] NCCL INFO Connected all rings
129: hkn0509:3124280:3124408 [1] NCCL INFO Connected all rings
427: hkn0727:1345680:1345791 [3] NCCL INFO Channel 00 : 427[e3000] -> 426[ca000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Connected all rings
176: hkn0525:986689:986834 [0] NCCL INFO Connected all rings
177: hkn0525:986697:986833 [1] NCCL INFO Connected all rings
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 00 : 40[31000] -> 41[4b000] via P2P/IPC/read
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 00 : 32[31000] -> 33[4b000] via P2P/IPC/read
497: hkn0812:693675:693791 [1] NCCL INFO Connected all rings
149: hkn0514:2950618:2950734 [1] NCCL INFO Connected all rings
160: hkn0520:2712777:2712878 [0] NCCL INFO Connected all rings
375: hkn0713:470140:470235 [3] NCCL INFO Connected all rings
184: hkn0527:1348838:1348947 [0] NCCL INFO Connected all rings
181: hkn0526:1428306:1428417 [1] NCCL INFO Connected all rings
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 00 : 24[31000] -> 25[4b000] via P2P/IPC/read
164: hkn0521:1197679:1197790 [0] NCCL INFO Connected all rings
 94: hkn0428:667247:667347 [2] NCCL INFO Connected all rings
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 00 : 72[31000] -> 73[4b000] via P2P/IPC/read
485: hkn0808:970565:970682 [1] NCCL INFO Connected all rings
141: hkn0512:3044053:3044152 [1] NCCL INFO Connected all rings
 68: hkn0422:4153004:4153125 [0] NCCL INFO Connected all rings
367: hkn0711:583792:583925 [3] NCCL INFO Connected all rings
269: hkn0616:404794:404911 [1] NCCL INFO Connected all rings
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 00 : 92[31000] -> 93[4b000] via P2P/IPC/read
355: hkn0707:4019792:4019918 [3] NCCL INFO Connected all rings
489: hkn0809:937231:937375 [1] NCCL INFO Connected all rings
168: hkn0523:1547961:1548090 [0] NCCL INFO Connected all rings
 54: hkn0418:1869045:1869174 [2] NCCL INFO Connected all rings
427: hkn0727:1345680:1345791 [3] NCCL INFO Channel 01 : 427[e3000] -> 426[ca000] via P2P/IPC/read
 78: hkn0424:2947862:2947966 [2] NCCL INFO Connected all rings
157: hkn0516:2915847:2915969 [1] NCCL INFO Connected all rings
 30: hkn0411:2315763:2315863 [2] NCCL INFO Connected all rings
 58: hkn0419:1544203:1544299 [2] NCCL INFO Connected all rings
 96: hkn0501:1327777:1327903 [0] NCCL INFO Connected all rings
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 01 : 64[31000] -> 65[4b000] via P2P/IPC/read
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 00 : 76[31000] -> 77[4b000] via P2P/IPC/read
169: hkn0523:1547989:1548085 [1] NCCL INFO Connected all rings
 18: hkn0408:2890646:2890768 [2] NCCL INFO Connected all rings
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 01 : 60[31000] -> 61[4b000] via P2P/IPC/read
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 00 : 28[31000] -> 29[4b000] via P2P/IPC/read
212: hkn0535:2398877:2398992 [0] NCCL INFO Connected all rings
204: hkn0532:924615:924928 [0] NCCL INFO Connected all rings
188: hkn0528:1301555:1301679 [0] NCCL INFO Connected all rings
268: hkn0616:404786:404909 [0] NCCL INFO Connected all rings
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 00 : 44[31000] -> 45[4b000] via P2P/IPC/read
137: hkn0511:3066282:3066391 [1] NCCL INFO Connected all rings
122: hkn0507:3186958:3187070 [2] NCCL INFO Connected all rings
208: hkn0534:1148264:1148419 [0] NCCL INFO Connected all rings
260: hkn0613:902581:902700 [0] NCCL INFO Connected all rings
221: hkn0602:3362307:3362555 [1] NCCL INFO Connected all rings
213: hkn0535:2398861:2398990 [1] NCCL INFO Connected all rings
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 00 : 61[4b000] -> 62[ca000] via P2P/IPC/read
256: hkn0612:916852:916975 [0] NCCL INFO Connected all rings
200: hkn0531:1230521:1230636 [0] NCCL INFO Connected all rings
493: hkn0810:939417:939538 [1] NCCL INFO Connected all rings
252: hkn0611:709722:709820 [0] NCCL INFO Connected all rings
192: hkn0529:1540728:1540857 [0] NCCL INFO Connected all rings
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 00 : 56[31000] -> 57[4b000] via P2P/IPC/read
248: hkn0609:710728:710827 [0] NCCL INFO Connected all rings
472: hkn0805:1111994:1112121 [0] NCCL INFO Connected all rings
481: hkn0807:1018958:1019082 [1] NCCL INFO Connected all rings
110: hkn0504:40723:40837 [2] NCCL INFO Connected all rings
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 01 : 36[31000] -> 37[4b000] via P2P/IPC/read
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 01 : 84[31000] -> 85[4b000] via P2P/IPC/read
161: hkn0520:2712765:2712877 [1] NCCL INFO Connected all rings
185: hkn0527:1348822:1348946 [1] NCCL INFO Connected all rings
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 00 : 52[31000] -> 53[4b000] via P2P/IPC/read
506: hkn0815:395000:395128 [2] NCCL INFO Connected all rings
197: hkn0530:1258062:1258153 [1] NCCL INFO Connected all rings
  6: hkn0404:1339274:1339395 [2] NCCL INFO Connected all rings
108: hkn0504:40743:40838 [0] NCCL INFO Channel 00 : 108[31000] -> 109[4b000] via P2P/IPC/read
 50: hkn0417:2267531:2267655 [2] NCCL INFO Connected all rings
264: hkn0615:414213:414324 [0] NCCL INFO Connected all rings
476: hkn0806:1054250:1054352 [0] NCCL INFO Connected all rings
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 01 : 80[31000] -> 81[4b000] via P2P/IPC/read
257: hkn0612:916860:916982 [1] NCCL INFO Connected all rings
106: hkn0503:2899580:2899695 [2] NCCL INFO Connected all rings
501: hkn0814:675740:675838 [1] NCCL INFO Connected all rings
261: hkn0613:902589:902698 [1] NCCL INFO Connected all rings
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 01 : 88[31000] -> 89[4b000] via P2P/IPC/read
477: hkn0806:1054230:1054353 [1] NCCL INFO Connected all rings
236: hkn0606:2371977:2372089 [0] NCCL INFO Connected all rings
196: hkn0530:1258042:1258156 [0] NCCL INFO Connected all rings
265: hkn0615:414225:414318 [1] NCCL INFO Connected all rings
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 00 : 120[31000] -> 121[4b000] via P2P/IPC/read
 97: hkn0501:1327797:1327897 [1] NCCL INFO Connected all rings
  2: hkn0403:1763934:1764351 [2] NCCL INFO Connected all rings
209: hkn0534:1148292:1148420 [1] NCCL INFO Connected all rings
 22: hkn0409:2585544:2585697 [2] NCCL INFO Connected all rings
118: hkn0506:837941:838072 [2] NCCL INFO Connected all rings
245: hkn0608:485636:485738 [1] NCCL INFO Connected all rings
114: hkn0505:2303656:2303781 [2] NCCL INFO Connected all rings
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 01 : 40[31000] -> 41[4b000] via P2P/IPC/read
237: hkn0606:2371969:2372080 [1] NCCL INFO Connected all rings
240: hkn0607:904254:904366 [0] NCCL INFO Connected all rings
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 01 : 32[31000] -> 33[4b000] via P2P/IPC/read
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 00 : 20[31000] -> 21[4b000] via P2P/IPC/read
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via P2P/IPC/read
 12: hkn0407:1816178:1816273 [0] NCCL INFO Connected all rings
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 00 : 4[31000] -> 5[4b000] via P2P/IPC/read
189: hkn0528:1301571:1301681 [1] NCCL INFO Connected all rings
193: hkn0529:1540700:1540850 [1] NCCL INFO Connected all rings
126: hkn0508:3139025:3139135 [2] NCCL INFO Connected all rings
166: hkn0521:1197663:1197794 [2] NCCL INFO Connected all rings
427: hkn0727:1345680:1345791 [3] NCCL INFO Connected all rings
 62: hkn0420:3210093:3210219 [2] NCCL INFO Channel 00 : 62[ca000] -> 63[e3000] via P2P/IPC/read
504: hkn0815:395016:395129 [0] NCCL INFO Channel 00 : 504[31000] -> 505[4b000] via P2P/IPC/read
480: hkn0807:1018966:1019081 [0] NCCL INFO Connected all rings
100: hkn0502:228966:229066 [0] NCCL INFO Connected all rings
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 00 : 112[31000] -> 113[4b000] via P2P/IPC/read
276: hkn0621:1991476:1991587 [0] NCCL INFO Connected all rings
158: hkn0516:2915855:2915974 [2] NCCL INFO Connected all rings
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 01 : 72[31000] -> 73[4b000] via P2P/IPC/read
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 00 : 48[31000] -> 49[4b000] via P2P/IPC/read
510: hkn0816:375512:375637 [2] NCCL INFO Connected all rings
253: hkn0611:709702:709825 [1] NCCL INFO Connected all rings
473: hkn0805:1112022:1112123 [1] NCCL INFO Connected all rings
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 01 : 61[4b000] -> 62[ca000] via P2P/IPC/read
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 01 : 24[31000] -> 25[4b000] via P2P/IPC/read
289: hkn0624:1772850:1772951 [1] NCCL INFO Connected all rings
 10: hkn0405:3206770:3206895 [2] NCCL INFO Connected all rings
468: hkn0804:1205515:1205623 [0] NCCL INFO Connected all rings
174: hkn0524:1133687:1133798 [2] NCCL INFO Connected all rings
341: hkn0704:791903:792016 [1] NCCL INFO Connected all rings
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 00 : 124[31000] -> 125[4b000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO Connected all rings
272: hkn0617:2294566:2294704 [0] NCCL INFO Connected all rings
205: hkn0532:924607:924924 [1] NCCL INFO Connected all rings
150: hkn0514:2950610:2950728 [2] NCCL INFO Connected all rings
144: hkn0513:3012844:3012958 [0] NCCL INFO Connected all rings
116: hkn0506:837949:838063 [0] NCCL INFO Channel 00 : 116[31000] -> 117[4b000] via P2P/IPC/read
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 00 : 68[31000] -> 69[4b000] via P2P/IPC/read
508: hkn0816:375484:375639 [0] NCCL INFO Channel 00 : 508[31000] -> 509[4b000] via P2P/IPC/read
130: hkn0509:3124308:3124406 [2] NCCL INFO Connected all rings
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 01 : 92[31000] -> 93[4b000] via P2P/IPC/read
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 00 : 8[31000] -> 9[4b000] via P2P/IPC/read
244: hkn0608:485608:485739 [0] NCCL INFO Connected all rings
 37: hkn0413:2366588:2366711 [1] NCCL INFO Channel 00 : 37[4b000] -> 38[ca000] via P2P/IPC/read
178: hkn0525:986708:986837 [2] NCCL INFO Connected all rings
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 01 : 76[31000] -> 77[4b000] via P2P/IPC/read
 45: hkn0415:2496313:2496432 [1] NCCL INFO Connected all rings
224: hkn0603:1413107:1413231 [0] NCCL INFO Connected all rings
469: hkn0804:1205507:1205626 [1] NCCL INFO Connected all rings
201: hkn0531:1230529:1230638 [1] NCCL INFO Connected all rings
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 00 : 128[31000] -> 129[4b000] via P2P/IPC/read
 69: hkn0422:4153025:4153124 [1] NCCL INFO Channel 00 : 69[4b000] -> 70[ca000] via P2P/IPC/read
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 01 : 28[31000] -> 29[4b000] via P2P/IPC/read
182: hkn0526:1428290:1428419 [2] NCCL INFO Connected all rings
465: hkn0803:876477:876562 [1] NCCL INFO Connected all rings
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 00 : 81[4b000] -> 82[ca000] via P2P/IPC/read
444: hkn0733:1389270:1389389 [0] NCCL INFO Connected all rings
233: hkn0605:712002:712113 [1] NCCL INFO Connected all rings
498: hkn0812:693667:693793 [2] NCCL INFO Connected all rings
344: hkn0705:783129:783218 [0] NCCL INFO Connected all rings
270: hkn0616:404806:404907 [2] NCCL INFO Connected all rings
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 00 : 25[4b000] -> 26[ca000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Connected all rings
214: hkn0535:2398869:2398986 [2] NCCL INFO Connected all rings
 85: hkn0426:813954:814076 [1] NCCL INFO Channel 00 : 85[4b000] -> 86[ca000] via P2P/IPC/read
288: hkn0624:1772822:1772950 [0] NCCL INFO Connected all rings
142: hkn0512:3044033:3044156 [2] NCCL INFO Connected all rings
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 00 : 89[4b000] -> 90[ca000] via P2P/IPC/read
486: hkn0808:970577:970677 [2] NCCL INFO Connected all rings
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 00 : 164[31000] -> 165[4b000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 00 : 172[31000] -> 173[4b000] via P2P/IPC/read
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 01 : 56[31000] -> 57[4b000] via P2P/IPC/read
132: hkn0510:2761944:2762047 [0] NCCL INFO Connected all rings
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 00 : 180[31000] -> 181[4b000] via P2P/IPC/read
232: hkn0605:711997:712115 [0] NCCL INFO Connected all rings
228: hkn0604:689133:689241 [0] NCCL INFO Connected all rings
148: hkn0514:2950603:2950729 [0] NCCL INFO Connected all rings
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 00 : 140[31000] -> 141[4b000] via P2P/IPC/read
494: hkn0810:939437:939537 [2] NCCL INFO Connected all rings
445: hkn0733:1389278:1389388 [1] NCCL INFO Connected all rings
138: hkn0511:3066294:3066390 [2] NCCL INFO Connected all rings
490: hkn0809:937230:937376 [2] NCCL INFO Connected all rings
496: hkn0812:693695:693790 [0] NCCL INFO Channel 00 : 496[31000] -> 497[4b000] via P2P/IPC/read
484: hkn0808:970557:970676 [0] NCCL INFO Channel 00 : 484[31000] -> 485[4b000] via P2P/IPC/read
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 00 : 41[4b000] -> 42[ca000] via P2P/IPC/read
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 01 : 52[31000] -> 53[4b000] via P2P/IPC/read
108: hkn0504:40743:40838 [0] NCCL INFO Channel 01 : 108[31000] -> 109[4b000] via P2P/IPC/read
312: hkn0631:1021735:1021830 [0] NCCL INFO Connected all rings
440: hkn0732:1211563:1211665 [0] NCCL INFO Connected all rings
464: hkn0803:876465:876561 [0] NCCL INFO Connected all rings
222: hkn0602:3362295:3362554 [2] NCCL INFO Connected all rings
277: hkn0621:1991460:1991584 [1] NCCL INFO Connected all rings
156: hkn0516:2915863:2915972 [0] NCCL INFO Connected all rings
388: hkn0717:4187551:4187658 [0] NCCL INFO Connected all rings
176: hkn0525:986689:986834 [0] NCCL INFO Channel 00 : 176[31000] -> 177[4b000] via P2P/IPC/read
 82: hkn0425:2083927:2084031 [2] NCCL INFO Channel 00 : 82[ca000] -> 83[e3000] via P2P/IPC/read
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 00 : 33[4b000] -> 34[ca000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Channel 00 : 488[31000] -> 489[4b000] via P2P/IPC/read
258: hkn0612:916880:916979 [2] NCCL INFO Connected all rings
300: hkn0628:671767:671903 [0] NCCL INFO Connected all rings
320: hkn0633:1526202:1526350 [0] NCCL INFO Connected all rings
441: hkn0732:1211535:1211667 [1] NCCL INFO Connected all rings
478: hkn0806:1054238:1054345 [2] NCCL INFO Connected all rings
502: hkn0814:675720:675841 [2] NCCL INFO Connected all rings
389: hkn0717:4187531:4187655 [1] NCCL INFO Connected all rings
249: hkn0609:710716:710825 [1] NCCL INFO Connected all rings
345: hkn0705:783117:783216 [1] NCCL INFO Connected all rings
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 00 : 73[4b000] -> 74[ca000] via P2P/IPC/read
 26: hkn0410:1159602:1159714 [2] NCCL INFO Channel 00 : 26[ca000] -> 27[e3000] via P2P/IPC/read
170: hkn0523:1547969:1548086 [2] NCCL INFO Connected all rings
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 01 : 120[31000] -> 121[4b000] via P2P/IPC/read
 38: hkn0413:2366608:2366707 [2] NCCL INFO Channel 00 : 38[ca000] -> 39[e3000] via P2P/IPC/read
482: hkn0807:1018950:1019079 [2] NCCL INFO Connected all rings
241: hkn0607:904238:904362 [1] NCCL INFO Connected all rings
 13: hkn0407:1816167:1816272 [1] NCCL INFO Connected all rings
321: hkn0633:1526230:1526356 [1] NCCL INFO Connected all rings
309: hkn0630:1598347:1598454 [1] NCCL INFO Connected all rings
273: hkn0617:2294577:2294697 [1] NCCL INFO Connected all rings
492: hkn0810:939409:939536 [0] NCCL INFO Channel 00 : 492[31000] -> 493[4b000] via P2P/IPC/read
460: hkn0802:1200224:1200344 [0] NCCL INFO Connected all rings
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 00 : 93[4b000] -> 94[ca000] via P2P/IPC/read
336: hkn0703:740936:741046 [0] NCCL INFO Connected all rings
268: hkn0616:404786:404909 [0] NCCL INFO Channel 00 : 268[31000] -> 269[4b000] via P2P/IPC/read
 37: hkn0413:2366588:2366711 [1] NCCL INFO Channel 01 : 37[4b000] -> 38[ca000] via P2P/IPC/read
285: hkn0623:1872640:1872768 [1] NCCL INFO Connected all rings
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 00 : 144[31000] -> 145[4b000] via P2P/IPC/read
 42: hkn0414:1981511:1981611 [2] NCCL INFO Channel 00 : 42[ca000] -> 43[e3000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Connected all rings
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 00 : 212[31000] -> 213[4b000] via P2P/IPC/read
104: hkn0503:2899591:2899697 [0] NCCL INFO Connected all rings
500: hkn0814:675728:675835 [0] NCCL INFO Channel 00 : 500[31000] -> 501[4b000] via P2P/IPC/read
216: hkn0601:117612:117713 [0] NCCL INFO Connected all rings
101: hkn0502:228954:229059 [1] NCCL INFO Connected all rings
 65: hkn0421:2180584:2180857 [1] NCCL INFO Connected all rings
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via P2P/IPC/read
186: hkn0527:1348830:1348950 [2] NCCL INFO Connected all rings
316: hkn0632:1758503:1758621 [0] NCCL INFO Connected all rings
229: hkn0604:689145:689242 [1] NCCL INFO Connected all rings
 90: hkn0427:1135009:1135135 [2] NCCL INFO Channel 00 : 90[ca000] -> 91[e3000] via P2P/IPC/read
385: hkn0716:108390:108502 [1] NCCL INFO Connected all rings
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 01 : 81[4b000] -> 82[ca000] via P2P/IPC/read
 34: hkn0412:2262277:2262396 [2] NCCL INFO Channel 00 : 34[ca000] -> 35[e3000] via P2P/IPC/read
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 01 : 20[31000] -> 21[4b000] via P2P/IPC/read
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 00 : 17[4b000] -> 18[ca000] via P2P/IPC/read
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 01 : 4[31000] -> 5[4b000] via P2P/IPC/read
437: hkn0731:1386617:1386741 [1] NCCL INFO Connected all rings
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 01 : 112[31000] -> 113[4b000] via P2P/IPC/read
504: hkn0815:395016:395129 [0] NCCL INFO Channel 01 : 504[31000] -> 505[4b000] via P2P/IPC/read
162: hkn0520:2712749:2712876 [2] NCCL INFO Connected all rings
198: hkn0530:1258034:1258159 [2] NCCL INFO Connected all rings
225: hkn0603:1413115:1413233 [1] NCCL INFO Connected all rings
340: hkn0704:791895:792019 [0] NCCL INFO Connected all rings
152: hkn0515:2896675:2896797 [0] NCCL INFO Connected all rings
 74: hkn0423:1704821:1704920 [2] NCCL INFO Channel 00 : 74[ca000] -> 75[e3000] via P2P/IPC/read
 86: hkn0426:813946:814074 [2] NCCL INFO Channel 00 : 86[ca000] -> 87[e3000] via P2P/IPC/read
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 00 : 184[31000] -> 185[4b000] via P2P/IPC/read
 62: hkn0420:3210093:3210219 [2] NCCL INFO Channel 01 : 62[ca000] -> 63[e3000] via P2P/IPC/read
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 01 : 25[4b000] -> 26[ca000] via P2P/IPC/read
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 01 : 124[31000] -> 125[4b000] via P2P/IPC/read
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 00 : 77[4b000] -> 78[ca000] via P2P/IPC/read
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 01 : 89[4b000] -> 90[ca000] via P2P/IPC/read
384: hkn0716:108410:108503 [0] NCCL INFO Connected all rings
456: hkn0801:2239904:2240015 [0] NCCL INFO Connected all rings
262: hkn0613:902573:902699 [2] NCCL INFO Connected all rings
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 00 : 168[31000] -> 169[4b000] via P2P/IPC/read
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 00 : 29[4b000] -> 30[ca000] via P2P/IPC/read
461: hkn0802:1200244:1200347 [1] NCCL INFO Connected all rings
 85: hkn0426:813954:814076 [1] NCCL INFO Channel 01 : 85[4b000] -> 86[ca000] via P2P/IPC/read
266: hkn0615:414205:414319 [2] NCCL INFO Connected all rings
297: hkn0627:1787808:1787920 [1] NCCL INFO Connected all rings
116: hkn0506:837949:838063 [0] NCCL INFO Channel 01 : 116[31000] -> 117[4b000] via P2P/IPC/read
508: hkn0816:375484:375639 [0] NCCL INFO Channel 01 : 508[31000] -> 509[4b000] via P2P/IPC/read
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 01 : 68[31000] -> 69[4b000] via P2P/IPC/read
 98: hkn0501:1327785:1327898 [2] NCCL INFO Connected all rings
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 00 : 160[31000] -> 161[4b000] via P2P/IPC/read
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 01 : 48[31000] -> 49[4b000] via P2P/IPC/read
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 01 : 8[31000] -> 9[4b000] via P2P/IPC/read
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 00 : 476[31000] -> 477[4b000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Connected all rings
256: hkn0612:916852:916975 [0] NCCL INFO Channel 00 : 256[31000] -> 257[4b000] via P2P/IPC/read
246: hkn0608:485616:485737 [2] NCCL INFO Connected all rings
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 00 : 57[4b000] -> 58[ca000] via P2P/IPC/read
313: hkn0631:1021707:1021834 [1] NCCL INFO Connected all rings
453: hkn0736:1508232:1508369 [1] NCCL INFO Connected all rings
210: hkn0534:1148280:1148416 [2] NCCL INFO Connected all rings
342: hkn0704:791887:792017 [2] NCCL INFO Connected all rings
 53: hkn0418:1869083:1869169 [1] NCCL INFO Channel 00 : 53[4b000] -> 54[ca000] via P2P/IPC/read
 70: hkn0422:4153005:4153119 [2] NCCL INFO Channel 00 : 70[ca000] -> 71[e3000] via P2P/IPC/read
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 01 : 41[4b000] -> 42[ca000] via P2P/IPC/read
238: hkn0606:2371989:2372088 [2] NCCL INFO Connected all rings
190: hkn0528:1301582:1301674 [2] NCCL INFO Connected all rings
337: hkn0703:740940:741049 [1] NCCL INFO Connected all rings
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 00 : 96[31000] -> 97[4b000] via P2P/IPC/read
 69: hkn0422:4153025:4153124 [1] NCCL INFO Channel 01 : 69[4b000] -> 70[ca000] via P2P/IPC/read
234: hkn0605:711998:712112 [2] NCCL INFO Connected all rings
220: hkn0602:3362279:3362548 [0] NCCL INFO Connected all rings
416: hkn0725:3111837:3111934 [0] NCCL INFO Connected all rings
405: hkn0721:2299079:2299192 [1] NCCL INFO Connected all rings
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 01 : 33[4b000] -> 34[ca000] via P2P/IPC/read
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 01 : 128[31000] -> 129[4b000] via P2P/IPC/read
202: hkn0531:1230513:1230642 [2] NCCL INFO Connected all rings
302: hkn0628:671759:671904 [2] NCCL INFO Connected all rings
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 00 : 105[4b000] -> 106[ca000] via P2P/IPC/read
429: hkn0728:1323903:1323996 [1] NCCL INFO Connected all rings
260: hkn0613:902581:902700 [0] NCCL INFO Channel 00 : 260[31000] -> 261[4b000] via P2P/IPC/read
413: hkn0724:1715874:1715982 [1] NCCL INFO Connected all rings
380: hkn0715:401772:401896 [0] NCCL INFO Connected all rings
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 00 : 480[31000] -> 481[4b000] via P2P/IPC/read
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 00 : 121[4b000] -> 122[ca000] via P2P/IPC/read
206: hkn0532:924599:924925 [2] NCCL INFO Connected all rings
333: hkn0636:1654159:1654274 [1] NCCL INFO Connected all rings
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 01 : 73[4b000] -> 74[ca000] via P2P/IPC/read
290: hkn0624:1772838:1772944 [2] NCCL INFO Connected all rings
376: hkn0714:431923:432030 [0] NCCL INFO Connected all rings
136: hkn0511:3066274:3066392 [0] NCCL INFO Connected all rings
109: hkn0504:40731:40842 [1] NCCL INFO Channel 00 : 109[4b000] -> 110[ca000] via P2P/IPC/read
254: hkn0611:709710:709819 [2] NCCL INFO Connected all rings
317: hkn0632:1758522:1758616 [1] NCCL INFO Connected all rings
332: hkn0636:1654151:1654265 [0] NCCL INFO Connected all rings
194: hkn0529:1540708:1540856 [2] NCCL INFO Connected all rings
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 00 : 196[31000] -> 197[4b000] via P2P/IPC/read
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 01 : 164[31000] -> 165[4b000] via P2P/IPC/read
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 00 : 208[31000] -> 209[4b000] via P2P/IPC/read
 94: hkn0428:667247:667347 [2] NCCL INFO Channel 00 : 94[ca000] -> 95[e3000] via P2P/IPC/read
404: hkn0721:2299087:2299193 [0] NCCL INFO Connected all rings
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 01 : 180[31000] -> 181[4b000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 01 : 172[31000] -> 173[4b000] via P2P/IPC/read
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 00 : 188[31000] -> 189[4b000] via P2P/IPC/read
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 01 : 93[4b000] -> 94[ca000] via P2P/IPC/read
264: hkn0615:414213:414324 [0] NCCL INFO Channel 00 : 264[31000] -> 265[4b000] via P2P/IPC/read
204: hkn0532:924615:924928 [0] NCCL INFO Channel 00 : 204[31000] -> 205[4b000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 00 : 16[31000] -> 17[4b000] via P2P/IPC/read
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 01 : 140[31000] -> 141[4b000] via P2P/IPC/read
252: hkn0611:709722:709820 [0] NCCL INFO Channel 00 : 252[31000] -> 253[4b000] via P2P/IPC/read
474: hkn0805:1112002:1112122 [2] NCCL INFO Connected all rings
484: hkn0808:970557:970676 [0] NCCL INFO Channel 01 : 484[31000] -> 485[4b000] via P2P/IPC/read
496: hkn0812:693695:693790 [0] NCCL INFO Channel 01 : 496[31000] -> 497[4b000] via P2P/IPC/read
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 00 : 148[31000] -> 149[4b000] via P2P/IPC/read
  5: hkn0404:1339266:1339391 [1] NCCL INFO Channel 00 : 5[4b000] -> 6[ca000] via P2P/IPC/read
 54: hkn0418:1869045:1869174 [2] NCCL INFO Channel 00 : 54[ca000] -> 55[e3000] via P2P/IPC/read
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 00 : 192[31000] -> 193[4b000] via P2P/IPC/read
428: hkn0728:1323875:1324003 [0] NCCL INFO Connected all rings
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 00 : 200[31000] -> 201[4b000] via P2P/IPC/read
176: hkn0525:986689:986834 [0] NCCL INFO Channel 01 : 176[31000] -> 177[4b000] via P2P/IPC/read
505: hkn0815:395028:395124 [1] NCCL INFO Channel 00 : 505[4b000] -> 506[ca000] via P2P/IPC/read
216: hkn0601:117612:117713 [0] NCCL INFO Channel 00 : 216[31000] -> 217[4b000] via P2P/IPC/read
284: hkn0623:1872656:1872763 [0] NCCL INFO Connected all rings
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 00 : 236[31000] -> 237[4b000] via P2P/IPC/read
 78: hkn0424:2947862:2947966 [2] NCCL INFO Channel 00 : 78[ca000] -> 79[e3000] via P2P/IPC/read
 82: hkn0425:2083927:2084031 [2] NCCL INFO Channel 01 : 82[ca000] -> 83[e3000] via P2P/IPC/read
 30: hkn0411:2315763:2315863 [2] NCCL INFO Channel 00 : 30[ca000] -> 31[e3000] via P2P/IPC/read
381: hkn0715:401780:401901 [1] NCCL INFO Connected all rings
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 00 : 156[31000] -> 157[4b000] via P2P/IPC/read
280: hkn0622:2020412:2020505 [0] NCCL INFO Connected all rings
457: hkn0801:2239896:2240017 [1] NCCL INFO Connected all rings
466: hkn0803:876456:876564 [2] NCCL INFO Connected all rings
488: hkn0809:937239:937379 [0] NCCL INFO Channel 01 : 488[31000] -> 489[4b000] via P2P/IPC/read
470: hkn0804:1205535:1205629 [2] NCCL INFO Connected all rings
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 00 : 472[31000] -> 473[4b000] via P2P/IPC/read
408: hkn0723:207901:208066 [0] NCCL INFO Connected all rings
244: hkn0608:485608:485739 [0] NCCL INFO Channel 00 : 244[31000] -> 245[4b000] via P2P/IPC/read
 46: hkn0415:2496333:2496437 [2] NCCL INFO Connected all rings
432: hkn0730:1401606:1401733 [0] NCCL INFO Connected all rings
117: hkn0506:837969:838070 [1] NCCL INFO Channel 00 : 117[4b000] -> 118[ca000] via P2P/IPC/read
 21: hkn0409:2585543:2585692 [1] NCCL INFO Channel 00 : 21[4b000] -> 22[ca000] via P2P/IPC/read
377: hkn0714:431907:432038 [1] NCCL INFO Connected all rings
304: hkn0629:1591939:1592054 [0] NCCL INFO Connected all rings
 58: hkn0419:1544203:1544299 [2] NCCL INFO Channel 00 : 58[ca000] -> 59[e3000] via P2P/IPC/read
 26: hkn0410:1159602:1159714 [2] NCCL INFO Channel 01 : 26[ca000] -> 27[e3000] via P2P/IPC/read
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 01 : 77[4b000] -> 78[ca000] via P2P/IPC/read
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 00 : 49[4b000] -> 50[ca000] via P2P/IPC/read
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 01 : 44[31000] -> 45[4b000] via P2P/IPC/read
492: hkn0810:939409:939536 [0] NCCL INFO Channel 01 : 492[31000] -> 493[4b000] via P2P/IPC/read
373: hkn0713:470120:470234 [1] NCCL INFO Connected all rings
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 01 : 29[4b000] -> 30[ca000] via P2P/IPC/read
  1: hkn0403:1763954:1764350 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[ca000] via P2P/IPC/read
248: hkn0609:710728:710827 [0] NCCL INFO Channel 00 : 248[31000] -> 249[4b000] via P2P/IPC/read
322: hkn0633:1526218:1526355 [2] NCCL INFO Connected all rings
436: hkn0731:1386645:1386747 [0] NCCL INFO Connected all rings
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 01 : 57[4b000] -> 58[ca000] via P2P/IPC/read
 38: hkn0413:2366608:2366707 [2] NCCL INFO Channel 01 : 38[ca000] -> 39[e3000] via P2P/IPC/read
268: hkn0616:404786:404909 [0] NCCL INFO Channel 01 : 268[31000] -> 269[4b000] via P2P/IPC/read
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 00 : 125[4b000] -> 126[ca000] via P2P/IPC/read
401: hkn0720:5385:5649 [1] NCCL INFO Connected all rings
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 00 : 288[31000] -> 289[4b000] via P2P/IPC/read
509: hkn0816:375500:375645 [1] NCCL INFO Channel 00 : 509[4b000] -> 510[ca000] via P2P/IPC/read
232: hkn0605:711997:712115 [0] NCCL INFO Channel 00 : 232[31000] -> 233[4b000] via P2P/IPC/read
324: hkn0634:1520769:1520870 [0] NCCL INFO Connected all rings
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 00 : 9[4b000] -> 10[ca000] via P2P/IPC/read
500: hkn0814:675728:675835 [0] NCCL INFO Channel 01 : 500[31000] -> 501[4b000] via P2P/IPC/read
446: hkn0733:1389290:1389387 [2] NCCL INFO Connected all rings
 42: hkn0414:1981511:1981611 [2] NCCL INFO Channel 01 : 42[ca000] -> 43[e3000] via P2P/IPC/read
 53: hkn0418:1869083:1869169 [1] NCCL INFO Channel 01 : 53[4b000] -> 54[ca000] via P2P/IPC/read
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 01 : 212[31000] -> 213[4b000] via P2P/IPC/read
122: hkn0507:3186958:3187070 [2] NCCL INFO Channel 00 : 122[ca000] -> 123[e3000] via P2P/IPC/read
 34: hkn0412:2262277:2262396 [2] NCCL INFO Channel 01 : 34[ca000] -> 35[e3000] via P2P/IPC/read
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 00 : 113[4b000] -> 114[ca000] via P2P/IPC/read
230: hkn0604:689117:689240 [2] NCCL INFO Connected all rings
110: hkn0504:40723:40837 [2] NCCL INFO Channel 00 : 110[ca000] -> 111[e3000] via P2P/IPC/read
310: hkn0630:1598359:1598459 [2] NCCL INFO Connected all rings
 18: hkn0408:2890646:2890768 [2] NCCL INFO Channel 00 : 18[ca000] -> 19[e3000] via P2P/IPC/read
 74: hkn0423:1704821:1704920 [2] NCCL INFO Channel 01 : 74[ca000] -> 75[e3000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 00 : 129[4b000] -> 130[ca000] via P2P/IPC/read
390: hkn0717:4187539:4187652 [2] NCCL INFO Connected all rings
250: hkn0609:710708:710822 [2] NCCL INFO Connected all rings
278: hkn0621:1991488:1991585 [2] NCCL INFO Connected all rings
109: hkn0504:40731:40842 [1] NCCL INFO Channel 01 : 109[4b000] -> 110[ca000] via P2P/IPC/read
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 00 : 104[31000] -> 105[4b000] via P2P/IPC/read
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 01 : 121[4b000] -> 122[ca000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 00 : 468[31000] -> 469[4b000] via P2P/IPC/read
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 01 : 17[4b000] -> 18[ca000] via P2P/IPC/read
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 00 : 173[4b000] -> 174[ca000] via P2P/IPC/read
149: hkn0514:2950618:2950734 [1] NCCL INFO Channel 00 : 149[4b000] -> 150[ca000] via P2P/IPC/read
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 01 : 184[31000] -> 185[4b000] via P2P/IPC/read
133: hkn0510:2761928:2762038 [1] NCCL INFO Connected all rings
329: hkn0635:1225473:1225593 [1] NCCL INFO Connected all rings
165: hkn0521:1197671:1197795 [1] NCCL INFO Channel 00 : 165[4b000] -> 166[ca000] via P2P/IPC/read
242: hkn0607:904266:904368 [2] NCCL INFO Connected all rings
412: hkn0724:1715866:1715984 [0] NCCL INFO Connected all rings
 66: hkn0421:2180592:2180858 [2] NCCL INFO Connected all rings
346: hkn0705:783101:783217 [2] NCCL INFO Connected all rings
 86: hkn0426:813946:814074 [2] NCCL INFO Channel 01 : 86[ca000] -> 87[e3000] via P2P/IPC/read
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 01 : 160[31000] -> 161[4b000] via P2P/IPC/read
 90: hkn0427:1135009:1135135 [2] NCCL INFO Channel 01 : 90[ca000] -> 91[e3000] via P2P/IPC/read
325: hkn0634:1520753:1520864 [1] NCCL INFO Connected all rings
300: hkn0628:671767:671903 [0] NCCL INFO Channel 00 : 300[31000] -> 301[4b000] via P2P/IPC/read
442: hkn0732:1211543:1211663 [2] NCCL INFO Connected all rings
  2: hkn0403:1763934:1764351 [2] NCCL INFO Channel 00 : 2[ca000] -> 3[e3000] via P2P/IPC/read
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 01 : 168[31000] -> 169[4b000] via P2P/IPC/read
286: hkn0623:1872648:1872765 [2] NCCL INFO Connected all rings
506: hkn0815:395000:395128 [2] NCCL INFO Channel 00 : 506[ca000] -> 507[e3000] via P2P/IPC/read
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 00 : 276[31000] -> 277[4b000] via P2P/IPC/read
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 00 : 157[4b000] -> 158[ca000] via P2P/IPC/read
308: hkn0630:1598339:1598456 [0] NCCL INFO Connected all rings
 14: hkn0407:1816159:1816274 [2] NCCL INFO Connected all rings
  6: hkn0404:1339274:1339395 [2] NCCL INFO Channel 00 : 6[ca000] -> 7[e3000] via P2P/IPC/read
256: hkn0612:916852:916975 [0] NCCL INFO Channel 01 : 256[31000] -> 257[4b000] via P2P/IPC/read
274: hkn0617:2294558:2294701 [2] NCCL INFO Connected all rings
106: hkn0503:2899580:2899695 [2] NCCL INFO Channel 00 : 106[ca000] -> 107[e3000] via P2P/IPC/read
438: hkn0731:1386633:1386740 [2] NCCL INFO Connected all rings
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 01 : 476[31000] -> 477[4b000] via P2P/IPC/read
464: hkn0803:876465:876561 [0] NCCL INFO Channel 00 : 464[31000] -> 465[4b000] via P2P/IPC/read
497: hkn0812:693675:693791 [1] NCCL INFO Channel 00 : 497[4b000] -> 498[ca000] via P2P/IPC/read
505: hkn0815:395028:395124 [1] NCCL INFO Channel 01 : 505[4b000] -> 506[ca000] via P2P/IPC/read
314: hkn0631:1021723:1021832 [2] NCCL INFO Connected all rings
430: hkn0728:1323891:1323997 [2] NCCL INFO Connected all rings
 22: hkn0409:2585544:2585697 [2] NCCL INFO Channel 00 : 22[ca000] -> 23[e3000] via P2P/IPC/read
  5: hkn0404:1339266:1339391 [1] NCCL INFO Channel 01 : 5[4b000] -> 6[ca000] via P2P/IPC/read
177: hkn0525:986697:986833 [1] NCCL INFO Channel 00 : 177[4b000] -> 178[ca000] via P2P/IPC/read
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 01 : 96[31000] -> 97[4b000] via P2P/IPC/read
353: hkn0707:4019808:4019912 [1] NCCL INFO Connected all rings
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 00 : 12[31000] -> 13[4b000] via P2P/IPC/read
240: hkn0607:904254:904366 [0] NCCL INFO Channel 00 : 240[31000] -> 241[4b000] via P2P/IPC/read
340: hkn0704:791895:792019 [0] NCCL INFO Channel 00 : 340[31000] -> 341[4b000] via P2P/IPC/read
260: hkn0613:902581:902700 [0] NCCL INFO Channel 01 : 260[31000] -> 261[4b000] via P2P/IPC/read
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 00 : 444[31000] -> 445[4b000] via P2P/IPC/read
102: hkn0502:228938:229065 [2] NCCL INFO Connected all rings
418: hkn0725:3111809:3111929 [2] NCCL INFO Connected all rings
344: hkn0705:783129:783218 [0] NCCL INFO Channel 00 : 344[31000] -> 345[4b000] via P2P/IPC/read
181: hkn0526:1428306:1428417 [1] NCCL INFO Channel 00 : 181[4b000] -> 182[ca000] via P2P/IPC/read
298: hkn0627:1787836:1787925 [2] NCCL INFO Connected all rings
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 00 : 272[31000] -> 273[4b000] via P2P/IPC/read
 70: hkn0422:4153005:4153119 [2] NCCL INFO Channel 01 : 70[ca000] -> 71[e3000] via P2P/IPC/read
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 00 : 220[31000] -> 221[4b000] via P2P/IPC/read
448: hkn0734:1156433:1156551 [0] NCCL INFO Connected all rings
114: hkn0505:2303656:2303781 [2] NCCL INFO Channel 00 : 114[ca000] -> 115[e3000] via P2P/IPC/read
386: hkn0716:108398:108509 [2] NCCL INFO Connected all rings
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 00 : 320[31000] -> 321[4b000] via P2P/IPC/read
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 01 : 480[31000] -> 481[4b000] via P2P/IPC/read
454: hkn0736:1508244:1508370 [2] NCCL INFO Connected all rings
 21: hkn0409:2585543:2585692 [1] NCCL INFO Channel 01 : 21[4b000] -> 22[ca000] via P2P/IPC/read
118: hkn0506:837941:838072 [2] NCCL INFO Channel 00 : 118[ca000] -> 119[e3000] via P2P/IPC/read
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 00 : 388[31000] -> 389[4b000] via P2P/IPC/read
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 01 : 144[31000] -> 145[4b000] via P2P/IPC/read
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 01 : 105[4b000] -> 106[ca000] via P2P/IPC/read
 10: hkn0405:3206770:3206895 [2] NCCL INFO Channel 00 : 10[ca000] -> 11[e3000] via P2P/IPC/read
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 00 : 440[31000] -> 441[4b000] via P2P/IPC/read
226: hkn0603:1413123:1413232 [2] NCCL INFO Connected all rings
409: hkn0723:207893:208068 [1] NCCL INFO Connected all rings
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 01 : 208[31000] -> 209[4b000] via P2P/IPC/read
100: hkn0502:228966:229066 [0] NCCL INFO Channel 00 : 100[31000] -> 101[4b000] via P2P/IPC/read
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 00 : 137[4b000] -> 138[ca000] via P2P/IPC/read
228: hkn0604:689133:689241 [0] NCCL INFO Channel 00 : 228[31000] -> 229[4b000] via P2P/IPC/read
117: hkn0506:837969:838070 [1] NCCL INFO Channel 01 : 117[4b000] -> 118[ca000] via P2P/IPC/read
485: hkn0808:970565:970682 [1] NCCL INFO Channel 00 : 485[4b000] -> 486[ca000] via P2P/IPC/read
510: hkn0816:375512:375637 [2] NCCL INFO Channel 00 : 510[ca000] -> 511[e3000] via P2P/IPC/read
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 00 : 141[4b000] -> 142[ca000] via P2P/IPC/read
393: hkn0718:3916897:3917023 [1] NCCL INFO Connected all rings
489: hkn0809:937231:937375 [1] NCCL INFO Channel 00 : 489[4b000] -> 490[ca000] via P2P/IPC/read
166: hkn0521:1197663:1197794 [2] NCCL INFO Channel 00 : 166[ca000] -> 167[e3000] via P2P/IPC/read
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 00 : 221[4b000] -> 222[ca000] via P2P/IPC/read
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 00 : 304[31000] -> 305[4b000] via P2P/IPC/read
153: hkn0515:2896667:2896795 [1] NCCL INFO Connected all rings
126: hkn0508:3139025:3139135 [2] NCCL INFO Channel 00 : 126[ca000] -> 127[e3000] via P2P/IPC/read
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 01 : 196[31000] -> 197[4b000] via P2P/IPC/read
 50: hkn0417:2267531:2267655 [2] NCCL INFO Channel 00 : 50[ca000] -> 51[e3000] via P2P/IPC/read
  1: hkn0403:1763954:1764350 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[ca000] via P2P/IPC/read
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 01 : 148[31000] -> 149[4b000] via P2P/IPC/read
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 01 : 188[31000] -> 189[4b000] via P2P/IPC/read
 94: hkn0428:667247:667347 [2] NCCL INFO Channel 01 : 94[ca000] -> 95[e3000] via P2P/IPC/read
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 00 : 224[31000] -> 225[4b000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 01 : 16[31000] -> 17[4b000] via P2P/IPC/read
269: hkn0616:404794:404911 [1] NCCL INFO Channel 00 : 269[4b000] -> 270[ca000] via P2P/IPC/read
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 01 : 125[4b000] -> 126[ca000] via P2P/IPC/read
328: hkn0635:1225461:1225602 [0] NCCL INFO Connected all rings
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 01 : 49[4b000] -> 50[ca000] via P2P/IPC/read
264: hkn0615:414213:414324 [0] NCCL INFO Channel 01 : 264[31000] -> 265[4b000] via P2P/IPC/read
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 01 : 9[4b000] -> 10[ca000] via P2P/IPC/read
252: hkn0611:709722:709820 [0] NCCL INFO Channel 01 : 252[31000] -> 253[4b000] via P2P/IPC/read
204: hkn0532:924615:924928 [0] NCCL INFO Channel 01 : 204[31000] -> 205[4b000] via P2P/IPC/read
 54: hkn0418:1869045:1869174 [2] NCCL INFO Channel 01 : 54[ca000] -> 55[e3000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Connected all rings
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 01 : 192[31000] -> 193[4b000] via P2P/IPC/read
509: hkn0816:375500:375645 [1] NCCL INFO Channel 01 : 509[4b000] -> 510[ca000] via P2P/IPC/read
462: hkn0802:1200232:1200339 [2] NCCL INFO Connected all rings
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 00 : 136[31000] -> 137[4b000] via P2P/IPC/read
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 01 : 200[31000] -> 201[4b000] via P2P/IPC/read
213: hkn0535:2398861:2398990 [1] NCCL INFO Channel 00 : 213[4b000] -> 214[ca000] via P2P/IPC/read
130: hkn0509:3124308:3124406 [2] NCCL INFO Channel 00 : 130[ca000] -> 131[e3000] via P2P/IPC/read
338: hkn0703:740952:741043 [2] NCCL INFO Connected all rings
182: hkn0526:1428290:1428419 [2] NCCL INFO Channel 00 : 182[ca000] -> 183[e3000] via P2P/IPC/read
356: hkn0708:413102:413217 [0] NCCL INFO Connected all rings
493: hkn0810:939417:939538 [1] NCCL INFO Channel 00 : 493[4b000] -> 494[ca000] via P2P/IPC/read
414: hkn0724:1715886:1715987 [2] NCCL INFO Connected all rings
174: hkn0524:1133687:1133798 [2] NCCL INFO Channel 00 : 174[ca000] -> 175[e3000] via P2P/IPC/read
 63: hkn0420:3210091:3210218 [3] NCCL INFO Connected all trees
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 01 : 156[31000] -> 157[4b000] via P2P/IPC/read
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 00 : 132[31000] -> 133[4b000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 01 : 129[4b000] -> 130[ca000] via P2P/IPC/read
433: hkn0730:1401614:1401727 [1] NCCL INFO Connected all rings
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 01 : 113[4b000] -> 114[ca000] via P2P/IPC/read
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 01 : 236[31000] -> 237[4b000] via P2P/IPC/read
406: hkn0721:2299071:2299198 [2] NCCL INFO Connected all rings
400: hkn0720:5369:5640 [0] NCCL INFO Connected all rings
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 00 : 312[31000] -> 313[4b000] via P2P/IPC/read
502: hkn0814:675720:675841 [2] NCCL INFO Channel 00 : 502[ca000] -> 503[e3000] via P2P/IPC/read
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 01 : 472[31000] -> 473[4b000] via P2P/IPC/read
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 01 : 173[4b000] -> 174[ca000] via P2P/IPC/read
244: hkn0608:485608:485739 [0] NCCL INFO Channel 01 : 244[31000] -> 245[4b000] via P2P/IPC/read
 63: hkn0420:3210091:3210218 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
158: hkn0516:2915855:2915974 [2] NCCL INFO Channel 00 : 158[ca000] -> 159[e3000] via P2P/IPC/read
334: hkn0636:1654143:1654268 [2] NCCL INFO Connected all rings
 63: hkn0420:3210091:3210218 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 78: hkn0424:2947862:2947966 [2] NCCL INFO Channel 01 : 78[ca000] -> 79[e3000] via P2P/IPC/read
142: hkn0512:3044033:3044156 [2] NCCL INFO Channel 00 : 142[ca000] -> 143[e3000] via P2P/IPC/read
165: hkn0521:1197671:1197795 [1] NCCL INFO Channel 01 : 165[4b000] -> 166[ca000] via P2P/IPC/read
498: hkn0812:693667:693793 [2] NCCL INFO Channel 00 : 498[ca000] -> 499[e3000] via P2P/IPC/read
 30: hkn0411:2315763:2315863 [2] NCCL INFO Channel 01 : 30[ca000] -> 31[e3000] via P2P/IPC/read
378: hkn0714:431915:432039 [2] NCCL INFO Connected all rings
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 00 : 416[31000] -> 417[4b000] via P2P/IPC/read
178: hkn0525:986708:986837 [2] NCCL INFO Channel 00 : 178[ca000] -> 179[e3000] via P2P/IPC/read
348: hkn0706:752164:752267 [0] NCCL INFO Connected all rings
384: hkn0716:108410:108503 [0] NCCL INFO Channel 00 : 384[31000] -> 385[4b000] via P2P/IPC/read
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 00 : 169[4b000] -> 170[ca000] via P2P/IPC/read
 18: hkn0408:2890646:2890768 [2] NCCL INFO Channel 01 : 18[ca000] -> 19[e3000] via P2P/IPC/read
318: hkn0632:1758495:1758618 [2] NCCL INFO Connected all rings
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 00 : 460[31000] -> 461[4b000] via P2P/IPC/read
257: hkn0612:916860:916982 [1] NCCL INFO Channel 00 : 257[4b000] -> 258[ca000] via P2P/IPC/read
336: hkn0703:740936:741046 [0] NCCL INFO Channel 00 : 336[31000] -> 337[4b000] via P2P/IPC/read
497: hkn0812:693675:693791 [1] NCCL INFO Channel 01 : 497[4b000] -> 498[ca000] via P2P/IPC/read
232: hkn0605:711997:712115 [0] NCCL INFO Channel 01 : 232[31000] -> 233[4b000] via P2P/IPC/read
150: hkn0514:2950610:2950728 [2] NCCL INFO Channel 00 : 150[ca000] -> 151[e3000] via P2P/IPC/read
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 00 : 185[4b000] -> 186[ca000] via P2P/IPC/read
 58: hkn0419:1544203:1544299 [2] NCCL INFO Channel 01 : 58[ca000] -> 59[e3000] via P2P/IPC/read
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 00 : 477[4b000] -> 478[ca000] via P2P/IPC/read
122: hkn0507:3186958:3187070 [2] NCCL INFO Channel 01 : 122[ca000] -> 123[e3000] via P2P/IPC/read
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 00 : 284[31000] -> 285[4b000] via P2P/IPC/read
177: hkn0525:986697:986833 [1] NCCL INFO Channel 01 : 177[4b000] -> 178[ca000] via P2P/IPC/read
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 00 : 161[4b000] -> 162[ca000] via P2P/IPC/read
486: hkn0808:970577:970677 [2] NCCL INFO Channel 00 : 486[ca000] -> 487[e3000] via P2P/IPC/read
149: hkn0514:2950618:2950734 [1] NCCL INFO Channel 01 : 149[4b000] -> 150[ca000] via P2P/IPC/read
270: hkn0616:404806:404907 [2] NCCL INFO Channel 00 : 270[ca000] -> 271[e3000] via P2P/IPC/read
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 01 : 288[31000] -> 289[4b000] via P2P/IPC/read
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 01 : 104[31000] -> 105[4b000] via P2P/IPC/read
494: hkn0810:939437:939537 [2] NCCL INFO Channel 00 : 494[ca000] -> 495[e3000] via P2P/IPC/read
374: hkn0713:470128:470236 [2] NCCL INFO Connected all rings
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 00 : 316[31000] -> 317[4b000] via P2P/IPC/read
365: hkn0711:583808:583920 [1] NCCL INFO Connected all rings
214: hkn0535:2398869:2398986 [2] NCCL INFO Channel 00 : 214[ca000] -> 215[e3000] via P2P/IPC/read
145: hkn0513:3012872:3012961 [1] NCCL INFO Connected all rings
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 00 : 481[4b000] -> 482[ca000] via P2P/IPC/read
490: hkn0809:937230:937376 [2] NCCL INFO Channel 00 : 490[ca000] -> 491[e3000] via P2P/IPC/read
261: hkn0613:902589:902698 [1] NCCL INFO Channel 00 : 261[4b000] -> 262[ca000] via P2P/IPC/read
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 01 : 157[4b000] -> 158[ca000] via P2P/IPC/read
197: hkn0530:1258062:1258153 [1] NCCL INFO Channel 00 : 197[4b000] -> 198[ca000] via P2P/IPC/read
181: hkn0526:1428306:1428417 [1] NCCL INFO Channel 01 : 181[4b000] -> 182[ca000] via P2P/IPC/read
106: hkn0503:2899580:2899695 [2] NCCL INFO Channel 01 : 106[ca000] -> 107[e3000] via P2P/IPC/read
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 00 : 428[31000] -> 429[4b000] via P2P/IPC/read
248: hkn0609:710728:710827 [0] NCCL INFO Channel 01 : 248[31000] -> 249[4b000] via P2P/IPC/read
485: hkn0808:970565:970682 [1] NCCL INFO Channel 01 : 485[4b000] -> 486[ca000] via P2P/IPC/read
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 00 : 404[31000] -> 405[4b000] via P2P/IPC/read
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 00 : 97[4b000] -> 98[ca000] via P2P/IPC/read
354: hkn0707:4019820:4019919 [2] NCCL INFO Connected all rings
110: hkn0504:40723:40837 [2] NCCL INFO Channel 01 : 110[ca000] -> 111[e3000] via P2P/IPC/read
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 00 : 436[31000] -> 437[4b000] via P2P/IPC/read
458: hkn0801:2239916:2240014 [2] NCCL INFO Connected all rings
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 01 : 468[31000] -> 469[4b000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 00 : 292[31000] -> 293[4b000] via P2P/IPC/read
382: hkn0715:401788:401899 [2] NCCL INFO Connected all rings
501: hkn0814:675740:675838 [1] NCCL INFO Channel 00 : 501[4b000] -> 502[ca000] via P2P/IPC/read
489: hkn0809:937231:937375 [1] NCCL INFO Channel 01 : 489[4b000] -> 490[ca000] via P2P/IPC/read
402: hkn0720:5397:5643 [2] NCCL INFO Connected all rings
300: hkn0628:671767:671903 [0] NCCL INFO Channel 01 : 300[31000] -> 301[4b000] via P2P/IPC/read
425: hkn0727:1345672:1345787 [1] NCCL INFO Connected all rings
396: hkn0719:1305611:1305724 [0] NCCL INFO Connected all rings
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 01 : 141[4b000] -> 142[ca000] via P2P/IPC/read
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 00 : 209[4b000] -> 210[ca000] via P2P/IPC/read
  2: hkn0403:1763934:1764351 [2] NCCL INFO Channel 01 : 2[ca000] -> 3[e3000] via P2P/IPC/read
170: hkn0523:1547969:1548086 [2] NCCL INFO Channel 00 : 170[ca000] -> 171[e3000] via P2P/IPC/read
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 00 : 456[31000] -> 457[4b000] via P2P/IPC/read
258: hkn0612:916880:916979 [2] NCCL INFO Channel 00 : 258[ca000] -> 259[e3000] via P2P/IPC/read
245: hkn0608:485636:485738 [1] NCCL INFO Channel 00 : 245[4b000] -> 246[ca000] via P2P/IPC/read
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 00 : 332[31000] -> 333[4b000] via P2P/IPC/read
506: hkn0815:395000:395128 [2] NCCL INFO Channel 01 : 506[ca000] -> 507[e3000] via P2P/IPC/read
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 01 : 276[31000] -> 277[4b000] via P2P/IPC/read
360: hkn0710:355429:355558 [0] NCCL INFO Connected all rings
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 00 : 308[31000] -> 309[4b000] via P2P/IPC/read
464: hkn0803:876465:876561 [0] NCCL INFO Channel 01 : 464[31000] -> 465[4b000] via P2P/IPC/read
269: hkn0616:404794:404911 [1] NCCL INFO Channel 01 : 269[4b000] -> 270[ca000] via P2P/IPC/read
265: hkn0615:414225:414318 [1] NCCL INFO Channel 00 : 265[4b000] -> 266[ca000] via P2P/IPC/read
478: hkn0806:1054238:1054345 [2] NCCL INFO Channel 00 : 478[ca000] -> 479[e3000] via P2P/IPC/read
376: hkn0714:431923:432030 [0] NCCL INFO Channel 00 : 376[31000] -> 377[4b000] via P2P/IPC/read
  6: hkn0404:1339274:1339395 [2] NCCL INFO Channel 01 : 6[ca000] -> 7[e3000] via P2P/IPC/read
138: hkn0511:3066294:3066390 [2] NCCL INFO Channel 00 : 138[ca000] -> 139[e3000] via P2P/IPC/read
420: hkn0726:1548019:1548119 [0] NCCL INFO Connected all rings
452: hkn0736:1508216:1508371 [0] NCCL INFO Connected all rings
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 01 : 12[31000] -> 13[4b000] via P2P/IPC/read
340: hkn0704:791895:792019 [0] NCCL INFO Channel 01 : 340[31000] -> 341[4b000] via P2P/IPC/read
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 00 : 189[4b000] -> 190[ca000] via P2P/IPC/read
380: hkn0715:401772:401896 [0] NCCL INFO Channel 00 : 380[31000] -> 381[4b000] via P2P/IPC/read
213: hkn0535:2398861:2398990 [1] NCCL INFO Channel 01 : 213[4b000] -> 214[ca000] via P2P/IPC/read
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 00 : 280[31000] -> 281[4b000] via P2P/IPC/read
482: hkn0807:1018950:1019079 [2] NCCL INFO Channel 00 : 482[ca000] -> 483[e3000] via P2P/IPC/read
493: hkn0810:939417:939538 [1] NCCL INFO Channel 01 : 493[4b000] -> 494[ca000] via P2P/IPC/read
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 01 : 444[31000] -> 445[4b000] via P2P/IPC/read
253: hkn0611:709702:709825 [1] NCCL INFO Channel 00 : 253[4b000] -> 254[ca000] via P2P/IPC/read
205: hkn0532:924607:924924 [1] NCCL INFO Channel 00 : 205[4b000] -> 206[ca000] via P2P/IPC/read
240: hkn0607:904254:904366 [0] NCCL INFO Channel 01 : 240[31000] -> 241[4b000] via P2P/IPC/read
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 01 : 220[31000] -> 221[4b000] via P2P/IPC/read
114: hkn0505:2303656:2303781 [2] NCCL INFO Channel 01 : 114[ca000] -> 115[e3000] via P2P/IPC/read
344: hkn0705:783129:783218 [0] NCCL INFO Channel 01 : 344[31000] -> 345[4b000] via P2P/IPC/read
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 00 : 193[4b000] -> 194[ca000] via P2P/IPC/read
330: hkn0635:1225453:1225598 [2] NCCL INFO Connected all rings
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 01 : 272[31000] -> 273[4b000] via P2P/IPC/read
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 01 : 320[31000] -> 321[4b000] via P2P/IPC/read
 22: hkn0409:2585544:2585697 [2] NCCL INFO Channel 01 : 22[ca000] -> 23[e3000] via P2P/IPC/read
222: hkn0602:3362295:3362554 [2] NCCL INFO Channel 00 : 222[ca000] -> 223[e3000] via P2P/IPC/read
341: hkn0704:791903:792016 [1] NCCL INFO Channel 00 : 341[4b000] -> 342[ca000] via P2P/IPC/read
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 00 : 237[4b000] -> 238[ca000] via P2P/IPC/read
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 00 : 289[4b000] -> 290[ca000] via P2P/IPC/read
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 01 : 440[31000] -> 441[4b000] via P2P/IPC/read
502: hkn0814:675720:675841 [2] NCCL INFO Channel 01 : 502[ca000] -> 503[e3000] via P2P/IPC/read
134: hkn0510:2761956:2762044 [2] NCCL INFO Connected all rings
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 00 : 412[31000] -> 413[4b000] via P2P/IPC/read
100: hkn0502:228966:229066 [0] NCCL INFO Channel 01 : 100[31000] -> 101[4b000] via P2P/IPC/read
449: hkn0734:1156453:1156552 [1] NCCL INFO Connected all rings
186: hkn0527:1348830:1348950 [2] NCCL INFO Channel 00 : 186[ca000] -> 187[e3000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 00 : 392[31000] -> 393[4b000] via P2P/IPC/read
166: hkn0521:1197663:1197794 [2] NCCL INFO Channel 01 : 166[ca000] -> 167[e3000] via P2P/IPC/read
 39: hkn0413:2366596:2366702 [3] NCCL INFO Connected all trees
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 00 : 473[4b000] -> 474[ca000] via P2P/IPC/read
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 01 : 221[4b000] -> 222[ca000] via P2P/IPC/read
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 01 : 388[31000] -> 389[4b000] via P2P/IPC/read
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 00 : 201[4b000] -> 202[ca000] via P2P/IPC/read
228: hkn0604:689133:689241 [0] NCCL INFO Channel 01 : 228[31000] -> 229[4b000] via P2P/IPC/read
118: hkn0506:837941:838072 [2] NCCL INFO Channel 01 : 118[ca000] -> 119[e3000] via P2P/IPC/read
233: hkn0605:712002:712113 [1] NCCL INFO Channel 00 : 233[4b000] -> 234[ca000] via P2P/IPC/read
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 01 : 137[4b000] -> 138[ca000] via P2P/IPC/read
 27: hkn0410:1159586:1159707 [3] NCCL INFO Connected all trees
162: hkn0520:2712749:2712876 [2] NCCL INFO Channel 00 : 162[ca000] -> 163[e3000] via P2P/IPC/read
326: hkn0634:1520761:1520867 [2] NCCL INFO Connected all rings
394: hkn0718:3916905:3917029 [2] NCCL INFO Connected all rings
 83: hkn0425:2083899:2084034 [3] NCCL INFO Connected all trees
 39: hkn0413:2366596:2366702 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 01 : 169[4b000] -> 170[ca000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO Channel 00 : 301[4b000] -> 302[ca000] via P2P/IPC/read
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 01 : 224[31000] -> 225[4b000] via P2P/IPC/read
 39: hkn0413:2366596:2366702 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
217: hkn0601:117600:117712 [1] NCCL INFO Connected all rings
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 01 : 185[4b000] -> 186[ca000] via P2P/IPC/read
257: hkn0612:916860:916982 [1] NCCL INFO Channel 01 : 257[4b000] -> 258[ca000] via P2P/IPC/read
 27: hkn0410:1159586:1159707 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 01 : 161[4b000] -> 162[ca000] via P2P/IPC/read
266: hkn0615:414205:414319 [2] NCCL INFO Channel 00 : 266[ca000] -> 267[e3000] via P2P/IPC/read
357: hkn0708:413110:413222 [1] NCCL INFO Connected all rings
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 01 : 477[4b000] -> 478[ca000] via P2P/IPC/read
 83: hkn0425:2083899:2084034 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 00 : 45[4b000] -> 46[ca000] via P2P/IPC/read
262: hkn0613:902573:902699 [2] NCCL INFO Channel 00 : 262[ca000] -> 263[e3000] via P2P/IPC/read
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 01 : 304[31000] -> 305[4b000] via P2P/IPC/read
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 00 : 152[31000] -> 153[4b000] via P2P/IPC/read
 27: hkn0410:1159586:1159707 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:752164:752267 [0] NCCL INFO Channel 00 : 348[31000] -> 349[4b000] via P2P/IPC/read
198: hkn0530:1258034:1258159 [2] NCCL INFO Channel 00 : 198[ca000] -> 199[e3000] via P2P/IPC/read
510: hkn0816:375512:375637 [2] NCCL INFO Channel 01 : 510[ca000] -> 511[e3000] via P2P/IPC/read
 83: hkn0425:2083899:2084034 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
190: hkn0528:1301582:1301674 [2] NCCL INFO Channel 00 : 190[ca000] -> 191[e3000] via P2P/IPC/read
126: hkn0508:3139025:3139135 [2] NCCL INFO Channel 01 : 126[ca000] -> 127[e3000] via P2P/IPC/read
 10: hkn0405:3206770:3206895 [2] NCCL INFO Channel 01 : 10[ca000] -> 11[e3000] via P2P/IPC/read
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 01 : 481[4b000] -> 482[ca000] via P2P/IPC/read
261: hkn0613:902589:902698 [1] NCCL INFO Channel 01 : 261[4b000] -> 262[ca000] via P2P/IPC/read
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 01 : 136[31000] -> 137[4b000] via P2P/IPC/read
158: hkn0516:2915855:2915974 [2] NCCL INFO Channel 01 : 158[ca000] -> 159[e3000] via P2P/IPC/read
 98: hkn0501:1327785:1327898 [2] NCCL INFO Channel 00 : 98[ca000] -> 99[e3000] via P2P/IPC/read
197: hkn0530:1258062:1258153 [1] NCCL INFO Channel 01 : 197[4b000] -> 198[ca000] via P2P/IPC/read
182: hkn0526:1428290:1428419 [2] NCCL INFO Channel 01 : 182[ca000] -> 183[e3000] via P2P/IPC/read
130: hkn0509:3124308:3124406 [2] NCCL INFO Channel 01 : 130[ca000] -> 131[e3000] via P2P/IPC/read
281: hkn0622:2020392:2020504 [1] NCCL INFO Connected all rings
 91: hkn0427:1135017:1135131 [3] NCCL INFO Connected all trees
465: hkn0803:876477:876562 [1] NCCL INFO Channel 00 : 465[4b000] -> 466[ca000] via P2P/IPC/read
 43: hkn0414:1981498:1981609 [3] NCCL INFO Connected all trees
238: hkn0606:2371989:2372088 [2] NCCL INFO Channel 00 : 238[ca000] -> 239[e3000] via P2P/IPC/read
 91: hkn0427:1135017:1135131 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 01 : 312[31000] -> 313[4b000] via P2P/IPC/read
 35: hkn0412:2262278:2262387 [3] NCCL INFO Connected all trees
174: hkn0524:1133687:1133798 [2] NCCL INFO Channel 01 : 174[ca000] -> 175[e3000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 01 : 292[31000] -> 293[4b000] via P2P/IPC/read
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 01 : 97[4b000] -> 98[ca000] via P2P/IPC/read
 91: hkn0427:1135017:1135131 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 50: hkn0417:2267531:2267655 [2] NCCL INFO Channel 01 : 50[ca000] -> 51[e3000] via P2P/IPC/read
142: hkn0512:3044033:3044156 [2] NCCL INFO Channel 01 : 142[ca000] -> 143[e3000] via P2P/IPC/read
410: hkn0723:207909:208065 [2] NCCL INFO Connected all rings
210: hkn0534:1148280:1148416 [2] NCCL INFO Channel 00 : 210[ca000] -> 211[e3000] via P2P/IPC/read
 43: hkn0414:1981498:1981609 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 75: hkn0423:1704809:1704921 [3] NCCL INFO Connected all trees
 87: hkn0426:813974:814075 [3] NCCL INFO Connected all trees
 35: hkn0412:2262278:2262387 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1205507:1205626 [1] NCCL INFO Channel 00 : 469[4b000] -> 470[ca000] via P2P/IPC/read
 43: hkn0414:1981498:1981609 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
202: hkn0531:1230513:1230642 [2] NCCL INFO Channel 00 : 202[ca000] -> 203[e3000] via P2P/IPC/read
146: hkn0513:3012852:3012957 [2] NCCL INFO Connected all rings
384: hkn0716:108410:108503 [0] NCCL INFO Channel 01 : 384[31000] -> 385[4b000] via P2P/IPC/read
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 00 : 297[4b000] -> 298[ca000] via P2P/IPC/read
368: hkn0712:294956:295068 [0] NCCL INFO Connected all rings
 35: hkn0412:2262278:2262387 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:709710:709819 [2] NCCL INFO Channel 00 : 254[ca000] -> 255[e3000] via P2P/IPC/read
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 01 : 209[4b000] -> 210[ca000] via P2P/IPC/read
234: hkn0605:711998:712112 [2] NCCL INFO Channel 00 : 234[ca000] -> 235[e3000] via P2P/IPC/read
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 01 : 460[31000] -> 461[4b000] via P2P/IPC/read
246: hkn0608:485616:485737 [2] NCCL INFO Channel 00 : 246[ca000] -> 247[e3000] via P2P/IPC/read
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 01 : 416[31000] -> 417[4b000] via P2P/IPC/read
336: hkn0703:740936:741046 [0] NCCL INFO Channel 01 : 336[31000] -> 337[4b000] via P2P/IPC/read
 75: hkn0423:1704809:1704921 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 87: hkn0426:813974:814075 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 00 : 324[31000] -> 325[4b000] via P2P/IPC/read
408: hkn0723:207901:208066 [0] NCCL INFO Channel 00 : 408[31000] -> 409[4b000] via P2P/IPC/read
206: hkn0532:924599:924925 [2] NCCL INFO Channel 00 : 206[ca000] -> 207[e3000] via P2P/IPC/read
498: hkn0812:693667:693793 [2] NCCL INFO Channel 01 : 498[ca000] -> 499[e3000] via P2P/IPC/read
 75: hkn0423:1704809:1704921 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 87: hkn0426:813974:814075 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
302: hkn0628:671759:671904 [2] NCCL INFO Channel 00 : 302[ca000] -> 303[e3000] via P2P/IPC/read
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 00 : 420[31000] -> 421[4b000] via P2P/IPC/read
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 00 : 65[4b000] -> 66[ca000] via P2P/IPC/read
245: hkn0608:485636:485738 [1] NCCL INFO Channel 01 : 245[4b000] -> 246[ca000] via P2P/IPC/read
178: hkn0525:986708:986837 [2] NCCL INFO Channel 01 : 178[ca000] -> 179[e3000] via P2P/IPC/read
154: hkn0515:2896695:2896792 [2] NCCL INFO Connected all rings
277: hkn0621:1991460:1991584 [1] NCCL INFO Channel 00 : 277[4b000] -> 278[ca000] via P2P/IPC/read
194: hkn0529:1540708:1540856 [2] NCCL INFO Channel 00 : 194[ca000] -> 195[e3000] via P2P/IPC/read
270: hkn0616:404806:404907 [2] NCCL INFO Channel 01 : 270[ca000] -> 271[e3000] via P2P/IPC/read
400: hkn0720:5369:5640 [0] NCCL INFO Channel 00 : 400[31000] -> 401[4b000] via P2P/IPC/read
265: hkn0615:414225:414318 [1] NCCL INFO Channel 01 : 265[4b000] -> 266[ca000] via P2P/IPC/read
501: hkn0814:675740:675838 [1] NCCL INFO Channel 01 : 501[4b000] -> 502[ca000] via P2P/IPC/read
 71: hkn0422:4153013:4153117 [3] NCCL INFO Connected all trees
150: hkn0514:2950610:2950728 [2] NCCL INFO Channel 01 : 150[ca000] -> 151[e3000] via P2P/IPC/read
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 01 : 316[31000] -> 317[4b000] via P2P/IPC/read
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 01 : 284[31000] -> 285[4b000] via P2P/IPC/read
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 01 : 189[4b000] -> 190[ca000] via P2P/IPC/read
214: hkn0535:2398869:2398986 [2] NCCL INFO Channel 01 : 214[ca000] -> 215[e3000] via P2P/IPC/read
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 00 : 328[31000] -> 329[4b000] via P2P/IPC/read
 71: hkn0422:4153013:4153117 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
494: hkn0810:939437:939537 [2] NCCL INFO Channel 01 : 494[ca000] -> 495[e3000] via P2P/IPC/read
253: hkn0611:709702:709825 [1] NCCL INFO Channel 01 : 253[4b000] -> 254[ca000] via P2P/IPC/read
205: hkn0532:924607:924924 [1] NCCL INFO Channel 01 : 205[4b000] -> 206[ca000] via P2P/IPC/read
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 00 : 432[31000] -> 433[4b000] via P2P/IPC/read
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 01 : 132[31000] -> 133[4b000] via P2P/IPC/read
 71: hkn0422:4153013:4153117 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
342: hkn0704:791887:792017 [2] NCCL INFO Channel 00 : 342[ca000] -> 343[e3000] via P2P/IPC/read
290: hkn0624:1772838:1772944 [2] NCCL INFO Channel 00 : 290[ca000] -> 291[e3000] via P2P/IPC/read
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 01 : 308[31000] -> 309[4b000] via P2P/IPC/read
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 00 : 321[4b000] -> 322[ca000] via P2P/IPC/read
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 01 : 428[31000] -> 429[4b000] via P2P/IPC/read
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 00 : 445[4b000] -> 446[ca000] via P2P/IPC/read
241: hkn0607:904238:904362 [1] NCCL INFO Channel 00 : 241[4b000] -> 242[ca000] via P2P/IPC/read
364: hkn0711:583800:583921 [0] NCCL INFO Connected all rings
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 01 : 404[31000] -> 405[4b000] via P2P/IPC/read
249: hkn0609:710716:710825 [1] NCCL INFO Channel 00 : 249[4b000] -> 250[ca000] via P2P/IPC/read
369: hkn0712:294968:295070 [1] NCCL INFO Connected all rings
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 00 : 13[4b000] -> 14[ca000] via P2P/IPC/read
426: hkn0727:1345664:1345786 [2] NCCL INFO Connected all rings
474: hkn0805:1112002:1112122 [2] NCCL INFO Channel 00 : 474[ca000] -> 475[e3000] via P2P/IPC/read
341: hkn0704:791903:792016 [1] NCCL INFO Channel 01 : 341[4b000] -> 342[ca000] via P2P/IPC/read
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 01 : 237[4b000] -> 238[ca000] via P2P/IPC/read
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 01 : 289[4b000] -> 290[ca000] via P2P/IPC/read
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 01 : 436[31000] -> 437[4b000] via P2P/IPC/read
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 00 : 441[4b000] -> 442[ca000] via P2P/IPC/read
138: hkn0511:3066294:3066390 [2] NCCL INFO Channel 01 : 138[ca000] -> 139[e3000] via P2P/IPC/read
366: hkn0711:583820:583927 [2] NCCL INFO Connected all rings
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 01 : 193[4b000] -> 194[ca000] via P2P/IPC/read
486: hkn0808:970577:970677 [2] NCCL INFO Channel 01 : 486[ca000] -> 487[e3000] via P2P/IPC/read
 46: hkn0415:2496333:2496437 [2] NCCL INFO Channel 00 : 46[ca000] -> 47[e3000] via P2P/IPC/read
470: hkn0804:1205535:1205629 [2] NCCL INFO Channel 00 : 470[ca000] -> 471[e3000] via P2P/IPC/read
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 01 : 473[4b000] -> 474[ca000] via P2P/IPC/read
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 01 : 201[4b000] -> 202[ca000] via P2P/IPC/read
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 00 : 273[4b000] -> 274[ca000] via P2P/IPC/read
453: hkn0736:1508232:1508369 [1] NCCL INFO Channel 00 : 453[4b000] -> 454[ca000] via P2P/IPC/read
170: hkn0523:1547969:1548086 [2] NCCL INFO Channel 01 : 170[ca000] -> 171[e3000] via P2P/IPC/read
233: hkn0605:712002:712113 [1] NCCL INFO Channel 01 : 233[4b000] -> 234[ca000] via P2P/IPC/read
389: hkn0717:4187531:4187655 [1] NCCL INFO Channel 00 : 389[4b000] -> 390[ca000] via P2P/IPC/read
345: hkn0705:783117:783216 [1] NCCL INFO Channel 00 : 345[4b000] -> 346[ca000] via P2P/IPC/read
490: hkn0809:937230:937376 [2] NCCL INFO Channel 01 : 490[ca000] -> 491[e3000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Connected all rings
258: hkn0612:916880:916979 [2] NCCL INFO Channel 01 : 258[ca000] -> 259[e3000] via P2P/IPC/read
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 01 : 332[31000] -> 333[4b000] via P2P/IPC/read
229: hkn0604:689145:689242 [1] NCCL INFO Channel 00 : 229[4b000] -> 230[ca000] via P2P/IPC/read
380: hkn0715:401772:401896 [0] NCCL INFO Channel 01 : 380[31000] -> 381[4b000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO Channel 01 : 301[4b000] -> 302[ca000] via P2P/IPC/read
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 01 : 456[31000] -> 457[4b000] via P2P/IPC/read
478: hkn0806:1054238:1054345 [2] NCCL INFO Channel 01 : 478[ca000] -> 479[e3000] via P2P/IPC/read
216: hkn0601:117612:117713 [0] NCCL INFO Channel 01 : 216[31000] -> 217[4b000] via P2P/IPC/read
434: hkn0730:1401634:1401726 [2] NCCL INFO Connected all rings
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 00 : 285[4b000] -> 286[ca000] via P2P/IPC/read
296: hkn0627:1787824:1787924 [0] NCCL INFO Connected all rings
466: hkn0803:876456:876564 [2] NCCL INFO Channel 00 : 466[ca000] -> 467[e3000] via P2P/IPC/read
503: hkn0814:675719:675836 [3] NCCL INFO Connected all trees
503: hkn0814:675719:675836 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
482: hkn0807:1018950:1019079 [2] NCCL INFO Channel 01 : 482[ca000] -> 483[e3000] via P2P/IPC/read
503: hkn0814:675719:675836 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 00 : 225[4b000] -> 226[ca000] via P2P/IPC/read
376: hkn0714:431923:432030 [0] NCCL INFO Channel 01 : 376[31000] -> 377[4b000] via P2P/IPC/read
 62: hkn0420:3210093:3210219 [2] NCCL INFO Connected all trees
 55: hkn0418:1869061:1869166 [3] NCCL INFO Connected all trees
361: hkn0710:355445:355552 [1] NCCL INFO Connected all rings
 31: hkn0411:2315753:2315871 [3] NCCL INFO Connected all trees
101: hkn0502:228954:229059 [1] NCCL INFO Channel 00 : 101[4b000] -> 102[ca000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 00 : 417[4b000] -> 418[ca000] via P2P/IPC/read
 95: hkn0428:667235:667348 [3] NCCL INFO Connected all trees
 62: hkn0420:3210093:3210219 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
322: hkn0633:1526218:1526355 [2] NCCL INFO Channel 00 : 322[ca000] -> 323[e3000] via P2P/IPC/read
465: hkn0803:876477:876562 [1] NCCL INFO Channel 01 : 465[4b000] -> 466[ca000] via P2P/IPC/read
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 01 : 45[4b000] -> 46[ca000] via P2P/IPC/read
446: hkn0733:1389290:1389387 [2] NCCL INFO Channel 00 : 446[ca000] -> 447[e3000] via P2P/IPC/read
 55: hkn0418:1869061:1869166 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 62: hkn0420:3210093:3210219 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 00 : 313[4b000] -> 314[ca000] via P2P/IPC/read
437: hkn0731:1386617:1386741 [1] NCCL INFO Channel 00 : 437[4b000] -> 438[ca000] via P2P/IPC/read
 31: hkn0411:2315753:2315871 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 55: hkn0418:1869061:1869166 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
250: hkn0609:710708:710822 [2] NCCL INFO Channel 00 : 250[ca000] -> 251[e3000] via P2P/IPC/read
 95: hkn0428:667235:667348 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 31: hkn0411:2315753:2315871 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 95: hkn0428:667235:667348 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 79: hkn0424:2947870:2947971 [3] NCCL INFO Connected all trees
385: hkn0716:108390:108502 [1] NCCL INFO Channel 00 : 385[4b000] -> 386[ca000] via P2P/IPC/read
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 00 : 452[31000] -> 453[4b000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 01 : 392[31000] -> 393[4b000] via P2P/IPC/read
222: hkn0602:3362295:3362554 [2] NCCL INFO Channel 01 : 222[ca000] -> 223[e3000] via P2P/IPC/read
278: hkn0621:1991488:1991585 [2] NCCL INFO Channel 00 : 278[ca000] -> 279[e3000] via P2P/IPC/read
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 01 : 412[31000] -> 413[4b000] via P2P/IPC/read
390: hkn0717:4187539:4187652 [2] NCCL INFO Channel 00 : 390[ca000] -> 391[e3000] via P2P/IPC/read
352: hkn0707:4019800:4019913 [0] NCCL INFO Connected all rings
 79: hkn0424:2947870:2947971 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1598347:1598454 [1] NCCL INFO Channel 00 : 309[4b000] -> 310[ca000] via P2P/IPC/read
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 00 : 429[4b000] -> 430[ca000] via P2P/IPC/read
469: hkn0804:1205507:1205626 [1] NCCL INFO Channel 01 : 469[4b000] -> 470[ca000] via P2P/IPC/read
 66: hkn0421:2180592:2180858 [2] NCCL INFO Channel 00 : 66[ca000] -> 67[e3000] via P2P/IPC/read
346: hkn0705:783101:783217 [2] NCCL INFO Channel 00 : 346[ca000] -> 347[e3000] via P2P/IPC/read
230: hkn0604:689117:689240 [2] NCCL INFO Channel 00 : 230[ca000] -> 231[e3000] via P2P/IPC/read
 79: hkn0424:2947870:2947971 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
266: hkn0615:414205:414319 [2] NCCL INFO Channel 01 : 266[ca000] -> 267[e3000] via P2P/IPC/read
218: hkn0601:117591:117714 [2] NCCL INFO Connected all rings
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 00 : 461[4b000] -> 462[ca000] via P2P/IPC/read
186: hkn0527:1348830:1348950 [2] NCCL INFO Channel 01 : 186[ca000] -> 187[e3000] via P2P/IPC/read
162: hkn0520:2712749:2712876 [2] NCCL INFO Channel 01 : 162[ca000] -> 163[e3000] via P2P/IPC/read
 59: hkn0419:1544187:1544303 [3] NCCL INFO Connected all trees
277: hkn0621:1991460:1991584 [1] NCCL INFO Channel 01 : 277[4b000] -> 278[ca000] via P2P/IPC/read
310: hkn0630:1598359:1598459 [2] NCCL INFO Channel 00 : 310[ca000] -> 311[e3000] via P2P/IPC/read
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 01 : 297[4b000] -> 298[ca000] via P2P/IPC/read
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 00 : 448[31000] -> 449[4b000] via P2P/IPC/read
 14: hkn0407:1816159:1816274 [2] NCCL INFO Channel 00 : 14[ca000] -> 15[e3000] via P2P/IPC/read
 59: hkn0419:1544187:1544303 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
190: hkn0528:1301582:1301674 [2] NCCL INFO Channel 01 : 190[ca000] -> 191[e3000] via P2P/IPC/read
298: hkn0627:1787836:1787925 [2] NCCL INFO Channel 00 : 298[ca000] -> 299[e3000] via P2P/IPC/read
305: hkn0629:1591959:1592057 [1] NCCL INFO Connected all rings
 59: hkn0419:1544187:1544303 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
442: hkn0732:1211543:1211663 [2] NCCL INFO Channel 00 : 442[ca000] -> 443[e3000] via P2P/IPC/read
262: hkn0613:902573:902699 [2] NCCL INFO Channel 01 : 262[ca000] -> 263[e3000] via P2P/IPC/read
373: hkn0713:470120:470234 [1] NCCL INFO Channel 00 : 373[4b000] -> 374[ca000] via P2P/IPC/read
242: hkn0607:904266:904368 [2] NCCL INFO Channel 00 : 242[ca000] -> 243[e3000] via P2P/IPC/read
102: hkn0502:228938:229065 [2] NCCL INFO Channel 00 : 102[ca000] -> 103[e3000] via P2P/IPC/read
337: hkn0703:740940:741049 [1] NCCL INFO Channel 00 : 337[4b000] -> 338[ca000] via P2P/IPC/read
274: hkn0617:2294558:2294701 [2] NCCL INFO Channel 00 : 274[ca000] -> 275[e3000] via P2P/IPC/read
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 01 : 321[4b000] -> 322[ca000] via P2P/IPC/read
  3: hkn0403:1763926:1764349 [3] NCCL INFO Connected all trees
  3: hkn0403:1763926:1764349 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 01 : 445[4b000] -> 446[ca000] via P2P/IPC/read
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 01 : 65[4b000] -> 66[ca000] via P2P/IPC/read
405: hkn0721:2299079:2299192 [1] NCCL INFO Channel 00 : 405[4b000] -> 406[ca000] via P2P/IPC/read
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [receive] via NET/IBext/0
198: hkn0530:1258034:1258159 [2] NCCL INFO Channel 01 : 198[ca000] -> 199[e3000] via P2P/IPC/read
  3: hkn0403:1763926:1764349 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 01 : 13[4b000] -> 14[ca000] via P2P/IPC/read
241: hkn0607:904238:904362 [1] NCCL INFO Channel 01 : 241[4b000] -> 242[ca000] via P2P/IPC/read
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 00 : 413[4b000] -> 414[ca000] via P2P/IPC/read
238: hkn0606:2371989:2372088 [2] NCCL INFO Channel 01 : 238[ca000] -> 239[e3000] via P2P/IPC/read
249: hkn0609:710716:710825 [1] NCCL INFO Channel 01 : 249[4b000] -> 250[ca000] via P2P/IPC/read
314: hkn0631:1021723:1021832 [2] NCCL INFO Channel 00 : 314[ca000] -> 315[e3000] via P2P/IPC/read
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 01 : 441[4b000] -> 442[ca000] via P2P/IPC/read
123: hkn0507:3186970:3187067 [3] NCCL INFO Connected all trees
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 00 : 317[4b000] -> 318[ca000] via P2P/IPC/read
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 01 : 273[4b000] -> 274[ca000] via P2P/IPC/read
389: hkn0717:4187531:4187655 [1] NCCL INFO Channel 01 : 389[4b000] -> 390[ca000] via P2P/IPC/read
507: hkn0815:395008:395125 [3] NCCL INFO Connected all trees
397: hkn0719:1305595:1305722 [1] NCCL INFO Connected all rings
349: hkn0706:752136:752262 [1] NCCL INFO Connected all rings
123: hkn0507:3186970:3187067 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
210: hkn0534:1148280:1148416 [2] NCCL INFO Channel 01 : 210[ca000] -> 211[e3000] via P2P/IPC/read
234: hkn0605:711998:712112 [2] NCCL INFO Channel 01 : 234[ca000] -> 235[e3000] via P2P/IPC/read
286: hkn0623:1872648:1872765 [2] NCCL INFO Channel 00 : 286[ca000] -> 287[e3000] via P2P/IPC/read
345: hkn0705:783117:783216 [1] NCCL INFO Channel 01 : 345[4b000] -> 346[ca000] via P2P/IPC/read
430: hkn0728:1323891:1323997 [2] NCCL INFO Channel 00 : 430[ca000] -> 431[e3000] via P2P/IPC/read
123: hkn0507:3186970:3187067 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1156441:1156545 [2] NCCL INFO Connected all rings
  7: hkn0404:1339294:1339386 [3] NCCL INFO Connected all trees
  7: hkn0404:1339294:1339386 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
202: hkn0531:1230513:1230642 [2] NCCL INFO Channel 01 : 202[ca000] -> 203[e3000] via P2P/IPC/read
507: hkn0815:395008:395125 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
229: hkn0604:689145:689242 [1] NCCL INFO Channel 01 : 229[4b000] -> 230[ca000] via P2P/IPC/read
111: hkn0504:40715:40839 [3] NCCL INFO Connected all trees
226: hkn0603:1413123:1413232 [2] NCCL INFO Channel 00 : 226[ca000] -> 227[e3000] via P2P/IPC/read
  7: hkn0404:1339294:1339386 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 00 : 333[4b000] -> 334[ca000] via P2P/IPC/read
507: hkn0815:395008:395125 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
302: hkn0628:671759:671904 [2] NCCL INFO Channel 01 : 302[ca000] -> 303[e3000] via P2P/IPC/read
438: hkn0731:1386633:1386740 [2] NCCL INFO Channel 00 : 438[ca000] -> 439[e3000] via P2P/IPC/read
408: hkn0723:207901:208066 [0] NCCL INFO Channel 01 : 408[31000] -> 409[4b000] via P2P/IPC/read
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 01 : 152[31000] -> 153[4b000] via P2P/IPC/read
400: hkn0720:5369:5640 [0] NCCL INFO Channel 01 : 400[31000] -> 401[4b000] via P2P/IPC/read
111: hkn0504:40715:40839 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 01 : 324[31000] -> 325[4b000] via P2P/IPC/read
418: hkn0725:3111809:3111929 [2] NCCL INFO Channel 00 : 418[ca000] -> 419[e3000] via P2P/IPC/read
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 01 : 285[4b000] -> 286[ca000] via P2P/IPC/read
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 00 : 353[4b000] -> 354[ca000] via P2P/IPC/read
386: hkn0716:108398:108509 [2] NCCL INFO Channel 00 : 386[ca000] -> 387[e3000] via P2P/IPC/read
111: hkn0504:40715:40839 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:709710:709819 [2] NCCL INFO Channel 01 : 254[ca000] -> 255[e3000] via P2P/IPC/read
 19: hkn0408:2890647:2890769 [3] NCCL INFO Connected all trees
377: hkn0714:431907:432038 [1] NCCL INFO Channel 00 : 377[4b000] -> 378[ca000] via P2P/IPC/read
246: hkn0608:485616:485737 [2] NCCL INFO Channel 01 : 246[ca000] -> 247[e3000] via P2P/IPC/read
437: hkn0731:1386617:1386741 [1] NCCL INFO Channel 01 : 437[4b000] -> 438[ca000] via P2P/IPC/read
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 00 : 457[4b000] -> 458[ca000] via P2P/IPC/read
 23: hkn0409:2585564:2585689 [3] NCCL INFO Connected all trees
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 01 : 225[4b000] -> 226[ca000] via P2P/IPC/read
206: hkn0532:924599:924925 [2] NCCL INFO Channel 01 : 206[ca000] -> 207[e3000] via P2P/IPC/read
424: hkn0727:1345692:1345788 [0] NCCL INFO Connected all rings
 19: hkn0408:2890647:2890769 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:228954:229059 [1] NCCL INFO Channel 01 : 101[4b000] -> 102[ca000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 01 : 417[4b000] -> 418[ca000] via P2P/IPC/read
338: hkn0703:740952:741043 [2] NCCL INFO Channel 00 : 338[ca000] -> 339[e3000] via P2P/IPC/read
194: hkn0529:1540708:1540856 [2] NCCL INFO Channel 01 : 194[ca000] -> 195[e3000] via P2P/IPC/read
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 01 : 328[31000] -> 329[4b000] via P2P/IPC/read
358: hkn0708:413122:413219 [2] NCCL INFO Connected all rings
 23: hkn0409:2585564:2585689 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 19: hkn0408:2890647:2890769 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
381: hkn0715:401780:401901 [1] NCCL INFO Channel 00 : 381[4b000] -> 382[ca000] via P2P/IPC/read
 26: hkn0410:1159602:1159714 [2] NCCL INFO Connected all trees
385: hkn0716:108390:108502 [1] NCCL INFO Channel 01 : 385[4b000] -> 386[ca000] via P2P/IPC/read
 82: hkn0425:2083927:2084031 [2] NCCL INFO Connected all trees
 23: hkn0409:2585564:2585689 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 38: hkn0413:2366608:2366707 [2] NCCL INFO Connected all trees
462: hkn0802:1200232:1200339 [2] NCCL INFO Channel 00 : 462[ca000] -> 463[e3000] via P2P/IPC/read
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 01 : 313[4b000] -> 314[ca000] via P2P/IPC/read
 26: hkn0410:1159602:1159714 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
290: hkn0624:1772838:1772944 [2] NCCL INFO Channel 01 : 290[ca000] -> 291[e3000] via P2P/IPC/read
356: hkn0708:413102:413217 [0] NCCL INFO Channel 00 : 356[31000] -> 357[4b000] via P2P/IPC/read
 82: hkn0425:2083927:2084031 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 38: hkn0413:2366608:2366707 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 01 : 432[31000] -> 433[4b000] via P2P/IPC/read
342: hkn0704:791887:792017 [2] NCCL INFO Channel 01 : 342[ca000] -> 343[e3000] via P2P/IPC/read
 26: hkn0410:1159602:1159714 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
309: hkn0630:1598347:1598454 [1] NCCL INFO Channel 01 : 309[4b000] -> 310[ca000] via P2P/IPC/read
107: hkn0503:2899572:2899698 [3] NCCL INFO Connected all trees
119: hkn0506:837957:838067 [3] NCCL INFO Connected all trees
 82: hkn0425:2083927:2084031 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
470: hkn0804:1205535:1205629 [2] NCCL INFO Channel 01 : 470[ca000] -> 471[e3000] via P2P/IPC/read
 38: hkn0413:2366608:2366707 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
474: hkn0805:1112002:1112122 [2] NCCL INFO Channel 01 : 474[ca000] -> 475[e3000] via P2P/IPC/read
115: hkn0505:2303672:2303774 [3] NCCL INFO Connected all trees
115: hkn0505:2303672:2303774 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
167: hkn0521:1197691:1197791 [3] NCCL INFO Connected all trees
115: hkn0505:2303672:2303774 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 01 : 461[4b000] -> 462[ca000] via P2P/IPC/read
334: hkn0636:1654143:1654268 [2] NCCL INFO Channel 00 : 334[ca000] -> 335[e3000] via P2P/IPC/read
167: hkn0521:1197691:1197791 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
406: hkn0721:2299071:2299198 [2] NCCL INFO Channel 00 : 406[ca000] -> 407[e3000] via P2P/IPC/read
131: hkn0509:3124296:3124401 [3] NCCL INFO Connected all trees
167: hkn0521:1197691:1197791 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 34: hkn0412:2262277:2262396 [2] NCCL INFO Connected all trees
 42: hkn0414:1981511:1981611 [2] NCCL INFO Connected all trees
 34: hkn0412:2262277:2262396 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
131: hkn0509:3124296:3124401 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
466: hkn0803:876456:876564 [2] NCCL INFO Channel 01 : 466[ca000] -> 467[e3000] via P2P/IPC/read
 34: hkn0412:2262277:2262396 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 46: hkn0415:2496333:2496437 [2] NCCL INFO Channel 01 : 46[ca000] -> 47[e3000] via P2P/IPC/read
131: hkn0509:3124296:3124401 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [receive] via NET/IBext/0
446: hkn0733:1389290:1389387 [2] NCCL INFO Channel 01 : 446[ca000] -> 447[e3000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Channel 00 : 372[31000] -> 373[4b000] via P2P/IPC/read
414: hkn0724:1715886:1715987 [2] NCCL INFO Channel 00 : 414[ca000] -> 415[e3000] via P2P/IPC/read
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [send] via NET/IBext/0
 42: hkn0414:1981511:1981611 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 01 : 413[4b000] -> 414[ca000] via P2P/IPC/read
499: hkn0812:693683:693792 [3] NCCL INFO Connected all trees
499: hkn0812:693683:693792 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
143: hkn0512:3044032:3044153 [3] NCCL INFO Connected all trees
374: hkn0713:470128:470236 [2] NCCL INFO Channel 00 : 374[ca000] -> 375[e3000] via P2P/IPC/read
499: hkn0812:693683:693792 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 42: hkn0414:1981511:1981611 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
143: hkn0512:3044032:3044153 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
175: hkn0524:1133671:1133797 [3] NCCL INFO Connected all trees
143: hkn0512:3044032:3044153 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
102: hkn0502:228938:229065 [2] NCCL INFO Channel 01 : 102[ca000] -> 103[e3000] via P2P/IPC/read
394: hkn0718:3916905:3917029 [2] NCCL INFO Channel 00 : 394[ca000] -> 395[e3000] via P2P/IPC/read
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [send] via NET/IBext/0
 70: hkn0422:4153005:4153119 [2] NCCL INFO Connected all trees
495: hkn0810:939425:939541 [3] NCCL INFO Connected all trees
 14: hkn0407:1816159:1816274 [2] NCCL INFO Channel 01 : 14[ca000] -> 15[e3000] via P2P/IPC/read
409: hkn0723:207893:208068 [1] NCCL INFO Channel 00 : 409[4b000] -> 410[ca000] via P2P/IPC/read
 70: hkn0422:4153005:4153119 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
495: hkn0810:939425:939541 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
491: hkn0809:937251:937374 [3] NCCL INFO Connected all trees
 70: hkn0422:4153005:4153119 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
495: hkn0810:939425:939541 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:470120:470234 [1] NCCL INFO Channel 01 : 373[4b000] -> 374[ca000] via P2P/IPC/read
491: hkn0809:937251:937374 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
242: hkn0607:904266:904368 [2] NCCL INFO Channel 01 : 242[ca000] -> 243[e3000] via P2P/IPC/read
491: hkn0809:937251:937374 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
171: hkn0523:1547977:1548089 [3] NCCL INFO Connected all trees
  2: hkn0403:1763934:1764351 [2] NCCL INFO Connected all trees
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [send] via NET/IBext/0
  2: hkn0403:1763934:1764351 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
171: hkn0523:1547977:1548089 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
479: hkn0806:1054222:1054347 [3] NCCL INFO Connected all trees
479: hkn0806:1054222:1054347 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
226: hkn0603:1413123:1413232 [2] NCCL INFO Channel 01 : 226[ca000] -> 227[e3000] via P2P/IPC/read
479: hkn0806:1054222:1054347 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 00 : 393[4b000] -> 394[ca000] via P2P/IPC/read
  2: hkn0403:1763934:1764351 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
171: hkn0523:1547977:1548089 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
394: hkn0718:3916905:3917029 [2] NCCL INFO Channel 01 : 394[ca000] -> 395[e3000] via P2P/IPC/read
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 00 : 425[4b000] -> 426[ca000] via P2P/IPC/read
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [receive] via NET/IBext/0
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 00 : 433[4b000] -> 434[ca000] via P2P/IPC/read
 30: hkn0411:2315763:2315863 [2] NCCL INFO Connected all trees
223: hkn0602:3362287:3362549 [3] NCCL INFO Connected all trees
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 00 : 424[31000] -> 425[4b000] via P2P/IPC/read
 30: hkn0411:2315763:2315863 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
410: hkn0723:207909:208065 [2] NCCL INFO Channel 00 : 410[ca000] -> 411[e3000] via P2P/IPC/read
 30: hkn0411:2315763:2315863 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
223: hkn0602:3362287:3362549 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 01 : 448[31000] -> 449[4b000] via P2P/IPC/read
223: hkn0602:3362287:3362549 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
175: hkn0524:1133671:1133797 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
263: hkn0613:902601:902691 [3] NCCL INFO Connected all trees
263: hkn0613:902601:902691 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:470112:470238 [0] NCCL INFO Channel 01 : 372[31000] -> 373[4b000] via P2P/IPC/read
263: hkn0613:902601:902691 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
409: hkn0723:207893:208068 [1] NCCL INFO Channel 01 : 409[4b000] -> 410[ca000] via P2P/IPC/read
122: hkn0507:3186958:3187070 [2] NCCL INFO Connected all trees
122: hkn0507:3186958:3187070 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
374: hkn0713:470128:470236 [2] NCCL INFO Channel 01 : 374[ca000] -> 375[e3000] via P2P/IPC/read
122: hkn0507:3186958:3187070 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
175: hkn0524:1133671:1133797 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
211: hkn0534:1148272:1148423 [3] NCCL INFO Connected all trees
151: hkn0514:2950630:2950735 [3] NCCL INFO Connected all trees
151: hkn0514:2950630:2950735 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
217: hkn0601:117600:117712 [1] NCCL INFO Channel 00 : 217[4b000] -> 218[ca000] via P2P/IPC/read
414: hkn0724:1715886:1715987 [2] NCCL INFO Channel 01 : 414[ca000] -> 415[e3000] via P2P/IPC/read
211: hkn0534:1148272:1148423 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
151: hkn0514:2950630:2950735 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
211: hkn0534:1148272:1148423 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [receive] via NET/IBext/0
 22: hkn0409:2585544:2585697 [2] NCCL INFO Connected all trees
255: hkn0611:709694:709822 [3] NCCL INFO Connected all trees
 22: hkn0409:2585544:2585697 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
207: hkn0532:924627:924923 [3] NCCL INFO Connected all trees
 22: hkn0409:2585544:2585697 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
255: hkn0611:709694:709822 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
255: hkn0611:709694:709822 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
207: hkn0532:924627:924923 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
166: hkn0521:1197663:1197794 [2] NCCL INFO Connected all trees
207: hkn0532:924627:924923 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
434: hkn0730:1401634:1401726 [2] NCCL INFO Channel 00 : 434[ca000] -> 435[e3000] via P2P/IPC/read
 18: hkn0408:2890646:2890768 [2] NCCL INFO Connected all trees
166: hkn0521:1197663:1197794 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [send] via NET/IBext/0
166: hkn0521:1197663:1197794 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 01 : 433[4b000] -> 434[ca000] via P2P/IPC/read
426: hkn0727:1345664:1345786 [2] NCCL INFO Channel 00 : 426[ca000] -> 427[e3000] via P2P/IPC/read
475: hkn0805:1112010:1112126 [3] NCCL INFO Connected all trees
130: hkn0509:3124308:3124406 [2] NCCL INFO Connected all trees
218: hkn0601:117591:117714 [2] NCCL INFO Channel 00 : 218[ca000] -> 219[e3000] via P2P/IPC/read
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [receive] via NET/IBext/0
475: hkn0805:1112010:1112126 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
130: hkn0509:3124308:3124406 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
475: hkn0805:1112010:1112126 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
395: hkn0718:3916925:3917028 [3] NCCL INFO Connected all trees
130: hkn0509:3124308:3124406 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1205505:1205631 [3] NCCL INFO Connected all trees
 18: hkn0408:2890646:2890768 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
395: hkn0718:3916925:3917028 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 18: hkn0408:2890646:2890768 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
395: hkn0718:3916925:3917028 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1205505:1205631 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 01 : 393[4b000] -> 394[ca000] via P2P/IPC/read
 47: hkn0415:2496310:2496438 [3] NCCL INFO Connected all trees
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [send] via NET/IBext/0
471: hkn0804:1205505:1205631 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
142: hkn0512:3044033:3044156 [2] NCCL INFO Connected all trees
 47: hkn0415:2496310:2496438 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
467: hkn0803:876457:876566 [3] NCCL INFO Connected all trees
142: hkn0512:3044033:3044156 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
502: hkn0814:675720:675841 [2] NCCL INFO Connected all trees
142: hkn0512:3044033:3044156 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
467: hkn0803:876457:876566 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 47: hkn0415:2496310:2496438 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
467: hkn0803:876457:876566 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
502: hkn0814:675720:675841 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
502: hkn0814:675720:675841 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [send] via NET/IBext/0
494: hkn0810:939437:939537 [2] NCCL INFO Connected all trees
  1: hkn0403:1763954:1764350 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via P2P/IPC/read
494: hkn0810:939437:939537 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
447: hkn0733:1389269:1389383 [3] NCCL INFO Connected all trees
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [receive] via NET/IBext/0
494: hkn0810:939437:939537 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
490: hkn0809:937230:937376 [2] NCCL INFO Connected all trees
 15: hkn0407:1816151:1816277 [3] NCCL INFO Connected all trees
 15: hkn0407:1816151:1816277 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
410: hkn0723:207909:208065 [2] NCCL INFO Channel 01 : 410[ca000] -> 411[e3000] via P2P/IPC/read
490: hkn0809:937230:937376 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  1: hkn0403:1763954:1764350 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via P2P/IPC/read
478: hkn0806:1054238:1054345 [2] NCCL INFO Connected all trees
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [receive] via NET/IBext/0
490: hkn0809:937230:937376 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1816151:1816277 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
478: hkn0806:1054238:1054345 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
447: hkn0733:1389269:1389383 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
478: hkn0806:1054238:1054345 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
447: hkn0733:1389269:1389383 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
227: hkn0603:1413135:1413236 [3] NCCL INFO Connected all trees
217: hkn0601:117600:117712 [1] NCCL INFO Channel 01 : 217[4b000] -> 218[ca000] via P2P/IPC/read
170: hkn0523:1547969:1548086 [2] NCCL INFO Connected all trees
243: hkn0607:904246:904360 [3] NCCL INFO Connected all trees
243: hkn0607:904246:904360 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
227: hkn0603:1413135:1413236 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
243: hkn0607:904246:904360 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
227: hkn0603:1413135:1413236 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
170: hkn0523:1547969:1548086 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:937239:937379 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [send] via NET/IBext/0
170: hkn0523:1547969:1548086 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
262: hkn0613:902573:902699 [2] NCCL INFO Connected all trees
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 01 : 425[4b000] -> 426[ca000] via P2P/IPC/read
498: hkn0812:693667:693793 [2] NCCL INFO Connected all trees
235: hkn0605:712014:712118 [3] NCCL INFO Connected all trees
262: hkn0613:902573:902699 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [send] via NET/IBext/0
262: hkn0613:902573:902699 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:939409:939536 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [receive] via NET/IBext/0
218: hkn0601:117591:117714 [2] NCCL INFO Channel 01 : 218[ca000] -> 219[e3000] via P2P/IPC/read
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 01 : 424[31000] -> 425[4b000] via P2P/IPC/read
434: hkn0730:1401634:1401726 [2] NCCL INFO Channel 01 : 434[ca000] -> 435[e3000] via P2P/IPC/read
426: hkn0727:1345664:1345786 [2] NCCL INFO Channel 01 : 426[ca000] -> 427[e3000] via P2P/IPC/read
498: hkn0812:693667:693793 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
235: hkn0605:712014:712118 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
498: hkn0812:693667:693793 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
235: hkn0605:712014:712118 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
496: hkn0812:693695:693790 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [send] via NET/IBext/0
222: hkn0602:3362295:3362554 [2] NCCL INFO Connected all trees
415: hkn0724:1715858:1715983 [3] NCCL INFO Connected all trees
103: hkn0502:228946:229060 [3] NCCL INFO Connected all trees
222: hkn0602:3362295:3362554 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 00 : 449[4b000] -> 450[ca000] via P2P/IPC/read
415: hkn0724:1715858:1715983 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
234: hkn0605:711998:712112 [2] NCCL INFO Connected all trees
415: hkn0724:1715858:1715983 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3362295:3362554 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [receive] via NET/IBext/0
234: hkn0605:711998:712112 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
210: hkn0534:1148280:1148416 [2] NCCL INFO Connected all trees
234: hkn0605:711998:712112 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [receive] via NET/IBext/0
103: hkn0502:228946:229060 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
103: hkn0502:228946:229060 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
210: hkn0534:1148280:1148416 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
450: hkn0734:1156441:1156545 [2] NCCL INFO Channel 00 : 450[ca000] -> 451[e3000] via P2P/IPC/read
 37: hkn0413:2366588:2366711 [1] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [receive] via NET/IBext/0
210: hkn0534:1148280:1148416 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:709710:709819 [2] NCCL INFO Connected all trees
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 01 : 449[4b000] -> 450[ca000] via P2P/IPC/read
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [receive] via NET/IBext/0
206: hkn0532:924599:924925 [2] NCCL INFO Connected all trees
254: hkn0611:709710:709819 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
474: hkn0805:1112002:1112122 [2] NCCL INFO Connected all trees
254: hkn0611:709710:709819 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
206: hkn0532:924599:924925 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
206: hkn0532:924599:924925 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
474: hkn0805:1112002:1112122 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
474: hkn0805:1112002:1112122 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1156441:1156545 [2] NCCL INFO Channel 01 : 450[ca000] -> 451[e3000] via P2P/IPC/read
 69: hkn0422:4153025:4153124 [1] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [receive] via NET/IBext/0
252: hkn0611:709722:709820 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [receive] via NET/IBext/0
375: hkn0713:470140:470235 [3] NCCL INFO Connected all trees
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [receive] via NET/IBext/0
470: hkn0804:1205535:1205629 [2] NCCL INFO Connected all trees
470: hkn0804:1205535:1205629 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [send] via NET/IBext/0
470: hkn0804:1205535:1205629 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
446: hkn0733:1389290:1389387 [2] NCCL INFO Connected all trees
375: hkn0713:470140:470235 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
232: hkn0605:711997:712115 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [send] via NET/IBext/0
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [receive] via NET/IBext/0
446: hkn0733:1389290:1389387 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 46: hkn0415:2496333:2496437 [2] NCCL INFO Connected all trees
446: hkn0733:1389290:1389387 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 46: hkn0415:2496333:2496437 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
375: hkn0713:470140:470235 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 46: hkn0415:2496333:2496437 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:924615:924928 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [receive] via NET/IBext/0
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [send] via NET/IBext/0
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [send] via NET/IBext/0
174: hkn0524:1133687:1133798 [2] NCCL INFO Connected all trees
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [receive] via NET/IBext/0
390: hkn0717:4187539:4187652 [2] NCCL INFO Channel 01 : 390[ca000] -> 391[e3000] via P2P/IPC/read
 66: hkn0421:2180592:2180858 [2] NCCL INFO Channel 01 : 66[ca000] -> 67[e3000] via P2P/IPC/read
466: hkn0803:876456:876564 [2] NCCL INFO Connected all trees
174: hkn0524:1133687:1133798 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
102: hkn0502:228938:229065 [2] NCCL INFO Connected all trees
174: hkn0524:1133687:1133798 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
466: hkn0803:876456:876564 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 14: hkn0407:1816159:1816274 [2] NCCL INFO Connected all trees
 14: hkn0407:1816159:1816274 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
466: hkn0803:876456:876564 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [receive] via NET/IBext/0
260: hkn0613:902581:902700 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [receive] via NET/IBext/0
 14: hkn0407:1816159:1816274 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [receive] via NET/IBext/0
242: hkn0607:904266:904368 [2] NCCL INFO Connected all trees
102: hkn0502:228938:229065 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [receive] via NET/IBext/0
242: hkn0607:904266:904368 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
102: hkn0502:228938:229065 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
500: hkn0814:675728:675835 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [receive] via NET/IBext/0
242: hkn0607:904266:904368 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
411: hkn0723:207921:208060 [3] NCCL INFO Connected all trees
150: hkn0514:2950610:2950728 [2] NCCL INFO Connected all trees
150: hkn0514:2950610:2950728 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
391: hkn0717:4187523:4187653 [3] NCCL INFO Connected all trees
464: hkn0803:876465:876561 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [send] via NET/IBext/0
226: hkn0603:1413123:1413232 [2] NCCL INFO Connected all trees
411: hkn0723:207921:208060 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [send] via NET/IBext/0
226: hkn0603:1413123:1413232 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
226: hkn0603:1413123:1413232 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
411: hkn0723:207921:208060 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [receive] via NET/IBext/0
150: hkn0514:2950610:2950728 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
391: hkn0717:4187523:4187653 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 67: hkn0421:2180600:2180859 [3] NCCL INFO Connected all trees
240: hkn0607:904254:904366 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [send] via NET/IBext/0
391: hkn0717:4187523:4187653 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
390: hkn0717:4187539:4187652 [2] NCCL INFO Connected all trees
 67: hkn0421:2180600:2180859 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
390: hkn0717:4187539:4187652 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 67: hkn0421:2180600:2180859 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [receive] via NET/IBext/0
390: hkn0717:4187539:4187652 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [receive] via NET/IBext/0
 66: hkn0421:2180592:2180858 [2] NCCL INFO Connected all trees
435: hkn0730:1401622:1401732 [3] NCCL INFO Connected all trees
435: hkn0730:1401622:1401732 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 66: hkn0421:2180592:2180858 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [send] via NET/IBext/0
435: hkn0730:1401622:1401732 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [receive] via NET/IBext/0
100: hkn0502:228966:229066 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [receive] via NET/IBext/0
 66: hkn0421:2180592:2180858 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
114: hkn0505:2303656:2303781 [2] NCCL INFO Connected all trees
114: hkn0505:2303656:2303781 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
114: hkn0505:2303656:2303781 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [receive] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [send] via NET/IBext/0
414: hkn0724:1715886:1715987 [2] NCCL INFO Connected all trees
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [send] via NET/IBext/0
343: hkn0704:791915:792018 [3] NCCL INFO Connected all trees
378: hkn0714:431915:432039 [2] NCCL INFO Channel 00 : 378[ca000] -> 379[e3000] via P2P/IPC/read
414: hkn0724:1715886:1715987 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
462: hkn0802:1200232:1200339 [2] NCCL INFO Channel 01 : 462[ca000] -> 463[e3000] via P2P/IPC/read
427: hkn0727:1345680:1345791 [3] NCCL INFO Connected all trees
427: hkn0727:1345680:1345791 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1715886:1715987 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
343: hkn0704:791915:792018 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
377: hkn0714:431907:432038 [1] NCCL INFO Channel 01 : 377[4b000] -> 378[ca000] via P2P/IPC/read
343: hkn0704:791915:792018 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
378: hkn0714:431915:432039 [2] NCCL INFO Channel 01 : 378[ca000] -> 379[e3000] via P2P/IPC/read
 21: hkn0409:2585543:2585692 [1] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [receive] via NET/IBext/0
342: hkn0704:791887:792017 [2] NCCL INFO Connected all trees
342: hkn0704:791887:792017 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
427: hkn0727:1345680:1345791 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
342: hkn0704:791887:792017 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:791895:792019 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [receive] via NET/IBext/0
379: hkn0714:431935:432037 [3] NCCL INFO Connected all trees
379: hkn0714:431935:432037 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
463: hkn0802:1200216:1200348 [3] NCCL INFO Connected all trees
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [send] via NET/IBext/0
451: hkn0734:1156425:1156546 [3] NCCL INFO Connected all trees
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [receive] via NET/IBext/0
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [receive] via NET/IBext/0
451: hkn0734:1156425:1156546 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
379: hkn0714:431935:432037 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
394: hkn0718:3916905:3917029 [2] NCCL INFO Connected all trees
165: hkn0521:1197671:1197795 [1] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [receive] via NET/IBext/0
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [receive] via NET/IBext/0
374: hkn0713:470128:470236 [2] NCCL INFO Connected all trees
374: hkn0713:470128:470236 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
394: hkn0718:3916905:3917029 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
374: hkn0713:470128:470236 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
394: hkn0718:3916905:3917029 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [send] via NET/IBext/0
497: hkn0812:693675:693791 [1] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [receive] via NET/IBext/0
451: hkn0734:1156425:1156546 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
219: hkn0601:117592:117705 [3] NCCL INFO Connected all trees
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [send] via NET/IBext/0
378: hkn0714:431915:432039 [2] NCCL INFO Connected all trees
378: hkn0714:431915:432039 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
463: hkn0802:1200216:1200348 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
219: hkn0601:117592:117705 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
378: hkn0714:431915:432039 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [send] via NET/IBext/0
219: hkn0601:117592:117705 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:431923:432030 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [send] via NET/IBext/0
463: hkn0802:1200216:1200348 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
462: hkn0802:1200232:1200339 [2] NCCL INFO Connected all trees
  6: hkn0404:1339274:1339395 [2] NCCL INFO Connected all trees
462: hkn0802:1200232:1200339 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 54: hkn0418:1869045:1869174 [2] NCCL INFO Connected all trees
462: hkn0802:1200232:1200339 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1339274:1339395 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:939417:939538 [1] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [send] via NET/IBext/0
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [receive] via NET/IBext/0
  6: hkn0404:1339274:1339395 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 54: hkn0418:1869045:1869174 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [receive] via NET/IBext/0
 54: hkn0418:1869045:1869174 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:675740:675838 [1] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [receive] via NET/IBext/0
  5: hkn0404:1339266:1339391 [1] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [receive] via NET/IBext/0
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [receive] via NET/IBext/0
187: hkn0527:1348850:1348948 [3] NCCL INFO Connected all trees
 53: hkn0418:1869083:1869169 [1] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [receive] via NET/IBext/0
259: hkn0612:916868:916976 [3] NCCL INFO Connected all trees
187: hkn0527:1348850:1348948 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
139: hkn0511:3066266:3066383 [3] NCCL INFO Connected all trees
489: hkn0809:937231:937375 [1] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [receive] via NET/IBext/0
187: hkn0527:1348850:1348948 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
186: hkn0527:1348830:1348950 [2] NCCL INFO Connected all trees
259: hkn0612:916868:916976 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
186: hkn0527:1348830:1348950 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
259: hkn0612:916868:916976 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
410: hkn0723:207909:208065 [2] NCCL INFO Connected all trees
186: hkn0527:1348830:1348950 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [receive] via NET/IBext/0
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [send] via NET/IBext/0
410: hkn0723:207909:208065 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
258: hkn0612:916880:916979 [2] NCCL INFO Connected all trees
410: hkn0723:207909:208065 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
258: hkn0612:916880:916979 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [send] via NET/IBext/0
258: hkn0612:916880:916979 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [send] via NET/IBext/0
256: hkn0612:916852:916975 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [send] via NET/IBext/0
149: hkn0514:2950618:2950734 [1] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [receive] via NET/IBext/0
257: hkn0612:916860:916982 [1] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [receive] via NET/IBext/0
139: hkn0511:3066266:3066383 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
318: hkn0632:1758495:1758618 [2] NCCL INFO Channel 00 : 318[ca000] -> 319[e3000] via P2P/IPC/read
426: hkn0727:1345664:1345786 [2] NCCL INFO Connected all trees
426: hkn0727:1345664:1345786 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [receive] via NET/IBext/0
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [receive] via NET/IBext/0
139: hkn0511:3066266:3066383 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
138: hkn0511:3066294:3066390 [2] NCCL INFO Connected all trees
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 01 : 317[4b000] -> 318[ca000] via P2P/IPC/read
261: hkn0613:902589:902698 [1] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [receive] via NET/IBext/0
426: hkn0727:1345664:1345786 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:709702:709825 [1] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [send] via NET/IBext/0
205: hkn0532:924607:924924 [1] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [send] via NET/IBext/0
408: hkn0723:207901:208066 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [send] via NET/IBext/0
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [send] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [send] via NET/IBext/0
138: hkn0511:3066294:3066390 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
434: hkn0730:1401634:1401726 [2] NCCL INFO Connected all trees
138: hkn0511:3066294:3066390 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
434: hkn0730:1401634:1401726 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [send] via NET/IBext/0
218: hkn0601:117591:117714 [2] NCCL INFO Connected all trees
434: hkn0730:1401634:1401726 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:791903:792016 [1] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [receive] via NET/IBext/0
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [receive] via NET/IBext/0
218: hkn0601:117591:117714 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
318: hkn0632:1758495:1758618 [2] NCCL INFO Channel 01 : 318[ca000] -> 319[e3000] via P2P/IPC/read
218: hkn0601:117591:117714 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
319: hkn0632:1758511:1758619 [3] NCCL INFO Connected all trees
319: hkn0632:1758511:1758619 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
319: hkn0632:1758511:1758619 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:583800:583921 [0] NCCL INFO Channel 00 : 364[31000] -> 365[4b000] via P2P/IPC/read
318: hkn0632:1758495:1758618 [2] NCCL INFO Connected all trees
293: hkn0626:1298357:1298456 [1] NCCL INFO Connected all rings
233: hkn0605:712002:712113 [1] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [receive] via NET/IBext/0
318: hkn0632:1758495:1758618 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
318: hkn0632:1758495:1758618 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:583800:583921 [0] NCCL INFO Channel 01 : 364[31000] -> 365[4b000] via P2P/IPC/read
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [receive] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [receive] via NET/IBext/0
465: hkn0803:876477:876562 [1] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [receive] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO Channel 00 : 365[4b000] -> 366[ca000] via P2P/IPC/read
366: hkn0711:583820:583927 [2] NCCL INFO Channel 00 : 366[ca000] -> 367[e3000] via P2P/IPC/read
294: hkn0626:1298329:1298455 [2] NCCL INFO Connected all rings
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [receive] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO Channel 01 : 365[4b000] -> 366[ca000] via P2P/IPC/read
366: hkn0711:583820:583927 [2] NCCL INFO Channel 01 : 366[ca000] -> 367[e3000] via P2P/IPC/read
293: hkn0626:1298357:1298456 [1] NCCL INFO Channel 00 : 293[4b000] -> 294[ca000] via P2P/IPC/read
450: hkn0734:1156441:1156545 [2] NCCL INFO Connected all trees
367: hkn0711:583792:583925 [3] NCCL INFO Connected all trees
367: hkn0711:583792:583925 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
294: hkn0626:1298329:1298455 [2] NCCL INFO Channel 00 : 294[ca000] -> 295[e3000] via P2P/IPC/read
450: hkn0734:1156441:1156545 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [send] via NET/IBext/0
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [receive] via NET/IBext/0
450: hkn0734:1156441:1156545 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
367: hkn0711:583792:583925 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1298357:1298456 [1] NCCL INFO Channel 01 : 293[4b000] -> 294[ca000] via P2P/IPC/read
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [send] via NET/IBext/0
366: hkn0711:583820:583927 [2] NCCL INFO Connected all trees
469: hkn0804:1205507:1205626 [1] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [receive] via NET/IBext/0
294: hkn0626:1298329:1298455 [2] NCCL INFO Channel 01 : 294[ca000] -> 295[e3000] via P2P/IPC/read
366: hkn0711:583820:583927 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
295: hkn0626:1298345:1298453 [3] NCCL INFO Connected all trees
389: hkn0717:4187531:4187655 [1] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [receive] via NET/IBext/0
366: hkn0711:583820:583927 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
216: hkn0601:117612:117713 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [send] via NET/IBext/0
364: hkn0711:583800:583921 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [receive] via NET/IBext/0
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [send] via NET/IBext/0
306: hkn0629:1591947:1592059 [2] NCCL INFO Connected all rings
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [send] via NET/IBext/0
295: hkn0626:1298345:1298453 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
295: hkn0626:1298345:1298453 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 00 : 305[4b000] -> 306[ca000] via P2P/IPC/read
306: hkn0629:1591947:1592059 [2] NCCL INFO Channel 00 : 306[ca000] -> 307[e3000] via P2P/IPC/read
247: hkn0608:485624:485730 [3] NCCL INFO Connected all trees
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 01 : 305[4b000] -> 306[ca000] via P2P/IPC/read
 58: hkn0419:1544203:1544299 [2] NCCL INFO Connected all trees
306: hkn0629:1591947:1592059 [2] NCCL INFO Channel 01 : 306[ca000] -> 307[e3000] via P2P/IPC/read
247: hkn0608:485624:485730 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
307: hkn0629:1591931:1592055 [3] NCCL INFO Connected all trees
247: hkn0608:485624:485730 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [send] via NET/IBext/0
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [receive] via NET/IBext/0
307: hkn0629:1591931:1592055 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
246: hkn0608:485616:485737 [2] NCCL INFO Connected all trees
307: hkn0629:1591931:1592055 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
246: hkn0608:485616:485737 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
306: hkn0629:1591947:1592059 [2] NCCL INFO Connected all trees
246: hkn0608:485616:485737 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [send] via NET/IBext/0
244: hkn0608:485608:485739 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [receive] via NET/IBext/0
241: hkn0607:904238:904362 [1] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [receive] via NET/IBext/0
306: hkn0629:1591947:1592059 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:228954:229059 [1] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [receive] via NET/IBext/0
306: hkn0629:1591947:1592059 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:485636:485738 [1] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [receive] via NET/IBext/0
 58: hkn0419:1544203:1544299 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 58: hkn0419:1544203:1544299 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
418: hkn0725:3111809:3111929 [2] NCCL INFO Channel 01 : 418[ca000] -> 419[e3000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [send] via NET/IBext/0
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [send] via NET/IBext/0
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [receive] via NET/IBext/0
419: hkn0725:3111817:3111928 [3] NCCL INFO Connected all trees
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [receive] via NET/IBext/0
419: hkn0725:3111817:3111928 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
419: hkn0725:3111817:3111928 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
239: hkn0606:2371961:2372083 [3] NCCL INFO Connected all trees
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [send] via NET/IBext/0
418: hkn0725:3111809:3111929 [2] NCCL INFO Connected all trees
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [receive] via NET/IBext/0
418: hkn0725:3111809:3111929 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
418: hkn0725:3111809:3111929 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
239: hkn0606:2371961:2372083 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [send] via NET/IBext/0
239: hkn0606:2371961:2372083 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [receive] via NET/IBext/0
238: hkn0606:2371989:2372088 [2] NCCL INFO Connected all trees
238: hkn0606:2371989:2372088 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
286: hkn0623:1872648:1872765 [2] NCCL INFO Channel 01 : 286[ca000] -> 287[e3000] via P2P/IPC/read
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [send] via NET/IBext/0
238: hkn0606:2371989:2372088 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [receive] via NET/IBext/0
287: hkn0623:1872668:1872764 [3] NCCL INFO Connected all trees
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [send] via NET/IBext/0
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [send] via NET/IBext/0
287: hkn0623:1872668:1872764 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
191: hkn0528:1301563:1301675 [3] NCCL INFO Connected all trees
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [send] via NET/IBext/0
287: hkn0623:1872668:1872764 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [send] via NET/IBext/0
286: hkn0623:1872648:1872765 [2] NCCL INFO Connected all trees
286: hkn0623:1872648:1872765 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
191: hkn0528:1301563:1301675 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
286: hkn0623:1872648:1872765 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
191: hkn0528:1301563:1301675 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [receive] via NET/IBext/0
190: hkn0528:1301582:1301674 [2] NCCL INFO Connected all trees
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [send] via NET/IBext/0
232: hkn0605:711997:712115 [0] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [send] via NET/IBext/0
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [send] via NET/IBext/0
190: hkn0528:1301582:1301674 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
190: hkn0528:1301582:1301674 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2299079:2299192 [1] NCCL INFO Channel 01 : 405[4b000] -> 406[ca000] via P2P/IPC/read
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [receive] via NET/IBext/0
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [receive] via NET/IBext/0
372: hkn0713:470112:470238 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [receive] via NET/IBext/0
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [send] via NET/IBext/0
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [send] via NET/IBext/0
377: hkn0714:431907:432038 [1] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [receive] via NET/IBext/0
406: hkn0721:2299071:2299198 [2] NCCL INFO Channel 01 : 406[ca000] -> 407[e3000] via P2P/IPC/read
250: hkn0609:710708:710822 [2] NCCL INFO Channel 01 : 250[ca000] -> 251[e3000] via P2P/IPC/read
407: hkn0721:2299099:2299196 [3] NCCL INFO Connected all trees
382: hkn0715:401788:401899 [2] NCCL INFO Channel 00 : 382[ca000] -> 383[e3000] via P2P/IPC/read
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [receive] via NET/IBext/0
407: hkn0721:2299099:2299196 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [receive] via NET/IBext/0
256: hkn0612:916852:916975 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [send] via NET/IBext/0
407: hkn0721:2299099:2299196 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
251: hkn0609:710700:710823 [3] NCCL INFO Connected all trees
251: hkn0609:710700:710823 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [send] via NET/IBext/0
406: hkn0721:2299071:2299198 [2] NCCL INFO Connected all trees
406: hkn0721:2299071:2299198 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
406: hkn0721:2299071:2299198 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
251: hkn0609:710700:710823 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [receive] via NET/IBext/0
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [receive] via NET/IBext/0
294: hkn0626:1298329:1298455 [2] NCCL INFO Connected all trees
405: hkn0721:2299079:2299192 [1] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [receive] via NET/IBext/0
409: hkn0723:207893:208068 [1] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [receive] via NET/IBext/0
250: hkn0609:710708:710822 [2] NCCL INFO Connected all trees
373: hkn0713:470120:470234 [1] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [receive] via NET/IBext/0
250: hkn0609:710708:710822 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:693695:693790 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [send] via NET/IBext/0
250: hkn0609:710708:710822 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:939409:939536 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [receive] via NET/IBext/0
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [receive] via NET/IBext/0
294: hkn0626:1298329:1298455 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:710728:710827 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [send] via NET/IBext/0
294: hkn0626:1298329:1298455 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
249: hkn0609:710716:710825 [1] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [receive] via NET/IBext/0
248: hkn0609:710728:710827 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [receive] via NET/IBext/0
381: hkn0715:401780:401901 [1] NCCL INFO Channel 01 : 381[4b000] -> 382[ca000] via P2P/IPC/read
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [send] via NET/IBext/0
382: hkn0715:401788:401899 [2] NCCL INFO Channel 01 : 382[ca000] -> 383[e3000] via P2P/IPC/read
464: hkn0803:876465:876561 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [send] via NET/IBext/0
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [send] via NET/IBext/0
383: hkn0715:401800:401893 [3] NCCL INFO Connected all trees
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 01 : 333[4b000] -> 334[ca000] via P2P/IPC/read
383: hkn0715:401800:401893 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
203: hkn0531:1230541:1230644 [3] NCCL INFO Connected all trees
383: hkn0715:401800:401893 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
334: hkn0636:1654143:1654268 [2] NCCL INFO Channel 01 : 334[ca000] -> 335[e3000] via P2P/IPC/read
382: hkn0715:401788:401899 [2] NCCL INFO Connected all trees
335: hkn0636:1654171:1654272 [3] NCCL INFO Connected all trees
382: hkn0715:401788:401899 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
335: hkn0636:1654171:1654272 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
382: hkn0715:401788:401899 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
335: hkn0636:1654171:1654272 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:401772:401896 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [receive] via NET/IBext/0
334: hkn0636:1654143:1654268 [2] NCCL INFO Connected all trees
381: hkn0715:401780:401901 [1] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [send] via NET/IBext/0
334: hkn0636:1654143:1654268 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
334: hkn0636:1654143:1654268 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
203: hkn0531:1230541:1230644 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
240: hkn0607:904254:904366 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [send] via NET/IBext/0
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [send] via NET/IBext/0
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [receive] via NET/IBext/0
203: hkn0531:1230541:1230644 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [send] via NET/IBext/0
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [send] via NET/IBext/0
202: hkn0531:1230513:1230642 [2] NCCL INFO Connected all trees
179: hkn0525:986681:986840 [3] NCCL INFO Connected all trees
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [receive] via NET/IBext/0
202: hkn0531:1230513:1230642 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [receive] via NET/IBext/0
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [receive] via NET/IBext/0
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [receive] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [send] via NET/IBext/0
202: hkn0531:1230513:1230642 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
179: hkn0525:986681:986840 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [send] via NET/IBext/0
179: hkn0525:986681:986840 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [receive] via NET/IBext/0
178: hkn0525:986708:986837 [2] NCCL INFO Connected all trees
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [send] via NET/IBext/0
178: hkn0525:986708:986837 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
178: hkn0525:986708:986837 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [receive] via NET/IBext/0
176: hkn0525:986689:986834 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [send] via NET/IBext/0
215: hkn0535:2398889:2398985 [3] NCCL INFO Connected all trees
177: hkn0525:986697:986833 [1] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [receive] via NET/IBext/0
 94: hkn0428:667247:667347 [2] NCCL INFO Connected all trees
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [receive] via NET/IBext/0
176: hkn0525:986689:986834 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [send] via NET/IBext/0
 94: hkn0428:667247:667347 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
215: hkn0535:2398889:2398985 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [send] via NET/IBext/0
 94: hkn0428:667247:667347 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [send] via NET/IBext/0
215: hkn0535:2398889:2398985 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [receive] via NET/IBext/0
214: hkn0535:2398869:2398986 [2] NCCL INFO Connected all trees
260: hkn0613:902581:902700 [0] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [send] via NET/IBext/0
214: hkn0535:2398869:2398986 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:709722:709820 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [receive] via NET/IBext/0
204: hkn0532:924615:924928 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [receive] via NET/IBext/0
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [receive] via NET/IBext/0
214: hkn0535:2398869:2398986 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [receive] via NET/IBext/0
346: hkn0705:783101:783217 [2] NCCL INFO Channel 01 : 346[ca000] -> 347[e3000] via P2P/IPC/read
213: hkn0535:2398861:2398990 [1] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [receive] via NET/IBext/0
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 00 : 153[4b000] -> 154[ca000] via P2P/IPC/read
365: hkn0711:583808:583920 [1] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [send] via NET/IBext/0
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [send] via NET/IBext/0
500: hkn0814:675728:675835 [0] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [send] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [send] via NET/IBext/0
376: hkn0714:431923:432030 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [receive] via NET/IBext/0
347: hkn0705:783109:783209 [3] NCCL INFO Connected all trees
347: hkn0705:783109:783209 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
347: hkn0705:783109:783209 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
154: hkn0515:2896695:2896792 [2] NCCL INFO Channel 00 : 154[ca000] -> 155[e3000] via P2P/IPC/read
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [receive] via NET/IBext/0
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [receive] via NET/IBext/0
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [send] via NET/IBext/0
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [receive] via NET/IBext/0
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [send] via NET/IBext/0
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [send] via NET/IBext/0
346: hkn0705:783101:783217 [2] NCCL INFO Connected all trees
346: hkn0705:783101:783217 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 01 : 153[4b000] -> 154[ca000] via P2P/IPC/read
346: hkn0705:783101:783217 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
154: hkn0515:2896695:2896792 [2] NCCL INFO Channel 01 : 154[ca000] -> 155[e3000] via P2P/IPC/read
344: hkn0705:783129:783218 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [send] via NET/IBext/0
155: hkn0515:2896683:2896800 [3] NCCL INFO Connected all trees
345: hkn0705:783117:783216 [1] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [receive] via NET/IBext/0
155: hkn0515:2896683:2896800 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
155: hkn0515:2896683:2896800 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [send] via NET/IBext/0
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [send] via NET/IBext/0
244: hkn0608:485608:485739 [0] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [send] via NET/IBext/0
154: hkn0515:2896695:2896792 [2] NCCL INFO Connected all trees
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [receive] via NET/IBext/0
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [send] via NET/IBext/0
154: hkn0515:2896695:2896792 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
154: hkn0515:2896695:2896792 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
337: hkn0703:740940:741049 [1] NCCL INFO Channel 01 : 337[4b000] -> 338[ca000] via P2P/IPC/read
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [send] via NET/IBext/0
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [send] via NET/IBext/0
338: hkn0703:740952:741043 [2] NCCL INFO Channel 01 : 338[ca000] -> 339[e3000] via P2P/IPC/read
506: hkn0815:395000:395128 [2] NCCL INFO Connected all trees
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [receive] via NET/IBext/0
339: hkn0703:740935:741041 [3] NCCL INFO Connected all trees
339: hkn0703:740935:741041 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:395000:395128 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
339: hkn0703:740935:741041 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
506: hkn0815:395000:395128 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [send] via NET/IBext/0
338: hkn0703:740952:741043 [2] NCCL INFO Connected all trees
100: hkn0502:228966:229066 [0] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [send] via NET/IBext/0
338: hkn0703:740952:741043 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
338: hkn0703:740952:741043 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:395016:395129 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [send] via NET/IBext/0
336: hkn0703:740936:741046 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [send] via NET/IBext/0
505: hkn0815:395028:395124 [1] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [receive] via NET/IBext/0
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [send] via NET/IBext/0
337: hkn0703:740940:741049 [1] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [receive] via NET/IBext/0
336: hkn0703:740936:741046 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [send] via NET/IBext/0
504: hkn0815:395016:395129 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [receive] via NET/IBext/0
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [receive] via NET/IBext/0
408: hkn0723:207901:208066 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [receive] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [receive] via NET/IBext/0
278: hkn0621:1991488:1991585 [2] NCCL INFO Channel 01 : 278[ca000] -> 279[e3000] via P2P/IPC/read
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [send] via NET/IBext/0
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 00 : 396[31000] -> 397[4b000] via P2P/IPC/read
279: hkn0621:1991468:1991586 [3] NCCL INFO Connected all trees
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [receive] via NET/IBext/0
279: hkn0621:1991468:1991586 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [receive] via NET/IBext/0
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [send] via NET/IBext/0
279: hkn0621:1991468:1991586 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
278: hkn0621:1991488:1991585 [2] NCCL INFO Connected all trees
398: hkn0719:1305623:1305723 [2] NCCL INFO Connected all rings
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [receive] via NET/IBext/0
278: hkn0621:1991488:1991585 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
278: hkn0621:1991488:1991585 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 01 : 396[31000] -> 397[4b000] via P2P/IPC/read
217: hkn0601:117600:117712 [1] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [receive] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [receive] via NET/IBext/0
277: hkn0621:1991460:1991584 [1] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [receive] via NET/IBext/0
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 00 : 397[4b000] -> 398[ca000] via P2P/IPC/read
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [receive] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [send] via NET/IBext/0
398: hkn0719:1305623:1305723 [2] NCCL INFO Channel 00 : 398[ca000] -> 399[e3000] via P2P/IPC/read
159: hkn0516:2915875:2915970 [3] NCCL INFO Connected all trees
380: hkn0715:401772:401896 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [receive] via NET/IBext/0
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 01 : 397[4b000] -> 398[ca000] via P2P/IPC/read
398: hkn0719:1305623:1305723 [2] NCCL INFO Channel 01 : 398[ca000] -> 399[e3000] via P2P/IPC/read
159: hkn0516:2915875:2915970 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
399: hkn0719:1305603:1305721 [3] NCCL INFO Connected all trees
159: hkn0516:2915875:2915970 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:791895:792019 [0] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [send] via NET/IBext/0
399: hkn0719:1305603:1305721 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
399: hkn0719:1305603:1305721 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
158: hkn0516:2915855:2915974 [2] NCCL INFO Connected all trees
158: hkn0516:2915855:2915974 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
398: hkn0719:1305623:1305723 [2] NCCL INFO Connected all trees
158: hkn0516:2915855:2915974 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
398: hkn0719:1305623:1305723 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [receive] via NET/IBext/0
398: hkn0719:1305623:1305723 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [send] via NET/IBext/0
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [receive] via NET/IBext/0
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [receive] via NET/IBext/0
 74: hkn0423:1704821:1704920 [2] NCCL INFO Connected all trees
 74: hkn0423:1704821:1704920 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
195: hkn0529:1540716:1540851 [3] NCCL INFO Connected all trees
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [send] via NET/IBext/0
 74: hkn0423:1704821:1704920 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
195: hkn0529:1540716:1540851 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
133: hkn0510:2761928:2762038 [1] NCCL INFO Channel 00 : 133[4b000] -> 134[ca000] via P2P/IPC/read
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [receive] via NET/IBext/0
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [send] via NET/IBext/0
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [receive] via NET/IBext/0
195: hkn0529:1540716:1540851 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [receive] via NET/IBext/0
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [receive] via NET/IBext/0
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [send] via NET/IBext/0
194: hkn0529:1540708:1540856 [2] NCCL INFO Connected all trees
194: hkn0529:1540708:1540856 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
134: hkn0510:2761956:2762044 [2] NCCL INFO Channel 00 : 134[ca000] -> 135[e3000] via P2P/IPC/read
194: hkn0529:1540708:1540856 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
133: hkn0510:2761928:2762038 [1] NCCL INFO Channel 01 : 133[4b000] -> 134[ca000] via P2P/IPC/read
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [send] via NET/IBext/0
134: hkn0510:2761956:2762044 [2] NCCL INFO Channel 01 : 134[ca000] -> 135[e3000] via P2P/IPC/read
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [receive] via NET/IBext/0
135: hkn0510:2761936:2762043 [3] NCCL INFO Connected all trees
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [send] via NET/IBext/0
135: hkn0510:2761936:2762043 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [send] via NET/IBext/0
135: hkn0510:2761936:2762043 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
216: hkn0601:117612:117713 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [receive] via NET/IBext/0
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [send] via NET/IBext/0
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [send] via NET/IBext/0
134: hkn0510:2761956:2762044 [2] NCCL INFO Connected all trees
134: hkn0510:2761956:2762044 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
362: hkn0710:355457:355550 [2] NCCL INFO Connected all rings
134: hkn0510:2761956:2762044 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 86: hkn0426:813946:814074 [2] NCCL INFO Connected all trees
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [receive] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO Channel 00 : 360[31000] -> 361[4b000] via P2P/IPC/read
133: hkn0510:2761928:2762038 [1] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [receive] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO Channel 01 : 360[31000] -> 361[4b000] via P2P/IPC/read
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [send] via NET/IBext/0
361: hkn0710:355445:355552 [1] NCCL INFO Channel 00 : 361[4b000] -> 362[ca000] via P2P/IPC/read
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [send] via NET/IBext/0
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [receive] via NET/IBext/0
362: hkn0710:355457:355550 [2] NCCL INFO Channel 00 : 362[ca000] -> 363[e3000] via P2P/IPC/read
 86: hkn0426:813946:814074 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [receive] via NET/IBext/0
361: hkn0710:355445:355552 [1] NCCL INFO Channel 01 : 361[4b000] -> 362[ca000] via P2P/IPC/read
362: hkn0710:355457:355550 [2] NCCL INFO Channel 01 : 362[ca000] -> 363[e3000] via P2P/IPC/read
 86: hkn0426:813946:814074 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
363: hkn0710:355437:355557 [3] NCCL INFO Connected all trees
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [receive] via NET/IBext/0
363: hkn0710:355437:355557 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:813954:814076 [1] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [receive] via NET/IBext/0
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [send] via NET/IBext/0
363: hkn0710:355437:355557 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [send] via NET/IBext/0
362: hkn0710:355457:355550 [2] NCCL INFO Connected all trees
362: hkn0710:355457:355550 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [send] via NET/IBext/0
362: hkn0710:355457:355550 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [receive] via NET/IBext/0
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [receive] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [send] via NET/IBext/0
361: hkn0710:355445:355552 [1] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [receive] via NET/IBext/0
 98: hkn0501:1327785:1327898 [2] NCCL INFO Channel 01 : 98[ca000] -> 99[e3000] via P2P/IPC/read
348: hkn0706:752164:752267 [0] NCCL INFO Channel 01 : 348[31000] -> 349[4b000] via P2P/IPC/read
230: hkn0604:689117:689240 [2] NCCL INFO Channel 01 : 230[ca000] -> 231[e3000] via P2P/IPC/read
360: hkn0710:355429:355558 [0] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [send] via NET/IBext/0
 99: hkn0501:1327769:1327904 [3] NCCL INFO Connected all trees
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [send] via NET/IBext/0
 99: hkn0501:1327769:1327904 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 99: hkn0501:1327769:1327904 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
350: hkn0706:752144:752268 [2] NCCL INFO Connected all rings
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [send] via NET/IBext/0
349: hkn0706:752136:752262 [1] NCCL INFO Channel 00 : 349[4b000] -> 350[ca000] via P2P/IPC/read
 98: hkn0501:1327785:1327898 [2] NCCL INFO Connected all trees
350: hkn0706:752144:752268 [2] NCCL INFO Channel 00 : 350[ca000] -> 351[e3000] via P2P/IPC/read
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [receive] via NET/IBext/0
 98: hkn0501:1327785:1327898 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 98: hkn0501:1327785:1327898 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
349: hkn0706:752136:752262 [1] NCCL INFO Channel 01 : 349[4b000] -> 350[ca000] via P2P/IPC/read
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [receive] via NET/IBext/0
350: hkn0706:752144:752268 [2] NCCL INFO Channel 01 : 350[ca000] -> 351[e3000] via P2P/IPC/read
344: hkn0705:783129:783218 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [receive] via NET/IBext/0
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [send] via NET/IBext/0
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [receive] via NET/IBext/0
351: hkn0706:752152:752261 [3] NCCL INFO Connected all trees
351: hkn0706:752152:752261 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
231: hkn0604:689125:689244 [3] NCCL INFO Connected all trees
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [receive] via NET/IBext/0
351: hkn0706:752152:752261 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
350: hkn0706:752144:752268 [2] NCCL INFO Connected all trees
350: hkn0706:752144:752268 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
231: hkn0604:689125:689244 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
350: hkn0706:752144:752268 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
231: hkn0604:689125:689244 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:752164:752267 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [receive] via NET/IBext/0
230: hkn0604:689117:689240 [2] NCCL INFO Connected all trees
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [receive] via NET/IBext/0
349: hkn0706:752136:752262 [1] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [send] via NET/IBext/0
230: hkn0604:689117:689240 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
282: hkn0622:2020384:2020510 [2] NCCL INFO Connected all rings
230: hkn0604:689117:689240 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
271: hkn0616:404778:404908 [3] NCCL INFO Connected all trees
271: hkn0616:404778:404908 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:689133:689241 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [receive] via NET/IBext/0
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 01 : 280[31000] -> 281[4b000] via P2P/IPC/read
229: hkn0604:689145:689242 [1] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [receive] via NET/IBext/0
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 00 : 281[4b000] -> 282[ca000] via P2P/IPC/read
228: hkn0604:689133:689241 [0] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [send] via NET/IBext/0
282: hkn0622:2020384:2020510 [2] NCCL INFO Channel 00 : 282[ca000] -> 283[e3000] via P2P/IPC/read
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 01 : 281[4b000] -> 282[ca000] via P2P/IPC/read
271: hkn0616:404778:404908 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [send] via NET/IBext/0
282: hkn0622:2020384:2020510 [2] NCCL INFO Channel 01 : 282[ca000] -> 283[e3000] via P2P/IPC/read
283: hkn0622:2020400:2020511 [3] NCCL INFO Connected all trees
270: hkn0616:404806:404907 [2] NCCL INFO Connected all trees
283: hkn0622:2020400:2020511 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
270: hkn0616:404806:404907 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
283: hkn0622:2020400:2020511 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
270: hkn0616:404806:404907 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
282: hkn0622:2020384:2020510 [2] NCCL INFO Connected all trees
268: hkn0616:404786:404909 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [receive] via NET/IBext/0
177: hkn0525:986697:986833 [1] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [send] via NET/IBext/0
282: hkn0622:2020384:2020510 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
282: hkn0622:2020384:2020510 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
269: hkn0616:404794:404911 [1] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [send] via NET/IBext/0
464: hkn0803:876465:876561 [0] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [send] via NET/IBext/0
176: hkn0525:986689:986834 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [receive] via NET/IBext/0
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [receive] via NET/IBext/0
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [send] via NET/IBext/0
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [receive] via NET/IBext/0
268: hkn0616:404786:404909 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [receive] via NET/IBext/0
497: hkn0812:693675:693791 [1] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [send] via NET/IBext/0
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [receive] via NET/IBext/0
496: hkn0812:693695:693790 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [receive] via NET/IBext/0
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [receive] via NET/IBext/0
293: hkn0626:1298357:1298456 [1] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [receive] via NET/IBext/0
163: hkn0520:2712757:2712880 [3] NCCL INFO Connected all trees
127: hkn0508:3139037:3139138 [3] NCCL INFO Connected all trees
401: hkn0720:5385:5649 [1] NCCL INFO Channel 00 : 401[4b000] -> 402[ca000] via P2P/IPC/read
163: hkn0520:2712757:2712880 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
354: hkn0707:4019820:4019919 [2] NCCL INFO Channel 00 : 354[ca000] -> 355[e3000] via P2P/IPC/read
163: hkn0520:2712757:2712880 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
127: hkn0508:3139037:3139138 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [send] via NET/IBext/0
162: hkn0520:2712749:2712876 [2] NCCL INFO Connected all trees
162: hkn0520:2712749:2712876 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
162: hkn0520:2712749:2712876 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
127: hkn0508:3139037:3139138 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [send] via NET/IBext/0
126: hkn0508:3139025:3139135 [2] NCCL INFO Connected all trees
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [receive] via NET/IBext/0
126: hkn0508:3139025:3139135 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [send] via NET/IBext/0
364: hkn0711:583800:583921 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [receive] via NET/IBext/0
348: hkn0706:752164:752267 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [receive] via NET/IBext/0
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [send] via NET/IBext/0
126: hkn0508:3139025:3139135 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
402: hkn0720:5397:5643 [2] NCCL INFO Channel 00 : 402[ca000] -> 403[e3000] via P2P/IPC/read
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [receive] via NET/IBext/0
401: hkn0720:5385:5649 [1] NCCL INFO Channel 01 : 401[4b000] -> 402[ca000] via P2P/IPC/read
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [send] via NET/IBext/0
402: hkn0720:5397:5643 [2] NCCL INFO Channel 01 : 402[ca000] -> 403[e3000] via P2P/IPC/read
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [send] via NET/IBext/0
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [receive] via NET/IBext/0
403: hkn0720:5377:5646 [3] NCCL INFO Connected all trees
403: hkn0720:5377:5646 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 00 : 352[31000] -> 353[4b000] via P2P/IPC/read
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [send] via NET/IBext/0
403: hkn0720:5377:5646 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [send] via NET/IBext/0
402: hkn0720:5397:5643 [2] NCCL INFO Connected all trees
402: hkn0720:5397:5643 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:5397:5643 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 01 : 353[4b000] -> 354[ca000] via P2P/IPC/read
400: hkn0720:5369:5640 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [send] via NET/IBext/0
354: hkn0707:4019820:4019919 [2] NCCL INFO Channel 01 : 354[ca000] -> 355[e3000] via P2P/IPC/read
401: hkn0720:5385:5649 [1] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [receive] via NET/IBext/0
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 01 : 352[31000] -> 353[4b000] via P2P/IPC/read
240: hkn0607:904254:904366 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [receive] via NET/IBext/0
400: hkn0720:5369:5640 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [send] via NET/IBext/0
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 00 : 81[4b000] -> 80[31000] via P2P/IPC/read
355: hkn0707:4019792:4019918 [3] NCCL INFO Connected all trees
241: hkn0607:904238:904362 [1] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [send] via NET/IBext/0
355: hkn0707:4019792:4019918 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
355: hkn0707:4019792:4019918 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 00 : 329[4b000] -> 330[ca000] via P2P/IPC/read
260: hkn0613:902581:902700 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [send] via NET/IBext/0
354: hkn0707:4019820:4019919 [2] NCCL INFO Connected all trees
354: hkn0707:4019820:4019919 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
330: hkn0635:1225453:1225598 [2] NCCL INFO Channel 00 : 330[ca000] -> 331[e3000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [receive] via NET/IBext/0
354: hkn0707:4019820:4019919 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [send] via NET/IBext/0
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 01 : 329[4b000] -> 330[ca000] via P2P/IPC/read
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [receive] via NET/IBext/0
330: hkn0635:1225453:1225598 [2] NCCL INFO Channel 01 : 330[ca000] -> 331[e3000] via P2P/IPC/read
500: hkn0814:675728:675835 [0] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [receive] via NET/IBext/0
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [send] via NET/IBext/0
331: hkn0635:1225445:1225601 [3] NCCL INFO Connected all trees
331: hkn0635:1225445:1225601 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
199: hkn0530:1258050:1258161 [3] NCCL INFO Connected all trees
331: hkn0635:1225445:1225601 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 78: hkn0424:2947862:2947966 [2] NCCL INFO Connected all trees
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [receive] via NET/IBext/0
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [receive] via NET/IBext/0
 81: hkn0425:2083915:2084030 [1] NCCL INFO Channel 01 : 81[4b000] -> 80[31000] via P2P/IPC/read
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [send] via NET/IBext/0
504: hkn0815:395016:395129 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [send] via NET/IBext/0
330: hkn0635:1225453:1225598 [2] NCCL INFO Connected all trees
330: hkn0635:1225453:1225598 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [send] via NET/IBext/0
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [send] via NET/IBext/0
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [send] via NET/IBext/0
232: hkn0605:711997:712115 [0] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [receive] via NET/IBext/0
489: hkn0809:937231:937375 [1] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [send] via NET/IBext/0
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [receive] via NET/IBext/0
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [send] via NET/IBext/0
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [send] via NET/IBext/0
228: hkn0604:689133:689241 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [send] via NET/IBext/0
330: hkn0635:1225453:1225598 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [send] via NET/IBext/0
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [send] via NET/IBext/0
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [receive] via NET/IBext/0
199: hkn0530:1258050:1258161 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [send] via NET/IBext/0
199: hkn0530:1258050:1258161 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
198: hkn0530:1258034:1258159 [2] NCCL INFO Connected all trees
 78: hkn0424:2947862:2947966 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
198: hkn0530:1258034:1258159 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 78: hkn0424:2947862:2947966 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
198: hkn0530:1258034:1258159 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [receive] via NET/IBext/0
177: hkn0525:986697:986833 [1] NCCL INFO Channel 00 : 177[4b000] -> 176[31000] via P2P/IPC/read
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [receive] via NET/IBext/0
244: hkn0608:485608:485739 [0] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [receive] via NET/IBext/0
248: hkn0609:710728:710827 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [send] via NET/IBext/0
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [send] via NET/IBext/0
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [send] via NET/IBext/0
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [receive] via NET/IBext/0
197: hkn0530:1258062:1258153 [1] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [receive] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [receive] via NET/IBext/0
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [send] via NET/IBext/0
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [send] via NET/IBext/0
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [send] via NET/IBext/0
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [receive] via NET/IBext/0
 90: hkn0427:1135009:1135135 [2] NCCL INFO Connected all trees
100: hkn0502:228966:229066 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [send] via NET/IBext/0
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [receive] via NET/IBext/0
 90: hkn0427:1135009:1135135 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 00 : 145[4b000] -> 146[ca000] via P2P/IPC/read
 90: hkn0427:1135009:1135135 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:108398:108509 [2] NCCL INFO Channel 01 : 386[ca000] -> 387[e3000] via P2P/IPC/read
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [receive] via NET/IBext/0
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [send] via NET/IBext/0
400: hkn0720:5369:5640 [0] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [send] via NET/IBext/0
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [receive] via NET/IBext/0
177: hkn0525:986697:986833 [1] NCCL INFO Channel 01 : 177[4b000] -> 176[31000] via P2P/IPC/read
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [receive] via NET/IBext/0
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [send] via NET/IBext/0
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [send] via NET/IBext/0
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [send] via NET/IBext/0
146: hkn0513:3012852:3012957 [2] NCCL INFO Channel 00 : 146[ca000] -> 147[e3000] via P2P/IPC/read
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 01 : 145[4b000] -> 146[ca000] via P2P/IPC/read
387: hkn0716:108382:108508 [3] NCCL INFO Connected all trees
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [send] via NET/IBext/0
146: hkn0513:3012852:3012957 [2] NCCL INFO Channel 01 : 146[ca000] -> 147[e3000] via P2P/IPC/read
147: hkn0513:3012860:3012956 [3] NCCL INFO Connected all trees
387: hkn0716:108382:108508 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
147: hkn0513:3012860:3012956 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
387: hkn0716:108382:108508 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
147: hkn0513:3012860:3012956 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:108398:108509 [2] NCCL INFO Connected all trees
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [receive] via NET/IBext/0
146: hkn0513:3012852:3012957 [2] NCCL INFO Connected all trees
146: hkn0513:3012852:3012957 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
386: hkn0716:108398:108509 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:791895:792019 [0] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [receive] via NET/IBext/0
146: hkn0513:3012852:3012957 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [send] via NET/IBext/0
386: hkn0716:108398:108509 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [send] via NET/IBext/0
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [receive] via NET/IBext/0
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [send] via NET/IBext/0
384: hkn0716:108410:108503 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [send] via NET/IBext/0
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [receive] via NET/IBext/0
385: hkn0716:108390:108502 [1] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [receive] via NET/IBext/0
372: hkn0713:470112:470238 [0] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [send] via NET/IBext/0
384: hkn0716:108410:108503 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [send] via NET/IBext/0
505: hkn0815:395028:395124 [1] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [send] via NET/IBext/0
110: hkn0504:40723:40837 [2] NCCL INFO Connected all trees
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [send] via NET/IBext/0
183: hkn0526:1428318:1428415 [3] NCCL INFO Connected all trees
110: hkn0504:40723:40837 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1520753:1520864 [1] NCCL INFO Channel 00 : 325[4b000] -> 326[ca000] via P2P/IPC/read
110: hkn0504:40723:40837 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
183: hkn0526:1428318:1428415 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 00 : 209[4b000] -> 208[31000] via P2P/IPC/read
108: hkn0504:40743:40838 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [receive] via NET/IBext/0
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [send] via NET/IBext/0
109: hkn0504:40731:40842 [1] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [send] via NET/IBext/0
108: hkn0504:40743:40838 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [receive] via NET/IBext/0
183: hkn0526:1428318:1428415 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:876477:876562 [1] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [send] via NET/IBext/0
233: hkn0605:712002:712113 [1] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [send] via NET/IBext/0
182: hkn0526:1428290:1428419 [2] NCCL INFO Connected all trees
326: hkn0634:1520761:1520867 [2] NCCL INFO Channel 00 : 326[ca000] -> 327[e3000] via P2P/IPC/read
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [send] via NET/IBext/0
182: hkn0526:1428290:1428419 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:693675:693791 [1] NCCL INFO Channel 00 : 497[4b000] -> 496[31000] via P2P/IPC/read
182: hkn0526:1428290:1428419 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [receive] via NET/IBext/0
325: hkn0634:1520753:1520864 [1] NCCL INFO Channel 01 : 325[4b000] -> 326[ca000] via P2P/IPC/read
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [receive] via NET/IBext/0
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [send] via NET/IBext/0
249: hkn0609:710716:710825 [1] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [send] via NET/IBext/0
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [send] via NET/IBext/0
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [receive] via NET/IBext/0
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [send] via NET/IBext/0
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [send] via NET/IBext/0
181: hkn0526:1428306:1428417 [1] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [receive] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [receive] via NET/IBext/0
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [send] via NET/IBext/0
209: hkn0534:1148292:1148420 [1] NCCL INFO Channel 01 : 209[4b000] -> 208[31000] via P2P/IPC/read
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [receive] via NET/IBext/0
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [send] via NET/IBext/0
326: hkn0634:1520761:1520867 [2] NCCL INFO Channel 01 : 326[ca000] -> 327[e3000] via P2P/IPC/read
241: hkn0607:904238:904362 [1] NCCL INFO Channel 00 : 241[4b000] -> 240[31000] via P2P/IPC/read
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [receive] via NET/IBext/0
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [send] via NET/IBext/0
327: hkn0634:1520781:1520863 [3] NCCL INFO Connected all trees
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [receive] via NET/IBext/0
327: hkn0634:1520781:1520863 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:693675:693791 [1] NCCL INFO Channel 01 : 497[4b000] -> 496[31000] via P2P/IPC/read
327: hkn0634:1520781:1520863 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [send] via NET/IBext/0
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [send] via NET/IBext/0
408: hkn0723:207901:208066 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [send] via NET/IBext/0
326: hkn0634:1520761:1520867 [2] NCCL INFO Connected all trees
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [send] via NET/IBext/0
326: hkn0634:1520761:1520867 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
326: hkn0634:1520761:1520867 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 51: hkn0417:2267539:2267651 [3] NCCL INFO Connected all trees
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [receive] via NET/IBext/0
267: hkn0615:414197:414325 [3] NCCL INFO Connected all trees
325: hkn0634:1520753:1520864 [1] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [receive] via NET/IBext/0
 51: hkn0417:2267539:2267651 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [send] via NET/IBext/0
 51: hkn0417:2267539:2267651 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [send] via NET/IBext/0
267: hkn0615:414197:414325 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
241: hkn0607:904238:904362 [1] NCCL INFO Channel 01 : 241[4b000] -> 240[31000] via P2P/IPC/read
 50: hkn0417:2267531:2267655 [2] NCCL INFO Connected all trees
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [send] via NET/IBext/0
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [send] via NET/IBext/0
 50: hkn0417:2267531:2267655 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
267: hkn0615:414197:414325 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 50: hkn0417:2267531:2267655 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
266: hkn0615:414205:414319 [2] NCCL INFO Connected all trees
266: hkn0615:414205:414319 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [receive] via NET/IBext/0
266: hkn0615:414205:414319 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [send] via NET/IBext/0
264: hkn0615:414213:414324 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [send] via NET/IBext/0
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [receive] via NET/IBext/0
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [receive] via NET/IBext/0
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [send] via NET/IBext/0
337: hkn0703:740940:741049 [1] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [send] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [receive] via NET/IBext/0
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [send] via NET/IBext/0
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 00 : 49[4b000] -> 48[31000] via P2P/IPC/read
265: hkn0615:414225:414318 [1] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [receive] via NET/IBext/0
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [send] via NET/IBext/0
264: hkn0615:414213:414324 [0] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [send] via NET/IBext/0
 49: hkn0417:2267523:2267656 [1] NCCL INFO Channel 01 : 49[4b000] -> 48[31000] via P2P/IPC/read
264: hkn0615:414213:414324 [0] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [receive] via NET/IBext/0
265: hkn0615:414225:414318 [1] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [send] via NET/IBext/0
303: hkn0628:671779:671905 [3] NCCL INFO Connected all trees
291: hkn0624:1772830:1772945 [3] NCCL INFO Connected all trees
314: hkn0631:1021723:1021832 [2] NCCL INFO Channel 01 : 314[ca000] -> 315[e3000] via P2P/IPC/read
303: hkn0628:671779:671905 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
310: hkn0630:1598359:1598459 [2] NCCL INFO Channel 01 : 310[ca000] -> 311[e3000] via P2P/IPC/read
303: hkn0628:671779:671905 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
291: hkn0624:1772830:1772945 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 00 : 17[4b000] -> 16[31000] via P2P/IPC/read
336: hkn0703:740936:741046 [0] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [send] via NET/IBext/0
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [receive] via NET/IBext/0
302: hkn0628:671759:671904 [2] NCCL INFO Connected all trees
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [send] via NET/IBext/0
302: hkn0628:671759:671904 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [send] via NET/IBext/0
345: hkn0705:783117:783216 [1] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [send] via NET/IBext/0
302: hkn0628:671759:671904 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
291: hkn0624:1772830:1772945 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
300: hkn0628:671767:671903 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [receive] via NET/IBext/0
290: hkn0624:1772838:1772944 [2] NCCL INFO Connected all trees
301: hkn0628:671751:671908 [1] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [send] via NET/IBext/0
290: hkn0624:1772838:1772944 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:671767:671903 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [receive] via NET/IBext/0
290: hkn0624:1772838:1772944 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [send] via NET/IBext/0
315: hkn0631:1021715:1021825 [3] NCCL INFO Connected all trees
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [receive] via NET/IBext/0
315: hkn0631:1021715:1021825 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [send] via NET/IBext/0
315: hkn0631:1021715:1021825 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
314: hkn0631:1021723:1021832 [2] NCCL INFO Connected all trees
311: hkn0630:1598331:1598462 [3] NCCL INFO Connected all trees
314: hkn0631:1021723:1021832 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
311: hkn0630:1598331:1598462 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
409: hkn0723:207893:208068 [1] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [send] via NET/IBext/0
 17: hkn0408:2890667:2890771 [1] NCCL INFO Channel 01 : 17[4b000] -> 16[31000] via P2P/IPC/read
216: hkn0601:117612:117713 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [send] via NET/IBext/0
314: hkn0631:1021723:1021832 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [send] via NET/IBext/0
311: hkn0630:1598331:1598462 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [receive] via NET/IBext/0
310: hkn0630:1598359:1598459 [2] NCCL INFO Connected all trees
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [receive] via NET/IBext/0
310: hkn0630:1598359:1598459 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
310: hkn0630:1598359:1598459 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:413102:413217 [0] NCCL INFO Channel 01 : 356[31000] -> 357[4b000] via P2P/IPC/read
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [receive] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 00 : 296[31000] -> 297[4b000] via P2P/IPC/read
309: hkn0630:1598347:1598454 [1] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [receive] via NET/IBext/0
357: hkn0708:413110:413222 [1] NCCL INFO Channel 00 : 357[4b000] -> 358[ca000] via P2P/IPC/read
465: hkn0803:876477:876562 [1] NCCL INFO Channel 00 : 465[4b000] -> 464[31000] via P2P/IPC/read
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [receive] via NET/IBext/0
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [send] via NET/IBext/0
358: hkn0708:413122:413219 [2] NCCL INFO Channel 00 : 358[ca000] -> 359[e3000] via P2P/IPC/read
357: hkn0708:413110:413222 [1] NCCL INFO Channel 01 : 357[4b000] -> 358[ca000] via P2P/IPC/read
298: hkn0627:1787836:1787925 [2] NCCL INFO Channel 01 : 298[ca000] -> 299[e3000] via P2P/IPC/read
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [send] via NET/IBext/0
358: hkn0708:413122:413219 [2] NCCL INFO Channel 01 : 358[ca000] -> 359[e3000] via P2P/IPC/read
359: hkn0708:413094:413225 [3] NCCL INFO Connected all trees
299: hkn0627:1787816:1787921 [3] NCCL INFO Connected all trees
464: hkn0803:876465:876561 [0] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [receive] via NET/IBext/0
359: hkn0708:413094:413225 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [receive] via NET/IBext/0
359: hkn0708:413094:413225 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [receive] via NET/IBext/0
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 00 : 97[4b000] -> 96[31000] via P2P/IPC/read
358: hkn0708:413122:413219 [2] NCCL INFO Connected all trees
299: hkn0627:1787816:1787921 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [send] via NET/IBext/0
358: hkn0708:413122:413219 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
358: hkn0708:413122:413219 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
299: hkn0627:1787816:1787921 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:413102:413217 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [receive] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 01 : 296[31000] -> 297[4b000] via P2P/IPC/read
357: hkn0708:413110:413222 [1] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [receive] via NET/IBext/0
298: hkn0627:1787836:1787925 [2] NCCL INFO Connected all trees
465: hkn0803:876477:876562 [1] NCCL INFO Channel 01 : 465[4b000] -> 464[31000] via P2P/IPC/read
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [send] via NET/IBext/0
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [send] via NET/IBext/0
356: hkn0708:413102:413217 [0] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [send] via NET/IBext/0
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [send] via NET/IBext/0
298: hkn0627:1787836:1787925 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
298: hkn0627:1787836:1787925 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
274: hkn0617:2294558:2294701 [2] NCCL INFO Channel 01 : 274[ca000] -> 275[e3000] via P2P/IPC/read
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [receive] via NET/IBext/0
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [receive] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [send] via NET/IBext/0
275: hkn0617:2294550:2294702 [3] NCCL INFO Connected all trees
275: hkn0617:2294550:2294702 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [send] via NET/IBext/0
275: hkn0617:2294550:2294702 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 97: hkn0501:1327797:1327897 [1] NCCL INFO Channel 01 : 97[4b000] -> 96[31000] via P2P/IPC/read
274: hkn0617:2294558:2294701 [2] NCCL INFO Connected all trees
274: hkn0617:2294558:2294701 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
274: hkn0617:2294558:2294701 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
107: hkn0503:2899572:2899698 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [receive] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [send] via NET/IBext/0
344: hkn0705:783129:783218 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [send] via NET/IBext/0
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [receive] via NET/IBext/0
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [send] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [send] via NET/IBext/0
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [receive] via NET/IBext/0
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [send] via NET/IBext/0
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 00 : 273[4b000] -> 272[31000] via P2P/IPC/read
107: hkn0503:2899572:2899698 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [receive] via NET/IBext/0
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 00 : 113[4b000] -> 112[31000] via P2P/IPC/read
337: hkn0703:740940:741049 [1] NCCL INFO Channel 00 : 337[4b000] -> 336[31000] via P2P/IPC/read
273: hkn0617:2294577:2294697 [1] NCCL INFO Channel 01 : 273[4b000] -> 272[31000] via P2P/IPC/read
260: hkn0613:902581:902700 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [receive] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [send] via NET/IBext/0
106: hkn0503:2899580:2899695 [2] NCCL INFO Connected all trees
 11: hkn0405:3206742:3206897 [3] NCCL INFO Connected all trees
119: hkn0506:837957:838067 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
370: hkn0712:294940:295065 [2] NCCL INFO Connected all rings
106: hkn0503:2899580:2899695 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 11: hkn0405:3206742:3206897 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
106: hkn0503:2899580:2899695 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 11: hkn0405:3206742:3206897 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [receive] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [send] via NET/IBext/0
376: hkn0714:431923:432030 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [send] via NET/IBext/0
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [receive] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [send] via NET/IBext/0
 10: hkn0405:3206770:3206895 [2] NCCL INFO Connected all trees
217: hkn0601:117600:117712 [1] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [send] via NET/IBext/0
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [send] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [receive] via NET/IBext/0
 10: hkn0405:3206770:3206895 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 10: hkn0405:3206770:3206895 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
119: hkn0506:837957:838067 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
113: hkn0505:2303684:2303783 [1] NCCL INFO Channel 01 : 113[4b000] -> 112[31000] via P2P/IPC/read
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [send] via NET/IBext/0
496: hkn0812:693695:693790 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [send] via NET/IBext/0
337: hkn0703:740940:741049 [1] NCCL INFO Channel 01 : 337[4b000] -> 336[31000] via P2P/IPC/read
228: hkn0604:689133:689241 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [receive] via NET/IBext/0
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [receive] via NET/IBext/0
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [receive] via NET/IBext/0
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [send] via NET/IBext/0
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [send] via NET/IBext/0
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [send] via NET/IBext/0
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [receive] via NET/IBext/0
118: hkn0506:837941:838072 [2] NCCL INFO Connected all trees
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 00 : 77[4b000] -> 76[31000] via P2P/IPC/read
368: hkn0712:294956:295068 [0] NCCL INFO Channel 00 : 368[31000] -> 369[4b000] via P2P/IPC/read
109: hkn0504:40731:40842 [1] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [receive] via NET/IBext/0
118: hkn0506:837941:838072 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [receive] via NET/IBext/0
401: hkn0720:5385:5649 [1] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [send] via NET/IBext/0
176: hkn0525:986689:986834 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [send] via NET/IBext/0
118: hkn0506:837941:838072 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [receive] via NET/IBext/0
493: hkn0810:939417:939538 [1] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [receive] via NET/IBext/0
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [receive] via NET/IBext/0
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [receive] via NET/IBext/0
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [send] via NET/IBext/0
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [send] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [receive] via NET/IBext/0
368: hkn0712:294956:295068 [0] NCCL INFO Channel 01 : 368[31000] -> 369[4b000] via P2P/IPC/read
117: hkn0506:837969:838070 [1] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [receive] via NET/IBext/0
369: hkn0712:294968:295070 [1] NCCL INFO Channel 00 : 369[4b000] -> 370[ca000] via P2P/IPC/read
264: hkn0615:414213:414324 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [receive] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [send] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [receive] via NET/IBext/0
370: hkn0712:294940:295065 [2] NCCL INFO Channel 00 : 370[ca000] -> 371[e3000] via P2P/IPC/read
356: hkn0708:413102:413217 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [send] via NET/IBext/0
116: hkn0506:837949:838063 [0] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [send] via NET/IBext/0
369: hkn0712:294968:295070 [1] NCCL INFO Channel 01 : 369[4b000] -> 370[ca000] via P2P/IPC/read
322: hkn0633:1526218:1526355 [2] NCCL INFO Channel 01 : 322[ca000] -> 323[e3000] via P2P/IPC/read
492: hkn0810:939409:939536 [0] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [receive] via NET/IBext/0
370: hkn0712:294940:295065 [2] NCCL INFO Channel 01 : 370[ca000] -> 371[e3000] via P2P/IPC/read
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [receive] via NET/IBext/0
371: hkn0712:294948:295061 [3] NCCL INFO Connected all trees
371: hkn0712:294948:295061 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
323: hkn0633:1526210:1526349 [3] NCCL INFO Connected all trees
100: hkn0502:228966:229066 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [receive] via NET/IBext/0
371: hkn0712:294948:295061 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
370: hkn0712:294940:295065 [2] NCCL INFO Connected all trees
323: hkn0633:1526210:1526349 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
370: hkn0712:294940:295065 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
323: hkn0633:1526210:1526349 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [receive] via NET/IBext/0
204: hkn0532:924615:924928 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [send] via NET/IBext/0
240: hkn0607:904254:904366 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [send] via NET/IBext/0
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [receive] via NET/IBext/0
268: hkn0616:404786:404909 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [send] via NET/IBext/0
 77: hkn0424:2947854:2947962 [1] NCCL INFO Channel 01 : 77[4b000] -> 76[31000] via P2P/IPC/read
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [send] via NET/IBext/0
370: hkn0712:294940:295065 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:294956:295068 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [send] via NET/IBext/0
322: hkn0633:1526218:1526355 [2] NCCL INFO Connected all trees
369: hkn0712:294968:295070 [1] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [receive] via NET/IBext/0
322: hkn0633:1526218:1526355 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:294956:295068 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [send] via NET/IBext/0
322: hkn0633:1526218:1526355 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
488: hkn0809:937239:937379 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [receive] via NET/IBext/0
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [send] via NET/IBext/0
368: hkn0712:294956:295068 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [receive] via NET/IBext/0
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [receive] via NET/IBext/0
400: hkn0720:5369:5640 [0] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [receive] via NET/IBext/0
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [receive] via NET/IBext/0
369: hkn0712:294968:295070 [1] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [send] via NET/IBext/0
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [send] via NET/IBext/0
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [send] via NET/IBext/0
487: hkn0808:970549:970680 [3] NCCL INFO Connected all trees
500: hkn0814:675728:675835 [0] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [send] via NET/IBext/0
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 01 : 420[31000] -> 421[4b000] via P2P/IPC/read
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [receive] via NET/IBext/0
232: hkn0605:711997:712115 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [receive] via NET/IBext/0
487: hkn0808:970549:970680 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
421: hkn0726:1547991:1548116 [1] NCCL INFO Connected all rings
487: hkn0808:970549:970680 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
422: hkn0726:1548007:1548114 [2] NCCL INFO Connected all rings
486: hkn0808:970577:970677 [2] NCCL INFO Connected all trees
421: hkn0726:1547991:1548116 [1] NCCL INFO Channel 00 : 421[4b000] -> 422[ca000] via P2P/IPC/read
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [receive] via NET/IBext/0
369: hkn0712:294968:295070 [1] NCCL INFO Channel 00 : 369[4b000] -> 368[31000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [send] via NET/IBext/0
486: hkn0808:970577:970677 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [receive] via NET/IBext/0
486: hkn0808:970577:970677 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:970557:970676 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [receive] via NET/IBext/0
422: hkn0726:1548007:1548114 [2] NCCL INFO Channel 00 : 422[ca000] -> 423[e3000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [send] via NET/IBext/0
485: hkn0808:970565:970682 [1] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [receive] via NET/IBext/0
205: hkn0532:924607:924924 [1] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [receive] via NET/IBext/0
484: hkn0808:970557:970676 [0] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [send] via NET/IBext/0
484: hkn0808:970557:970676 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [send] via NET/IBext/0
421: hkn0726:1547991:1548116 [1] NCCL INFO Channel 01 : 421[4b000] -> 422[ca000] via P2P/IPC/read
484: hkn0808:970557:970676 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [receive] via NET/IBext/0
422: hkn0726:1548007:1548114 [2] NCCL INFO Channel 01 : 422[ca000] -> 423[e3000] via P2P/IPC/read
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [send] via NET/IBext/0
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 00 : 145[4b000] -> 144[31000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [receive] via NET/IBext/0
423: hkn0726:1547999:1548115 [3] NCCL INFO Connected all trees
423: hkn0726:1547999:1548115 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
483: hkn0807:1018978:1019080 [3] NCCL INFO Connected all trees
108: hkn0504:40743:40838 [0] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [receive] via NET/IBext/0
423: hkn0726:1547999:1548115 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
422: hkn0726:1548007:1548114 [2] NCCL INFO Connected all trees
483: hkn0807:1018978:1019080 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:294968:295070 [1] NCCL INFO Channel 01 : 369[4b000] -> 368[31000] via P2P/IPC/read
422: hkn0726:1548007:1548114 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
422: hkn0726:1548007:1548114 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
483: hkn0807:1018978:1019080 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [send] via NET/IBext/0
244: hkn0608:485608:485739 [0] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [send] via NET/IBext/0
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [receive] via NET/IBext/0
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [receive] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [send] via NET/IBext/0
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [send] via NET/IBext/0
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [receive] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [receive] via NET/IBext/0
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [send] via NET/IBext/0
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [receive] via NET/IBext/0
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [receive] via NET/IBext/0
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [receive] via NET/IBext/0
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [receive] via NET/IBext/0
421: hkn0726:1547991:1548116 [1] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [receive] via NET/IBext/0
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [send] via NET/IBext/0
482: hkn0807:1018950:1019079 [2] NCCL INFO Connected all trees
269: hkn0616:404794:404911 [1] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [receive] via NET/IBext/0
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [send] via NET/IBext/0
482: hkn0807:1018950:1019079 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
511: hkn0816:375492:375642 [3] NCCL INFO Connected all trees
145: hkn0513:3012872:3012961 [1] NCCL INFO Channel 01 : 145[4b000] -> 144[31000] via P2P/IPC/read
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [send] via NET/IBext/0
482: hkn0807:1018950:1019079 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
511: hkn0816:375492:375642 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [send] via NET/IBext/0
511: hkn0816:375492:375642 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [receive] via NET/IBext/0
510: hkn0816:375512:375637 [2] NCCL INFO Connected all trees
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [receive] via NET/IBext/0
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [send] via NET/IBext/0
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [receive] via NET/IBext/0
510: hkn0816:375512:375637 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [send] via NET/IBext/0
510: hkn0816:375512:375637 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 00 : 481[4b000] -> 480[31000] via P2P/IPC/read
508: hkn0816:375484:375639 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [receive] via NET/IBext/0
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [receive] via NET/IBext/0
509: hkn0816:375500:375645 [1] NCCL INFO Channel 00 : 509[4b000] -> 508[31000] via P2P/IPC/read
509: hkn0816:375500:375645 [1] NCCL INFO Channel 01 : 509[4b000] -> 508[31000] via P2P/IPC/read
438: hkn0731:1386633:1386740 [2] NCCL INFO Channel 01 : 438[ca000] -> 439[e3000] via P2P/IPC/read
508: hkn0816:375484:375639 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [receive] via NET/IBext/0
442: hkn0732:1211543:1211663 [2] NCCL INFO Channel 01 : 442[ca000] -> 443[e3000] via P2P/IPC/read
340: hkn0704:791895:792019 [0] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [send] via NET/IBext/0
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [send] via NET/IBext/0
481: hkn0807:1018958:1019082 [1] NCCL INFO Channel 01 : 481[4b000] -> 480[31000] via P2P/IPC/read
508: hkn0816:375484:375639 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [send] via NET/IBext/0
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [receive] via NET/IBext/0
439: hkn0731:1386625:1386746 [3] NCCL INFO Connected all trees
439: hkn0731:1386625:1386746 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
439: hkn0731:1386625:1386746 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
443: hkn0732:1211551:1211659 [3] NCCL INFO Connected all trees
438: hkn0731:1386633:1386740 [2] NCCL INFO Connected all trees
443: hkn0732:1211551:1211659 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
336: hkn0703:740936:741046 [0] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [receive] via NET/IBext/0
438: hkn0731:1386633:1386740 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
377: hkn0714:431907:432038 [1] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [send] via NET/IBext/0
438: hkn0731:1386633:1386740 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [send] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [receive] via NET/IBext/0
372: hkn0713:470112:470238 [0] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [receive] via NET/IBext/0
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [send] via NET/IBext/0
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [send] via NET/IBext/0
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [receive] via NET/IBext/0
437: hkn0731:1386617:1386741 [1] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [receive] via NET/IBext/0
443: hkn0732:1211551:1211659 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [send] via NET/IBext/0
442: hkn0732:1211543:1211663 [2] NCCL INFO Connected all trees
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [receive] via NET/IBext/0
442: hkn0732:1211543:1211663 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [send] via NET/IBext/0
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [send] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [receive] via NET/IBext/0
442: hkn0732:1211543:1211663 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [send] via NET/IBext/0
453: hkn0736:1508232:1508369 [1] NCCL INFO Channel 01 : 453[4b000] -> 454[ca000] via P2P/IPC/read
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [send] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [send] via NET/IBext/0
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [receive] via NET/IBext/0
454: hkn0736:1508244:1508370 [2] NCCL INFO Channel 00 : 454[ca000] -> 455[e3000] via P2P/IPC/read
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [receive] via NET/IBext/0
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 01 : 452[31000] -> 453[4b000] via P2P/IPC/read
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [send] via NET/IBext/0
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [send] via NET/IBext/0
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [send] via NET/IBext/0
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [send] via NET/IBext/0
454: hkn0736:1508244:1508370 [2] NCCL INFO Channel 01 : 454[ca000] -> 455[e3000] via P2P/IPC/read
458: hkn0801:2239916:2240014 [2] NCCL INFO Channel 00 : 458[ca000] -> 459[e3000] via P2P/IPC/read
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [send] via NET/IBext/0
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [send] via NET/IBext/0
455: hkn0736:1508224:1508372 [3] NCCL INFO Connected all trees
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 01 : 457[4b000] -> 458[ca000] via P2P/IPC/read
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 00 : 45[4b000] -> 44[31000] via P2P/IPC/read
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 00 : 173[4b000] -> 172[31000] via P2P/IPC/read
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [send] via NET/IBext/0
109: hkn0504:40731:40842 [1] NCCL INFO Channel 00 : 109[4b000] -> 108[31000] via P2P/IPC/read
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [send] via NET/IBext/0
455: hkn0736:1508224:1508372 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
455: hkn0736:1508224:1508372 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
458: hkn0801:2239916:2240014 [2] NCCL INFO Channel 01 : 458[ca000] -> 459[e3000] via P2P/IPC/read
454: hkn0736:1508244:1508370 [2] NCCL INFO Connected all trees
459: hkn0801:2239888:2240016 [3] NCCL INFO Connected all trees
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [send] via NET/IBext/0
454: hkn0736:1508244:1508370 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
454: hkn0736:1508244:1508370 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
459: hkn0801:2239888:2240016 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [send] via NET/IBext/0
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [receive] via NET/IBext/0
453: hkn0736:1508232:1508369 [1] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [receive] via NET/IBext/0
459: hkn0801:2239888:2240016 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [send] via NET/IBext/0
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [send] via NET/IBext/0
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [send] via NET/IBext/0
458: hkn0801:2239916:2240014 [2] NCCL INFO Connected all trees
458: hkn0801:2239916:2240014 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 01 : 429[4b000] -> 430[ca000] via P2P/IPC/read
458: hkn0801:2239916:2240014 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
173: hkn0524:1133699:1133792 [1] NCCL INFO Channel 01 : 173[4b000] -> 172[31000] via P2P/IPC/read
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [send] via NET/IBext/0
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [receive] via NET/IBext/0
109: hkn0504:40731:40842 [1] NCCL INFO Channel 01 : 109[4b000] -> 108[31000] via P2P/IPC/read
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [receive] via NET/IBext/0
430: hkn0728:1323891:1323997 [2] NCCL INFO Channel 01 : 430[ca000] -> 431[e3000] via P2P/IPC/read
 45: hkn0415:2496313:2496432 [1] NCCL INFO Channel 01 : 45[4b000] -> 44[31000] via P2P/IPC/read
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 00 : 89[4b000] -> 88[31000] via P2P/IPC/read
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [send] via NET/IBext/0
431: hkn0728:1323883:1324000 [3] NCCL INFO Connected all trees
431: hkn0728:1323883:1324000 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [receive] via NET/IBext/0
431: hkn0728:1323883:1324000 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 00 : 433[4b000] -> 432[31000] via P2P/IPC/read
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [send] via NET/IBext/0
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [receive] via NET/IBext/0
430: hkn0728:1323891:1323997 [2] NCCL INFO Connected all trees
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [receive] via NET/IBext/0
430: hkn0728:1323891:1323997 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [send] via NET/IBext/0
430: hkn0728:1323891:1323997 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [receive] via NET/IBext/0
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [receive] via NET/IBext/0
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [receive] via NET/IBext/0
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [send] via NET/IBext/0
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [receive] via NET/IBext/0
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [receive] via NET/IBext/0
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [send] via NET/IBext/0
493: hkn0810:939417:939538 [1] NCCL INFO Channel 00 : 493[4b000] -> 492[31000] via P2P/IPC/read
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [receive] via NET/IBext/0
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 00 : 13[4b000] -> 12[31000] via P2P/IPC/read
 89: hkn0427:1135025:1135132 [1] NCCL INFO Channel 01 : 89[4b000] -> 88[31000] via P2P/IPC/read
401: hkn0720:5385:5649 [1] NCCL INFO Channel 00 : 401[4b000] -> 400[31000] via P2P/IPC/read
433: hkn0730:1401614:1401727 [1] NCCL INFO Channel 01 : 433[4b000] -> 432[31000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 00 : 417[4b000] -> 416[31000] via P2P/IPC/read
361: hkn0710:355445:355552 [1] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [send] via NET/IBext/0
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 00 : 461[4b000] -> 460[31000] via P2P/IPC/read
493: hkn0810:939417:939538 [1] NCCL INFO Channel 01 : 493[4b000] -> 492[31000] via P2P/IPC/read
 13: hkn0407:1816167:1816272 [1] NCCL INFO Channel 01 : 13[4b000] -> 12[31000] via P2P/IPC/read
368: hkn0712:294956:295068 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [send] via NET/IBext/0
401: hkn0720:5385:5649 [1] NCCL INFO Channel 01 : 401[4b000] -> 400[31000] via P2P/IPC/read
417: hkn0725:3111825:3111935 [1] NCCL INFO Channel 01 : 417[4b000] -> 416[31000] via P2P/IPC/read
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [receive] via NET/IBext/0
461: hkn0802:1200244:1200347 [1] NCCL INFO Channel 01 : 461[4b000] -> 460[31000] via P2P/IPC/read
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [receive] via NET/IBext/0
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [receive] via NET/IBext/0
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 00 : 161[4b000] -> 160[31000] via P2P/IPC/read
116: hkn0506:837949:838063 [0] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [receive] via NET/IBext/0
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 00 : 225[4b000] -> 224[31000] via P2P/IPC/read
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [receive] via NET/IBext/0
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [receive] via NET/IBext/0
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [send] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [receive] via NET/IBext/0
161: hkn0520:2712765:2712877 [1] NCCL INFO Channel 01 : 161[4b000] -> 160[31000] via P2P/IPC/read
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 00 : 237[4b000] -> 236[31000] via P2P/IPC/read
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [send] via NET/IBext/0
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [send] via NET/IBext/0
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 00 : 333[4b000] -> 332[31000] via P2P/IPC/read
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [send] via NET/IBext/0
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [send] via NET/IBext/0
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 00 : 305[4b000] -> 304[31000] via P2P/IPC/read
360: hkn0710:355429:355558 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [receive] via NET/IBext/0
268: hkn0616:404786:404909 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [receive] via NET/IBext/0
356: hkn0708:413102:413217 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [receive] via NET/IBext/0
225: hkn0603:1413115:1413233 [1] NCCL INFO Channel 01 : 225[4b000] -> 224[31000] via P2P/IPC/read
204: hkn0532:924615:924928 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [receive] via NET/IBext/0
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [receive] via NET/IBext/0
237: hkn0606:2371969:2372080 [1] NCCL INFO Channel 01 : 237[4b000] -> 236[31000] via P2P/IPC/read
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [receive] via NET/IBext/0
333: hkn0636:1654159:1654274 [1] NCCL INFO Channel 01 : 333[4b000] -> 332[31000] via P2P/IPC/read
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 00 : 353[4b000] -> 352[31000] via P2P/IPC/read
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 00 : 33[4b000] -> 32[31000] via P2P/IPC/read
500: hkn0814:675728:675835 [0] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [receive] via NET/IBext/0
305: hkn0629:1591959:1592057 [1] NCCL INFO Channel 01 : 305[4b000] -> 304[31000] via P2P/IPC/read
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 00 : 141[4b000] -> 140[31000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [receive] via NET/IBext/0
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 00 : 29[4b000] -> 28[31000] via P2P/IPC/read
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [receive] via NET/IBext/0
353: hkn0707:4019808:4019912 [1] NCCL INFO Channel 01 : 353[4b000] -> 352[31000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [receive] via NET/IBext/0
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 00 : 65[4b000] -> 64[31000] via P2P/IPC/read
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [send] via NET/IBext/0
 33: hkn0412:2262290:2262395 [1] NCCL INFO Channel 01 : 33[4b000] -> 32[31000] via P2P/IPC/read
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [receive] via NET/IBext/0
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [receive] via NET/IBext/0
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [send] via NET/IBext/0
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 00 : 429[4b000] -> 428[31000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [receive] via NET/IBext/0
464: hkn0803:876465:876561 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [receive] via NET/IBext/0
141: hkn0512:3044053:3044152 [1] NCCL INFO Channel 01 : 141[4b000] -> 140[31000] via P2P/IPC/read
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [receive] via NET/IBext/0
364: hkn0711:583800:583921 [0] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [receive] via NET/IBext/0
 29: hkn0411:2315755:2315870 [1] NCCL INFO Channel 01 : 29[4b000] -> 28[31000] via P2P/IPC/read
244: hkn0608:485608:485739 [0] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [receive] via NET/IBext/0
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [receive] via NET/IBext/0
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 00 : 57[4b000] -> 56[31000] via P2P/IPC/read
205: hkn0532:924607:924924 [1] NCCL INFO Channel 00 : 205[4b000] -> 204[31000] via P2P/IPC/read
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [send] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [receive] via NET/IBext/0
 65: hkn0421:2180584:2180857 [1] NCCL INFO Channel 01 : 65[4b000] -> 64[31000] via P2P/IPC/read
429: hkn0728:1323903:1323996 [1] NCCL INFO Channel 01 : 429[4b000] -> 428[31000] via P2P/IPC/read
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 00 : 121[4b000] -> 120[31000] via P2P/IPC/read
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [receive] via NET/IBext/0
492: hkn0810:939409:939536 [0] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [send] via NET/IBext/0
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [receive] via NET/IBext/0
269: hkn0616:404794:404911 [1] NCCL INFO Channel 00 : 269[4b000] -> 268[31000] via P2P/IPC/read
340: hkn0704:791895:792019 [0] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [receive] via NET/IBext/0
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [send] via NET/IBext/0
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [receive] via NET/IBext/0
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 00 : 185[4b000] -> 184[31000] via P2P/IPC/read
 57: hkn0419:1544215:1544300 [1] NCCL INFO Channel 01 : 57[4b000] -> 56[31000] via P2P/IPC/read
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [receive] via NET/IBext/0
205: hkn0532:924607:924924 [1] NCCL INFO Channel 01 : 205[4b000] -> 204[31000] via P2P/IPC/read
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [receive] via NET/IBext/0
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 00 : 193[4b000] -> 192[31000] via P2P/IPC/read
121: hkn0507:3186962:3187062 [1] NCCL INFO Channel 01 : 121[4b000] -> 120[31000] via P2P/IPC/read
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 00 : 397[4b000] -> 396[31000] via P2P/IPC/read
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [receive] via NET/IBext/0
269: hkn0616:404794:404911 [1] NCCL INFO Channel 01 : 269[4b000] -> 268[31000] via P2P/IPC/read
185: hkn0527:1348822:1348946 [1] NCCL INFO Channel 01 : 185[4b000] -> 184[31000] via P2P/IPC/read
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [receive] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [receive] via NET/IBext/0
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [send] via NET/IBext/0
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [receive] via NET/IBext/0
193: hkn0529:1540700:1540850 [1] NCCL INFO Channel 01 : 193[4b000] -> 192[31000] via P2P/IPC/read
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [receive] via NET/IBext/0
 84: hkn0426:813962:814073 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [send] via NET/IBext/0
300: hkn0628:671767:671903 [0] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [receive] via NET/IBext/0
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [send] via NET/IBext/0
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [send] via NET/IBext/0
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 00 : 25[4b000] -> 24[31000] via P2P/IPC/read
108: hkn0504:40743:40838 [0] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [send] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [receive] via NET/IBext/0
505: hkn0815:395028:395124 [1] NCCL INFO Channel 00 : 505[4b000] -> 504[31000] via P2P/IPC/read
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [receive] via NET/IBext/0
397: hkn0719:1305595:1305722 [1] NCCL INFO Channel 01 : 397[4b000] -> 396[31000] via P2P/IPC/read
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [receive] via NET/IBext/0
 25: hkn0410:1159614:1159709 [1] NCCL INFO Channel 01 : 25[4b000] -> 24[31000] via P2P/IPC/read
505: hkn0815:395028:395124 [1] NCCL INFO Channel 01 : 505[4b000] -> 504[31000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [send] via NET/IBext/0
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 00 : 289[4b000] -> 288[31000] via P2P/IPC/read
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [send] via NET/IBext/0
400: hkn0720:5369:5640 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [receive] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [receive] via NET/IBext/0
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 00 : 473[4b000] -> 472[31000] via P2P/IPC/read
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [receive] via NET/IBext/0
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [send] via NET/IBext/0
249: hkn0609:710716:710825 [1] NCCL INFO Channel 00 : 249[4b000] -> 248[31000] via P2P/IPC/read
289: hkn0624:1772850:1772951 [1] NCCL INFO Channel 01 : 289[4b000] -> 288[31000] via P2P/IPC/read
 80: hkn0425:2083907:2084029 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [receive] via NET/IBext/0
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [receive] via NET/IBext/0
473: hkn0805:1112022:1112123 [1] NCCL INFO Channel 01 : 473[4b000] -> 472[31000] via P2P/IPC/read
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [send] via NET/IBext/0
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [receive] via NET/IBext/0
384: hkn0716:108410:108503 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [receive] via NET/IBext/0
249: hkn0609:710716:710825 [1] NCCL INFO Channel 01 : 249[4b000] -> 248[31000] via P2P/IPC/read
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [receive] via NET/IBext/0
345: hkn0705:783117:783216 [1] NCCL INFO Channel 00 : 345[4b000] -> 344[31000] via P2P/IPC/read
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [send] via NET/IBext/0
345: hkn0705:783117:783216 [1] NCCL INFO Channel 01 : 345[4b000] -> 344[31000] via P2P/IPC/read
348: hkn0706:752164:752267 [0] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [receive] via NET/IBext/0
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [send] via NET/IBext/0
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [receive] via NET/IBext/0
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [receive] via NET/IBext/0
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [receive] via NET/IBext/0
336: hkn0703:740936:741046 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [receive] via NET/IBext/0
217: hkn0601:117600:117712 [1] NCCL INFO Channel 00 : 217[4b000] -> 216[31000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 00 : 129[4b000] -> 128[31000] via P2P/IPC/read
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 00 : 441[4b000] -> 440[31000] via P2P/IPC/read
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [receive] via NET/IBext/0
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [send] via NET/IBext/0
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 00 : 153[4b000] -> 152[31000] via P2P/IPC/read
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [send] via NET/IBext/0
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 00 : 449[4b000] -> 448[31000] via P2P/IPC/read
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 00 : 477[4b000] -> 476[31000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO Channel 01 : 129[4b000] -> 128[31000] via P2P/IPC/read
441: hkn0732:1211535:1211667 [1] NCCL INFO Channel 01 : 441[4b000] -> 440[31000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [send] via NET/IBext/0
217: hkn0601:117600:117712 [1] NCCL INFO Channel 01 : 217[4b000] -> 216[31000] via P2P/IPC/read
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [send] via NET/IBext/0
409: hkn0723:207893:208068 [1] NCCL INFO Channel 00 : 409[4b000] -> 408[31000] via P2P/IPC/read
449: hkn0734:1156453:1156552 [1] NCCL INFO Channel 01 : 449[4b000] -> 448[31000] via P2P/IPC/read
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [receive] via NET/IBext/0
153: hkn0515:2896667:2896795 [1] NCCL INFO Channel 01 : 153[4b000] -> 152[31000] via P2P/IPC/read
477: hkn0806:1054230:1054353 [1] NCCL INFO Channel 01 : 477[4b000] -> 476[31000] via P2P/IPC/read
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 00 : 157[4b000] -> 156[31000] via P2P/IPC/read
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 00 : 281[4b000] -> 280[31000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO Channel 00 : 301[4b000] -> 300[31000] via P2P/IPC/read
 52: hkn0418:1869053:1869172 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [send] via NET/IBext/0
409: hkn0723:207893:208068 [1] NCCL INFO Channel 01 : 409[4b000] -> 408[31000] via P2P/IPC/read
116: hkn0506:837949:838063 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [send] via NET/IBext/0
157: hkn0516:2915847:2915969 [1] NCCL INFO Channel 01 : 157[4b000] -> 156[31000] via P2P/IPC/read
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [receive] via NET/IBext/0
301: hkn0628:671751:671908 [1] NCCL INFO Channel 01 : 301[4b000] -> 300[31000] via P2P/IPC/read
281: hkn0622:2020392:2020504 [1] NCCL INFO Channel 01 : 281[4b000] -> 280[31000] via P2P/IPC/read
180: hkn0526:1428298:1428416 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [send] via NET/IBext/0
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [receive] via NET/IBext/0
492: hkn0810:939409:939536 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [send] via NET/IBext/0
349: hkn0706:752136:752262 [1] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [receive] via NET/IBext/0
 20: hkn0409:2585552:2585695 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [send] via NET/IBext/0
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [receive] via NET/IBext/0
500: hkn0814:675728:675835 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [send] via NET/IBext/0
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 00 : 93[4b000] -> 92[31000] via P2P/IPC/read
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [receive] via NET/IBext/0
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [receive] via NET/IBext/0
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [send] via NET/IBext/0
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [receive] via NET/IBext/0
 93: hkn0428:667227:667353 [1] NCCL INFO Channel 01 : 93[4b000] -> 92[31000] via P2P/IPC/read
 44: hkn0415:2496321:2496433 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [send] via NET/IBext/0
468: hkn0804:1205515:1205623 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [send] via NET/IBext/0
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [send] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [receive] via NET/IBext/0
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [receive] via NET/IBext/0
108: hkn0504:40743:40838 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [send] via NET/IBext/0
464: hkn0803:876465:876561 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [receive] via NET/IBext/0
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 00 : 221[4b000] -> 220[31000] via P2P/IPC/read
364: hkn0711:583800:583921 [0] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [send] via NET/IBext/0
244: hkn0608:485608:485739 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [send] via NET/IBext/0
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [receive] via NET/IBext/0
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [receive] via NET/IBext/0
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [receive] via NET/IBext/0
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [send] via NET/IBext/0
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [send] via NET/IBext/0
340: hkn0704:791895:792019 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [send] via NET/IBext/0
221: hkn0602:3362307:3362555 [1] NCCL INFO Channel 01 : 221[4b000] -> 220[31000] via P2P/IPC/read
408: hkn0723:207901:208066 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [receive] via NET/IBext/0
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [receive] via NET/IBext/0
 81: hkn0425:2083915:2084030 [1] NCCL INFO Connected all trees
 81: hkn0425:2083915:2084030 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2083915:2084030 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [send] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO Connected all trees
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [receive] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2083907:2084029 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
365: hkn0711:583808:583920 [1] NCCL INFO Channel 00 : 365[4b000] -> 364[31000] via P2P/IPC/read
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [send] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [send] via NET/IBext/0
212: hkn0535:2398877:2398992 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [send] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [receive] via NET/IBext/0
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [receive] via NET/IBext/0
 80: hkn0425:2083907:2084029 [0] NCCL INFO comm 0x154d58008fb0 rank 80 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
148: hkn0514:2950603:2950729 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [send] via NET/IBext/0
 81: hkn0425:2083915:2084030 [1] NCCL INFO comm 0x1508d0008fb0 rank 81 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 82: hkn0425:2083927:2084031 [2] NCCL INFO comm 0x14d838008fb0 rank 82 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 83: hkn0425:2083899:2084034 [3] NCCL INFO comm 0x149ffc008fb0 rank 83 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [receive] via NET/IBext/0
300: hkn0628:671767:671903 [0] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [send] via NET/IBext/0
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [receive] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO Channel 01 : 365[4b000] -> 364[31000] via P2P/IPC/read
436: hkn0731:1386645:1386747 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [send] via NET/IBext/0
256: hkn0612:916852:916975 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [receive] via NET/IBext/0
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [receive] via NET/IBext/0
400: hkn0720:5369:5640 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [receive] via NET/IBext/0
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [send] via NET/IBext/0
216: hkn0601:117612:117713 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [receive] via NET/IBext/0
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [receive] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [receive] via NET/IBext/0
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [receive] via NET/IBext/0
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [receive] via NET/IBext/0
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [receive] via NET/IBext/0
276: hkn0621:1991476:1991587 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [send] via NET/IBext/0
404: hkn0721:2299087:2299193 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [send] via NET/IBext/0
144: hkn0513:3012844:3012958 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [receive] via NET/IBext/0
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 00 : 321[4b000] -> 320[31000] via P2P/IPC/read
344: hkn0705:783129:783218 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [receive] via NET/IBext/0
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [send] via NET/IBext/0
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 00 : 313[4b000] -> 312[31000] via P2P/IPC/read
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [receive] via NET/IBext/0
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [receive] via NET/IBext/0
313: hkn0631:1021707:1021834 [1] NCCL INFO Channel 01 : 313[4b000] -> 312[31000] via P2P/IPC/read
321: hkn0633:1526230:1526356 [1] NCCL INFO Channel 01 : 321[4b000] -> 320[31000] via P2P/IPC/read
208: hkn0534:1148264:1148419 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [receive] via NET/IBext/0
384: hkn0716:108410:108503 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [send] via NET/IBext/0
336: hkn0703:740936:741046 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [receive] via NET/IBext/0
 45: hkn0415:2496313:2496432 [1] NCCL INFO Connected all trees
 45: hkn0415:2496313:2496432 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
349: hkn0706:752136:752262 [1] NCCL INFO Channel 00 : 349[4b000] -> 348[31000] via P2P/IPC/read
 45: hkn0415:2496313:2496432 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2262276:2262390 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [receive] via NET/IBext/0
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 00 : 41[4b000] -> 40[31000] via P2P/IPC/read
 44: hkn0415:2496321:2496433 [0] NCCL INFO Connected all trees
 44: hkn0415:2496321:2496433 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:916860:916982 [1] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [send] via NET/IBext/0
 44: hkn0415:2496321:2496433 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:752164:752267 [0] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [send] via NET/IBext/0
349: hkn0706:752136:752262 [1] NCCL INFO Channel 01 : 349[4b000] -> 348[31000] via P2P/IPC/read
 47: hkn0415:2496310:2496438 [3] NCCL INFO comm 0x14fa58008fb0 rank 47 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 41: hkn0414:1981499:1981602 [1] NCCL INFO Channel 01 : 41[4b000] -> 40[31000] via P2P/IPC/read
 44: hkn0415:2496321:2496433 [0] NCCL INFO comm 0x151d84008fb0 rank 44 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 46: hkn0415:2496333:2496437 [2] NCCL INFO comm 0x145d34008fb0 rank 46 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 45: hkn0415:2496313:2496432 [1] NCCL INFO comm 0x14a528008fb0 rank 45 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
492: hkn0810:939409:939536 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [send] via NET/IBext/0
176: hkn0525:986689:986834 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [receive] via NET/IBext/0
385: hkn0716:108390:108502 [1] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [send] via NET/IBext/0
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 00 : 189[4b000] -> 188[31000] via P2P/IPC/read
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [receive] via NET/IBext/0
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 00 : 61[4b000] -> 60[31000] via P2P/IPC/read
372: hkn0713:470112:470238 [0] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [receive] via NET/IBext/0
189: hkn0528:1301571:1301681 [1] NCCL INFO Channel 01 : 189[4b000] -> 188[31000] via P2P/IPC/read
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 00 : 285[4b000] -> 284[31000] via P2P/IPC/read
172: hkn0524:1133679:1133791 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [send] via NET/IBext/0
 61: hkn0420:3210101:3210213 [1] NCCL INFO Channel 01 : 61[4b000] -> 60[31000] via P2P/IPC/read
108: hkn0504:40743:40838 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [send] via NET/IBext/0
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [receive] via NET/IBext/0
160: hkn0520:2712777:2712878 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [receive] via NET/IBext/0
465: hkn0803:876477:876562 [1] NCCL INFO Connected all trees
364: hkn0711:583800:583921 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [send] via NET/IBext/0
285: hkn0623:1872640:1872768 [1] NCCL INFO Channel 01 : 285[4b000] -> 284[31000] via P2P/IPC/read
465: hkn0803:876477:876562 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:876477:876562 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [receive] via NET/IBext/0
464: hkn0803:876465:876561 [0] NCCL INFO Connected all trees
484: hkn0808:970557:970676 [0] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [receive] via NET/IBext/0
464: hkn0803:876465:876561 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
464: hkn0803:876465:876561 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:916852:916975 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [send] via NET/IBext/0
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 00 : 413[4b000] -> 412[31000] via P2P/IPC/read
257: hkn0612:916860:916982 [1] NCCL INFO Channel 00 : 257[4b000] -> 256[31000] via P2P/IPC/read
465: hkn0803:876477:876562 [1] NCCL INFO comm 0x150d58008fb0 rank 465 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
464: hkn0803:876465:876561 [0] NCCL INFO comm 0x14cbc0008fb0 rank 464 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
466: hkn0803:876456:876564 [2] NCCL INFO comm 0x147550008fb0 rank 466 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [receive] via NET/IBext/0
413: hkn0724:1715874:1715982 [1] NCCL INFO Channel 01 : 413[4b000] -> 412[31000] via P2P/IPC/read
257: hkn0612:916860:916982 [1] NCCL INFO Channel 01 : 257[4b000] -> 256[31000] via P2P/IPC/read
467: hkn0803:876457:876566 [3] NCCL INFO comm 0x152b54008fb0 rank 467 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [send] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [send] via NET/IBext/0
385: hkn0716:108390:108502 [1] NCCL INFO Channel 00 : 385[4b000] -> 384[31000] via P2P/IPC/read
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [send] via NET/IBext/0
 40: hkn0414:1981497:1981610 [0] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [send] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [receive] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [receive] via NET/IBext/0
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [receive] via NET/IBext/0
385: hkn0716:108390:108502 [1] NCCL INFO Channel 01 : 385[4b000] -> 384[31000] via P2P/IPC/read
300: hkn0628:671767:671903 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [send] via NET/IBext/0
377: hkn0714:431907:432038 [1] NCCL INFO Channel 00 : 377[4b000] -> 376[31000] via P2P/IPC/read
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [receive] via NET/IBext/0
236: hkn0606:2371977:2372089 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [send] via NET/IBext/0
308: hkn0630:1598339:1598456 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [send] via NET/IBext/0
144: hkn0513:3012844:3012958 [0] NCCL INFO Connected all trees
144: hkn0513:3012844:3012958 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 00 : 317[4b000] -> 316[31000] via P2P/IPC/read
144: hkn0513:3012844:3012958 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [receive] via NET/IBext/0
401: hkn0720:5385:5649 [1] NCCL INFO Connected all trees
401: hkn0720:5385:5649 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [send] via NET/IBext/0
 16: hkn0408:2890655:2890770 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [receive] via NET/IBext/0
377: hkn0714:431907:432038 [1] NCCL INFO Channel 01 : 377[4b000] -> 376[31000] via P2P/IPC/read
401: hkn0720:5385:5649 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:939409:939536 [0] NCCL INFO Connected all trees
492: hkn0810:939409:939536 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
492: hkn0810:939409:939536 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
489: hkn0809:937231:937375 [1] NCCL INFO Channel 00 : 489[4b000] -> 488[31000] via P2P/IPC/read
145: hkn0513:3012872:3012961 [1] NCCL INFO Connected all trees
400: hkn0720:5369:5640 [0] NCCL INFO Connected all trees
145: hkn0513:3012872:3012961 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
400: hkn0720:5369:5640 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
145: hkn0513:3012872:3012961 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:5369:5640 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [send] via NET/IBext/0
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [receive] via NET/IBext/0
317: hkn0632:1758522:1758616 [1] NCCL INFO Channel 01 : 317[4b000] -> 316[31000] via P2P/IPC/read
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [receive] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [send] via NET/IBext/0
493: hkn0810:939417:939538 [1] NCCL INFO Connected all trees
400: hkn0720:5369:5640 [0] NCCL INFO comm 0x1520e8008fb0 rank 400 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
493: hkn0810:939417:939538 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:939417:939538 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:5385:5649 [1] NCCL INFO comm 0x15530c008fb0 rank 401 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
489: hkn0809:937231:937375 [1] NCCL INFO Channel 01 : 489[4b000] -> 488[31000] via P2P/IPC/read
144: hkn0513:3012844:3012958 [0] NCCL INFO comm 0x14f208008fb0 rank 144 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
100: hkn0502:228966:229066 [0] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [receive] via NET/IBext/0
145: hkn0513:3012872:3012961 [1] NCCL INFO comm 0x14edb8008fb0 rank 145 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
337: hkn0703:740940:741049 [1] NCCL INFO Connected all trees
337: hkn0703:740940:741049 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:401772:401896 [0] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [receive] via NET/IBext/0
337: hkn0703:740940:741049 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
208: hkn0534:1148264:1148419 [0] NCCL INFO Connected all trees
403: hkn0720:5377:5646 [3] NCCL INFO comm 0x1506f0008fb0 rank 403 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
492: hkn0810:939409:939536 [0] NCCL INFO comm 0x14d8d8008fb0 rank 492 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
208: hkn0534:1148264:1148419 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:5397:5643 [2] NCCL INFO comm 0x14c574008fb0 rank 402 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
146: hkn0513:3012852:3012957 [2] NCCL INFO comm 0x14563c008fb0 rank 146 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
208: hkn0534:1148264:1148419 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
147: hkn0513:3012860:3012956 [3] NCCL INFO comm 0x154738008fb0 rank 147 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
494: hkn0810:939437:939537 [2] NCCL INFO comm 0x14a868008fb0 rank 494 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [receive] via NET/IBext/0
336: hkn0703:740936:741046 [0] NCCL INFO Connected all trees
495: hkn0810:939425:939541 [3] NCCL INFO comm 0x1510f8008fb0 rank 495 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
336: hkn0703:740936:741046 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
336: hkn0703:740936:741046 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
209: hkn0534:1148292:1148420 [1] NCCL INFO Connected all trees
173: hkn0524:1133699:1133792 [1] NCCL INFO Connected all trees
209: hkn0534:1148292:1148420 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1148292:1148420 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
173: hkn0524:1133699:1133792 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1133699:1133792 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:689133:689241 [0] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [receive] via NET/IBext/0
109: hkn0504:40731:40842 [1] NCCL INFO Connected all trees
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 00 : 169[4b000] -> 168[31000] via P2P/IPC/read
416: hkn0725:3111837:3111934 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [receive] via NET/IBext/0
109: hkn0504:40731:40842 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:939417:939538 [1] NCCL INFO comm 0x145444008fb0 rank 493 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
172: hkn0524:1133679:1133791 [0] NCCL INFO Connected all trees
172: hkn0524:1133679:1133791 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
336: hkn0703:740936:741046 [0] NCCL INFO comm 0x148b40008fb0 rank 336 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
109: hkn0504:40731:40842 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
172: hkn0524:1133679:1133791 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
381: hkn0715:401780:401901 [1] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [receive] via NET/IBext/0
338: hkn0703:740952:741043 [2] NCCL INFO comm 0x147020008fb0 rank 338 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
337: hkn0703:740940:741049 [1] NCCL INFO comm 0x14fe64008fb0 rank 337 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
348: hkn0706:752164:752267 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [send] via NET/IBext/0
211: hkn0534:1148272:1148423 [3] NCCL INFO comm 0x150aa0008fb0 rank 211 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
339: hkn0703:740935:741041 [3] NCCL INFO comm 0x14dc5c008fb0 rank 339 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
108: hkn0504:40743:40838 [0] NCCL INFO Connected all trees
209: hkn0534:1148292:1148420 [1] NCCL INFO comm 0x146098008fb0 rank 209 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
108: hkn0504:40743:40838 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1148264:1148419 [0] NCCL INFO comm 0x14bd84008fb0 rank 208 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
108: hkn0504:40743:40838 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
210: hkn0534:1148280:1148416 [2] NCCL INFO comm 0x153bc4008fb0 rank 210 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [send] via NET/IBext/0
 48: hkn0417:2267551:2267653 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [receive] via NET/IBext/0
172: hkn0524:1133679:1133791 [0] NCCL INFO comm 0x151a3c008fb0 rank 172 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 64: hkn0421:2180612:2180860 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [receive] via NET/IBext/0
173: hkn0524:1133699:1133792 [1] NCCL INFO comm 0x14d568008fb0 rank 173 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
169: hkn0523:1547989:1548085 [1] NCCL INFO Channel 01 : 169[4b000] -> 168[31000] via P2P/IPC/read
108: hkn0504:40743:40838 [0] NCCL INFO comm 0x14fe30008fb0 rank 108 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
175: hkn0524:1133671:1133797 [3] NCCL INFO comm 0x14b2b8008fb0 rank 175 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
109: hkn0504:40731:40842 [1] NCCL INFO comm 0x145c44008fb0 rank 109 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
110: hkn0504:40723:40837 [2] NCCL INFO comm 0x1488c8008fb0 rank 110 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
111: hkn0504:40715:40839 [3] NCCL INFO comm 0x1500b4008fb0 rank 111 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [send] via NET/IBext/0
174: hkn0524:1133687:1133798 [2] NCCL INFO comm 0x14e980008fb0 rank 174 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [receive] via NET/IBext/0
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [receive] via NET/IBext/0
 37: hkn0413:2366588:2366711 [1] NCCL INFO Channel 00 : 37[4b000] -> 36[31000] via P2P/IPC/read
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 00 : 105[4b000] -> 104[31000] via P2P/IPC/read
 41: hkn0414:1981499:1981602 [1] NCCL INFO Connected all trees
 41: hkn0414:1981499:1981602 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 41: hkn0414:1981499:1981602 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:583800:583921 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [send] via NET/IBext/0
 40: hkn0414:1981497:1981610 [0] NCCL INFO Connected all trees
 40: hkn0414:1981497:1981610 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 40: hkn0414:1981497:1981610 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 00 : 445[4b000] -> 444[31000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [send] via NET/IBext/0
105: hkn0503:2899564:2899692 [1] NCCL INFO Channel 01 : 105[4b000] -> 104[31000] via P2P/IPC/read
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [receive] via NET/IBext/0
 37: hkn0413:2366588:2366711 [1] NCCL INFO Channel 01 : 37[4b000] -> 36[31000] via P2P/IPC/read
176: hkn0525:986689:986834 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [receive] via NET/IBext/0
 43: hkn0414:1981498:1981609 [3] NCCL INFO comm 0x14684c008fb0 rank 43 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 40: hkn0414:1981497:1981610 [0] NCCL INFO comm 0x15482c008fb0 rank 40 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 42: hkn0414:1981511:1981611 [2] NCCL INFO comm 0x148474008fb0 rank 42 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
233: hkn0605:712002:712113 [1] NCCL INFO Channel 00 : 233[4b000] -> 232[31000] via P2P/IPC/read
 41: hkn0414:1981499:1981602 [1] NCCL INFO comm 0x153d48008fb0 rank 41 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
237: hkn0606:2371969:2372080 [1] NCCL INFO Connected all trees
237: hkn0606:2371969:2372080 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
237: hkn0606:2371969:2372080 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:667219:667351 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [send] via NET/IBext/0
236: hkn0606:2371977:2372089 [0] NCCL INFO Connected all trees
233: hkn0605:712002:712113 [1] NCCL INFO Channel 01 : 233[4b000] -> 232[31000] via P2P/IPC/read
236: hkn0606:2371977:2372089 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2371977:2372089 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2294566:2294704 [0] NCCL INFO Connected all trees
272: hkn0617:2294566:2294704 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
272: hkn0617:2294566:2294704 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
237: hkn0606:2371969:2372080 [1] NCCL INFO comm 0x148b60008fb0 rank 237 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [receive] via NET/IBext/0
239: hkn0606:2371961:2372083 [3] NCCL INFO comm 0x150920008fb0 rank 239 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
236: hkn0606:2371977:2372089 [0] NCCL INFO comm 0x145d44008fb0 rank 236 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
168: hkn0523:1547961:1548090 [0] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [send] via NET/IBext/0
273: hkn0617:2294577:2294697 [1] NCCL INFO Connected all trees
238: hkn0606:2371989:2372088 [2] NCCL INFO comm 0x14c1c0008fb0 rank 238 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
273: hkn0617:2294577:2294697 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
273: hkn0617:2294577:2294697 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 37: hkn0413:2366588:2366711 [1] NCCL INFO Connected all trees
381: hkn0715:401780:401901 [1] NCCL INFO Channel 00 : 381[4b000] -> 380[31000] via P2P/IPC/read
 37: hkn0413:2366588:2366711 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:671767:671903 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [send] via NET/IBext/0
 37: hkn0413:2366588:2366711 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:413102:413217 [0] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [receive] via NET/IBext/0
272: hkn0617:2294566:2294704 [0] NCCL INFO comm 0x14b5c8008fb0 rank 272 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
256: hkn0612:916852:916975 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [receive] via NET/IBext/0
484: hkn0808:970557:970676 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [send] via NET/IBext/0
273: hkn0617:2294577:2294697 [1] NCCL INFO comm 0x14f658008fb0 rank 273 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 36: hkn0413:2366580:2366708 [0] NCCL INFO Connected all trees
 36: hkn0413:2366580:2366708 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
274: hkn0617:2294558:2294701 [2] NCCL INFO comm 0x1489a8008fb0 rank 274 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 36: hkn0413:2366580:2366708 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
275: hkn0617:2294550:2294702 [3] NCCL INFO comm 0x14840c008fb0 rank 275 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
381: hkn0715:401780:401901 [1] NCCL INFO Channel 01 : 381[4b000] -> 380[31000] via P2P/IPC/read
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [send] via NET/IBext/0
 36: hkn0413:2366580:2366708 [0] NCCL INFO comm 0x153320008fb0 rank 36 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  0: hkn0403:1763942:1764342 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [receive] via NET/IBext/0
 37: hkn0413:2366588:2366711 [1] NCCL INFO comm 0x1543bc008fb0 rank 37 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 38: hkn0413:2366608:2366707 [2] NCCL INFO comm 0x149494008fb0 rank 38 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 39: hkn0413:2366596:2366702 [3] NCCL INFO comm 0x154c88008fb0 rank 39 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [send] via NET/IBext/0
 33: hkn0412:2262290:2262395 [1] NCCL INFO Connected all trees
204: hkn0532:924615:924928 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [send] via NET/IBext/0
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [receive] via NET/IBext/0
 33: hkn0412:2262290:2262395 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 33: hkn0412:2262290:2262395 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [receive] via NET/IBext/0
445: hkn0733:1389278:1389388 [1] NCCL INFO Channel 01 : 445[4b000] -> 444[31000] via P2P/IPC/read
428: hkn0728:1323875:1324003 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [send] via NET/IBext/0
 32: hkn0412:2262276:2262390 [0] NCCL INFO Connected all trees
 32: hkn0412:2262276:2262390 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2262276:2262390 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
372: hkn0713:470112:470238 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [send] via NET/IBext/0
 17: hkn0408:2890667:2890771 [1] NCCL INFO Connected all trees
 17: hkn0408:2890667:2890771 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2890667:2890771 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 16: hkn0408:2890655:2890770 [0] NCCL INFO Connected all trees
220: hkn0602:3362279:3362548 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [send] via NET/IBext/0
 16: hkn0408:2890655:2890770 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2262276:2262390 [0] NCCL INFO comm 0x150ab0008fb0 rank 32 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 16: hkn0408:2890655:2890770 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 34: hkn0412:2262277:2262396 [2] NCCL INFO comm 0x149088008fb0 rank 34 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
164: hkn0521:1197679:1197790 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [send] via NET/IBext/0
 35: hkn0412:2262278:2262387 [3] NCCL INFO comm 0x149848008fb0 rank 35 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
104: hkn0503:2899591:2899697 [0] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [send] via NET/IBext/0
 33: hkn0412:2262290:2262395 [1] NCCL INFO comm 0x1489b0008fb0 rank 33 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [receive] via NET/IBext/0
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [receive] via NET/IBext/0
 17: hkn0408:2890667:2890771 [1] NCCL INFO comm 0x147654008fb0 rank 17 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 18: hkn0408:2890646:2890768 [2] NCCL INFO comm 0x14973c008fb0 rank 18 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 16: hkn0408:2890655:2890770 [0] NCCL INFO comm 0x15513c008fb0 rank 16 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
232: hkn0605:711997:712115 [0] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [send] via NET/IBext/0
 19: hkn0408:2890647:2890769 [3] NCCL INFO comm 0x150cbc008fb0 rank 19 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
288: hkn0624:1772822:1772950 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [receive] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO Connected all trees
348: hkn0706:752164:752267 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [send] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:709722:709820 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [receive] via NET/IBext/0
365: hkn0711:583808:583920 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:970565:970682 [1] NCCL INFO Channel 00 : 485[4b000] -> 484[31000] via P2P/IPC/read
 49: hkn0417:2267523:2267656 [1] NCCL INFO Connected all trees
 49: hkn0417:2267523:2267656 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [send] via NET/IBext/0
432: hkn0730:1401606:1401733 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [receive] via NET/IBext/0
 49: hkn0417:2267523:2267656 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:709702:709825 [1] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [receive] via NET/IBext/0
364: hkn0711:583800:583921 [0] NCCL INFO Connected all trees
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [receive] via NET/IBext/0
364: hkn0711:583800:583921 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
364: hkn0711:583800:583921 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
489: hkn0809:937231:937375 [1] NCCL INFO Connected all trees
 48: hkn0417:2267551:2267653 [0] NCCL INFO Connected all trees
489: hkn0809:937231:937375 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 48: hkn0417:2267551:2267653 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
489: hkn0809:937231:937375 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2267551:2267653 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:355445:355552 [1] NCCL INFO Channel 00 : 361[4b000] -> 360[31000] via P2P/IPC/read
485: hkn0808:970565:970682 [1] NCCL INFO Channel 01 : 485[4b000] -> 484[31000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO Connected all trees
364: hkn0711:583800:583921 [0] NCCL INFO comm 0x14cc2c008fb0 rank 364 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
488: hkn0809:937239:937379 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:937239:937379 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
367: hkn0711:583792:583925 [3] NCCL INFO comm 0x14d5bc008fb0 rank 367 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
365: hkn0711:583808:583920 [1] NCCL INFO comm 0x148070008fb0 rank 365 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
366: hkn0711:583820:583927 [2] NCCL INFO comm 0x1477a0008fb0 rank 366 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 49: hkn0417:2267523:2267656 [1] NCCL INFO comm 0x1493e4008fb0 rank 49 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 96: hkn0501:1327777:1327903 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [receive] via NET/IBext/0
 48: hkn0417:2267551:2267653 [0] NCCL INFO comm 0x149ce0008fb0 rank 48 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 93: hkn0428:667227:667353 [1] NCCL INFO Connected all trees
 51: hkn0417:2267539:2267651 [3] NCCL INFO comm 0x1519c8008fb0 rank 51 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [send] via NET/IBext/0
 93: hkn0428:667227:667353 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 50: hkn0417:2267531:2267655 [2] NCCL INFO comm 0x14cc8c008fb0 rank 50 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 93: hkn0428:667227:667353 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
489: hkn0809:937231:937375 [1] NCCL INFO comm 0x14c908008fb0 rank 489 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
491: hkn0809:937251:937374 [3] NCCL INFO comm 0x14565c008fb0 rank 491 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
490: hkn0809:937230:937376 [2] NCCL INFO comm 0x14cf90008fb0 rank 490 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
361: hkn0710:355445:355552 [1] NCCL INFO Channel 01 : 361[4b000] -> 360[31000] via P2P/IPC/read
488: hkn0809:937239:937379 [0] NCCL INFO comm 0x14a730008fb0 rank 488 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 92: hkn0428:667219:667351 [0] NCCL INFO Connected all trees
 92: hkn0428:667219:667351 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:401772:401896 [0] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [send] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 00 : 125[4b000] -> 124[31000] via P2P/IPC/read
228: hkn0604:689133:689241 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [send] via NET/IBext/0
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [send] via NET/IBext/0
 92: hkn0428:667219:667351 [0] NCCL INFO comm 0x14de74008fb0 rank 92 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [receive] via NET/IBext/0
 94: hkn0428:667247:667347 [2] NCCL INFO comm 0x1512f8008fb0 rank 94 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
169: hkn0523:1547989:1548085 [1] NCCL INFO Connected all trees
 95: hkn0428:667235:667348 [3] NCCL INFO comm 0x14a570008fb0 rank 95 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
169: hkn0523:1547989:1548085 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 93: hkn0428:667227:667353 [1] NCCL INFO comm 0x153d34008fb0 rank 93 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
169: hkn0523:1547989:1548085 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
165: hkn0521:1197671:1197795 [1] NCCL INFO Channel 00 : 165[4b000] -> 164[31000] via P2P/IPC/read
125: hkn0508:3139009:3139136 [1] NCCL INFO Channel 01 : 125[4b000] -> 124[31000] via P2P/IPC/read
168: hkn0523:1547961:1548090 [0] NCCL INFO Connected all trees
168: hkn0523:1547961:1548090 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
168: hkn0523:1547961:1548090 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 00 : 297[4b000] -> 296[31000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO Connected all trees
301: hkn0628:671751:671908 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
301: hkn0628:671751:671908 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
177: hkn0525:986697:986833 [1] NCCL INFO Connected all trees
171: hkn0523:1547977:1548089 [3] NCCL INFO comm 0x14c688008fb0 rank 171 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
177: hkn0525:986697:986833 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:986697:986833 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1547961:1548090 [0] NCCL INFO comm 0x150770008fb0 rank 168 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
169: hkn0523:1547989:1548085 [1] NCCL INFO comm 0x14d3f8008fb0 rank 169 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
300: hkn0628:671767:671903 [0] NCCL INFO Connected all trees
170: hkn0523:1547969:1548086 [2] NCCL INFO comm 0x1495bc008fb0 rank 170 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
300: hkn0628:671767:671903 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:671767:671903 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
176: hkn0525:986689:986834 [0] NCCL INFO Connected all trees
176: hkn0525:986689:986834 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:986689:986834 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
297: hkn0627:1787808:1787920 [1] NCCL INFO Channel 01 : 297[4b000] -> 296[31000] via P2P/IPC/read
165: hkn0521:1197671:1197795 [1] NCCL INFO Channel 01 : 165[4b000] -> 164[31000] via P2P/IPC/read
301: hkn0628:671751:671908 [1] NCCL INFO comm 0x153600008fb0 rank 301 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
300: hkn0628:671767:671903 [0] NCCL INFO comm 0x145fd4008fb0 rank 300 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
302: hkn0628:671759:671904 [2] NCCL INFO comm 0x145dc0008fb0 rank 302 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
177: hkn0525:986697:986833 [1] NCCL INFO comm 0x1536a4008fb0 rank 177 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
303: hkn0628:671779:671905 [3] NCCL INFO comm 0x14dfb8008fb0 rank 303 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 00 : 425[4b000] -> 424[31000] via P2P/IPC/read
176: hkn0525:986689:986834 [0] NCCL INFO comm 0x145ab4008fb0 rank 176 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
429: hkn0728:1323903:1323996 [1] NCCL INFO Connected all trees
128: hkn0509:3124288:3124402 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [receive] via NET/IBext/0
429: hkn0728:1323903:1323996 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:228966:229066 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [send] via NET/IBext/0
429: hkn0728:1323903:1323996 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1323875:1324003 [0] NCCL INFO Connected all trees
179: hkn0525:986681:986840 [3] NCCL INFO comm 0x14ae1c008fb0 rank 179 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
428: hkn0728:1323875:1324003 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
428: hkn0728:1323875:1324003 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
178: hkn0525:986708:986837 [2] NCCL INFO comm 0x154abc008fb0 rank 178 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
425: hkn0727:1345672:1345787 [1] NCCL INFO Channel 01 : 425[4b000] -> 424[31000] via P2P/IPC/read
360: hkn0710:355429:355558 [0] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [send] via NET/IBext/0
101: hkn0502:228954:229059 [1] NCCL INFO Channel 00 : 101[4b000] -> 100[31000] via P2P/IPC/read
430: hkn0728:1323891:1323997 [2] NCCL INFO comm 0x14f1ac008fb0 rank 430 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
428: hkn0728:1323875:1324003 [0] NCCL INFO comm 0x151158008fb0 rank 428 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
429: hkn0728:1323903:1323996 [1] NCCL INFO comm 0x14c060008fb0 rank 429 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
431: hkn0728:1323883:1324000 [3] NCCL INFO comm 0x1480b4008fb0 rank 431 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
229: hkn0604:689145:689242 [1] NCCL INFO Channel 00 : 229[4b000] -> 228[31000] via P2P/IPC/read
320: hkn0633:1526202:1526350 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [receive] via NET/IBext/0
384: hkn0716:108410:108503 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [receive] via NET/IBext/0
101: hkn0502:228954:229059 [1] NCCL INFO Channel 01 : 101[4b000] -> 100[31000] via P2P/IPC/read
349: hkn0706:752136:752262 [1] NCCL INFO Connected all trees
165: hkn0521:1197671:1197795 [1] NCCL INFO Connected all trees
349: hkn0706:752136:752262 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
476: hkn0806:1054250:1054352 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [send] via NET/IBext/0
221: hkn0602:3362307:3362555 [1] NCCL INFO Connected all trees
349: hkn0706:752136:752262 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
165: hkn0521:1197671:1197795 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
221: hkn0602:3362307:3362555 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
165: hkn0521:1197671:1197795 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
233: hkn0605:712002:712113 [1] NCCL INFO Connected all trees
221: hkn0602:3362307:3362555 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2899564:2899692 [1] NCCL INFO Connected all trees
105: hkn0503:2899564:2899692 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:752164:752267 [0] NCCL INFO Connected all trees
105: hkn0503:2899564:2899692 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
233: hkn0605:712002:712113 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:752164:752267 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
229: hkn0604:689145:689242 [1] NCCL INFO Channel 01 : 229[4b000] -> 228[31000] via P2P/IPC/read
164: hkn0521:1197679:1197790 [0] NCCL INFO Connected all trees
233: hkn0605:712002:712113 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:752164:752267 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:709722:709820 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [send] via NET/IBext/0
220: hkn0602:3362279:3362548 [0] NCCL INFO Connected all trees
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [receive] via NET/IBext/0
164: hkn0521:1197679:1197790 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
164: hkn0521:1197679:1197790 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:711997:712115 [0] NCCL INFO Connected all trees
220: hkn0602:3362279:3362548 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
204: hkn0532:924615:924928 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [send] via NET/IBext/0
220: hkn0602:3362279:3362548 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
104: hkn0503:2899591:2899697 [0] NCCL INFO Connected all trees
104: hkn0503:2899591:2899697 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 76: hkn0424:2947881:2947969 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [send] via NET/IBext/0
104: hkn0503:2899591:2899697 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:711997:712115 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
232: hkn0605:711997:712115 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 88: hkn0427:1135037:1135137 [0] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [send] via NET/IBext/0
350: hkn0706:752144:752268 [2] NCCL INFO comm 0x14fbcc008fb0 rank 350 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
351: hkn0706:752152:752261 [3] NCCL INFO comm 0x14dbe8008fb0 rank 351 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
166: hkn0521:1197663:1197794 [2] NCCL INFO comm 0x145504008fb0 rank 166 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
348: hkn0706:752164:752267 [0] NCCL INFO comm 0x149b4c008fb0 rank 348 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
165: hkn0521:1197671:1197795 [1] NCCL INFO comm 0x14a1c8008fb0 rank 165 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
164: hkn0521:1197679:1197790 [0] NCCL INFO comm 0x150044008fb0 rank 164 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
235: hkn0605:712014:712118 [3] NCCL INFO comm 0x14e228008fb0 rank 235 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
167: hkn0521:1197691:1197791 [3] NCCL INFO comm 0x147890008fb0 rank 167 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
349: hkn0706:752136:752262 [1] NCCL INFO comm 0x148484008fb0 rank 349 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
232: hkn0605:711997:712115 [0] NCCL INFO comm 0x1539f4008fb0 rank 232 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
221: hkn0602:3362307:3362555 [1] NCCL INFO comm 0x14cbd4008fb0 rank 221 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
233: hkn0605:712002:712113 [1] NCCL INFO comm 0x148638008fb0 rank 233 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
222: hkn0602:3362295:3362554 [2] NCCL INFO comm 0x151d28008fb0 rank 222 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [receive] via NET/IBext/0
107: hkn0503:2899572:2899698 [3] NCCL INFO comm 0x147f98008fb0 rank 107 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
234: hkn0605:711998:712112 [2] NCCL INFO comm 0x14c59c008fb0 rank 234 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
220: hkn0602:3362279:3362548 [0] NCCL INFO comm 0x14e660008fb0 rank 220 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
105: hkn0503:2899564:2899692 [1] NCCL INFO comm 0x149b90008fb0 rank 105 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
223: hkn0602:3362287:3362549 [3] NCCL INFO comm 0x14d4e0008fb0 rank 223 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
161: hkn0520:2712765:2712877 [1] NCCL INFO Connected all trees
104: hkn0503:2899591:2899697 [0] NCCL INFO comm 0x148efc008fb0 rank 104 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
253: hkn0611:709702:709825 [1] NCCL INFO Channel 00 : 253[4b000] -> 252[31000] via P2P/IPC/read
161: hkn0520:2712765:2712877 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2712765:2712877 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:916852:916975 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [receive] via NET/IBext/0
160: hkn0520:2712777:2712878 [0] NCCL INFO Connected all trees
160: hkn0520:2712777:2712878 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
160: hkn0520:2712777:2712878 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:413102:413217 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [send] via NET/IBext/0
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [receive] via NET/IBext/0
253: hkn0611:709702:709825 [1] NCCL INFO Channel 01 : 253[4b000] -> 252[31000] via P2P/IPC/read
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [send] via NET/IBext/0
161: hkn0520:2712765:2712877 [1] NCCL INFO comm 0x148030008fb0 rank 161 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
106: hkn0503:2899580:2899695 [2] NCCL INFO comm 0x147ba4008fb0 rank 106 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
160: hkn0520:2712777:2712878 [0] NCCL INFO comm 0x14b930008fb0 rank 160 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
444: hkn0733:1389270:1389389 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [send] via NET/IBext/0
433: hkn0730:1401614:1401727 [1] NCCL INFO Connected all trees
163: hkn0520:2712757:2712880 [3] NCCL INFO comm 0x151f54008fb0 rank 163 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
162: hkn0520:2712749:2712876 [2] NCCL INFO comm 0x151b38008fb0 rank 162 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
433: hkn0730:1401614:1401727 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
433: hkn0730:1401614:1401727 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
432: hkn0730:1401606:1401733 [0] NCCL INFO Connected all trees
432: hkn0730:1401606:1401733 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1401606:1401733 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [receive] via NET/IBext/0
432: hkn0730:1401606:1401733 [0] NCCL INFO comm 0x148e74008fb0 rank 432 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
433: hkn0730:1401614:1401727 [1] NCCL INFO comm 0x149128008fb0 rank 433 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
216: hkn0601:117612:117713 [0] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [send] via NET/IBext/0
304: hkn0629:1591939:1592054 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [receive] via NET/IBext/0
188: hkn0528:1301555:1301679 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [send] via NET/IBext/0
435: hkn0730:1401622:1401732 [3] NCCL INFO comm 0x146d74008fb0 rank 435 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
434: hkn0730:1401634:1401726 [2] NCCL INFO comm 0x14da08008fb0 rank 434 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
112: hkn0505:2303664:2303782 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [receive] via NET/IBext/0
380: hkn0715:401772:401896 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [send] via NET/IBext/0
357: hkn0708:413110:413222 [1] NCCL INFO Channel 00 : 357[4b000] -> 356[31000] via P2P/IPC/read
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [receive] via NET/IBext/0
332: hkn0636:1654151:1654265 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [send] via NET/IBext/0
292: hkn0626:1298337:1298454 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [send] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [send] via NET/IBext/0
361: hkn0710:355445:355552 [1] NCCL INFO Connected all trees
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [receive] via NET/IBext/0
344: hkn0705:783129:783218 [0] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [send] via NET/IBext/0
361: hkn0710:355445:355552 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
361: hkn0710:355445:355552 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:413110:413222 [1] NCCL INFO Channel 01 : 357[4b000] -> 356[31000] via P2P/IPC/read
420: hkn0726:1548019:1548119 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [send] via NET/IBext/0
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [send] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO Connected all trees
101: hkn0502:228954:229059 [1] NCCL INFO Connected all trees
101: hkn0502:228954:229059 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:228954:229059 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:355429:355558 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:355429:355558 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1054230:1054353 [1] NCCL INFO Connected all trees
477: hkn0806:1054230:1054353 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1054230:1054353 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
424: hkn0727:1345692:1345788 [0] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [send] via NET/IBext/0
100: hkn0502:228966:229066 [0] NCCL INFO Connected all trees
476: hkn0806:1054250:1054352 [0] NCCL INFO Connected all trees
361: hkn0710:355445:355552 [1] NCCL INFO comm 0x14cb8c008fb0 rank 361 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
100: hkn0502:228966:229066 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
476: hkn0806:1054250:1054352 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:228966:229066 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1054250:1054352 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
362: hkn0710:355457:355550 [2] NCCL INFO comm 0x14e5bc008fb0 rank 362 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [send] via NET/IBext/0
360: hkn0710:355429:355558 [0] NCCL INFO comm 0x153944008fb0 rank 360 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
363: hkn0710:355437:355557 [3] NCCL INFO comm 0x14f4dc008fb0 rank 363 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 85: hkn0426:813954:814076 [1] NCCL INFO Channel 00 : 85[4b000] -> 84[31000] via P2P/IPC/read
478: hkn0806:1054238:1054345 [2] NCCL INFO comm 0x14c1d8008fb0 rank 478 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
205: hkn0532:924607:924924 [1] NCCL INFO Connected all trees
 77: hkn0424:2947854:2947962 [1] NCCL INFO Connected all trees
205: hkn0532:924607:924924 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 96: hkn0501:1327777:1327903 [0] NCCL INFO Connected all trees
 77: hkn0424:2947854:2947962 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
476: hkn0806:1054250:1054352 [0] NCCL INFO comm 0x152ca8008fb0 rank 476 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
205: hkn0532:924607:924924 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
101: hkn0502:228954:229059 [1] NCCL INFO comm 0x155290008fb0 rank 101 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 77: hkn0424:2947854:2947962 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 88: hkn0427:1135037:1135137 [0] NCCL INFO Connected all trees
 96: hkn0501:1327777:1327903 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
479: hkn0806:1054222:1054347 [3] NCCL INFO comm 0x153bc8008fb0 rank 479 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
100: hkn0502:228966:229066 [0] NCCL INFO comm 0x14565c008fb0 rank 100 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 96: hkn0501:1327777:1327903 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 88: hkn0427:1135037:1135137 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1054230:1054353 [1] NCCL INFO comm 0x14bad4008fb0 rank 477 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 88: hkn0427:1135037:1135137 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
103: hkn0502:228946:229060 [3] NCCL INFO comm 0x14f694008fb0 rank 103 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
102: hkn0502:228938:229065 [2] NCCL INFO comm 0x148a74008fb0 rank 102 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
204: hkn0532:924615:924928 [0] NCCL INFO Connected all trees
192: hkn0529:1540728:1540857 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [receive] via NET/IBext/0
 76: hkn0424:2947881:2947969 [0] NCCL INFO Connected all trees
204: hkn0532:924615:924928 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:813954:814076 [1] NCCL INFO Channel 01 : 85[4b000] -> 84[31000] via P2P/IPC/read
204: hkn0532:924615:924928 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2947881:2947969 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 76: hkn0424:2947881:2947969 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 00 : 73[4b000] -> 72[31000] via P2P/IPC/read
 89: hkn0427:1135025:1135132 [1] NCCL INFO Connected all trees
 89: hkn0427:1135025:1135132 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 89: hkn0427:1135025:1135132 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
206: hkn0532:924599:924925 [2] NCCL INFO comm 0x150454008fb0 rank 206 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 97: hkn0501:1327797:1327897 [1] NCCL INFO Connected all trees
 77: hkn0424:2947854:2947962 [1] NCCL INFO comm 0x14f4e4008fb0 rank 77 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [receive] via NET/IBext/0
205: hkn0532:924607:924924 [1] NCCL INFO comm 0x1479e8008fb0 rank 205 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
204: hkn0532:924615:924928 [0] NCCL INFO comm 0x1549e8008fb0 rank 204 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 97: hkn0501:1327797:1327897 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 97: hkn0501:1327797:1327897 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 78: hkn0424:2947862:2947966 [2] NCCL INFO comm 0x1475f8008fb0 rank 78 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 88: hkn0427:1135037:1135137 [0] NCCL INFO comm 0x14c6cc008fb0 rank 88 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 79: hkn0424:2947870:2947971 [3] NCCL INFO comm 0x147cc0008fb0 rank 79 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 76: hkn0424:2947881:2947969 [0] NCCL INFO comm 0x153f0c008fb0 rank 76 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 91: hkn0427:1135017:1135131 [3] NCCL INFO comm 0x149ac0008fb0 rank 91 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
207: hkn0532:924627:924923 [3] NCCL INFO comm 0x14d1dc008fb0 rank 207 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 73: hkn0423:1704793:1704926 [1] NCCL INFO Channel 01 : 73[4b000] -> 72[31000] via P2P/IPC/read
 90: hkn0427:1135009:1135135 [2] NCCL INFO comm 0x148cd4008fb0 rank 90 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 89: hkn0427:1135025:1135132 [1] NCCL INFO comm 0x147348008fb0 rank 89 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 00 : 201[4b000] -> 200[31000] via P2P/IPC/read
 96: hkn0501:1327777:1327903 [0] NCCL INFO comm 0x150918008fb0 rank 96 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 97: hkn0501:1327797:1327897 [1] NCCL INFO comm 0x151360008fb0 rank 97 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 98: hkn0501:1327785:1327898 [2] NCCL INFO comm 0x14e7cc008fb0 rank 98 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 99: hkn0501:1327769:1327904 [3] NCCL INFO comm 0x1463e4008fb0 rank 99 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [receive] via NET/IBext/0
445: hkn0733:1389278:1389388 [1] NCCL INFO Connected all trees
445: hkn0733:1389278:1389388 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
445: hkn0733:1389278:1389388 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1389270:1389389 [0] NCCL INFO Connected all trees
201: hkn0531:1230529:1230638 [1] NCCL INFO Channel 01 : 201[4b000] -> 200[31000] via P2P/IPC/read
444: hkn0733:1389270:1389389 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1389270:1389389 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 85: hkn0426:813954:814076 [1] NCCL INFO Connected all trees
 85: hkn0426:813954:814076 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:813954:814076 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:294956:295068 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [receive] via NET/IBext/0
444: hkn0733:1389270:1389389 [0] NCCL INFO comm 0x1483a0008fb0 rank 444 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 84: hkn0426:813962:814073 [0] NCCL INFO Connected all trees
213: hkn0535:2398861:2398990 [1] NCCL INFO Channel 00 : 213[4b000] -> 212[31000] via P2P/IPC/read
445: hkn0733:1389278:1389388 [1] NCCL INFO comm 0x149590008fb0 rank 445 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
216: hkn0601:117612:117713 [0] NCCL INFO Connected all trees
 84: hkn0426:813962:814073 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
446: hkn0733:1389290:1389387 [2] NCCL INFO comm 0x14a808008fb0 rank 446 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 84: hkn0426:813962:814073 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
447: hkn0733:1389269:1389383 [3] NCCL INFO comm 0x14b420008fb0 rank 447 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
216: hkn0601:117612:117713 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
216: hkn0601:117612:117713 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1301555:1301679 [0] NCCL INFO Connected all trees
188: hkn0528:1301555:1301679 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
188: hkn0528:1301555:1301679 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 84: hkn0426:813962:814073 [0] NCCL INFO comm 0x153c60008fb0 rank 84 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
217: hkn0601:117600:117712 [1] NCCL INFO Connected all trees
 87: hkn0426:813974:814075 [3] NCCL INFO comm 0x1515c0008fb0 rank 87 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 85: hkn0426:813954:814076 [1] NCCL INFO comm 0x153e24008fb0 rank 85 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
217: hkn0601:117600:117712 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 86: hkn0426:813946:814074 [2] NCCL INFO comm 0x14cc7c008fb0 rank 86 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
217: hkn0601:117600:117712 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1301571:1301681 [1] NCCL INFO Connected all trees
213: hkn0535:2398861:2398990 [1] NCCL INFO Channel 01 : 213[4b000] -> 212[31000] via P2P/IPC/read
189: hkn0528:1301571:1301681 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
189: hkn0528:1301571:1301681 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:108410:108503 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [receive] via NET/IBext/0
333: hkn0636:1654159:1654274 [1] NCCL INFO Connected all trees
341: hkn0704:791903:792016 [1] NCCL INFO Channel 00 : 341[4b000] -> 340[31000] via P2P/IPC/read
333: hkn0636:1654159:1654274 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
333: hkn0636:1654159:1654274 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
191: hkn0528:1301563:1301675 [3] NCCL INFO comm 0x145430008fb0 rank 191 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
216: hkn0601:117612:117713 [0] NCCL INFO comm 0x14d1dc008fb0 rank 216 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
188: hkn0528:1301555:1301679 [0] NCCL INFO comm 0x14de70008fb0 rank 188 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
190: hkn0528:1301582:1301674 [2] NCCL INFO comm 0x15150c008fb0 rank 190 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
332: hkn0636:1654151:1654265 [0] NCCL INFO Connected all trees
218: hkn0601:117591:117714 [2] NCCL INFO comm 0x1474dc008fb0 rank 218 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
460: hkn0802:1200224:1200344 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [send] via NET/IBext/0
189: hkn0528:1301571:1301681 [1] NCCL INFO comm 0x14ad74008fb0 rank 189 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
332: hkn0636:1654151:1654265 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
217: hkn0601:117600:117712 [1] NCCL INFO comm 0x14b33c008fb0 rank 217 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
332: hkn0636:1654151:1654265 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
219: hkn0601:117592:117705 [3] NCCL INFO comm 0x14a758008fb0 rank 219 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
345: hkn0705:783117:783216 [1] NCCL INFO Connected all trees
345: hkn0705:783117:783216 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
345: hkn0705:783117:783216 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1111994:1112121 [0] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [send] via NET/IBext/0
341: hkn0704:791903:792016 [1] NCCL INFO Channel 01 : 341[4b000] -> 340[31000] via P2P/IPC/read
421: hkn0726:1547991:1548116 [1] NCCL INFO Channel 00 : 421[4b000] -> 420[31000] via P2P/IPC/read
332: hkn0636:1654151:1654265 [0] NCCL INFO comm 0x14c4d4008fb0 rank 332 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
200: hkn0531:1230521:1230636 [0] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [send] via NET/IBext/0
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 00 : 329[4b000] -> 328[31000] via P2P/IPC/read
252: hkn0611:709722:709820 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [send] via NET/IBext/0
344: hkn0705:783129:783218 [0] NCCL INFO Connected all trees
335: hkn0636:1654171:1654272 [3] NCCL INFO comm 0x146730008fb0 rank 335 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
333: hkn0636:1654159:1654274 [1] NCCL INFO comm 0x14c858008fb0 rank 333 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
344: hkn0705:783129:783218 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
334: hkn0636:1654143:1654268 [2] NCCL INFO comm 0x14fdd8008fb0 rank 334 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
344: hkn0705:783129:783218 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1298357:1298456 [1] NCCL INFO Channel 00 : 293[4b000] -> 292[31000] via P2P/IPC/read
344: hkn0705:783129:783218 [0] NCCL INFO comm 0x147084008fb0 rank 344 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
421: hkn0726:1547991:1548116 [1] NCCL INFO Channel 01 : 421[4b000] -> 420[31000] via P2P/IPC/read
345: hkn0705:783117:783216 [1] NCCL INFO comm 0x14f890008fb0 rank 345 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
329: hkn0635:1225473:1225593 [1] NCCL INFO Channel 01 : 329[4b000] -> 328[31000] via P2P/IPC/read
212: hkn0535:2398877:2398992 [0] NCCL INFO Connected all trees
346: hkn0705:783101:783217 [2] NCCL INFO comm 0x14bb08008fb0 rank 346 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
212: hkn0535:2398877:2398992 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
212: hkn0535:2398877:2398992 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
347: hkn0705:783109:783209 [3] NCCL INFO comm 0x14fea8008fb0 rank 347 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
297: hkn0627:1787808:1787920 [1] NCCL INFO Connected all trees
304: hkn0629:1591939:1592054 [0] NCCL INFO Connected all trees
 72: hkn0423:1704801:1704925 [0] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [send] via NET/IBext/0
297: hkn0627:1787808:1787920 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
297: hkn0627:1787808:1787920 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
304: hkn0629:1591939:1592054 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
304: hkn0629:1591939:1592054 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
508: hkn0816:375484:375639 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [send] via NET/IBext/0
213: hkn0535:2398861:2398990 [1] NCCL INFO Connected all trees
213: hkn0535:2398861:2398990 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
213: hkn0535:2398861:2398990 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
113: hkn0505:2303684:2303783 [1] NCCL INFO Connected all trees
113: hkn0505:2303684:2303783 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:401772:401896 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [send] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO Connected all trees
293: hkn0626:1298357:1298456 [1] NCCL INFO Channel 01 : 293[4b000] -> 292[31000] via P2P/IPC/read
113: hkn0505:2303684:2303783 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
296: hkn0627:1787824:1787924 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
305: hkn0629:1591959:1592057 [1] NCCL INFO Connected all trees
296: hkn0627:1787824:1787924 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1591959:1592057 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
305: hkn0629:1591959:1592057 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1772822:1772950 [0] NCCL INFO Connected all trees
425: hkn0727:1345672:1345787 [1] NCCL INFO Connected all trees
288: hkn0624:1772822:1772950 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2303664:2303782 [0] NCCL INFO Connected all trees
340: hkn0704:791895:792019 [0] NCCL INFO Connected all trees
288: hkn0624:1772822:1772950 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
112: hkn0505:2303664:2303782 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2303664:2303782 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:791895:792019 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
425: hkn0727:1345672:1345787 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:791895:792019 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
213: hkn0535:2398861:2398990 [1] NCCL INFO comm 0x153130008fb0 rank 213 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
425: hkn0727:1345672:1345787 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
416: hkn0725:3111837:3111934 [0] NCCL INFO Connected all trees
214: hkn0535:2398869:2398986 [2] NCCL INFO comm 0x15158c008fb0 rank 214 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
416: hkn0725:3111837:3111934 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
215: hkn0535:2398889:2398985 [3] NCCL INFO comm 0x1466c0008fb0 rank 215 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
416: hkn0725:3111837:3111934 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
212: hkn0535:2398877:2398992 [0] NCCL INFO comm 0x14f488008fb0 rank 212 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
289: hkn0624:1772850:1772951 [1] NCCL INFO Connected all trees
424: hkn0727:1345692:1345788 [0] NCCL INFO Connected all trees
289: hkn0624:1772850:1772951 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
297: hkn0627:1787808:1787920 [1] NCCL INFO comm 0x14fe30008fb0 rank 297 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
341: hkn0704:791903:792016 [1] NCCL INFO Connected all trees
289: hkn0624:1772850:1772951 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1211563:1211665 [0] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [send] via NET/IBext/0
424: hkn0727:1345692:1345788 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
299: hkn0627:1787816:1787921 [3] NCCL INFO comm 0x14daa0008fb0 rank 299 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
424: hkn0727:1345692:1345788 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:791903:792016 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
341: hkn0704:791903:792016 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
114: hkn0505:2303656:2303781 [2] NCCL INFO comm 0x14b028008fb0 rank 114 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
304: hkn0629:1591939:1592054 [0] NCCL INFO comm 0x152794008fb0 rank 304 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
412: hkn0724:1715866:1715984 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [send] via NET/IBext/0
296: hkn0627:1787824:1787924 [0] NCCL INFO comm 0x14a360008fb0 rank 296 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
305: hkn0629:1591959:1592057 [1] NCCL INFO comm 0x150f9c008fb0 rank 305 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
298: hkn0627:1787836:1787925 [2] NCCL INFO comm 0x14c52c008fb0 rank 298 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
112: hkn0505:2303664:2303782 [0] NCCL INFO comm 0x151b0c008fb0 rank 112 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
417: hkn0725:3111825:3111935 [1] NCCL INFO Connected all trees
420: hkn0726:1548019:1548119 [0] NCCL INFO Connected all trees
113: hkn0505:2303684:2303783 [1] NCCL INFO comm 0x145b70008fb0 rank 113 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
306: hkn0629:1591947:1592059 [2] NCCL INFO comm 0x150a28008fb0 rank 306 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
417: hkn0725:3111825:3111935 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
240: hkn0607:904254:904366 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [receive] via NET/IBext/0
115: hkn0505:2303672:2303774 [3] NCCL INFO comm 0x149ee8008fb0 rank 115 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
417: hkn0725:3111825:3111935 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
291: hkn0624:1772830:1772945 [3] NCCL INFO comm 0x145d20008fb0 rank 291 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
420: hkn0726:1548019:1548119 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
307: hkn0629:1591931:1592055 [3] NCCL INFO comm 0x145bf0008fb0 rank 307 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
420: hkn0726:1548019:1548119 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:791903:792016 [1] NCCL INFO comm 0x1503e4008fb0 rank 341 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
290: hkn0624:1772838:1772944 [2] NCCL INFO comm 0x145e58008fb0 rank 290 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
288: hkn0624:1772822:1772950 [0] NCCL INFO comm 0x150f38008fb0 rank 288 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
425: hkn0727:1345672:1345787 [1] NCCL INFO comm 0x148aa8008fb0 rank 425 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
340: hkn0704:791895:792019 [0] NCCL INFO comm 0x151714008fb0 rank 340 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
352: hkn0707:4019800:4019913 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [receive] via NET/IBext/0
342: hkn0704:791887:792017 [2] NCCL INFO comm 0x147c18008fb0 rank 342 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
289: hkn0624:1772850:1772951 [1] NCCL INFO comm 0x14694c008fb0 rank 289 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
343: hkn0704:791915:792018 [3] NCCL INFO comm 0x14d5f8008fb0 rank 343 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
426: hkn0727:1345664:1345786 [2] NCCL INFO comm 0x14c9b4008fb0 rank 426 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
421: hkn0726:1547991:1548116 [1] NCCL INFO Connected all trees
424: hkn0727:1345692:1345788 [0] NCCL INFO comm 0x155308008fb0 rank 424 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
419: hkn0725:3111817:3111928 [3] NCCL INFO comm 0x1454d4008fb0 rank 419 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
421: hkn0726:1547991:1548116 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
421: hkn0726:1547991:1548116 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3111825:3111935 [1] NCCL INFO comm 0x14af14008fb0 rank 417 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
427: hkn0727:1345680:1345791 [3] NCCL INFO comm 0x14b100008fb0 rank 427 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
416: hkn0725:3111837:3111934 [0] NCCL INFO comm 0x149a64008fb0 rank 416 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
418: hkn0725:3111809:3111929 [2] NCCL INFO comm 0x14f8d8008fb0 rank 418 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
184: hkn0527:1348838:1348947 [0] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [send] via NET/IBext/0
292: hkn0626:1298337:1298454 [0] NCCL INFO Connected all trees
156: hkn0516:2915863:2915972 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [send] via NET/IBext/0
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [send] via NET/IBext/0
423: hkn0726:1547999:1548115 [3] NCCL INFO comm 0x14bfd0008fb0 rank 423 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
292: hkn0626:1298337:1298454 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1298337:1298454 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
421: hkn0726:1547991:1548116 [1] NCCL INFO comm 0x149580008fb0 rank 421 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
420: hkn0726:1548019:1548119 [0] NCCL INFO comm 0x148a94008fb0 rank 420 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
422: hkn0726:1548007:1548114 [2] NCCL INFO comm 0x14a794008fb0 rank 422 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 68: hkn0422:4153004:4153125 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [send] via NET/IBext/0
293: hkn0626:1298357:1298456 [1] NCCL INFO Connected all trees
293: hkn0626:1298357:1298456 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
293: hkn0626:1298357:1298456 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1258042:1258156 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [send] via NET/IBext/0
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [receive] via NET/IBext/0
292: hkn0626:1298337:1298454 [0] NCCL INFO comm 0x14b740008fb0 rank 292 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [send] via NET/IBext/0
294: hkn0626:1298329:1298455 [2] NCCL INFO comm 0x14667c008fb0 rank 294 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
295: hkn0626:1298345:1298453 [3] NCCL INFO comm 0x148148008fb0 rank 295 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
293: hkn0626:1298357:1298456 [1] NCCL INFO comm 0x151ca8008fb0 rank 293 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
224: hkn0603:1413107:1413231 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [receive] via NET/IBext/0
461: hkn0802:1200244:1200347 [1] NCCL INFO Connected all trees
461: hkn0802:1200244:1200347 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1200244:1200347 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
197: hkn0530:1258062:1258153 [1] NCCL INFO Channel 00 : 197[4b000] -> 196[31000] via P2P/IPC/read
469: hkn0804:1205507:1205626 [1] NCCL INFO Channel 00 : 469[4b000] -> 468[31000] via P2P/IPC/read
328: hkn0635:1225461:1225602 [0] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [send] via NET/IBext/0
472: hkn0805:1111994:1112121 [0] NCCL INFO Connected all trees
472: hkn0805:1111994:1112121 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1111994:1112121 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
201: hkn0531:1230529:1230638 [1] NCCL INFO Connected all trees
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [send] via NET/IBext/0
201: hkn0531:1230529:1230638 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
201: hkn0531:1230529:1230638 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
197: hkn0530:1258062:1258153 [1] NCCL INFO Channel 01 : 197[4b000] -> 196[31000] via P2P/IPC/read
473: hkn0805:1112022:1112123 [1] NCCL INFO Connected all trees
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [receive] via NET/IBext/0
473: hkn0805:1112022:1112123 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
473: hkn0805:1112022:1112123 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
469: hkn0804:1205507:1205626 [1] NCCL INFO Channel 01 : 469[4b000] -> 468[31000] via P2P/IPC/read
200: hkn0531:1230521:1230636 [0] NCCL INFO Connected all trees
460: hkn0802:1200224:1200344 [0] NCCL INFO Connected all trees
200: hkn0531:1230521:1230636 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
460: hkn0802:1200224:1200344 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
200: hkn0531:1230521:1230636 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
460: hkn0802:1200224:1200344 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1111994:1112121 [0] NCCL INFO comm 0x1460e4008fb0 rank 472 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
200: hkn0531:1230521:1230636 [0] NCCL INFO comm 0x14bb04008fb0 rank 200 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 69: hkn0422:4153025:4153124 [1] NCCL INFO Channel 00 : 69[4b000] -> 68[31000] via P2P/IPC/read
473: hkn0805:1112022:1112123 [1] NCCL INFO comm 0x148b24008fb0 rank 473 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
474: hkn0805:1112002:1112122 [2] NCCL INFO comm 0x145898008fb0 rank 474 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
376: hkn0714:431923:432030 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [receive] via NET/IBext/0
460: hkn0802:1200224:1200344 [0] NCCL INFO comm 0x14e2a8008fb0 rank 460 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 73: hkn0423:1704793:1704926 [1] NCCL INFO Connected all trees
475: hkn0805:1112010:1112126 [3] NCCL INFO comm 0x14568c008fb0 rank 475 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
201: hkn0531:1230529:1230638 [1] NCCL INFO comm 0x147b3c008fb0 rank 201 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
462: hkn0802:1200232:1200339 [2] NCCL INFO comm 0x14aedc008fb0 rank 462 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 73: hkn0423:1704793:1704926 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
203: hkn0531:1230541:1230644 [3] NCCL INFO comm 0x152a3c008fb0 rank 203 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 73: hkn0423:1704793:1704926 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
461: hkn0802:1200244:1200347 [1] NCCL INFO comm 0x150194008fb0 rank 461 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
463: hkn0802:1200216:1200348 [3] NCCL INFO comm 0x148f14008fb0 rank 463 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
202: hkn0531:1230513:1230642 [2] NCCL INFO comm 0x14d210008fb0 rank 202 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 72: hkn0423:1704801:1704925 [0] NCCL INFO Connected all trees
 72: hkn0423:1704801:1704925 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 72: hkn0423:1704801:1704925 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 75: hkn0423:1704809:1704921 [3] NCCL INFO comm 0x15008c008fb0 rank 75 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
324: hkn0634:1520769:1520870 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [send] via NET/IBext/0
 73: hkn0423:1704793:1704926 [1] NCCL INFO comm 0x14a3a0008fb0 rank 73 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 00 : 457[4b000] -> 456[31000] via P2P/IPC/read
 69: hkn0422:4153025:4153124 [1] NCCL INFO Channel 01 : 69[4b000] -> 68[31000] via P2P/IPC/read
 74: hkn0423:1704821:1704920 [2] NCCL INFO comm 0x148c64008fb0 rank 74 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 72: hkn0423:1704801:1704925 [0] NCCL INFO comm 0x150238008fb0 rank 72 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
413: hkn0724:1715874:1715982 [1] NCCL INFO Connected all trees
441: hkn0732:1211535:1211667 [1] NCCL INFO Connected all trees
413: hkn0724:1715874:1715982 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1715874:1715982 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
441: hkn0732:1211535:1211667 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
437: hkn0731:1386617:1386741 [1] NCCL INFO Channel 00 : 437[4b000] -> 436[31000] via P2P/IPC/read
441: hkn0732:1211535:1211667 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
469: hkn0804:1205507:1205626 [1] NCCL INFO Connected all trees
469: hkn0804:1205507:1205626 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:709722:709820 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [send] via NET/IBext/0
469: hkn0804:1205507:1205626 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
448: hkn0734:1156433:1156551 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [receive] via NET/IBext/0
440: hkn0732:1211563:1211665 [0] NCCL INFO Connected all trees
440: hkn0732:1211563:1211665 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1211563:1211665 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
468: hkn0804:1205515:1205623 [0] NCCL INFO Connected all trees
468: hkn0804:1205515:1205623 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2239896:2240017 [1] NCCL INFO Channel 01 : 457[4b000] -> 456[31000] via P2P/IPC/read
468: hkn0804:1205515:1205623 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:413110:413222 [1] NCCL INFO Connected all trees
368: hkn0712:294956:295068 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [receive] via NET/IBext/0
357: hkn0708:413110:413222 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
357: hkn0708:413110:413222 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
437: hkn0731:1386617:1386741 [1] NCCL INFO Channel 01 : 437[4b000] -> 436[31000] via P2P/IPC/read
443: hkn0732:1211551:1211659 [3] NCCL INFO comm 0x153a70008fb0 rank 443 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
356: hkn0708:413102:413217 [0] NCCL INFO Connected all trees
440: hkn0732:1211563:1211665 [0] NCCL INFO comm 0x14b0d8008fb0 rank 440 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
356: hkn0708:413102:413217 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:413102:413217 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
468: hkn0804:1205515:1205623 [0] NCCL INFO comm 0x154600008fb0 rank 468 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
157: hkn0516:2915847:2915969 [1] NCCL INFO Connected all trees
441: hkn0732:1211535:1211667 [1] NCCL INFO comm 0x151af0008fb0 rank 441 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
469: hkn0804:1205507:1205626 [1] NCCL INFO comm 0x145f94008fb0 rank 469 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
412: hkn0724:1715866:1715984 [0] NCCL INFO Connected all trees
157: hkn0516:2915847:2915969 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
181: hkn0526:1428306:1428417 [1] NCCL INFO Channel 00 : 181[4b000] -> 180[31000] via P2P/IPC/read
470: hkn0804:1205535:1205629 [2] NCCL INFO comm 0x145f0c008fb0 rank 470 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
185: hkn0527:1348822:1348946 [1] NCCL INFO Connected all trees
157: hkn0516:2915847:2915969 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
442: hkn0732:1211543:1211663 [2] NCCL INFO comm 0x14a98c008fb0 rank 442 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
471: hkn0804:1205505:1205631 [3] NCCL INFO comm 0x152b8c008fb0 rank 471 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
412: hkn0724:1715866:1715984 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
412: hkn0724:1715866:1715984 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
185: hkn0527:1348822:1348946 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
185: hkn0527:1348822:1348946 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:413102:413217 [0] NCCL INFO comm 0x1531e8008fb0 rank 356 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
184: hkn0527:1348838:1348947 [0] NCCL INFO Connected all trees
358: hkn0708:413122:413219 [2] NCCL INFO comm 0x146ee8008fb0 rank 358 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
184: hkn0527:1348838:1348947 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
359: hkn0708:413094:413225 [3] NCCL INFO comm 0x155124008fb0 rank 359 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
184: hkn0527:1348838:1348947 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:413110:413222 [1] NCCL INFO comm 0x14af5c008fb0 rank 357 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
413: hkn0724:1715874:1715982 [1] NCCL INFO comm 0x14e8a0008fb0 rank 413 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
197: hkn0530:1258062:1258153 [1] NCCL INFO Connected all trees
415: hkn0724:1715858:1715983 [3] NCCL INFO comm 0x1478b4008fb0 rank 415 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
414: hkn0724:1715886:1715987 [2] NCCL INFO comm 0x14ec84008fb0 rank 414 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
412: hkn0724:1715866:1715984 [0] NCCL INFO comm 0x14f9bc008fb0 rank 412 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
181: hkn0526:1428306:1428417 [1] NCCL INFO Channel 01 : 181[4b000] -> 180[31000] via P2P/IPC/read
197: hkn0530:1258062:1258153 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
197: hkn0530:1258062:1258153 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1258042:1258156 [0] NCCL INFO Connected all trees
185: hkn0527:1348822:1348946 [1] NCCL INFO comm 0x14565c008fb0 rank 185 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
186: hkn0527:1348830:1348950 [2] NCCL INFO comm 0x14cf44008fb0 rank 186 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
187: hkn0527:1348850:1348948 [3] NCCL INFO comm 0x14b698008fb0 rank 187 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
184: hkn0527:1348838:1348947 [0] NCCL INFO comm 0x14c280008fb0 rank 184 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
196: hkn0530:1258042:1258156 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
196: hkn0530:1258042:1258156 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4153025:4153124 [1] NCCL INFO Connected all trees
 69: hkn0422:4153025:4153124 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 69: hkn0422:4153025:4153124 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
156: hkn0516:2915863:2915972 [0] NCCL INFO Connected all trees
156: hkn0516:2915863:2915972 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2915863:2915972 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [send] via NET/IBext/0
196: hkn0530:1258042:1258156 [0] NCCL INFO comm 0x15263c008fb0 rank 196 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
436: hkn0731:1386645:1386747 [0] NCCL INFO Connected all trees
436: hkn0731:1386645:1386747 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1386645:1386747 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4153004:4153125 [0] NCCL INFO Connected all trees
229: hkn0604:689145:689242 [1] NCCL INFO Connected all trees
197: hkn0530:1258062:1258153 [1] NCCL INFO comm 0x14fef0008fb0 rank 197 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 68: hkn0422:4153004:4153125 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
229: hkn0604:689145:689242 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
199: hkn0530:1258050:1258161 [3] NCCL INFO comm 0x1455a0008fb0 rank 199 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 68: hkn0422:4153004:4153125 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:689145:689242 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
198: hkn0530:1258034:1258159 [2] NCCL INFO comm 0x14beb0008fb0 rank 198 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
456: hkn0801:2239904:2240015 [0] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [send] via NET/IBext/0
157: hkn0516:2915847:2915969 [1] NCCL INFO comm 0x14573c008fb0 rank 157 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
437: hkn0731:1386617:1386741 [1] NCCL INFO Connected all trees
228: hkn0604:689133:689241 [0] NCCL INFO Connected all trees
437: hkn0731:1386617:1386741 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
159: hkn0516:2915875:2915970 [3] NCCL INFO comm 0x1513b8008fb0 rank 159 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
437: hkn0731:1386617:1386741 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
156: hkn0516:2915863:2915972 [0] NCCL INFO comm 0x1541b8008fb0 rank 156 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
228: hkn0604:689133:689241 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
158: hkn0516:2915855:2915974 [2] NCCL INFO comm 0x14b7d8008fb0 rank 158 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
228: hkn0604:689133:689241 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
193: hkn0529:1540700:1540850 [1] NCCL INFO Connected all trees
 69: hkn0422:4153025:4153124 [1] NCCL INFO comm 0x153db0008fb0 rank 69 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 71: hkn0422:4153013:4153117 [3] NCCL INFO comm 0x1494ac008fb0 rank 71 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 70: hkn0422:4153005:4153119 [2] NCCL INFO comm 0x14539c008fb0 rank 70 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
248: hkn0609:710728:710827 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [receive] via NET/IBext/0
 68: hkn0422:4153004:4153125 [0] NCCL INFO comm 0x151764008fb0 rank 68 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
193: hkn0529:1540700:1540850 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
193: hkn0529:1540700:1540850 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
353: hkn0707:4019808:4019912 [1] NCCL INFO Connected all trees
316: hkn0632:1758503:1758621 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [send] via NET/IBext/0
 64: hkn0421:2180612:2180860 [0] NCCL INFO Connected all trees
353: hkn0707:4019808:4019912 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1386645:1386747 [0] NCCL INFO comm 0x14c840008fb0 rank 436 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
353: hkn0707:4019808:4019912 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
329: hkn0635:1225473:1225593 [1] NCCL INFO Connected all trees
329: hkn0635:1225473:1225593 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 64: hkn0421:2180612:2180860 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
329: hkn0635:1225473:1225593 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
180: hkn0526:1428298:1428416 [0] NCCL INFO Connected all trees
437: hkn0731:1386617:1386741 [1] NCCL INFO comm 0x14bee0008fb0 rank 437 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 64: hkn0421:2180612:2180860 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:689145:689242 [1] NCCL INFO comm 0x150be8008fb0 rank 229 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
325: hkn0634:1520753:1520864 [1] NCCL INFO Channel 00 : 325[4b000] -> 324[31000] via P2P/IPC/read
438: hkn0731:1386633:1386740 [2] NCCL INFO comm 0x145dfc008fb0 rank 438 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
180: hkn0526:1428298:1428416 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
439: hkn0731:1386625:1386746 [3] NCCL INFO comm 0x1454cc008fb0 rank 439 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
180: hkn0526:1428298:1428416 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
352: hkn0707:4019800:4019913 [0] NCCL INFO Connected all trees
230: hkn0604:689117:689240 [2] NCCL INFO comm 0x1502c4008fb0 rank 230 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
352: hkn0707:4019800:4019913 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1225461:1225602 [0] NCCL INFO Connected all trees
231: hkn0604:689125:689244 [3] NCCL INFO comm 0x14aa94008fb0 rank 231 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
228: hkn0604:689133:689241 [0] NCCL INFO comm 0x14e508008fb0 rank 228 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
352: hkn0707:4019800:4019913 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1225461:1225602 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
381: hkn0715:401780:401901 [1] NCCL INFO Connected all trees
328: hkn0635:1225461:1225602 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1428306:1428417 [1] NCCL INFO Connected all trees
 65: hkn0421:2180584:2180857 [1] NCCL INFO Connected all trees
381: hkn0715:401780:401901 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
181: hkn0526:1428306:1428417 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 65: hkn0421:2180584:2180857 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
381: hkn0715:401780:401901 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1428306:1428417 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 65: hkn0421:2180584:2180857 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1225461:1225602 [0] NCCL INFO comm 0x145860008fb0 rank 328 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
329: hkn0635:1225473:1225593 [1] NCCL INFO comm 0x1464bc008fb0 rank 329 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
181: hkn0526:1428306:1428417 [1] NCCL INFO comm 0x152ed0008fb0 rank 181 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
354: hkn0707:4019820:4019919 [2] NCCL INFO comm 0x148a20008fb0 rank 354 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
331: hkn0635:1225445:1225601 [3] NCCL INFO comm 0x145fd4008fb0 rank 331 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
224: hkn0603:1413107:1413231 [0] NCCL INFO Connected all trees
224: hkn0603:1413107:1413231 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1540728:1540857 [0] NCCL INFO Connected all trees
353: hkn0707:4019808:4019912 [1] NCCL INFO comm 0x1542a8008fb0 rank 353 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
224: hkn0603:1413107:1413231 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 64: hkn0421:2180612:2180860 [0] NCCL INFO comm 0x145db0008fb0 rank 64 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
325: hkn0634:1520753:1520864 [1] NCCL INFO Channel 01 : 325[4b000] -> 324[31000] via P2P/IPC/read
355: hkn0707:4019792:4019918 [3] NCCL INFO comm 0x152454008fb0 rank 355 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
183: hkn0526:1428318:1428415 [3] NCCL INFO comm 0x14e984008fb0 rank 183 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
352: hkn0707:4019800:4019913 [0] NCCL INFO comm 0x14c5c4008fb0 rank 352 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 67: hkn0421:2180600:2180859 [3] NCCL INFO comm 0x14caa4008fb0 rank 67 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
192: hkn0529:1540728:1540857 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
182: hkn0526:1428290:1428419 [2] NCCL INFO comm 0x146fd4008fb0 rank 182 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 65: hkn0421:2180584:2180857 [1] NCCL INFO comm 0x14eac0008fb0 rank 65 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
396: hkn0719:1305611:1305724 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [send] via NET/IBext/0
192: hkn0529:1540728:1540857 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
180: hkn0526:1428298:1428416 [0] NCCL INFO comm 0x150a80008fb0 rank 180 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 66: hkn0421:2180592:2180858 [2] NCCL INFO comm 0x14a6a8008fb0 rank 66 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
225: hkn0603:1413115:1413233 [1] NCCL INFO Connected all trees
225: hkn0603:1413115:1413233 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
225: hkn0603:1413115:1413233 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:207901:208066 [0] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [send] via NET/IBext/0
193: hkn0529:1540700:1540850 [1] NCCL INFO comm 0x1530e8008fb0 rank 193 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
195: hkn0529:1540716:1540851 [3] NCCL INFO comm 0x153be8008fb0 rank 195 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
192: hkn0529:1540728:1540857 [0] NCCL INFO comm 0x149dbc008fb0 rank 192 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
194: hkn0529:1540708:1540856 [2] NCCL INFO comm 0x1468dc008fb0 rank 194 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
380: hkn0715:401772:401896 [0] NCCL INFO Connected all trees
226: hkn0603:1413123:1413232 [2] NCCL INFO comm 0x146b70008fb0 rank 226 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
380: hkn0715:401772:401896 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:401772:401896 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1413107:1413231 [0] NCCL INFO comm 0x1496e8008fb0 rank 224 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
227: hkn0603:1413135:1413236 [3] NCCL INFO comm 0x1469d0008fb0 rank 227 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
225: hkn0603:1413115:1413233 [1] NCCL INFO comm 0x14e414008fb0 rank 225 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [send] via NET/IBext/0
240: hkn0607:904254:904366 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [receive] via NET/IBext/0
140: hkn0512:3044041:3044149 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [send] via NET/IBext/0
381: hkn0715:401780:401901 [1] NCCL INFO comm 0x154c0c008fb0 rank 381 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
382: hkn0715:401788:401899 [2] NCCL INFO comm 0x14e1a4008fb0 rank 382 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
380: hkn0715:401772:401896 [0] NCCL INFO comm 0x14a804008fb0 rank 380 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
383: hkn0715:401800:401893 [3] NCCL INFO comm 0x14fc84008fb0 rank 383 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
324: hkn0634:1520769:1520870 [0] NCCL INFO Connected all trees
324: hkn0634:1520769:1520870 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1520769:1520870 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
496: hkn0812:693695:693790 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [receive] via NET/IBext/0
325: hkn0634:1520753:1520864 [1] NCCL INFO Connected all trees
325: hkn0634:1520753:1520864 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
152: hkn0515:2896675:2896797 [0] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [send] via NET/IBext/0
325: hkn0634:1520753:1520864 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1520769:1520870 [0] NCCL INFO comm 0x147ca8008fb0 rank 324 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
327: hkn0634:1520781:1520863 [3] NCCL INFO comm 0x1505d4008fb0 rank 327 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
325: hkn0634:1520753:1520864 [1] NCCL INFO comm 0x1525a4008fb0 rank 325 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
326: hkn0634:1520761:1520867 [2] NCCL INFO comm 0x146e34008fb0 rank 326 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [receive] via NET/IBext/0
321: hkn0633:1526230:1526356 [1] NCCL INFO Connected all trees
321: hkn0633:1526230:1526356 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
321: hkn0633:1526230:1526356 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
320: hkn0633:1526202:1526350 [0] NCCL INFO Connected all trees
320: hkn0633:1526202:1526350 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
330: hkn0635:1225453:1225598 [2] NCCL INFO comm 0x14d564008fb0 rank 330 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
320: hkn0633:1526202:1526350 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1508232:1508369 [1] NCCL INFO Channel 00 : 453[4b000] -> 452[31000] via P2P/IPC/read
369: hkn0712:294968:295070 [1] NCCL INFO Connected all trees
457: hkn0801:2239896:2240017 [1] NCCL INFO Connected all trees
369: hkn0712:294968:295070 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:294968:295070 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
457: hkn0801:2239896:2240017 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
323: hkn0633:1526210:1526349 [3] NCCL INFO comm 0x153f10008fb0 rank 323 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
457: hkn0801:2239896:2240017 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:294956:295068 [0] NCCL INFO Connected all trees
253: hkn0611:709702:709825 [1] NCCL INFO Connected all trees
317: hkn0632:1758522:1758616 [1] NCCL INFO Connected all trees
321: hkn0633:1526230:1526356 [1] NCCL INFO comm 0x154ffc008fb0 rank 321 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
480: hkn0807:1018966:1019081 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [receive] via NET/IBext/0
253: hkn0611:709702:709825 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
317: hkn0632:1758522:1758616 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
320: hkn0633:1526202:1526350 [0] NCCL INFO comm 0x150c44008fb0 rank 320 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
456: hkn0801:2239904:2240015 [0] NCCL INFO Connected all trees
253: hkn0611:709702:709825 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
317: hkn0632:1758522:1758616 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
322: hkn0633:1526218:1526355 [2] NCCL INFO comm 0x147f80008fb0 rank 322 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
376: hkn0714:431923:432030 [0] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [send] via NET/IBext/0
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [receive] via NET/IBext/0
368: hkn0712:294956:295068 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
456: hkn0801:2239904:2240015 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:294956:295068 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1508216:1508371 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [send] via NET/IBext/0
456: hkn0801:2239904:2240015 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1508232:1508369 [1] NCCL INFO Channel 01 : 453[4b000] -> 452[31000] via P2P/IPC/read
252: hkn0611:709722:709820 [0] NCCL INFO Connected all trees
252: hkn0611:709722:709820 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1758503:1758621 [0] NCCL INFO Connected all trees
252: hkn0611:709722:709820 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:294956:295068 [0] NCCL INFO comm 0x14b5a4008fb0 rank 368 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
316: hkn0632:1758503:1758621 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1758503:1758621 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
459: hkn0801:2239888:2240016 [3] NCCL INFO comm 0x153a94008fb0 rank 459 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
457: hkn0801:2239896:2240017 [1] NCCL INFO comm 0x150f60008fb0 rank 457 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
371: hkn0712:294948:295061 [3] NCCL INFO comm 0x14da08008fb0 rank 371 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
456: hkn0801:2239904:2240015 [0] NCCL INFO comm 0x153b28008fb0 rank 456 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
369: hkn0712:294968:295070 [1] NCCL INFO comm 0x154f74008fb0 rank 369 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
370: hkn0712:294940:295065 [2] NCCL INFO comm 0x14eb34008fb0 rank 370 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
458: hkn0801:2239916:2240014 [2] NCCL INFO comm 0x1518c4008fb0 rank 458 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
253: hkn0611:709702:709825 [1] NCCL INFO comm 0x148d00008fb0 rank 253 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
316: hkn0632:1758503:1758621 [0] NCCL INFO comm 0x14abfc008fb0 rank 316 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
252: hkn0611:709722:709820 [0] NCCL INFO comm 0x14aa68008fb0 rank 252 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
254: hkn0611:709710:709819 [2] NCCL INFO comm 0x1539d4008fb0 rank 254 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
255: hkn0611:709694:709822 [3] NCCL INFO comm 0x15197c008fb0 rank 255 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
317: hkn0632:1758522:1758616 [1] NCCL INFO comm 0x14b418008fb0 rank 317 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
319: hkn0632:1758511:1758619 [3] NCCL INFO comm 0x14f054008fb0 rank 319 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
318: hkn0632:1758495:1758618 [2] NCCL INFO comm 0x1500d4008fb0 rank 318 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
124: hkn0508:3139017:3139132 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [send] via NET/IBext/0
405: hkn0721:2299079:2299192 [1] NCCL INFO Channel 00 : 405[4b000] -> 404[31000] via P2P/IPC/read
409: hkn0723:207893:208068 [1] NCCL INFO Connected all trees
409: hkn0723:207893:208068 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
409: hkn0723:207893:208068 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 00 : 393[4b000] -> 392[31000] via P2P/IPC/read
408: hkn0723:207901:208066 [0] NCCL INFO Connected all trees
396: hkn0719:1305611:1305724 [0] NCCL INFO Connected all trees
408: hkn0723:207901:208066 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:207901:208066 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1305611:1305724 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
396: hkn0719:1305611:1305724 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2299079:2299192 [1] NCCL INFO Channel 01 : 405[4b000] -> 404[31000] via P2P/IPC/read
393: hkn0718:3916897:3917023 [1] NCCL INFO Channel 01 : 393[4b000] -> 392[31000] via P2P/IPC/read
141: hkn0512:3044053:3044152 [1] NCCL INFO Connected all trees
141: hkn0512:3044053:3044152 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
141: hkn0512:3044053:3044152 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
397: hkn0719:1305595:1305722 [1] NCCL INFO Connected all trees
397: hkn0719:1305595:1305722 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
397: hkn0719:1305595:1305722 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
409: hkn0723:207893:208068 [1] NCCL INFO comm 0x148524008fb0 rank 409 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
140: hkn0512:3044041:3044149 [0] NCCL INFO Connected all trees
410: hkn0723:207909:208065 [2] NCCL INFO comm 0x14979c008fb0 rank 410 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
140: hkn0512:3044041:3044149 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
411: hkn0723:207921:208060 [3] NCCL INFO comm 0x152074008fb0 rank 411 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
140: hkn0512:3044041:3044149 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:207901:208066 [0] NCCL INFO comm 0x1464b4008fb0 rank 408 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
149: hkn0514:2950618:2950734 [1] NCCL INFO Channel 00 : 149[4b000] -> 148[31000] via P2P/IPC/read
396: hkn0719:1305611:1305724 [0] NCCL INFO comm 0x14f540008fb0 rank 396 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
143: hkn0512:3044032:3044153 [3] NCCL INFO comm 0x14a670008fb0 rank 143 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
397: hkn0719:1305595:1305722 [1] NCCL INFO comm 0x1536b4008fb0 rank 397 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
141: hkn0512:3044053:3044152 [1] NCCL INFO comm 0x14cfe0008fb0 rank 141 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
152: hkn0515:2896675:2896797 [0] NCCL INFO Connected all trees
140: hkn0512:3044041:3044149 [0] NCCL INFO comm 0x153d08008fb0 rank 140 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
398: hkn0719:1305623:1305723 [2] NCCL INFO comm 0x1472b8008fb0 rank 398 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
152: hkn0515:2896675:2896797 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
142: hkn0512:3044033:3044156 [2] NCCL INFO comm 0x14dc58008fb0 rank 142 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
152: hkn0515:2896675:2896797 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 00 : 137[4b000] -> 136[31000] via P2P/IPC/read
399: hkn0719:1305603:1305721 [3] NCCL INFO comm 0x14bba4008fb0 rank 399 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
153: hkn0515:2896667:2896795 [1] NCCL INFO Connected all trees
149: hkn0514:2950618:2950734 [1] NCCL INFO Channel 01 : 149[4b000] -> 148[31000] via P2P/IPC/read
153: hkn0515:2896667:2896795 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
153: hkn0515:2896667:2896795 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:710728:710827 [0] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [send] via NET/IBext/0
404: hkn0721:2299087:2299193 [0] NCCL INFO Connected all trees
404: hkn0721:2299087:2299193 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2299087:2299193 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3066282:3066391 [1] NCCL INFO Channel 01 : 137[4b000] -> 136[31000] via P2P/IPC/read
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [send] via NET/IBext/0
284: hkn0623:1872656:1872763 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [send] via NET/IBext/0
312: hkn0631:1021735:1021830 [0] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [send] via NET/IBext/0
405: hkn0721:2299079:2299192 [1] NCCL INFO Connected all trees
405: hkn0721:2299079:2299192 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
405: hkn0721:2299079:2299192 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
154: hkn0515:2896695:2896792 [2] NCCL INFO comm 0x14ab54008fb0 rank 154 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
153: hkn0515:2896667:2896795 [1] NCCL INFO comm 0x147198008fb0 rank 153 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
241: hkn0607:904238:904362 [1] NCCL INFO Connected all trees
152: hkn0515:2896675:2896797 [0] NCCL INFO comm 0x14f488008fb0 rank 152 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
155: hkn0515:2896683:2896800 [3] NCCL INFO comm 0x15137c008fb0 rank 155 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
241: hkn0607:904238:904362 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
241: hkn0607:904238:904362 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
404: hkn0721:2299087:2299193 [0] NCCL INFO comm 0x14fa84008fb0 rank 404 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
240: hkn0607:904254:904366 [0] NCCL INFO Connected all trees
240: hkn0607:904254:904366 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
407: hkn0721:2299099:2299196 [3] NCCL INFO comm 0x14fd18008fb0 rank 407 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
240: hkn0607:904254:904366 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:470120:470234 [1] NCCL INFO Channel 00 : 373[4b000] -> 372[31000] via P2P/IPC/read
405: hkn0721:2299079:2299192 [1] NCCL INFO comm 0x147e34008fb0 rank 405 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
406: hkn0721:2299071:2299198 [2] NCCL INFO comm 0x146e10008fb0 rank 406 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
377: hkn0714:431907:432038 [1] NCCL INFO Connected all trees
377: hkn0714:431907:432038 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
377: hkn0714:431907:432038 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
148: hkn0514:2950603:2950729 [0] NCCL INFO Connected all trees
240: hkn0607:904254:904366 [0] NCCL INFO comm 0x146cf0008fb0 rank 240 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
148: hkn0514:2950603:2950729 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2950603:2950729 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
241: hkn0607:904238:904362 [1] NCCL INFO comm 0x153c80008fb0 rank 241 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
242: hkn0607:904266:904368 [2] NCCL INFO comm 0x151370008fb0 rank 242 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
243: hkn0607:904246:904360 [3] NCCL INFO comm 0x150418008fb0 rank 243 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
376: hkn0714:431923:432030 [0] NCCL INFO Connected all trees
373: hkn0713:470120:470234 [1] NCCL INFO Channel 01 : 373[4b000] -> 372[31000] via P2P/IPC/read
392: hkn0718:3916913:3917022 [0] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [send] via NET/IBext/0
376: hkn0714:431923:432030 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
376: hkn0714:431923:432030 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:970557:970676 [0] NCCL INFO Connected all trees
149: hkn0514:2950618:2950734 [1] NCCL INFO Connected all trees
149: hkn0514:2950618:2950734 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:395016:395129 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [receive] via NET/IBext/0
149: hkn0514:2950618:2950734 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1508232:1508369 [1] NCCL INFO Connected all trees
484: hkn0808:970557:970676 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:970557:970676 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1508232:1508369 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
453: hkn0736:1508232:1508369 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
379: hkn0714:431935:432037 [3] NCCL INFO comm 0x1546cc008fb0 rank 379 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
485: hkn0808:970565:970682 [1] NCCL INFO Connected all trees
378: hkn0714:431915:432039 [2] NCCL INFO comm 0x150824008fb0 rank 378 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
452: hkn0736:1508216:1508371 [0] NCCL INFO Connected all trees
452: hkn0736:1508216:1508371 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2950603:2950729 [0] NCCL INFO comm 0x14a9bc008fb0 rank 148 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
485: hkn0808:970565:970682 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1508216:1508371 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:970565:970682 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
151: hkn0514:2950630:2950735 [3] NCCL INFO comm 0x14ae50008fb0 rank 151 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
376: hkn0714:431923:432030 [0] NCCL INFO comm 0x14fe3c008fb0 rank 376 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
149: hkn0514:2950618:2950734 [1] NCCL INFO comm 0x145588008fb0 rank 149 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
150: hkn0514:2950610:2950728 [2] NCCL INFO comm 0x150284008fb0 rank 150 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
485: hkn0808:970565:970682 [1] NCCL INFO comm 0x147688008fb0 rank 485 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
484: hkn0808:970557:970676 [0] NCCL INFO comm 0x14d1a4008fb0 rank 484 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
453: hkn0736:1508232:1508369 [1] NCCL INFO comm 0x1466a4008fb0 rank 453 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
124: hkn0508:3139017:3139132 [0] NCCL INFO Connected all trees
454: hkn0736:1508244:1508370 [2] NCCL INFO comm 0x14e7ac008fb0 rank 454 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
268: hkn0616:404786:404909 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [send] via NET/IBext/0
124: hkn0508:3139017:3139132 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
487: hkn0808:970549:970680 [3] NCCL INFO comm 0x151ca4008fb0 rank 487 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
124: hkn0508:3139017:3139132 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
486: hkn0808:970577:970677 [2] NCCL INFO comm 0x1453a4008fb0 rank 486 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
448: hkn0734:1156433:1156551 [0] NCCL INFO Connected all trees
448: hkn0734:1156433:1156551 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
455: hkn0736:1508224:1508372 [3] NCCL INFO comm 0x1529f8008fb0 rank 455 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
448: hkn0734:1156433:1156551 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1508216:1508371 [0] NCCL INFO comm 0x150884008fb0 rank 452 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
125: hkn0508:3139009:3139136 [1] NCCL INFO Connected all trees
125: hkn0508:3139009:3139136 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
125: hkn0508:3139009:3139136 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:470120:470234 [1] NCCL INFO Connected all trees
373: hkn0713:470120:470234 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
449: hkn0734:1156453:1156552 [1] NCCL INFO Connected all trees
373: hkn0713:470120:470234 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
449: hkn0734:1156453:1156552 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
449: hkn0734:1156453:1156552 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
481: hkn0807:1018958:1019082 [1] NCCL INFO Connected all trees
481: hkn0807:1018958:1019082 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:693695:693790 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [receive] via NET/IBext/0
481: hkn0807:1018958:1019082 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
372: hkn0713:470112:470238 [0] NCCL INFO Connected all trees
372: hkn0713:470112:470238 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:470112:470238 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3139017:3139132 [0] NCCL INFO comm 0x146b30008fb0 rank 124 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
125: hkn0508:3139009:3139136 [1] NCCL INFO comm 0x14acd4008fb0 rank 125 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
480: hkn0807:1018966:1019081 [0] NCCL INFO Connected all trees
126: hkn0508:3139025:3139135 [2] NCCL INFO comm 0x1530f0008fb0 rank 126 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
448: hkn0734:1156433:1156551 [0] NCCL INFO comm 0x154f70008fb0 rank 448 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
480: hkn0807:1018966:1019081 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
127: hkn0508:3139037:3139138 [3] NCCL INFO comm 0x15409c008fb0 rank 127 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
480: hkn0807:1018966:1019081 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1156441:1156545 [2] NCCL INFO comm 0x14db90008fb0 rank 450 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
449: hkn0734:1156453:1156552 [1] NCCL INFO comm 0x14ef08008fb0 rank 449 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
388: hkn0717:4187551:4187658 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [send] via NET/IBext/0
451: hkn0734:1156425:1156546 [3] NCCL INFO comm 0x146654008fb0 rank 451 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
481: hkn0807:1018958:1019082 [1] NCCL INFO comm 0x1500d4008fb0 rank 481 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
372: hkn0713:470112:470238 [0] NCCL INFO comm 0x149884008fb0 rank 372 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
483: hkn0807:1018978:1019080 [3] NCCL INFO comm 0x147380008fb0 rank 483 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
373: hkn0713:470120:470234 [1] NCCL INFO comm 0x1453ac008fb0 rank 373 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
375: hkn0713:470140:470235 [3] NCCL INFO comm 0x146234008fb0 rank 375 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
480: hkn0807:1018966:1019081 [0] NCCL INFO comm 0x149b60008fb0 rank 480 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
482: hkn0807:1018950:1019079 [2] NCCL INFO comm 0x14be18008fb0 rank 482 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
245: hkn0608:485636:485738 [1] NCCL INFO Channel 00 : 245[4b000] -> 244[31000] via P2P/IPC/read
374: hkn0713:470128:470236 [2] NCCL INFO comm 0x1497bc008fb0 rank 374 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
249: hkn0609:710716:710825 [1] NCCL INFO Connected all trees
249: hkn0609:710716:710825 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1872656:1872763 [0] NCCL INFO Connected all trees
249: hkn0609:710716:710825 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1872656:1872763 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1872656:1872763 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:710728:710827 [0] NCCL INFO Connected all trees
248: hkn0609:710728:710827 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:485636:485738 [1] NCCL INFO Channel 01 : 245[4b000] -> 244[31000] via P2P/IPC/read
248: hkn0609:710728:710827 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
313: hkn0631:1021707:1021834 [1] NCCL INFO Connected all trees
132: hkn0510:2761944:2762047 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [send] via NET/IBext/0
313: hkn0631:1021707:1021834 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
313: hkn0631:1021707:1021834 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
309: hkn0630:1598347:1598454 [1] NCCL INFO Channel 00 : 309[4b000] -> 308[31000] via P2P/IPC/read
285: hkn0623:1872640:1872768 [1] NCCL INFO Connected all trees
248: hkn0609:710728:710827 [0] NCCL INFO comm 0x147c50008fb0 rank 248 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
377: hkn0714:431907:432038 [1] NCCL INFO comm 0x148c1c008fb0 rank 377 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
285: hkn0623:1872640:1872768 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
285: hkn0623:1872640:1872768 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1021735:1021830 [0] NCCL INFO Connected all trees
136: hkn0511:3066274:3066392 [0] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [send] via NET/IBext/0
249: hkn0609:710716:710825 [1] NCCL INFO comm 0x153884008fb0 rank 249 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
312: hkn0631:1021735:1021830 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
312: hkn0631:1021735:1021830 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
250: hkn0609:710708:710822 [2] NCCL INFO comm 0x1538a0008fb0 rank 250 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
251: hkn0609:710700:710823 [3] NCCL INFO comm 0x14df2c008fb0 rank 251 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
284: hkn0623:1872656:1872763 [0] NCCL INFO comm 0x14aed4008fb0 rank 284 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
286: hkn0623:1872648:1872765 [2] NCCL INFO comm 0x14ec90008fb0 rank 286 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
309: hkn0630:1598347:1598454 [1] NCCL INFO Channel 01 : 309[4b000] -> 308[31000] via P2P/IPC/read
389: hkn0717:4187531:4187655 [1] NCCL INFO Channel 00 : 389[4b000] -> 388[31000] via P2P/IPC/read
285: hkn0623:1872640:1872768 [1] NCCL INFO comm 0x14b318008fb0 rank 285 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
314: hkn0631:1021723:1021832 [2] NCCL INFO comm 0x15030c008fb0 rank 314 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
287: hkn0623:1872668:1872764 [3] NCCL INFO comm 0x1475c8008fb0 rank 287 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
312: hkn0631:1021735:1021830 [0] NCCL INFO comm 0x150a64008fb0 rank 312 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
313: hkn0631:1021707:1021834 [1] NCCL INFO comm 0x151ef0008fb0 rank 313 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
393: hkn0718:3916897:3917023 [1] NCCL INFO Connected all trees
393: hkn0718:3916897:3917023 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3916897:3917023 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
244: hkn0608:485608:485739 [0] NCCL INFO Connected all trees
244: hkn0608:485608:485739 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3916913:3917022 [0] NCCL INFO Connected all trees
244: hkn0608:485608:485739 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3916913:3917022 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
315: hkn0631:1021715:1021825 [3] NCCL INFO comm 0x154a04008fb0 rank 315 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
392: hkn0718:3916913:3917022 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
509: hkn0816:375500:375645 [1] NCCL INFO Connected all trees
245: hkn0608:485636:485738 [1] NCCL INFO Connected all trees
509: hkn0816:375500:375645 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:4187531:4187655 [1] NCCL INFO Channel 01 : 389[4b000] -> 388[31000] via P2P/IPC/read
245: hkn0608:485636:485738 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
509: hkn0816:375500:375645 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
120: hkn0507:3186982:3187071 [0] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [send] via NET/IBext/0
245: hkn0608:485636:485738 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3916897:3917023 [1] NCCL INFO comm 0x152e40008fb0 rank 393 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
392: hkn0718:3916913:3917022 [0] NCCL INFO comm 0x14ab68008fb0 rank 392 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
508: hkn0816:375484:375639 [0] NCCL INFO Connected all trees
394: hkn0718:3916905:3917029 [2] NCCL INFO comm 0x1469b8008fb0 rank 394 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
395: hkn0718:3916925:3917028 [3] NCCL INFO comm 0x147d00008fb0 rank 395 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
508: hkn0816:375484:375639 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
508: hkn0816:375484:375639 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3210113:3210211 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [send] via NET/IBext/0
244: hkn0608:485608:485739 [0] NCCL INFO comm 0x148b64008fb0 rank 244 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
245: hkn0608:485636:485738 [1] NCCL INFO comm 0x14c4ac008fb0 rank 245 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
308: hkn0630:1598339:1598456 [0] NCCL INFO Connected all trees
246: hkn0608:485616:485737 [2] NCCL INFO comm 0x14b774008fb0 rank 246 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
308: hkn0630:1598339:1598456 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
247: hkn0608:485624:485730 [3] NCCL INFO comm 0x147d08008fb0 rank 247 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
308: hkn0630:1598339:1598456 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
508: hkn0816:375484:375639 [0] NCCL INFO comm 0x14ebb8008fb0 rank 508 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
509: hkn0816:375500:375645 [1] NCCL INFO comm 0x148208008fb0 rank 509 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
511: hkn0816:375492:375642 [3] NCCL INFO comm 0x150db8008fb0 rank 511 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
510: hkn0816:375512:375637 [2] NCCL INFO comm 0x1476c0008fb0 rank 510 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
309: hkn0630:1598347:1598454 [1] NCCL INFO Connected all trees
309: hkn0630:1598347:1598454 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1598347:1598454 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
308: hkn0630:1598339:1598456 [0] NCCL INFO comm 0x14e660008fb0 rank 308 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
310: hkn0630:1598359:1598459 [2] NCCL INFO comm 0x149d44008fb0 rank 310 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
311: hkn0630:1598331:1598462 [3] NCCL INFO comm 0x14d750008fb0 rank 311 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
309: hkn0630:1598347:1598454 [1] NCCL INFO comm 0x1516cc008fb0 rank 309 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
389: hkn0717:4187531:4187655 [1] NCCL INFO Connected all trees
389: hkn0717:4187531:4187655 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:4187531:4187655 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4187551:4187658 [0] NCCL INFO Connected all trees
388: hkn0717:4187551:4187658 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
388: hkn0717:4187551:4187658 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [send] via NET/IBext/0
268: hkn0616:404786:404909 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [send] via NET/IBext/0
388: hkn0717:4187551:4187658 [0] NCCL INFO comm 0x147350008fb0 rank 388 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
389: hkn0717:4187531:4187655 [1] NCCL INFO comm 0x1548cc008fb0 rank 389 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
390: hkn0717:4187539:4187652 [2] NCCL INFO comm 0x1545b4008fb0 rank 390 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
391: hkn0717:4187523:4187653 [3] NCCL INFO comm 0x149600008fb0 rank 391 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
133: hkn0510:2761928:2762038 [1] NCCL INFO Channel 00 : 133[4b000] -> 132[31000] via P2P/IPC/read
280: hkn0622:2020412:2020505 [0] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [send] via NET/IBext/0
497: hkn0812:693675:693791 [1] NCCL INFO Connected all trees
133: hkn0510:2761928:2762038 [1] NCCL INFO Channel 01 : 133[4b000] -> 132[31000] via P2P/IPC/read
497: hkn0812:693675:693791 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:693675:693791 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:395016:395129 [0] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [send] via NET/IBext/0
496: hkn0812:693695:693790 [0] NCCL INFO Connected all trees
496: hkn0812:693695:693790 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:693695:693790 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
497: hkn0812:693675:693791 [1] NCCL INFO comm 0x1453b4008fb0 rank 497 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
498: hkn0812:693667:693793 [2] NCCL INFO comm 0x14c078008fb0 rank 498 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
499: hkn0812:693683:693792 [3] NCCL INFO comm 0x1518fc008fb0 rank 499 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
137: hkn0511:3066282:3066391 [1] NCCL INFO Connected all trees
496: hkn0812:693695:693790 [0] NCCL INFO comm 0x1513a8008fb0 rank 496 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
137: hkn0511:3066282:3066391 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
137: hkn0511:3066282:3066391 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
385: hkn0716:108390:108502 [1] NCCL INFO Connected all trees
385: hkn0716:108390:108502 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
385: hkn0716:108390:108502 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
136: hkn0511:3066274:3066392 [0] NCCL INFO Connected all trees
136: hkn0511:3066274:3066392 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3066274:3066392 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:108410:108503 [0] NCCL INFO Connected all trees
120: hkn0507:3186982:3187071 [0] NCCL INFO Connected all trees
384: hkn0716:108410:108503 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
384: hkn0716:108410:108503 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
117: hkn0506:837969:838070 [1] NCCL INFO Channel 00 : 117[4b000] -> 116[31000] via P2P/IPC/read
120: hkn0507:3186982:3187071 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3186982:3187071 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 61: hkn0420:3210101:3210213 [1] NCCL INFO Connected all trees
132: hkn0510:2761944:2762047 [0] NCCL INFO Connected all trees
 61: hkn0420:3210101:3210213 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
132: hkn0510:2761944:2762047 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 61: hkn0420:3210101:3210213 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2761944:2762047 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3066282:3066391 [1] NCCL INFO comm 0x153524008fb0 rank 137 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
385: hkn0716:108390:108502 [1] NCCL INFO comm 0x1474ec008fb0 rank 385 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
138: hkn0511:3066294:3066390 [2] NCCL INFO comm 0x146c44008fb0 rank 138 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 60: hkn0420:3210113:3210211 [0] NCCL INFO Connected all trees
121: hkn0507:3186962:3187062 [1] NCCL INFO Connected all trees
384: hkn0716:108410:108503 [0] NCCL INFO comm 0x14c218008fb0 rank 384 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
139: hkn0511:3066266:3066383 [3] NCCL INFO comm 0x1501f4008fb0 rank 139 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 60: hkn0420:3210113:3210211 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
133: hkn0510:2761928:2762038 [1] NCCL INFO Connected all trees
121: hkn0507:3186962:3187062 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3066274:3066392 [0] NCCL INFO comm 0x151c98008fb0 rank 136 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 60: hkn0420:3210113:3210211 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
121: hkn0507:3186962:3187062 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
133: hkn0510:2761928:2762038 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
133: hkn0510:2761928:2762038 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
129: hkn0509:3124280:3124408 [1] NCCL INFO Connected all trees
386: hkn0716:108398:108509 [2] NCCL INFO comm 0x14599c008fb0 rank 386 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
117: hkn0506:837969:838070 [1] NCCL INFO Channel 01 : 117[4b000] -> 116[31000] via P2P/IPC/read
129: hkn0509:3124280:3124408 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
387: hkn0716:108382:108508 [3] NCCL INFO comm 0x1502d8008fb0 rank 387 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
129: hkn0509:3124280:3124408 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:902581:902700 [0] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [receive] via NET/IBext/0
 61: hkn0420:3210101:3210213 [1] NCCL INFO comm 0x148364008fb0 rank 61 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
121: hkn0507:3186962:3187062 [1] NCCL INFO comm 0x14b444008fb0 rank 121 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 60: hkn0420:3210113:3210211 [0] NCCL INFO comm 0x147280008fb0 rank 60 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
128: hkn0509:3124288:3124402 [0] NCCL INFO Connected all trees
132: hkn0510:2761944:2762047 [0] NCCL INFO comm 0x150648008fb0 rank 132 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
120: hkn0507:3186982:3187071 [0] NCCL INFO comm 0x15155c008fb0 rank 120 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 63: hkn0420:3210091:3210218 [3] NCCL INFO comm 0x1488a0008fb0 rank 63 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
128: hkn0509:3124288:3124402 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
122: hkn0507:3186958:3187070 [2] NCCL INFO comm 0x145fbc008fb0 rank 122 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
128: hkn0509:3124288:3124402 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
123: hkn0507:3186970:3187067 [3] NCCL INFO comm 0x153e20008fb0 rank 123 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 62: hkn0420:3210093:3210219 [2] NCCL INFO comm 0x14dc70008fb0 rank 62 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
134: hkn0510:2761956:2762044 [2] NCCL INFO comm 0x14c778008fb0 rank 134 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
129: hkn0509:3124280:3124408 [1] NCCL INFO comm 0x1483d0008fb0 rank 129 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
128: hkn0509:3124288:3124402 [0] NCCL INFO comm 0x14a0ac008fb0 rank 128 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
130: hkn0509:3124308:3124406 [2] NCCL INFO comm 0x149418008fb0 rank 130 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
131: hkn0509:3124296:3124401 [3] NCCL INFO comm 0x154850008fb0 rank 131 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
117: hkn0506:837969:838070 [1] NCCL INFO Connected all trees
117: hkn0506:837969:838070 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
117: hkn0506:837969:838070 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
116: hkn0506:837949:838063 [0] NCCL INFO Connected all trees
269: hkn0616:404794:404911 [1] NCCL INFO Connected all trees
116: hkn0506:837949:838063 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:837949:838063 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
269: hkn0616:404794:404911 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
269: hkn0616:404794:404911 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:404786:404909 [0] NCCL INFO Connected all trees
117: hkn0506:837969:838070 [1] NCCL INFO comm 0x150a00008fb0 rank 117 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
268: hkn0616:404786:404909 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
268: hkn0616:404786:404909 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
116: hkn0506:837949:838063 [0] NCCL INFO comm 0x145928008fb0 rank 116 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
119: hkn0506:837957:838067 [3] NCCL INFO comm 0x14e788008fb0 rank 119 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
118: hkn0506:837941:838072 [2] NCCL INFO comm 0x150204008fb0 rank 118 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
135: hkn0510:2761936:2762043 [3] NCCL INFO comm 0x151ff8008fb0 rank 135 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
133: hkn0510:2761928:2762038 [1] NCCL INFO comm 0x151304008fb0 rank 133 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
268: hkn0616:404786:404909 [0] NCCL INFO comm 0x1461d4008fb0 rank 268 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
269: hkn0616:404794:404911 [1] NCCL INFO comm 0x14b504008fb0 rank 269 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
505: hkn0815:395028:395124 [1] NCCL INFO Connected all trees
270: hkn0616:404806:404907 [2] NCCL INFO comm 0x154860008fb0 rank 270 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
265: hkn0615:414225:414318 [1] NCCL INFO Channel 00 : 265[4b000] -> 264[31000] via P2P/IPC/read
501: hkn0814:675740:675838 [1] NCCL INFO Channel 00 : 501[4b000] -> 500[31000] via P2P/IPC/read
505: hkn0815:395028:395124 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
280: hkn0622:2020412:2020505 [0] NCCL INFO Connected all trees
271: hkn0616:404778:404908 [3] NCCL INFO comm 0x14fec8008fb0 rank 271 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
505: hkn0815:395028:395124 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2020412:2020505 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
277: hkn0621:1991460:1991584 [1] NCCL INFO Channel 00 : 277[4b000] -> 276[31000] via P2P/IPC/read
280: hkn0622:2020412:2020505 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:395016:395129 [0] NCCL INFO Connected all trees
504: hkn0815:395016:395129 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:395016:395129 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
281: hkn0622:2020392:2020504 [1] NCCL INFO Connected all trees
281: hkn0622:2020392:2020504 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2020392:2020504 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:414225:414318 [1] NCCL INFO Channel 01 : 265[4b000] -> 264[31000] via P2P/IPC/read
501: hkn0814:675740:675838 [1] NCCL INFO Channel 01 : 501[4b000] -> 500[31000] via P2P/IPC/read
 56: hkn0419:1544195:1544301 [0] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [send] via NET/IBext/0
507: hkn0815:395008:395125 [3] NCCL INFO comm 0x14bfa4008fb0 rank 507 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
277: hkn0621:1991460:1991584 [1] NCCL INFO Channel 01 : 277[4b000] -> 276[31000] via P2P/IPC/read
505: hkn0815:395028:395124 [1] NCCL INFO comm 0x14dfc0008fb0 rank 505 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
506: hkn0815:395000:395128 [2] NCCL INFO comm 0x1474e8008fb0 rank 506 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
504: hkn0815:395016:395129 [0] NCCL INFO comm 0x14f090008fb0 rank 504 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 28: hkn0411:2315775:2315872 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [send] via NET/IBext/0
281: hkn0622:2020392:2020504 [1] NCCL INFO comm 0x14639c008fb0 rank 281 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
280: hkn0622:2020412:2020505 [0] NCCL INFO comm 0x1470a8008fb0 rank 280 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
283: hkn0622:2020400:2020511 [3] NCCL INFO comm 0x14c3c4008fb0 rank 283 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
282: hkn0622:2020384:2020510 [2] NCCL INFO comm 0x155100008fb0 rank 282 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
500: hkn0814:675728:675835 [0] NCCL INFO Connected all trees
500: hkn0814:675728:675835 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
276: hkn0621:1991476:1991587 [0] NCCL INFO Connected all trees
276: hkn0621:1991476:1991587 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
500: hkn0814:675728:675835 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
276: hkn0621:1991476:1991587 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:675740:675838 [1] NCCL INFO Connected all trees
277: hkn0621:1991460:1991584 [1] NCCL INFO Connected all trees
501: hkn0814:675740:675838 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
501: hkn0814:675740:675838 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:1991460:1991584 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
277: hkn0621:1991460:1991584 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
500: hkn0814:675728:675835 [0] NCCL INFO comm 0x14c754008fb0 rank 500 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
276: hkn0621:1991476:1991587 [0] NCCL INFO comm 0x152fa0008fb0 rank 276 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
501: hkn0814:675740:675838 [1] NCCL INFO comm 0x152ecc008fb0 rank 501 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
502: hkn0814:675720:675841 [2] NCCL INFO comm 0x14cee4008fb0 rank 502 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
277: hkn0621:1991460:1991584 [1] NCCL INFO comm 0x145e14008fb0 rank 277 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
503: hkn0814:675719:675836 [3] NCCL INFO comm 0x145630008fb0 rank 503 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
278: hkn0621:1991488:1991585 [2] NCCL INFO comm 0x150618008fb0 rank 278 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
279: hkn0621:1991468:1991586 [3] NCCL INFO comm 0x148540008fb0 rank 279 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [send] via NET/IBext/0
264: hkn0615:414213:414324 [0] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [send] via NET/IBext/0
 29: hkn0411:2315755:2315870 [1] NCCL INFO Connected all trees
 56: hkn0419:1544195:1544301 [0] NCCL INFO Connected all trees
 56: hkn0419:1544195:1544301 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 56: hkn0419:1544195:1544301 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2315755:2315870 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 29: hkn0411:2315755:2315870 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:902581:902700 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [send] via NET/IBext/0
 57: hkn0419:1544215:1544300 [1] NCCL INFO Connected all trees
 57: hkn0419:1544215:1544300 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 57: hkn0419:1544215:1544300 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1869083:1869169 [1] NCCL INFO Channel 00 : 53[4b000] -> 52[31000] via P2P/IPC/read
 28: hkn0411:2315775:2315872 [0] NCCL INFO Connected all trees
 28: hkn0411:2315775:2315872 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 28: hkn0411:2315775:2315872 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 56: hkn0419:1544195:1544301 [0] NCCL INFO comm 0x150bdc008fb0 rank 56 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 57: hkn0419:1544215:1544300 [1] NCCL INFO comm 0x14cf3c008fb0 rank 57 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 58: hkn0419:1544203:1544299 [2] NCCL INFO comm 0x14eeb8008fb0 rank 58 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 59: hkn0419:1544187:1544303 [3] NCCL INFO comm 0x148cd8008fb0 rank 59 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 53: hkn0418:1869083:1869169 [1] NCCL INFO Channel 01 : 53[4b000] -> 52[31000] via P2P/IPC/read
 31: hkn0411:2315753:2315871 [3] NCCL INFO comm 0x151ab8008fb0 rank 31 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 30: hkn0411:2315763:2315863 [2] NCCL INFO comm 0x145fec008fb0 rank 30 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 29: hkn0411:2315755:2315870 [1] NCCL INFO comm 0x14de48008fb0 rank 29 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 28: hkn0411:2315775:2315872 [0] NCCL INFO comm 0x14e570008fb0 rank 28 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 52: hkn0418:1869053:1869172 [0] NCCL INFO Connected all trees
 52: hkn0418:1869053:1869172 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1869053:1869172 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1869083:1869169 [1] NCCL INFO Connected all trees
 53: hkn0418:1869083:1869169 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
261: hkn0613:902589:902698 [1] NCCL INFO Channel 00 : 261[4b000] -> 260[31000] via P2P/IPC/read
 53: hkn0418:1869083:1869169 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:414225:414318 [1] NCCL INFO Connected all trees
265: hkn0615:414225:414318 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
265: hkn0615:414225:414318 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 52: hkn0418:1869053:1869172 [0] NCCL INFO comm 0x14d33c008fb0 rank 52 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 53: hkn0418:1869083:1869169 [1] NCCL INFO comm 0x14fbe4008fb0 rank 53 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 55: hkn0418:1869061:1869166 [3] NCCL INFO comm 0x149118008fb0 rank 55 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 54: hkn0418:1869045:1869174 [2] NCCL INFO comm 0x1469bc008fb0 rank 54 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
264: hkn0615:414213:414324 [0] NCCL INFO Connected all trees
264: hkn0615:414213:414324 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
264: hkn0615:414213:414324 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:414225:414318 [1] NCCL INFO comm 0x152d38008fb0 rank 265 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
261: hkn0613:902589:902698 [1] NCCL INFO Channel 01 : 261[4b000] -> 260[31000] via P2P/IPC/read
264: hkn0615:414213:414324 [0] NCCL INFO comm 0x146640008fb0 rank 264 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
267: hkn0615:414197:414325 [3] NCCL INFO comm 0x14fb54008fb0 rank 267 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 24: hkn0410:1159594:1159711 [0] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [send] via NET/IBext/0
266: hkn0615:414205:414319 [2] NCCL INFO comm 0x153e9c008fb0 rank 266 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 12: hkn0407:1816178:1816273 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [send] via NET/IBext/0
261: hkn0613:902589:902698 [1] NCCL INFO Connected all trees
261: hkn0613:902589:902698 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
261: hkn0613:902589:902698 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:902581:902700 [0] NCCL INFO Connected all trees
260: hkn0613:902581:902700 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
260: hkn0613:902581:902700 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
261: hkn0613:902589:902698 [1] NCCL INFO comm 0x15185c008fb0 rank 261 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
260: hkn0613:902581:902700 [0] NCCL INFO comm 0x14d0a8008fb0 rank 260 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
262: hkn0613:902573:902699 [2] NCCL INFO comm 0x155288008fb0 rank 262 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
263: hkn0613:902601:902691 [3] NCCL INFO comm 0x149220008fb0 rank 263 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
256: hkn0612:916852:916975 [0] NCCL INFO Connected all trees
256: hkn0612:916852:916975 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
256: hkn0612:916852:916975 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
257: hkn0612:916860:916982 [1] NCCL INFO Connected all trees
257: hkn0612:916860:916982 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:916860:916982 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [receive] via NET/IBext/0
259: hkn0612:916868:916976 [3] NCCL INFO comm 0x14ca84008fb0 rank 259 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
258: hkn0612:916880:916979 [2] NCCL INFO comm 0x14db90008fb0 rank 258 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
256: hkn0612:916852:916975 [0] NCCL INFO comm 0x14f824008fb0 rank 256 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
257: hkn0612:916860:916982 [1] NCCL INFO comm 0x14db08008fb0 rank 257 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 25: hkn0410:1159614:1159709 [1] NCCL INFO Connected all trees
 25: hkn0410:1159614:1159709 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 25: hkn0410:1159614:1159709 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1159594:1159711 [0] NCCL INFO Connected all trees
 21: hkn0409:2585543:2585692 [1] NCCL INFO Channel 00 : 21[4b000] -> 20[31000] via P2P/IPC/read
 24: hkn0410:1159594:1159711 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 24: hkn0410:1159594:1159711 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1816167:1816272 [1] NCCL INFO Connected all trees
 27: hkn0410:1159586:1159707 [3] NCCL INFO comm 0x14b020008fb0 rank 27 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 13: hkn0407:1816167:1816272 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 26: hkn0410:1159602:1159714 [2] NCCL INFO comm 0x14b190008fb0 rank 26 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 13: hkn0407:1816167:1816272 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1159594:1159711 [0] NCCL INFO comm 0x14cc9c008fb0 rank 24 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 25: hkn0410:1159614:1159709 [1] NCCL INFO comm 0x1453d4008fb0 rank 25 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 21: hkn0409:2585543:2585692 [1] NCCL INFO Channel 01 : 21[4b000] -> 20[31000] via P2P/IPC/read
 12: hkn0407:1816178:1816273 [0] NCCL INFO Connected all trees
 12: hkn0407:1816178:1816273 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 12: hkn0407:1816178:1816273 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1816178:1816273 [0] NCCL INFO comm 0x14ab00008fb0 rank 12 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 15: hkn0407:1816151:1816277 [3] NCCL INFO comm 0x154538008fb0 rank 15 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 13: hkn0407:1816167:1816272 [1] NCCL INFO comm 0x14d044008fb0 rank 13 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 14: hkn0407:1816159:1816274 [2] NCCL INFO comm 0x14c230008fb0 rank 14 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 20: hkn0409:2585552:2585695 [0] NCCL INFO Connected all trees
 20: hkn0409:2585552:2585695 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 00 : 9[4b000] -> 8[31000] via P2P/IPC/read
 20: hkn0409:2585552:2585695 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2585543:2585692 [1] NCCL INFO Connected all trees
 21: hkn0409:2585543:2585692 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 21: hkn0409:2585543:2585692 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3206758:3206903 [1] NCCL INFO Channel 01 : 9[4b000] -> 8[31000] via P2P/IPC/read
 22: hkn0409:2585544:2585697 [2] NCCL INFO comm 0x152db0008fb0 rank 22 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 23: hkn0409:2585564:2585689 [3] NCCL INFO comm 0x145c4c008fb0 rank 23 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 20: hkn0409:2585552:2585695 [0] NCCL INFO comm 0x153938008fb0 rank 20 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 21: hkn0409:2585543:2585692 [1] NCCL INFO comm 0x14b674008fb0 rank 21 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  8: hkn0405:3206750:3206902 [0] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [send] via NET/IBext/0
  4: hkn0404:1339282:1339394 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [send] via NET/IBext/0
  9: hkn0405:3206758:3206903 [1] NCCL INFO Connected all trees
  9: hkn0405:3206758:3206903 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  9: hkn0405:3206758:3206903 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  5: hkn0404:1339266:1339391 [1] NCCL INFO Channel 00 : 5[4b000] -> 4[31000] via P2P/IPC/read
  8: hkn0405:3206750:3206902 [0] NCCL INFO Connected all trees
  8: hkn0405:3206750:3206902 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  8: hkn0405:3206750:3206902 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  8: hkn0405:3206750:3206902 [0] NCCL INFO comm 0x152cac008fb0 rank 8 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 10: hkn0405:3206770:3206895 [2] NCCL INFO comm 0x14c640008fb0 rank 10 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  9: hkn0405:3206758:3206903 [1] NCCL INFO comm 0x14f530008fb0 rank 9 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 11: hkn0405:3206742:3206897 [3] NCCL INFO comm 0x146604008fb0 rank 11 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  5: hkn0404:1339266:1339391 [1] NCCL INFO Channel 01 : 5[4b000] -> 4[31000] via P2P/IPC/read
  4: hkn0404:1339282:1339394 [0] NCCL INFO Connected all trees
  4: hkn0404:1339282:1339394 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1339282:1339394 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  5: hkn0404:1339266:1339391 [1] NCCL INFO Connected all trees
  5: hkn0404:1339266:1339391 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  5: hkn0404:1339266:1339391 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  5: hkn0404:1339266:1339391 [1] NCCL INFO comm 0x15218c008fb0 rank 5 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  7: hkn0404:1339294:1339386 [3] NCCL INFO comm 0x151190008fb0 rank 7 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  4: hkn0404:1339282:1339394 [0] NCCL INFO comm 0x14c480008fb0 rank 4 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  6: hkn0404:1339274:1339395 [2] NCCL INFO comm 0x1542c0008fb0 rank 6 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  1: hkn0403:1763954:1764350 [1] NCCL INFO Connected all trees
  1: hkn0403:1763954:1764350 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  1: hkn0403:1763954:1764350 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1763942:1764342 [0] NCCL INFO Connected all trees
  0: hkn0403:1763942:1764342 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1763942:1764342 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1763942:1764342 [0] NCCL INFO comm 0x147dd8008fb0 rank 0 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  1: hkn0403:1763954:1764350 [1] NCCL INFO comm 0x14ab54008fb0 rank 1 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  3: hkn0403:1763926:1764349 [3] NCCL INFO comm 0x145a94008fb0 rank 3 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  2: hkn0403:1763934:1764351 [2] NCCL INFO comm 0x147a08008fb0 rank 2 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  0: hkn0403:1763942:1763942 [0] NCCL INFO Launch mode Parallel
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078818, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "deepcam", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 55}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078890, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HelmholtzAI", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 58}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078891, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 61}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078891, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 64}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078891, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "HoreKa", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 67}}
385: hdf5!!
  3: hdf5!!
410: hdf5!!
496: hdf5!!
 65: hdf5!!
115: hdf5!!
419: hdf5!!
238: hdf5!!
314: hdf5!!
322: hdf5!!
465: hdf5!!
 81: hdf5!!
 44: hdf5!!
227: hdf5!!
  1: hdf5!!
 39: hdf5!!
168: hdf5!!
373: hdf5!!
475: hdf5!!
413: hdf5!!
208: hdf5!!
449: hdf5!!
173: hdf5!!
341: hdf5!!
461: hdf5!!
248: hdf5!!
176: hdf5!!
346: hdf5!!
336: hdf5!!
277: hdf5!!
 87: hdf5!!
 98: hdf5!!
349: hdf5!!
268: hdf5!!
384: hdf5!!
325: hdf5!!
 50: hdf5!!
291: hdf5!!
313: hdf5!!
359: hdf5!!
107: hdf5!!
116: hdf5!!
371: hdf5!!
420: hdf5!!
509: hdf5!!
442: hdf5!!
477: hdf5!!
464: hdf5!!
501: hdf5!!
143: hdf5!!
393: hdf5!!
488: hdf5!!
 45: hdf5!!
262: hdf5!!
129: hdf5!!
224: hdf5!!
  2: hdf5!!
122: hdf5!!
219: hdf5!!
171: hdf5!!
254: hdf5!!
432: hdf5!!
374: hdf5!!
240: hdf5!!
415: hdf5!!
498: hdf5!!
 41: hdf5!!
233: hdf5!!
101: hdf5!!
448: hdf5!!
151: hdf5!!
 66: hdf5!!
342: hdf5!!
378: hdf5!!
185: hdf5!!
258: hdf5!!
136: hdf5!!
316: hdf5!!
247: hdf5!!
417: hdf5!!
286: hdf5!!
189: hdf5!!
250: hdf5!!
383: hdf5!!
202: hdf5!!
177: hdf5!!
215: hdf5!!
347: hdf5!!
152: hdf5!!
 60: hdf5!!
339: hdf5!!
505: hdf5!!
278: hdf5!!
397: hdf5!!
158: hdf5!!
 72: hdf5!!
134: hdf5!!
 85: hdf5!!
 99: hdf5!!
350: hdf5!!
228: hdf5!!
270: hdf5!!
161: hdf5!!
126: hdf5!!
403: hdf5!!
352: hdf5!!
330: hdf5!!
 78: hdf5!!
 90: hdf5!!
386: hdf5!!
180: hdf5!!
326: hdf5!!
 48: hdf5!!
290: hdf5!!
310: hdf5!!
356: hdf5!!
105: hdf5!!
321: hdf5!!
486: hdf5!!
422: hdf5!!
480: hdf5!!
511: hdf5!!
439: hdf5!!
440: hdf5!!
453: hdf5!!
456: hdf5!!
479: hdf5!!
467: hdf5!!
503: hdf5!!
142: hdf5!!
392: hdf5!!
 83: hdf5!!
 34: hdf5!!
489: hdf5!!
 46: hdf5!!
261: hdf5!!
130: hdf5!!
225: hdf5!!
165: hdf5!!
 69: hdf5!!
492: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078891, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 98}}
 13: hdf5!!
409: hdf5!!
123: hdf5!!
 37: hdf5!!
446: hdf5!!
217: hdf5!!
169: hdf5!!
253: hdf5!!
204: hdf5!!
435: hdf5!!
375: hdf5!!
241: hdf5!!
427: hdf5!!
472: hdf5!!
412: hdf5!!
499: hdf5!!
211: hdf5!!
 18: hdf5!!
 40: hdf5!!
234: hdf5!!
222: hdf5!!
100: hdf5!!
451: hdf5!!
174: hdf5!!
150: hdf5!!
388: hdf5!!
 64: hdf5!!
112: hdf5!!
340: hdf5!!
377: hdf5!!
460: hdf5!!
  5: hdf5!!
 52: hdf5!!
186: hdf5!!
259: hdf5!!
138: hdf5!!
319: hdf5!!
364: hdf5!!
293: hdf5!!
306: hdf5!!
246: hdf5!!
 58: hdf5!!
418: hdf5!!
239: hdf5!!
287: hdf5!!
190: hdf5!!
404: hdf5!!
249: hdf5!!
380: hdf5!!
333: hdf5!!
203: hdf5!!
179: hdf5!!
 94: hdf5!!
213: hdf5!!
344: hdf5!!
154: hdf5!!
 61: hdf5!!
337: hdf5!!
504: hdf5!!
276: hdf5!!
 27: hdf5!!
396: hdf5!!
157: hdf5!!
 74: hdf5!!
193: hdf5!!
133: hdf5!!
360: hdf5!!
 84: hdf5!!
 96: hdf5!!
348: hdf5!!
229: hdf5!!
280: hdf5!!
271: hdf5!!
162: hdf5!!
127: hdf5!!
400: hdf5!!
355: hdf5!!
331: hdf5!!
199: hdf5!!
 79: hdf5!!
 88: hdf5!!
145: hdf5!!
387: hdf5!!
109: hdf5!!
183: hdf5!!
327: hdf5!!
 49: hdf5!!
265: hdf5!!
300: hdf5!!
288: hdf5!!
315: hdf5!!
311: hdf5!!
358: hdf5!!
296: hdf5!!
272: hdf5!!
104: hdf5!!
119: hdf5!!
370: hdf5!!
323: hdf5!!
485: hdf5!!
421: hdf5!!
481: hdf5!!
510: hdf5!!
436: hdf5!!
441: hdf5!!
454: hdf5!!
457: hdf5!!
429: hdf5!!
478: hdf5!!
466: hdf5!!
500: hdf5!!
141: hdf5!!
394: hdf5!!
 80: hdf5!!
 35: hdf5!!
490: hdf5!!
 23: hdf5!!
 47: hdf5!!
260: hdf5!!
128: hdf5!!
226: hdf5!!
166: hdf5!!
 70: hdf5!!
493: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078891, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 99}}
 15: hdf5!!
411: hdf5!!
121: hdf5!!
468: hdf5!!
 38: hdf5!!
447: hdf5!!
218: hdf5!!
170: hdf5!!
252: hdf5!!
205: hdf5!!
434: hdf5!!
372: hdf5!!
243: hdf5!!
424: hdf5!!
473: hdf5!!
414: hdf5!!
210: hdf5!!
 29: hdf5!!
 19: hdf5!!
 42: hdf5!!
232: hdf5!!
220: hdf5!!
102: hdf5!!
450: hdf5!!
175: hdf5!!
148: hdf5!!
390: hdf5!!
 67: hdf5!!
113: hdf5!!
343: hdf5!!
379: hdf5!!
462: hdf5!!
  4: hdf5!!
 54: hdf5!!
187: hdf5!!
257: hdf5!!
137: hdf5!!
318: hdf5!!
365: hdf5!!
295: hdf5!!
305: hdf5!!
245: hdf5!!
 59: hdf5!!
416: hdf5!!
236: hdf5!!
285: hdf5!!
191: hdf5!!
405: hdf5!!
251: hdf5!!
381: hdf5!!
335: hdf5!!
200: hdf5!!
178: hdf5!!
 95: hdf5!!
214: hdf5!!
345: hdf5!!
153: hdf5!!
 63: hdf5!!
338: hdf5!!
506: hdf5!!
279: hdf5!!
 26: hdf5!!
398: hdf5!!
156: hdf5!!
 73: hdf5!!
194: hdf5!!
132: hdf5!!
362: hdf5!!
 97: hdf5!!
351: hdf5!!
230: hdf5!!
281: hdf5!!
269: hdf5!!
163: hdf5!!
124: hdf5!!
402: hdf5!!
353: hdf5!!
328: hdf5!!
197: hdf5!!
 76: hdf5!!
 89: hdf5!!
147: hdf5!!
110: hdf5!!
181: hdf5!!
324: hdf5!!
 51: hdf5!!
266: hdf5!!
302: hdf5!!
289: hdf5!!
312: hdf5!!
309: hdf5!!
357: hdf5!!
297: hdf5!!
273: hdf5!!
106: hdf5!!
  8: hdf5!!
117: hdf5!!
369: hdf5!!
320: hdf5!!
487: hdf5!!
423: hdf5!!
482: hdf5!!
508: hdf5!!
438: hdf5!!
443: hdf5!!
452: hdf5!!
458: hdf5!!
430: hdf5!!
476: hdf5!!
502: hdf5!!
140: hdf5!!
395: hdf5!!
 82: hdf5!!
 32: hdf5!!
491: hdf5!!
 22: hdf5!!
263: hdf5!!
131: hdf5!!
164: hdf5!!
 71: hdf5!!
495: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414078892, "event_type": "POINT_IN_TIME", "key": "seed", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 103}}
 12: hdf5!!
408: hdf5!!
120: hdf5!!
470: hdf5!!
 36: hdf5!!
444: hdf5!!
216: hdf5!!
255: hdf5!!
207: hdf5!!
433: hdf5!!
426: hdf5!!
474: hdf5!!
209: hdf5!!
 31: hdf5!!
 17: hdf5!!
 43: hdf5!!
235: hdf5!!
221: hdf5!!
103: hdf5!!
172: hdf5!!
149: hdf5!!
391: hdf5!!
114: hdf5!!
376: hdf5!!
463: hdf5!!
  7: hdf5!!
 55: hdf5!!
184: hdf5!!
256: hdf5!!
139: hdf5!!
317: hdf5!!
366: hdf5!!
294: hdf5!!
304: hdf5!!
244: hdf5!!
 57: hdf5!!
237: hdf5!!
188: hdf5!!
407: hdf5!!
382: hdf5!!
332: hdf5!!
201: hdf5!!
 93: hdf5!!
212: hdf5!!
155: hdf5!!
 62: hdf5!!
507: hdf5!!
 25: hdf5!!
399: hdf5!!
159: hdf5!!
 75: hdf5!!
195: hdf5!!
135: hdf5!!
363: hdf5!!
 86: hdf5!!
231: hdf5!!
283: hdf5!!
160: hdf5!!
125: hdf5!!
401: hdf5!!
354: hdf5!!
329: hdf5!!
196: hdf5!!
 77: hdf5!!
 91: hdf5!!
146: hdf5!!
111: hdf5!!
182: hdf5!!
267: hdf5!!
303: hdf5!!
308: hdf5!!
299: hdf5!!
274: hdf5!!
  9: hdf5!!
118: hdf5!!
368: hdf5!!
484: hdf5!!
483: hdf5!!
437: hdf5!!
455: hdf5!!
459: hdf5!!
431: hdf5!!
 33: hdf5!!
 21: hdf5!!
 68: hdf5!!
494: hdf5!!
  0: hdf5!!
 14: hdf5!!
471: hdf5!!
445: hdf5!!
206: hdf5!!
425: hdf5!!
 28: hdf5!!
 16: hdf5!!
223: hdf5!!
  6: hdf5!!
 53: hdf5!!
367: hdf5!!
307: hdf5!!
 56: hdf5!!
284: hdf5!!
406: hdf5!!
334: hdf5!!
 92: hdf5!!
 24: hdf5!!
192: hdf5!!
361: hdf5!!
282: hdf5!!
198: hdf5!!
144: hdf5!!
108: hdf5!!
264: hdf5!!
301: hdf5!!
298: hdf5!!
275: hdf5!!
 10: hdf5!!
428: hdf5!!
 20: hdf5!!
469: hdf5!!
 30: hdf5!!
389: hdf5!!
 11: hdf5!!
497: hdf5!!
292: hdf5!!
167: hdf5!!
242: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
162: root_dir: /tmp/deepcam/instance0
159: root_dir: /tmp/deepcam/instance0
442: root_dir: /tmp/deepcam/instance0
102: root_dir: /tmp/deepcam/instance0
491: root_dir: /tmp/deepcam/instance0
 10: root_dir: /tmp/deepcam/instance0
421: root_dir: /tmp/deepcam/instance0
 52: root_dir: /tmp/deepcam/instance0
 61: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
137: root_dir: /tmp/deepcam/instance0
128: root_dir: /tmp/deepcam/instance0
170: root_dir: /tmp/deepcam/instance0
289: root_dir: /tmp/deepcam/instance0
477: root_dir: /tmp/deepcam/instance0
497: root_dir: /tmp/deepcam/instance0
340: root_dir: /tmp/deepcam/instance0
 58: root_dir: /tmp/deepcam/instance0
405: root_dir: /tmp/deepcam/instance0
124: root_dir: /tmp/deepcam/instance0
147: root_dir: /tmp/deepcam/instance0
309: root_dir: /tmp/deepcam/instance0
183: root_dir: /tmp/deepcam/instance0
403: root_dir: /tmp/deepcam/instance0
473: root_dir: /tmp/deepcam/instance0
358: root_dir: /tmp/deepcam/instance0
235: root_dir: /tmp/deepcam/instance0
404: root_dir: /tmp/deepcam/instance0
131: root_dir: /tmp/deepcam/instance0
186: root_dir: /tmp/deepcam/instance0
352: root_dir: /tmp/deepcam/instance0
177: root_dir: /tmp/deepcam/instance0
  6: root_dir: /tmp/deepcam/instance0
496: root_dir: /tmp/deepcam/instance0
 31: root_dir: /tmp/deepcam/instance0
150: root_dir: /tmp/deepcam/instance0
482: root_dir: /tmp/deepcam/instance0
452: root_dir: /tmp/deepcam/instance0
 78: root_dir: /tmp/deepcam/instance0
153: root_dir: /tmp/deepcam/instance0
355: root_dir: /tmp/deepcam/instance0
 88: root_dir: /tmp/deepcam/instance0
416: root_dir: /tmp/deepcam/instance0
151: root_dir: /tmp/deepcam/instance0
308: root_dir: /tmp/deepcam/instance0
290: root_dir: /tmp/deepcam/instance0
419: root_dir: /tmp/deepcam/instance0
380: root_dir: /tmp/deepcam/instance0
439: root_dir: /tmp/deepcam/instance0
389: root_dir: /tmp/deepcam/instance0
 32: root_dir: /tmp/deepcam/instance0
120: root_dir: /tmp/deepcam/instance0
173: root_dir: /tmp/deepcam/instance0
498: root_dir: /tmp/deepcam/instance0
 38: root_dir: /tmp/deepcam/instance0
375: root_dir: /tmp/deepcam/instance0
143: root_dir: /tmp/deepcam/instance0
323: root_dir: /tmp/deepcam/instance0
126: root_dir: /tmp/deepcam/instance0
483: root_dir: /tmp/deepcam/instance0
211: root_dir: /tmp/deepcam/instance0
415: root_dir: /tmp/deepcam/instance0
 56: root_dir: /tmp/deepcam/instance0
237: root_dir: /tmp/deepcam/instance0
449: root_dir: /tmp/deepcam/instance0
 76: root_dir: /tmp/deepcam/instance0
465: root_dir: /tmp/deepcam/instance0
 84: root_dir: /tmp/deepcam/instance0
 44: root_dir: /tmp/deepcam/instance0
263: root_dir: /tmp/deepcam/instance0
 13: root_dir: /tmp/deepcam/instance0
 33: root_dir: /tmp/deepcam/instance0
 85: root_dir: /tmp/deepcam/instance0
411: root_dir: /tmp/deepcam/instance0
 91: root_dir: /tmp/deepcam/instance0
332: root_dir: /tmp/deepcam/instance0
 40: root_dir: /tmp/deepcam/instance0
505: root_dir: /tmp/deepcam/instance0
430: root_dir: /tmp/deepcam/instance0
312: root_dir: /tmp/deepcam/instance0
 96: root_dir: /tmp/deepcam/instance0
436: root_dir: /tmp/deepcam/instance0
249: root_dir: /tmp/deepcam/instance0
 64: root_dir: /tmp/deepcam/instance0
 46: root_dir: /tmp/deepcam/instance0
329: root_dir: /tmp/deepcam/instance0
165: root_dir: /tmp/deepcam/instance0
  5: root_dir: /tmp/deepcam/instance0
264: root_dir: /tmp/deepcam/instance0
244: root_dir: /tmp/deepcam/instance0
387: root_dir: /tmp/deepcam/instance0
 48: root_dir: /tmp/deepcam/instance0
190: root_dir: /tmp/deepcam/instance0
455: root_dir: /tmp/deepcam/instance0
501: root_dir: /tmp/deepcam/instance0
242: root_dir: /tmp/deepcam/instance0
447: root_dir: /tmp/deepcam/instance0
123: root_dir: /tmp/deepcam/instance0
 30: root_dir: /tmp/deepcam/instance0
 73: root_dir: /tmp/deepcam/instance0
 69: root_dir: /tmp/deepcam/instance0
321: root_dir: /tmp/deepcam/instance0
511: root_dir: /tmp/deepcam/instance0
 14: root_dir: /tmp/deepcam/instance0
412: root_dir: /tmp/deepcam/instance0
 27: root_dir: /tmp/deepcam/instance0
 74: root_dir: /tmp/deepcam/instance0
 21: root_dir: /tmp/deepcam/instance0
 25: root_dir: /tmp/deepcam/instance0
110: root_dir: /tmp/deepcam/instance0
274: root_dir: /tmp/deepcam/instance0
154: root_dir: /tmp/deepcam/instance0
 92: root_dir: /tmp/deepcam/instance0
486: root_dir: /tmp/deepcam/instance0
 45: root_dir: /tmp/deepcam/instance0
281: root_dir: /tmp/deepcam/instance0
194: root_dir: /tmp/deepcam/instance0
250: root_dir: /tmp/deepcam/instance0
379: root_dir: /tmp/deepcam/instance0
168: root_dir: /tmp/deepcam/instance0
469: root_dir: /tmp/deepcam/instance0
301: root_dir: /tmp/deepcam/instance0
254: root_dir: /tmp/deepcam/instance0
 22: root_dir: /tmp/deepcam/instance0
446: root_dir: /tmp/deepcam/instance0
207: root_dir: /tmp/deepcam/instance0
240: root_dir: /tmp/deepcam/instance0
388: root_dir: /tmp/deepcam/instance0
258: root_dir: /tmp/deepcam/instance0
366: root_dir: /tmp/deepcam/instance0
176: root_dir: /tmp/deepcam/instance0
326: root_dir: /tmp/deepcam/instance0
456: root_dir: /tmp/deepcam/instance0
467: root_dir: /tmp/deepcam/instance0
487: root_dir: /tmp/deepcam/instance0
287: root_dir: /tmp/deepcam/instance0
492: root_dir: /tmp/deepcam/instance0
424: root_dir: /tmp/deepcam/instance0
347: root_dir: /tmp/deepcam/instance0
257: root_dir: /tmp/deepcam/instance0
208: root_dir: /tmp/deepcam/instance0
493: root_dir: /tmp/deepcam/instance0
275: root_dir: /tmp/deepcam/instance0
261: root_dir: /tmp/deepcam/instance0
104: root_dir: /tmp/deepcam/instance0
349: root_dir: /tmp/deepcam/instance0
 86: root_dir: /tmp/deepcam/instance0
509: root_dir: /tmp/deepcam/instance0
198: root_dir: /tmp/deepcam/instance0
205: root_dir: /tmp/deepcam/instance0
166: root_dir: /tmp/deepcam/instance0
197: root_dir: /tmp/deepcam/instance0
457: root_dir: /tmp/deepcam/instance0
361: root_dir: /tmp/deepcam/instance0
119: root_dir: /tmp/deepcam/instance0
238: root_dir: /tmp/deepcam/instance0
464: root_dir: /tmp/deepcam/instance0
217: root_dir: /tmp/deepcam/instance0
294: root_dir: /tmp/deepcam/instance0
252: root_dir: /tmp/deepcam/instance0
348: root_dir: /tmp/deepcam/instance0
432: root_dir: /tmp/deepcam/instance0
 17: root_dir: /tmp/deepcam/instance0
485: root_dir: /tmp/deepcam/instance0
435: root_dir: /tmp/deepcam/instance0
116: root_dir: /tmp/deepcam/instance0
454: root_dir: /tmp/deepcam/instance0
167: root_dir: /tmp/deepcam/instance0
346: root_dir: /tmp/deepcam/instance0
472: root_dir: /tmp/deepcam/instance0
 16: root_dir: /tmp/deepcam/instance0
313: root_dir: /tmp/deepcam/instance0
 83: root_dir: /tmp/deepcam/instance0
378: root_dir: /tmp/deepcam/instance0
471: root_dir: /tmp/deepcam/instance0
175: root_dir: /tmp/deepcam/instance0
189: root_dir: /tmp/deepcam/instance0
 34: root_dir: /tmp/deepcam/instance0
266: root_dir: /tmp/deepcam/instance0
461: root_dir: /tmp/deepcam/instance0
285: root_dir: /tmp/deepcam/instance0
112: root_dir: /tmp/deepcam/instance0
192: root_dir: /tmp/deepcam/instance0
212: root_dir: /tmp/deepcam/instance0
195: root_dir: /tmp/deepcam/instance0
141: root_dir: /tmp/deepcam/instance0
295: root_dir: /tmp/deepcam/instance0
226: root_dir: /tmp/deepcam/instance0
215: root_dir: /tmp/deepcam/instance0
503: root_dir: /tmp/deepcam/instance0
130: root_dir: /tmp/deepcam/instance0
255: root_dir: /tmp/deepcam/instance0
260: root_dir: /tmp/deepcam/instance0
243: root_dir: /tmp/deepcam/instance0
222: root_dir: /tmp/deepcam/instance0
202: root_dir: /tmp/deepcam/instance0
305: root_dir: /tmp/deepcam/instance0
319: root_dir: /tmp/deepcam/instance0
510: root_dir: /tmp/deepcam/instance0
351: root_dir: /tmp/deepcam/instance0
425: root_dir: /tmp/deepcam/instance0
460: root_dir: /tmp/deepcam/instance0
 99: root_dir: /tmp/deepcam/instance0
149: root_dir: /tmp/deepcam/instance0
216: root_dir: /tmp/deepcam/instance0
339: root_dir: /tmp/deepcam/instance0
304: root_dir: /tmp/deepcam/instance0
267: root_dir: /tmp/deepcam/instance0
268: root_dir: /tmp/deepcam/instance0
269: root_dir: /tmp/deepcam/instance0
 77: root_dir: /tmp/deepcam/instance0
193: root_dir: /tmp/deepcam/instance0
433: root_dir: /tmp/deepcam/instance0
297: root_dir: /tmp/deepcam/instance0
368: root_dir: /tmp/deepcam/instance0
385: root_dir: /tmp/deepcam/instance0
133: root_dir: /tmp/deepcam/instance0
273: root_dir: /tmp/deepcam/instance0
344: root_dir: /tmp/deepcam/instance0
200: root_dir: /tmp/deepcam/instance0
105: root_dir: /tmp/deepcam/instance0
225: root_dir: /tmp/deepcam/instance0
247: root_dir: /tmp/deepcam/instance0
342: root_dir: /tmp/deepcam/instance0
229: root_dir: /tmp/deepcam/instance0
230: root_dir: /tmp/deepcam/instance0
306: root_dir: /tmp/deepcam/instance0
314: root_dir: /tmp/deepcam/instance0
201: root_dir: /tmp/deepcam/instance0
203: root_dir: /tmp/deepcam/instance0
188: root_dir: /tmp/deepcam/instance0
427: root_dir: /tmp/deepcam/instance0
298: root_dir: /tmp/deepcam/instance0
376: root_dir: /tmp/deepcam/instance0
299: root_dir: /tmp/deepcam/instance0
397: root_dir: /tmp/deepcam/instance0
335: root_dir: /tmp/deepcam/instance0
155: root_dir: /tmp/deepcam/instance0
434: root_dir: /tmp/deepcam/instance0
276: root_dir: /tmp/deepcam/instance0
204: root_dir: /tmp/deepcam/instance0
220: root_dir: /tmp/deepcam/instance0
  2: root_dir: /tmp/deepcam/instance0
377: root_dir: /tmp/deepcam/instance0
224: root_dir: /tmp/deepcam/instance0
279: root_dir: /tmp/deepcam/instance0
184: root_dir: /tmp/deepcam/instance0
399: root_dir: /tmp/deepcam/instance0
417: root_dir: /tmp/deepcam/instance0
239: root_dir: /tmp/deepcam/instance0
270: root_dir: /tmp/deepcam/instance0
292: root_dir: /tmp/deepcam/instance0
303: root_dir: /tmp/deepcam/instance0
426: root_dir: /tmp/deepcam/instance0
106: root_dir: /tmp/deepcam/instance0
213: root_dir: /tmp/deepcam/instance0
277: root_dir: /tmp/deepcam/instance0
362: root_dir: /tmp/deepcam/instance0
438: root_dir: /tmp/deepcam/instance0
494: root_dir: /tmp/deepcam/instance0
382: root_dir: /tmp/deepcam/instance0
280: root_dir: /tmp/deepcam/instance0
109: root_dir: /tmp/deepcam/instance0
 97: root_dir: /tmp/deepcam/instance0
369: root_dir: /tmp/deepcam/instance0
214: root_dir: /tmp/deepcam/instance0
107: root_dir: /tmp/deepcam/instance0
181: root_dir: /tmp/deepcam/instance0
  3: root_dir: /tmp/deepcam/instance0
284: root_dir: /tmp/deepcam/instance0
495: root_dir: /tmp/deepcam/instance0
307: root_dir: /tmp/deepcam/instance0
 82: root_dir: /tmp/deepcam/instance0
345: root_dir: /tmp/deepcam/instance0
398: root_dir: /tmp/deepcam/instance0
293: root_dir: /tmp/deepcam/instance0
318: root_dir: /tmp/deepcam/instance0
507: root_dir: /tmp/deepcam/instance0
  1: root_dir: /tmp/deepcam/instance0
221: root_dir: /tmp/deepcam/instance0
 42: root_dir: /tmp/deepcam/instance0
296: root_dir: /tmp/deepcam/instance0
223: root_dir: /tmp/deepcam/instance0
 36: root_dir: /tmp/deepcam/instance0
185: root_dir: /tmp/deepcam/instance0
470: root_dir: /tmp/deepcam/instance0
381: root_dir: /tmp/deepcam/instance0
474: root_dir: /tmp/deepcam/instance0
428: root_dir: /tmp/deepcam/instance0
228: root_dir: /tmp/deepcam/instance0
 71: root_dir: /tmp/deepcam/instance0
 19: root_dir: /tmp/deepcam/instance0
383: root_dir: /tmp/deepcam/instance0
325: root_dir: /tmp/deepcam/instance0
402: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
302: root_dir: /tmp/deepcam/instance0
187: root_dir: /tmp/deepcam/instance0
334: root_dir: /tmp/deepcam/instance0
328: root_dir: /tmp/deepcam/instance0
350: root_dir: /tmp/deepcam/instance0
114: root_dir: /tmp/deepcam/instance0
 35: root_dir: /tmp/deepcam/instance0
458: root_dir: /tmp/deepcam/instance0
443: root_dir: /tmp/deepcam/instance0
499: root_dir: /tmp/deepcam/instance0
251: root_dir: /tmp/deepcam/instance0
182: root_dir: /tmp/deepcam/instance0
  0: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164129, "event_type": "POINT_IN_TIME", "key": "number_of_ranks", "value": 512, "metadata": {"file": "./train_instance.py", "lineno": 211}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164129, "event_type": "POINT_IN_TIME", "key": "number_of_nodes", "value": 128, "metadata": {"file": "./train_instance.py", "lineno": 212}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164129, "event_type": "POINT_IN_TIME", "key": "accelerators_per_node", "value": 4, "metadata": {"file": "./train_instance.py", "lineno": 213}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "instance_id", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 215}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "checkpoint", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 217}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "./train_instance.py", "lineno": 218}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "batchnorm_group_size", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 219}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_frequency", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "data_format", "value": "dali-numpy/hdf5", "metadata": {"file": "./train_instance.py", "lineno": 222}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "shuffle_mode", "value": "global", "metadata": {"file": "./train_instance.py", "lineno": 223}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164130, "event_type": "POINT_IN_TIME", "key": "data_oversampling_factor", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 224}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164135, "event_type": "POINT_IN_TIME", "key": "stage_dir_prefix", "value": "/tmp/deepcam", "metadata": {"file": "./train_instance.py", "lineno": 226}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164135, "event_type": "POINT_IN_TIME", "key": "stage_mode", "value": "node", "metadata": {"file": "./train_instance.py", "lineno": 227}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164135, "event_type": "POINT_IN_TIME", "key": "stage_batch_size", "value": -1, "metadata": {"file": "./train_instance.py", "lineno": 228}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164135, "event_type": "POINT_IN_TIME", "key": "stage_verify", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 229}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164136, "event_type": "POINT_IN_TIME", "key": "stage_full_data_per_node", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164136, "event_type": "POINT_IN_TIME", "key": "stage_use_direct_io", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 231}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164136, "event_type": "POINT_IN_TIME", "key": "precision_mode", "value": "amp", "metadata": {"file": "./train_instance.py", "lineno": 233}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164136, "event_type": "POINT_IN_TIME", "key": "enable_nhwc", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 234}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164136, "event_type": "POINT_IN_TIME", "key": "enable_graph", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 235}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164136, "event_type": "POINT_IN_TIME", "key": "enable_jit", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164136, "event_type": "POINT_IN_TIME", "key": "disable_comm_overlap", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 237}}
  0: Constructing DeepLabv3+ model...
  0: Number of output channels: 3
  0: Output stride: 16
  0: Number of Input Channels: 16
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164853, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "LAMB", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 144}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164853, "event_type": "POINT_IN_TIME", "key": "opt_lr", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164853, "event_type": "POINT_IN_TIME", "key": "opt_bias_correction", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164853, "event_type": "POINT_IN_TIME", "key": "opt_betas", "value": [0.9, 0.999], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164854, "event_type": "POINT_IN_TIME", "key": "opt_eps", "value": 1e-06, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164854, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.01, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164854, "event_type": "POINT_IN_TIME", "key": "opt_grad_averaging", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164854, "event_type": "POINT_IN_TIME", "key": "opt_max_grad_norm", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164855, "event_type": "POINT_IN_TIME", "key": "scheduler_type", "value": "multistep", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164855, "event_type": "POINT_IN_TIME", "key": "scheduler_milestones", "value": [1100, 4096], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164855, "event_type": "POINT_IN_TIME", "key": "scheduler_decay_rate", "value": 0.1, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164855, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_steps", "value": 200, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414164855, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_factor", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: DeepLabv3_plus(
  0:   (xception_features): Xception(
  0:     (relu): ReLU()
  0:     (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  0:     (bn1): Sequential(
  0:       (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:     (bn2): Sequential(
  0:       (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (block1): Block(
  0:       (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
  0:           (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Seque
  0: ntial(
  0:           (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block2): Block(
  0:       (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1):
  0:  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block3): Block(
  0:       (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), 
  0: bias=False)
  0:       (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (2): ReLU()
  0:         (3): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (5): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2
  0: d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block4): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size
  0: =(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block5): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm
  0: 2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block6): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), 
  0: padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block7): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, mome
  0: ntum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block8): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=
  0: 728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block
  0: 9): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d
  0: (728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block10): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU
  0: ()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block11): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_siz
  0: e=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block12): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (
  0: 2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block13): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1
  0: ), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block14): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_s
  0: ame(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchN
  0: orm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block15): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kern
  0: el_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block16): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): B
  0: atchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block17): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), strid
  0: e=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block18): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1
  0: e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block19): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 
  0: 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0: 
  0:     (block20): Block(
  0:       (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:        
  0:    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
  0:           (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (conv3): SeparableConv2d_same(
  0:       (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1024, bias=False)
  0:       (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn3): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv4): SeparableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn4): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv5): Separ
  0: ableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn5): Sequential(
  0:       (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (bottleneck): Bottleneck(
  0:     (aspp1): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp2): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp3): ASPP_module(
  0:       (atrous_co
  0: nvolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp4): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (global_avg_pool): GlobalAveragePool(
  0:       (global_average_pool): Sequential(
  0:         (0): AdaptiveAvgPool2d(output_size=(1, 1))
  0:         (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         (2): TrainableAffine()
  0:         (3): ReLU(inplace=True)
  0:       )
  0:     )
  0:     (tiling): Tiling()
  0:     (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     (bn): Sequential(
  0:       (0): BatchNorm2d(256, eps=1e-05, 
  0: momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (conv2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:   (bn2): Sequential(
  0:     (0): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:     (1): ReLU()
  0:   )
  0:   (upsample): DeconvUpsampler(
  0:     (deconv1): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (conv1): Sequential(
  0:       (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0: 
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  0:     )
  0:     (deconv2): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (last_deconv): Sequential(
  0:       (0): ConvTranspose2d(256, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:     )
  0:   )
  0: )
  0: Number of trainable parameters: 56454720
  0: Creating Dataloaders
256: root_dir: /tmp/deepcam/instance0
357: root_dir: /tmp/deepcam/instance0
364: root_dir: /tmp/deepcam/instance0
 75: root_dir: /tmp/deepcam/instance0
272: root_dir: /tmp/deepcam/instance0
136: root_dir: /tmp/deepcam/instance0
490: root_dir: /tmp/deepcam/instance0
129: root_dir: /tmp/deepcam/instance0
374: root_dir: /tmp/deepcam/instance0
253: root_dir: /tmp/deepcam/instance0
394: root_dir: /tmp/deepcam/instance0
 59: root_dir: /tmp/deepcam/instance0
508: root_dir: /tmp/deepcam/instance0
 12: root_dir: /tmp/deepcam/instance0
333: root_dir: /tmp/deepcam/instance0
118: root_dir: /tmp/deepcam/instance0
360: root_dir: /tmp/deepcam/instance0
 62: root_dir: /tmp/deepcam/instance0
444: root_dir: /tmp/deepcam/instance0
371: root_dir: /tmp/deepcam/instance0
 66: root_dir: /tmp/deepcam/instance0
132: root_dir: /tmp/deepcam/instance0
414: root_dir: /tmp/deepcam/instance0
236: root_dir: /tmp/deepcam/instance0
134: root_dir: /tmp/deepcam/instance0
 11: root_dir: /tmp/deepcam/instance0
164: root_dir: /tmp/deepcam/instance0
 95: root_dir: /tmp/deepcam/instance0
 29: root_dir: /tmp/deepcam/instance0
384: root_dir: /tmp/deepcam/instance0
462: root_dir: /tmp/deepcam/instance0
163: root_dir: /tmp/deepcam/instance0
429: root_dir: /tmp/deepcam/instance0
392: root_dir: /tmp/deepcam/instance0
206: root_dir: /tmp/deepcam/instance0
121: root_dir: /tmp/deepcam/instance0
440: root_dir: /tmp/deepcam/instance0
396: root_dir: /tmp/deepcam/instance0
 87: root_dir: /tmp/deepcam/instance0
 65: root_dir: /tmp/deepcam/instance0
 98: root_dir: /tmp/deepcam/instance0
506: root_dir: /tmp/deepcam/instance0
327: root_dir: /tmp/deepcam/instance0
475: root_dir: /tmp/deepcam/instance0
158: root_dir: /tmp/deepcam/instance0
234: root_dir: /tmp/deepcam/instance0
286: root_dir: /tmp/deepcam/instance0
246: root_dir: /tmp/deepcam/instance0
156: root_dir: /tmp/deepcam/instance0
395: root_dir: /tmp/deepcam/instance0
341: root_dir: /tmp/deepcam/instance0
359: root_dir: /tmp/deepcam/instance0
218: root_dir: /tmp/deepcam/instance0
468: root_dir: /tmp/deepcam/instance0
248: root_dir: /tmp/deepcam/instance0
 63: root_dir: /tmp/deepcam/instance0
484: root_dir: /tmp/deepcam/instance0
 49: root_dir: /tmp/deepcam/instance0
 18: root_dir: /tmp/deepcam/instance0
172: root_dir: /tmp/deepcam/instance0
336: root_dir: /tmp/deepcam/instance0
127: root_dir: /tmp/deepcam/instance0
420: root_dir: /tmp/deepcam/instance0
140: root_dir: /tmp/deepcam/instance0
 90: root_dir: /tmp/deepcam/instance0
 57: root_dir: /tmp/deepcam/instance0
117: root_dir: /tmp/deepcam/instance0
191: root_dir: /tmp/deepcam/instance0
 26: root_dir: /tmp/deepcam/instance0
227: root_dir: /tmp/deepcam/instance0
331: root_dir: /tmp/deepcam/instance0
245: root_dir: /tmp/deepcam/instance0
363: root_dir: /tmp/deepcam/instance0
 51: root_dir: /tmp/deepcam/instance0
271: root_dir: /tmp/deepcam/instance0
 70: root_dir: /tmp/deepcam/instance0
367: root_dir: /tmp/deepcam/instance0
343: root_dir: /tmp/deepcam/instance0
 43: root_dir: /tmp/deepcam/instance0
370: root_dir: /tmp/deepcam/instance0
  9: root_dir: /tmp/deepcam/instance0
500: root_dir: /tmp/deepcam/instance0
 94: root_dir: /tmp/deepcam/instance0
481: root_dir: /tmp/deepcam/instance0
103: root_dir: /tmp/deepcam/instance0
451: root_dir: /tmp/deepcam/instance0
310: root_dir: /tmp/deepcam/instance0
 80: root_dir: /tmp/deepcam/instance0
219: root_dir: /tmp/deepcam/instance0
300: root_dir: /tmp/deepcam/instance0
209: root_dir: /tmp/deepcam/instance0
148: root_dir: /tmp/deepcam/instance0
282: root_dir: /tmp/deepcam/instance0
 28: root_dir: /tmp/deepcam/instance0
322: root_dir: /tmp/deepcam/instance0
431: root_dir: /tmp/deepcam/instance0
 15: root_dir: /tmp/deepcam/instance0
338: root_dir: /tmp/deepcam/instance0
210: root_dir: /tmp/deepcam/instance0
466: root_dir: /tmp/deepcam/instance0
410: root_dir: /tmp/deepcam/instance0
115: root_dir: /tmp/deepcam/instance0
232: root_dir: /tmp/deepcam/instance0
174: root_dir: /tmp/deepcam/instance0
 79: root_dir: /tmp/deepcam/instance0
108: root_dir: /tmp/deepcam/instance0
100: root_dir: /tmp/deepcam/instance0
 24: root_dir: /tmp/deepcam/instance0
231: root_dir: /tmp/deepcam/instance0
315: root_dir: /tmp/deepcam/instance0
400: root_dir: /tmp/deepcam/instance0
 37: root_dir: /tmp/deepcam/instance0
171: root_dir: /tmp/deepcam/instance0
478: root_dir: /tmp/deepcam/instance0
324: root_dir: /tmp/deepcam/instance0
406: root_dir: /tmp/deepcam/instance0
356: root_dir: /tmp/deepcam/instance0
441: root_dir: /tmp/deepcam/instance0
101: root_dir: /tmp/deepcam/instance0
 50: root_dir: /tmp/deepcam/instance0
241: root_dir: /tmp/deepcam/instance0
139: root_dir: /tmp/deepcam/instance0
386: root_dir: /tmp/deepcam/instance0
504: root_dir: /tmp/deepcam/instance0
353: root_dir: /tmp/deepcam/instance0
 41: root_dir: /tmp/deepcam/instance0
179: root_dir: /tmp/deepcam/instance0
450: root_dir: /tmp/deepcam/instance0
265: root_dir: /tmp/deepcam/instance0
489: root_dir: /tmp/deepcam/instance0
407: root_dir: /tmp/deepcam/instance0
152: root_dir: /tmp/deepcam/instance0
278: root_dir: /tmp/deepcam/instance0
111: root_dir: /tmp/deepcam/instance0
502: root_dir: /tmp/deepcam/instance0
 89: root_dir: /tmp/deepcam/instance0
423: root_dir: /tmp/deepcam/instance0
 81: root_dir: /tmp/deepcam/instance0
233: root_dir: /tmp/deepcam/instance0
401: root_dir: /tmp/deepcam/instance0
480: root_dir: /tmp/deepcam/instance0
 93: root_dir: /tmp/deepcam/instance0
  4: root_dir: /tmp/deepcam/instance0
125: root_dir: /tmp/deepcam/instance0
316: root_dir: /tmp/deepcam/instance0
330: root_dir: /tmp/deepcam/instance0
391: root_dir: /tmp/deepcam/instance0
372: root_dir: /tmp/deepcam/instance0
122: root_dir: /tmp/deepcam/instance0
453: root_dir: /tmp/deepcam/instance0
 23: root_dir: /tmp/deepcam/instance0
 68: root_dir: /tmp/deepcam/instance0
142: root_dir: /tmp/deepcam/instance0
  7: root_dir: /tmp/deepcam/instance0
196: root_dir: /tmp/deepcam/instance0
262: root_dir: /tmp/deepcam/instance0
445: root_dir: /tmp/deepcam/instance0
199: root_dir: /tmp/deepcam/instance0
 39: root_dir: /tmp/deepcam/instance0
393: root_dir: /tmp/deepcam/instance0
459: root_dir: /tmp/deepcam/instance0
 55: root_dir: /tmp/deepcam/instance0
113: root_dir: /tmp/deepcam/instance0
463: root_dir: /tmp/deepcam/instance0
 72: root_dir: /tmp/deepcam/instance0
161: root_dir: /tmp/deepcam/instance0
408: root_dir: /tmp/deepcam/instance0
365: root_dir: /tmp/deepcam/instance0
422: root_dir: /tmp/deepcam/instance0
337: root_dir: /tmp/deepcam/instance0
259: root_dir: /tmp/deepcam/instance0
409: root_dir: /tmp/deepcam/instance0
 47: root_dir: /tmp/deepcam/instance0
 54: root_dir: /tmp/deepcam/instance0
 60: root_dir: /tmp/deepcam/instance0
 53: root_dir: /tmp/deepcam/instance0
157: root_dir: /tmp/deepcam/instance0
437: root_dir: /tmp/deepcam/instance0
317: root_dir: /tmp/deepcam/instance0
169: root_dir: /tmp/deepcam/instance0
144: root_dir: /tmp/deepcam/instance0
160: root_dir: /tmp/deepcam/instance0
476: root_dir: /tmp/deepcam/instance0
311: root_dir: /tmp/deepcam/instance0
 20: root_dir: /tmp/deepcam/instance0
354: root_dir: /tmp/deepcam/instance0
180: root_dir: /tmp/deepcam/instance0
178: root_dir: /tmp/deepcam/instance0
288: root_dir: /tmp/deepcam/instance0
413: root_dir: /tmp/deepcam/instance0
448: root_dir: /tmp/deepcam/instance0
283: root_dir: /tmp/deepcam/instance0
479: root_dir: /tmp/deepcam/instance0
291: root_dir: /tmp/deepcam/instance0
390: root_dir: /tmp/deepcam/instance0
488: root_dir: /tmp/deepcam/instance0
138: root_dir: /tmp/deepcam/instance0
  8: root_dir: /tmp/deepcam/instance0
 67: root_dir: /tmp/deepcam/instance0
146: root_dir: /tmp/deepcam/instance0
145: root_dir: /tmp/deepcam/instance0
418: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633414194749, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 121266, "metadata": {"file": "./train_instance.py", "lineno": 353}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414194751, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 15158, "metadata": {"file": "./train_instance.py", "lineno": 354}}
  0: Number of steps per epoch 118
  0: Creating Trainer
  0: Creating Validator
320: root_dir: /tmp/deepcam/instance0
373: root_dir: /tmp/deepcam/instance0
135: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633414237954, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 398}}
  1: hdf5!!
  2: hdf5!!
  3: hdf5!!
208: hdf5!!
256: hdf5!!
384: hdf5!!
464: hdf5!!
 80: hdf5!!
 32: hdf5!!
128: hdf5!!
224: hdf5!!
216: hdf5!!
168: hdf5!!
432: hdf5!!
473: hdf5!!
172: hdf5!!
 64: hdf5!!
112: hdf5!!
 60: hdf5!!
 96: hdf5!!
160: hdf5!!
400: hdf5!!
352: hdf5!!
180: hdf5!!
 48: hdf5!!
312: hdf5!!
116: hdf5!!
368: hdf5!!
320: hdf5!!
480: hdf5!!
476: hdf5!!
500: hdf5!!
140: hdf5!!
392: hdf5!!
 81: hdf5!!
488: hdf5!!
 20: hdf5!!
 44: hdf5!!
260: hdf5!!
129: hdf5!!
164: hdf5!!
492: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414237955, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 401}}
 12: hdf5!!
408: hdf5!!
120: hdf5!!
468: hdf5!!
 36: hdf5!!
444: hdf5!!
204: hdf5!!
372: hdf5!!
240: hdf5!!
424: hdf5!!
412: hdf5!!
496: hdf5!!
209: hdf5!!
 28: hdf5!!
 16: hdf5!!
 40: hdf5!!
220: hdf5!!
100: hdf5!!
448: hdf5!!
148: hdf5!!
388: hdf5!!
 65: hdf5!!
340: hdf5!!
376: hdf5!!
460: hdf5!!
  4: hdf5!!
184: hdf5!!
257: hdf5!!
136: hdf5!!
316: hdf5!!
365: hdf5!!
292: hdf5!!
304: hdf5!!
244: hdf5!!
 56: hdf5!!
416: hdf5!!
236: hdf5!!
284: hdf5!!
188: hdf5!!
404: hdf5!!
248: hdf5!!
380: hdf5!!
332: hdf5!!
200: hdf5!!
176: hdf5!!
 92: hdf5!!
212: hdf5!!
344: hdf5!!
152: hdf5!!
 61: hdf5!!
336: hdf5!!
504: hdf5!!
276: hdf5!!
 24: hdf5!!
396: hdf5!!
156: hdf5!!
 72: hdf5!!
192: hdf5!!
132: hdf5!!
360: hdf5!!
 84: hdf5!!
 97: hdf5!!
348: hdf5!!
280: hdf5!!
268: hdf5!!
124: hdf5!!
328: hdf5!!
196: hdf5!!
 76: hdf5!!
 88: hdf5!!
144: hdf5!!
385: hdf5!!
108: hdf5!!
324: hdf5!!
264: hdf5!!
300: hdf5!!
288: hdf5!!
308: hdf5!!
356: hdf5!!
296: hdf5!!
272: hdf5!!
104: hdf5!!
  8: hdf5!!
117: hdf5!!
369: hdf5!!
420: hdf5!!
508: hdf5!!
436: hdf5!!
440: hdf5!!
452: hdf5!!
428: hdf5!!
477: hdf5!!
465: hdf5!!
501: hdf5!!
141: hdf5!!
393: hdf5!!
 82: hdf5!!
 33: hdf5!!
489: hdf5!!
 21: hdf5!!
 45: hdf5!!
261: hdf5!!
130: hdf5!!
225: hdf5!!
165: hdf5!!
 68: hdf5!!
493: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633414237955, "event_type": "INTERVAL_START", "key": "staging_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 405}}
 13: hdf5!!
409: hdf5!!
121: hdf5!!
469: hdf5!!
 37: hdf5!!
445: hdf5!!
217: hdf5!!
169: hdf5!!
252: hdf5!!
205: hdf5!!
433: hdf5!!
373: hdf5!!
241: hdf5!!
425: hdf5!!
474: hdf5!!
413: hdf5!!
497: hdf5!!
210: hdf5!!
 29: hdf5!!
 17: hdf5!!
 41: hdf5!!
232: hdf5!!
221: hdf5!!
101: hdf5!!
449: hdf5!!
173: hdf5!!
149: hdf5!!
389: hdf5!!
 67: hdf5!!
113: hdf5!!
341: hdf5!!
377: hdf5!!
461: hdf5!!
  5: hdf5!!
 52: hdf5!!
185: hdf5!!
258: hdf5!!
137: hdf5!!
317: hdf5!!
366: hdf5!!
293: hdf5!!
305: hdf5!!
245: hdf5!!
 57: hdf5!!
418: hdf5!!
237: hdf5!!
285: hdf5!!
189: hdf5!!
405: hdf5!!
249: hdf5!!
381: hdf5!!
333: hdf5!!
201: hdf5!!
177: hdf5!!
 93: hdf5!!
213: hdf5!!
345: hdf5!!
153: hdf5!!
 62: hdf5!!
337: hdf5!!
505: hdf5!!
277: hdf5!!
 25: hdf5!!
397: hdf5!!
157: hdf5!!
 73: hdf5!!
193: hdf5!!
133: hdf5!!
361: hdf5!!
 85: hdf5!!
 98: hdf5!!
349: hdf5!!
228: hdf5!!
281: hdf5!!
269: hdf5!!
162: hdf5!!
125: hdf5!!
401: hdf5!!
353: hdf5!!
329: hdf5!!
197: hdf5!!
 77: hdf5!!
 89: hdf5!!
145: hdf5!!
386: hdf5!!
109: hdf5!!
181: hdf5!!
325: hdf5!!
 49: hdf5!!
265: hdf5!!
301: hdf5!!
289: hdf5!!
313: hdf5!!
309: hdf5!!
357: hdf5!!
297: hdf5!!
273: hdf5!!
105: hdf5!!
  9: hdf5!!
118: hdf5!!
370: hdf5!!
321: hdf5!!
484: hdf5!!
421: hdf5!!
481: hdf5!!
509: hdf5!!
437: hdf5!!
441: hdf5!!
454: hdf5!!
456: hdf5!!
429: hdf5!!
478: hdf5!!
466: hdf5!!
502: hdf5!!
142: hdf5!!
394: hdf5!!
 83: hdf5!!
 34: hdf5!!
490: hdf5!!
 22: hdf5!!
 46: hdf5!!
262: hdf5!!
131: hdf5!!
226: hdf5!!
166: hdf5!!
 69: hdf5!!
494: hdf5!!
  0: hdf5!!
 14: hdf5!!
410: hdf5!!
122: hdf5!!
470: hdf5!!
 38: hdf5!!
447: hdf5!!
218: hdf5!!
170: hdf5!!
253: hdf5!!
206: hdf5!!
434: hdf5!!
374: hdf5!!
242: hdf5!!
427: hdf5!!
475: hdf5!!
414: hdf5!!
498: hdf5!!
211: hdf5!!
 30: hdf5!!
 18: hdf5!!
 42: hdf5!!
233: hdf5!!
222: hdf5!!
102: hdf5!!
450: hdf5!!
174: hdf5!!
150: hdf5!!
390: hdf5!!
 66: hdf5!!
114: hdf5!!
342: hdf5!!
378: hdf5!!
462: hdf5!!
  6: hdf5!!
 53: hdf5!!
186: hdf5!!
259: hdf5!!
139: hdf5!!
318: hdf5!!
367: hdf5!!
294: hdf5!!
306: hdf5!!
246: hdf5!!
 58: hdf5!!
419: hdf5!!
238: hdf5!!
286: hdf5!!
190: hdf5!!
406: hdf5!!
250: hdf5!!
383: hdf5!!
334: hdf5!!
202: hdf5!!
178: hdf5!!
 94: hdf5!!
214: hdf5!!
346: hdf5!!
155: hdf5!!
 63: hdf5!!
338: hdf5!!
506: hdf5!!
278: hdf5!!
 26: hdf5!!
398: hdf5!!
158: hdf5!!
 74: hdf5!!
194: hdf5!!
134: hdf5!!
362: hdf5!!
 86: hdf5!!
 99: hdf5!!
350: hdf5!!
229: hdf5!!
282: hdf5!!
270: hdf5!!
163: hdf5!!
126: hdf5!!
402: hdf5!!
354: hdf5!!
330: hdf5!!
198: hdf5!!
 78: hdf5!!
 90: hdf5!!
146: hdf5!!
387: hdf5!!
110: hdf5!!
182: hdf5!!
326: hdf5!!
 50: hdf5!!
266: hdf5!!
302: hdf5!!
290: hdf5!!
314: hdf5!!
310: hdf5!!
358: hdf5!!
298: hdf5!!
274: hdf5!!
106: hdf5!!
 10: hdf5!!
119: hdf5!!
371: hdf5!!
322: hdf5!!
485: hdf5!!
422: hdf5!!
482: hdf5!!
510: hdf5!!
438: hdf5!!
442: hdf5!!
455: hdf5!!
457: hdf5!!
430: hdf5!!
479: hdf5!!
467: hdf5!!
503: hdf5!!
143: hdf5!!
395: hdf5!!
 35: hdf5!!
491: hdf5!!
 23: hdf5!!
 47: hdf5!!
263: hdf5!!
227: hdf5!!
167: hdf5!!
 70: hdf5!!
495: hdf5!!
 15: hdf5!!
411: hdf5!!
123: hdf5!!
471: hdf5!!
 39: hdf5!!
446: hdf5!!
219: hdf5!!
171: hdf5!!
254: hdf5!!
207: hdf5!!
435: hdf5!!
375: hdf5!!
243: hdf5!!
426: hdf5!!
472: hdf5!!
415: hdf5!!
499: hdf5!!
 31: hdf5!!
 19: hdf5!!
 43: hdf5!!
234: hdf5!!
223: hdf5!!
103: hdf5!!
451: hdf5!!
175: hdf5!!
151: hdf5!!
391: hdf5!!
115: hdf5!!
343: hdf5!!
379: hdf5!!
463: hdf5!!
  7: hdf5!!
 54: hdf5!!
187: hdf5!!
138: hdf5!!
319: hdf5!!
364: hdf5!!
295: hdf5!!
307: hdf5!!
247: hdf5!!
 59: hdf5!!
417: hdf5!!
239: hdf5!!
287: hdf5!!
191: hdf5!!
407: hdf5!!
251: hdf5!!
382: hdf5!!
335: hdf5!!
203: hdf5!!
179: hdf5!!
 95: hdf5!!
215: hdf5!!
347: hdf5!!
154: hdf5!!
339: hdf5!!
507: hdf5!!
279: hdf5!!
 27: hdf5!!
399: hdf5!!
159: hdf5!!
 75: hdf5!!
195: hdf5!!
135: hdf5!!
363: hdf5!!
 87: hdf5!!
351: hdf5!!
230: hdf5!!
283: hdf5!!
271: hdf5!!
127: hdf5!!
403: hdf5!!
355: hdf5!!
331: hdf5!!
199: hdf5!!
 79: hdf5!!
 91: hdf5!!
147: hdf5!!
111: hdf5!!
183: hdf5!!
327: hdf5!!
 51: hdf5!!
267: hdf5!!
303: hdf5!!
291: hdf5!!
315: hdf5!!
311: hdf5!!
359: hdf5!!
299: hdf5!!
275: hdf5!!
107: hdf5!!
 11: hdf5!!
323: hdf5!!
486: hdf5!!
423: hdf5!!
483: hdf5!!
511: hdf5!!
439: hdf5!!
443: hdf5!!
453: hdf5!!
458: hdf5!!
431: hdf5!!
 71: hdf5!!
255: hdf5!!
235: hdf5!!
 55: hdf5!!
231: hdf5!!
487: hdf5!!
459: hdf5!!
161: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
  0: :::MLLOG {"namespace": "", "time_ms": 1633414350628, "event_type": "INTERVAL_END", "key": "staging_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 425}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414350633, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 1, "step_num": 0}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414356366, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00017999999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414356367, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.16184446215629578, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414356367, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.4767040014266968, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414358320, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00038, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414358352, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.1954430788755417, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414358352, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.1297831535339355, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414359289, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00058, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414359290, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.26677924394607544, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414359290, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.7705472111701965, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414360223, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0007800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414360224, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3190229535102844, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414360224, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.44533804059028625, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414361168, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00098, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414361169, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3284015655517578, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414361169, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.2261807769536972, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414362106, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00118, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414362106, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3318077325820923, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414362106, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.12455553561449051, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414363038, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00138, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414363038, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.369941383600235, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414363038, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.08000599592924118, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414363978, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00158, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414363979, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.45873966813087463, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414363979, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0597187802195549, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414364916, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0017800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414364917, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.49724286794662476, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414364917, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.048287928104400635, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414365849, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00198, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414365850, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5061310529708862, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414365850, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.04242801293730736, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414366782, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00218, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414366783, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.49004867672920227, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414366783, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.040858250111341476, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414367532, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 1}}
  0: EVAL: first data load time: 0.3576338663697243
  0: EVAL: step 1 time -> 0.05071822926402092
  0: EVAL: step 2 time -> 0.12739552464336157
  0: EVAL: step 3 time -> 0.011585582047700882
  0: EVAL: step 4 time -> 0.01213864702731371
  0: EVAL: full eval time -> 1.0585339702665806
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368594, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.49233522778813166, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368597, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.0578616059601881, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368597, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368614, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368633, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 2, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368833, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0023799999999999997, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368834, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5364026427268982, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414368834, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03696119412779808, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414369767, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0025800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414369769, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5376390814781189, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414369769, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03664066269993782, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414370708, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00278, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414370709, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5580685138702393, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414370710, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03232981637120247, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414371650, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00298, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414371650, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5524646639823914, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414371651, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03385351970791817, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414372582, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00318, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414372583, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5793607234954834, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414372583, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.030319692566990852, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414373525, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0033799999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414373525, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5759937763214111, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414373526, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.030227944254875183, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414374465, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0035800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414374465, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5821133255958557, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414374466, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02968285046517849, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414375408, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00378, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414375409, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5814926028251648, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414375409, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.032164279371500015, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414376348, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00398, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414376348, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5946351289749146, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414376349, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.028443656861782074, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414377282, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414377283, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5966190099716187, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414377283, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.027373986318707466, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414378220, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414378220, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6000850200653076, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414378221, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02697346918284893, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414379162, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414379162, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6150204539299011, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414379163, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02585609257221222, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414379736, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 2}}
  0: EVAL: first data load time: 0.001317913644015789
  0: EVAL: step 1 time -> 0.013065185397863388
  0: EVAL: step 2 time -> 0.012155013158917427
  0: EVAL: step 3 time -> 0.011934472247958183
  0: EVAL: step 4 time -> 0.12526856362819672
  0: EVAL: full eval time -> 0.3908630609512329
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380132, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6121133436139332, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380132, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.023957726256736336, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380132, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 2}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380133, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380152, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 3, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380537, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380538, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6105062961578369, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414380538, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.025376182049512863, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414381468, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414381468, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6326942443847656, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414381469, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.023693418130278587, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414382399, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414382399, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6307584047317505, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414382400, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02244294062256813, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414383327, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414383328, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6355342864990234, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414383329, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021881187334656715, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414384257, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414384258, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.648065984249115, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414384259, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021189816296100616, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414385198, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414385199, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6443569660186768, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414385200, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020469535142183304, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414386130, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414386131, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6446630954742432, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414386132, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021174246445298195, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414387062, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414387063, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6416071057319641, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414387063, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02125021256506443, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414387992, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414387993, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6484501957893372, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414387994, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019689902663230896, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414388930, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414388931, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6508339643478394, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414388931, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020124567672610283, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414389870, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414389871, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6571511030197144, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414389871, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020032305270433426, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414390798, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414390799, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6484435200691223, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414390799, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0194697305560112, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414391180, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 3}}
  0: EVAL: first data load time: 0.001307448372244835
  0: EVAL: step 1 time -> 0.013556823134422302
  0: EVAL: step 2 time -> 0.012365706264972687
  0: EVAL: step 3 time -> 0.012055394239723682
  0: EVAL: step 4 time -> 0.011016365140676498
  0: EVAL: full eval time -> 0.5140911061316729
  0: :::MLLOG {"namespace": "", "time_ms": 1633414391698, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.640418065130624, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414391699, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.019444285572825612, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414391699, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 3}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414391718, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414391741, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 4, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414393555, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414393555, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6486396789550781, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414393555, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019236402586102486, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414395221, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414395221, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6523953676223755, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414395222, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017896365374326706, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414396302, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414396303, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.669095516204834, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414396304, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017756262794137, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414397239, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414397240, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6635192036628723, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414397240, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017829393967986107, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414398177, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414398178, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6720415353775024, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414398178, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016875961795449257, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414399110, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414399111, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6638311147689819, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414399111, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01823178119957447, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414400041, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414400042, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6761087775230408, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414400043, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017102360725402832, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414400980, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414400981, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6723514199256897, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414400982, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016963303089141846, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414401917, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414401918, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6669095754623413, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414401918, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017532169818878174, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414402861, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414402862, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6811568140983582, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414402862, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016936950385570526, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414403795, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414403796, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6851666569709778, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414403797, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016369234770536423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414404725, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414404725, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6867857575416565, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414404726, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016712382435798645, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414404921, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 4}}
  0: EVAL: first data load time: 0.0013941358774900436
  0: EVAL: step 1 time -> 0.013419709168374538
  0: EVAL: step 2 time -> 0.012368837371468544
  0: EVAL: step 3 time -> 0.012337490916252136
  0: EVAL: step 4 time -> 0.011095564812421799
  0: EVAL: full eval time -> 0.3143557272851467
  0: :::MLLOG {"namespace": "", "time_ms": 1633414405241, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.663034203782656, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414405242, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.018772709604019947, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414405242, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 4}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414405291, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414405322, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 5, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414407698, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414407698, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6926509737968445, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414407698, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015638554468750954, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414408731, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414408731, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6963593363761902, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414408732, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015459013171494007, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414409662, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414409663, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7007777094841003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414409664, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015102886594831944, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414410620, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414410621, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6893973350524902, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414410621, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014745003543794155, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414411637, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414411638, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6820063591003418, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414411639, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015164959244430065, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414412575, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414412575, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.693669319152832, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414412576, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015296929515898228, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414413508, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414413508, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6939670443534851, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414413509, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015370255336165428, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414414445, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414414446, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6934173703193665, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414414447, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01592855527997017, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414415384, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414415385, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6949158310890198, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414415385, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014504841528832912, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414416321, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414416321, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6828262805938721, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414416322, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014674883335828781, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414417265, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414417266, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.703376829624176, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414417266, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015420274809002876, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418199, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418199, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7148249745368958, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418200, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014475432224571705, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418205, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 5}}
  0: EVAL: first data load time: 0.0012003285810351372
  0: EVAL: step 1 time -> 0.012862300500273705
  0: EVAL: step 2 time -> 0.012238001450896263
  0: EVAL: step 3 time -> 0.01268753781914711
  0: EVAL: step 4 time -> 0.011016842909157276
  0: EVAL: full eval time -> 0.32198246754705906
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418530, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6691021242908035, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418531, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.021070293864909412, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418531, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 5}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418550, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414418553, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 6, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414419493, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414419494, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7158982753753662, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414419494, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01476407703012228, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414420426, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414420427, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7096560597419739, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414420427, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013400280848145485, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414421353, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414421354, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7229577302932739, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414421354, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01321906317025423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414422282, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414422283, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7272270917892456, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414422283, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013314759358763695, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414423223, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414423224, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7052415013313293, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414423225, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014466281048953533, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414424163, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414424164, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7141394019126892, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414424164, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01391800306737423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414425107, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414425108, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6968808174133301, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414425108, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01428117137402296, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414426042, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414426043, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7192475199699402, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414426044, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014107917435467243, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414426986, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414426987, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7117494344711304, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414426987, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012593758292496204, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414427930, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414427931, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7369763255119324, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414427931, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013321952894330025, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414428857, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414428858, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.734453558921814, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414428858, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013278230093419552, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414429601, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 6}}
  0: EVAL: first data load time: 0.001370854675769806
  0: EVAL: step 1 time -> 0.013729088008403778
  0: EVAL: step 2 time -> 0.01219081413000822
  0: EVAL: step 3 time -> 0.012613869272172451
  0: EVAL: step 4 time -> 0.010992824099957943
  0: EVAL: full eval time -> 0.6197566697373986
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430226, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6585250594776686, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430226, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.0179140337823107, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430226, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 6}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430246, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430270, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 7, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430861, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430861, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7493670582771301, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414430861, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012047529220581055, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414432964, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414432965, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7220541834831238, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414432965, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012950683012604713, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414433906, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414433908, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.750732958316803, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414433908, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01213223859667778, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414434850, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414434851, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7611231207847595, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414434852, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011359196156263351, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414435779, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414435780, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7423931360244751, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414435780, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012191635556519032, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414436727, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414436728, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.756251335144043, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414436729, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012110084295272827, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414437672, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414437673, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7521169185638428, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414437674, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011589856818318367, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414438622, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414438623, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7516001462936401, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414438623, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011449802666902542, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414439565, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414439566, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7637687921524048, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414439567, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011550534516572952, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414440495, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414440496, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7450122237205505, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414440496, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012482024729251862, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414441436, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414441437, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7292156219482422, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414441438, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015183022245764732, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414442366, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414442367, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7567071914672852, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414442367, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012204794213175774, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414442931, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 7}}
  0: EVAL: first data load time: 0.0013757981359958649
  0: EVAL: step 1 time -> 0.01365238893777132
  0: EVAL: step 2 time -> 0.012444842606782913
  0: EVAL: step 3 time -> 0.012731186114251614
  0: EVAL: step 4 time -> 0.011029447428882122
  0: EVAL: full eval time -> 0.5352457351982594
  0: :::MLLOG {"namespace": "", "time_ms": 1633414443471, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6329848383485618, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414443471, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.0246405847501371, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414443471, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 7}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414443490, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414443514, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 8, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414444731, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414444731, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7611140608787537, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414444732, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0111106988042593, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414446786, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414446787, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7661558985710144, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414446787, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011788553558290005, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414447941, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414447942, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7671495676040649, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414447942, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01149094756692648, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414448909, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414448910, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.73309326171875, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414448911, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011039171367883682, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414449842, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414449843, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7183324098587036, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414449844, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011119714938104153, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414450780, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414450781, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7388522624969482, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414450782, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01113306824117899, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414451717, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414451717, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7598506808280945, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414451718, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01113764476031065, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414452649, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414452650, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7703441977500916, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414452651, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01124234776943922, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414453582, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414453583, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7646489143371582, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414453584, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011294500902295113, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414454523, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414454524, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7736040949821472, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414454525, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011005314067006111, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414455460, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414455461, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7573564052581787, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414455462, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011464310809969902, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414456384, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414456385, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7620534896850586, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414456385, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01096576638519764, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414456766, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 8}}
  0: EVAL: first data load time: 0.0013813646510243416
  0: EVAL: step 1 time -> 0.013485461473464966
  0: EVAL: step 2 time -> 0.012591703794896603
  0: EVAL: step 3 time -> 0.013167282566428185
  0: EVAL: step 4 time -> 0.01105779130011797
  0: EVAL: full eval time -> 0.6359024625271559
  0: :::MLLOG {"namespace": "", "time_ms": 1633414457407, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7374390791991028, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414457408, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01919155017668063, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414457408, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 8}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414457427, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414457451, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 9, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414459283, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414459283, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7868830561637878, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414459284, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009550515562295914, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414460763, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414460763, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7892321944236755, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414460764, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009980753064155579, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414461828, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414461828, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7962613701820374, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414461829, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010875105857849121, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414462773, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414462774, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.790378987789154, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414462774, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01041643787175417, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414463704, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414463705, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7861434817314148, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414463705, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009526037611067295, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414464664, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414464665, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7777318954467773, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414464665, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01014622300863266, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414465618, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414465619, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7959704399108887, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414465619, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010399984195828438, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414466548, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414466548, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.798419177532196, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414466549, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010267999023199081, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414467476, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414467477, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7898327112197876, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414467478, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009940307587385178, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414468422, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414468424, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7874308228492737, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414468424, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010404850356280804, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414469365, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414469366, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8008021712303162, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414469366, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010229497216641903, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414470302, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414470303, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7864266633987427, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414470303, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00991977658122778, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414470492, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 9}}
  0: EVAL: first data load time: 0.0013967221602797508
  0: EVAL: step 1 time -> 0.013670258224010468
  0: EVAL: step 2 time -> 0.01246576476842165
  0: EVAL: step 3 time -> 0.012734879739582539
  0: EVAL: step 4 time -> 0.011050035245716572
  0: EVAL: full eval time -> 0.7450000494718552
  0: :::MLLOG {"namespace": "", "time_ms": 1633414471243, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7182119177991819, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414471243, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.02658482707731169, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414471243, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 9}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414471263, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414471287, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 10, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414473602, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414473603, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8024061918258667, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414473603, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009374863468110561, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414474811, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414474812, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8103095293045044, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414474813, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009235904552042484, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414475739, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414475740, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.767649233341217, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414475741, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009187273681163788, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414476671, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414476671, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8070952296257019, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414476672, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008878062479197979, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414477601, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414477602, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7998577356338501, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414477603, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00916712824255228, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414478536, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414478537, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8046938180923462, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414478538, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009178929962217808, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414479475, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414479475, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7974559664726257, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414479476, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00974303763359785, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414480412, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414480412, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7943479418754578, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414480412, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009389590471982956, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414481343, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414481344, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8024137616157532, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414481344, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009315278381109238, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414482277, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414482278, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8088811635971069, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414482279, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009699002839624882, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414483216, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414483217, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7808469533920288, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414483217, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009854174219071865, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484151, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484152, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7734590768814087, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484152, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010392999276518822, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484156, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 10}}
  0: EVAL: first data load time: 0.0011334819719195366
  0: EVAL: step 1 time -> 0.013188336975872517
  0: EVAL: step 2 time -> 0.01322102826088667
  0: EVAL: step 3 time -> 0.013287890702486038
  0: EVAL: step 4 time -> 0.011081820353865623
  0: EVAL: full eval time -> 0.545363562181592
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484704, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7665211594125214, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484704, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.011811917399743535, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484705, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484724, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414484749, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 11, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414487518, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414487518, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8114281296730042, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414487518, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008954138495028019, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414488753, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414488753, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8020559549331665, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414488754, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009591949172317982, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414489790, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414489790, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7913147211074829, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414489791, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00928316917270422, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414490729, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414490730, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8075445294380188, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414490731, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008871559053659439, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414491667, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414491668, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8077629804611206, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414491671, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008870307356119156, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414492598, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414492598, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.795343816280365, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414492599, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009153190068900585, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414493535, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414493536, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8110049962997437, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414493537, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00932072289288044, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414494473, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414494473, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.794721782207489, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414494474, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010048062540590763, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414495405, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414495406, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7526666522026062, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414495407, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010069570504128933, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414496347, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414496348, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7976217269897461, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414496348, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00908676814287901, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414497285, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414497286, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7895121574401855, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414497287, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009337972849607468, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414498040, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 11}}
  0: EVAL: first data load time: 0.0013482440263032913
  0: EVAL: step 1 time -> 0.013637530617415905
  0: EVAL: step 2 time -> 0.012425333261489868
  0: EVAL: step 3 time -> 0.01267524529248476
  0: EVAL: step 4 time -> 0.011045319028198719
  0: EVAL: full eval time -> 0.6793221579864621
  0: :::MLLOG {"namespace": "", "time_ms": 1633414498725, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7630454653689471, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414498725, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.023544041741443256, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414498726, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 11}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414498745, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414498769, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 12, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414499380, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414499380, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8179881572723389, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414499380, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008500386029481888, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414501562, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414501563, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8356649279594421, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414501564, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007212319876998663, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414502504, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414502505, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8428904414176941, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414502506, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0068914215080440044, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414503434, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414503435, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8415278196334839, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414503435, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0062324912287294865, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414504365, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414504366, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8491827249526978, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414504366, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006104539148509502, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414505296, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414505298, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8454525470733643, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414505298, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0059652323834598064, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414506236, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414506236, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8475443720817566, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414506237, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006435215473175049, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414507169, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414507170, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8505674600601196, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414507170, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006042218767106533, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414508104, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414508105, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8493272066116333, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414508105, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006049366667866707, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414509041, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414509041, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8502587080001831, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414509042, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005865888670086861, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414509967, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414509968, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8580664396286011, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414509968, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0058664134703576565, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414510920, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414510921, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8486342430114746, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414510922, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00614923844113946, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414511491, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 12}}
  0: EVAL: first data load time: 0.0014088107272982597
  0: EVAL: step 1 time -> 0.013279418461024761
  0: EVAL: step 2 time -> 0.01244411338120699
  0: EVAL: step 3 time -> 0.012609991244971752
  0: EVAL: step 4 time -> 0.01103728637099266
  0: EVAL: full eval time -> 0.33020920399576426
  0: :::MLLOG {"namespace": "", "time_ms": 1633414511827, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8202247523997229, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414511827, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01607347632605823, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414511827, "event_type": "POINT_IN_TIME", "key": "target_accuracy_reached", "value": 0.82, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 374, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414511827, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 12}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414511847, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633414511848, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 507, "status": "success"}}
213: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
213: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
492: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
492: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
160: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
160: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
467: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
467: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
392: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 46: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 46: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
392: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
124: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
124: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
316: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
316: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
363: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
363: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
297: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
297: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  5: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  5: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
468: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
468: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
210: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
210: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
247: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
247: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
366: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
366: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
108: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 77: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
400: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
108: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
400: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
265: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 77: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
265: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
130: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
130: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
375: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
375: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
444: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
444: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
501: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
501: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
500: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
500: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
385: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
385: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
280: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
280: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
281: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
281: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
261: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
261: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
342: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
341: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
342: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
341: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
418: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
418: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
416: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
416: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 51: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 51: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
449: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
449: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
353: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
353: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 41: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 41: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
240: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
240: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 73: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 73: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
358: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
358: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
295: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
295: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
430: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
430: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
423: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
423: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
237: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
237: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
162: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
162: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
207: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
207: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
255: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
255: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
167: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
167: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
464: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
464: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 44: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 44: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
410: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
410: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
408: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
408: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
115: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
115: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
379: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
379: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 93: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 93: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
212: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
212: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
177: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
177: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 76: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 76: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
296: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
296: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
224: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
224: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
434: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
434: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 64: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 64: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
441: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
441: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
105: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
105: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  4: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  4: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 88: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 88: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
127: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
127: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
496: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
498: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
496: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
498: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
485: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
485: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
168: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
168: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
113: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
113: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
128: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
128: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
153: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
153: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
154: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
154: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
264: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
264: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
320: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
208: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
208: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
320: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
364: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
364: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 58: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 58: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 48: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 48: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 83: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 83: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
352: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
352: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
454: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
454: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
269: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
269: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
268: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
268: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
182: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
182: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
428: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
428: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
386: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
386: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
178: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
178: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
448: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
448: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
252: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
252: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 72: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 72: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
372: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
345: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
372: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
345: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
346: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
346: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
475: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
475: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
440: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
440: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
292: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
292: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
323: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
323: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
447: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
447: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
233: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
233: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
360: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
360: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 92: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 92: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
260: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
260: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
236: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
236: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
257: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
257: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
204: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
204: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
258: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
258: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
219: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
219: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
217: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
217: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
121: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
121: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 40: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
225: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 40: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
225: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
348: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
348: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
350: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
350: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
220: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
220: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 12: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 12: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
377: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
377: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
399: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
399: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
495: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
495: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
420: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
420: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
356: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
356: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
161: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
161: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
110: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
110: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
202: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
202: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
484: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
484: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
424: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
324: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
424: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
324: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
228: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
229: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
228: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
229: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
164: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
164: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
107: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
107: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
243: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
243: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 99: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 99: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 96: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 96: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
452: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
452: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
413: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
412: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
412: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
413: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
317: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
317: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
483: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
483: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
314: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
314: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
471: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
471: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
433: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
433: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 45: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 45: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
136: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
136: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
246: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
246: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
171: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
171: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 61: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 61: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 33: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 33: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
120: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
120: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
478: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
478: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
476: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
476: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
112: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
112: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
370: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
370: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
368: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
368: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
144: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
144: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
134: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
134: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
135: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
135: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 67: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 67: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
508: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
508: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
384: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
384: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
181: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
181: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 32: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 32: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
393: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
393: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
491: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
491: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 85: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 85: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
311: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
311: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
198: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
198: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
203: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
203: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
267: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
267: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
251: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
251: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
249: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
249: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
338: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
338: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
355: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
355: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
299: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
299: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
488: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
488: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
312: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
312: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
215: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
215: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
272: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
272: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
380: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
380: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
282: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
282: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
396: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
396: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
367: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
367: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
126: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
126: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
405: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
405: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
480: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
480: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 62: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 62: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
376: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
376: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 20: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 20: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 21: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 21: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
391: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
388: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
328: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
391: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
328: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
388: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  7: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  7: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
336: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
446: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
336: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
446: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
288: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
289: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
288: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
289: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
 18: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 18: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
302: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
302: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
466: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
466: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 78: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 78: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 50: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 50: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
451: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
451: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
414: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
414: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
374: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
374: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 69: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 69: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
248: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
248: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
131: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
131: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 84: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 84: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
254: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
254: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
104: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
104: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
308: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
308: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
230: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
230: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
185: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
186: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
186: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
185: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
443: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
443: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
409: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
409: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
174: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
174: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
209: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
209: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
137: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 68: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
137: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 68: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 28: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 29: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 28: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 29: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
263: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
263: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  0: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  1: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  0: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  1: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
205: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
205: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
472: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
472: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 25: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 25: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
190: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
190: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
362: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
362: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
326: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
326: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
404: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
404: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 75: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
402: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 75: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
402: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
429: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
429: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
232: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
232: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
223: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
223: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
294: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
294: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
458: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
458: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
216: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
216: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
147: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 42: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
147: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 42: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
349: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
349: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
238: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
238: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 89: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 89: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
226: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
226: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
421: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
421: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
344: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
344: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
455: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
455: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
176: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
176: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
103: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
103: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
357: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
505: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
357: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
505: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
494: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
494: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
193: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
193: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
321: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
321: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
479: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
479: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
300: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 53: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 53: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
300: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
285: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
285: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
196: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
196: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
242: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
242: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
279: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
279: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 80: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
192: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 80: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
192: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
244: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
244: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
276: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
276: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
426: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
426: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
140: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
140: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
111: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
111: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
486: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
486: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
180: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
141: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
141: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
180: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 95: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
271: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 95: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
271: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
275: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
275: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
158: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
158: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 11: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 11: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
439: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
439: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
511: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
511: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
470: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  8: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
470: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  8: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 16: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 16: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
319: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
319: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
117: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
117: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
432: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
432: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
304: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
304: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
175: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
175: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
188: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
188: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
184: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
184: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
461: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
461: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
166: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
166: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
148: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
330: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
148: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
330: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 38: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 38: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
383: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
383: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
456: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
456: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
 24: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 24: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 34: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 34: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
504: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
504: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
116: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
116: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 65: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 65: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 57: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
170: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 57: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
170: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
200: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
200: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
133: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
133: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
123: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
123: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
334: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
334: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
394: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
394: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
389: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
389: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
339: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
339: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
315: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
315: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
481: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
481: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 60: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 60: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  2: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  2: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
234: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
234: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 23: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 23: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
146: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
146: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 52: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 52: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
460: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
460: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
490: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
490: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
310: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
310: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
 36: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 36: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
100: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
100: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
278: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
278: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
139: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
139: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
327: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
327: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
474: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
474: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 14: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 14: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 13: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 13: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
290: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
290: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
369: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
369: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
284: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
284: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
172: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
172: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
406: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
403: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
403: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
406: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
397: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
397: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 86: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 86: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 91: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 91: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
307: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
307: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
427: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
427: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
301: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
301: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
142: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
142: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 19: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 19: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
221: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
221: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
197: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
197: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
 71: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 71: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 30: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 30: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
510: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
510: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
274: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
274: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
156: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
156: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
  9: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
  9: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
436: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
436: RESULT,DEEPCAM_HPC,,466,qv2382,2021-10-05 08:07:29 AM
382: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
382: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
331: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
331: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
343: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
343: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
191: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
191: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
333: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
333: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 81: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 81: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 56: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 56: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
506: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
506: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
459: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
459: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 26: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 26: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
119: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
119: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
195: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
195: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 55: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 55: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
150: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
150: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
462: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
462: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
286: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
286: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
101: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
101: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
438: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
438: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
332: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
332: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
306: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
306: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
159: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
159: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 39: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 39: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
149: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
149: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
256: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
256: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
155: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
155: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
419: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
419: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
502: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
502: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
497: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
497: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
 98: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
 98: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
477: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
477: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
250: ENDING TIMING RUN AT 2021-10-05 08:15:15 AM
250: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:28 AM
361: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
361: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
469: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
469: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
318: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
318: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
283: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
283: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
129: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
129: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
214: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
214: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
109: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
109: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 49: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 49: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 43: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 43: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
298: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
298: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
365: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
365: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
450: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
450: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
445: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
445: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
401: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
401: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
411: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
411: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
373: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
373: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 90: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 90: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
211: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
211: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
293: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
293: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
262: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
262: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
387: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
387: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
351: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
351: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
106: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
106: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 74: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 74: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
493: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
493: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
465: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
465: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
218: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
218: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
266: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
266: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
359: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
359: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
183: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
183: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
241: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
241: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
179: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
179: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
222: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
222: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
270: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
270: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
 66: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 66: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 15: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 15: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
347: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
347: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
415: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
415: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
125: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
125: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
235: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
235: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
435: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 47: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
435: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 47: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 82: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 82: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
239: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
239: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
201: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
201: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
395: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
395: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
132: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
132: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
322: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
322: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 79: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 79: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
371: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
371: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
231: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
231: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
489: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
489: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
  6: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
  6: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
431: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
431: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
187: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
187: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
390: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
390: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
291: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
291: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 70: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 70: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
422: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
422: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
407: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
407: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
163: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
163: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
114: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
114: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
337: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
337: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 22: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 22: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 87: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 87: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
253: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
253: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
354: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
354: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
487: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
487: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
165: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
165: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 31: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 31: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 94: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 94: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
287: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
287: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
442: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
442: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 59: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 59: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
206: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
206: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
277: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
277: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
102: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
102: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
437: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
437: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
378: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
378: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
  3: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
  3: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
329: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
329: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 54: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 54: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
245: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
245: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
 17: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 17: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
453: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
453: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
259: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
259: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
118: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
118: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
169: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
169: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
425: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
425: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
194: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
194: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
122: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
122: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
340: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
340: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
138: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
138: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
273: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
273: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
507: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
507: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
151: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
151: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
313: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
313: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
417: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
417: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 35: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 35: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
325: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
325: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
227: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
227: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
145: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
145: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
482: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
482: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
309: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
309: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
305: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
305: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
457: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
457: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
473: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
473: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 63: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 63: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
143: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
143: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 10: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 10: RESULT,DEEPCAM_HPC,,467,qv2382,2021-10-05 08:07:29 AM
503: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
503: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
509: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
509: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
398: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
398: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
157: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
157: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
189: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
189: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
173: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
173: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
381: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
381: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 27: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 27: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
463: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
463: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
152: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
152: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
199: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
199: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
303: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
303: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
499: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
499: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 37: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 37: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
 97: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
 97: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
335: ENDING TIMING RUN AT 2021-10-05 08:15:16 AM
335: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 08:07:28 AM
