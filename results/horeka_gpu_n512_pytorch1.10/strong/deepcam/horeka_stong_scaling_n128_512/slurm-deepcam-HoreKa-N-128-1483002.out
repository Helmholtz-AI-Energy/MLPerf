/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/docker/deepcam_optimized-21.09_2.sif
configs/best_configs/config_DGXA100_512GPU_BS1024_graph.sh
#!/bin/bash

# hyperparameters
export LOCAL_BATCH_SIZE=2
export START_LR=0.004
export OPTIMIZER="LAMB"
export LR_SCHEDULE_TYPE="multistep"
export LR_MILESTONES="1100 4096"
export LR_DECAY_RATE="0.1"
export LR_WARMUP_STEPS=200
export LR_WARMUP_FACTOR=1.
export WEIGHT_DECAY=0.01
export BATCHNORM_GROUP_SIZE=1

# data parameters
export SHUFFLE_MODE="global"
export DATA_FORMAT="dali-es/hdf5"
export PRECISION_MODE="amp"
export LOCAL_VALIDATION_BATCH_SIZE=8

# output parameters
#export OUTPUT_ROOT=/results/best

export TRAINING_INSTANCE_SIZE=$((128*4))

# auxiliary parameters
export LOGGING_FREQUENCY=10

# misc args
export ADDITIONAL_ARGS="--enable_jit --enable_graph"
#--disable_comm_overlap
# system parameters
#export DGXNGPU=8
#export DGXNNODES=64
#export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
#export WALLTIME=00:30:00
export DGXNGPU=4
export DGXNNODES=128
export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
export WALLTIME=01:00:00
  1: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  0: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 34: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  0: Using bindings from SLURM: mask_cpu:
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: Running Multi Instance Training
  1: Running Multi Instance Training
  0: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  1: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: Running Multi Instance Training
 34: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
410: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 33: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: Running Multi Instance Training
 33: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: Running Multi Instance Training
410: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
112: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
436: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
435: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: Running Multi Instance Training
112: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: Running Multi Instance Training
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
435: Running Multi Instance Training
435: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
264: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  3: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
280: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 44: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: Running Multi Instance Training
264: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: Running Multi Instance Training
  3: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
268: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: Running Multi Instance Training
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 44: Running Multi Instance Training
 44: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
433: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: Running Multi Instance Training
268: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
108: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: Running Multi Instance Training
433: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
438: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: Running Multi Instance Training
369: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
369: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
108: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
263: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: Running Multi Instance Training
438: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
277: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
369: Running Multi Instance Training
369: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
282: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
408: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: Running Multi Instance Training
263: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: Running Multi Instance Training
277: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
282: Running Multi Instance Training
282: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: Running Multi Instance Training
114: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
408: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
224: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 32: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
242: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: Running Multi Instance Training
342: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
114: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
109: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: Running Multi Instance Training
443: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: Running Multi Instance Training
 32: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: Running Multi Instance Training
224: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: Running Multi Instance Training
109: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
267: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: Running Multi Instance Training
242: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: Running Multi Instance Training
371: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
342: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
270: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
270: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
234: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
385: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: Running Multi Instance Training
267: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
292: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: Running Multi Instance Training
371: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: Running Multi Instance Training
270: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: Running Multi Instance Training
 68: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: Running Multi Instance Training
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
234: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 45: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: Running Multi Instance Training
 45: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
385: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: Running Multi Instance Training
292: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: Running Multi Instance Training
379: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 45: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: Running Multi Instance Training
 53: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: Running Multi Instance Training
206: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
210: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
215: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
215: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: Running Multi Instance Training
379: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
243: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 17: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: Running Multi Instance Training
 70: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
243: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
215: Running Multi Instance Training
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: Running Multi Instance Training
215: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
279: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
206: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
439: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: Running Multi Instance Training
 70: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: Running Multi Instance Training
232: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
279: Running Multi Instance Training
 17: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
279: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
409: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 55: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
266: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
439: Running Multi Instance Training
434: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
439: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: Running Multi Instance Training
232: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
284: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: Running Multi Instance Training
227: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
227: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
221: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: Running Multi Instance Training
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
266: Running Multi Instance Training
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
434: Running Multi Instance Training
434: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
113: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: Running Multi Instance Training
227: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: Running Multi Instance Training
237: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
284: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: Running Multi Instance Training
221: Running Multi Instance Training
113: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
221: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
207: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
147: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 41: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
281: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
442: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
213: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
237: Running Multi Instance Training
289: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
237: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: Running Multi Instance Training
207: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
386: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: Running Multi Instance Training
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
147: Running Multi Instance Training
261: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: Running Multi Instance Training
147: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
213: Running Multi Instance Training
442: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
213: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: Running Multi Instance Training
272: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 41: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
405: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: Running Multi Instance Training
386: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: Running Multi Instance Training
289: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
343: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
175: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: Running Multi Instance Training
 47: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
261: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
111: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
271: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
378: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
285: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: Running Multi Instance Training
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
272: Running Multi Instance Training
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: Running Multi Instance Training
 47: Running Multi Instance Training
272: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
295: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
405: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
295: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: Running Multi Instance Training
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: Running Multi Instance Training
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
175: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
271: Running Multi Instance Training
111: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
378: Running Multi Instance Training
378: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: Running Multi Instance Training
285: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
218: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
368: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: Running Multi Instance Training
295: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
239: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: Running Multi Instance Training
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: Running Multi Instance Training
368: Running Multi Instance Training
231: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
318: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 19: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 19: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
209: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: Running Multi Instance Training
255: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
239: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: Running Multi Instance Training
218: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 43: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: Running Multi Instance Training
276: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
146: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
146: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: Running Multi Instance Training
209: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
194: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
299: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: Running Multi Instance Training
240: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 43: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: Running Multi Instance Training
255: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
275: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: Running Multi Instance Training
146: Running Multi Instance Training
363: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
363: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
223: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
223: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
291: Running Multi Instance Training
146: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
276: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
291: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: Running Multi Instance Training
260: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
240: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: Running Multi Instance Training
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: Running Multi Instance Training
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
299: Running Multi Instance Training
194: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: Running Multi Instance Training
223: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
233: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
363: Running Multi Instance Training
260: Running Multi Instance Training
363: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
260: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
225: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
376: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: Running Multi Instance Training
233: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
172: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: Running Multi Instance Training
225: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: Running Multi Instance Training
376: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
157: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
257: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
172: Running Multi Instance Training
172: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: Running Multi Instance Training
 69: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
441: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 54: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
474: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 26: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
192: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: Running Multi Instance Training
257: Running Multi Instance Training
157: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
257: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
205: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: Running Multi Instance Training
249: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: Running Multi Instance Training
 54: Running Multi Instance Training
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: Running Multi Instance Training
441: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 54: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
384: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
212: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: Running Multi Instance Training
192: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
340: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: Running Multi Instance Training
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
474: Running Multi Instance Training
 18: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 18: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
102: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 26: Running Multi Instance Training
 26: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: Running Multi Instance Training
222: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
212: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: Running Multi Instance Training
340: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
302: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: Running Multi Instance Training
211: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
211: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 18: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
293: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
222: Running Multi Instance Training
222: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
317: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: Running Multi Instance Training
102: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
329: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
211: Running Multi Instance Training
211: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: Running Multi Instance Training
313: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: Running Multi Instance Training
302: Running Multi Instance Training
219: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
302: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: Running Multi Instance Training
317: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
142: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
462: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
253: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: Running Multi Instance Training
160: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
329: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
297: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: Running Multi Instance Training
313: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
135: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
248: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
230: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
253: Running Multi Instance Training
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: Running Multi Instance Training
253: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
142: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: Running Multi Instance Training
462: Running Multi Instance Training
297: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
462: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
286: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: Running Multi Instance Training
230: Running Multi Instance Training
248: Running Multi Instance Training
160: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
230: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
248: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: Running Multi Instance Training
361: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
145: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
173: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: Running Multi Instance Training
135: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
355: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: Running Multi Instance Training
286: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: Running Multi Instance Training
159: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
406: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
406: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: Running Multi Instance Training
290: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
145: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
106: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
176: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: Running Multi Instance Training
173: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  6: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: Running Multi Instance Training
406: Running Multi Instance Training
355: Running Multi Instance Training
 42: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
159: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
355: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
406: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  8: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: Running Multi Instance Training
217: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
290: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: Running Multi Instance Training
324: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
339: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
301: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
106: Running Multi Instance Training
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
176: Running Multi Instance Training
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 42: Running Multi Instance Training
 42: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: Running Multi Instance Training
  6: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: Running Multi Instance Training
217: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: Running Multi Instance Training
  8: Running Multi Instance Training
301: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  8: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
274: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
163: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: Running Multi Instance Training
 25: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
339: Running Multi Instance Training
339: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 80: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: Running Multi Instance Training
 77: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
259: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: Running Multi Instance Training
133: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
163: Running Multi Instance Training
274: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 25: Running Multi Instance Training
 25: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: Running Multi Instance Training
 31: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: Running Multi Instance Training
259: Running Multi Instance Training
 80: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
259: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: Running Multi Instance Training
353: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
353: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 15: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
247: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: Running Multi Instance Training
353: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
407: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
316: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
179: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
141: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: Running Multi Instance Training
 15: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
229: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: Running Multi Instance Training
247: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
315: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: Running Multi Instance Training
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: Running Multi Instance Training
195: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
407: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
179: Running Multi Instance Training
316: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
179: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
332: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 58: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  9: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: Running Multi Instance Training
141: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: Running Multi Instance Training
254: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
229: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  2: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: Running Multi Instance Training
 22: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
315: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: Running Multi Instance Training
195: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: Running Multi Instance Training
 35: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  9: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 82: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
296: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
104: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: Running Multi Instance Training
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: Running Multi Instance Training
254: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  2: Running Multi Instance Training
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: Running Multi Instance Training
 58: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  2: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 29: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
332: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
360: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: Running Multi Instance Training
 82: Running Multi Instance Training
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
296: Running Multi Instance Training
 82: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: Running Multi Instance Training
296: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
104: Running Multi Instance Training
104: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
265: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
326: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: Running Multi Instance Training
 29: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
251: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
251: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: Running Multi Instance Training
360: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
367: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
101: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: Running Multi Instance Training
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: Running Multi Instance Training
326: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  7: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
265: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
475: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
251: Running Multi Instance Training
251: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: Running Multi Instance Training
101: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 76: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: Running Multi Instance Training
455: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
244: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: Running Multi Instance Training
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
475: Running Multi Instance Training
475: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
164: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
143: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: Running Multi Instance Training
314: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 76: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
334: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: Running Multi Instance Training
158: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: Running Multi Instance Training
455: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: Running Multi Instance Training
143: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
303: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
334: Running Multi Instance Training
314: Running Multi Instance Training
463: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
334: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
314: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
330: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
158: Running Multi Instance Training
 24: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: Running Multi Instance Training
158: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
164: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: Running Multi Instance Training
380: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: Running Multi Instance Training
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: Running Multi Instance Training
303: Running Multi Instance Training
446: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: Running Multi Instance Training
330: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
303: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 24: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
123: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 12: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: Running Multi Instance Training
 39: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
256: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
366: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: Running Multi Instance Training
366: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 12: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: Running Multi Instance Training
446: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: Running Multi Instance Training
103: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
256: Running Multi Instance Training
256: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: Running Multi Instance Training
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
366: Running Multi Instance Training
366: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  4: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: Running Multi Instance Training
103: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
161: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
139: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: Running Multi Instance Training
  4: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
132: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 20: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: Running Multi Instance Training
161: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: Running Multi Instance Training
357: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: Running Multi Instance Training
 20: Running Multi Instance Training
132: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 20: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
336: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
354: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
382: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
331: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 11: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
445: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
178: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: Running Multi Instance Training
336: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: Running Multi Instance Training
382: Running Multi Instance Training
 91: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
382: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
461: Running Multi Instance Training
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
357: Running Multi Instance Training
357: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
203: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 28: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
165: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
331: Running Multi Instance Training
331: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: Running Multi Instance Training
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: Running Multi Instance Training
178: Running Multi Instance Training
 11: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
445: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
178: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: Running Multi Instance Training
 91: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
391: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 28: Running Multi Instance Training
165: Running Multi Instance Training
 28: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
165: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
403: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
453: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: Running Multi Instance Training
347: Running Multi Instance Training
203: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
347: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 78: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 78: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
126: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
459: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: Running Multi Instance Training
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
453: Running Multi Instance Training
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: Running Multi Instance Training
 81: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 81: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
391: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 78: Running Multi Instance Training
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: Running Multi Instance Training
 78: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
403: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
411: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: Running Multi Instance Training
126: Running Multi Instance Training
246: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
432: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
304: Running Multi Instance Training
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 81: Running Multi Instance Training
459: Running Multi Instance Training
 81: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
459: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 56: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: Running Multi Instance Training
 38: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
121: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
437: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
121: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: Running Multi Instance Training
 60: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
246: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: Running Multi Instance Training
 94: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: Running Multi Instance Training
337: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
337: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: Running Multi Instance Training
115: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: Running Multi Instance Training
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
437: Running Multi Instance Training
121: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
437: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
465: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
171: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 21: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 60: Running Multi Instance Training
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 60: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
337: Running Multi Instance Training
115: Running Multi Instance Training
337: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
115: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: Running Multi Instance Training
320: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 94: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: Running Multi Instance Training
505: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 13: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: Running Multi Instance Training
335: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
335: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: Running Multi Instance Training
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: Running Multi Instance Training
171: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
426: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: Running Multi Instance Training
129: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: Running Multi Instance Training
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: Running Multi Instance Training
359: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
151: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: Running Multi Instance Training
 13: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: Running Multi Instance Training
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: Running Multi Instance Training
320: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
335: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
454: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: Running Multi Instance Training
283: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
400: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: Running Multi Instance Training
359: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
269: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: Running Multi Instance Training
454: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: Running Multi Instance Training
400: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 72: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: Running Multi Instance Training
 59: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
269: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
370: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
365: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
110: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
201: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: Running Multi Instance Training
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: Running Multi Instance Training
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: Running Multi Instance Training
 62: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 72: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
370: Running Multi Instance Training
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
365: Running Multi Instance Training
383: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
262: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
365: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
148: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 46: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 46: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: Running Multi Instance Training
201: Running Multi Instance Training
110: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
201: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: Running Multi Instance Training
465: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
466: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: Running Multi Instance Training
137: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: Running Multi Instance Training
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: Running Multi Instance Training
127: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
127: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: Running Multi Instance Training
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 46: Running Multi Instance Training
148: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
128: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
510: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 46: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
413: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
169: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
169: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
278: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: Running Multi Instance Training
117: Running Multi Instance Training
127: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
128: Running Multi Instance Training
128: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: Running Multi Instance Training
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
169: Running Multi Instance Training
413: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: Running Multi Instance Training
152: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
458: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
305: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
305: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
235: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
278: Running Multi Instance Training
278: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
447: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 71: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 89: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 37: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: Running Multi Instance Training
458: Running Multi Instance Training
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
235: Running Multi Instance Training
458: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 84: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
235: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
122: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: Running Multi Instance Training
166: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
152: Running Multi Instance Training
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: Running Multi Instance Training
447: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
152: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
440: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 71: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
497: Running Multi Instance Training
 89: Running Multi Instance Training
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: Running Multi Instance Training
497: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 89: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 37: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
387: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: Running Multi Instance Training
166: Running Multi Instance Training
122: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 96: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: Running Multi Instance Training
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: Running Multi Instance Training
 84: Running Multi Instance Training
440: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 52: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 84: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
345: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 95: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: Running Multi Instance Training
387: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: Running Multi Instance Training
341: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
226: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
323: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: Running Multi Instance Training
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 95: Running Multi Instance Training
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: Running Multi Instance Training
 95: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
390: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
350: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: Running Multi Instance Training
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: Running Multi Instance Training
427: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: Running Multi Instance Training
323: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
451: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
451: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
294: Running Multi Instance Training
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: Running Multi Instance Training
422: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
294: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
390: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
186: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
204: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
350: Running Multi Instance Training
350: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
419: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: Running Multi Instance Training
509: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
451: Running Multi Instance Training
136: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
393: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: Running Multi Instance Training
 75: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 86: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: Running Multi Instance Training
422: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: Running Multi Instance Training
186: Running Multi Instance Training
204: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
186: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
401: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: Running Multi Instance Training
136: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: Running Multi Instance Training
 86: Running Multi Instance Training
419: Running Multi Instance Training
214: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 75: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 86: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
419: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
393: Running Multi Instance Training
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
401: Running Multi Instance Training
401: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
119: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
170: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
144: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: Running Multi Instance Training
214: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
202: Running Multi Instance Training
344: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
202: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
504: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
154: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: Running Multi Instance Training
170: Running Multi Instance Training
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
144: Running Multi Instance Training
170: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
241: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
144: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
125: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
220: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: Running Multi Instance Training
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: Running Multi Instance Training
377: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: Running Multi Instance Training
344: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
154: Running Multi Instance Training
503: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
154: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
375: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
389: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
236: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
241: Running Multi Instance Training
236: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 16: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
241: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: Running Multi Instance Training
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
220: Running Multi Instance Training
 63: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
174: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
220: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
428: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
208: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
197: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
468: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
414: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: Running Multi Instance Training
456: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: Running Multi Instance Training
389: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
351: Running Multi Instance Training
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
236: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 16: Running Multi Instance Training
351: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
498: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 16: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: Running Multi Instance Training
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: Running Multi Instance Training
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 63: Running Multi Instance Training
131: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
174: Running Multi Instance Training
503: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
375: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 63: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
174: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: Running Multi Instance Training
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: Running Multi Instance Training
208: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
395: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
181: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: Running Multi Instance Training
456: Running Multi Instance Training
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
428: Running Multi Instance Training
456: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: Running Multi Instance Training
 40: Running Multi Instance Training
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
149: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
498: Running Multi Instance Training
197: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 40: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: Running Multi Instance Training
498: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
306: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: Running Multi Instance Training
131: Running Multi Instance Training
288: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
131: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: Running Multi Instance Training
466: Running Multi Instance Training
466: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
467: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: Running Multi Instance Training
467: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
395: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
487: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: Running Multi Instance Training
149: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: Running Multi Instance Training
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: Running Multi Instance Training
306: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 66: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
181: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 93: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
425: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
322: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
506: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: Running Multi Instance Training
 93: Running Multi Instance Training
 66: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 93: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
449: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: Running Multi Instance Training
425: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: Running Multi Instance Training
322: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: Running Multi Instance Training
506: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
493: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: Running Multi Instance Training
449: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
423: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
273: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
187: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
252: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
416: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
479: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
429: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 73: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
404: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: Running Multi Instance Training
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
273: Running Multi Instance Training
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: Running Multi Instance Training
198: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
198: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: Running Multi Instance Training
511: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
493: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
187: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: Running Multi Instance Training
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: Running Multi Instance Training
252: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
416: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: Running Multi Instance Training
429: Running Multi Instance Training
404: Running Multi Instance Training
 73: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
429: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
193: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: Running Multi Instance Training
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
511: Running Multi Instance Training
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
482: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
479: Running Multi Instance Training
479: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: Running Multi Instance Training
180: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 49: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 99: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: Running Multi Instance Training
228: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
319: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: Running Multi Instance Training
193: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
216: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
116: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
308: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: Running Multi Instance Training
298: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
228: Running Multi Instance Training
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: Running Multi Instance Training
228: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
482: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: Running Multi Instance Training
487: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
485: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: Running Multi Instance Training
216: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: Running Multi Instance Training
116: Running Multi Instance Training
374: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 49: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
116: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: Running Multi Instance Training
298: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: Running Multi Instance Training
308: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 87: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
362: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: Running Multi Instance Training
374: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
153: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
471: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
472: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
488: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: Running Multi Instance Training
 87: Running Multi Instance Training
362: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 87: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: Running Multi Instance Training
471: Running Multi Instance Training
153: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
471: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: Running Multi Instance Training
472: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: Running Multi Instance Training
477: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: Running Multi Instance Training
488: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: Running Multi Instance Training
250: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 67: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
156: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: Running Multi Instance Training
477: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 10: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 98: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
398: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: Running Multi Instance Training
 67: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: Running Multi Instance Training
300: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
156: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 27: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: Running Multi Instance Training
 10: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
258: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: Running Multi Instance Training
 98: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
348: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: Running Multi Instance Training
312: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
300: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: Running Multi Instance Training
 27: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
448: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: Running Multi Instance Training
258: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: Running Multi Instance Training
348: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
392: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
494: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: Running Multi Instance Training
312: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
448: Running Multi Instance Training
448: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
100: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
134: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
162: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: Running Multi Instance Training
392: Running Multi Instance Training
417: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
185: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
494: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
392: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: Running Multi Instance Training
140: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
421: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
310: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: Running Multi Instance Training
485: Running Multi Instance Training
100: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
485: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
484: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: Running Multi Instance Training
484: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: Running Multi Instance Training
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
162: Running Multi Instance Training
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: Running Multi Instance Training
185: Running Multi Instance Training
417: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
185: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
483: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: Running Multi Instance Training
 50: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
310: Running Multi Instance Training
  5: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
310: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
196: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
196: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
189: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: Running Multi Instance Training
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 50: Running Multi Instance Training
 50: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: Running Multi Instance Training
  5: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
500: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
196: Running Multi Instance Training
177: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
196: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
177: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
460: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
460: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: Running Multi Instance Training
182: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: Running Multi Instance Training
500: Running Multi Instance Training
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
491: Running Multi Instance Training
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
177: Running Multi Instance Training
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
460: Running Multi Instance Training
460: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 30: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
328: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: Running Multi Instance Training
182: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
352: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 79: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: Running Multi Instance Training
372: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
469: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: Running Multi Instance Training
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: Running Multi Instance Training
 30: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
328: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: Running Multi Instance Training
352: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: Running Multi Instance Training
 79: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: Running Multi Instance Training
469: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
105: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
327: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
480: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: Running Multi Instance Training
105: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: Running Multi Instance Training
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: Running Multi Instance Training
327: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
338: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: Running Multi Instance Training
480: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: Running Multi Instance Training
398: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
397: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
245: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
501: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: Running Multi Instance Training
338: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: Running Multi Instance Training
 14: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: Running Multi Instance Training
 83: Running Multi Instance Training
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 83: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
501: Running Multi Instance Training
501: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
495: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
333: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
476: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: Running Multi Instance Training
495: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: Running Multi Instance Training
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
476: Running Multi Instance Training
476: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 57: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 23: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: Running Multi Instance Training
 57: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: Running Multi Instance Training
 23: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 51: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
309: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
364: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: Running Multi Instance Training
 51: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: Running Multi Instance Training
309: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: Running Multi Instance Training
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: Running Multi Instance Training
381: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
364: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
489: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
444: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: Running Multi Instance Training
489: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 88: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
452: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: Running Multi Instance Training
444: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
397: Running Multi Instance Training
397: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
399: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: Running Multi Instance Training
399: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: Running Multi Instance Training
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
452: Running Multi Instance Training
452: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
191: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
167: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
120: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: Running Multi Instance Training
120: Running Multi Instance Training
 36: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
356: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
167: Running Multi Instance Training
191: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
120: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 36: Running Multi Instance Training
356: Running Multi Instance Training
 36: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
356: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
200: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: Running Multi Instance Training
346: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: Running Multi Instance Training
200: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
415: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 61: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
124: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
402: Running Multi Instance Training
402: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: Running Multi Instance Training
 61: Running Multi Instance Training
415: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: Running Multi Instance Training
124: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
457: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
388: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
464: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: Running Multi Instance Training
388: Running Multi Instance Training
457: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
388: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: Running Multi Instance Training
190: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: Running Multi Instance Training
464: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
138: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
130: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
307: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
321: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: Running Multi Instance Training
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
130: Running Multi Instance Training
130: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
168: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: Running Multi Instance Training
307: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: Running Multi Instance Training
507: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
321: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 92: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
150: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: Running Multi Instance Training
168: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: Running Multi Instance Training
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: Running Multi Instance Training
507: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 92: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: Running Multi Instance Training
 74: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
150: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: Running Multi Instance Training
 74: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
424: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
499: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: Running Multi Instance Training
424: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: Running Multi Instance Training
499: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
508: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: Running Multi Instance Training
508: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: Running Multi Instance Training
118: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 85: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 97: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: Running Multi Instance Training
 85: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: Running Multi Instance Training
155: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: Running Multi Instance Training
 97: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
450: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
349: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: Running Multi Instance Training
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: Running Multi Instance Training
450: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
349: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
418: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: Running Multi Instance Training
418: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
184: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: Running Multi Instance Training
420: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: Running Multi Instance Training
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
184: Running Multi Instance Training
184: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
199: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
430: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
470: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
183: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: Running Multi Instance Training
486: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
486: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: Running Multi Instance Training
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: Running Multi Instance Training
430: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: Running Multi Instance Training
470: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
183: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: Running Multi Instance Training
486: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
373: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 65: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: Running Multi Instance Training
373: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: Running Multi Instance Training
 65: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
492: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
502: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: Running Multi Instance Training
492: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: Running Multi Instance Training
502: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
481: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: Running Multi Instance Training
481: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
478: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 48: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: Running Multi Instance Training
478: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: Running Multi Instance Training
 48: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
490: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: Running Multi Instance Training
490: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
311: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: Running Multi Instance Training
311: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
396: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: Running Multi Instance Training
396: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
188: STARTING TIMING RUN AT 2021-10-05 08:36:11 AM
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: Running Multi Instance Training
188: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1483002 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1483002 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 44: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  4: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
160: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
128: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: creating process group
 52: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 45: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 45: creating process group
 32: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 12: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 48: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  5: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
172: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: creating process group
136: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
129: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: creating process group
168: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 56: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: creating process group
  2: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  2: creating process group
 53: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 40: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 46: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: creating process group
 14: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 49: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  6: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
173: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
162: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
130: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
130: creating process group
164: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
169: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 58: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 58: creating process group
 10: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: creating process group
 54: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 47: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 47: creating process group
 34: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 34: creating process group
 15: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 51: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  7: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
174: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
174: creating process group
163: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
138: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
131: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
131: creating process group
165: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
170: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 59: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 59: creating process group
 11: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  0: creating process group
 55: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 55: creating process group
 42: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
204: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 44: creating process group
 35: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 35: creating process group
236: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 12: creating process group
 48: creating process group
194: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  4: creating process group
175: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
175: creating process group
160: creating process group
139: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
139: creating process group
128: creating process group
167: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
200: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 56: creating process group
 10: creating process group
 52: creating process group
 43: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
205: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 46: creating process group
 32: creating process group
212: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 14: creating process group
 49: creating process group
195: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 60: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  5: creating process group
172: creating process group
162: creating process group
136: creating process group
196: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
129: creating process group
168: creating process group
200: creating process group
 57: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
152: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 11: creating process group
 53: creating process group
208: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 40: creating process group
216: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
206: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
206: creating process group
224: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
236: creating process group
140: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
213: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
144: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
156: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
156: creating process group
 15: creating process group
 51: creating process group
194: creating process group
  6: creating process group
173: creating process group
163: creating process group
148: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: creating process group
197: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
197: creating process group
164: creating process group
169: creating process group
203: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 57: creating process group
153: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: creating process group
 54: creating process group
209: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
232: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
220: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 42: creating process group
217: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
217: creating process group
109: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
207: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
207: creating process group
225: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 68: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
141: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
214: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: creating process group
157: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
157: creating process group
 13: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 50: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: creating process group
 61: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
182: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  7: creating process group
 77: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 64: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 88: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
138: creating process group
198: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
198: creating process group
184: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
176: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
165: creating process group
 92: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
170: creating process group
 96: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 84: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
201: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
155: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
188: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: creating process group
233: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
220: creating process group
 43: creating process group
219: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
219: creating process group
110: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
204: creating process group
226: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 70: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
140: creating process group
215: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
146: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
146: creating process group
158: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
158: creating process group
228: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 13: creating process group
 50: creating process group
192: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 62: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
182: creating process group
 79: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 65: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
101: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 28: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 89: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
149: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
149: creating process group
199: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
199: creating process group
185: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
178: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
178: creating process group
 20: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
105: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 83: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 83: creating process group
167: creating process group
 93: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: creating process group
 97: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 97: creating process group
 85: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 85: creating process group
203: creating process group
152: creating process group
208: creating process group
 16: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
112: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
234: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
234: creating process group
221: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 41: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
216: creating process group
109: creating process group
205: creating process group
227: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
227: creating process group
 71: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
143: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
212: creating process group
147: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
147: creating process group
 25: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
159: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
159: creating process group
229: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
120: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
133: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
193: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 60: creating process group
180: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 77: creating process group
 66: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
102: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 29: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 29: creating process group
125: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 90: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 90: creating process group
150: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
150: creating process group
196: creating process group
186: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
179: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 21: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
107: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
107: creating process group
 80: creating process group
 94: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: creating process group
 86: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 86: creating process group
201: creating process group
153: creating process group
190: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
209: creating process group
 18: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 18: creating process group
113: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
235: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
235: creating process group
223: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 41: creating process group
218: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
110: creating process group
224: creating process group
 68: creating process group
238: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
141: creating process group
213: creating process group
144: creating process group
 27: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
231: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
121: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
134: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
134: creating process group
192: creating process group
 61: creating process group
181: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 78: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 67: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 67: creating process group
103: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
103: creating process group
 30: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 30: creating process group
127: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 91: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 91: creating process group
151: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
151: creating process group
184: creating process group
176: creating process group
 20: creating process group
104: creating process group
 82: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
116: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: creating process group
 87: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 87: creating process group
202: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
155: creating process group
191: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
210: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: creating process group
114: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
232: creating process group
221: creating process group
218: creating process group
108: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
252: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
225: creating process group
 70: creating process group
238: creating process group
143: creating process group
214: creating process group
 25: creating process group
228: creating process group
122: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
122: creating process group
135: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
135: creating process group
193: creating process group
 62: creating process group
183: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 79: creating process group
 64: creating process group
101: creating process group
 31: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 31: creating process group
124: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 88: creating process group
244: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
148: creating process group
185: creating process group
179: creating process group
 21: creating process group
105: creating process group
 81: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
118: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 92: creating process group
 72: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 96: creating process group
 84: creating process group
202: creating process group
154: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
188: creating process group
210: creating process group
 16: creating process group
115: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
233: creating process group
223: creating process group
111: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
240: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
255: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
226: creating process group
 71: creating process group
239: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
142: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
215: creating process group
248: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 26: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
229: creating process group
123: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
133: creating process group
 36: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 63: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
180: creating process group
 76: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 65: creating process group
102: creating process group
 28: creating process group
125: creating process group
 89: creating process group
245: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
186: creating process group
177: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 22: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
106: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 82: creating process group
119: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: creating process group
 73: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
154: creating process group
190: creating process group
 17: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
112: creating process group
222: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
108: creating process group
241: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
241: creating process group
252: creating process group
 69: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
237: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
142: creating process group
249: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 27: creating process group
231: creating process group
120: creating process group
132: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 39: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 63: creating process group
181: creating process group
 78: creating process group
 66: creating process group
100: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
126: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
246: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
187: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
177: creating process group
 23: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
106: creating process group
 81: creating process group
116: creating process group
 94: creating process group
 72: creating process group
191: creating process group
 17: creating process group
113: creating process group
111: creating process group
242: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
242: creating process group
255: creating process group
 69: creating process group
239: creating process group
251: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 24: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
230: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
121: creating process group
132: creating process group
 39: creating process group
183: creating process group
 76: creating process group
100: creating process group
127: creating process group
244: creating process group
187: creating process group
 22: creating process group
117: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: creating process group
 73: creating process group
189: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
114: creating process group
243: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
243: creating process group
253: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
237: creating process group
248: creating process group
 26: creating process group
230: creating process group
123: creating process group
 36: creating process group
124: creating process group
245: creating process group
 23: creating process group
118: creating process group
 74: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
189: creating process group
115: creating process group
222: creating process group
240: creating process group
254: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
249: creating process group
 24: creating process group
 37: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
126: creating process group
246: creating process group
119: creating process group
 75: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
253: creating process group
251: creating process group
 38: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
247: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
117: creating process group
 75: creating process group
254: creating process group
250: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
247: creating process group
 74: creating process group
250: creating process group
 37: creating process group
 38: creating process group
404: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
285: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
272: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
396: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
292: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
280: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
256: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
408: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
288: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
264: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
276: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
320: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
352: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
424: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
400: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
372: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
412: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
388: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
392: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
269: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
376: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
432: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
360: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
384: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
277: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
348: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
260: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
407: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
368: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
286: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
324: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
444: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
337: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
364: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
340: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
273: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
344: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
356: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
374: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
428: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
423: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
416: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
397: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
293: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
281: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
281: creating process group
304: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
257: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
257: creating process group
472: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
409: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
312: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
289: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
265: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
278: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
440: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
261: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
404: creating process group
297: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
285: creating process group
338: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
328: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
353: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
460: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
425: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
401: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
401: creating process group
448: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
275: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
380: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
308: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
357: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
332: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
452: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
413: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
389: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
468: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
456: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
393: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
393: creating process group
429: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: creating process group
480: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
489: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
492: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
476: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
399: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
464: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
317: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
294: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
270: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
282: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
282: creating process group
307: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
377: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
433: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
410: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
361: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
290: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
266: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
385: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
301: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: creating process group
349: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
441: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
260: creating process group
406: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
369: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
369: creating process group
286: creating process group
324: creating process group
445: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
339: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
339: creating process group
437: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
365: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
341: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
329: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: creating process group
426: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
402: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
402: creating process group
449: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
272: creating process group
345: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
381: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
359: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
359: creating process group
333: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
372: creating process group
412: creating process group
390: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
394: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
394: creating process group
430: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
423: creating process group
482: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
490: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
418: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
396: creating process group
484: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
318: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
295: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
295: creating process group
271: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
283: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
283: creating process group
304: creating process group
259: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: creating process group
473: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
473: creating process group
378: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
378: creating process group
434: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
411: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
411: creating process group
313: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
362: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
291: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
291: creating process group
267: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
267: creating process group
386: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
302: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
276: creating process group
350: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
442: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
322: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
261: creating process group
407: creating process group
298: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
371: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
371: creating process group
287: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
325: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
446: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
446: creating process group
337: creating process group
438: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
366: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
342: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
330: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
330: creating process group
355: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
463: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
509: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
425: creating process group
403: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
403: creating process group
450: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
275: creating process group
346: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
310: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
356: creating process group
334: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
453: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
374: creating process group
501: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
413: creating process group
391: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
391: creating process group
504: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
469: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
457: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
457: creating process group
395: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
395: creating process group
431: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
431: creating process group
420: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
480: creating process group
491: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
493: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
419: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
477: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
496: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
397: creating process group
465: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
486: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
318: creating process group
292: creating process group
269: creating process group
280: creating process group
307: creating process group
256: creating process group
474: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: creating process group
435: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
408: creating process group
314: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
363: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
363: creating process group
288: creating process group
264: creating process group
387: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
387: creating process group
303: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
303: creating process group
277: creating process group
351: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
351: creating process group
443: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
323: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
263: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
297: creating process group
368: creating process group
284: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
326: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
447: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
447: creating process group
338: creating process group
439: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
367: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
343: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
331: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
331: creating process group
352: creating process group
460: creating process group
510: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
426: creating process group
400: creating process group
451: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
451: creating process group
273: creating process group
344: creating process group
383: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
383: creating process group
311: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
311: creating process group
357: creating process group
335: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
454: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: creating process group
503: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
388: creating process group
504: creating process group
470: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
458: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
458: creating process group
392: creating process group
428: creating process group
422: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
482: creating process group
489: creating process group
494: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
416: creating process group
478: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
497: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
399: creating process group
466: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
487: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
487: creating process group
317: creating process group
293: creating process group
270: creating process group
305: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: creating process group
475: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
475: creating process group
376: creating process group
432: creating process group
409: creating process group
315: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
360: creating process group
289: creating process group
265: creating process group
384: creating process group
300: creating process group
278: creating process group
348: creating process group
440: creating process group
320: creating process group
263: creating process group
406: creating process group
298: creating process group
370: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
284: creating process group
327: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
444: creating process group
336: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: creating process group
364: creating process group
340: creating process group
328: creating process group
353: creating process group
463: creating process group
511: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
448: creating process group
274: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
345: creating process group
380: creating process group
308: creating process group
358: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
332: creating process group
455: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
455: creating process group
373: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
501: creating process group
415: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
389: creating process group
507: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
471: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
471: creating process group
459: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
459: creating process group
429: creating process group
420: creating process group
481: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
490: creating process group
495: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: creating process group
479: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
479: creating process group
498: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
398: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
467: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
467: creating process group
484: creating process group
319: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
294: creating process group
271: creating process group
306: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
472: creating process group
377: creating process group
433: creating process group
410: creating process group
312: creating process group
361: creating process group
290: creating process group
266: creating process group
385: creating process group
301: creating process group
349: creating process group
441: creating process group
321: creating process group
262: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: creating process group
299: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
370: creating process group
287: creating process group
326: creating process group
445: creating process group
336: creating process group
437: creating process group
365: creating process group
341: creating process group
329: creating process group
355: creating process group
461: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
509: creating process group
424: creating process group
449: creating process group
274: creating process group
346: creating process group
381: creating process group
310: creating process group
358: creating process group
333: creating process group
452: creating process group
373: creating process group
500: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: creating process group
390: creating process group
505: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
468: creating process group
456: creating process group
430: creating process group
422: creating process group
483: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
491: creating process group
492: creating process group
418: creating process group
476: creating process group
499: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
398: creating process group
464: creating process group
485: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
316: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
268: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
305: creating process group
474: creating process group
434: creating process group
313: creating process group
362: creating process group
386: creating process group
302: creating process group
350: creating process group
442: creating process group
322: creating process group
262: creating process group
296: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
327: creating process group
438: creating process group
366: creating process group
342: creating process group
462: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
510: creating process group
427: creating process group
450: creating process group
347: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: creating process group
309: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
334: creating process group
453: creating process group
502: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: creating process group
506: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
469: creating process group
481: creating process group
488: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
493: creating process group
419: creating process group
477: creating process group
496: creating process group
465: creating process group
486: creating process group
319: creating process group
268: creating process group
306: creating process group
435: creating process group
314: creating process group
443: creating process group
323: creating process group
299: creating process group
325: creating process group
439: creating process group
367: creating process group
343: creating process group
461: creating process group
511: creating process group
347: creating process group
309: creating process group
335: creating process group
454: creating process group
503: creating process group
507: creating process group
470: creating process group
483: creating process group
488: creating process group
494: creating process group
478: creating process group
497: creating process group
466: creating process group
485: creating process group
316: creating process group
315: creating process group
296: creating process group
462: creating process group
508: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
500: creating process group
505: creating process group
495: creating process group
498: creating process group
508: creating process group
502: creating process group
506: creating process group
499: creating process group
  0: Process group successfully created for rank 0 . Now a global mpi barrier...
162: Process group successfully created for rank 162 . Now a global mpi barrier...
182: Process group successfully created for rank 182 . Now a global mpi barrier...
184: Process group successfully created for rank 184 . Now a global mpi barrier...
177: Process group successfully created for rank 177 . Now a global mpi barrier...
 99: Process group successfully created for rank 99 . Now a global mpi barrier...
158: Process group successfully created for rank 158 . Now a global mpi barrier...
157: Process group successfully created for rank 157 . Now a global mpi barrier...
192: Process group successfully created for rank 192 . Now a global mpi barrier...
185: Process group successfully created for rank 185 . Now a global mpi barrier...
188: Process group successfully created for rank 188 . Now a global mpi barrier...
208: Process group successfully created for rank 208 . Now a global mpi barrier...
213: Process group successfully created for rank 213 . Now a global mpi barrier...
193: Process group successfully created for rank 193 . Now a global mpi barrier...
183: Process group successfully created for rank 183 . Now a global mpi barrier...
196: Process group successfully created for rank 196 . Now a global mpi barrier...
187: Process group successfully created for rank 187 . Now a global mpi barrier...
200: Process group successfully created for rank 200 . Now a global mpi barrier...
210: Process group successfully created for rank 210 . Now a global mpi barrier...
217: Process group successfully created for rank 217 . Now a global mpi barrier...
204: Process group successfully created for rank 204 . Now a global mpi barrier...
212: Process group successfully created for rank 212 . Now a global mpi barrier...
194: Process group successfully created for rank 194 . Now a global mpi barrier...
198: Process group successfully created for rank 198 . Now a global mpi barrier...
186: Process group successfully created for rank 186 . Now a global mpi barrier...
170: Process group successfully created for rank 170 . Now a global mpi barrier...
201: Process group successfully created for rank 201 . Now a global mpi barrier...
189: Process group successfully created for rank 189 . Now a global mpi barrier...
220: Process group successfully created for rank 220 . Now a global mpi barrier...
219: Process group successfully created for rank 219 . Now a global mpi barrier...
206: Process group successfully created for rank 206 . Now a global mpi barrier...
225: Process group successfully created for rank 225 . Now a global mpi barrier...
214: Process group successfully created for rank 214 . Now a global mpi barrier...
195: Process group successfully created for rank 195 . Now a global mpi barrier...
197: Process group successfully created for rank 197 . Now a global mpi barrier...
202: Process group successfully created for rank 202 . Now a global mpi barrier...
190: Process group successfully created for rank 190 . Now a global mpi barrier...
209: Process group successfully created for rank 209 . Now a global mpi barrier...
232: Process group successfully created for rank 232 . Now a global mpi barrier...
221: Process group successfully created for rank 221 . Now a global mpi barrier...
218: Process group successfully created for rank 218 . Now a global mpi barrier...
207: Process group successfully created for rank 207 . Now a global mpi barrier...
226: Process group successfully created for rank 226 . Now a global mpi barrier...
215: Process group successfully created for rank 215 . Now a global mpi barrier...
228: Process group successfully created for rank 228 . Now a global mpi barrier...
199: Process group successfully created for rank 199 . Now a global mpi barrier...
203: Process group successfully created for rank 203 . Now a global mpi barrier...
191: Process group successfully created for rank 191 . Now a global mpi barrier...
233: Process group successfully created for rank 233 . Now a global mpi barrier...
222: Process group successfully created for rank 222 . Now a global mpi barrier...
216: Process group successfully created for rank 216 . Now a global mpi barrier...
224: Process group successfully created for rank 224 . Now a global mpi barrier...
236: Process group successfully created for rank 236 . Now a global mpi barrier...
230: Process group successfully created for rank 230 . Now a global mpi barrier...
244: Process group successfully created for rank 244 . Now a global mpi barrier...
234: Process group successfully created for rank 234 . Now a global mpi barrier...
223: Process group successfully created for rank 223 . Now a global mpi barrier...
243: Process group successfully created for rank 243 . Now a global mpi barrier...
252: Process group successfully created for rank 252 . Now a global mpi barrier...
237: Process group successfully created for rank 237 . Now a global mpi barrier...
248: Process group successfully created for rank 248 . Now a global mpi barrier...
231: Process group successfully created for rank 231 . Now a global mpi barrier...
269: Process group successfully created for rank 269 . Now a global mpi barrier...
235: Process group successfully created for rank 235 . Now a global mpi barrier...
257: Process group successfully created for rank 257 . Now a global mpi barrier...
242: Process group successfully created for rank 242 . Now a global mpi barrier...
255: Process group successfully created for rank 255 . Now a global mpi barrier...
260: Process group successfully created for rank 260 . Now a global mpi barrier...
239: Process group successfully created for rank 239 . Now a global mpi barrier...
249: Process group successfully created for rank 249 . Now a global mpi barrier...
270: Process group successfully created for rank 270 . Now a global mpi barrier...
256: Process group successfully created for rank 256 . Now a global mpi barrier...
241: Process group successfully created for rank 241 . Now a global mpi barrier...
264: Process group successfully created for rank 264 . Now a global mpi barrier...
253: Process group successfully created for rank 253 . Now a global mpi barrier...
261: Process group successfully created for rank 261 . Now a global mpi barrier...
238: Process group successfully created for rank 238 . Now a global mpi barrier...
250: Process group successfully created for rank 250 . Now a global mpi barrier...
245: Process group successfully created for rank 245 . Now a global mpi barrier...
272: Process group successfully created for rank 272 . Now a global mpi barrier...
258: Process group successfully created for rank 258 . Now a global mpi barrier...
266: Process group successfully created for rank 266 . Now a global mpi barrier...
276: Process group successfully created for rank 276 . Now a global mpi barrier...
254: Process group successfully created for rank 254 . Now a global mpi barrier...
263: Process group successfully created for rank 263 . Now a global mpi barrier...
246: Process group successfully created for rank 246 . Now a global mpi barrier...
275: Process group successfully created for rank 275 . Now a global mpi barrier...
259: Process group successfully created for rank 259 . Now a global mpi barrier...
288: Process group successfully created for rank 288 . Now a global mpi barrier...
265: Process group successfully created for rank 265 . Now a global mpi barrier...
277: Process group successfully created for rank 277 . Now a global mpi barrier...
251: Process group successfully created for rank 251 . Now a global mpi barrier...
247: Process group successfully created for rank 247 . Now a global mpi barrier...
273: Process group successfully created for rank 273 . Now a global mpi barrier...
300: Process group successfully created for rank 300 . Now a global mpi barrier...
285: Process group successfully created for rank 285 . Now a global mpi barrier...
293: Process group successfully created for rank 293 . Now a global mpi barrier...
287: Process group successfully created for rank 287 . Now a global mpi barrier...
301: Process group successfully created for rank 301 . Now a global mpi barrier...
316: Process group successfully created for rank 316 . Now a global mpi barrier...
305: Process group successfully created for rank 305 . Now a global mpi barrier...
313: Process group successfully created for rank 313 . Now a global mpi barrier...
291: Process group successfully created for rank 291 . Now a global mpi barrier...
302: Process group successfully created for rank 302 . Now a global mpi barrier...
314: Process group successfully created for rank 314 . Now a global mpi barrier...
289: Process group successfully created for rank 289 . Now a global mpi barrier...
320: Process group successfully created for rank 320 . Now a global mpi barrier...
299: Process group successfully created for rank 299 . Now a global mpi barrier...
312: Process group successfully created for rank 312 . Now a global mpi barrier...
303: Process group successfully created for rank 303 . Now a global mpi barrier...
321: Process group successfully created for rank 321 . Now a global mpi barrier...
324: Process group successfully created for rank 324 . Now a global mpi barrier...
323: Process group successfully created for rank 323 . Now a global mpi barrier...
329: Process group successfully created for rank 329 . Now a global mpi barrier...
311: Process group successfully created for rank 311 . Now a global mpi barrier...
322: Process group successfully created for rank 322 . Now a global mpi barrier...
334: Process group successfully created for rank 334 . Now a global mpi barrier...
336: Process group successfully created for rank 336 . Now a global mpi barrier...
345: Process group successfully created for rank 345 . Now a global mpi barrier...
335: Process group successfully created for rank 335 . Now a global mpi barrier...
350: Process group successfully created for rank 350 . Now a global mpi barrier...
337: Process group successfully created for rank 337 . Now a global mpi barrier...
348: Process group successfully created for rank 348 . Now a global mpi barrier...
338: Process group successfully created for rank 338 . Now a global mpi barrier...
346: Process group successfully created for rank 346 . Now a global mpi barrier...
349: Process group successfully created for rank 349 . Now a global mpi barrier...
339: Process group successfully created for rank 339 . Now a global mpi barrier...
360: Process group successfully created for rank 360 . Now a global mpi barrier...
351: Process group successfully created for rank 351 . Now a global mpi barrier...
325: Process group successfully created for rank 325 . Now a global mpi barrier...
357: Process group successfully created for rank 357 . Now a global mpi barrier...
369: Process group successfully created for rank 369 . Now a global mpi barrier...
326: Process group successfully created for rank 326 . Now a global mpi barrier...
361: Process group successfully created for rank 361 . Now a global mpi barrier...
327: Process group successfully created for rank 327 . Now a global mpi barrier...
359: Process group successfully created for rank 359 . Now a global mpi barrier...
372: Process group successfully created for rank 372 . Now a global mpi barrier...
376: Process group successfully created for rank 376 . Now a global mpi barrier...
363: Process group successfully created for rank 363 . Now a global mpi barrier...
381: Process group successfully created for rank 381 . Now a global mpi barrier...
374: Process group successfully created for rank 374 . Now a global mpi barrier...
373: Process group successfully created for rank 373 . Now a global mpi barrier...
486: Process group successfully created for rank 486 . Now a global mpi barrier...
507: Process group successfully created for rank 507 . Now a global mpi barrier...
509: Process group successfully created for rank 509 . Now a global mpi barrier...
499: Process group successfully created for rank 499 . Now a global mpi barrier...
510: Process group successfully created for rank 510 . Now a global mpi barrier...
498: Process group successfully created for rank 498 . Now a global mpi barrier...
294: Process group successfully created for rank 294 . Now a global mpi barrier...
280: Process group successfully created for rank 280 . Now a global mpi barrier...
295: Process group successfully created for rank 295 . Now a global mpi barrier...
281: Process group successfully created for rank 281 . Now a global mpi barrier...
282: Process group successfully created for rank 282 . Now a global mpi barrier...
304: Process group successfully created for rank 304 . Now a global mpi barrier...
283: Process group successfully created for rank 283 . Now a global mpi barrier...
307: Process group successfully created for rank 307 . Now a global mpi barrier...
354: Process group successfully created for rank 354 . Now a global mpi barrier...
297: Process group successfully created for rank 297 . Now a global mpi barrier...
364: Process group successfully created for rank 364 . Now a global mpi barrier...
377: Process group successfully created for rank 377 . Now a global mpi barrier...
375: Process group successfully created for rank 375 . Now a global mpi barrier...
365: Process group successfully created for rank 365 . Now a global mpi barrier...
383: Process group successfully created for rank 383 . Now a global mpi barrier...
 51: Process group successfully created for rank 51 . Now a global mpi barrier...
  7: Process group successfully created for rank 7 . Now a global mpi barrier...
271: Process group successfully created for rank 271 . Now a global mpi barrier...
306: Process group successfully created for rank 306 . Now a global mpi barrier...
309: Process group successfully created for rank 309 . Now a global mpi barrier...
296: Process group successfully created for rank 296 . Now a global mpi barrier...
284: Process group successfully created for rank 284 . Now a global mpi barrier...
330: Process group successfully created for rank 330 . Now a global mpi barrier...
319: Process group successfully created for rank 319 . Now a global mpi barrier...
340: Process group successfully created for rank 340 . Now a global mpi barrier...
353: Process group successfully created for rank 353 . Now a global mpi barrier...
347: Process group successfully created for rank 347 . Now a global mpi barrier...
333: Process group successfully created for rank 333 . Now a global mpi barrier...
 57: Process group successfully created for rank 57 . Now a global mpi barrier...
286: Process group successfully created for rank 286 . Now a global mpi barrier...
341: Process group successfully created for rank 341 . Now a global mpi barrier...
355: Process group successfully created for rank 355 . Now a global mpi barrier...
332: Process group successfully created for rank 332 . Now a global mpi barrier...
342: Process group successfully created for rank 342 . Now a global mpi barrier...
308: Process group successfully created for rank 308 . Now a global mpi barrier...
385: Process group successfully created for rank 385 . Now a global mpi barrier...
368: Process group successfully created for rank 368 . Now a global mpi barrier...
343: Process group successfully created for rank 343 . Now a global mpi barrier...
388: Process group successfully created for rank 388 . Now a global mpi barrier...
317: Process group successfully created for rank 317 . Now a global mpi barrier...
298: Process group successfully created for rank 298 . Now a global mpi barrier...
371: Process group successfully created for rank 371 . Now a global mpi barrier...
366: Process group successfully created for rank 366 . Now a global mpi barrier...
310: Process group successfully created for rank 310 . Now a global mpi barrier...
384: Process group successfully created for rank 384 . Now a global mpi barrier...
331: Process group successfully created for rank 331 . Now a global mpi barrier...
382: Process group successfully created for rank 382 . Now a global mpi barrier...
392: Process group successfully created for rank 392 . Now a global mpi barrier...
387: Process group successfully created for rank 387 . Now a global mpi barrier...
404: Process group successfully created for rank 404 . Now a global mpi barrier...
370: Process group successfully created for rank 370 . Now a global mpi barrier...
396: Process group successfully created for rank 396 . Now a global mpi barrier...
362: Process group successfully created for rank 362 . Now a global mpi barrier...
386: Process group successfully created for rank 386 . Now a global mpi barrier...
394: Process group successfully created for rank 394 . Now a global mpi barrier...
397: Process group successfully created for rank 397 . Now a global mpi barrier...
403: Process group successfully created for rank 403 . Now a global mpi barrier...
398: Process group successfully created for rank 398 . Now a global mpi barrier...
399: Process group successfully created for rank 399 . Now a global mpi barrier...
389: Process group successfully created for rank 389 . Now a global mpi barrier...
488: Process group successfully created for rank 488 . Now a global mpi barrier...
508: Process group successfully created for rank 508 . Now a global mpi barrier...
367: Process group successfully created for rank 367 . Now a global mpi barrier...
356: Process group successfully created for rank 356 . Now a global mpi barrier...
378: Process group successfully created for rank 378 . Now a global mpi barrier...
401: Process group successfully created for rank 401 . Now a global mpi barrier...
344: Process group successfully created for rank 344 . Now a global mpi barrier...
379: Process group successfully created for rank 379 . Now a global mpi barrier...
406: Process group successfully created for rank 406 . Now a global mpi barrier...
391: Process group successfully created for rank 391 . Now a global mpi barrier...
402: Process group successfully created for rank 402 . Now a global mpi barrier...
393: Process group successfully created for rank 393 . Now a global mpi barrier...
408: Process group successfully created for rank 408 . Now a global mpi barrier...
407: Process group successfully created for rank 407 . Now a global mpi barrier...
412: Process group successfully created for rank 412 . Now a global mpi barrier...
358: Process group successfully created for rank 358 . Now a global mpi barrier...
426: Process group successfully created for rank 426 . Now a global mpi barrier...
413: Process group successfully created for rank 413 . Now a global mpi barrier...
395: Process group successfully created for rank 395 . Now a global mpi barrier...
415: Process group successfully created for rank 415 . Now a global mpi barrier...
421: Process group successfully created for rank 421 . Now a global mpi barrier...
417: Process group successfully created for rank 417 . Now a global mpi barrier...
400: Process group successfully created for rank 400 . Now a global mpi barrier...
390: Process group successfully created for rank 390 . Now a global mpi barrier...
428: Process group successfully created for rank 428 . Now a global mpi barrier...
419: Process group successfully created for rank 419 . Now a global mpi barrier...
409: Process group successfully created for rank 409 . Now a global mpi barrier...
436: Process group successfully created for rank 436 . Now a global mpi barrier...
429: Process group successfully created for rank 429 . Now a global mpi barrier...
423: Process group successfully created for rank 423 . Now a global mpi barrier...
418: Process group successfully created for rank 418 . Now a global mpi barrier...
410: Process group successfully created for rank 410 . Now a global mpi barrier...
439: Process group successfully created for rank 439 . Now a global mpi barrier...
430: Process group successfully created for rank 430 . Now a global mpi barrier...
416: Process group successfully created for rank 416 . Now a global mpi barrier...
411: Process group successfully created for rank 411 . Now a global mpi barrier...
380: Process group successfully created for rank 380 . Now a global mpi barrier...
425: Process group successfully created for rank 425 . Now a global mpi barrier...
420: Process group successfully created for rank 420 . Now a global mpi barrier...
437: Process group successfully created for rank 437 . Now a global mpi barrier...
424: Process group successfully created for rank 424 . Now a global mpi barrier...
440: Process group successfully created for rank 440 . Now a global mpi barrier...
422: Process group successfully created for rank 422 . Now a global mpi barrier...
432: Process group successfully created for rank 432 . Now a global mpi barrier...
444: Process group successfully created for rank 444 . Now a global mpi barrier...
442: Process group successfully created for rank 442 . Now a global mpi barrier...
446: Process group successfully created for rank 446 . Now a global mpi barrier...
448: Process group successfully created for rank 448 . Now a global mpi barrier...
414: Process group successfully created for rank 414 . Now a global mpi barrier...
456: Process group successfully created for rank 456 . Now a global mpi barrier...
433: Process group successfully created for rank 433 . Now a global mpi barrier...
443: Process group successfully created for rank 443 . Now a global mpi barrier...
447: Process group successfully created for rank 447 . Now a global mpi barrier...
452: Process group successfully created for rank 452 . Now a global mpi barrier...
434: Process group successfully created for rank 434 . Now a global mpi barrier...
441: Process group successfully created for rank 441 . Now a global mpi barrier...
445: Process group successfully created for rank 445 . Now a global mpi barrier...
438: Process group successfully created for rank 438 . Now a global mpi barrier...
449: Process group successfully created for rank 449 . Now a global mpi barrier...
459: Process group successfully created for rank 459 . Now a global mpi barrier...
464: Process group successfully created for rank 464 . Now a global mpi barrier...
460: Process group successfully created for rank 460 . Now a global mpi barrier...
450: Process group successfully created for rank 450 . Now a global mpi barrier...
453: Process group successfully created for rank 453 . Now a global mpi barrier...
473: Process group successfully created for rank 473 . Now a global mpi barrier...
451: Process group successfully created for rank 451 . Now a global mpi barrier...
454: Process group successfully created for rank 454 . Now a global mpi barrier...
468: Process group successfully created for rank 468 . Now a global mpi barrier...
476: Process group successfully created for rank 476 . Now a global mpi barrier...
461: Process group successfully created for rank 461 . Now a global mpi barrier...
455: Process group successfully created for rank 455 . Now a global mpi barrier...
493: Process group successfully created for rank 493 . Now a global mpi barrier...
462: Process group successfully created for rank 462 . Now a global mpi barrier...
469: Process group successfully created for rank 469 . Now a global mpi barrier...
497: Process group successfully created for rank 497 . Now a global mpi barrier...
467: Process group successfully created for rank 467 . Now a global mpi barrier...
470: Process group successfully created for rank 470 . Now a global mpi barrier...
471: Process group successfully created for rank 471 . Now a global mpi barrier...
472: Process group successfully created for rank 472 . Now a global mpi barrier...
475: Process group successfully created for rank 475 . Now a global mpi barrier...
463: Process group successfully created for rank 463 . Now a global mpi barrier...
458: Process group successfully created for rank 458 . Now a global mpi barrier...
431: Process group successfully created for rank 431 . Now a global mpi barrier...
474: Process group successfully created for rank 474 . Now a global mpi barrier...
504: Process group successfully created for rank 504 . Now a global mpi barrier...
457: Process group successfully created for rank 457 . Now a global mpi barrier...
494: Process group successfully created for rank 494 . Now a global mpi barrier...
478: Process group successfully created for rank 478 . Now a global mpi barrier...
465: Process group successfully created for rank 465 . Now a global mpi barrier...
485: Process group successfully created for rank 485 . Now a global mpi barrier...
505: Process group successfully created for rank 505 . Now a global mpi barrier...
492: Process group successfully created for rank 492 . Now a global mpi barrier...
506: Process group successfully created for rank 506 . Now a global mpi barrier...
483: Process group successfully created for rank 483 . Now a global mpi barrier...
495: Process group successfully created for rank 495 . Now a global mpi barrier...
496: Process group successfully created for rank 496 . Now a global mpi barrier...
482: Process group successfully created for rank 482 . Now a global mpi barrier...
480: Process group successfully created for rank 480 . Now a global mpi barrier...
484: Process group successfully created for rank 484 . Now a global mpi barrier...
466: Process group successfully created for rank 466 . Now a global mpi barrier...
  1: Process group successfully created for rank 1 . Now a global mpi barrier...
  2: Process group successfully created for rank 2 . Now a global mpi barrier...
  3: Process group successfully created for rank 3 . Now a global mpi barrier...
267: Process group successfully created for rank 267 . Now a global mpi barrier...
227: Process group successfully created for rank 227 . Now a global mpi barrier...
292: Process group successfully created for rank 292 . Now a global mpi barrier...
268: Process group successfully created for rank 268 . Now a global mpi barrier...
290: Process group successfully created for rank 290 . Now a global mpi barrier...
490: Process group successfully created for rank 490 . Now a global mpi barrier...
229: Process group successfully created for rank 229 . Now a global mpi barrier...
481: Process group successfully created for rank 481 . Now a global mpi barrier...
479: Process group successfully created for rank 479 . Now a global mpi barrier...
503: Process group successfully created for rank 503 . Now a global mpi barrier...
  4: Process group successfully created for rank 4 . Now a global mpi barrier...
  6: Process group successfully created for rank 6 . Now a global mpi barrier...
  8: Process group successfully created for rank 8 . Now a global mpi barrier...
  5: Process group successfully created for rank 5 . Now a global mpi barrier...
278: Process group successfully created for rank 278 . Now a global mpi barrier...
352: Process group successfully created for rank 352 . Now a global mpi barrier...
205: Process group successfully created for rank 205 . Now a global mpi barrier...
315: Process group successfully created for rank 315 . Now a global mpi barrier...
279: Process group successfully created for rank 279 . Now a global mpi barrier...
328: Process group successfully created for rank 328 . Now a global mpi barrier...
477: Process group successfully created for rank 477 . Now a global mpi barrier...
318: Process group successfully created for rank 318 . Now a global mpi barrier...
181: Process group successfully created for rank 181 . Now a global mpi barrier...
427: Process group successfully created for rank 427 . Now a global mpi barrier...
  9: Process group successfully created for rank 9 . Now a global mpi barrier...
 15: Process group successfully created for rank 15 . Now a global mpi barrier...
 11: Process group successfully created for rank 11 . Now a global mpi barrier...
 18: Process group successfully created for rank 18 . Now a global mpi barrier...
 12: Process group successfully created for rank 12 . Now a global mpi barrier...
 10: Process group successfully created for rank 10 . Now a global mpi barrier...
 33: Process group successfully created for rank 33 . Now a global mpi barrier...
 25: Process group successfully created for rank 25 . Now a global mpi barrier...
 14: Process group successfully created for rank 14 . Now a global mpi barrier...
 28: Process group successfully created for rank 28 . Now a global mpi barrier...
 20: Process group successfully created for rank 20 . Now a global mpi barrier...
 26: Process group successfully created for rank 26 . Now a global mpi barrier...
 36: Process group successfully created for rank 36 . Now a global mpi barrier...
 21: Process group successfully created for rank 21 . Now a global mpi barrier...
 27: Process group successfully created for rank 27 . Now a global mpi barrier...
 22: Process group successfully created for rank 22 . Now a global mpi barrier...
 19: Process group successfully created for rank 19 . Now a global mpi barrier...
211: Process group successfully created for rank 211 . Now a global mpi barrier...
491: Process group successfully created for rank 491 . Now a global mpi barrier...
501: Process group successfully created for rank 501 . Now a global mpi barrier...
 24: Process group successfully created for rank 24 . Now a global mpi barrier...
 29: Process group successfully created for rank 29 . Now a global mpi barrier...
 23: Process group successfully created for rank 23 . Now a global mpi barrier...
 16: Process group successfully created for rank 16 . Now a global mpi barrier...
 37: Process group successfully created for rank 37 . Now a global mpi barrier...
240: Process group successfully created for rank 240 . Now a global mpi barrier...
274: Process group successfully created for rank 274 . Now a global mpi barrier...
262: Process group successfully created for rank 262 . Now a global mpi barrier...
 42: Process group successfully created for rank 42 . Now a global mpi barrier...
 34: Process group successfully created for rank 34 . Now a global mpi barrier...
 31: Process group successfully created for rank 31 . Now a global mpi barrier...
 32: Process group successfully created for rank 32 . Now a global mpi barrier...
 45: Process group successfully created for rank 45 . Now a global mpi barrier...
 49: Process group successfully created for rank 49 . Now a global mpi barrier...
 56: Process group successfully created for rank 56 . Now a global mpi barrier...
 47: Process group successfully created for rank 47 . Now a global mpi barrier...
 69: Process group successfully created for rank 69 . Now a global mpi barrier...
502: Process group successfully created for rank 502 . Now a global mpi barrier...
511: Process group successfully created for rank 511 . Now a global mpi barrier...
435: Process group successfully created for rank 435 . Now a global mpi barrier...
 30: Process group successfully created for rank 30 . Now a global mpi barrier...
 40: Process group successfully created for rank 40 . Now a global mpi barrier...
 44: Process group successfully created for rank 44 . Now a global mpi barrier...
 38: Process group successfully created for rank 38 . Now a global mpi barrier...
 52: Process group successfully created for rank 52 . Now a global mpi barrier...
 41: Process group successfully created for rank 41 . Now a global mpi barrier...
 35: Process group successfully created for rank 35 . Now a global mpi barrier...
 13: Process group successfully created for rank 13 . Now a global mpi barrier...
 48: Process group successfully created for rank 48 . Now a global mpi barrier...
 39: Process group successfully created for rank 39 . Now a global mpi barrier...
 59: Process group successfully created for rank 59 . Now a global mpi barrier...
 54: Process group successfully created for rank 54 . Now a global mpi barrier...
 46: Process group successfully created for rank 46 . Now a global mpi barrier...
 68: Process group successfully created for rank 68 . Now a global mpi barrier...
 50: Process group successfully created for rank 50 . Now a global mpi barrier...
 66: Process group successfully created for rank 66 . Now a global mpi barrier...
 58: Process group successfully created for rank 58 . Now a global mpi barrier...
 53: Process group successfully created for rank 53 . Now a global mpi barrier...
 71: Process group successfully created for rank 71 . Now a global mpi barrier...
 63: Process group successfully created for rank 63 . Now a global mpi barrier...
 73: Process group successfully created for rank 73 . Now a global mpi barrier...
 61: Process group successfully created for rank 61 . Now a global mpi barrier...
 70: Process group successfully created for rank 70 . Now a global mpi barrier...
 60: Process group successfully created for rank 60 . Now a global mpi barrier...
 62: Process group successfully created for rank 62 . Now a global mpi barrier...
 64: Process group successfully created for rank 64 . Now a global mpi barrier...
 72: Process group successfully created for rank 72 . Now a global mpi barrier...
 77: Process group successfully created for rank 77 . Now a global mpi barrier...
 67: Process group successfully created for rank 67 . Now a global mpi barrier...
 80: Process group successfully created for rank 80 . Now a global mpi barrier...
 74: Process group successfully created for rank 74 . Now a global mpi barrier...
 78: Process group successfully created for rank 78 . Now a global mpi barrier...
 65: Process group successfully created for rank 65 . Now a global mpi barrier...
 92: Process group successfully created for rank 92 . Now a global mpi barrier...
 75: Process group successfully created for rank 75 . Now a global mpi barrier...
 96: Process group successfully created for rank 96 . Now a global mpi barrier...
 79: Process group successfully created for rank 79 . Now a global mpi barrier...
101: Process group successfully created for rank 101 . Now a global mpi barrier...
 88: Process group successfully created for rank 88 . Now a global mpi barrier...
105: Process group successfully created for rank 105 . Now a global mpi barrier...
 81: Process group successfully created for rank 81 . Now a global mpi barrier...
 95: Process group successfully created for rank 95 . Now a global mpi barrier...
 98: Process group successfully created for rank 98 . Now a global mpi barrier...
 84: Process group successfully created for rank 84 . Now a global mpi barrier...
107: Process group successfully created for rank 107 . Now a global mpi barrier...
 82: Process group successfully created for rank 82 . Now a global mpi barrier...
 93: Process group successfully created for rank 93 . Now a global mpi barrier...
 85: Process group successfully created for rank 85 . Now a global mpi barrier...
 83: Process group successfully created for rank 83 . Now a global mpi barrier...
 94: Process group successfully created for rank 94 . Now a global mpi barrier...
 87: Process group successfully created for rank 87 . Now a global mpi barrier...
 86: Process group successfully created for rank 86 . Now a global mpi barrier...
 17: Process group successfully created for rank 17 . Now a global mpi barrier...
102: Process group successfully created for rank 102 . Now a global mpi barrier...
 43: Process group successfully created for rank 43 . Now a global mpi barrier...
 76: Process group successfully created for rank 76 . Now a global mpi barrier...
103: Process group successfully created for rank 103 . Now a global mpi barrier...
 89: Process group successfully created for rank 89 . Now a global mpi barrier...
104: Process group successfully created for rank 104 . Now a global mpi barrier...
114: Process group successfully created for rank 114 . Now a global mpi barrier...
108: Process group successfully created for rank 108 . Now a global mpi barrier...
122: Process group successfully created for rank 122 . Now a global mpi barrier...
100: Process group successfully created for rank 100 . Now a global mpi barrier...
 90: Process group successfully created for rank 90 . Now a global mpi barrier...
106: Process group successfully created for rank 106 . Now a global mpi barrier...
119: Process group successfully created for rank 119 . Now a global mpi barrier...
 97: Process group successfully created for rank 97 . Now a global mpi barrier...
113: Process group successfully created for rank 113 . Now a global mpi barrier...
110: Process group successfully created for rank 110 . Now a global mpi barrier...
116: Process group successfully created for rank 116 . Now a global mpi barrier...
115: Process group successfully created for rank 115 . Now a global mpi barrier...
109: Process group successfully created for rank 109 . Now a global mpi barrier...
118: Process group successfully created for rank 118 . Now a global mpi barrier...
111: Process group successfully created for rank 111 . Now a global mpi barrier...
500: Process group successfully created for rank 500 . Now a global mpi barrier...
112: Process group successfully created for rank 112 . Now a global mpi barrier...
120: Process group successfully created for rank 120 . Now a global mpi barrier...
117: Process group successfully created for rank 117 . Now a global mpi barrier...
124: Process group successfully created for rank 124 . Now a global mpi barrier...
 91: Process group successfully created for rank 91 . Now a global mpi barrier...
 55: Process group successfully created for rank 55 . Now a global mpi barrier...
140: Process group successfully created for rank 140 . Now a global mpi barrier...
123: Process group successfully created for rank 123 . Now a global mpi barrier...
133: Process group successfully created for rank 133 . Now a global mpi barrier...
125: Process group successfully created for rank 125 . Now a global mpi barrier...
128: Process group successfully created for rank 128 . Now a global mpi barrier...
143: Process group successfully created for rank 143 . Now a global mpi barrier...
144: Process group successfully created for rank 144 . Now a global mpi barrier...
121: Process group successfully created for rank 121 . Now a global mpi barrier...
134: Process group successfully created for rank 134 . Now a global mpi barrier...
127: Process group successfully created for rank 127 . Now a global mpi barrier...
150: Process group successfully created for rank 150 . Now a global mpi barrier...
136: Process group successfully created for rank 136 . Now a global mpi barrier...
130: Process group successfully created for rank 130 . Now a global mpi barrier...
152: Process group successfully created for rank 152 . Now a global mpi barrier...
151: Process group successfully created for rank 151 . Now a global mpi barrier...
137: Process group successfully created for rank 137 . Now a global mpi barrier...
131: Process group successfully created for rank 131 . Now a global mpi barrier...
139: Process group successfully created for rank 139 . Now a global mpi barrier...
129: Process group successfully created for rank 129 . Now a global mpi barrier...
487: Process group successfully created for rank 487 . Now a global mpi barrier...
142: Process group successfully created for rank 142 . Now a global mpi barrier...
135: Process group successfully created for rank 135 . Now a global mpi barrier...
148: Process group successfully created for rank 148 . Now a global mpi barrier...
138: Process group successfully created for rank 138 . Now a global mpi barrier...
141: Process group successfully created for rank 141 . Now a global mpi barrier...
156: Process group successfully created for rank 156 . Now a global mpi barrier...
132: Process group successfully created for rank 132 . Now a global mpi barrier...
160: Process group successfully created for rank 160 . Now a global mpi barrier...
126: Process group successfully created for rank 126 . Now a global mpi barrier...
169: Process group successfully created for rank 169 . Now a global mpi barrier...
153: Process group successfully created for rank 153 . Now a global mpi barrier...
145: Process group successfully created for rank 145 . Now a global mpi barrier...
159: Process group successfully created for rank 159 . Now a global mpi barrier...
149: Process group successfully created for rank 149 . Now a global mpi barrier...
164: Process group successfully created for rank 164 . Now a global mpi barrier...
154: Process group successfully created for rank 154 . Now a global mpi barrier...
147: Process group successfully created for rank 147 . Now a global mpi barrier...
172: Process group successfully created for rank 172 . Now a global mpi barrier...
163: Process group successfully created for rank 163 . Now a global mpi barrier...
166: Process group successfully created for rank 166 . Now a global mpi barrier...
155: Process group successfully created for rank 155 . Now a global mpi barrier...
146: Process group successfully created for rank 146 . Now a global mpi barrier...
174: Process group successfully created for rank 174 . Now a global mpi barrier...
489: Process group successfully created for rank 489 . Now a global mpi barrier...
161: Process group successfully created for rank 161 . Now a global mpi barrier...
165: Process group successfully created for rank 165 . Now a global mpi barrier...
168: Process group successfully created for rank 168 . Now a global mpi barrier...
173: Process group successfully created for rank 173 . Now a global mpi barrier...
178: Process group successfully created for rank 178 . Now a global mpi barrier...
167: Process group successfully created for rank 167 . Now a global mpi barrier...
171: Process group successfully created for rank 171 . Now a global mpi barrier...
175: Process group successfully created for rank 175 . Now a global mpi barrier...
179: Process group successfully created for rank 179 . Now a global mpi barrier...
180: Process group successfully created for rank 180 . Now a global mpi barrier...
176: Process group successfully created for rank 176 . Now a global mpi barrier...
405: Process group successfully created for rank 405 . Now a global mpi barrier...
284: ... barrier passed on rank  284 .
156: ... barrier passed on rank  156 .
 36: ... barrier passed on rank  36 .
 28: ... barrier passed on rank  28 .
412: ... barrier passed on rank  412 .
420: ... barrier passed on rank  420 .
292: ... barrier passed on rank  292 .
260: ... barrier passed on rank  260 .
132: ... barrier passed on rank  132 .
  4: ... barrier passed on rank  4 .
164: ... barrier passed on rank  164 .
388: ... barrier passed on rank  388 .
316: ... barrier passed on rank  316 .
280: ... barrier passed on rank  280 .
376: ... barrier passed on rank  376 .
312: ... barrier passed on rank  312 .
440: ... barrier passed on rank  440 .
248: ... barrier passed on rank  248 .
 24: ... barrier passed on rank  24 .
120: ... barrier passed on rank  120 .
444: ... barrier passed on rank  444 .
 60: ... barrier passed on rank  60 .
184: ... barrier passed on rank  184 .
 56: ... barrier passed on rank  56 .
152: ... barrier passed on rank  152 .
188: ... barrier passed on rank  188 .
504: ... barrier passed on rank  504 .
428: ... barrier passed on rank  428 .
294: ... barrier passed on rank  294 .
268: ... barrier passed on rank  268 .
108: ... barrier passed on rank  108 .
408: ... barrier passed on rank  408 .
300: ... barrier passed on rank  300 .
252: ... barrier passed on rank  252 .
 44: ... barrier passed on rank  44 .
236: ... barrier passed on rank  236 .
140: ... barrier passed on rank  140 .
 12: ... barrier passed on rank  12 .
 38: ... barrier passed on rank  38 .
364: ... barrier passed on rank  364 .
172: ... barrier passed on rank  172 .
124: ... barrier passed on rank  124 .
508: ... barrier passed on rank  508 .
380: ... barrier passed on rank  380 .
166: ... barrier passed on rank  166 .
422: ... barrier passed on rank  422 .
492: ... barrier passed on rank  492 .
396: ... barrier passed on rank  396 .
 54: ... barrier passed on rank  54 .
232: ... barrier passed on rank  232 .
283: ... barrier passed on rank  283 .
 40: ... barrier passed on rank  40 .
379: ... barrier passed on rank  379 .
411: ... barrier passed on rank  411 .
315: ... barrier passed on rank  315 .
360: ... barrier passed on rank  360 .
290: ... barrier passed on rank  290 .
264: ... barrier passed on rank  264 .
278: ... barrier passed on rank  278 .
226: ... barrier passed on rank  226 .
443: ... barrier passed on rank  443 .
262: ... barrier passed on rank  262 .
 34: ... barrier passed on rank  34 .
406: ... barrier passed on rank  406 .
296: ... barrier passed on rank  296 .
251: ... barrier passed on rank  251 .
 27: ... barrier passed on rank  27 .
230: ... barrier passed on rank  230 .
123: ... barrier passed on rank  123 .
134: ... barrier passed on rank  134 .
438: ... barrier passed on rank  438 .
  6: ... barrier passed on rank  6 .
354: ... barrier passed on rank  354 .
162: ... barrier passed on rank  162 .
102: ... barrier passed on rank  102 .
246: ... barrier passed on rank  246 .
150: ... barrier passed on rank  150 .
136: ... barrier passed on rank  136 .
424: ... barrier passed on rank  424 .
187: ... barrier passed on rank  187 .
 22: ... barrier passed on rank  22 .
104: ... barrier passed on rank  104 .
358: ... barrier passed on rank  358 .
118: ... barrier passed on rank  118 .
168: ... barrier passed on rank  168 .
 98: ... barrier passed on rank  98 .
374: ... barrier passed on rank  374 .
 59: ... barrier passed on rank  59 .
502: ... barrier passed on rank  502 .
155: ... barrier passed on rank  155 .
  8: ... barrier passed on rank  8 .
390: ... barrier passed on rank  390 .
507: ... barrier passed on rank  507 .
392: ... barrier passed on rank  392 .
482: ... barrier passed on rank  482 .
488: ... barrier passed on rank  488 .
486: ... barrier passed on rank  486 .
  2: ... barrier passed on rank  2 .
 52: ... barrier passed on rank  52 .
 18: ... barrier passed on rank  18 .
270: ... barrier passed on rank  270 .
114: ... barrier passed on rank  114 .
235: ... barrier passed on rank  235 .
220: ... barrier passed on rank  220 .
282: ... barrier passed on rank  282 .
306: ... barrier passed on rank  306 .
258: ... barrier passed on rank  258 .
 43: ... barrier passed on rank  43 .
474: ... barrier passed on rank  474 .
378: ... barrier passed on rank  378 .
218: ... barrier passed on rank  218 .
110: ... barrier passed on rank  110 .
434: ... barrier passed on rank  434 .
204: ... barrier passed on rank  204 .
410: ... barrier passed on rank  410 .
314: ... barrier passed on rank  314 .
363: ... barrier passed on rank  363 .
291: ... barrier passed on rank  291 .
242: ... barrier passed on rank  242 .
267: ... barrier passed on rank  267 .
386: ... barrier passed on rank  386 .
302: ... barrier passed on rank  302 .
276: ... barrier passed on rank  276 .
254: ... barrier passed on rank  254 .
348: ... barrier passed on rank  348 .
227: ... barrier passed on rank  227 .
 46: ... barrier passed on rank  46 .
442: ... barrier passed on rank  442 .
 68: ... barrier passed on rank  68 .
 35: ... barrier passed on rank  35 .
404: ... barrier passed on rank  404 .
299: ... barrier passed on rank  299 .
370: ... barrier passed on rank  370 .
285: ... barrier passed on rank  285 .
238: ... barrier passed on rank  238 .
142: ... barrier passed on rank  142 .
250: ... barrier passed on rank  250 .
146: ... barrier passed on rank  146 .
324: ... barrier passed on rank  324 .
 26: ... barrier passed on rank  26 .
158: ... barrier passed on rank  158 .
228: ... barrier passed on rank  228 .
122: ... barrier passed on rank  122 .
 14: ... barrier passed on rank  14 .
 50: ... barrier passed on rank  50 .
182: ... barrier passed on rank  182 .
436: ... barrier passed on rank  436 .
366: ... barrier passed on rank  366 .
174: ... barrier passed on rank  174 .
 76: ... barrier passed on rank  76 .
355: ... barrier passed on rank  355 .
163: ... barrier passed on rank  163 .
100: ... barrier passed on rank  100 .
 29: ... barrier passed on rank  29 .
126: ... barrier passed on rank  126 .
 90: ... barrier passed on rank  90 .
460: ... barrier passed on rank  460 .
244: ... barrier passed on rank  244 .
148: ... barrier passed on rank  148 .
139: ... barrier passed on rank  139 .
196: ... barrier passed on rank  196 .
510: ... barrier passed on rank  510 .
427: ... barrier passed on rank  427 .
402: ... barrier passed on rank  402 .
186: ... barrier passed on rank  186 .
274: ... barrier passed on rank  274 .
346: ... barrier passed on rank  346 .
178: ... barrier passed on rank  178 .
 20: ... barrier passed on rank  20 .
381: ... barrier passed on rank  381 .
107: ... barrier passed on rank  107 .
310: ... barrier passed on rank  310 .
356: ... barrier passed on rank  356 .
332: ... barrier passed on rank  332 .
130: ... barrier passed on rank  130 .
116: ... barrier passed on rank  116 .
452: ... barrier passed on rank  452 .
 92: ... barrier passed on rank  92 .
171: ... barrier passed on rank  171 .
 99: ... barrier passed on rank  99 .
372: ... barrier passed on rank  372 .
 58: ... barrier passed on rank  58 .
500: ... barrier passed on rank  500 .
154: ... barrier passed on rank  154 .
 11: ... barrier passed on rank  11 .
414: ... barrier passed on rank  414 .
506: ... barrier passed on rank  506 .
395: ... barrier passed on rank  395 .
430: ... barrier passed on rank  430 .
483: ... barrier passed on rank  483 .
491: ... barrier passed on rank  491 .
494: ... barrier passed on rank  494 .
418: ... barrier passed on rank  418 .
476: ... barrier passed on rank  476 .
498: ... barrier passed on rank  498 .
398: ... barrier passed on rank  398 .
484: ... barrier passed on rank  484 .
  3: ... barrier passed on rank  3 .
 53: ... barrier passed on rank  53 .
210: ... barrier passed on rank  210 .
 19: ... barrier passed on rank  19 .
317: ... barrier passed on rank  317 .
293: ... barrier passed on rank  293 .
269: ... barrier passed on rank  269 .
115: ... barrier passed on rank  115 .
234: ... barrier passed on rank  234 .
222: ... barrier passed on rank  222 .
281: ... barrier passed on rank  281 .
307: ... barrier passed on rank  307 .
259: ... barrier passed on rank  259 .
 42: ... barrier passed on rank  42 .
472: ... barrier passed on rank  472 .
377: ... barrier passed on rank  377 .
216: ... barrier passed on rank  216 .
109: ... barrier passed on rank  109 .
435: ... barrier passed on rank  435 .
206: ... barrier passed on rank  206 .
409: ... barrier passed on rank  409 .
313: ... barrier passed on rank  313 .
362: ... barrier passed on rank  362 .
288: ... barrier passed on rank  288 .
243: ... barrier passed on rank  243 .
266: ... barrier passed on rank  266 .
387: ... barrier passed on rank  387 .
277: ... barrier passed on rank  277 .
253: ... barrier passed on rank  253 .
350: ... barrier passed on rank  350 .
224: ... barrier passed on rank  224 .
 45: ... barrier passed on rank  45 .
441: ... barrier passed on rank  441 .
 70: ... barrier passed on rank  70 .
322: ... barrier passed on rank  322 .
261: ... barrier passed on rank  261 .
 32: ... barrier passed on rank  32 .
405: ... barrier passed on rank  405 .
298: ... barrier passed on rank  298 .
371: ... barrier passed on rank  371 .
286: ... barrier passed on rank  286 .
237: ... barrier passed on rank  237 .
141: ... barrier passed on rank  141 .
214: ... barrier passed on rank  214 .
249: ... barrier passed on rank  249 .
147: ... barrier passed on rank  147 .
326: ... barrier passed on rank  326 .
 25: ... barrier passed on rank  25 .
157: ... barrier passed on rank  157 .
231: ... barrier passed on rank  231 .
121: ... barrier passed on rank  121 .
133: ... barrier passed on rank  133 .
 13: ... barrier passed on rank  13 .
 51: ... barrier passed on rank  51 .
 39: ... barrier passed on rank  39 .
445: ... barrier passed on rank  445 .
338: ... barrier passed on rank  338 .
194: ... barrier passed on rank  194 .
 61: ... barrier passed on rank  61 .
180: ... barrier passed on rank  180 .
437: ... barrier passed on rank  437 .
  5: ... barrier passed on rank  5 .
365: ... barrier passed on rank  365 .
173: ... barrier passed on rank  173 .
 78: ... barrier passed on rank  78 .
342: ... barrier passed on rank  342 .
328: ... barrier passed on rank  328 .
352: ... barrier passed on rank  352 .
 66: ... barrier passed on rank  66 .
160: ... barrier passed on rank  160 .
101: ... barrier passed on rank  101 .
 30: ... barrier passed on rank  30 .
125: ... barrier passed on rank  125 .
 88: ... barrier passed on rank  88 .
462: ... barrier passed on rank  462 .
245: ... barrier passed on rank  245 .
149: ... barrier passed on rank  149 .
138: ... barrier passed on rank  138 .
198: ... barrier passed on rank  198 .
509: ... barrier passed on rank  509 .
426: ... barrier passed on rank  426 .
403: ... barrier passed on rank  403 .
185: ... barrier passed on rank  185 .
450: ... barrier passed on rank  450 .
275: ... barrier passed on rank  275 .
344: ... barrier passed on rank  344 .
179: ... barrier passed on rank  179 .
 21: ... barrier passed on rank  21 .
382: ... barrier passed on rank  382 .
106: ... barrier passed on rank  106 .
308: ... barrier passed on rank  308 .
357: ... barrier passed on rank  357 .
334: ... barrier passed on rank  334 .
 82: ... barrier passed on rank  82 .
131: ... barrier passed on rank  131 .
165: ... barrier passed on rank  165 .
454: ... barrier passed on rank  454 .
 94: ... barrier passed on rank  94 .
 72: ... barrier passed on rank  72 .
170: ... barrier passed on rank  170 .
 96: ... barrier passed on rank  96 .
373: ... barrier passed on rank  373 .
 86: ... barrier passed on rank  86 .
200: ... barrier passed on rank  200 .
 57: ... barrier passed on rank  57 .
501: ... barrier passed on rank  501 .
153: ... barrier passed on rank  153 .
189: ... barrier passed on rank  189 .
 10: ... barrier passed on rank  10 .
413: ... barrier passed on rank  413 .
389: ... barrier passed on rank  389 .
505: ... barrier passed on rank  505 .
470: ... barrier passed on rank  470 .
456: ... barrier passed on rank  456 .
394: ... barrier passed on rank  394 .
429: ... barrier passed on rank  429 .
421: ... barrier passed on rank  421 .
480: ... barrier passed on rank  480 .
490: ... barrier passed on rank  490 .
493: ... barrier passed on rank  493 .
419: ... barrier passed on rank  419 .
478: ... barrier passed on rank  478 .
499: ... barrier passed on rank  499 .
397: ... barrier passed on rank  397 .
466: ... barrier passed on rank  466 .
487: ... barrier passed on rank  487 .
  0: ... barrier passed on rank  0 .
 55: ... barrier passed on rank  55 .
211: ... barrier passed on rank  211 .
 16: ... barrier passed on rank  16 .
318: ... barrier passed on rank  318 .
295: ... barrier passed on rank  295 .
271: ... barrier passed on rank  271 .
112: ... barrier passed on rank  112 .
233: ... barrier passed on rank  233 .
221: ... barrier passed on rank  221 .
304: ... barrier passed on rank  304 .
256: ... barrier passed on rank  256 .
 41: ... barrier passed on rank  41 .
475: ... barrier passed on rank  475 .
219: ... barrier passed on rank  219 .
111: ... barrier passed on rank  111 .
432: ... barrier passed on rank  432 .
205: ... barrier passed on rank  205 .
361: ... barrier passed on rank  361 .
289: ... barrier passed on rank  289 .
240: ... barrier passed on rank  240 .
265: ... barrier passed on rank  265 .
384: ... barrier passed on rank  384 .
301: ... barrier passed on rank  301 .
279: ... barrier passed on rank  279 .
255: ... barrier passed on rank  255 .
349: ... barrier passed on rank  349 .
225: ... barrier passed on rank  225 .
 47: ... barrier passed on rank  47 .
 69: ... barrier passed on rank  69 .
323: ... barrier passed on rank  323 .
263: ... barrier passed on rank  263 .
 33: ... barrier passed on rank  33 .
407: ... barrier passed on rank  407 .
297: ... barrier passed on rank  297 .
368: ... barrier passed on rank  368 .
287: ... barrier passed on rank  287 .
239: ... barrier passed on rank  239 .
143: ... barrier passed on rank  143 .
212: ... barrier passed on rank  212 .
144: ... barrier passed on rank  144 .
325: ... barrier passed on rank  325 .
159: ... barrier passed on rank  159 .
229: ... barrier passed on rank  229 .
135: ... barrier passed on rank  135 .
 15: ... barrier passed on rank  15 .
 48: ... barrier passed on rank  48 .
 37: ... barrier passed on rank  37 .
446: ... barrier passed on rank  446 .
339: ... barrier passed on rank  339 .
195: ... barrier passed on rank  195 .
 62: ... barrier passed on rank  62 .
181: ... barrier passed on rank  181 .
439: ... barrier passed on rank  439 .
  7: ... barrier passed on rank  7 .
367: ... barrier passed on rank  367 .
175: ... barrier passed on rank  175 .
 77: ... barrier passed on rank  77 .
340: ... barrier passed on rank  340 .
331: ... barrier passed on rank  331 .
353: ... barrier passed on rank  353 .
 67: ... barrier passed on rank  67 .
161: ... barrier passed on rank  161 .
103: ... barrier passed on rank  103 .
 31: ... barrier passed on rank  31 .
127: ... barrier passed on rank  127 .
 91: ... barrier passed on rank  91 .
461: ... barrier passed on rank  461 .
247: ... barrier passed on rank  247 .
151: ... barrier passed on rank  151 .
137: ... barrier passed on rank  137 .
197: ... barrier passed on rank  197 .
511: ... barrier passed on rank  511 .
425: ... barrier passed on rank  425 .
400: ... barrier passed on rank  400 .
451: ... barrier passed on rank  451 .
272: ... barrier passed on rank  272 .
347: ... barrier passed on rank  347 .
176: ... barrier passed on rank  176 .
 23: ... barrier passed on rank  23 .
383: ... barrier passed on rank  383 .
105: ... barrier passed on rank  105 .
309: ... barrier passed on rank  309 .
359: ... barrier passed on rank  359 .
333: ... barrier passed on rank  333 .
 83: ... barrier passed on rank  83 .
128: ... barrier passed on rank  128 .
167: ... barrier passed on rank  167 .
117: ... barrier passed on rank  117 .
453: ... barrier passed on rank  453 .
 93: ... barrier passed on rank  93 .
 75: ... barrier passed on rank  75 .
169: ... barrier passed on rank  169 .
 97: ... barrier passed on rank  97 .
375: ... barrier passed on rank  375 .
 84: ... barrier passed on rank  84 .
203: ... barrier passed on rank  203 .
503: ... barrier passed on rank  503 .
190: ... barrier passed on rank  190 .
  9: ... barrier passed on rank  9 .
415: ... barrier passed on rank  415 .
391: ... barrier passed on rank  391 .
468: ... barrier passed on rank  468 .
459: ... barrier passed on rank  459 .
393: ... barrier passed on rank  393 .
431: ... barrier passed on rank  431 .
423: ... barrier passed on rank  423 .
481: ... barrier passed on rank  481 .
489: ... barrier passed on rank  489 .
495: ... barrier passed on rank  495 .
416: ... barrier passed on rank  416 .
477: ... barrier passed on rank  477 .
496: ... barrier passed on rank  496 .
399: ... barrier passed on rank  399 .
467: ... barrier passed on rank  467 .
485: ... barrier passed on rank  485 .
  1: ... barrier passed on rank  1 .
208: ... barrier passed on rank  208 .
 17: ... barrier passed on rank  17 .
319: ... barrier passed on rank  319 .
113: ... barrier passed on rank  113 .
223: ... barrier passed on rank  223 .
305: ... barrier passed on rank  305 .
257: ... barrier passed on rank  257 .
473: ... barrier passed on rank  473 .
217: ... barrier passed on rank  217 .
433: ... barrier passed on rank  433 .
207: ... barrier passed on rank  207 .
241: ... barrier passed on rank  241 .
385: ... barrier passed on rank  385 .
303: ... barrier passed on rank  303 .
351: ... barrier passed on rank  351 .
 71: ... barrier passed on rank  71 .
320: ... barrier passed on rank  320 .
369: ... barrier passed on rank  369 .
215: ... barrier passed on rank  215 .
145: ... barrier passed on rank  145 .
327: ... barrier passed on rank  327 .
 49: ... barrier passed on rank  49 .
447: ... barrier passed on rank  447 .
336: ... barrier passed on rank  336 .
192: ... barrier passed on rank  192 .
 63: ... barrier passed on rank  63 .
183: ... barrier passed on rank  183 .
 79: ... barrier passed on rank  79 .
343: ... barrier passed on rank  343 .
330: ... barrier passed on rank  330 .
 64: ... barrier passed on rank  64 .
 89: ... barrier passed on rank  89 .
463: ... barrier passed on rank  463 .
199: ... barrier passed on rank  199 .
401: ... barrier passed on rank  401 .
448: ... barrier passed on rank  448 .
273: ... barrier passed on rank  273 .
345: ... barrier passed on rank  345 .
177: ... barrier passed on rank  177 .
311: ... barrier passed on rank  311 .
335: ... barrier passed on rank  335 .
 80: ... barrier passed on rank  80 .
129: ... barrier passed on rank  129 .
119: ... barrier passed on rank  119 .
455: ... barrier passed on rank  455 .
 95: ... barrier passed on rank  95 .
 74: ... barrier passed on rank  74 .
 87: ... barrier passed on rank  87 .
202: ... barrier passed on rank  202 .
191: ... barrier passed on rank  191 .
471: ... barrier passed on rank  471 .
458: ... barrier passed on rank  458 .
417: ... barrier passed on rank  417 .
479: ... barrier passed on rank  479 .
497: ... barrier passed on rank  497 .
464: ... barrier passed on rank  464 .
209: ... barrier passed on rank  209 .
321: ... barrier passed on rank  321 .
213: ... barrier passed on rank  213 .
337: ... barrier passed on rank  337 .
193: ... barrier passed on rank  193 .
341: ... barrier passed on rank  341 .
329: ... barrier passed on rank  329 .
 65: ... barrier passed on rank  65 .
449: ... barrier passed on rank  449 .
 81: ... barrier passed on rank  81 .
 73: ... barrier passed on rank  73 .
 85: ... barrier passed on rank  85 .
201: ... barrier passed on rank  201 .
469: ... barrier passed on rank  469 .
457: ... barrier passed on rank  457 .
465: ... barrier passed on rank  465 .
  0: hkn0403:1808436:1808436 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  0: hkn0403:1808436:1808436 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  0: hkn0403:1808436:1808436 [0] NCCL INFO P2P plugin IBext
  0: hkn0403:1808436:1808436 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  0: hkn0403:1808436:1808436 [0] NCCL INFO Using network IBext
  0: NCCL version 2.11.4+cuda11.4
152: hkn0515:2921174:2921174 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
  3: hkn0403:1808445:1808445 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  1: hkn0403:1808437:1808437 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  2: hkn0403:1808457:1808457 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
153: hkn0515:2921190:2921190 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
154: hkn0515:2921182:2921182 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
152: hkn0515:2921174:2921174 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
152: hkn0515:2921174:2921174 [0] NCCL INFO P2P plugin IBext
155: hkn0515:2921202:2921202 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
  3: hkn0403:1808445:1808445 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  3: hkn0403:1808445:1808445 [3] NCCL INFO P2P plugin IBext
  1: hkn0403:1808437:1808437 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  1: hkn0403:1808437:1808437 [1] NCCL INFO P2P plugin IBext
  2: hkn0403:1808457:1808457 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  2: hkn0403:1808457:1808457 [2] NCCL INFO P2P plugin IBext
153: hkn0515:2921190:2921190 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
153: hkn0515:2921190:2921190 [1] NCCL INFO P2P plugin IBext
145: hkn0513:3037331:3037331 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
154: hkn0515:2921182:2921182 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
154: hkn0515:2921182:2921182 [2] NCCL INFO P2P plugin IBext
  1: hkn0403:1808437:1808437 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  3: hkn0403:1808445:1808445 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  1: hkn0403:1808437:1808437 [1] NCCL INFO Using network IBext
  3: hkn0403:1808445:1808445 [3] NCCL INFO Using network IBext
  2: hkn0403:1808457:1808457 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  2: hkn0403:1808457:1808457 [2] NCCL INFO Using network IBext
155: hkn0515:2921202:2921202 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
155: hkn0515:2921202:2921202 [3] NCCL INFO P2P plugin IBext
153: hkn0515:2921190:2921190 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
154: hkn0515:2921182:2921182 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
153: hkn0515:2921190:2921190 [1] NCCL INFO Using network IBext
154: hkn0515:2921182:2921182 [2] NCCL INFO Using network IBext
145: hkn0513:3037331:3037331 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
145: hkn0513:3037331:3037331 [1] NCCL INFO P2P plugin IBext
155: hkn0515:2921202:2921202 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
155: hkn0515:2921202:2921202 [3] NCCL INFO Using network IBext
152: hkn0515:2921174:2921174 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
152: hkn0515:2921174:2921174 [0] NCCL INFO Using network IBext
435: hkn0730:1426037:1426037 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
434: hkn0730:1426053:1426053 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
435: hkn0730:1426037:1426037 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
435: hkn0730:1426037:1426037 [3] NCCL INFO P2P plugin IBext
434: hkn0730:1426053:1426053 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
434: hkn0730:1426053:1426053 [2] NCCL INFO P2P plugin IBext
432: hkn0730:1426065:1426065 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
113: hkn0505:2328151:2328151 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
112: hkn0505:2328135:2328135 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
115: hkn0505:2328163:2328163 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
433: hkn0730:1426045:1426045 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
114: hkn0505:2328143:2328143 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
145: hkn0513:3037331:3037331 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
145: hkn0513:3037331:3037331 [1] NCCL INFO Using network IBext
429: hkn0728:1348481:1348481 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
434: hkn0730:1426053:1426053 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
434: hkn0730:1426053:1426053 [2] NCCL INFO Using network IBext
432: hkn0730:1426065:1426065 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
432: hkn0730:1426065:1426065 [0] NCCL INFO P2P plugin IBext
428: hkn0728:1348473:1348473 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
113: hkn0505:2328151:2328151 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
113: hkn0505:2328151:2328151 [1] NCCL INFO P2P plugin IBext
430: hkn0728:1348501:1348501 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
112: hkn0505:2328135:2328135 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
112: hkn0505:2328135:2328135 [0] NCCL INFO P2P plugin IBext
115: hkn0505:2328163:2328163 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
115: hkn0505:2328163:2328163 [3] NCCL INFO P2P plugin IBext
433: hkn0730:1426045:1426045 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
433: hkn0730:1426045:1426045 [1] NCCL INFO P2P plugin IBext
114: hkn0505:2328143:2328143 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
114: hkn0505:2328143:2328143 [2] NCCL INFO P2P plugin IBext
100: hkn0502:253422:253422 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
431: hkn0728:1348489:1348489 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
147: hkn0513:3037315:3037315 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
144: hkn0513:3037343:3037343 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
429: hkn0728:1348481:1348481 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
429: hkn0728:1348481:1348481 [1] NCCL INFO P2P plugin IBext
435: hkn0730:1426037:1426037 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
435: hkn0730:1426037:1426037 [3] NCCL INFO Using network IBext
432: hkn0730:1426065:1426065 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
432: hkn0730:1426065:1426065 [0] NCCL INFO Using network IBext
433: hkn0730:1426045:1426045 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
433: hkn0730:1426045:1426045 [1] NCCL INFO Using network IBext
103: hkn0502:253410:253410 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
428: hkn0728:1348473:1348473 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
428: hkn0728:1348473:1348473 [0] NCCL INFO P2P plugin IBext
430: hkn0728:1348501:1348501 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
430: hkn0728:1348501:1348501 [2] NCCL INFO P2P plugin IBext
102: hkn0502:253394:253394 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
101: hkn0502:253402:253402 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
114: hkn0505:2328143:2328143 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
114: hkn0505:2328143:2328143 [2] NCCL INFO Using network IBext
115: hkn0505:2328163:2328163 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
115: hkn0505:2328163:2328163 [3] NCCL INFO Using network IBext
100: hkn0502:253422:253422 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
100: hkn0502:253422:253422 [0] NCCL INFO P2P plugin IBext
431: hkn0728:1348489:1348489 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
431: hkn0728:1348489:1348489 [3] NCCL INFO P2P plugin IBext
147: hkn0513:3037315:3037315 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
147: hkn0513:3037315:3037315 [3] NCCL INFO P2P plugin IBext
144: hkn0513:3037343:3037343 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
144: hkn0513:3037343:3037343 [0] NCCL INFO P2P plugin IBext
184: hkn0527:1373322:1373322 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
430: hkn0728:1348501:1348501 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
103: hkn0502:253410:253410 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
103: hkn0502:253410:253410 [3] NCCL INFO P2P plugin IBext
428: hkn0728:1348473:1348473 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
430: hkn0728:1348501:1348501 [2] NCCL INFO Using network IBext
428: hkn0728:1348473:1348473 [0] NCCL INFO Using network IBext
113: hkn0505:2328151:2328151 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
113: hkn0505:2328151:2328151 [1] NCCL INFO Using network IBext
112: hkn0505:2328135:2328135 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
112: hkn0505:2328135:2328135 [0] NCCL INFO Using network IBext
431: hkn0728:1348489:1348489 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
431: hkn0728:1348489:1348489 [3] NCCL INFO Using network IBext
185: hkn0527:1373310:1373310 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
102: hkn0502:253394:253394 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
102: hkn0502:253394:253394 [2] NCCL INFO P2P plugin IBext
101: hkn0502:253402:253402 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
101: hkn0502:253402:253402 [1] NCCL INFO P2P plugin IBext
147: hkn0513:3037315:3037315 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
147: hkn0513:3037315:3037315 [3] NCCL INFO Using network IBext
144: hkn0513:3037343:3037343 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
144: hkn0513:3037343:3037343 [0] NCCL INFO Using network IBext
429: hkn0728:1348481:1348481 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
429: hkn0728:1348481:1348481 [1] NCCL INFO Using network IBext
187: hkn0527:1373302:1373302 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
184: hkn0527:1373322:1373322 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
184: hkn0527:1373322:1373322 [0] NCCL INFO P2P plugin IBext
101: hkn0502:253402:253402 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
102: hkn0502:253394:253394 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
101: hkn0502:253402:253402 [1] NCCL INFO Using network IBext
102: hkn0502:253394:253394 [2] NCCL INFO Using network IBext
103: hkn0502:253410:253410 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
103: hkn0502:253410:253410 [3] NCCL INFO Using network IBext
350: hkn0706:776596:776596 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
185: hkn0527:1373310:1373310 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
185: hkn0527:1373310:1373310 [1] NCCL INFO P2P plugin IBext
214: hkn0535:2423350:2423350 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
186: hkn0527:1373294:1373294 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
212: hkn0535:2423336:2423336 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
100: hkn0502:253422:253422 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
100: hkn0502:253422:253422 [0] NCCL INFO Using network IBext
213: hkn0535:2423328:2423328 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
187: hkn0527:1373302:1373302 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
187: hkn0527:1373302:1373302 [3] NCCL INFO P2P plugin IBext
350: hkn0706:776596:776596 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
350: hkn0706:776596:776596 [2] NCCL INFO P2P plugin IBext
355: hkn0707:4044292:4044292 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
263: hkn0613:927090:927090 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
185: hkn0527:1373310:1373310 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
185: hkn0527:1373310:1373310 [1] NCCL INFO Using network IBext
214: hkn0535:2423350:2423350 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
214: hkn0535:2423350:2423350 [2] NCCL INFO P2P plugin IBext
186: hkn0527:1373294:1373294 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
186: hkn0527:1373294:1373294 [2] NCCL INFO P2P plugin IBext
261: hkn0613:927098:927098 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
212: hkn0535:2423336:2423336 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
212: hkn0535:2423336:2423336 [0] NCCL INFO P2P plugin IBext
260: hkn0613:927106:927106 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
187: hkn0527:1373302:1373302 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
187: hkn0527:1373302:1373302 [3] NCCL INFO Using network IBext
213: hkn0535:2423328:2423328 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
213: hkn0535:2423328:2423328 [1] NCCL INFO P2P plugin IBext
262: hkn0613:927118:927118 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
348: hkn0706:776612:776612 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
352: hkn0707:4044320:4044320 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
 66: hkn0421:2208703:2208703 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
354: hkn0707:4044308:4044308 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
353: hkn0707:4044300:4044300 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
186: hkn0527:1373294:1373294 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
186: hkn0527:1373294:1373294 [2] NCCL INFO Using network IBext
184: hkn0527:1373322:1373322 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
184: hkn0527:1373322:1373322 [0] NCCL INFO Using network IBext
355: hkn0707:4044292:4044292 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
355: hkn0707:4044292:4044292 [3] NCCL INFO P2P plugin IBext
263: hkn0613:927090:927090 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
263: hkn0613:927090:927090 [3] NCCL INFO P2P plugin IBext
162: hkn0520:2737243:2737243 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
351: hkn0706:776604:776604 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
261: hkn0613:927098:927098 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
261: hkn0613:927098:927098 [1] NCCL INFO P2P plugin IBext
  7: hkn0404:1363854:1363854 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
213: hkn0535:2423328:2423328 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
213: hkn0535:2423328:2423328 [1] NCCL INFO Using network IBext
  5: hkn0404:1363874:1363874 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
260: hkn0613:927106:927106 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
260: hkn0613:927106:927106 [0] NCCL INFO P2P plugin IBext
 65: hkn0421:2208731:2208731 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
262: hkn0613:927118:927118 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
262: hkn0613:927118:927118 [2] NCCL INFO P2P plugin IBext
163: hkn0520:2737223:2737223 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
 67: hkn0421:2208711:2208711 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
 51: hkn0417:2292063:2292063 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
  4: hkn0404:1363862:1363862 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
 27: hkn0410:1184055:1184055 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
348: hkn0706:776612:776612 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
348: hkn0706:776612:776612 [0] NCCL INFO P2P plugin IBext
 64: hkn0421:2208719:2208719 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
  6: hkn0404:1363846:1363846 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
 48: hkn0417:2292075:2292075 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
 66: hkn0421:2208703:2208703 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 66: hkn0421:2208703:2208703 [2] NCCL INFO P2P plugin IBext
 49: hkn0417:2292047:2292047 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
 50: hkn0417:2292055:2292055 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
444: hkn0733:1413747:1413747 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
161: hkn0520:2737231:2737231 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
354: hkn0707:4044308:4044308 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
354: hkn0707:4044308:4044308 [2] NCCL INFO P2P plugin IBext
352: hkn0707:4044320:4044320 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
352: hkn0707:4044320:4044320 [0] NCCL INFO P2P plugin IBext
353: hkn0707:4044300:4044300 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
353: hkn0707:4044300:4044300 [1] NCCL INFO P2P plugin IBext
160: hkn0520:2737215:2737215 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
162: hkn0520:2737243:2737243 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
162: hkn0520:2737243:2737243 [2] NCCL INFO P2P plugin IBext
349: hkn0706:776624:776624 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
260: hkn0613:927106:927106 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
260: hkn0613:927106:927106 [0] NCCL INFO Using network IBext
261: hkn0613:927098:927098 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
261: hkn0613:927098:927098 [1] NCCL INFO Using network IBext
351: hkn0706:776604:776604 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
351: hkn0706:776604:776604 [3] NCCL INFO P2P plugin IBext
262: hkn0613:927118:927118 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
262: hkn0613:927118:927118 [2] NCCL INFO Using network IBext
  7: hkn0404:1363854:1363854 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  7: hkn0404:1363854:1363854 [3] NCCL INFO P2P plugin IBext
214: hkn0535:2423350:2423350 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
214: hkn0535:2423350:2423350 [2] NCCL INFO Using network IBext
212: hkn0535:2423336:2423336 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
348: hkn0706:776612:776612 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
212: hkn0535:2423336:2423336 [0] NCCL INFO Using network IBext
348: hkn0706:776612:776612 [0] NCCL INFO Using network IBext
350: hkn0706:776596:776596 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
350: hkn0706:776596:776596 [2] NCCL INFO Using network IBext
  5: hkn0404:1363874:1363874 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  5: hkn0404:1363874:1363874 [1] NCCL INFO P2P plugin IBext
 65: hkn0421:2208731:2208731 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 65: hkn0421:2208731:2208731 [1] NCCL INFO P2P plugin IBext
 26: hkn0410:1184027:1184027 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 67: hkn0421:2208711:2208711 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 67: hkn0421:2208711:2208711 [3] NCCL INFO P2P plugin IBext
163: hkn0520:2737223:2737223 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
163: hkn0520:2737223:2737223 [3] NCCL INFO P2P plugin IBext
446: hkn0733:1413719:1413719 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
  4: hkn0404:1363862:1363862 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  4: hkn0404:1363862:1363862 [0] NCCL INFO P2P plugin IBext
 27: hkn0410:1184055:1184055 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 27: hkn0410:1184055:1184055 [3] NCCL INFO P2P plugin IBext
104: hkn0503:2924170:2924170 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
 64: hkn0421:2208719:2208719 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 64: hkn0421:2208719:2208719 [0] NCCL INFO P2P plugin IBext
106: hkn0503:2924162:2924162 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
  6: hkn0404:1363846:1363846 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  6: hkn0404:1363846:1363846 [2] NCCL INFO P2P plugin IBext
 48: hkn0417:2292075:2292075 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 48: hkn0417:2292075:2292075 [0] NCCL INFO P2P plugin IBext
 49: hkn0417:2292047:2292047 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 49: hkn0417:2292047:2292047 [1] NCCL INFO P2P plugin IBext
 51: hkn0417:2292063:2292063 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 51: hkn0417:2292063:2292063 [3] NCCL INFO P2P plugin IBext
 50: hkn0417:2292055:2292055 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 50: hkn0417:2292055:2292055 [2] NCCL INFO P2P plugin IBext
444: hkn0733:1413747:1413747 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
444: hkn0733:1413747:1413747 [0] NCCL INFO P2P plugin IBext
107: hkn0503:2924178:2924178 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
352: hkn0707:4044320:4044320 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
352: hkn0707:4044320:4044320 [0] NCCL INFO Using network IBext
353: hkn0707:4044300:4044300 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
354: hkn0707:4044308:4044308 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
353: hkn0707:4044300:4044300 [1] NCCL INFO Using network IBext
354: hkn0707:4044308:4044308 [2] NCCL INFO Using network IBext
105: hkn0503:2924190:2924190 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
445: hkn0733:1413727:1413727 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
161: hkn0520:2737231:2737231 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
161: hkn0520:2737231:2737231 [1] NCCL INFO P2P plugin IBext
351: hkn0706:776604:776604 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
351: hkn0706:776604:776604 [3] NCCL INFO Using network IBext
 24: hkn0410:1184043:1184043 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
355: hkn0707:4044292:4044292 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
355: hkn0707:4044292:4044292 [3] NCCL INFO Using network IBext
160: hkn0520:2737215:2737215 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
160: hkn0520:2737215:2737215 [0] NCCL INFO P2P plugin IBext
447: hkn0733:1413735:1413735 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
263: hkn0613:927090:927090 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
263: hkn0613:927090:927090 [3] NCCL INFO Using network IBext
349: hkn0706:776624:776624 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
349: hkn0706:776624:776624 [1] NCCL INFO P2P plugin IBext
 25: hkn0410:1184035:1184035 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
222: hkn0602:3390386:3390386 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
 64: hkn0421:2208719:2208719 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 65: hkn0421:2208731:2208731 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 67: hkn0421:2208711:2208711 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 67: hkn0421:2208711:2208711 [3] NCCL INFO Using network IBext
 64: hkn0421:2208719:2208719 [0] NCCL INFO Using network IBext
 65: hkn0421:2208731:2208731 [1] NCCL INFO Using network IBext
163: hkn0520:2737223:2737223 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
109: hkn0504:65443:65443 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
163: hkn0520:2737223:2737223 [3] NCCL INFO Using network IBext
  4: hkn0404:1363862:1363862 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  4: hkn0404:1363862:1363862 [0] NCCL INFO Using network IBext
  6: hkn0404:1363846:1363846 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  6: hkn0404:1363846:1363846 [2] NCCL INFO Using network IBext
 26: hkn0410:1184027:1184027 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 26: hkn0410:1184027:1184027 [2] NCCL INFO P2P plugin IBext
446: hkn0733:1413719:1413719 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
446: hkn0733:1413719:1413719 [2] NCCL INFO P2P plugin IBext
161: hkn0520:2737231:2737231 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
161: hkn0520:2737231:2737231 [1] NCCL INFO Using network IBext
106: hkn0503:2924162:2924162 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
106: hkn0503:2924162:2924162 [2] NCCL INFO P2P plugin IBext
160: hkn0520:2737215:2737215 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
160: hkn0520:2737215:2737215 [0] NCCL INFO Using network IBext
349: hkn0706:776624:776624 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
349: hkn0706:776624:776624 [1] NCCL INFO Using network IBext
 66: hkn0421:2208703:2208703 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 66: hkn0421:2208703:2208703 [2] NCCL INFO Using network IBext
107: hkn0503:2924178:2924178 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
107: hkn0503:2924178:2924178 [3] NCCL INFO P2P plugin IBext
105: hkn0503:2924190:2924190 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
105: hkn0503:2924190:2924190 [1] NCCL INFO P2P plugin IBext
104: hkn0503:2924170:2924170 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
104: hkn0503:2924170:2924170 [0] NCCL INFO P2P plugin IBext
445: hkn0733:1413727:1413727 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
445: hkn0733:1413727:1413727 [1] NCCL INFO P2P plugin IBext
221: hkn0602:3390370:3390370 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
447: hkn0733:1413735:1413735 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
447: hkn0733:1413735:1413735 [3] NCCL INFO P2P plugin IBext
111: hkn0504:65451:65451 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
 24: hkn0410:1184043:1184043 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 24: hkn0410:1184043:1184043 [0] NCCL INFO P2P plugin IBext
162: hkn0520:2737243:2737243 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
162: hkn0520:2737243:2737243 [2] NCCL INFO Using network IBext
110: hkn0504:65463:65463 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
220: hkn0602:3390398:3390398 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
 25: hkn0410:1184035:1184035 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 25: hkn0410:1184035:1184035 [1] NCCL INFO P2P plugin IBext
  7: hkn0404:1363854:1363854 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  7: hkn0404:1363854:1363854 [3] NCCL INFO Using network IBext
  5: hkn0404:1363874:1363874 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  5: hkn0404:1363874:1363874 [1] NCCL INFO Using network IBext
222: hkn0602:3390386:3390386 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
222: hkn0602:3390386:3390386 [2] NCCL INFO P2P plugin IBext
 26: hkn0410:1184027:1184027 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 26: hkn0410:1184027:1184027 [2] NCCL INFO Using network IBext
109: hkn0504:65443:65443 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
109: hkn0504:65443:65443 [1] NCCL INFO P2P plugin IBext
446: hkn0733:1413719:1413719 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
446: hkn0733:1413719:1413719 [2] NCCL INFO Using network IBext
223: hkn0602:3390378:3390378 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
445: hkn0733:1413727:1413727 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
445: hkn0733:1413727:1413727 [1] NCCL INFO Using network IBext
 27: hkn0410:1184055:1184055 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 27: hkn0410:1184055:1184055 [3] NCCL INFO Using network IBext
108: hkn0504:65435:65435 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
447: hkn0733:1413735:1413735 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
447: hkn0733:1413735:1413735 [3] NCCL INFO Using network IBext
 24: hkn0410:1184043:1184043 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 24: hkn0410:1184043:1184043 [0] NCCL INFO Using network IBext
107: hkn0503:2924178:2924178 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
107: hkn0503:2924178:2924178 [3] NCCL INFO Using network IBext
104: hkn0503:2924170:2924170 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
105: hkn0503:2924190:2924190 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
104: hkn0503:2924170:2924170 [0] NCCL INFO Using network IBext
105: hkn0503:2924190:2924190 [1] NCCL INFO Using network IBext
381: hkn0715:426296:426296 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
444: hkn0733:1413747:1413747 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
444: hkn0733:1413747:1413747 [0] NCCL INFO Using network IBext
 14: hkn0407:1840633:1840633 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
221: hkn0602:3390370:3390370 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
221: hkn0602:3390370:3390370 [1] NCCL INFO P2P plugin IBext
 25: hkn0410:1184035:1184035 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 25: hkn0410:1184035:1184035 [1] NCCL INFO Using network IBext
382: hkn0715:426276:426276 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
111: hkn0504:65451:65451 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
111: hkn0504:65451:65451 [3] NCCL INFO P2P plugin IBext
 12: hkn0407:1840613:1840613 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
110: hkn0504:65463:65463 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
110: hkn0504:65463:65463 [2] NCCL INFO P2P plugin IBext
 50: hkn0417:2292055:2292055 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 50: hkn0417:2292055:2292055 [2] NCCL INFO Using network IBext
 48: hkn0417:2292075:2292075 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 48: hkn0417:2292075:2292075 [0] NCCL INFO Using network IBext
 51: hkn0417:2292063:2292063 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 49: hkn0417:2292047:2292047 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 51: hkn0417:2292063:2292063 [3] NCCL INFO Using network IBext
 49: hkn0417:2292047:2292047 [1] NCCL INFO Using network IBext
 54: hkn0418:1893557:1893557 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
220: hkn0602:3390398:3390398 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
220: hkn0602:3390398:3390398 [0] NCCL INFO P2P plugin IBext
383: hkn0715:426284:426284 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
 52: hkn0418:1893569:1893569 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
223: hkn0602:3390378:3390378 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
223: hkn0602:3390378:3390378 [3] NCCL INFO P2P plugin IBext
 53: hkn0418:1893541:1893541 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
380: hkn0715:426268:426268 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
108: hkn0504:65435:65435 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
108: hkn0504:65435:65435 [0] NCCL INFO P2P plugin IBext
 13: hkn0407:1840621:1840621 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
106: hkn0503:2924162:2924162 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
106: hkn0503:2924162:2924162 [2] NCCL INFO Using network IBext
221: hkn0602:3390370:3390370 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
221: hkn0602:3390370:3390370 [1] NCCL INFO Using network IBext
 14: hkn0407:1840633:1840633 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 14: hkn0407:1840633:1840633 [2] NCCL INFO P2P plugin IBext
382: hkn0715:426276:426276 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
382: hkn0715:426276:426276 [2] NCCL INFO P2P plugin IBext
 55: hkn0418:1893549:1893549 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
220: hkn0602:3390398:3390398 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
220: hkn0602:3390398:3390398 [0] NCCL INFO Using network IBext
381: hkn0715:426296:426296 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
381: hkn0715:426296:426296 [1] NCCL INFO P2P plugin IBext
110: hkn0504:65463:65463 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
110: hkn0504:65463:65463 [2] NCCL INFO Using network IBext
111: hkn0504:65451:65451 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
111: hkn0504:65451:65451 [3] NCCL INFO Using network IBext
 12: hkn0407:1840613:1840613 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 12: hkn0407:1840613:1840613 [0] NCCL INFO P2P plugin IBext
 15: hkn0407:1840605:1840605 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
134: hkn0510:2786427:2786427 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
132: hkn0510:2786415:2786415 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
223: hkn0602:3390378:3390378 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
223: hkn0602:3390378:3390378 [3] NCCL INFO Using network IBext
 54: hkn0418:1893557:1893557 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 54: hkn0418:1893557:1893557 [2] NCCL INFO P2P plugin IBext
133: hkn0510:2786407:2786407 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
108: hkn0504:65435:65435 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
108: hkn0504:65435:65435 [0] NCCL INFO Using network IBext
109: hkn0504:65443:65443 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
109: hkn0504:65443:65443 [1] NCCL INFO Using network IBext
 52: hkn0418:1893569:1893569 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 52: hkn0418:1893569:1893569 [0] NCCL INFO P2P plugin IBext
222: hkn0602:3390386:3390386 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
135: hkn0510:2786399:2786399 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
222: hkn0602:3390386:3390386 [2] NCCL INFO Using network IBext
 53: hkn0418:1893541:1893541 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 53: hkn0418:1893541:1893541 [1] NCCL INFO P2P plugin IBext
383: hkn0715:426284:426284 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
383: hkn0715:426284:426284 [3] NCCL INFO P2P plugin IBext
 13: hkn0407:1840621:1840621 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 13: hkn0407:1840621:1840621 [1] NCCL INFO P2P plugin IBext
380: hkn0715:426268:426268 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
380: hkn0715:426268:426268 [0] NCCL INFO P2P plugin IBext
369: hkn0712:319420:319420 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
370: hkn0712:319448:319448 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
172: hkn0524:1158136:1158136 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
 43: hkn0414:2006106:2006106 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
 55: hkn0418:1893549:1893549 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 55: hkn0418:1893549:1893549 [3] NCCL INFO P2P plugin IBext
 41: hkn0414:2006098:2006098 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
371: hkn0712:319428:319428 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
 12: hkn0407:1840613:1840613 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 12: hkn0407:1840613:1840613 [0] NCCL INFO Using network IBext
 15: hkn0407:1840605:1840605 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 15: hkn0407:1840605:1840605 [3] NCCL INFO P2P plugin IBext
134: hkn0510:2786427:2786427 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
134: hkn0510:2786427:2786427 [2] NCCL INFO P2P plugin IBext
133: hkn0510:2786407:2786407 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
133: hkn0510:2786407:2786407 [1] NCCL INFO P2P plugin IBext
 13: hkn0407:1840621:1840621 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 13: hkn0407:1840621:1840621 [1] NCCL INFO Using network IBext
 53: hkn0418:1893541:1893541 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 53: hkn0418:1893541:1893541 [1] NCCL INFO Using network IBext
 52: hkn0418:1893569:1893569 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 52: hkn0418:1893569:1893569 [0] NCCL INFO Using network IBext
132: hkn0510:2786415:2786415 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
132: hkn0510:2786415:2786415 [0] NCCL INFO P2P plugin IBext
174: hkn0524:1158156:1158156 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
135: hkn0510:2786399:2786399 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
135: hkn0510:2786399:2786399 [3] NCCL INFO P2P plugin IBext
 55: hkn0418:1893549:1893549 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 55: hkn0418:1893549:1893549 [3] NCCL INFO Using network IBext
380: hkn0715:426268:426268 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
383: hkn0715:426284:426284 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
383: hkn0715:426284:426284 [3] NCCL INFO Using network IBext
380: hkn0715:426268:426268 [0] NCCL INFO Using network IBext
175: hkn0524:1158128:1158128 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
369: hkn0712:319420:319420 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
369: hkn0712:319420:319420 [1] NCCL INFO P2P plugin IBext
173: hkn0524:1158144:1158144 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
370: hkn0712:319448:319448 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
370: hkn0712:319448:319448 [2] NCCL INFO P2P plugin IBext
 15: hkn0407:1840605:1840605 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 15: hkn0407:1840605:1840605 [3] NCCL INFO Using network IBext
 40: hkn0414:2006126:2006126 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
 14: hkn0407:1840633:1840633 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 14: hkn0407:1840633:1840633 [2] NCCL INFO Using network IBext
120: hkn0507:3211471:3211471 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
172: hkn0524:1158136:1158136 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
172: hkn0524:1158136:1158136 [0] NCCL INFO P2P plugin IBext
 43: hkn0414:2006106:2006106 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 43: hkn0414:2006106:2006106 [3] NCCL INFO P2P plugin IBext
122: hkn0507:3211459:3211459 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
371: hkn0712:319428:319428 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
371: hkn0712:319428:319428 [3] NCCL INFO P2P plugin IBext
 41: hkn0414:2006098:2006098 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 41: hkn0414:2006098:2006098 [1] NCCL INFO P2P plugin IBext
123: hkn0507:3211443:3211443 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
121: hkn0507:3211451:3211451 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
382: hkn0715:426276:426276 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
382: hkn0715:426276:426276 [2] NCCL INFO Using network IBext
381: hkn0715:426296:426296 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
381: hkn0715:426296:426296 [1] NCCL INFO Using network IBext
 42: hkn0414:2006114:2006114 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
133: hkn0510:2786407:2786407 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
133: hkn0510:2786407:2786407 [1] NCCL INFO Using network IBext
132: hkn0510:2786415:2786415 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
135: hkn0510:2786399:2786399 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
132: hkn0510:2786415:2786415 [0] NCCL INFO Using network IBext
135: hkn0510:2786399:2786399 [3] NCCL INFO Using network IBext
 54: hkn0418:1893557:1893557 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 54: hkn0418:1893557:1893557 [2] NCCL INFO Using network IBext
174: hkn0524:1158156:1158156 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
174: hkn0524:1158156:1158156 [2] NCCL INFO P2P plugin IBext
368: hkn0712:319436:319436 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
175: hkn0524:1158128:1158128 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
175: hkn0524:1158128:1158128 [3] NCCL INFO P2P plugin IBext
 40: hkn0414:2006126:2006126 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 40: hkn0414:2006126:2006126 [0] NCCL INFO P2P plugin IBext
173: hkn0524:1158144:1158144 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
173: hkn0524:1158144:1158144 [1] NCCL INFO P2P plugin IBext
120: hkn0507:3211471:3211471 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
120: hkn0507:3211471:3211471 [0] NCCL INFO P2P plugin IBext
371: hkn0712:319428:319428 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
371: hkn0712:319428:319428 [3] NCCL INFO Using network IBext
123: hkn0507:3211443:3211443 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
123: hkn0507:3211443:3211443 [3] NCCL INFO P2P plugin IBext
 42: hkn0414:2006114:2006114 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 42: hkn0414:2006114:2006114 [2] NCCL INFO P2P plugin IBext
134: hkn0510:2786427:2786427 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
134: hkn0510:2786427:2786427 [2] NCCL INFO Using network IBext
122: hkn0507:3211459:3211459 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
122: hkn0507:3211459:3211459 [2] NCCL INFO P2P plugin IBext
126: hkn0508:3163478:3163478 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
124: hkn0508:3163506:3163506 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
121: hkn0507:3211451:3211451 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
121: hkn0507:3211451:3211451 [1] NCCL INFO P2P plugin IBext
174: hkn0524:1158156:1158156 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
174: hkn0524:1158156:1158156 [2] NCCL INFO Using network IBext
175: hkn0524:1158128:1158128 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
175: hkn0524:1158128:1158128 [3] NCCL INFO Using network IBext
173: hkn0524:1158144:1158144 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
173: hkn0524:1158144:1158144 [1] NCCL INFO Using network IBext
368: hkn0712:319436:319436 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
368: hkn0712:319436:319436 [0] NCCL INFO P2P plugin IBext
 40: hkn0414:2006126:2006126 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 40: hkn0414:2006126:2006126 [0] NCCL INFO Using network IBext
308: hkn0630:1622844:1622844 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
369: hkn0712:319420:319420 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
369: hkn0712:319420:319420 [1] NCCL INFO Using network IBext
370: hkn0712:319448:319448 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
370: hkn0712:319448:319448 [2] NCCL INFO Using network IBext
 42: hkn0414:2006114:2006114 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 42: hkn0414:2006114:2006114 [2] NCCL INFO Using network IBext
172: hkn0524:1158136:1158136 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
172: hkn0524:1158136:1158136 [0] NCCL INFO Using network IBext
 43: hkn0414:2006106:2006106 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 43: hkn0414:2006106:2006106 [3] NCCL INFO Using network IBext
 41: hkn0414:2006098:2006098 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 41: hkn0414:2006098:2006098 [1] NCCL INFO Using network IBext
122: hkn0507:3211459:3211459 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
123: hkn0507:3211443:3211443 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
123: hkn0507:3211443:3211443 [3] NCCL INFO Using network IBext
121: hkn0507:3211451:3211451 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
122: hkn0507:3211459:3211459 [2] NCCL INFO Using network IBext
121: hkn0507:3211451:3211451 [1] NCCL INFO Using network IBext
309: hkn0630:1622860:1622860 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
330: hkn0635:1249906:1249906 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
124: hkn0508:3163506:3163506 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
124: hkn0508:3163506:3163506 [0] NCCL INFO P2P plugin IBext
126: hkn0508:3163478:3163478 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
126: hkn0508:3163478:3163478 [2] NCCL INFO P2P plugin IBext
368: hkn0712:319436:319436 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
368: hkn0712:319436:319436 [0] NCCL INFO Using network IBext
361: hkn0710:379895:379895 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
281: hkn0622:2045016:2045016 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
360: hkn0710:379903:379903 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
283: hkn0622:2045028:2045028 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
125: hkn0508:3163494:3163494 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
127: hkn0508:3163486:3163486 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
308: hkn0630:1622844:1622844 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
308: hkn0630:1622844:1622844 [0] NCCL INFO P2P plugin IBext
328: hkn0635:1249926:1249926 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
120: hkn0507:3211471:3211471 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
120: hkn0507:3211471:3211471 [0] NCCL INFO Using network IBext
363: hkn0710:379887:379887 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
329: hkn0635:1249898:1249898 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
331: hkn0635:1249914:1249914 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
 89: hkn0427:1159514:1159514 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
309: hkn0630:1622860:1622860 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
309: hkn0630:1622860:1622860 [1] NCCL INFO P2P plugin IBext
280: hkn0622:2045000:2045000 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
330: hkn0635:1249906:1249906 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
330: hkn0635:1249906:1249906 [2] NCCL INFO P2P plugin IBext
287: hkn0623:1897155:1897155 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
 91: hkn0427:1159506:1159506 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
282: hkn0622:2045008:2045008 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
361: hkn0710:379895:379895 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
361: hkn0710:379895:379895 [1] NCCL INFO P2P plugin IBext
281: hkn0622:2045016:2045016 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
281: hkn0622:2045016:2045016 [1] NCCL INFO P2P plugin IBext
362: hkn0710:379915:379915 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
283: hkn0622:2045028:2045028 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
283: hkn0622:2045028:2045028 [3] NCCL INFO P2P plugin IBext
360: hkn0710:379903:379903 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
360: hkn0710:379903:379903 [0] NCCL INFO P2P plugin IBext
146: hkn0513:3037323:3037323 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
 90: hkn0427:1159498:1159498 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
328: hkn0635:1249926:1249926 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
328: hkn0635:1249926:1249926 [0] NCCL INFO P2P plugin IBext
127: hkn0508:3163486:3163486 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
127: hkn0508:3163486:3163486 [3] NCCL INFO P2P plugin IBext
125: hkn0508:3163494:3163494 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
125: hkn0508:3163494:3163494 [1] NCCL INFO P2P plugin IBext
286: hkn0623:1897143:1897143 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
363: hkn0710:379887:379887 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
363: hkn0710:379887:379887 [3] NCCL INFO P2P plugin IBext
331: hkn0635:1249914:1249914 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
331: hkn0635:1249914:1249914 [3] NCCL INFO P2P plugin IBext
 89: hkn0427:1159514:1159514 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 89: hkn0427:1159514:1159514 [1] NCCL INFO P2P plugin IBext
 88: hkn0427:1159526:1159526 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
309: hkn0630:1622860:1622860 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
309: hkn0630:1622860:1622860 [1] NCCL INFO Using network IBext
329: hkn0635:1249898:1249898 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
329: hkn0635:1249898:1249898 [1] NCCL INFO P2P plugin IBext
280: hkn0622:2045000:2045000 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
280: hkn0622:2045000:2045000 [0] NCCL INFO P2P plugin IBext
287: hkn0623:1897155:1897155 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
287: hkn0623:1897155:1897155 [3] NCCL INFO P2P plugin IBext
282: hkn0622:2045008:2045008 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
282: hkn0622:2045008:2045008 [2] NCCL INFO P2P plugin IBext
 91: hkn0427:1159506:1159506 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 91: hkn0427:1159506:1159506 [3] NCCL INFO P2P plugin IBext
362: hkn0710:379915:379915 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
362: hkn0710:379915:379915 [2] NCCL INFO P2P plugin IBext
360: hkn0710:379903:379903 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
215: hkn0535:2423320:2423320 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
360: hkn0710:379903:379903 [0] NCCL INFO Using network IBext
363: hkn0710:379887:379887 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
363: hkn0710:379887:379887 [3] NCCL INFO Using network IBext
146: hkn0513:3037323:3037323 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
146: hkn0513:3037323:3037323 [2] NCCL INFO P2P plugin IBext
 90: hkn0427:1159498:1159498 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 90: hkn0427:1159498:1159498 [2] NCCL INFO P2P plugin IBext
126: hkn0508:3163478:3163478 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
308: hkn0630:1622844:1622844 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
127: hkn0508:3163486:3163486 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
126: hkn0508:3163478:3163478 [2] NCCL INFO Using network IBext
127: hkn0508:3163486:3163486 [3] NCCL INFO Using network IBext
308: hkn0630:1622844:1622844 [0] NCCL INFO Using network IBext
124: hkn0508:3163506:3163506 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
125: hkn0508:3163494:3163494 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
125: hkn0508:3163494:3163494 [1] NCCL INFO Using network IBext
124: hkn0508:3163506:3163506 [0] NCCL INFO Using network IBext
328: hkn0635:1249926:1249926 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
331: hkn0635:1249914:1249914 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
328: hkn0635:1249926:1249926 [0] NCCL INFO Using network IBext
331: hkn0635:1249914:1249914 [3] NCCL INFO Using network IBext
329: hkn0635:1249898:1249898 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
329: hkn0635:1249898:1249898 [1] NCCL INFO Using network IBext
286: hkn0623:1897143:1897143 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
286: hkn0623:1897143:1897143 [2] NCCL INFO P2P plugin IBext
 88: hkn0427:1159526:1159526 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 88: hkn0427:1159526:1159526 [0] NCCL INFO P2P plugin IBext
282: hkn0622:2045008:2045008 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
282: hkn0622:2045008:2045008 [2] NCCL INFO Using network IBext
280: hkn0622:2045000:2045000 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
280: hkn0622:2045000:2045000 [0] NCCL INFO Using network IBext
362: hkn0710:379915:379915 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
362: hkn0710:379915:379915 [2] NCCL INFO Using network IBext
330: hkn0635:1249906:1249906 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
330: hkn0635:1249906:1249906 [2] NCCL INFO Using network IBext
 91: hkn0427:1159506:1159506 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 91: hkn0427:1159506:1159506 [3] NCCL INFO Using network IBext
361: hkn0710:379895:379895 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
361: hkn0710:379895:379895 [1] NCCL INFO Using network IBext
501: hkn0814:700172:700172 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
503: hkn0814:700156:700156 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
 90: hkn0427:1159498:1159498 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 90: hkn0427:1159498:1159498 [2] NCCL INFO Using network IBext
251: hkn0609:735154:735154 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
306: hkn0629:1616375:1616375 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
215: hkn0535:2423320:2423320 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
215: hkn0535:2423320:2423320 [3] NCCL INFO P2P plugin IBext
146: hkn0513:3037323:3037323 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
146: hkn0513:3037323:3037323 [2] NCCL INFO Using network IBext
281: hkn0622:2045016:2045016 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
281: hkn0622:2045016:2045016 [1] NCCL INFO Using network IBext
283: hkn0622:2045028:2045028 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
283: hkn0622:2045028:2045028 [3] NCCL INFO Using network IBext
500: hkn0814:700164:700164 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
224: hkn0603:1437575:1437575 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
 88: hkn0427:1159526:1159526 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 88: hkn0427:1159526:1159526 [0] NCCL INFO Using network IBext
502: hkn0814:700184:700184 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
250: hkn0609:735166:735166 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
286: hkn0623:1897143:1897143 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
286: hkn0623:1897143:1897143 [2] NCCL INFO Using network IBext
249: hkn0609:735138:735138 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
 89: hkn0427:1159514:1159514 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 89: hkn0427:1159514:1159514 [1] NCCL INFO Using network IBext
215: hkn0535:2423320:2423320 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
215: hkn0535:2423320:2423320 [3] NCCL INFO Using network IBext
503: hkn0814:700156:700156 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
503: hkn0814:700156:700156 [3] NCCL INFO P2P plugin IBext
251: hkn0609:735154:735154 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
287: hkn0623:1897155:1897155 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
251: hkn0609:735154:735154 [3] NCCL INFO P2P plugin IBext
287: hkn0623:1897155:1897155 [3] NCCL INFO Using network IBext
310: hkn0630:1622852:1622852 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
306: hkn0629:1616375:1616375 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
306: hkn0629:1616375:1616375 [2] NCCL INFO P2P plugin IBext
311: hkn0630:1622872:1622872 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
501: hkn0814:700172:700172 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
501: hkn0814:700172:700172 [1] NCCL INFO P2P plugin IBext
500: hkn0814:700164:700164 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
500: hkn0814:700164:700164 [0] NCCL INFO P2P plugin IBext
203: hkn0531:1255122:1255122 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
224: hkn0603:1437575:1437575 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
224: hkn0603:1437575:1437575 [0] NCCL INFO P2P plugin IBext
250: hkn0609:735166:735166 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
250: hkn0609:735166:735166 [2] NCCL INFO P2P plugin IBext
502: hkn0814:700184:700184 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
502: hkn0814:700184:700184 [2] NCCL INFO P2P plugin IBext
249: hkn0609:735138:735138 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
249: hkn0609:735138:735138 [1] NCCL INFO P2P plugin IBext
248: hkn0609:735146:735146 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
305: hkn0629:1616367:1616367 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
225: hkn0603:1437591:1437591 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
344: hkn0705:807566:807566 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
310: hkn0630:1622852:1622852 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
310: hkn0630:1622852:1622852 [2] NCCL INFO P2P plugin IBext
304: hkn0629:1616359:1616359 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
311: hkn0630:1622872:1622872 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
311: hkn0630:1622872:1622872 [3] NCCL INFO P2P plugin IBext
501: hkn0814:700172:700172 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
501: hkn0814:700172:700172 [1] NCCL INFO Using network IBext
500: hkn0814:700164:700164 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
500: hkn0814:700164:700164 [0] NCCL INFO Using network IBext
346: hkn0705:807578:807578 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
502: hkn0814:700184:700184 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
502: hkn0814:700184:700184 [2] NCCL INFO Using network IBext
202: hkn0531:1255138:1255138 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
227: hkn0603:1437583:1437583 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
203: hkn0531:1255122:1255122 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
203: hkn0531:1255122:1255122 [3] NCCL INFO P2P plugin IBext
307: hkn0629:1616387:1616387 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
249: hkn0609:735138:735138 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
250: hkn0609:735166:735166 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
249: hkn0609:735138:735138 [1] NCCL INFO Using network IBext
250: hkn0609:735166:735166 [2] NCCL INFO Using network IBext
248: hkn0609:735146:735146 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
248: hkn0609:735146:735146 [0] NCCL INFO P2P plugin IBext
310: hkn0630:1622852:1622852 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
311: hkn0630:1622872:1622872 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
310: hkn0630:1622852:1622852 [2] NCCL INFO Using network IBext
311: hkn0630:1622872:1622872 [3] NCCL INFO Using network IBext
305: hkn0629:1616367:1616367 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
305: hkn0629:1616367:1616367 [1] NCCL INFO P2P plugin IBext
285: hkn0623:1897135:1897135 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
357: hkn0708:437583:437583 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
226: hkn0603:1437603:1437603 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
344: hkn0705:807566:807566 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
344: hkn0705:807566:807566 [0] NCCL INFO P2P plugin IBext
251: hkn0609:735154:735154 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
251: hkn0609:735154:735154 [3] NCCL INFO Using network IBext
503: hkn0814:700156:700156 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
503: hkn0814:700156:700156 [3] NCCL INFO Using network IBext
201: hkn0531:1255130:1255130 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
225: hkn0603:1437591:1437591 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
225: hkn0603:1437591:1437591 [1] NCCL INFO P2P plugin IBext
346: hkn0705:807578:807578 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
346: hkn0705:807578:807578 [2] NCCL INFO P2P plugin IBext
304: hkn0629:1616359:1616359 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
304: hkn0629:1616359:1616359 [0] NCCL INFO P2P plugin IBext
284: hkn0623:1897127:1897127 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
202: hkn0531:1255138:1255138 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
202: hkn0531:1255138:1255138 [2] NCCL INFO P2P plugin IBext
307: hkn0629:1616387:1616387 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
307: hkn0629:1616387:1616387 [3] NCCL INFO P2P plugin IBext
345: hkn0705:807558:807558 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
248: hkn0609:735146:735146 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
248: hkn0609:735146:735146 [0] NCCL INFO Using network IBext
387: hkn0716:132839:132839 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
227: hkn0603:1437583:1437583 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
227: hkn0603:1437583:1437583 [3] NCCL INFO P2P plugin IBext
306: hkn0629:1616375:1616375 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
306: hkn0629:1616375:1616375 [2] NCCL INFO Using network IBext
305: hkn0629:1616367:1616367 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
305: hkn0629:1616367:1616367 [1] NCCL INFO Using network IBext
386: hkn0716:132819:132819 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
347: hkn0705:807550:807550 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
385: hkn0716:132811:132811 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
304: hkn0629:1616359:1616359 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
304: hkn0629:1616359:1616359 [0] NCCL INFO Using network IBext
225: hkn0603:1437591:1437591 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
225: hkn0603:1437591:1437591 [1] NCCL INFO Using network IBext
224: hkn0603:1437575:1437575 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
224: hkn0603:1437575:1437575 [0] NCCL INFO Using network IBext
357: hkn0708:437583:437583 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
357: hkn0708:437583:437583 [1] NCCL INFO P2P plugin IBext
227: hkn0603:1437583:1437583 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
227: hkn0603:1437583:1437583 [3] NCCL INFO Using network IBext
307: hkn0629:1616387:1616387 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
346: hkn0705:807578:807578 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
307: hkn0629:1616387:1616387 [3] NCCL INFO Using network IBext
346: hkn0705:807578:807578 [2] NCCL INFO Using network IBext
226: hkn0603:1437603:1437603 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
226: hkn0603:1437603:1437603 [2] NCCL INFO P2P plugin IBext
201: hkn0531:1255130:1255130 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
201: hkn0531:1255130:1255130 [1] NCCL INFO P2P plugin IBext
384: hkn0716:132827:132827 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
202: hkn0531:1255138:1255138 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
202: hkn0531:1255138:1255138 [2] NCCL INFO Using network IBext
345: hkn0705:807558:807558 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
345: hkn0705:807558:807558 [1] NCCL INFO P2P plugin IBext
285: hkn0623:1897135:1897135 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
285: hkn0623:1897135:1897135 [1] NCCL INFO P2P plugin IBext
200: hkn0531:1255150:1255150 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
203: hkn0531:1255122:1255122 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
203: hkn0531:1255122:1255122 [3] NCCL INFO Using network IBext
387: hkn0716:132839:132839 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
387: hkn0716:132839:132839 [3] NCCL INFO P2P plugin IBext
386: hkn0716:132819:132819 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
386: hkn0716:132819:132819 [2] NCCL INFO P2P plugin IBext
284: hkn0623:1897127:1897127 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
284: hkn0623:1897127:1897127 [0] NCCL INFO P2P plugin IBext
347: hkn0705:807550:807550 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
347: hkn0705:807550:807550 [3] NCCL INFO P2P plugin IBext
201: hkn0531:1255130:1255130 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
201: hkn0531:1255130:1255130 [1] NCCL INFO Using network IBext
226: hkn0603:1437603:1437603 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
226: hkn0603:1437603:1437603 [2] NCCL INFO Using network IBext
385: hkn0716:132811:132811 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
385: hkn0716:132811:132811 [1] NCCL INFO P2P plugin IBext
358: hkn0708:437599:437599 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
345: hkn0705:807558:807558 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
344: hkn0705:807566:807566 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
345: hkn0705:807558:807558 [1] NCCL INFO Using network IBext
344: hkn0705:807566:807566 [0] NCCL INFO Using network IBext
 83: hkn0425:2108537:2108537 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
296: hkn0627:1812310:1812310 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
384: hkn0716:132827:132827 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
384: hkn0716:132827:132827 [0] NCCL INFO P2P plugin IBext
285: hkn0623:1897135:1897135 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
285: hkn0623:1897135:1897135 [1] NCCL INFO Using network IBext
200: hkn0531:1255150:1255150 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
200: hkn0531:1255150:1255150 [0] NCCL INFO P2P plugin IBext
359: hkn0708:437591:437591 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
284: hkn0623:1897127:1897127 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
284: hkn0623:1897127:1897127 [0] NCCL INFO Using network IBext
347: hkn0705:807550:807550 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
347: hkn0705:807550:807550 [3] NCCL INFO Using network IBext
139: hkn0511:3090869:3090869 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
 80: hkn0425:2108509:2108509 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
297: hkn0627:1812302:1812302 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
298: hkn0627:1812322:1812322 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
386: hkn0716:132819:132819 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
386: hkn0716:132819:132819 [2] NCCL INFO Using network IBext
385: hkn0716:132811:132811 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
385: hkn0716:132811:132811 [1] NCCL INFO Using network IBext
 81: hkn0425:2108525:2108525 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
358: hkn0708:437599:437599 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
358: hkn0708:437599:437599 [2] NCCL INFO P2P plugin IBext
178: hkn0525:1011134:1011134 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
136: hkn0511:3090885:3090885 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
384: hkn0716:132827:132827 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
384: hkn0716:132827:132827 [0] NCCL INFO Using network IBext
176: hkn0525:1011118:1011118 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
137: hkn0511:3090877:3090877 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
270: hkn0616:429406:429406 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
200: hkn0531:1255150:1255150 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
177: hkn0525:1011146:1011146 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
200: hkn0531:1255150:1255150 [0] NCCL INFO Using network IBext
 83: hkn0425:2108537:2108537 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 83: hkn0425:2108537:2108537 [3] NCCL INFO P2P plugin IBext
138: hkn0511:3090897:3090897 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
296: hkn0627:1812310:1812310 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
296: hkn0627:1812310:1812310 [0] NCCL INFO P2P plugin IBext
357: hkn0708:437583:437583 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
357: hkn0708:437583:437583 [1] NCCL INFO Using network IBext
359: hkn0708:437591:437591 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
359: hkn0708:437591:437591 [3] NCCL INFO P2P plugin IBext
139: hkn0511:3090869:3090869 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
139: hkn0511:3090869:3090869 [3] NCCL INFO P2P plugin IBext
 82: hkn0425:2108517:2108517 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
 80: hkn0425:2108509:2108509 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 80: hkn0425:2108509:2108509 [0] NCCL INFO P2P plugin IBext
387: hkn0716:132839:132839 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
387: hkn0716:132839:132839 [3] NCCL INFO Using network IBext
269: hkn0616:429426:429426 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
299: hkn0627:1812294:1812294 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
298: hkn0627:1812322:1812322 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
298: hkn0627:1812322:1812322 [2] NCCL INFO P2P plugin IBext
271: hkn0616:429414:429414 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
358: hkn0708:437599:437599 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
358: hkn0708:437599:437599 [2] NCCL INFO Using network IBext
297: hkn0627:1812302:1812302 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
297: hkn0627:1812302:1812302 [1] NCCL INFO P2P plugin IBext
 81: hkn0425:2108525:2108525 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 81: hkn0425:2108525:2108525 [1] NCCL INFO P2P plugin IBext
274: hkn0617:2319200:2319200 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
356: hkn0708:437611:437611 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
136: hkn0511:3090885:3090885 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
136: hkn0511:3090885:3090885 [0] NCCL INFO P2P plugin IBext
178: hkn0525:1011134:1011134 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
178: hkn0525:1011134:1011134 [2] NCCL INFO P2P plugin IBext
137: hkn0511:3090877:3090877 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
137: hkn0511:3090877:3090877 [1] NCCL INFO P2P plugin IBext
176: hkn0525:1011118:1011118 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
176: hkn0525:1011118:1011118 [0] NCCL INFO P2P plugin IBext
179: hkn0525:1011126:1011126 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
270: hkn0616:429406:429406 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
270: hkn0616:429406:429406 [2] NCCL INFO P2P plugin IBext
359: hkn0708:437591:437591 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
359: hkn0708:437591:437591 [3] NCCL INFO Using network IBext
275: hkn0617:2319192:2319192 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
177: hkn0525:1011146:1011146 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
177: hkn0525:1011146:1011146 [1] NCCL INFO P2P plugin IBext
273: hkn0617:2319212:2319212 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
138: hkn0511:3090897:3090897 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
138: hkn0511:3090897:3090897 [2] NCCL INFO P2P plugin IBext
272: hkn0617:2319184:2319184 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
 82: hkn0425:2108517:2108517 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 82: hkn0425:2108517:2108517 [2] NCCL INFO P2P plugin IBext
 80: hkn0425:2108509:2108509 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 81: hkn0425:2108525:2108525 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 80: hkn0425:2108509:2108509 [0] NCCL INFO Using network IBext
 81: hkn0425:2108525:2108525 [1] NCCL INFO Using network IBext
298: hkn0627:1812322:1812322 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
298: hkn0627:1812322:1812322 [2] NCCL INFO Using network IBext
268: hkn0616:429398:429398 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
299: hkn0627:1812294:1812294 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
299: hkn0627:1812294:1812294 [3] NCCL INFO P2P plugin IBext
297: hkn0627:1812302:1812302 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
297: hkn0627:1812302:1812302 [1] NCCL INFO Using network IBext
269: hkn0616:429426:429426 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
269: hkn0616:429426:429426 [1] NCCL INFO P2P plugin IBext
271: hkn0616:429414:429414 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
271: hkn0616:429414:429414 [3] NCCL INFO P2P plugin IBext
274: hkn0617:2319200:2319200 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
274: hkn0617:2319200:2319200 [2] NCCL INFO P2P plugin IBext
356: hkn0708:437611:437611 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
356: hkn0708:437611:437611 [0] NCCL INFO P2P plugin IBext
425: hkn0727:1370175:1370175 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
168: hkn0523:1572589:1572589 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
136: hkn0511:3090885:3090885 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
137: hkn0511:3090877:3090877 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
138: hkn0511:3090897:3090897 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
136: hkn0511:3090885:3090885 [0] NCCL INFO Using network IBext
179: hkn0525:1011126:1011126 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
179: hkn0525:1011126:1011126 [3] NCCL INFO P2P plugin IBext
137: hkn0511:3090877:3090877 [1] NCCL INFO Using network IBext
138: hkn0511:3090897:3090897 [2] NCCL INFO Using network IBext
275: hkn0617:2319192:2319192 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
275: hkn0617:2319192:2319192 [3] NCCL INFO P2P plugin IBext
 82: hkn0425:2108517:2108517 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 82: hkn0425:2108517:2108517 [2] NCCL INFO Using network IBext
 83: hkn0425:2108537:2108537 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 83: hkn0425:2108537:2108537 [3] NCCL INFO Using network IBext
299: hkn0627:1812294:1812294 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
299: hkn0627:1812294:1812294 [3] NCCL INFO Using network IBext
272: hkn0617:2319184:2319184 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
272: hkn0617:2319184:2319184 [0] NCCL INFO P2P plugin IBext
273: hkn0617:2319212:2319212 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
273: hkn0617:2319212:2319212 [1] NCCL INFO P2P plugin IBext
177: hkn0525:1011146:1011146 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
177: hkn0525:1011146:1011146 [1] NCCL INFO Using network IBext
296: hkn0627:1812310:1812310 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
296: hkn0627:1812310:1812310 [0] NCCL INFO Using network IBext
139: hkn0511:3090869:3090869 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
139: hkn0511:3090869:3090869 [3] NCCL INFO Using network IBext
356: hkn0708:437611:437611 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
356: hkn0708:437611:437611 [0] NCCL INFO Using network IBext
268: hkn0616:429398:429398 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
268: hkn0616:429398:429398 [0] NCCL INFO P2P plugin IBext
271: hkn0616:429414:429414 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
271: hkn0616:429414:429414 [3] NCCL INFO Using network IBext
269: hkn0616:429426:429426 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
269: hkn0616:429426:429426 [1] NCCL INFO Using network IBext
456: hkn0801:2264545:2264545 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
179: hkn0525:1011126:1011126 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
179: hkn0525:1011126:1011126 [3] NCCL INFO Using network IBext
458: hkn0801:2264537:2264537 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
168: hkn0523:1572589:1572589 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
168: hkn0523:1572589:1572589 [0] NCCL INFO P2P plugin IBext
171: hkn0523:1572561:1572561 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
176: hkn0525:1011118:1011118 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
176: hkn0525:1011118:1011118 [0] NCCL INFO Using network IBext
178: hkn0525:1011134:1011134 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
178: hkn0525:1011134:1011134 [2] NCCL INFO Using network IBext
424: hkn0727:1370187:1370187 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
272: hkn0617:2319184:2319184 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
425: hkn0727:1370175:1370175 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
425: hkn0727:1370175:1370175 [1] NCCL INFO P2P plugin IBext
273: hkn0617:2319212:2319212 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
273: hkn0617:2319212:2319212 [1] NCCL INFO Using network IBext
272: hkn0617:2319184:2319184 [0] NCCL INFO Using network IBext
275: hkn0617:2319192:2319192 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
275: hkn0617:2319192:2319192 [3] NCCL INFO Using network IBext
170: hkn0523:1572577:1572577 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
426: hkn0727:1370159:1370159 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
270: hkn0616:429406:429406 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
270: hkn0616:429406:429406 [2] NCCL INFO Using network IBext
268: hkn0616:429398:429398 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
268: hkn0616:429398:429398 [0] NCCL INFO Using network IBext
459: hkn0801:2264529:2264529 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
427: hkn0727:1370167:1370167 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
131: hkn0509:3148767:3148767 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
507: hkn0815:419489:419489 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
293: hkn0626:1322798:1322798 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
456: hkn0801:2264545:2264545 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
456: hkn0801:2264545:2264545 [0] NCCL INFO P2P plugin IBext
274: hkn0617:2319200:2319200 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
274: hkn0617:2319200:2319200 [2] NCCL INFO Using network IBext
458: hkn0801:2264537:2264537 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
458: hkn0801:2264537:2264537 [2] NCCL INFO P2P plugin IBext
506: hkn0815:419477:419477 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
169: hkn0523:1572569:1572569 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
171: hkn0523:1572561:1572561 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
171: hkn0523:1572561:1572561 [3] NCCL INFO P2P plugin IBext
424: hkn0727:1370187:1370187 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
424: hkn0727:1370187:1370187 [0] NCCL INFO P2P plugin IBext
426: hkn0727:1370159:1370159 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
426: hkn0727:1370159:1370159 [2] NCCL INFO P2P plugin IBext
129: hkn0509:3148751:3148751 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
170: hkn0523:1572577:1572577 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
170: hkn0523:1572577:1572577 [2] NCCL INFO P2P plugin IBext
457: hkn0801:2264557:2264557 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
128: hkn0509:3148759:3148759 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
459: hkn0801:2264529:2264529 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
459: hkn0801:2264529:2264529 [3] NCCL INFO P2P plugin IBext
130: hkn0509:3148779:3148779 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
131: hkn0509:3148767:3148767 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
131: hkn0509:3148767:3148767 [3] NCCL INFO P2P plugin IBext
 99: hkn0501:1352386:1352386 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
427: hkn0727:1370167:1370167 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
427: hkn0727:1370167:1370167 [3] NCCL INFO P2P plugin IBext
293: hkn0626:1322798:1322798 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
293: hkn0626:1322798:1322798 [1] NCCL INFO P2P plugin IBext
505: hkn0815:419461:419461 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
504: hkn0815:419469:419469 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
507: hkn0815:419489:419489 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
507: hkn0815:419489:419489 [3] NCCL INFO P2P plugin IBext
458: hkn0801:2264537:2264537 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
458: hkn0801:2264537:2264537 [2] NCCL INFO Using network IBext
506: hkn0815:419477:419477 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
506: hkn0815:419477:419477 [2] NCCL INFO P2P plugin IBext
 98: hkn0501:1352394:1352394 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
169: hkn0523:1572569:1572569 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
169: hkn0523:1572569:1572569 [1] NCCL INFO P2P plugin IBext
171: hkn0523:1572561:1572561 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
171: hkn0523:1572561:1572561 [3] NCCL INFO Using network IBext
170: hkn0523:1572577:1572577 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
170: hkn0523:1572577:1572577 [2] NCCL INFO Using network IBext
459: hkn0801:2264529:2264529 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
459: hkn0801:2264529:2264529 [3] NCCL INFO Using network IBext
168: hkn0523:1572589:1572589 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
424: hkn0727:1370187:1370187 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
168: hkn0523:1572589:1572589 [0] NCCL INFO Using network IBext
426: hkn0727:1370159:1370159 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
424: hkn0727:1370187:1370187 [0] NCCL INFO Using network IBext
426: hkn0727:1370159:1370159 [2] NCCL INFO Using network IBext
425: hkn0727:1370175:1370175 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
425: hkn0727:1370175:1370175 [1] NCCL INFO Using network IBext
129: hkn0509:3148751:3148751 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
129: hkn0509:3148751:3148751 [1] NCCL INFO P2P plugin IBext
 97: hkn0501:1352406:1352406 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
295: hkn0626:1322790:1322790 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
457: hkn0801:2264557:2264557 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
457: hkn0801:2264557:2264557 [1] NCCL INFO P2P plugin IBext
427: hkn0727:1370167:1370167 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
427: hkn0727:1370167:1370167 [3] NCCL INFO Using network IBext
128: hkn0509:3148759:3148759 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
128: hkn0509:3148759:3148759 [0] NCCL INFO P2P plugin IBext
130: hkn0509:3148779:3148779 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
130: hkn0509:3148779:3148779 [2] NCCL INFO P2P plugin IBext
 99: hkn0501:1352386:1352386 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 99: hkn0501:1352386:1352386 [3] NCCL INFO P2P plugin IBext
 96: hkn0501:1352378:1352378 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
169: hkn0523:1572569:1572569 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
169: hkn0523:1572569:1572569 [1] NCCL INFO Using network IBext
294: hkn0626:1322810:1322810 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
504: hkn0815:419469:419469 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
504: hkn0815:419469:419469 [0] NCCL INFO P2P plugin IBext
505: hkn0815:419461:419461 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
505: hkn0815:419461:419461 [1] NCCL INFO P2P plugin IBext
456: hkn0801:2264545:2264545 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
456: hkn0801:2264545:2264545 [0] NCCL INFO Using network IBext
457: hkn0801:2264557:2264557 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
457: hkn0801:2264557:2264557 [1] NCCL INFO Using network IBext
495: hkn0810:963921:963921 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
 98: hkn0501:1352394:1352394 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 98: hkn0501:1352394:1352394 [2] NCCL INFO P2P plugin IBext
441: hkn0732:1236021:1236021 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
440: hkn0732:1236033:1236033 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
442: hkn0732:1236013:1236013 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
443: hkn0732:1236005:1236005 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
130: hkn0509:3148779:3148779 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
129: hkn0509:3148751:3148751 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
130: hkn0509:3148779:3148779 [2] NCCL INFO Using network IBext
128: hkn0509:3148759:3148759 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
128: hkn0509:3148759:3148759 [0] NCCL INFO Using network IBext
129: hkn0509:3148751:3148751 [1] NCCL INFO Using network IBext
295: hkn0626:1322790:1322790 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
295: hkn0626:1322790:1322790 [3] NCCL INFO P2P plugin IBext
156: hkn0516:2940342:2940342 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 97: hkn0501:1352406:1352406 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 97: hkn0501:1352406:1352406 [1] NCCL INFO P2P plugin IBext
131: hkn0509:3148767:3148767 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
131: hkn0509:3148767:3148767 [3] NCCL INFO Using network IBext
157: hkn0516:2940314:2940314 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 96: hkn0501:1352378:1352378 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 96: hkn0501:1352378:1352378 [0] NCCL INFO P2P plugin IBext
292: hkn0626:1322782:1322782 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
494: hkn0810:963913:963913 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
504: hkn0815:419469:419469 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
505: hkn0815:419461:419461 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
505: hkn0815:419461:419461 [1] NCCL INFO Using network IBext
504: hkn0815:419469:419469 [0] NCCL INFO Using network IBext
294: hkn0626:1322810:1322810 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
294: hkn0626:1322810:1322810 [2] NCCL INFO P2P plugin IBext
506: hkn0815:419477:419477 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
506: hkn0815:419477:419477 [2] NCCL INFO Using network IBext
495: hkn0810:963921:963921 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
495: hkn0810:963921:963921 [3] NCCL INFO P2P plugin IBext
507: hkn0815:419489:419489 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
507: hkn0815:419489:419489 [3] NCCL INFO Using network IBext
 98: hkn0501:1352394:1352394 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
293: hkn0626:1322798:1322798 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
 98: hkn0501:1352394:1352394 [2] NCCL INFO Using network IBext
293: hkn0626:1322798:1322798 [1] NCCL INFO Using network IBext
295: hkn0626:1322790:1322790 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
295: hkn0626:1322790:1322790 [3] NCCL INFO Using network IBext
159: hkn0516:2940322:2940322 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
441: hkn0732:1236021:1236021 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
441: hkn0732:1236021:1236021 [1] NCCL INFO P2P plugin IBext
440: hkn0732:1236033:1236033 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
440: hkn0732:1236033:1236033 [0] NCCL INFO P2P plugin IBext
442: hkn0732:1236013:1236013 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
442: hkn0732:1236013:1236013 [2] NCCL INFO P2P plugin IBext
 97: hkn0501:1352406:1352406 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 97: hkn0501:1352406:1352406 [1] NCCL INFO Using network IBext
 96: hkn0501:1352378:1352378 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 96: hkn0501:1352378:1352378 [0] NCCL INFO Using network IBext
443: hkn0732:1236005:1236005 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
443: hkn0732:1236005:1236005 [3] NCCL INFO P2P plugin IBext
493: hkn0810:963905:963905 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
158: hkn0516:2940330:2940330 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
294: hkn0626:1322810:1322810 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
294: hkn0626:1322810:1322810 [2] NCCL INFO Using network IBext
156: hkn0516:2940342:2940342 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
156: hkn0516:2940342:2940342 [0] NCCL INFO P2P plugin IBext
492: hkn0810:963933:963933 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
157: hkn0516:2940314:2940314 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
157: hkn0516:2940314:2940314 [1] NCCL INFO P2P plugin IBext
 99: hkn0501:1352386:1352386 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 99: hkn0501:1352386:1352386 [3] NCCL INFO Using network IBext
292: hkn0626:1322782:1322782 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
292: hkn0626:1322782:1322782 [0] NCCL INFO P2P plugin IBext
494: hkn0810:963913:963913 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
494: hkn0810:963913:963913 [2] NCCL INFO P2P plugin IBext
474: hkn0805:1136461:1136461 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
342: hkn0704:816326:816326 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
340: hkn0704:816342:816342 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
475: hkn0805:1136477:1136477 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
159: hkn0516:2940322:2940322 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
159: hkn0516:2940322:2940322 [3] NCCL INFO P2P plugin IBext
443: hkn0732:1236005:1236005 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
443: hkn0732:1236005:1236005 [3] NCCL INFO Using network IBext
473: hkn0805:1136469:1136469 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
292: hkn0626:1322782:1322782 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
292: hkn0626:1322782:1322782 [0] NCCL INFO Using network IBext
493: hkn0810:963905:963905 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
493: hkn0810:963905:963905 [1] NCCL INFO P2P plugin IBext
158: hkn0516:2940330:2940330 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
158: hkn0516:2940330:2940330 [2] NCCL INFO P2P plugin IBext
492: hkn0810:963933:963933 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
492: hkn0810:963933:963933 [0] NCCL INFO P2P plugin IBext
341: hkn0704:816354:816354 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
494: hkn0810:963913:963913 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
494: hkn0810:963913:963913 [2] NCCL INFO Using network IBext
472: hkn0805:1136489:1136489 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
474: hkn0805:1136461:1136461 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
474: hkn0805:1136461:1136461 [2] NCCL INFO P2P plugin IBext
166: hkn0521:1222185:1222185 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
342: hkn0704:816326:816326 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
342: hkn0704:816326:816326 [2] NCCL INFO P2P plugin IBext
343: hkn0704:816334:816334 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
150: hkn0514:2975099:2975099 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
159: hkn0516:2940322:2940322 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
159: hkn0516:2940322:2940322 [3] NCCL INFO Using network IBext
493: hkn0810:963905:963905 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
493: hkn0810:963905:963905 [1] NCCL INFO Using network IBext
340: hkn0704:816342:816342 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
340: hkn0704:816342:816342 [0] NCCL INFO P2P plugin IBext
495: hkn0810:963921:963921 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
495: hkn0810:963921:963921 [3] NCCL INFO Using network IBext
475: hkn0805:1136477:1136477 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
475: hkn0805:1136477:1136477 [3] NCCL INFO P2P plugin IBext
158: hkn0516:2940330:2940330 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
158: hkn0516:2940330:2940330 [2] NCCL INFO Using network IBext
164: hkn0521:1222169:1222169 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
165: hkn0521:1222177:1222177 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
191: hkn0528:1326052:1326052 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
492: hkn0810:963933:963933 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
492: hkn0810:963933:963933 [0] NCCL INFO Using network IBext
441: hkn0732:1236021:1236021 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
441: hkn0732:1236021:1236021 [1] NCCL INFO Using network IBext
473: hkn0805:1136469:1136469 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
473: hkn0805:1136469:1136469 [1] NCCL INFO P2P plugin IBext
167: hkn0521:1222197:1222197 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
440: hkn0732:1236033:1236033 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
440: hkn0732:1236033:1236033 [0] NCCL INFO Using network IBext
442: hkn0732:1236013:1236013 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
442: hkn0732:1236013:1236013 [2] NCCL INFO Using network IBext
341: hkn0704:816354:816354 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
341: hkn0704:816354:816354 [1] NCCL INFO P2P plugin IBext
157: hkn0516:2940314:2940314 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
157: hkn0516:2940314:2940314 [1] NCCL INFO Using network IBext
156: hkn0516:2940342:2940342 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
156: hkn0516:2940342:2940342 [0] NCCL INFO Using network IBext
472: hkn0805:1136489:1136489 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
472: hkn0805:1136489:1136489 [0] NCCL INFO P2P plugin IBext
196: hkn0530:1282482:1282482 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
188: hkn0528:1326072:1326072 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
166: hkn0521:1222185:1222185 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
166: hkn0521:1222185:1222185 [2] NCCL INFO P2P plugin IBext
190: hkn0528:1326060:1326060 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
150: hkn0514:2975099:2975099 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
150: hkn0514:2975099:2975099 [2] NCCL INFO P2P plugin IBext
340: hkn0704:816342:816342 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
340: hkn0704:816342:816342 [0] NCCL INFO Using network IBext
343: hkn0704:816334:816334 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
343: hkn0704:816334:816334 [3] NCCL INFO P2P plugin IBext
400: hkn0720:33752:33752 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
197: hkn0530:1282466:1282466 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
475: hkn0805:1136477:1136477 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
401: hkn0720:33760:33760 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
475: hkn0805:1136477:1136477 [3] NCCL INFO Using network IBext
 87: hkn0426:838380:838380 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
473: hkn0805:1136469:1136469 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
473: hkn0805:1136469:1136469 [1] NCCL INFO Using network IBext
191: hkn0528:1326052:1326052 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
191: hkn0528:1326052:1326052 [3] NCCL INFO P2P plugin IBext
 84: hkn0426:838364:838364 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
165: hkn0521:1222177:1222177 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
165: hkn0521:1222177:1222177 [1] NCCL INFO P2P plugin IBext
164: hkn0521:1222169:1222169 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
164: hkn0521:1222169:1222169 [0] NCCL INFO P2P plugin IBext
189: hkn0528:1326044:1326044 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
167: hkn0521:1222197:1222197 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
167: hkn0521:1222197:1222197 [3] NCCL INFO P2P plugin IBext
341: hkn0704:816354:816354 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
341: hkn0704:816354:816354 [1] NCCL INFO Using network IBext
 86: hkn0426:838372:838372 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
472: hkn0805:1136489:1136489 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
472: hkn0805:1136489:1136489 [0] NCCL INFO Using network IBext
343: hkn0704:816334:816334 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
343: hkn0704:816334:816334 [3] NCCL INFO Using network IBext
149: hkn0514:2975087:2975087 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
474: hkn0805:1136461:1136461 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
474: hkn0805:1136461:1136461 [2] NCCL INFO Using network IBext
151: hkn0514:2975071:2975071 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
196: hkn0530:1282482:1282482 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
196: hkn0530:1282482:1282482 [0] NCCL INFO P2P plugin IBext
188: hkn0528:1326072:1326072 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
188: hkn0528:1326072:1326072 [0] NCCL INFO P2P plugin IBext
449: hkn0734:1180885:1180885 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
450: hkn0734:1180905:1180905 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
342: hkn0704:816326:816326 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
342: hkn0704:816326:816326 [2] NCCL INFO Using network IBext
451: hkn0734:1180877:1180877 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
190: hkn0528:1326060:1326060 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
190: hkn0528:1326060:1326060 [2] NCCL INFO P2P plugin IBext
400: hkn0720:33752:33752 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
400: hkn0720:33752:33752 [0] NCCL INFO P2P plugin IBext
197: hkn0530:1282466:1282466 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
197: hkn0530:1282466:1282466 [1] NCCL INFO P2P plugin IBext
401: hkn0720:33760:33760 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
401: hkn0720:33760:33760 [1] NCCL INFO P2P plugin IBext
198: hkn0530:1282474:1282474 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
199: hkn0530:1282494:1282494 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
 87: hkn0426:838380:838380 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 87: hkn0426:838380:838380 [3] NCCL INFO P2P plugin IBext
403: hkn0720:33744:33744 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
 84: hkn0426:838364:838364 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 84: hkn0426:838364:838364 [0] NCCL INFO P2P plugin IBext
148: hkn0514:2975079:2975079 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
189: hkn0528:1326044:1326044 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
189: hkn0528:1326044:1326044 [1] NCCL INFO P2P plugin IBext
402: hkn0720:33772:33772 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
164: hkn0521:1222169:1222169 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
165: hkn0521:1222177:1222177 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
167: hkn0521:1222197:1222197 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
164: hkn0521:1222169:1222169 [0] NCCL INFO Using network IBext
167: hkn0521:1222197:1222197 [3] NCCL INFO Using network IBext
165: hkn0521:1222177:1222177 [1] NCCL INFO Using network IBext
 85: hkn0426:838392:838392 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
 86: hkn0426:838372:838372 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 86: hkn0426:838372:838372 [2] NCCL INFO P2P plugin IBext
448: hkn0734:1180893:1180893 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
366: hkn0711:608384:608384 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
365: hkn0711:608392:608392 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
149: hkn0514:2975087:2975087 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
149: hkn0514:2975087:2975087 [1] NCCL INFO P2P plugin IBext
151: hkn0514:2975071:2975071 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
151: hkn0514:2975071:2975071 [3] NCCL INFO P2P plugin IBext
188: hkn0528:1326072:1326072 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
188: hkn0528:1326072:1326072 [0] NCCL INFO Using network IBext
190: hkn0528:1326060:1326060 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
190: hkn0528:1326060:1326060 [2] NCCL INFO Using network IBext
166: hkn0521:1222185:1222185 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
166: hkn0521:1222185:1222185 [2] NCCL INFO Using network IBext
364: hkn0711:608404:608404 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
197: hkn0530:1282466:1282466 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
197: hkn0530:1282466:1282466 [1] NCCL INFO Using network IBext
189: hkn0528:1326044:1326044 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
189: hkn0528:1326044:1326044 [1] NCCL INFO Using network IBext
198: hkn0530:1282474:1282474 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
198: hkn0530:1282474:1282474 [2] NCCL INFO P2P plugin IBext
199: hkn0530:1282494:1282494 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
199: hkn0530:1282494:1282494 [3] NCCL INFO P2P plugin IBext
450: hkn0734:1180905:1180905 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
450: hkn0734:1180905:1180905 [2] NCCL INFO P2P plugin IBext
191: hkn0528:1326052:1326052 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
191: hkn0528:1326052:1326052 [3] NCCL INFO Using network IBext
451: hkn0734:1180877:1180877 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
451: hkn0734:1180877:1180877 [3] NCCL INFO P2P plugin IBext
403: hkn0720:33744:33744 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
403: hkn0720:33744:33744 [3] NCCL INFO P2P plugin IBext
150: hkn0514:2975099:2975099 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
150: hkn0514:2975099:2975099 [2] NCCL INFO Using network IBext
148: hkn0514:2975079:2975079 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
148: hkn0514:2975079:2975079 [0] NCCL INFO P2P plugin IBext
 85: hkn0426:838392:838392 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 85: hkn0426:838392:838392 [1] NCCL INFO P2P plugin IBext
449: hkn0734:1180885:1180885 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
449: hkn0734:1180885:1180885 [1] NCCL INFO P2P plugin IBext
402: hkn0720:33772:33772 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
402: hkn0720:33772:33772 [2] NCCL INFO P2P plugin IBext
 86: hkn0426:838372:838372 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 86: hkn0426:838372:838372 [2] NCCL INFO Using network IBext
149: hkn0514:2975087:2975087 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
149: hkn0514:2975087:2975087 [1] NCCL INFO Using network IBext
367: hkn0711:608376:608376 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
151: hkn0514:2975071:2975071 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
151: hkn0514:2975071:2975071 [3] NCCL INFO Using network IBext
448: hkn0734:1180893:1180893 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
448: hkn0734:1180893:1180893 [0] NCCL INFO P2P plugin IBext
366: hkn0711:608384:608384 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
366: hkn0711:608384:608384 [2] NCCL INFO P2P plugin IBext
365: hkn0711:608392:608392 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
365: hkn0711:608392:608392 [1] NCCL INFO P2P plugin IBext
198: hkn0530:1282474:1282474 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
199: hkn0530:1282494:1282494 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
198: hkn0530:1282474:1282474 [2] NCCL INFO Using network IBext
199: hkn0530:1282494:1282494 [3] NCCL INFO Using network IBext
196: hkn0530:1282482:1282482 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
196: hkn0530:1282482:1282482 [0] NCCL INFO Using network IBext
148: hkn0514:2975079:2975079 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
148: hkn0514:2975079:2975079 [0] NCCL INFO Using network IBext
364: hkn0711:608404:608404 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
364: hkn0711:608404:608404 [0] NCCL INFO P2P plugin IBext
 85: hkn0426:838392:838392 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 85: hkn0426:838392:838392 [1] NCCL INFO Using network IBext
 84: hkn0426:838364:838364 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 84: hkn0426:838364:838364 [0] NCCL INFO Using network IBext
 87: hkn0426:838380:838380 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 87: hkn0426:838380:838380 [3] NCCL INFO Using network IBext
403: hkn0720:33744:33744 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
403: hkn0720:33744:33744 [3] NCCL INFO Using network IBext
401: hkn0720:33760:33760 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
401: hkn0720:33760:33760 [1] NCCL INFO Using network IBext
402: hkn0720:33772:33772 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
402: hkn0720:33772:33772 [2] NCCL INFO Using network IBext
400: hkn0720:33752:33752 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
400: hkn0720:33752:33752 [0] NCCL INFO Using network IBext
448: hkn0734:1180893:1180893 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
449: hkn0734:1180885:1180885 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
448: hkn0734:1180893:1180893 [0] NCCL INFO Using network IBext
449: hkn0734:1180885:1180885 [1] NCCL INFO Using network IBext
367: hkn0711:608376:608376 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
367: hkn0711:608376:608376 [3] NCCL INFO P2P plugin IBext
364: hkn0711:608404:608404 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
364: hkn0711:608404:608404 [0] NCCL INFO Using network IBext
238: hkn0606:2396571:2396571 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
367: hkn0711:608376:608376 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
451: hkn0734:1180877:1180877 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
367: hkn0711:608376:608376 [3] NCCL INFO Using network IBext
451: hkn0734:1180877:1180877 [3] NCCL INFO Using network IBext
450: hkn0734:1180905:1180905 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
450: hkn0734:1180905:1180905 [2] NCCL INFO Using network IBext
239: hkn0606:2396563:2396563 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
237: hkn0606:2396555:2396555 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
366: hkn0711:608384:608384 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
366: hkn0711:608384:608384 [2] NCCL INFO Using network IBext
365: hkn0711:608392:608392 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
365: hkn0711:608392:608392 [1] NCCL INFO Using network IBext
236: hkn0606:2396583:2396583 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
140: hkn0512:3068482:3068482 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
322: hkn0633:1550649:1550649 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
238: hkn0606:2396571:2396571 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
238: hkn0606:2396571:2396571 [2] NCCL INFO P2P plugin IBext
209: hkn0534:1172749:1172749 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
210: hkn0534:1172741:1172741 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
142: hkn0512:3068454:3068454 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
208: hkn0534:1172769:1172769 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
411: hkn0723:232580:232580 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 58: hkn0419:1568591:1568591 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
237: hkn0606:2396555:2396555 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
237: hkn0606:2396555:2396555 [1] NCCL INFO P2P plugin IBext
239: hkn0606:2396563:2396563 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
239: hkn0606:2396563:2396563 [3] NCCL INFO P2P plugin IBext
141: hkn0512:3068462:3068462 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
410: hkn0723:232552:232552 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 59: hkn0419:1568607:1568607 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
255: hkn0611:734150:734150 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
140: hkn0512:3068482:3068482 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
140: hkn0512:3068482:3068482 [0] NCCL INFO P2P plugin IBext
211: hkn0534:1172757:1172757 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
236: hkn0606:2396583:2396583 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
236: hkn0606:2396583:2396583 [0] NCCL INFO P2P plugin IBext
408: hkn0723:232560:232560 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
321: hkn0633:1550661:1550661 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
409: hkn0723:232568:232568 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 57: hkn0419:1568619:1568619 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
322: hkn0633:1550649:1550649 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
322: hkn0633:1550649:1550649 [2] NCCL INFO P2P plugin IBext
320: hkn0633:1550633:1550633 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
209: hkn0534:1172749:1172749 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
209: hkn0534:1172749:1172749 [1] NCCL INFO P2P plugin IBext
181: hkn0526:1452758:1452758 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
142: hkn0512:3068454:3068454 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
142: hkn0512:3068454:3068454 [2] NCCL INFO P2P plugin IBext
411: hkn0723:232580:232580 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
411: hkn0723:232580:232580 [3] NCCL INFO P2P plugin IBext
 58: hkn0419:1568591:1568591 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 58: hkn0419:1568591:1568591 [2] NCCL INFO P2P plugin IBext
210: hkn0534:1172741:1172741 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
210: hkn0534:1172741:1172741 [2] NCCL INFO P2P plugin IBext
208: hkn0534:1172769:1172769 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
208: hkn0534:1172769:1172769 [0] NCCL INFO P2P plugin IBext
236: hkn0606:2396583:2396583 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
237: hkn0606:2396555:2396555 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
239: hkn0606:2396563:2396563 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
236: hkn0606:2396583:2396583 [0] NCCL INFO Using network IBext
237: hkn0606:2396555:2396555 [1] NCCL INFO Using network IBext
239: hkn0606:2396563:2396563 [3] NCCL INFO Using network IBext
141: hkn0512:3068462:3068462 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
141: hkn0512:3068462:3068462 [1] NCCL INFO P2P plugin IBext
255: hkn0611:734150:734150 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
255: hkn0611:734150:734150 [3] NCCL INFO P2P plugin IBext
 59: hkn0419:1568607:1568607 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 59: hkn0419:1568607:1568607 [3] NCCL INFO P2P plugin IBext
323: hkn0633:1550641:1550641 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
143: hkn0512:3068470:3068470 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
410: hkn0723:232552:232552 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
410: hkn0723:232552:232552 [2] NCCL INFO P2P plugin IBext
 56: hkn0419:1568599:1568599 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
211: hkn0534:1172757:1172757 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
211: hkn0534:1172757:1172757 [3] NCCL INFO P2P plugin IBext
321: hkn0633:1550661:1550661 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
321: hkn0633:1550661:1550661 [1] NCCL INFO P2P plugin IBext
180: hkn0526:1452766:1452766 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
408: hkn0723:232560:232560 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
408: hkn0723:232560:232560 [0] NCCL INFO P2P plugin IBext
183: hkn0526:1452786:1452786 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
409: hkn0723:232568:232568 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
409: hkn0723:232568:232568 [1] NCCL INFO P2P plugin IBext
 57: hkn0419:1568619:1568619 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 57: hkn0419:1568619:1568619 [1] NCCL INFO P2P plugin IBext
254: hkn0611:734166:734166 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
253: hkn0611:734158:734158 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
320: hkn0633:1550633:1550633 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
320: hkn0633:1550633:1550633 [0] NCCL INFO P2P plugin IBext
252: hkn0611:734178:734178 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
238: hkn0606:2396571:2396571 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
238: hkn0606:2396571:2396571 [2] NCCL INFO Using network IBext
182: hkn0526:1452774:1452774 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
181: hkn0526:1452758:1452758 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
181: hkn0526:1452758:1452758 [1] NCCL INFO P2P plugin IBext
141: hkn0512:3068462:3068462 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
141: hkn0512:3068462:3068462 [1] NCCL INFO Using network IBext
142: hkn0512:3068454:3068454 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
142: hkn0512:3068454:3068454 [2] NCCL INFO Using network IBext
324: hkn0634:1545221:1545221 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
208: hkn0534:1172769:1172769 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
208: hkn0534:1172769:1172769 [0] NCCL INFO Using network IBext
327: hkn0634:1545249:1545249 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
211: hkn0534:1172757:1172757 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
211: hkn0534:1172757:1172757 [3] NCCL INFO Using network IBext
 57: hkn0419:1568619:1568619 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 59: hkn0419:1568607:1568607 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 57: hkn0419:1568619:1568619 [1] NCCL INFO Using network IBext
 59: hkn0419:1568607:1568607 [3] NCCL INFO Using network IBext
140: hkn0512:3068482:3068482 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
140: hkn0512:3068482:3068482 [0] NCCL INFO Using network IBext
210: hkn0534:1172741:1172741 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
210: hkn0534:1172741:1172741 [2] NCCL INFO Using network IBext
323: hkn0633:1550641:1550641 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
323: hkn0633:1550641:1550641 [3] NCCL INFO P2P plugin IBext
408: hkn0723:232560:232560 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
321: hkn0633:1550661:1550661 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
410: hkn0723:232552:232552 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
321: hkn0633:1550661:1550661 [1] NCCL INFO Using network IBext
408: hkn0723:232560:232560 [0] NCCL INFO Using network IBext
410: hkn0723:232552:232552 [2] NCCL INFO Using network IBext
409: hkn0723:232568:232568 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
409: hkn0723:232568:232568 [1] NCCL INFO Using network IBext
143: hkn0512:3068470:3068470 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
143: hkn0512:3068470:3068470 [3] NCCL INFO P2P plugin IBext
 56: hkn0419:1568599:1568599 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 56: hkn0419:1568599:1568599 [0] NCCL INFO P2P plugin IBext
180: hkn0526:1452766:1452766 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
180: hkn0526:1452766:1452766 [0] NCCL INFO P2P plugin IBext
320: hkn0633:1550633:1550633 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
320: hkn0633:1550633:1550633 [0] NCCL INFO Using network IBext
183: hkn0526:1452786:1452786 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
183: hkn0526:1452786:1452786 [3] NCCL INFO P2P plugin IBext
336: hkn0703:765538:765538 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
322: hkn0633:1550649:1550649 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
338: hkn0703:765558:765558 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
322: hkn0633:1550649:1550649 [2] NCCL INFO Using network IBext
254: hkn0611:734166:734166 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
254: hkn0611:734166:734166 [2] NCCL INFO P2P plugin IBext
253: hkn0611:734158:734158 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
253: hkn0611:734158:734158 [1] NCCL INFO P2P plugin IBext
404: hkn0721:2323901:2323901 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
406: hkn0721:2323879:2323879 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
252: hkn0611:734178:734178 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
252: hkn0611:734178:734178 [0] NCCL INFO P2P plugin IBext
209: hkn0534:1172749:1172749 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
209: hkn0534:1172749:1172749 [1] NCCL INFO Using network IBext
337: hkn0703:765546:765546 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
339: hkn0703:765530:765530 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
326: hkn0634:1545229:1545229 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
437: hkn0731:1411116:1411116 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
323: hkn0633:1550641:1550641 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
323: hkn0633:1550641:1550641 [3] NCCL INFO Using network IBext
182: hkn0526:1452774:1452774 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
182: hkn0526:1452774:1452774 [2] NCCL INFO P2P plugin IBext
324: hkn0634:1545221:1545221 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
324: hkn0634:1545221:1545221 [0] NCCL INFO P2P plugin IBext
436: hkn0731:1411088:1411088 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
143: hkn0512:3068470:3068470 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
143: hkn0512:3068470:3068470 [3] NCCL INFO Using network IBext
327: hkn0634:1545249:1545249 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
327: hkn0634:1545249:1545249 [3] NCCL INFO P2P plugin IBext
 58: hkn0419:1568591:1568591 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 58: hkn0419:1568591:1568591 [2] NCCL INFO Using network IBext
 56: hkn0419:1568599:1568599 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 56: hkn0419:1568599:1568599 [0] NCCL INFO Using network IBext
411: hkn0723:232580:232580 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
411: hkn0723:232580:232580 [3] NCCL INFO Using network IBext
438: hkn0731:1411096:1411096 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
405: hkn0721:2323871:2323871 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
325: hkn0634:1545237:1545237 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
439: hkn0731:1411104:1411104 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
407: hkn0721:2323889:2323889 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
180: hkn0526:1452766:1452766 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
183: hkn0526:1452786:1452786 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
180: hkn0526:1452766:1452766 [0] NCCL INFO Using network IBext
183: hkn0526:1452786:1452786 [3] NCCL INFO Using network IBext
336: hkn0703:765538:765538 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
336: hkn0703:765538:765538 [0] NCCL INFO P2P plugin IBext
464: hkn0803:901006:901006 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
254: hkn0611:734166:734166 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
254: hkn0611:734166:734166 [2] NCCL INFO Using network IBext
404: hkn0721:2323901:2323901 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
404: hkn0721:2323901:2323901 [0] NCCL INFO P2P plugin IBext
253: hkn0611:734158:734158 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
255: hkn0611:734150:734150 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
253: hkn0611:734158:734158 [1] NCCL INFO Using network IBext
255: hkn0611:734150:734150 [3] NCCL INFO Using network IBext
252: hkn0611:734178:734178 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
252: hkn0611:734178:734178 [0] NCCL INFO Using network IBext
182: hkn0526:1452774:1452774 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
182: hkn0526:1452774:1452774 [2] NCCL INFO Using network IBext
 38: hkn0413:2391078:2391078 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
338: hkn0703:765558:765558 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
338: hkn0703:765558:765558 [2] NCCL INFO P2P plugin IBext
337: hkn0703:765546:765546 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
337: hkn0703:765546:765546 [1] NCCL INFO P2P plugin IBext
 39: hkn0413:2391070:2391070 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
339: hkn0703:765530:765530 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
339: hkn0703:765530:765530 [3] NCCL INFO P2P plugin IBext
326: hkn0634:1545229:1545229 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
326: hkn0634:1545229:1545229 [2] NCCL INFO P2P plugin IBext
437: hkn0731:1411116:1411116 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
437: hkn0731:1411116:1411116 [1] NCCL INFO P2P plugin IBext
181: hkn0526:1452758:1452758 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
181: hkn0526:1452758:1452758 [1] NCCL INFO Using network IBext
406: hkn0721:2323879:2323879 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
406: hkn0721:2323879:2323879 [2] NCCL INFO P2P plugin IBext
436: hkn0731:1411088:1411088 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
436: hkn0731:1411088:1411088 [0] NCCL INFO P2P plugin IBext
 37: hkn0413:2391086:2391086 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
405: hkn0721:2323871:2323871 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
405: hkn0721:2323871:2323871 [1] NCCL INFO P2P plugin IBext
438: hkn0731:1411096:1411096 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
438: hkn0731:1411096:1411096 [2] NCCL INFO P2P plugin IBext
439: hkn0731:1411104:1411104 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
439: hkn0731:1411104:1411104 [3] NCCL INFO P2P plugin IBext
325: hkn0634:1545237:1545237 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
325: hkn0634:1545237:1545237 [1] NCCL INFO P2P plugin IBext
407: hkn0721:2323889:2323889 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
407: hkn0721:2323889:2323889 [3] NCCL INFO P2P plugin IBext
 36: hkn0413:2391098:2391098 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
464: hkn0803:901006:901006 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
464: hkn0803:901006:901006 [0] NCCL INFO P2P plugin IBext
466: hkn0803:900986:900986 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
 38: hkn0413:2391078:2391078 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 38: hkn0413:2391078:2391078 [2] NCCL INFO P2P plugin IBext
339: hkn0703:765530:765530 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
337: hkn0703:765546:765546 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
338: hkn0703:765558:765558 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
339: hkn0703:765530:765530 [3] NCCL INFO Using network IBext
337: hkn0703:765546:765546 [1] NCCL INFO Using network IBext
338: hkn0703:765558:765558 [2] NCCL INFO Using network IBext
 39: hkn0413:2391070:2391070 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 39: hkn0413:2391070:2391070 [3] NCCL INFO P2P plugin IBext
326: hkn0634:1545229:1545229 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
465: hkn0803:900978:900978 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
326: hkn0634:1545229:1545229 [2] NCCL INFO Using network IBext
467: hkn0803:900994:900994 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
325: hkn0634:1545237:1545237 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
325: hkn0634:1545237:1545237 [1] NCCL INFO Using network IBext
405: hkn0721:2323871:2323871 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
405: hkn0721:2323871:2323871 [1] NCCL INFO Using network IBext
406: hkn0721:2323879:2323879 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
406: hkn0721:2323879:2323879 [2] NCCL INFO Using network IBext
407: hkn0721:2323889:2323889 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
407: hkn0721:2323889:2323889 [3] NCCL INFO Using network IBext
324: hkn0634:1545221:1545221 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
324: hkn0634:1545221:1545221 [0] NCCL INFO Using network IBext
327: hkn0634:1545249:1545249 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
327: hkn0634:1545249:1545249 [3] NCCL INFO Using network IBext
 47: hkn0415:2520751:2520751 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
 37: hkn0413:2391086:2391086 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 37: hkn0413:2391086:2391086 [1] NCCL INFO P2P plugin IBext
439: hkn0731:1411104:1411104 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
439: hkn0731:1411104:1411104 [3] NCCL INFO Using network IBext
438: hkn0731:1411096:1411096 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
438: hkn0731:1411096:1411096 [2] NCCL INFO Using network IBext
 46: hkn0415:2520763:2520763 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
 36: hkn0413:2391098:2391098 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 36: hkn0413:2391098:2391098 [0] NCCL INFO P2P plugin IBext
 45: hkn0415:2520743:2520743 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
466: hkn0803:900986:900986 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
466: hkn0803:900986:900986 [2] NCCL INFO P2P plugin IBext
404: hkn0721:2323901:2323901 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
404: hkn0721:2323901:2323901 [0] NCCL INFO Using network IBext
336: hkn0703:765538:765538 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
336: hkn0703:765538:765538 [0] NCCL INFO Using network IBext
 44: hkn0415:2520735:2520735 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
465: hkn0803:900978:900978 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
465: hkn0803:900978:900978 [1] NCCL INFO P2P plugin IBext
290: hkn0624:1797282:1797282 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
467: hkn0803:900994:900994 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
467: hkn0803:900994:900994 [3] NCCL INFO P2P plugin IBext
 47: hkn0415:2520751:2520751 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 47: hkn0415:2520751:2520751 [3] NCCL INFO P2P plugin IBext
 36: hkn0413:2391098:2391098 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 37: hkn0413:2391086:2391086 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 37: hkn0413:2391086:2391086 [1] NCCL INFO Using network IBext
 36: hkn0413:2391098:2391098 [0] NCCL INFO Using network IBext
436: hkn0731:1411088:1411088 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
436: hkn0731:1411088:1411088 [0] NCCL INFO Using network IBext
437: hkn0731:1411116:1411116 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
437: hkn0731:1411116:1411116 [1] NCCL INFO Using network IBext
289: hkn0624:1797266:1797266 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
 46: hkn0415:2520763:2520763 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 46: hkn0415:2520763:2520763 [2] NCCL INFO P2P plugin IBext
 45: hkn0415:2520743:2520743 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 45: hkn0415:2520743:2520743 [1] NCCL INFO P2P plugin IBext
245: hkn0608:510084:510084 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
466: hkn0803:900986:900986 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
466: hkn0803:900986:900986 [2] NCCL INFO Using network IBext
 19: hkn0408:2915270:2915270 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
464: hkn0803:901006:901006 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
464: hkn0803:901006:901006 [0] NCCL INFO Using network IBext
465: hkn0803:900978:900978 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
465: hkn0803:900978:900978 [1] NCCL INFO Using network IBext
467: hkn0803:900994:900994 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
467: hkn0803:900994:900994 [3] NCCL INFO Using network IBext
391: hkn0717:19437:19437 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
 38: hkn0413:2391078:2391078 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 38: hkn0413:2391078:2391078 [2] NCCL INFO Using network IBext
490: hkn0809:961680:961680 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
 39: hkn0413:2391070:2391070 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 39: hkn0413:2391070:2391070 [3] NCCL INFO Using network IBext
244: hkn0608:510064:510064 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
 44: hkn0415:2520735:2520735 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 44: hkn0415:2520735:2520735 [0] NCCL INFO P2P plugin IBext
 18: hkn0408:2915278:2915278 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
290: hkn0624:1797282:1797282 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
290: hkn0624:1797282:1797282 [2] NCCL INFO P2P plugin IBext
491: hkn0809:961660:961660 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
289: hkn0624:1797266:1797266 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
289: hkn0624:1797266:1797266 [1] NCCL INFO P2P plugin IBext
 45: hkn0415:2520743:2520743 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 16: hkn0408:2915290:2915290 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
 45: hkn0415:2520743:2520743 [1] NCCL INFO Using network IBext
 46: hkn0415:2520763:2520763 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 46: hkn0415:2520763:2520763 [2] NCCL INFO Using network IBext
488: hkn0809:961652:961652 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
 17: hkn0408:2915262:2915262 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
246: hkn0608:510072:510072 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
245: hkn0608:510084:510084 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
245: hkn0608:510084:510084 [1] NCCL INFO P2P plugin IBext
 19: hkn0408:2915270:2915270 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 19: hkn0408:2915270:2915270 [3] NCCL INFO P2P plugin IBext
 44: hkn0415:2520735:2520735 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 44: hkn0415:2520735:2520735 [0] NCCL INFO Using network IBext
389: hkn0717:19453:19453 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
489: hkn0809:961668:961668 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
391: hkn0717:19437:19437 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
391: hkn0717:19437:19437 [3] NCCL INFO P2P plugin IBext
247: hkn0608:510056:510056 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
 68: hkn0422:4177469:4177469 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
490: hkn0809:961680:961680 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
490: hkn0809:961680:961680 [2] NCCL INFO P2P plugin IBext
388: hkn0717:19465:19465 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
244: hkn0608:510064:510064 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
244: hkn0608:510064:510064 [0] NCCL INFO P2P plugin IBext
 70: hkn0422:4177477:4177477 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 47: hkn0415:2520751:2520751 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 18: hkn0408:2915278:2915278 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 18: hkn0408:2915278:2915278 [2] NCCL INFO P2P plugin IBext
 47: hkn0415:2520751:2520751 [3] NCCL INFO Using network IBext
390: hkn0717:19445:19445 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
289: hkn0624:1797266:1797266 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
289: hkn0624:1797266:1797266 [1] NCCL INFO Using network IBext
491: hkn0809:961660:961660 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
491: hkn0809:961660:961660 [3] NCCL INFO P2P plugin IBext
 71: hkn0422:4177497:4177497 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 16: hkn0408:2915290:2915290 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 16: hkn0408:2915290:2915290 [0] NCCL INFO P2P plugin IBext
488: hkn0809:961652:961652 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
488: hkn0809:961652:961652 [0] NCCL INFO P2P plugin IBext
 79: hkn0424:2972333:2972333 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
 17: hkn0408:2915262:2915262 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 17: hkn0408:2915262:2915262 [1] NCCL INFO P2P plugin IBext
 69: hkn0422:4177485:4177485 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
246: hkn0608:510072:510072 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
246: hkn0608:510072:510072 [2] NCCL INFO P2P plugin IBext
 76: hkn0424:2972313:2972313 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
389: hkn0717:19453:19453 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
389: hkn0717:19453:19453 [1] NCCL INFO P2P plugin IBext
489: hkn0809:961668:961668 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
489: hkn0809:961668:961668 [1] NCCL INFO P2P plugin IBext
 78: hkn0424:2972321:2972321 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
244: hkn0608:510064:510064 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
244: hkn0608:510064:510064 [0] NCCL INFO Using network IBext
247: hkn0608:510056:510056 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
247: hkn0608:510056:510056 [3] NCCL INFO P2P plugin IBext
388: hkn0717:19465:19465 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
388: hkn0717:19465:19465 [0] NCCL INFO P2P plugin IBext
 68: hkn0422:4177469:4177469 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 68: hkn0422:4177469:4177469 [0] NCCL INFO P2P plugin IBext
 70: hkn0422:4177477:4177477 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 70: hkn0422:4177477:4177477 [2] NCCL INFO P2P plugin IBext
372: hkn0713:494598:494598 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
 18: hkn0408:2915278:2915278 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 18: hkn0408:2915278:2915278 [2] NCCL INFO Using network IBext
375: hkn0713:494582:494582 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
 16: hkn0408:2915290:2915290 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 77: hkn0424:2972305:2972305 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
 16: hkn0408:2915290:2915290 [0] NCCL INFO Using network IBext
491: hkn0809:961660:961660 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
373: hkn0713:494610:494610 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
488: hkn0809:961652:961652 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
491: hkn0809:961660:961660 [3] NCCL INFO Using network IBext
390: hkn0717:19445:19445 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
390: hkn0717:19445:19445 [2] NCCL INFO P2P plugin IBext
488: hkn0809:961652:961652 [0] NCCL INFO Using network IBext
290: hkn0624:1797282:1797282 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
290: hkn0624:1797282:1797282 [2] NCCL INFO Using network IBext
 17: hkn0408:2915262:2915262 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 17: hkn0408:2915262:2915262 [1] NCCL INFO Using network IBext
246: hkn0608:510072:510072 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
246: hkn0608:510072:510072 [2] NCCL INFO Using network IBext
 71: hkn0422:4177497:4177497 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 71: hkn0422:4177497:4177497 [3] NCCL INFO P2P plugin IBext
 79: hkn0424:2972333:2972333 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 79: hkn0424:2972333:2972333 [3] NCCL INFO P2P plugin IBext
489: hkn0809:961668:961668 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
 69: hkn0422:4177485:4177485 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 69: hkn0422:4177485:4177485 [1] NCCL INFO P2P plugin IBext
489: hkn0809:961668:961668 [1] NCCL INFO Using network IBext
245: hkn0608:510084:510084 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
245: hkn0608:510084:510084 [1] NCCL INFO Using network IBext
 76: hkn0424:2972313:2972313 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 76: hkn0424:2972313:2972313 [0] NCCL INFO P2P plugin IBext
487: hkn0808:995030:995030 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
389: hkn0717:19453:19453 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
389: hkn0717:19453:19453 [1] NCCL INFO Using network IBext
388: hkn0717:19465:19465 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
388: hkn0717:19465:19465 [0] NCCL INFO Using network IBext
247: hkn0608:510056:510056 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
 19: hkn0408:2915270:2915270 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
247: hkn0608:510056:510056 [3] NCCL INFO Using network IBext
 19: hkn0408:2915270:2915270 [3] NCCL INFO Using network IBext
390: hkn0717:19445:19445 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
390: hkn0717:19445:19445 [2] NCCL INFO Using network IBext
 78: hkn0424:2972321:2972321 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 78: hkn0424:2972321:2972321 [2] NCCL INFO P2P plugin IBext
374: hkn0713:494590:494590 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
391: hkn0717:19437:19437 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
391: hkn0717:19437:19437 [3] NCCL INFO Using network IBext
490: hkn0809:961680:961680 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
490: hkn0809:961680:961680 [2] NCCL INFO Using network IBext
372: hkn0713:494598:494598 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
372: hkn0713:494598:494598 [0] NCCL INFO P2P plugin IBext
375: hkn0713:494582:494582 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
375: hkn0713:494582:494582 [3] NCCL INFO P2P plugin IBext
 77: hkn0424:2972305:2972305 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 77: hkn0424:2972305:2972305 [1] NCCL INFO P2P plugin IBext
373: hkn0713:494610:494610 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
373: hkn0713:494610:494610 [1] NCCL INFO P2P plugin IBext
 71: hkn0422:4177497:4177497 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 71: hkn0422:4177497:4177497 [3] NCCL INFO Using network IBext
 69: hkn0422:4177485:4177485 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 69: hkn0422:4177485:4177485 [1] NCCL INFO Using network IBext
291: hkn0624:1797274:1797274 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
 76: hkn0424:2972313:2972313 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 78: hkn0424:2972321:2972321 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
486: hkn0808:995058:995058 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
 76: hkn0424:2972313:2972313 [0] NCCL INFO Using network IBext
 78: hkn0424:2972321:2972321 [2] NCCL INFO Using network IBext
485: hkn0808:995038:995038 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
 61: hkn0420:3234595:3234595 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
487: hkn0808:995030:995030 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
487: hkn0808:995030:995030 [3] NCCL INFO P2P plugin IBext
 77: hkn0424:2972305:2972305 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 77: hkn0424:2972305:2972305 [1] NCCL INFO Using network IBext
484: hkn0808:995046:995046 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
374: hkn0713:494590:494590 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
374: hkn0713:494590:494590 [2] NCCL INFO P2P plugin IBext
 62: hkn0420:3234575:3234575 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
 68: hkn0422:4177469:4177469 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 68: hkn0422:4177469:4177469 [0] NCCL INFO Using network IBext
 70: hkn0422:4177477:4177477 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 70: hkn0422:4177477:4177477 [2] NCCL INFO Using network IBext
 63: hkn0420:3234583:3234583 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
373: hkn0713:494610:494610 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
373: hkn0713:494610:494610 [1] NCCL INFO Using network IBext
 60: hkn0420:3234567:3234567 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
 79: hkn0424:2972333:2972333 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 79: hkn0424:2972333:2972333 [3] NCCL INFO Using network IBext
234: hkn0605:736544:736544 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
374: hkn0713:494590:494590 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
374: hkn0713:494590:494590 [2] NCCL INFO Using network IBext
 61: hkn0420:3234595:3234595 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 61: hkn0420:3234595:3234595 [1] NCCL INFO P2P plugin IBext
486: hkn0808:995058:995058 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
486: hkn0808:995058:995058 [2] NCCL INFO P2P plugin IBext
485: hkn0808:995038:995038 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
485: hkn0808:995038:995038 [1] NCCL INFO P2P plugin IBext
291: hkn0624:1797274:1797274 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
291: hkn0624:1797274:1797274 [3] NCCL INFO P2P plugin IBext
484: hkn0808:995046:995046 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
484: hkn0808:995046:995046 [0] NCCL INFO P2P plugin IBext
288: hkn0624:1797296:1797296 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
375: hkn0713:494582:494582 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
375: hkn0713:494582:494582 [3] NCCL INFO Using network IBext
 62: hkn0420:3234575:3234575 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 62: hkn0420:3234575:3234575 [2] NCCL INFO P2P plugin IBext
372: hkn0713:494598:494598 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
372: hkn0713:494598:494598 [0] NCCL INFO Using network IBext
 32: hkn0412:2286739:2286739 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 63: hkn0420:3234583:3234583 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 63: hkn0420:3234583:3234583 [3] NCCL INFO P2P plugin IBext
 73: hkn0423:1729402:1729402 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 34: hkn0412:2286727:2286727 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 33: hkn0412:2286731:2286731 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 60: hkn0420:3234567:3234567 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 60: hkn0420:3234567:3234567 [0] NCCL INFO P2P plugin IBext
 72: hkn0423:1729386:1729386 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
234: hkn0605:736544:736544 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
234: hkn0605:736544:736544 [2] NCCL INFO P2P plugin IBext
232: hkn0605:736552:736552 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
486: hkn0808:995058:995058 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
484: hkn0808:995046:995046 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
486: hkn0808:995058:995058 [2] NCCL INFO Using network IBext
484: hkn0808:995046:995046 [0] NCCL INFO Using network IBext
485: hkn0808:995038:995038 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
485: hkn0808:995038:995038 [1] NCCL INFO Using network IBext
 35: hkn0412:2286751:2286751 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
291: hkn0624:1797274:1797274 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
291: hkn0624:1797274:1797274 [3] NCCL INFO Using network IBext
487: hkn0808:995030:995030 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
487: hkn0808:995030:995030 [3] NCCL INFO Using network IBext
235: hkn0605:736572:736572 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
233: hkn0605:736560:736560 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
 63: hkn0420:3234583:3234583 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 63: hkn0420:3234583:3234583 [3] NCCL INFO Using network IBext
 62: hkn0420:3234575:3234575 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 62: hkn0420:3234575:3234575 [2] NCCL INFO Using network IBext
 60: hkn0420:3234567:3234567 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 60: hkn0420:3234567:3234567 [0] NCCL INFO Using network IBext
288: hkn0624:1797296:1797296 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
288: hkn0624:1797296:1797296 [0] NCCL INFO P2P plugin IBext
 32: hkn0412:2286739:2286739 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 32: hkn0412:2286739:2286739 [0] NCCL INFO P2P plugin IBext
 73: hkn0423:1729402:1729402 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 73: hkn0423:1729402:1729402 [1] NCCL INFO P2P plugin IBext
 34: hkn0412:2286727:2286727 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 34: hkn0412:2286727:2286727 [2] NCCL INFO P2P plugin IBext
 74: hkn0423:1729414:1729414 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 33: hkn0412:2286731:2286731 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 33: hkn0412:2286731:2286731 [1] NCCL INFO P2P plugin IBext
 72: hkn0423:1729386:1729386 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 72: hkn0423:1729386:1729386 [0] NCCL INFO P2P plugin IBext
232: hkn0605:736552:736552 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
232: hkn0605:736552:736552 [0] NCCL INFO P2P plugin IBext
508: hkn0816:399946:399946 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
 75: hkn0423:1729394:1729394 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 61: hkn0420:3234595:3234595 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 61: hkn0420:3234595:3234595 [1] NCCL INFO Using network IBext
 35: hkn0412:2286751:2286751 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 35: hkn0412:2286751:2286751 [3] NCCL INFO P2P plugin IBext
241: hkn0607:928753:928753 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
235: hkn0605:736572:736572 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
235: hkn0605:736572:736572 [3] NCCL INFO P2P plugin IBext
423: hkn0726:1572482:1572482 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
233: hkn0605:736560:736560 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
233: hkn0605:736560:736560 [1] NCCL INFO P2P plugin IBext
463: hkn0802:1224700:1224700 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
243: hkn0607:928733:928733 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
314: hkn0631:1046179:1046179 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
242: hkn0607:928725:928725 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
231: hkn0604:713531:713531 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
288: hkn0624:1797296:1797296 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
288: hkn0624:1797296:1797296 [0] NCCL INFO Using network IBext
230: hkn0604:713539:713539 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
312: hkn0631:1046191:1046191 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
 72: hkn0423:1729386:1729386 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 72: hkn0423:1729386:1729386 [0] NCCL INFO Using network IBext
 33: hkn0412:2286731:2286731 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 33: hkn0412:2286731:2286731 [1] NCCL INFO Using network IBext
 74: hkn0423:1729414:1729414 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 74: hkn0423:1729414:1729414 [2] NCCL INFO P2P plugin IBext
240: hkn0607:928741:928741 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
509: hkn0816:399926:399926 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
232: hkn0605:736552:736552 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
232: hkn0605:736552:736552 [0] NCCL INFO Using network IBext
461: hkn0802:1224708:1224708 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
 35: hkn0412:2286751:2286751 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 35: hkn0412:2286751:2286751 [3] NCCL INFO Using network IBext
313: hkn0631:1046163:1046163 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
508: hkn0816:399946:399946 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
508: hkn0816:399946:399946 [0] NCCL INFO P2P plugin IBext
234: hkn0605:736544:736544 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
234: hkn0605:736544:736544 [2] NCCL INFO Using network IBext
235: hkn0605:736572:736572 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
235: hkn0605:736572:736572 [3] NCCL INFO Using network IBext
510: hkn0816:399918:399918 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
 75: hkn0423:1729394:1729394 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 75: hkn0423:1729394:1729394 [3] NCCL INFO P2P plugin IBext
233: hkn0605:736560:736560 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
233: hkn0605:736560:736560 [1] NCCL INFO Using network IBext
421: hkn0726:1572490:1572490 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
119: hkn0506:862430:862430 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
511: hkn0816:399934:399934 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
228: hkn0604:713559:713559 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
423: hkn0726:1572482:1572482 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
423: hkn0726:1572482:1572482 [3] NCCL INFO P2P plugin IBext
315: hkn0631:1046171:1046171 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
420: hkn0726:1572502:1572502 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
241: hkn0607:928753:928753 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
241: hkn0607:928753:928753 [1] NCCL INFO P2P plugin IBext
463: hkn0802:1224700:1224700 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
463: hkn0802:1224700:1224700 [3] NCCL INFO P2P plugin IBext
229: hkn0604:713547:713547 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
314: hkn0631:1046179:1046179 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
314: hkn0631:1046179:1046179 [2] NCCL INFO P2P plugin IBext
 10: hkn0405:3231519:3231519 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
422: hkn0726:1572474:1572474 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
243: hkn0607:928733:928733 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
243: hkn0607:928733:928733 [3] NCCL INFO P2P plugin IBext
 74: hkn0423:1729414:1729414 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 74: hkn0423:1729414:1729414 [2] NCCL INFO Using network IBext
462: hkn0802:1224692:1224692 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
242: hkn0607:928725:928725 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
242: hkn0607:928725:928725 [2] NCCL INFO P2P plugin IBext
231: hkn0604:713531:713531 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
231: hkn0604:713531:713531 [3] NCCL INFO P2P plugin IBext
460: hkn0802:1224720:1224720 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
 32: hkn0412:2286739:2286739 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 32: hkn0412:2286739:2286739 [0] NCCL INFO Using network IBext
230: hkn0604:713539:713539 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
230: hkn0604:713539:713539 [2] NCCL INFO P2P plugin IBext
 34: hkn0412:2286727:2286727 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 34: hkn0412:2286727:2286727 [2] NCCL INFO Using network IBext
 73: hkn0423:1729402:1729402 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 73: hkn0423:1729402:1729402 [1] NCCL INFO Using network IBext
 75: hkn0423:1729394:1729394 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 75: hkn0423:1729394:1729394 [3] NCCL INFO Using network IBext
312: hkn0631:1046191:1046191 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
312: hkn0631:1046191:1046191 [0] NCCL INFO P2P plugin IBext
240: hkn0607:928741:928741 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
240: hkn0607:928741:928741 [0] NCCL INFO P2P plugin IBext
509: hkn0816:399926:399926 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
509: hkn0816:399926:399926 [1] NCCL INFO P2P plugin IBext
461: hkn0802:1224708:1224708 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
461: hkn0802:1224708:1224708 [1] NCCL INFO P2P plugin IBext
313: hkn0631:1046163:1046163 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
313: hkn0631:1046163:1046163 [1] NCCL INFO P2P plugin IBext
119: hkn0506:862430:862430 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
119: hkn0506:862430:862430 [3] NCCL INFO P2P plugin IBext
228: hkn0604:713559:713559 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
228: hkn0604:713559:713559 [0] NCCL INFO P2P plugin IBext
510: hkn0816:399918:399918 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
510: hkn0816:399918:399918 [2] NCCL INFO P2P plugin IBext
315: hkn0631:1046171:1046171 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
315: hkn0631:1046171:1046171 [3] NCCL INFO P2P plugin IBext
421: hkn0726:1572490:1572490 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
421: hkn0726:1572490:1572490 [1] NCCL INFO P2P plugin IBext
  9: hkn0405:3231499:3231499 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
420: hkn0726:1572502:1572502 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
420: hkn0726:1572502:1572502 [0] NCCL INFO P2P plugin IBext
229: hkn0604:713547:713547 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
229: hkn0604:713547:713547 [1] NCCL INFO P2P plugin IBext
511: hkn0816:399934:399934 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
511: hkn0816:399934:399934 [3] NCCL INFO P2P plugin IBext
242: hkn0607:928725:928725 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
242: hkn0607:928725:928725 [2] NCCL INFO Using network IBext
 10: hkn0405:3231519:3231519 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 10: hkn0405:3231519:3231519 [2] NCCL INFO P2P plugin IBext
243: hkn0607:928733:928733 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
243: hkn0607:928733:928733 [3] NCCL INFO Using network IBext
422: hkn0726:1572474:1572474 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
422: hkn0726:1572474:1572474 [2] NCCL INFO P2P plugin IBext
240: hkn0607:928741:928741 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
240: hkn0607:928741:928741 [0] NCCL INFO Using network IBext
478: hkn0806:1078688:1078688 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
460: hkn0802:1224720:1224720 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
460: hkn0802:1224720:1224720 [0] NCCL INFO P2P plugin IBext
462: hkn0802:1224692:1224692 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
462: hkn0802:1224692:1224692 [2] NCCL INFO P2P plugin IBext
312: hkn0631:1046191:1046191 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
313: hkn0631:1046163:1046163 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
312: hkn0631:1046191:1046191 [0] NCCL INFO Using network IBext
313: hkn0631:1046163:1046163 [1] NCCL INFO Using network IBext
509: hkn0816:399926:399926 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
461: hkn0802:1224708:1224708 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
509: hkn0816:399926:399926 [1] NCCL INFO Using network IBext
461: hkn0802:1224708:1224708 [1] NCCL INFO Using network IBext
510: hkn0816:399918:399918 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
510: hkn0816:399918:399918 [2] NCCL INFO Using network IBext
315: hkn0631:1046171:1046171 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
315: hkn0631:1046171:1046171 [3] NCCL INFO Using network IBext
508: hkn0816:399946:399946 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
508: hkn0816:399946:399946 [0] NCCL INFO Using network IBext
 11: hkn0405:3231507:3231507 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
511: hkn0816:399934:399934 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
511: hkn0816:399934:399934 [3] NCCL INFO Using network IBext
476: hkn0806:1078676:1078676 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
228: hkn0604:713559:713559 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
229: hkn0604:713547:713547 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
228: hkn0604:713559:713559 [0] NCCL INFO Using network IBext
229: hkn0604:713547:713547 [1] NCCL INFO Using network IBext
  9: hkn0405:3231499:3231499 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  9: hkn0405:3231499:3231499 [1] NCCL INFO P2P plugin IBext
422: hkn0726:1572474:1572474 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
422: hkn0726:1572474:1572474 [2] NCCL INFO Using network IBext
420: hkn0726:1572502:1572502 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
421: hkn0726:1572490:1572490 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
420: hkn0726:1572502:1572502 [0] NCCL INFO Using network IBext
421: hkn0726:1572490:1572490 [1] NCCL INFO Using network IBext
423: hkn0726:1572482:1572482 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
423: hkn0726:1572482:1572482 [3] NCCL INFO Using network IBext
241: hkn0607:928753:928753 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
241: hkn0607:928753:928753 [1] NCCL INFO Using network IBext
460: hkn0802:1224720:1224720 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
460: hkn0802:1224720:1224720 [0] NCCL INFO Using network IBext
479: hkn0806:1078660:1078660 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
462: hkn0802:1224692:1224692 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
462: hkn0802:1224692:1224692 [2] NCCL INFO Using network IBext
463: hkn0802:1224700:1224700 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
463: hkn0802:1224700:1224700 [3] NCCL INFO Using network IBext
477: hkn0806:1078668:1078668 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
  8: hkn0405:3231491:3231491 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
314: hkn0631:1046179:1046179 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
314: hkn0631:1046179:1046179 [2] NCCL INFO Using network IBext
478: hkn0806:1078688:1078688 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
478: hkn0806:1078688:1078688 [2] NCCL INFO P2P plugin IBext
231: hkn0604:713531:713531 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
231: hkn0604:713531:713531 [3] NCCL INFO Using network IBext
116: hkn0506:862438:862438 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
230: hkn0604:713539:713539 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
230: hkn0604:713539:713539 [2] NCCL INFO Using network IBext
118: hkn0506:862450:862450 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 11: hkn0405:3231507:3231507 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 11: hkn0405:3231507:3231507 [3] NCCL INFO P2P plugin IBext
377: hkn0714:456383:456383 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
476: hkn0806:1078676:1078676 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
476: hkn0806:1078676:1078676 [0] NCCL INFO P2P plugin IBext
  9: hkn0405:3231499:3231499 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  9: hkn0405:3231499:3231499 [1] NCCL INFO Using network IBext
479: hkn0806:1078660:1078660 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
479: hkn0806:1078660:1078660 [3] NCCL INFO P2P plugin IBext
477: hkn0806:1078668:1078668 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
477: hkn0806:1078668:1078668 [1] NCCL INFO P2P plugin IBext
119: hkn0506:862430:862430 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
119: hkn0506:862430:862430 [3] NCCL INFO Using network IBext
 10: hkn0405:3231519:3231519 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 10: hkn0405:3231519:3231519 [2] NCCL INFO Using network IBext
  8: hkn0405:3231491:3231491 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  8: hkn0405:3231491:3231491 [0] NCCL INFO P2P plugin IBext
116: hkn0506:862438:862438 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
116: hkn0506:862438:862438 [0] NCCL INFO P2P plugin IBext
 11: hkn0405:3231507:3231507 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 11: hkn0405:3231507:3231507 [3] NCCL INFO Using network IBext
378: hkn0714:456363:456363 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
379: hkn0714:456355:456355 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
118: hkn0506:862450:862450 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
118: hkn0506:862450:862450 [2] NCCL INFO P2P plugin IBext
117: hkn0506:862422:862422 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
376: hkn0714:456371:456371 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
377: hkn0714:456383:456383 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
377: hkn0714:456383:456383 [1] NCCL INFO P2P plugin IBext
479: hkn0806:1078660:1078660 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
479: hkn0806:1078660:1078660 [3] NCCL INFO Using network IBext
476: hkn0806:1078676:1078676 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
476: hkn0806:1078676:1078676 [0] NCCL INFO Using network IBext
477: hkn0806:1078668:1078668 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
477: hkn0806:1078668:1078668 [1] NCCL INFO Using network IBext
301: hkn0628:696372:696372 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
  8: hkn0405:3231491:3231491 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  8: hkn0405:3231491:3231491 [0] NCCL INFO Using network IBext
116: hkn0506:862438:862438 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
116: hkn0506:862438:862438 [0] NCCL INFO Using network IBext
302: hkn0628:696364:696364 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
118: hkn0506:862450:862450 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
118: hkn0506:862450:862450 [2] NCCL INFO Using network IBext
478: hkn0806:1078688:1078688 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
478: hkn0806:1078688:1078688 [2] NCCL INFO Using network IBext
378: hkn0714:456363:456363 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
378: hkn0714:456363:456363 [2] NCCL INFO P2P plugin IBext
379: hkn0714:456355:456355 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
379: hkn0714:456355:456355 [3] NCCL INFO P2P plugin IBext
 22: hkn0409:2609992:2609992 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
303: hkn0628:696380:696380 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
376: hkn0714:456371:456371 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
376: hkn0714:456371:456371 [0] NCCL INFO P2P plugin IBext
117: hkn0506:862422:862422 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
117: hkn0506:862422:862422 [1] NCCL INFO P2P plugin IBext
 21: hkn0409:2610008:2610008 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
300: hkn0628:696392:696392 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
 23: hkn0409:2610020:2610020 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
301: hkn0628:696372:696372 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
301: hkn0628:696372:696372 [1] NCCL INFO P2P plugin IBext
 20: hkn0409:2610000:2610000 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
302: hkn0628:696364:696364 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
302: hkn0628:696364:696364 [2] NCCL INFO P2P plugin IBext
117: hkn0506:862422:862422 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
117: hkn0506:862422:862422 [1] NCCL INFO Using network IBext
376: hkn0714:456371:456371 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
378: hkn0714:456363:456363 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
379: hkn0714:456355:456355 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
376: hkn0714:456371:456371 [0] NCCL INFO Using network IBext
378: hkn0714:456363:456363 [2] NCCL INFO Using network IBext
379: hkn0714:456355:456355 [3] NCCL INFO Using network IBext
 22: hkn0409:2609992:2609992 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 22: hkn0409:2609992:2609992 [2] NCCL INFO P2P plugin IBext
303: hkn0628:696380:696380 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
303: hkn0628:696380:696380 [3] NCCL INFO P2P plugin IBext
377: hkn0714:456383:456383 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
377: hkn0714:456383:456383 [1] NCCL INFO Using network IBext
469: hkn0804:1230034:1230034 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
300: hkn0628:696392:696392 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
300: hkn0628:696392:696392 [0] NCCL INFO P2P plugin IBext
 21: hkn0409:2610008:2610008 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 21: hkn0409:2610008:2610008 [1] NCCL INFO P2P plugin IBext
412: hkn0724:1740321:1740321 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
 23: hkn0409:2610020:2610020 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 23: hkn0409:2610020:2610020 [3] NCCL INFO P2P plugin IBext
302: hkn0628:696364:696364 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
302: hkn0628:696364:696364 [2] NCCL INFO Using network IBext
 20: hkn0409:2610000:2610000 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 20: hkn0409:2610000:2610000 [0] NCCL INFO P2P plugin IBext
303: hkn0628:696380:696380 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
303: hkn0628:696380:696380 [3] NCCL INFO Using network IBext
300: hkn0628:696392:696392 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
300: hkn0628:696392:696392 [0] NCCL INFO Using network IBext
413: hkn0724:1740329:1740329 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
471: hkn0804:1230026:1230026 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
469: hkn0804:1230034:1230034 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
469: hkn0804:1230034:1230034 [1] NCCL INFO P2P plugin IBext
 21: hkn0409:2610008:2610008 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 23: hkn0409:2610020:2610020 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 21: hkn0409:2610008:2610008 [1] NCCL INFO Using network IBext
 23: hkn0409:2610020:2610020 [3] NCCL INFO Using network IBext
470: hkn0804:1230046:1230046 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
301: hkn0628:696372:696372 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
 20: hkn0409:2610000:2610000 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
301: hkn0628:696372:696372 [1] NCCL INFO Using network IBext
 20: hkn0409:2610000:2610000 [0] NCCL INFO Using network IBext
392: hkn0718:3941435:3941435 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
394: hkn0718:3941447:3941447 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
412: hkn0724:1740321:1740321 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
412: hkn0724:1740321:1740321 [0] NCCL INFO P2P plugin IBext
468: hkn0804:1230018:1230018 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
414: hkn0724:1740337:1740337 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
395: hkn0718:3941427:3941427 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
206: hkn0532:950453:950453 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
413: hkn0724:1740329:1740329 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
413: hkn0724:1740329:1740329 [1] NCCL INFO P2P plugin IBext
415: hkn0724:1740349:1740349 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
454: hkn0736:1532624:1532624 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
471: hkn0804:1230026:1230026 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
471: hkn0804:1230026:1230026 [3] NCCL INFO P2P plugin IBext
207: hkn0532:950461:950461 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
 22: hkn0409:2609992:2609992 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 22: hkn0409:2609992:2609992 [2] NCCL INFO Using network IBext
470: hkn0804:1230046:1230046 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
470: hkn0804:1230046:1230046 [2] NCCL INFO P2P plugin IBext
394: hkn0718:3941447:3941447 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
394: hkn0718:3941447:3941447 [2] NCCL INFO P2P plugin IBext
392: hkn0718:3941435:3941435 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
392: hkn0718:3941435:3941435 [0] NCCL INFO P2P plugin IBext
468: hkn0804:1230018:1230018 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
468: hkn0804:1230018:1230018 [0] NCCL INFO P2P plugin IBext
204: hkn0532:950481:950481 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
205: hkn0532:950469:950469 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
265: hkn0615:438714:438714 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
414: hkn0724:1740337:1740337 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
414: hkn0724:1740337:1740337 [2] NCCL INFO P2P plugin IBext
453: hkn0736:1532616:1532616 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
393: hkn0718:3941419:3941419 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
395: hkn0718:3941427:3941427 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
395: hkn0718:3941427:3941427 [3] NCCL INFO P2P plugin IBext
413: hkn0724:1740329:1740329 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
413: hkn0724:1740329:1740329 [1] NCCL INFO Using network IBext
415: hkn0724:1740349:1740349 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
415: hkn0724:1740349:1740349 [3] NCCL INFO P2P plugin IBext
206: hkn0532:950453:950453 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
206: hkn0532:950453:950453 [2] NCCL INFO P2P plugin IBext
418: hkn0725:3136324:3136324 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
454: hkn0736:1532624:1532624 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
454: hkn0736:1532624:1532624 [2] NCCL INFO P2P plugin IBext
470: hkn0804:1230046:1230046 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
471: hkn0804:1230026:1230026 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
470: hkn0804:1230046:1230046 [2] NCCL INFO Using network IBext
471: hkn0804:1230026:1230026 [3] NCCL INFO Using network IBext
468: hkn0804:1230018:1230018 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
468: hkn0804:1230018:1230018 [0] NCCL INFO Using network IBext
417: hkn0725:3136312:3136312 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
207: hkn0532:950461:950461 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
207: hkn0532:950461:950461 [3] NCCL INFO P2P plugin IBext
414: hkn0724:1740337:1740337 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
414: hkn0724:1740337:1740337 [2] NCCL INFO Using network IBext
469: hkn0804:1230034:1230034 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
469: hkn0804:1230034:1230034 [1] NCCL INFO Using network IBext
264: hkn0615:438687:438687 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
482: hkn0807:1043406:1043406 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
265: hkn0615:438714:438714 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
265: hkn0615:438714:438714 [1] NCCL INFO P2P plugin IBext
204: hkn0532:950481:950481 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
204: hkn0532:950481:950481 [0] NCCL INFO P2P plugin IBext
412: hkn0724:1740321:1740321 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
412: hkn0724:1740321:1740321 [0] NCCL INFO Using network IBext
205: hkn0532:950469:950469 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
205: hkn0532:950469:950469 [1] NCCL INFO P2P plugin IBext
395: hkn0718:3941427:3941427 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
395: hkn0718:3941427:3941427 [3] NCCL INFO Using network IBext
453: hkn0736:1532616:1532616 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
453: hkn0736:1532616:1532616 [1] NCCL INFO P2P plugin IBext
415: hkn0724:1740349:1740349 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
415: hkn0724:1740349:1740349 [3] NCCL INFO Using network IBext
393: hkn0718:3941419:3941419 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
393: hkn0718:3941419:3941419 [1] NCCL INFO P2P plugin IBext
480: hkn0807:1043422:1043422 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
416: hkn0725:3136304:3136304 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
419: hkn0725:3136296:3136296 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
267: hkn0615:438695:438695 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
418: hkn0725:3136324:3136324 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
418: hkn0725:3136324:3136324 [2] NCCL INFO P2P plugin IBext
499: hkn0812:718257:718257 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
266: hkn0615:438703:438703 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
207: hkn0532:950461:950461 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
207: hkn0532:950461:950461 [3] NCCL INFO Using network IBext
417: hkn0725:3136312:3136312 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
417: hkn0725:3136312:3136312 [1] NCCL INFO P2P plugin IBext
204: hkn0532:950481:950481 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
204: hkn0532:950481:950481 [0] NCCL INFO Using network IBext
205: hkn0532:950469:950469 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
205: hkn0532:950469:950469 [1] NCCL INFO Using network IBext
264: hkn0615:438687:438687 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
264: hkn0615:438687:438687 [0] NCCL INFO P2P plugin IBext
481: hkn0807:1043434:1043434 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
393: hkn0718:3941419:3941419 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
393: hkn0718:3941419:3941419 [1] NCCL INFO Using network IBext
482: hkn0807:1043406:1043406 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
482: hkn0807:1043406:1043406 [2] NCCL INFO P2P plugin IBext
455: hkn0736:1532608:1532608 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
498: hkn0812:718237:718237 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
483: hkn0807:1043414:1043414 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
392: hkn0718:3941435:3941435 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
392: hkn0718:3941435:3941435 [0] NCCL INFO Using network IBext
497: hkn0812:718229:718229 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
217: hkn0601:142232:142232 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
453: hkn0736:1532616:1532616 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
453: hkn0736:1532616:1532616 [1] NCCL INFO Using network IBext
394: hkn0718:3941447:3941447 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
394: hkn0718:3941447:3941447 [2] NCCL INFO Using network IBext
480: hkn0807:1043422:1043422 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
480: hkn0807:1043422:1043422 [0] NCCL INFO P2P plugin IBext
267: hkn0615:438695:438695 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
267: hkn0615:438695:438695 [3] NCCL INFO P2P plugin IBext
416: hkn0725:3136304:3136304 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
416: hkn0725:3136304:3136304 [0] NCCL INFO P2P plugin IBext
419: hkn0725:3136296:3136296 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
419: hkn0725:3136296:3136296 [3] NCCL INFO P2P plugin IBext
206: hkn0532:950453:950453 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
206: hkn0532:950453:950453 [2] NCCL INFO Using network IBext
417: hkn0725:3136312:3136312 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
499: hkn0812:718257:718257 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
499: hkn0812:718257:718257 [3] NCCL INFO P2P plugin IBext
417: hkn0725:3136312:3136312 [1] NCCL INFO Using network IBext
266: hkn0615:438703:438703 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
266: hkn0615:438703:438703 [2] NCCL INFO P2P plugin IBext
454: hkn0736:1532624:1532624 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
454: hkn0736:1532624:1532624 [2] NCCL INFO Using network IBext
452: hkn0736:1532636:1532636 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
264: hkn0615:438687:438687 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
264: hkn0615:438687:438687 [0] NCCL INFO Using network IBext
496: hkn0812:718245:718245 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
218: hkn0601:142216:142216 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
481: hkn0807:1043434:1043434 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
481: hkn0807:1043434:1043434 [1] NCCL INFO P2P plugin IBext
455: hkn0736:1532608:1532608 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
455: hkn0736:1532608:1532608 [3] NCCL INFO P2P plugin IBext
498: hkn0812:718237:718237 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
498: hkn0812:718237:718237 [2] NCCL INFO P2P plugin IBext
265: hkn0615:438714:438714 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
265: hkn0615:438714:438714 [1] NCCL INFO Using network IBext
217: hkn0601:142232:142232 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
217: hkn0601:142232:142232 [1] NCCL INFO P2P plugin IBext
483: hkn0807:1043414:1043414 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
483: hkn0807:1043414:1043414 [3] NCCL INFO P2P plugin IBext
267: hkn0615:438695:438695 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
267: hkn0615:438695:438695 [3] NCCL INFO Using network IBext
497: hkn0812:718229:718229 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
497: hkn0812:718229:718229 [1] NCCL INFO P2P plugin IBext
416: hkn0725:3136304:3136304 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
419: hkn0725:3136296:3136296 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
416: hkn0725:3136304:3136304 [0] NCCL INFO Using network IBext
419: hkn0725:3136296:3136296 [3] NCCL INFO Using network IBext
480: hkn0807:1043422:1043422 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
480: hkn0807:1043422:1043422 [0] NCCL INFO Using network IBext
266: hkn0615:438703:438703 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
266: hkn0615:438703:438703 [2] NCCL INFO Using network IBext
216: hkn0601:142244:142244 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
195: hkn0529:1565159:1565159 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
418: hkn0725:3136324:3136324 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
418: hkn0725:3136324:3136324 [2] NCCL INFO Using network IBext
481: hkn0807:1043434:1043434 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
481: hkn0807:1043434:1043434 [1] NCCL INFO Using network IBext
455: hkn0736:1532608:1532608 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
455: hkn0736:1532608:1532608 [3] NCCL INFO Using network IBext
483: hkn0807:1043414:1043414 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
483: hkn0807:1043414:1043414 [3] NCCL INFO Using network IBext
219: hkn0601:142224:142224 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
452: hkn0736:1532636:1532636 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
452: hkn0736:1532636:1532636 [0] NCCL INFO P2P plugin IBext
 92: hkn0428:691744:691744 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
218: hkn0601:142216:142216 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
218: hkn0601:142216:142216 [2] NCCL INFO P2P plugin IBext
498: hkn0812:718237:718237 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
498: hkn0812:718237:718237 [2] NCCL INFO Using network IBext
497: hkn0812:718229:718229 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
497: hkn0812:718229:718229 [1] NCCL INFO Using network IBext
496: hkn0812:718245:718245 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
496: hkn0812:718245:718245 [0] NCCL INFO P2P plugin IBext
482: hkn0807:1043406:1043406 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
482: hkn0807:1043406:1043406 [2] NCCL INFO Using network IBext
192: hkn0529:1565151:1565151 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
 94: hkn0428:691716:691716 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
335: hkn0636:1678732:1678732 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
195: hkn0529:1565159:1565159 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
195: hkn0529:1565159:1565159 [3] NCCL INFO P2P plugin IBext
332: hkn0636:1678716:1678716 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
216: hkn0601:142244:142244 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
216: hkn0601:142244:142244 [0] NCCL INFO P2P plugin IBext
452: hkn0736:1532636:1532636 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
452: hkn0736:1532636:1532636 [0] NCCL INFO Using network IBext
 93: hkn0428:691732:691732 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
496: hkn0812:718245:718245 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
499: hkn0812:718257:718257 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
499: hkn0812:718257:718257 [3] NCCL INFO Using network IBext
496: hkn0812:718245:718245 [0] NCCL INFO Using network IBext
 95: hkn0428:691724:691724 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
219: hkn0601:142224:142224 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
219: hkn0601:142224:142224 [3] NCCL INFO P2P plugin IBext
193: hkn0529:1565171:1565171 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
 92: hkn0428:691744:691744 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 92: hkn0428:691744:691744 [0] NCCL INFO P2P plugin IBext
218: hkn0601:142216:142216 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
218: hkn0601:142216:142216 [2] NCCL INFO Using network IBext
192: hkn0529:1565151:1565151 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
192: hkn0529:1565151:1565151 [0] NCCL INFO P2P plugin IBext
217: hkn0601:142232:142232 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
217: hkn0601:142232:142232 [1] NCCL INFO Using network IBext
333: hkn0636:1678744:1678744 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
 94: hkn0428:691716:691716 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 94: hkn0428:691716:691716 [2] NCCL INFO P2P plugin IBext
216: hkn0601:142244:142244 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
216: hkn0601:142244:142244 [0] NCCL INFO Using network IBext
334: hkn0636:1678724:1678724 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
194: hkn0529:1565143:1565143 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
335: hkn0636:1678732:1678732 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
335: hkn0636:1678732:1678732 [3] NCCL INFO P2P plugin IBext
219: hkn0601:142224:142224 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
219: hkn0601:142224:142224 [3] NCCL INFO Using network IBext
332: hkn0636:1678716:1678716 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
332: hkn0636:1678716:1678716 [0] NCCL INFO P2P plugin IBext
 93: hkn0428:691732:691732 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 93: hkn0428:691732:691732 [1] NCCL INFO P2P plugin IBext
 95: hkn0428:691724:691724 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 95: hkn0428:691724:691724 [3] NCCL INFO P2P plugin IBext
 31: hkn0411:2340265:2340265 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
192: hkn0529:1565151:1565151 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
192: hkn0529:1565151:1565151 [0] NCCL INFO Using network IBext
193: hkn0529:1565171:1565171 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
193: hkn0529:1565171:1565171 [1] NCCL INFO P2P plugin IBext
 94: hkn0428:691716:691716 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 94: hkn0428:691716:691716 [2] NCCL INFO Using network IBext
333: hkn0636:1678744:1678744 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
333: hkn0636:1678744:1678744 [1] NCCL INFO P2P plugin IBext
 93: hkn0428:691732:691732 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 93: hkn0428:691732:691732 [1] NCCL INFO Using network IBext
278: hkn0621:2016125:2016125 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
334: hkn0636:1678724:1678724 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
334: hkn0636:1678724:1678724 [2] NCCL INFO P2P plugin IBext
 30: hkn0411:2340293:2340293 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
 95: hkn0428:691724:691724 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 95: hkn0428:691724:691724 [3] NCCL INFO Using network IBext
277: hkn0621:2016097:2016097 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
397: hkn0719:1330259:1330259 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
399: hkn0719:1330267:1330267 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
194: hkn0529:1565143:1565143 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
194: hkn0529:1565143:1565143 [2] NCCL INFO P2P plugin IBext
195: hkn0529:1565159:1565159 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
195: hkn0529:1565159:1565159 [3] NCCL INFO Using network IBext
398: hkn0719:1330251:1330251 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
 31: hkn0411:2340265:2340265 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 31: hkn0411:2340265:2340265 [3] NCCL INFO P2P plugin IBext
193: hkn0529:1565171:1565171 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
193: hkn0529:1565171:1565171 [1] NCCL INFO Using network IBext
 29: hkn0411:2340273:2340273 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
 92: hkn0428:691744:691744 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 92: hkn0428:691744:691744 [0] NCCL INFO Using network IBext
334: hkn0636:1678724:1678724 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
334: hkn0636:1678724:1678724 [2] NCCL INFO Using network IBext
396: hkn0719:1330279:1330279 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
194: hkn0529:1565143:1565143 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
333: hkn0636:1678744:1678744 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
194: hkn0529:1565143:1565143 [2] NCCL INFO Using network IBext
333: hkn0636:1678744:1678744 [1] NCCL INFO Using network IBext
278: hkn0621:2016125:2016125 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
278: hkn0621:2016125:2016125 [2] NCCL INFO P2P plugin IBext
 30: hkn0411:2340293:2340293 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 30: hkn0411:2340293:2340293 [2] NCCL INFO P2P plugin IBext
277: hkn0621:2016097:2016097 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
277: hkn0621:2016097:2016097 [1] NCCL INFO P2P plugin IBext
332: hkn0636:1678716:1678716 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
332: hkn0636:1678716:1678716 [0] NCCL INFO Using network IBext
335: hkn0636:1678732:1678732 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
335: hkn0636:1678732:1678732 [3] NCCL INFO Using network IBext
 28: hkn0411:2340281:2340281 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
399: hkn0719:1330267:1330267 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
399: hkn0719:1330267:1330267 [3] NCCL INFO P2P plugin IBext
397: hkn0719:1330259:1330259 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
397: hkn0719:1330259:1330259 [1] NCCL INFO P2P plugin IBext
398: hkn0719:1330251:1330251 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
398: hkn0719:1330251:1330251 [2] NCCL INFO P2P plugin IBext
 29: hkn0411:2340273:2340273 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 29: hkn0411:2340273:2340273 [1] NCCL INFO P2P plugin IBext
318: hkn0632:1782963:1782963 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
396: hkn0719:1330279:1330279 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
396: hkn0719:1330279:1330279 [0] NCCL INFO P2P plugin IBext
 30: hkn0411:2340293:2340293 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 30: hkn0411:2340293:2340293 [2] NCCL INFO Using network IBext
 28: hkn0411:2340281:2340281 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 28: hkn0411:2340281:2340281 [0] NCCL INFO P2P plugin IBext
 29: hkn0411:2340273:2340273 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 29: hkn0411:2340273:2340273 [1] NCCL INFO Using network IBext
 31: hkn0411:2340265:2340265 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 31: hkn0411:2340265:2340265 [3] NCCL INFO Using network IBext
316: hkn0632:1782979:1782979 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
319: hkn0632:1782991:1782991 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
318: hkn0632:1782963:1782963 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
318: hkn0632:1782963:1782963 [2] NCCL INFO P2P plugin IBext
396: hkn0719:1330279:1330279 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
396: hkn0719:1330279:1330279 [0] NCCL INFO Using network IBext
 28: hkn0411:2340281:2340281 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 28: hkn0411:2340281:2340281 [0] NCCL INFO Using network IBext
317: hkn0632:1782971:1782971 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
277: hkn0621:2016097:2016097 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
277: hkn0621:2016097:2016097 [1] NCCL INFO Using network IBext
278: hkn0621:2016125:2016125 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
278: hkn0621:2016125:2016125 [2] NCCL INFO Using network IBext
398: hkn0719:1330251:1330251 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
398: hkn0719:1330251:1330251 [2] NCCL INFO Using network IBext
316: hkn0632:1782979:1782979 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
316: hkn0632:1782979:1782979 [0] NCCL INFO P2P plugin IBext
397: hkn0719:1330259:1330259 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
397: hkn0719:1330259:1330259 [1] NCCL INFO Using network IBext
399: hkn0719:1330267:1330267 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
399: hkn0719:1330267:1330267 [3] NCCL INFO Using network IBext
319: hkn0632:1782991:1782991 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
319: hkn0632:1782991:1782991 [3] NCCL INFO P2P plugin IBext
258: hkn0612:941345:941345 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
259: hkn0612:941325:941325 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
257: hkn0612:941317:941317 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
256: hkn0612:941333:941333 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
317: hkn0632:1782971:1782971 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
317: hkn0632:1782971:1782971 [1] NCCL INFO P2P plugin IBext
319: hkn0632:1782991:1782991 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
319: hkn0632:1782991:1782991 [3] NCCL INFO Using network IBext
316: hkn0632:1782979:1782979 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
316: hkn0632:1782979:1782979 [0] NCCL INFO Using network IBext
258: hkn0612:941345:941345 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
258: hkn0612:941345:941345 [2] NCCL INFO P2P plugin IBext
318: hkn0632:1782963:1782963 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
318: hkn0632:1782963:1782963 [2] NCCL INFO Using network IBext
317: hkn0632:1782971:1782971 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
317: hkn0632:1782971:1782971 [1] NCCL INFO Using network IBext
259: hkn0612:941325:941325 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
259: hkn0612:941325:941325 [3] NCCL INFO P2P plugin IBext
257: hkn0612:941317:941317 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
257: hkn0612:941317:941317 [1] NCCL INFO P2P plugin IBext
256: hkn0612:941333:941333 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
256: hkn0612:941333:941333 [0] NCCL INFO P2P plugin IBext
256: hkn0612:941333:941333 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
256: hkn0612:941333:941333 [0] NCCL INFO Using network IBext
257: hkn0612:941317:941317 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
257: hkn0612:941317:941317 [1] NCCL INFO Using network IBext
279: hkn0621:2016105:2016105 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
258: hkn0612:941345:941345 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
258: hkn0612:941345:941345 [2] NCCL INFO Using network IBext
259: hkn0612:941325:941325 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
259: hkn0612:941325:941325 [3] NCCL INFO Using network IBext
276: hkn0621:2016113:2016113 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
279: hkn0621:2016105:2016105 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
279: hkn0621:2016105:2016105 [3] NCCL INFO P2P plugin IBext
276: hkn0621:2016113:2016113 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
276: hkn0621:2016113:2016113 [0] NCCL INFO P2P plugin IBext
279: hkn0621:2016105:2016105 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
279: hkn0621:2016105:2016105 [3] NCCL INFO Using network IBext
276: hkn0621:2016113:2016113 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
276: hkn0621:2016113:2016113 [0] NCCL INFO Using network IBext
 42: hkn0414:2006114:2006224 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
330: hkn0635:1249906:1250023 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
342: hkn0704:816326:816455 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
492: hkn0810:963933:964030 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 43: hkn0414:2006106:2006225 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 31: hkn0411:2340265:2340393 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 22: hkn0409:2609992:2610120 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 40: hkn0414:2006126:2006221 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
451: hkn0734:1180877:1181004 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 79: hkn0424:2972333:2972431 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
331: hkn0635:1249914:1250018 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 23: hkn0409:2610020:2610114 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
328: hkn0635:1249926:1250020 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
341: hkn0704:816354:816450 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 41: hkn0414:2006098:2006227 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
339: hkn0703:765530:765656 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
343: hkn0704:816334:816453 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
329: hkn0635:1249898:1250021 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 26: hkn0410:1184027:1184146 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 20: hkn0409:2610000:2610117 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
340: hkn0704:816342:816447 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
211: hkn0534:1172757:1172866 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
493: hkn0810:963905:964027 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 21: hkn0409:2610008:2610115 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 77: hkn0424:2972305:2972428 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
450: hkn0734:1180905:1181006 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 28: hkn0411:2340281:2340396 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 34: hkn0412:2286727:2286850 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
336: hkn0703:765538:765661 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
479: hkn0806:1078660:1078785 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
210: hkn0534:1172741:1172868 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
251: hkn0609:735154:735263 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  1: hkn0403:1808437:1808809 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
337: hkn0703:765546:765657 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
448: hkn0734:1180893:1180999 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
236: hkn0606:2396583:2396678 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
345: hkn0705:807558:807678 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 29: hkn0411:2340273:2340391 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 76: hkn0424:2972313:2972427 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 78: hkn0424:2972321:2972426 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
338: hkn0703:765558:765658 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
495: hkn0810:963921:964028 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
208: hkn0534:1172769:1172865 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
130: hkn0509:3148779:3148872 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
237: hkn0606:2396555:2396677 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
449: hkn0734:1180885:1181000 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
494: hkn0810:963913:964023 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
426: hkn0727:1370159:1370281 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 30: hkn0411:2340293:2340389 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
209: hkn0534:1172749:1172871 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 24: hkn0410:1184043:1184151 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
349: hkn0706:776624:776729 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
431: hkn0728:1348489:1348596 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
239: hkn0606:2396563:2396679 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
255: hkn0611:734150:734278 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
204: hkn0532:950481:950779 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
474: hkn0805:1136461:1136592 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 15: hkn0407:1840605:1840730 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
238: hkn0606:2396571:2396682 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
409: hkn0723:232568:232721 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
230: hkn0604:713539:713662 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
509: hkn0816:399926:400042 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
169: hkn0523:1572569:1572689 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
152: hkn0515:2921174:2921332 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
344: hkn0705:807566:807679 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  7: hkn0404:1363854:1363975 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
447: hkn0733:1413735:1413846 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 33: hkn0412:2286731:2286842 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 73: hkn0423:1729402:1729514 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
363: hkn0710:379887:380008 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 25: hkn0410:1184035:1184153 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
113: hkn0505:2328151:2328263 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
250: hkn0609:735166:735258 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 27: hkn0410:1184055:1184150 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
244: hkn0608:510064:510177 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 93: hkn0428:691732:691841 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
217: hkn0601:142232:142341 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
371: hkn0712:319428:319537 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
478: hkn0806:1078688:1078789 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
176: hkn0525:1011118:1011248 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
258: hkn0612:941345:941470 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
107: hkn0503:2924178:2924282 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
166: hkn0521:1222185:1222296 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
318: hkn0632:1782963:1783087 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
139: hkn0511:3090869:3090995 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
235: hkn0605:736572:736668 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
263: hkn0613:927090:927213 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
463: hkn0802:1224700:1224850 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
203: hkn0531:1255122:1255246 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
396: hkn0719:1330279:1330367 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
248: hkn0609:735146:735265 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
370: hkn0712:319448:319543 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  0: hkn0403:1808436:1808801 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 32: hkn0412:2286739:2286849 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
347: hkn0705:807550:807681 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
199: hkn0530:1282494:1282588 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
424: hkn0727:1370187:1370280 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
227: hkn0603:1437583:1437701 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
346: hkn0705:807578:807672 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
131: hkn0509:3148767:3148876 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
408: hkn0723:232560:232720 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 35: hkn0412:2286751:2286844 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
365: hkn0711:608392:608506 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
249: hkn0609:735138:735259 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 74: hkn0423:1729414:1729511 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
429: hkn0728:1348481:1348599 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
103: hkn0502:253410:253517 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
125: hkn0508:3163494:3163603 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 95: hkn0428:691724:691842 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
477: hkn0806:1078668:1078787 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
214: hkn0535:2423350:2423446 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
435: hkn0730:1426037:1426189 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
473: hkn0805:1136469:1136586 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
428: hkn0728:1348473:1348595 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
348: hkn0706:776612:776722 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
246: hkn0608:510072:510180 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
276: hkn0621:2016113:2016222 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
355: hkn0707:4044292:4044419 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
425: hkn0727:1370175:1370283 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 10: hkn0405:3231519:3231613 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
182: hkn0526:1452774:1452881 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
171: hkn0523:1572561:1572684 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
476: hkn0806:1078676:1078786 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  3: hkn0403:1808445:1808808 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
285: hkn0623:1897135:1897250 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
218: hkn0601:142216:142337 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
154: hkn0515:2921182:2921328 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
444: hkn0733:1413747:1413848 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
162: hkn0520:2737243:2737371 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  4: hkn0404:1363862:1363969 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 84: hkn0426:838364:838519 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
369: hkn0712:319420:319542 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
320: hkn0633:1550633:1550753 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
252: hkn0611:734178:734279 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
411: hkn0723:232580:232725 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
129: hkn0509:3148751:3148873 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
361: hkn0710:379895:380014 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
291: hkn0624:1797274:1797389 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 53: hkn0418:1893541:1893660 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
472: hkn0805:1136489:1136590 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
368: hkn0712:319436:319546 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
179: hkn0525:1011126:1011245 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
219: hkn0601:142224:142344 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
410: hkn0723:232552:232722 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 99: hkn0501:1352386:1352510 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  2: hkn0403:1808457:1808810 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
430: hkn0728:1348501:1348594 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
207: hkn0532:950461:950778 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
427: hkn0727:1370167:1370284 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
314: hkn0631:1046179:1046288 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 14: hkn0407:1840633:1840731 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
510: hkn0816:399918:400045 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
445: hkn0733:1413727:1413845 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 83: hkn0425:2108537:2108638 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
231: hkn0604:713531:713661 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
376: hkn0714:456371:456476 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
256: hkn0612:941333:941464 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
247: hkn0608:510056:510185 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
475: hkn0805:1136477:1136585 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
216: hkn0601:142244:142342 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 72: hkn0423:1729386:1729506 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
287: hkn0623:1897155:1897246 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
360: hkn0710:379903:380006 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
245: hkn0608:510084:510183 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
153: hkn0515:2921190:2921327 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
446: hkn0733:1413719:1413842 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
167: hkn0521:1222197:1222291 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 94: hkn0428:691716:691838 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
200: hkn0531:1255150:1255251 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 68: hkn0422:4177469:4177594 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
284: hkn0623:1897127:1897252 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 92: hkn0428:691744:691845 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
414: hkn0724:1740337:1740474 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
114: hkn0505:2328143:2328257 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
254: hkn0611:734166:734276 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
351: hkn0706:776604:776726 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
439: hkn0731:1411104:1411206 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
311: hkn0630:1622872:1622968 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
133: hkn0510:2786407:2786523 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
196: hkn0530:1282482:1282590 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
232: hkn0605:736552:736663 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
362: hkn0710:379915:380012 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
177: hkn0525:1011146:1011240 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
319: hkn0632:1782991:1783084 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
286: hkn0623:1897143:1897243 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
128: hkn0509:3148759:3148874 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 75: hkn0423:1729394:1729515 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
155: hkn0515:2921202:2921330 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
272: hkn0617:2319184:2319311 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
289: hkn0624:1797266:1797383 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
205: hkn0532:950469:950780 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
229: hkn0604:713547:713656 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  6: hkn0404:1363846:1363970 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
461: hkn0802:1224708:1224841 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
397: hkn0719:1330259:1330375 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
307: hkn0629:1616387:1616511 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
253: hkn0611:734158:734277 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
161: hkn0520:2737231:2737367 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
416: hkn0725:3136304:3136419 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
260: hkn0613:927106:927208 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
467: hkn0803:900994:901110 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
228: hkn0604:713559:713655 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
317: hkn0632:1782971:1783088 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
124: hkn0508:3163506:3163602 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
508: hkn0816:399946:400046 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
433: hkn0730:1426045:1426192 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
178: hkn0525:1011134:1011249 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
452: hkn0736:1532636:1532735 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
393: hkn0718:3941419:3941544 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 66: hkn0421:2208703:2208881 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
136: hkn0511:3090885:3090991 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
315: hkn0631:1046171:1046285 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
126: hkn0508:3163478:3163601 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
115: hkn0505:2328163:2328258 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
377: hkn0714:456383:456480 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
206: hkn0532:950453:950783 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 13: hkn0407:1840621:1840725 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  5: hkn0404:1363874:1363976 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
292: hkn0626:1322782:1322938 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
380: hkn0715:426268:426388 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
225: hkn0603:1437591:1437698 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
372: hkn0713:494598:494713 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
257: hkn0612:941317:941465 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
100: hkn0502:253422:253519 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
296: hkn0627:1812310:1812420 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
164: hkn0521:1222169:1222292 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
234: hkn0605:736544:736667 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
350: hkn0706:776596:776723 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
127: hkn0508:3163486:3163600 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
104: hkn0503:2924170:2924284 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
367: hkn0711:608376:608500 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
170: hkn0523:1572577:1572685 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 97: hkn0501:1352406:1352507 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 19: hkn0408:2915270:2915393 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 12: hkn0407:1840613:1840723 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
511: hkn0816:399934:400048 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
181: hkn0526:1452758:1452883 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
310: hkn0630:1622852:1622969 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
197: hkn0530:1282466:1282581 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 71: hkn0422:4177497:4177588 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
262: hkn0613:927118:927210 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
183: hkn0526:1452786:1452878 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
288: hkn0624:1797296:1797392 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
277: hkn0621:2016097:2016215 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
316: hkn0632:1782979:1783083 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 57: hkn0419:1568619:1568709 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
432: hkn0730:1426065:1426190 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
301: hkn0628:696372:696489 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
352: hkn0707:4044320:4044416 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
189: hkn0528:1326044:1326167 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
168: hkn0523:1572589:1572686 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 87: hkn0426:838380:838520 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
398: hkn0719:1330251:1330374 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
259: hkn0612:941325:941471 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
202: hkn0531:1255138:1255243 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
163: hkn0520:2737223:2737364 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
106: hkn0503:2924162:2924287 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
333: hkn0636:1678744:1678868 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
165: hkn0521:1222177:1222293 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 96: hkn0501:1352378:1352508 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
418: hkn0725:3136324:3136423 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
290: hkn0624:1797282:1797386 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
112: hkn0505:2328135:2328264 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
233: hkn0605:736560:736669 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
379: hkn0714:456355:456477 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
109: hkn0504:65443:65560 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
261: hkn0613:927098:927209 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
198: hkn0530:1282474:1282589 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
403: hkn0720:33744:33905 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
273: hkn0617:2319212:2319310 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
312: hkn0631:1046191:1046283 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  8: hkn0405:3231491:3231618 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
180: hkn0526:1452766:1452877 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
454: hkn0736:1532624:1532729 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
378: hkn0714:456363:456478 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 89: hkn0427:1159514:1159627 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
160: hkn0520:2737215:2737368 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
201: hkn0531:1255130:1255248 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 98: hkn0501:1352394:1352503 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
386: hkn0716:132819:132964 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 70: hkn0422:4177477:4177595 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
322: hkn0633:1550649:1550756 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
102: hkn0502:253394:253516 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
399: hkn0719:1330267:1330376 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
304: hkn0629:1616359:1616509 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
212: hkn0535:2423336:2423447 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
105: hkn0503:2924190:2924283 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
137: hkn0511:3090877:3090993 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 69: hkn0422:4177485:4177589 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 86: hkn0426:838372:838511 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
313: hkn0631:1046163:1046282 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
366: hkn0711:608384:608505 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
309: hkn0630:1622860:1622960 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 81: hkn0425:2108525:2108632 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
413: hkn0724:1740329:1740471 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
268: hkn0616:429398:429527 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 55: hkn0418:1893549:1893663 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 85: hkn0426:838392:838518 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
434: hkn0730:1426053:1426183 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
417: hkn0725:3136312:3136416 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 17: hkn0408:2915262:2915390 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
138: hkn0511:3090897:3090992 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
419: hkn0725:3136296:3136421 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 60: hkn0420:3234567:3234693 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
438: hkn0731:1411096:1411207 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
353: hkn0707:4044300:4044417 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
101: hkn0502:253402:253515 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
274: hkn0617:2319200:2319315 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
224: hkn0603:1437575:1437699 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
213: hkn0535:2423328:2423441 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
364: hkn0711:608404:608498 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
460: hkn0802:1224720:1224848 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
110: hkn0504:65463:65554 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
308: hkn0630:1622844:1622963 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
453: hkn0736:1532616:1532726 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
465: hkn0803:900978:901109 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
462: hkn0802:1224692:1224849 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
306: hkn0629:1616375:1616505 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  9: hkn0405:3231499:3231610 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 18: hkn0408:2915278:2915387 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
305: hkn0629:1616367:1616506 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
275: hkn0617:2319192:2319312 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
241: hkn0607:928753:928855 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
302: hkn0628:696364:696481 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
279: hkn0621:2016105:2016220 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
332: hkn0636:1678716:1678871 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 82: hkn0425:2108517:2108637 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
455: hkn0736:1532608:1532732 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
226: hkn0603:1437603:1437704 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
382: hkn0715:426276:426394 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
415: hkn0724:1740349:1740479 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
466: hkn0803:900986:901105 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
108: hkn0504:65435:65559 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
321: hkn0633:1550661:1550752 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 90: hkn0427:1159498:1159622 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
334: hkn0636:1678724:1678867 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
384: hkn0716:132827:132967 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 16: hkn0408:2915290:2915389 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
294: hkn0626:1322810:1322935 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
374: hkn0713:494590:494707 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
271: hkn0616:429414:429520 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
402: hkn0720:33772:33907 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 11: hkn0405:3231507:3231615 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
215: hkn0535:2423320:2423450 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 65: hkn0421:2208731:2208877 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
464: hkn0803:901006:901108 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
436: hkn0731:1411088:1411212 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
297: hkn0627:1812302:1812414 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
157: hkn0516:2940314:2940436 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 58: hkn0419:1568591:1568715 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
392: hkn0718:3941435:3941546 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
354: hkn0707:4044308:4044418 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 54: hkn0418:1893557:1893666 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
111: hkn0504:65451:65555 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
323: hkn0633:1550641:1550758 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 80: hkn0425:2108509:2108631 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
373: hkn0713:494610:494705 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 67: hkn0421:2208711:2208878 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
401: hkn0720:33760:33906 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
324: hkn0634:1545221:1545345 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
300: hkn0628:696392:696486 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
132: hkn0510:2786415:2786525 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
375: hkn0713:494582:494711 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 38: hkn0413:2391078:2391198 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
412: hkn0724:1740321:1740477 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
190: hkn0528:1326060:1326165 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
278: hkn0621:2016125:2016216 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
221: hkn0602:3390370:3390573 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
283: hkn0622:2045028:2045131 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
387: hkn0716:132839:132970 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
195: hkn0529:1565159:1565265 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
303: hkn0628:696380:696485 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
381: hkn0715:426296:426395 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
269: hkn0616:429426:429521 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
298: hkn0627:1812322:1812413 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 64: hkn0421:2208719:2208879 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
385: hkn0716:132811:132965 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
141: hkn0512:3068462:3068573 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 52: hkn0418:1893569:1893661 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
270: hkn0616:429406:429526 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
400: hkn0720:33752:33908 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
335: hkn0636:1678732:1678872 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
186: hkn0527:1373294:1373422 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
299: hkn0627:1812294:1812419 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 91: hkn0427:1159506:1159619 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
437: hkn0731:1411116:1411213 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
423: hkn0726:1572482:1572597 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
240: hkn0607:928741:928852 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 56: hkn0419:1568599:1568716 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
134: hkn0510:2786427:2786528 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 88: hkn0427:1159526:1159625 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 59: hkn0419:1568607:1568710 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
159: hkn0516:2940322:2940429 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
174: hkn0524:1158156:1158250 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
395: hkn0718:3941427:3941539 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
404: hkn0721:2323901:2323996 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 63: hkn0420:3234583:3234690 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
383: hkn0715:426284:426389 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
135: hkn0510:2786399:2786524 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
191: hkn0528:1326052:1326169 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
357: hkn0708:437583:437699 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
242: hkn0607:928725:928850 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
394: hkn0718:3941447:3941548 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
185: hkn0527:1373310:1373415 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
188: hkn0528:1326072:1326164 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 62: hkn0420:3234575:3234691 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
222: hkn0602:3390386:3390580 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 61: hkn0420:3234595:3234696 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
243: hkn0607:928733:928851 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
282: hkn0622:2045008:2045126 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
293: hkn0626:1322798:1322932 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
156: hkn0516:2940342:2940437 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
158: hkn0516:2940330:2940431 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
295: hkn0626:1322790:1322933 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
281: hkn0622:2045016:2045130 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
149: hkn0514:2975087:2975198 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
280: hkn0622:2045000:2045127 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
406: hkn0721:2323879:2323993 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
264: hkn0615:438687:438806 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
140: hkn0512:3068482:3068576 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
223: hkn0602:3390378:3390578 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
142: hkn0512:3068454:3068574 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
175: hkn0524:1158128:1158251 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
187: hkn0527:1373302:1373417 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 45: hkn0415:2520743:2520858 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
172: hkn0524:1158136:1158254 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
220: hkn0602:3390398:3390575 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 37: hkn0413:2391086:2391193 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
143: hkn0512:3068470:3068579 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
405: hkn0721:2323871:2323991 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
173: hkn0524:1158144:1158252 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
150: hkn0514:2975099:2975195 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
420: hkn0726:1572502:1572595 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
184: hkn0527:1373322:1373423 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
422: hkn0726:1572474:1572594 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
407: hkn0721:2323889:2323992 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
356: hkn0708:437611:437707 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
118: hkn0506:862450:862548 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
151: hkn0514:2975071:2975199 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
358: hkn0708:437599:437701 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
500: hkn0814:700164:700310 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
483: hkn0807:1043414:1043536 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 39: hkn0413:2391070:2391199 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
148: hkn0514:2975079:2975202 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
145: hkn0513:3037331:3037435 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
499: hkn0812:718257:718355 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
266: hkn0615:438703:438813 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
359: hkn0708:437591:437704 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
421: hkn0726:1572490:1572596 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
265: hkn0615:438714:438810 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
327: hkn0634:1545249:1545346 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
441: hkn0732:1236021:1236128 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 44: hkn0415:2520735:2520862 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
326: hkn0634:1545229:1545344 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
193: hkn0529:1565171:1565268 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 36: hkn0413:2391098:2391192 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
325: hkn0634:1545237:1545343 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
267: hkn0615:438695:438811 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
469: hkn0804:1230034:1230144 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
482: hkn0807:1043406:1043538 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 47: hkn0415:2520751:2520864 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
194: hkn0529:1565143:1565270 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 46: hkn0415:2520763:2520859 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
498: hkn0812:718237:718348 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
497: hkn0812:718229:718349 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
117: hkn0506:862422:862551 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 50: hkn0417:2292055:2292170 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
480: hkn0807:1043422:1043530 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
502: hkn0814:700184:700311 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
496: hkn0812:718245:718354 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
147: hkn0513:3037315:3037440 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
489: hkn0809:961668:961775 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
146: hkn0513:3037323:3037444 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
144: hkn0513:3037343:3037441 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
119: hkn0506:862430:862542 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
471: hkn0804:1230026:1230141 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
481: hkn0807:1043434:1043534 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
192: hkn0529:1565151:1565262 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
116: hkn0506:862438:862546 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
468: hkn0804:1230018:1230142 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
503: hkn0814:700156:700314 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
490: hkn0809:961680:961778 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
470: hkn0804:1230046:1230140 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
442: hkn0732:1236013:1236130 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
501: hkn0814:700172:700309 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
443: hkn0732:1236005:1236121 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
491: hkn0809:961660:961772 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
484: hkn0808:995046:995154 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
488: hkn0809:961652:961773 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 49: hkn0417:2292047:2292172 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
485: hkn0808:995038:995153 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
440: hkn0732:1236033:1236129 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 51: hkn0417:2292063:2292173 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
486: hkn0808:995058:995152 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
504: hkn0815:419469:419586 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
457: hkn0801:2264557:2264657 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
122: hkn0507:3211459:3211565 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
391: hkn0717:19437:19568 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
487: hkn0808:995030:995156 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
389: hkn0717:19453:19564 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
123: hkn0507:3211443:3211567 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
507: hkn0815:419489:419590 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
456: hkn0801:2264545:2264656 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
506: hkn0815:419477:419589 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
459: hkn0801:2264529:2264651 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 48: hkn0417:2292075:2292171 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
505: hkn0815:419461:419585 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
388: hkn0717:19465:19565 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
121: hkn0507:3211451:3211566 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
458: hkn0801:2264537:2264649 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
120: hkn0507:3211471:3211570 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
390: hkn0717:19445:19567 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 65: hkn0421:2208731:2208877 [1] NCCL INFO Trees [0] 66/32/-1->65->64 [1] 66/-1/-1->65->64
 65: hkn0421:2208731:2208877 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 68: hkn0422:4177469:4177594 [0] NCCL INFO Trees [0] 69/-1/-1->68->73 [1] 69/64/-1->68->76
 66: hkn0421:2208703:2208881 [2] NCCL INFO Trees [0] 67/-1/-1->66->65 [1] 67/-1/-1->66->65
 66: hkn0421:2208703:2208881 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 68: hkn0422:4177469:4177594 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 71: hkn0422:4177497:4177588 [3] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] -1/-1/-1->71->70
 71: hkn0422:4177497:4177588 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 64: hkn0421:2208719:2208879 [0] NCCL INFO Trees [0] 65/96/-1->64->129 [1] 65/-1/-1->64->68
 64: hkn0421:2208719:2208879 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 69: hkn0422:4177485:4177589 [1] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 70/72/-1->69->68
 67: hkn0421:2208711:2208878 [3] NCCL INFO Trees [0] -1/-1/-1->67->66 [1] -1/-1/-1->67->66
 72: hkn0423:1729386:1729506 [0] NCCL INFO Trees [0] 73/76/-1->72->81 [1] 73/-1/-1->72->69
 70: hkn0422:4177477:4177595 [2] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 71/-1/-1->70->69
 62: hkn0420:3234575:3234691 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61
 67: hkn0421:2208711:2208878 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 69: hkn0422:4177485:4177589 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 63: hkn0420:3234583:3234690 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62
 74: hkn0423:1729414:1729511 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] 75/-1/-1->74->73
 70: hkn0422:4177477:4177595 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 62: hkn0420:3234575:3234691 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 72: hkn0423:1729386:1729506 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 63: hkn0420:3234583:3234690 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 76: hkn0424:2972313:2972427 [0] NCCL INFO Trees [0] 77/-1/-1->76->72 [1] 77/68/-1->76->92
 74: hkn0423:1729414:1729511 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 61: hkn0420:3234595:3234696 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/92/-1->61->60
 76: hkn0424:2972313:2972427 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 75: hkn0423:1729394:1729515 [3] NCCL INFO Trees [0] -1/-1/-1->75->74 [1] -1/-1/-1->75->74
 60: hkn0420:3234567:3234693 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/28/-1->60->124
 60: hkn0420:3234567:3234693 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 75: hkn0423:1729394:1729515 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 61: hkn0420:3234595:3234696 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 73: hkn0423:1729402:1729514 [1] NCCL INFO Trees [0] 74/68/-1->73->72 [1] 74/-1/-1->73->72
 73: hkn0423:1729402:1729514 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 57: hkn0419:1568619:1568709 [1] NCCL INFO Trees [0] 58/52/-1->57->56 [1] 58/-1/-1->57->56
 57: hkn0419:1568619:1568709 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 77: hkn0424:2972305:2972428 [1] NCCL INFO Trees [0] 78/-1/-1->77->76 [1] 78/84/-1->77->76
 83: hkn0425:2108537:2108638 [3] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] -1/-1/-1->83->82
 59: hkn0419:1568607:1568710 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58
 59: hkn0419:1568607:1568710 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 78: hkn0424:2972321:2972426 [2] NCCL INFO Trees [0] 79/-1/-1->78->77 [1] 79/-1/-1->78->77
 78: hkn0424:2972321:2972426 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 83: hkn0425:2108537:2108638 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 84: hkn0426:838364:838519 [0] NCCL INFO Trees [0] 85/-1/-1->84->89 [1] 85/80/-1->84->77
 58: hkn0419:1568591:1568715 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57
 58: hkn0419:1568591:1568715 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 79: hkn0424:2972333:2972431 [3] NCCL INFO Trees [0] -1/-1/-1->79->78 [1] -1/-1/-1->79->78
 79: hkn0424:2972333:2972431 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 80: hkn0425:2108509:2108631 [0] NCCL INFO Trees [0] 81/88/-1->80->97 [1] 81/-1/-1->80->84
 84: hkn0426:838364:838519 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 56: hkn0419:1568599:1568716 [0] NCCL INFO Trees [0] 57/60/-1->56->48 [1] 57/-1/-1->56->53
 56: hkn0419:1568599:1568716 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 77: hkn0424:2972305:2972428 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 82: hkn0425:2108517:2108637 [2] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 83/-1/-1->82->81
 82: hkn0425:2108517:2108637 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 87: hkn0426:838380:838520 [3] NCCL INFO Trees [0] -1/-1/-1->87->86 [1] -1/-1/-1->87->86
 80: hkn0425:2108509:2108631 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 87: hkn0426:838380:838520 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 54: hkn0418:1893557:1893666 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53
 85: hkn0426:838392:838518 [1] NCCL INFO Trees [0] 86/-1/-1->85->84 [1] 86/88/-1->85->84
 55: hkn0418:1893549:1893663 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54
 47: hkn0415:2520751:2520864 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46
 50: hkn0417:2292055:2292170 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49
 50: hkn0417:2292055:2292170 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 85: hkn0426:838392:838518 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 54: hkn0418:1893557:1893666 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 81: hkn0425:2108525:2108632 [1] NCCL INFO Trees [0] 82/72/-1->81->80 [1] 82/-1/-1->81->80
 81: hkn0425:2108525:2108632 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 86: hkn0426:838372:838511 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] 87/-1/-1->86->85
 86: hkn0426:838372:838511 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 55: hkn0418:1893549:1893663 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 89: hkn0427:1159514:1159627 [1] NCCL INFO Trees [0] 90/84/-1->89->88 [1] 90/-1/-1->89->88
 53: hkn0418:1893541:1893660 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/56/-1->53->52
 53: hkn0418:1893541:1893660 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 47: hkn0415:2520751:2520864 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 89: hkn0427:1159514:1159627 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 52: hkn0418:1893569:1893661 [0] NCCL INFO Trees [0] 53/-1/-1->52->57 [1] 53/48/-1->52->45
 49: hkn0417:2292047:2292172 [1] NCCL INFO Trees [0] 50/40/-1->49->48 [1] 50/-1/-1->49->48
 90: hkn0427:1159498:1159622 [2] NCCL INFO Trees [0] 91/-1/-1->90->89 [1] 91/-1/-1->90->89
 52: hkn0418:1893569:1893661 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 45: hkn0415:2520743:2520858 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/52/-1->45->44
 51: hkn0417:2292063:2292173 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50
 90: hkn0427:1159498:1159622 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 43: hkn0414:2006106:2006225 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42
 49: hkn0417:2292047:2292172 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 88: hkn0427:1159526:1159625 [0] NCCL INFO Trees [0] 89/92/-1->88->80 [1] 89/-1/-1->88->85
 88: hkn0427:1159526:1159625 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 43: hkn0414:2006106:2006225 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 51: hkn0417:2292063:2292173 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 91: hkn0427:1159506:1159619 [3] NCCL INFO Trees [0] -1/-1/-1->91->90 [1] -1/-1/-1->91->90
 45: hkn0415:2520743:2520858 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 91: hkn0427:1159506:1159619 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 92: hkn0428:691744:691845 [0] NCCL INFO Trees [0] 93/-1/-1->92->88 [1] 93/76/-1->92->61
 92: hkn0428:691744:691845 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 46: hkn0415:2520763:2520859 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45
 93: hkn0428:691732:691841 [1] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 94/108/-1->93->92
 93: hkn0428:691732:691841 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 46: hkn0415:2520763:2520859 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 94: hkn0428:691716:691838 [2] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 95/-1/-1->94->93
 94: hkn0428:691716:691838 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 44: hkn0415:2520735:2520862 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/36/-1->44->29
 44: hkn0415:2520735:2520862 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 48: hkn0417:2292075:2292171 [0] NCCL INFO Trees [0] 49/56/-1->48->32 [1] 49/-1/-1->48->52
 95: hkn0428:691724:691842 [3] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] -1/-1/-1->95->94
 95: hkn0428:691724:691842 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 48: hkn0417:2292075:2292171 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 42: hkn0414:2006114:2006224 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41
134: hkn0510:2786427:2786528 [2] NCCL INFO Trees [0] 135/-1/-1->134->133 [1] 135/-1/-1->134->133
 42: hkn0414:2006114:2006224 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
134: hkn0510:2786427:2786528 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
133: hkn0510:2786407:2786523 [1] NCCL INFO Trees [0] 134/-1/-1->133->132 [1] 134/136/-1->133->132
131: hkn0509:3148767:3148876 [3] NCCL INFO Trees [0] -1/-1/-1->131->130 [1] -1/-1/-1->131->130
131: hkn0509:3148767:3148876 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 97: hkn0501:1352406:1352507 [1] NCCL INFO Trees [0] 98/80/-1->97->96 [1] 98/-1/-1->97->96
133: hkn0510:2786407:2786523 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 97: hkn0501:1352406:1352507 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
135: hkn0510:2786399:2786524 [3] NCCL INFO Trees [0] -1/-1/-1->135->134 [1] -1/-1/-1->135->134
 99: hkn0501:1352386:1352510 [3] NCCL INFO Trees [0] -1/-1/-1->99->98 [1] -1/-1/-1->99->98
135: hkn0510:2786399:2786524 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
130: hkn0509:3148779:3148872 [2] NCCL INFO Trees [0] 131/-1/-1->130->129 [1] 131/-1/-1->130->129
122: hkn0507:3211459:3211565 [2] NCCL INFO Trees [0] 123/-1/-1->122->121 [1] 123/-1/-1->122->121
132: hkn0510:2786415:2786525 [0] NCCL INFO Trees [0] 133/-1/-1->132->137 [1] 133/128/-1->132->140
130: hkn0509:3148779:3148872 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
118: hkn0506:862450:862548 [2] NCCL INFO Trees [0] 119/-1/-1->118->117 [1] 119/-1/-1->118->117
 99: hkn0501:1352386:1352510 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
132: hkn0510:2786415:2786525 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
101: hkn0502:253402:253515 [1] NCCL INFO Trees [0] 102/-1/-1->101->100 [1] 102/104/-1->101->100
136: hkn0511:3090885:3090991 [0] NCCL INFO Trees [0] 137/140/-1->136->145 [1] 137/-1/-1->136->133
107: hkn0503:2924178:2924282 [3] NCCL INFO Trees [0] -1/-1/-1->107->106 [1] -1/-1/-1->107->106
128: hkn0509:3148759:3148874 [0] NCCL INFO Trees [0] 129/192/-1->128->257 [1] 129/-1/-1->128->132
119: hkn0506:862430:862542 [3] NCCL INFO Trees [0] -1/-1/-1->119->118 [1] -1/-1/-1->119->118
 96: hkn0501:1352378:1352508 [0] NCCL INFO Trees [0] 97/112/-1->96->64 [1] 97/-1/-1->96->100
123: hkn0507:3211443:3211567 [3] NCCL INFO Trees [0] -1/-1/-1->123->122 [1] -1/-1/-1->123->122
102: hkn0502:253394:253516 [2] NCCL INFO Trees [0] 103/-1/-1->102->101 [1] 103/-1/-1->102->101
136: hkn0511:3090885:3090991 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
107: hkn0503:2924178:2924282 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
128: hkn0509:3148759:3148874 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
118: hkn0506:862450:862548 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 96: hkn0501:1352378:1352508 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
110: hkn0504:65463:65554 [2] NCCL INFO Trees [0] 111/-1/-1->110->109 [1] 111/-1/-1->110->109
122: hkn0507:3211459:3211565 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
101: hkn0502:253402:253515 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
104: hkn0503:2924170:2924284 [0] NCCL INFO Trees [0] 105/108/-1->104->113 [1] 105/-1/-1->104->101
104: hkn0503:2924170:2924284 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
129: hkn0509:3148751:3148873 [1] NCCL INFO Trees [0] 130/64/-1->129->128 [1] 130/-1/-1->129->128
119: hkn0506:862430:862542 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 98: hkn0501:1352394:1352503 [2] NCCL INFO Trees [0] 99/-1/-1->98->97 [1] 99/-1/-1->98->97
 98: hkn0501:1352394:1352503 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
112: hkn0505:2328135:2328264 [0] NCCL INFO Trees [0] 113/120/-1->112->96 [1] 113/-1/-1->112->116
109: hkn0504:65443:65560 [1] NCCL INFO Trees [0] 110/-1/-1->109->108 [1] 110/116/-1->109->108
123: hkn0507:3211443:3211567 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
102: hkn0502:253394:253516 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
124: hkn0508:3163506:3163602 [0] NCCL INFO Trees [0] 125/-1/-1->124->120 [1] 125/60/-1->124->252
139: hkn0511:3090869:3090995 [3] NCCL INFO Trees [0] -1/-1/-1->139->138 [1] -1/-1/-1->139->138
105: hkn0503:2924190:2924283 [1] NCCL INFO Trees [0] 106/100/-1->105->104 [1] 106/-1/-1->105->104
129: hkn0509:3148751:3148873 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
113: hkn0505:2328151:2328263 [1] NCCL INFO Trees [0] 114/104/-1->113->112 [1] 114/-1/-1->113->112
110: hkn0504:65463:65554 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
121: hkn0507:3211451:3211566 [1] NCCL INFO Trees [0] 122/116/-1->121->120 [1] 122/-1/-1->121->120
121: hkn0507:3211451:3211566 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
103: hkn0502:253410:253517 [3] NCCL INFO Trees [0] -1/-1/-1->103->102 [1] -1/-1/-1->103->102
125: hkn0508:3163494:3163603 [1] NCCL INFO Trees [0] 126/-1/-1->125->124 [1] 126/188/-1->125->124
139: hkn0511:3090869:3090995 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
106: hkn0503:2924162:2924287 [2] NCCL INFO Trees [0] 107/-1/-1->106->105 [1] 107/-1/-1->106->105
106: hkn0503:2924162:2924287 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
117: hkn0506:862422:862551 [1] NCCL INFO Trees [0] 118/-1/-1->117->116 [1] 118/120/-1->117->116
112: hkn0505:2328135:2328264 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
109: hkn0504:65443:65560 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
120: hkn0507:3211471:3211570 [0] NCCL INFO Trees [0] 121/124/-1->120->112 [1] 121/-1/-1->120->117
100: hkn0502:253422:253519 [0] NCCL INFO Trees [0] 101/-1/-1->100->105 [1] 101/96/-1->100->108
126: hkn0508:3163478:3163601 [2] NCCL INFO Trees [0] 127/-1/-1->126->125 [1] 127/-1/-1->126->125
138: hkn0511:3090897:3090992 [2] NCCL INFO Trees [0] 139/-1/-1->138->137 [1] 139/-1/-1->138->137
105: hkn0503:2924190:2924283 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
117: hkn0506:862422:862551 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
113: hkn0505:2328151:2328263 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 40: hkn0414:2006126:2006221 [0] NCCL INFO Trees [0] 41/44/-1->40->49 [1] 41/-1/-1->40->37
108: hkn0504:65435:65559 [0] NCCL INFO Trees [0] 109/-1/-1->108->104 [1] 109/100/-1->108->93
 34: hkn0412:2286727:2286850 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33
120: hkn0507:3211471:3211570 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 37: hkn0413:2391086:2391193 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/40/-1->37->36
103: hkn0502:253410:253517 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
127: hkn0508:3163486:3163600 [3] NCCL INFO Trees [0] -1/-1/-1->127->126 [1] -1/-1/-1->127->126
138: hkn0511:3090897:3090992 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
116: hkn0506:862438:862546 [0] NCCL INFO Trees [0] 117/-1/-1->116->121 [1] 117/112/-1->116->109
114: hkn0505:2328143:2328257 [2] NCCL INFO Trees [0] 115/-1/-1->114->113 [1] 115/-1/-1->114->113
114: hkn0505:2328143:2328257 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 41: hkn0414:2006098:2006227 [1] NCCL INFO Trees [0] 42/36/-1->41->40 [1] 42/-1/-1->41->40
111: hkn0504:65451:65555 [3] NCCL INFO Trees [0] -1/-1/-1->111->110 [1] -1/-1/-1->111->110
111: hkn0504:65451:65555 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 34: hkn0412:2286727:2286850 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 37: hkn0413:2391086:2391193 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
100: hkn0502:253422:253519 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
124: hkn0508:3163506:3163602 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
137: hkn0511:3090877:3090993 [1] NCCL INFO Trees [0] 138/132/-1->137->136 [1] 138/-1/-1->137->136
137: hkn0511:3090877:3090993 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
116: hkn0506:862438:862546 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
115: hkn0505:2328163:2328258 [3] NCCL INFO Trees [0] -1/-1/-1->115->114 [1] -1/-1/-1->115->114
 40: hkn0414:2006126:2006221 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
108: hkn0504:65435:65559 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
125: hkn0508:3163494:3163603 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
493: hkn0810:963905:964027 [1] NCCL INFO Trees [0] 494/-1/-1->493->492 [1] 494/500/-1->493->492
115: hkn0505:2328163:2328258 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 41: hkn0414:2006098:2006227 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 35: hkn0412:2286751:2286844 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34
 38: hkn0413:2391078:2391198 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37
 38: hkn0413:2391078:2391198 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
126: hkn0508:3163478:3163601 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
491: hkn0809:961660:961772 [3] NCCL INFO Trees [0] -1/-1/-1->491->490 [1] -1/-1/-1->491->490
495: hkn0810:963921:964028 [3] NCCL INFO Trees [0] -1/-1/-1->495->494 [1] -1/-1/-1->495->494
 35: hkn0412:2286751:2286844 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
141: hkn0512:3068462:3068573 [1] NCCL INFO Trees [0] 142/-1/-1->141->140 [1] 142/148/-1->141->140
 39: hkn0413:2391070:2391199 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38
 39: hkn0413:2391070:2391199 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 30: hkn0411:2340293:2340389 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29
127: hkn0508:3163486:3163600 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
493: hkn0810:963905:964027 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 33: hkn0412:2286731:2286842 [1] NCCL INFO Trees [0] 34/16/-1->33->32 [1] 34/-1/-1->33->32
141: hkn0512:3068462:3068573 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
325: hkn0634:1545237:1545343 [1] NCCL INFO Trees [0] 326/-1/-1->325->324 [1] 326/328/-1->325->324
 36: hkn0413:2391098:2391192 [0] NCCL INFO Trees [0] 37/-1/-1->36->41 [1] 37/32/-1->36->44
 36: hkn0413:2391098:2391192 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 31: hkn0411:2340265:2340393 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30
491: hkn0809:961660:961772 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
494: hkn0810:963913:964023 [2] NCCL INFO Trees [0] 495/-1/-1->494->493 [1] 495/-1/-1->494->493
 32: hkn0412:2286739:2286849 [0] NCCL INFO Trees [0] 33/48/-1->32->65 [1] 33/-1/-1->32->36
143: hkn0512:3068470:3068579 [3] NCCL INFO Trees [0] -1/-1/-1->143->142 [1] -1/-1/-1->143->142
 30: hkn0411:2340293:2340389 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
495: hkn0810:963921:964028 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 33: hkn0412:2286731:2286842 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
143: hkn0512:3068470:3068579 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 31: hkn0411:2340265:2340393 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
494: hkn0810:963913:964023 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 32: hkn0412:2286739:2286849 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
325: hkn0634:1545237:1545343 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
492: hkn0810:963933:964030 [0] NCCL INFO Trees [0] 493/-1/-1->492->488 [1] 493/484/-1->492->477
323: hkn0633:1550641:1550758 [3] NCCL INFO Trees [0] -1/-1/-1->323->322 [1] -1/-1/-1->323->322
140: hkn0512:3068482:3068576 [0] NCCL INFO Trees [0] 141/-1/-1->140->136 [1] 141/132/-1->140->156
327: hkn0634:1545249:1545346 [3] NCCL INFO Trees [0] -1/-1/-1->327->326 [1] -1/-1/-1->327->326
492: hkn0810:963933:964030 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
323: hkn0633:1550641:1550758 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
140: hkn0512:3068482:3068576 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
145: hkn0513:3037331:3037435 [1] NCCL INFO Trees [0] 146/136/-1->145->144 [1] 146/-1/-1->145->144
327: hkn0634:1545249:1545346 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
497: hkn0812:718229:718349 [1] NCCL INFO Trees [0] 498/488/-1->497->496 [1] 498/-1/-1->497->496
322: hkn0633:1550649:1550756 [2] NCCL INFO Trees [0] 323/-1/-1->322->321 [1] 323/-1/-1->322->321
142: hkn0512:3068454:3068574 [2] NCCL INFO Trees [0] 143/-1/-1->142->141 [1] 143/-1/-1->142->141
145: hkn0513:3037331:3037435 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
326: hkn0634:1545229:1545344 [2] NCCL INFO Trees [0] 327/-1/-1->326->325 [1] 327/-1/-1->326->325
326: hkn0634:1545229:1545344 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
488: hkn0809:961652:961773 [0] NCCL INFO Trees [0] 489/492/-1->488->497 [1] 489/-1/-1->488->485
488: hkn0809:961652:961773 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
497: hkn0812:718229:718349 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
322: hkn0633:1550649:1550756 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
142: hkn0512:3068454:3068574 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
147: hkn0513:3037315:3037440 [3] NCCL INFO Trees [0] -1/-1/-1->147->146 [1] -1/-1/-1->147->146
324: hkn0634:1545221:1545345 [0] NCCL INFO Trees [0] 325/-1/-1->324->329 [1] 325/320/-1->324->332
149: hkn0514:2975087:2975198 [1] NCCL INFO Trees [0] 150/-1/-1->149->148 [1] 150/152/-1->149->148
498: hkn0812:718237:718348 [2] NCCL INFO Trees [0] 499/-1/-1->498->497 [1] 499/-1/-1->498->497
147: hkn0513:3037315:3037440 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
324: hkn0634:1545221:1545345 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
499: hkn0812:718257:718355 [3] NCCL INFO Trees [0] -1/-1/-1->499->498 [1] -1/-1/-1->499->498
146: hkn0513:3037323:3037444 [2] NCCL INFO Trees [0] 147/-1/-1->146->145 [1] 147/-1/-1->146->145
329: hkn0635:1249898:1250021 [1] NCCL INFO Trees [0] 330/324/-1->329->328 [1] 330/-1/-1->329->328
149: hkn0514:2975087:2975198 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
490: hkn0809:961680:961778 [2] NCCL INFO Trees [0] 491/-1/-1->490->489 [1] 491/-1/-1->490->489
490: hkn0809:961680:961778 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
498: hkn0812:718237:718348 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
146: hkn0513:3037323:3037444 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
330: hkn0635:1249906:1250023 [2] NCCL INFO Trees [0] 331/-1/-1->330->329 [1] 331/-1/-1->330->329
150: hkn0514:2975099:2975195 [2] NCCL INFO Trees [0] 151/-1/-1->150->149 [1] 151/-1/-1->150->149
489: hkn0809:961668:961775 [1] NCCL INFO Trees [0] 490/484/-1->489->488 [1] 490/-1/-1->489->488
499: hkn0812:718257:718355 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
144: hkn0513:3037343:3037441 [0] NCCL INFO Trees [0] 145/152/-1->144->161 [1] 145/-1/-1->144->148
329: hkn0635:1249898:1250021 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
150: hkn0514:2975099:2975195 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
332: hkn0636:1678716:1678871 [0] NCCL INFO Trees [0] 333/-1/-1->332->328 [1] 333/324/-1->332->348
489: hkn0809:961668:961775 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
496: hkn0812:718245:718354 [0] NCCL INFO Trees [0] 497/504/-1->496->480 [1] 497/-1/-1->496->500
487: hkn0808:995030:995156 [3] NCCL INFO Trees [0] -1/-1/-1->487->486 [1] -1/-1/-1->487->486
144: hkn0513:3037343:3037441 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
330: hkn0635:1249906:1250023 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
148: hkn0514:2975079:2975202 [0] NCCL INFO Trees [0] 149/-1/-1->148->153 [1] 149/144/-1->148->141
332: hkn0636:1678716:1678871 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
152: hkn0515:2921174:2921332 [0] NCCL INFO Trees [0] 153/156/-1->152->144 [1] 153/-1/-1->152->149
482: hkn0807:1043406:1043538 [2] NCCL INFO Trees [0] 483/-1/-1->482->481 [1] 483/-1/-1->482->481
496: hkn0812:718245:718354 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
487: hkn0808:995030:995156 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
321: hkn0633:1550661:1550752 [1] NCCL INFO Trees [0] 322/288/-1->321->320 [1] 322/-1/-1->321->320
321: hkn0633:1550661:1550752 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
331: hkn0635:1249914:1250018 [3] NCCL INFO Trees [0] -1/-1/-1->331->330 [1] -1/-1/-1->331->330
 29: hkn0411:2340273:2340391 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/44/-1->29->28
151: hkn0514:2975071:2975199 [3] NCCL INFO Trees [0] -1/-1/-1->151->150 [1] -1/-1/-1->151->150
334: hkn0636:1678724:1678867 [2] NCCL INFO Trees [0] 335/-1/-1->334->333 [1] 335/-1/-1->334->333
500: hkn0814:700164:700310 [0] NCCL INFO Trees [0] 501/-1/-1->500->505 [1] 501/496/-1->500->493
152: hkn0515:2921174:2921332 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
482: hkn0807:1043406:1043538 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
479: hkn0806:1078660:1078785 [3] NCCL INFO Trees [0] -1/-1/-1->479->478 [1] -1/-1/-1->479->478
328: hkn0635:1249926:1250020 [0] NCCL INFO Trees [0] 329/332/-1->328->337 [1] 329/-1/-1->328->325
328: hkn0635:1249926:1250020 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 29: hkn0411:2340273:2340391 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
148: hkn0514:2975079:2975202 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
333: hkn0636:1678744:1678868 [1] NCCL INFO Trees [0] 334/-1/-1->333->332 [1] 334/340/-1->333->332
333: hkn0636:1678744:1678868 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
500: hkn0814:700164:700310 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
479: hkn0806:1078660:1078785 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
331: hkn0635:1249914:1250018 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
151: hkn0514:2975071:2975199 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
334: hkn0636:1678724:1678867 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
481: hkn0807:1043434:1043534 [1] NCCL INFO Trees [0] 482/464/-1->481->480 [1] 482/-1/-1->481->480
320: hkn0633:1550633:1550753 [0] NCCL INFO Trees [0] 321/352/-1->320->385 [1] 321/-1/-1->320->324
335: hkn0636:1678732:1678872 [3] NCCL INFO Trees [0] -1/-1/-1->335->334 [1] -1/-1/-1->335->334
335: hkn0636:1678732:1678872 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
480: hkn0807:1043422:1043530 [0] NCCL INFO Trees [0] 481/496/-1->480->448 [1] 481/-1/-1->480->484
478: hkn0806:1078688:1078789 [2] NCCL INFO Trees [0] 479/-1/-1->478->477 [1] 479/-1/-1->478->477
485: hkn0808:995038:995153 [1] NCCL INFO Trees [0] 486/-1/-1->485->484 [1] 486/488/-1->485->484
481: hkn0807:1043434:1043534 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
478: hkn0806:1078688:1078789 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
485: hkn0808:995038:995153 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
319: hkn0632:1782991:1783084 [3] NCCL INFO Trees [0] -1/-1/-1->319->318 [1] -1/-1/-1->319->318
315: hkn0631:1046171:1046285 [3] NCCL INFO Trees [0] -1/-1/-1->315->314 [1] -1/-1/-1->315->314
320: hkn0633:1550633:1550753 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
501: hkn0814:700172:700309 [1] NCCL INFO Trees [0] 502/-1/-1->501->500 [1] 502/504/-1->501->500
505: hkn0815:419461:419585 [1] NCCL INFO Trees [0] 506/500/-1->505->504 [1] 506/-1/-1->505->504
480: hkn0807:1043422:1043530 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
477: hkn0806:1078668:1078787 [1] NCCL INFO Trees [0] 478/-1/-1->477->476 [1] 478/492/-1->477->476
486: hkn0808:995058:995152 [2] NCCL INFO Trees [0] 487/-1/-1->486->485 [1] 487/-1/-1->486->485
315: hkn0631:1046171:1046285 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
511: hkn0816:399934:400048 [3] NCCL INFO Trees [0] -1/-1/-1->511->510 [1] -1/-1/-1->511->510
153: hkn0515:2921190:2921327 [1] NCCL INFO Trees [0] 154/148/-1->153->152 [1] 154/-1/-1->153->152
153: hkn0515:2921190:2921327 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
506: hkn0815:419477:419589 [2] NCCL INFO Trees [0] 507/-1/-1->506->505 [1] 507/-1/-1->506->505
477: hkn0806:1078668:1078787 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
486: hkn0808:995058:995152 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
410: hkn0723:232552:232722 [2] NCCL INFO Trees [0] 411/-1/-1->410->409 [1] 411/-1/-1->410->409
314: hkn0631:1046179:1046288 [2] NCCL INFO Trees [0] 315/-1/-1->314->313 [1] 315/-1/-1->314->313
361: hkn0710:379895:380014 [1] NCCL INFO Trees [0] 362/356/-1->361->360 [1] 362/-1/-1->361->360
310: hkn0630:1622852:1622969 [2] NCCL INFO Trees [0] 311/-1/-1->310->309 [1] 311/-1/-1->310->309
501: hkn0814:700172:700309 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
154: hkn0515:2921182:2921328 [2] NCCL INFO Trees [0] 155/-1/-1->154->153 [1] 155/-1/-1->154->153
505: hkn0815:419461:419585 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
483: hkn0807:1043414:1043536 [3] NCCL INFO Trees [0] -1/-1/-1->483->482 [1] -1/-1/-1->483->482
483: hkn0807:1043414:1043536 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
476: hkn0806:1078676:1078786 [0] NCCL INFO Trees [0] 477/-1/-1->476->472 [1] 477/460/-1->476->445
476: hkn0806:1078676:1078786 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
484: hkn0808:995046:995154 [0] NCCL INFO Trees [0] 485/-1/-1->484->489 [1] 485/480/-1->484->492
319: hkn0632:1782991:1783084 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
304: hkn0629:1616359:1616509 [0] NCCL INFO Trees [0] 305/312/-1->304->288 [1] 305/-1/-1->304->308
474: hkn0805:1136461:1136592 [2] NCCL INFO Trees [0] 475/-1/-1->474->473 [1] 475/-1/-1->474->473
314: hkn0631:1046179:1046288 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
363: hkn0710:379887:380008 [3] NCCL INFO Trees [0] -1/-1/-1->363->362 [1] -1/-1/-1->363->362
302: hkn0628:696364:696481 [2] NCCL INFO Trees [0] 303/-1/-1->302->301 [1] 303/-1/-1->302->301
302: hkn0628:696364:696481 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
406: hkn0721:2323879:2323993 [2] NCCL INFO Trees [0] 407/-1/-1->406->405 [1] 407/-1/-1->406->405
510: hkn0816:399918:400045 [2] NCCL INFO Trees [0] 511/-1/-1->510->509 [1] 511/-1/-1->510->509
510: hkn0816:399918:400045 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
310: hkn0630:1622852:1622969 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
502: hkn0814:700184:700311 [2] NCCL INFO Trees [0] 503/-1/-1->502->501 [1] 503/-1/-1->502->501
502: hkn0814:700184:700311 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
155: hkn0515:2921202:2921330 [3] NCCL INFO Trees [0] -1/-1/-1->155->154 [1] -1/-1/-1->155->154
506: hkn0815:419477:419589 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
484: hkn0808:995046:995154 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
318: hkn0632:1782963:1783087 [2] NCCL INFO Trees [0] 319/-1/-1->318->317 [1] 319/-1/-1->318->317
474: hkn0805:1136461:1136592 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
313: hkn0631:1046163:1046282 [1] NCCL INFO Trees [0] 314/308/-1->313->312 [1] 314/-1/-1->313->312
361: hkn0710:379895:380014 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
406: hkn0721:2323879:2323993 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
336: hkn0703:765538:765661 [0] NCCL INFO Trees [0] 337/344/-1->336->353 [1] 337/-1/-1->336->340
511: hkn0816:399934:400048 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
311: hkn0630:1622872:1622968 [3] NCCL INFO Trees [0] -1/-1/-1->311->310 [1] -1/-1/-1->311->310
503: hkn0814:700156:700314 [3] NCCL INFO Trees [0] -1/-1/-1->503->502 [1] -1/-1/-1->503->502
503: hkn0814:700156:700314 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
154: hkn0515:2921182:2921328 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
507: hkn0815:419489:419590 [3] NCCL INFO Trees [0] -1/-1/-1->507->506 [1] -1/-1/-1->507->506
421: hkn0726:1572490:1572596 [1] NCCL INFO Trees [0] 422/-1/-1->421->420 [1] 422/424/-1->421->420
421: hkn0726:1572490:1572596 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
418: hkn0725:3136324:3136423 [2] NCCL INFO Trees [0] 419/-1/-1->418->417 [1] 419/-1/-1->418->417
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 00/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
316: hkn0632:1782979:1783083 [0] NCCL INFO Trees [0] 317/-1/-1->316->312 [1] 317/284/-1->316->380
307: hkn0629:1616387:1616511 [3] NCCL INFO Trees [0] -1/-1/-1->307->306 [1] -1/-1/-1->307->306
307: hkn0629:1616387:1616511 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
473: hkn0805:1136469:1136586 [1] NCCL INFO Trees [0] 474/468/-1->473->472 [1] 474/-1/-1->473->472
473: hkn0805:1136469:1136586 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
313: hkn0631:1046163:1046282 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
363: hkn0710:379887:380008 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
407: hkn0721:2323889:2323992 [3] NCCL INFO Trees [0] -1/-1/-1->407->406 [1] -1/-1/-1->407->406
336: hkn0703:765538:765661 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
509: hkn0816:399926:400042 [1] NCCL INFO Trees [0] 510/-1/-1->509->508 [1] 510/-1/-1->509->508
509: hkn0816:399926:400042 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
427: hkn0727:1370167:1370284 [3] NCCL INFO Trees [0] -1/-1/-1->427->426 [1] -1/-1/-1->427->426
311: hkn0630:1622872:1622968 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
155: hkn0515:2921202:2921330 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
414: hkn0724:1740337:1740474 [2] NCCL INFO Trees [0] 415/-1/-1->414->413 [1] 415/-1/-1->414->413
507: hkn0815:419489:419590 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
393: hkn0718:3941419:3941544 [1] NCCL INFO Trees [0] 394/388/-1->393->392 [1] 394/-1/-1->393->392
431: hkn0728:1348489:1348596 [3] NCCL INFO Trees [0] -1/-1/-1->431->430 [1] -1/-1/-1->431->430
423: hkn0726:1572482:1572597 [3] NCCL INFO Trees [0] -1/-1/-1->423->422 [1] -1/-1/-1->423->422
423: hkn0726:1572482:1572597 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
418: hkn0725:3136324:3136423 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
318: hkn0632:1782963:1783087 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
304: hkn0629:1616359:1616509 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
475: hkn0805:1136477:1136585 [3] NCCL INFO Trees [0] -1/-1/-1->475->474 [1] -1/-1/-1->475->474
411: hkn0723:232580:232725 [3] NCCL INFO Trees [0] -1/-1/-1->411->410 [1] -1/-1/-1->411->410
312: hkn0631:1046191:1046283 [0] NCCL INFO Trees [0] 313/316/-1->312->304 [1] 313/-1/-1->312->309
362: hkn0710:379915:380012 [2] NCCL INFO Trees [0] 363/-1/-1->362->361 [1] 363/-1/-1->362->361
303: hkn0628:696380:696485 [3] NCCL INFO Trees [0] -1/-1/-1->303->302 [1] -1/-1/-1->303->302
407: hkn0721:2323889:2323992 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
338: hkn0703:765558:765658 [2] NCCL INFO Trees [0] 339/-1/-1->338->337 [1] 339/-1/-1->338->337
365: hkn0711:608392:608506 [1] NCCL INFO Trees [0] 366/-1/-1->365->364 [1] 366/372/-1->365->364
340: hkn0704:816342:816447 [0] NCCL INFO Trees [0] 341/-1/-1->340->345 [1] 341/336/-1->340->333
340: hkn0704:816342:816447 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
508: hkn0816:399946:400046 [0] NCCL INFO Trees [0] 509/-1/-1->508->504 [1] 509/252/-1->508->-1
427: hkn0727:1370167:1370284 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
345: hkn0705:807558:807678 [1] NCCL INFO Trees [0] 346/340/-1->345->344 [1] 346/-1/-1->345->344
309: hkn0630:1622860:1622960 [1] NCCL INFO Trees [0] 310/-1/-1->309->308 [1] 310/312/-1->309->308
359: hkn0708:437591:437704 [3] NCCL INFO Trees [0] -1/-1/-1->359->358 [1] -1/-1/-1->359->358
504: hkn0815:419469:419586 [0] NCCL INFO Trees [0] 505/508/-1->504->496 [1] 505/-1/-1->504->501
469: hkn0804:1230034:1230144 [1] NCCL INFO Trees [0] 470/-1/-1->469->468 [1] 470/472/-1->469->468
469: hkn0804:1230034:1230144 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
393: hkn0718:3941419:3941544 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
431: hkn0728:1348489:1348596 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
422: hkn0726:1572474:1572594 [2] NCCL INFO Trees [0] 423/-1/-1->422->421 [1] 423/-1/-1->422->421
422: hkn0726:1572474:1572594 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
416: hkn0725:3136304:3136419 [0] NCCL INFO Trees [0] 417/432/-1->416->449 [1] 417/-1/-1->416->420
416: hkn0725:3136304:3136419 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 01/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
316: hkn0632:1782979:1783083 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
306: hkn0629:1616375:1616505 [2] NCCL INFO Trees [0] 307/-1/-1->306->305 [1] 307/-1/-1->306->305
475: hkn0805:1136477:1136585 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
435: hkn0730:1426037:1426189 [3] NCCL INFO Trees [0] -1/-1/-1->435->434 [1] -1/-1/-1->435->434
409: hkn0723:232568:232721 [1] NCCL INFO Trees [0] 410/404/-1->409->408 [1] 410/-1/-1->409->408
312: hkn0631:1046191:1046283 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
362: hkn0710:379915:380012 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
303: hkn0628:696380:696485 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
350: hkn0706:776596:776723 [2] NCCL INFO Trees [0] 351/-1/-1->350->349 [1] 351/-1/-1->350->349
404: hkn0721:2323901:2323996 [0] NCCL INFO Trees [0] 405/-1/-1->404->409 [1] 405/400/-1->404->397
370: hkn0712:319448:319543 [2] NCCL INFO Trees [0] 371/-1/-1->370->369 [1] 371/-1/-1->370->369
370: hkn0712:319448:319543 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
338: hkn0703:765558:765658 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
366: hkn0711:608384:608505 [2] NCCL INFO Trees [0] 367/-1/-1->366->365 [1] 367/-1/-1->366->365
341: hkn0704:816354:816450 [1] NCCL INFO Trees [0] 342/-1/-1->341->340 [1] 342/344/-1->341->340
341: hkn0704:816354:816450 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
508: hkn0816:399946:400046 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
425: hkn0727:1370175:1370283 [1] NCCL INFO Trees [0] 426/420/-1->425->424 [1] 426/-1/-1->425->424
425: hkn0727:1370175:1370283 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
346: hkn0705:807578:807672 [2] NCCL INFO Trees [0] 347/-1/-1->346->345 [1] 347/-1/-1->346->345
309: hkn0630:1622860:1622960 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
412: hkn0724:1740321:1740477 [0] NCCL INFO Trees [0] 413/-1/-1->412->408 [1] 413/396/-1->412->444
504: hkn0815:419469:419586 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
471: hkn0804:1230026:1230141 [3] NCCL INFO Trees [0] -1/-1/-1->471->470 [1] -1/-1/-1->471->470
395: hkn0718:3941427:3941539 [3] NCCL INFO Trees [0] -1/-1/-1->395->394 [1] -1/-1/-1->395->394
428: hkn0728:1348473:1348595 [0] NCCL INFO Trees [0] 429/-1/-1->428->424 [1] 429/420/-1->428->413
428: hkn0728:1348473:1348595 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
420: hkn0726:1572502:1572595 [0] NCCL INFO Trees [0] 421/-1/-1->420->425 [1] 421/416/-1->420->428
420: hkn0726:1572502:1572595 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
417: hkn0725:3136312:3136416 [1] NCCL INFO Trees [0] 418/400/-1->417->416 [1] 418/-1/-1->417->416
417: hkn0725:3136312:3136416 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
396: hkn0719:1330279:1330367 [0] NCCL INFO Trees [0] 397/-1/-1->396->392 [1] 397/388/-1->396->412
  1: hkn0403:1808437:1808809 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
317: hkn0632:1782971:1783088 [1] NCCL INFO Trees [0] 318/-1/-1->317->316 [1] 318/348/-1->317->316
317: hkn0632:1782971:1783088 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
306: hkn0629:1616375:1616505 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
472: hkn0805:1136489:1136590 [0] NCCL INFO Trees [0] 473/476/-1->472->464 [1] 473/-1/-1->472->469
435: hkn0730:1426037:1426189 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
410: hkn0723:232552:232722 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
360: hkn0710:379903:380006 [0] NCCL INFO Trees [0] 361/364/-1->360->369 [1] 361/-1/-1->360->357
350: hkn0706:776596:776723 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
404: hkn0721:2323901:2323996 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
368: hkn0712:319436:319546 [0] NCCL INFO Trees [0] 369/376/-1->368->352 [1] 369/-1/-1->368->372
368: hkn0712:319436:319546 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
159: hkn0516:2940322:2940429 [3] NCCL INFO Trees [0] -1/-1/-1->159->158 [1] -1/-1/-1->159->158
339: hkn0703:765530:765656 [3] NCCL INFO Trees [0] -1/-1/-1->339->338 [1] -1/-1/-1->339->338
339: hkn0703:765530:765656 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
365: hkn0711:608392:608506 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
342: hkn0704:816326:816455 [2] NCCL INFO Trees [0] 343/-1/-1->342->341 [1] 343/-1/-1->342->341
342: hkn0704:816326:816455 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
426: hkn0727:1370159:1370281 [2] NCCL INFO Trees [0] 427/-1/-1->426->425 [1] 427/-1/-1->426->425
426: hkn0727:1370159:1370281 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
402: hkn0720:33772:33907 [2] NCCL INFO Trees [0] 403/-1/-1->402->401 [1] 403/-1/-1->402->401
345: hkn0705:807558:807678 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
308: hkn0630:1622844:1622963 [0] NCCL INFO Trees [0] 309/-1/-1->308->313 [1] 309/304/-1->308->301
414: hkn0724:1740337:1740474 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
471: hkn0804:1230026:1230141 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
395: hkn0718:3941427:3941539 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
429: hkn0728:1348481:1348599 [1] NCCL INFO Trees [0] 430/-1/-1->429->428 [1] 430/436/-1->429->428
419: hkn0725:3136296:3136421 [3] NCCL INFO Trees [0] -1/-1/-1->419->418 [1] -1/-1/-1->419->418
419: hkn0725:3136296:3136421 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
396: hkn0719:1330279:1330367 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
466: hkn0803:900986:901105 [2] NCCL INFO Trees [0] 467/-1/-1->466->465 [1] 467/-1/-1->466->465
  1: hkn0403:1808437:1808809 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
295: hkn0626:1322790:1322933 [3] NCCL INFO Trees [0] -1/-1/-1->295->294 [1] -1/-1/-1->295->294
305: hkn0629:1616367:1616506 [1] NCCL INFO Trees [0] 306/296/-1->305->304 [1] 306/-1/-1->305->304
472: hkn0805:1136489:1136590 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
433: hkn0730:1426045:1426192 [1] NCCL INFO Trees [0] 434/424/-1->433->432 [1] 434/-1/-1->433->432
411: hkn0723:232580:232725 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
360: hkn0710:379903:380006 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
351: hkn0706:776604:776726 [3] NCCL INFO Trees [0] -1/-1/-1->351->350 [1] -1/-1/-1->351->350
405: hkn0721:2323871:2323991 [1] NCCL INFO Trees [0] 406/-1/-1->405->404 [1] 406/408/-1->405->404
298: hkn0627:1812322:1812413 [2] NCCL INFO Trees [0] 299/-1/-1->298->297 [1] 299/-1/-1->298->297
371: hkn0712:319428:319537 [3] NCCL INFO Trees [0] -1/-1/-1->371->370 [1] -1/-1/-1->371->370
371: hkn0712:319428:319537 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
159: hkn0516:2940322:2940429 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
337: hkn0703:765546:765657 [1] NCCL INFO Trees [0] 338/328/-1->337->336 [1] 338/-1/-1->337->336
  4: hkn0404:1363862:1363969 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/0/-1->4->12
366: hkn0711:608384:608505 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
343: hkn0704:816334:816453 [3] NCCL INFO Trees [0] -1/-1/-1->343->342 [1] -1/-1/-1->343->342
343: hkn0704:816334:816453 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
354: hkn0707:4044308:4044418 [2] NCCL INFO Trees [0] 355/-1/-1->354->353 [1] 355/-1/-1->354->353
161: hkn0520:2737231:2737367 [1] NCCL INFO Trees [0] 162/144/-1->161->160 [1] 162/-1/-1->161->160
424: hkn0727:1370187:1370280 [0] NCCL INFO Trees [0] 425/428/-1->424->433 [1] 425/-1/-1->424->421
424: hkn0727:1370187:1370280 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
403: hkn0720:33744:33905 [3] NCCL INFO Trees [0] -1/-1/-1->403->402 [1] -1/-1/-1->403->402
346: hkn0705:807578:807672 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
308: hkn0630:1622844:1622963 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
359: hkn0708:437591:437704 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
412: hkn0724:1740321:1740477 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
391: hkn0717:19437:19568 [3] NCCL INFO Trees [0] -1/-1/-1->391->390 [1] -1/-1/-1->391->390
470: hkn0804:1230046:1230140 [2] NCCL INFO Trees [0] 471/-1/-1->470->469 [1] 471/-1/-1->470->469
470: hkn0804:1230046:1230140 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
394: hkn0718:3941447:3941548 [2] NCCL INFO Trees [0] 395/-1/-1->394->393 [1] 395/-1/-1->394->393
430: hkn0728:1348501:1348594 [2] NCCL INFO Trees [0] 431/-1/-1->430->429 [1] 431/-1/-1->430->429
430: hkn0728:1348501:1348594 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
399: hkn0719:1330267:1330376 [3] NCCL INFO Trees [0] -1/-1/-1->399->398 [1] -1/-1/-1->399->398
467: hkn0803:900994:901110 [3] NCCL INFO Trees [0] -1/-1/-1->467->466 [1] -1/-1/-1->467->466
  0: hkn0403:1808436:1808801 [0] NCCL INFO Trees [0] 1/256/-1->0->-1 [1] 1/-1/-1->0->4
295: hkn0626:1322790:1322933 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
305: hkn0629:1616367:1616506 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
433: hkn0730:1426045:1426192 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
409: hkn0723:232568:232721 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
351: hkn0706:776604:776726 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
405: hkn0721:2323871:2323991 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
369: hkn0712:319420:319542 [1] NCCL INFO Trees [0] 370/360/-1->369->368 [1] 370/-1/-1->369->368
369: hkn0712:319420:319542 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 26: hkn0410:1184027:1184146 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25
157: hkn0516:2940314:2940436 [1] NCCL INFO Trees [0] 158/-1/-1->157->156 [1] 158/172/-1->157->156
337: hkn0703:765546:765657 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
436: hkn0731:1411088:1411212 [0] NCCL INFO Trees [0] 437/-1/-1->436->441 [1] 437/432/-1->436->429
436: hkn0731:1411088:1411212 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  4: hkn0404:1363862:1363969 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
367: hkn0711:608376:608500 [3] NCCL INFO Trees [0] -1/-1/-1->367->366 [1] -1/-1/-1->367->366
355: hkn0707:4044292:4044419 [3] NCCL INFO Trees [0] -1/-1/-1->355->354 [1] -1/-1/-1->355->354
161: hkn0520:2737231:2737367 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 28: hkn0411:2340281:2340396 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/12/-1->28->60
463: hkn0802:1224700:1224850 [3] NCCL INFO Trees [0] -1/-1/-1->463->462 [1] -1/-1/-1->463->462
402: hkn0720:33772:33907 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
344: hkn0705:807566:807679 [0] NCCL INFO Trees [0] 345/348/-1->344->336 [1] 345/-1/-1->344->341
344: hkn0705:807566:807679 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
358: hkn0708:437599:437701 [2] NCCL INFO Trees [0] 359/-1/-1->358->357 [1] 359/-1/-1->358->357
372: hkn0713:494598:494713 [0] NCCL INFO Trees [0] 373/-1/-1->372->377 [1] 373/368/-1->372->365
413: hkn0724:1740329:1740471 [1] NCCL INFO Trees [0] 414/-1/-1->413->412 [1] 414/428/-1->413->412
468: hkn0804:1230018:1230142 [0] NCCL INFO Trees [0] 469/-1/-1->468->473 [1] 469/464/-1->468->461
394: hkn0718:3941447:3941548 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
429: hkn0728:1348481:1348599 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
399: hkn0719:1330267:1330376 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
466: hkn0803:900986:901105 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  3: hkn0403:1808445:1808808 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
 19: hkn0408:2915270:2915393 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18
294: hkn0626:1322810:1322935 [2] NCCL INFO Trees [0] 295/-1/-1->294->293 [1] 295/-1/-1->294->293
434: hkn0730:1426053:1426183 [2] NCCL INFO Trees [0] 435/-1/-1->434->433 [1] 435/-1/-1->434->433
408: hkn0723:232560:232720 [0] NCCL INFO Trees [0] 409/412/-1->408->400 [1] 409/-1/-1->408->405
300: hkn0628:696392:696486 [0] NCCL INFO Trees [0] 301/-1/-1->300->296 [1] 301/292/-1->300->285
349: hkn0706:776624:776729 [1] NCCL INFO Trees [0] 350/-1/-1->349->348 [1] 350/364/-1->349->348
298: hkn0627:1812322:1812413 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 26: hkn0410:1184027:1184146 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
157: hkn0516:2940314:2940436 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
439: hkn0731:1411104:1411206 [3] NCCL INFO Trees [0] -1/-1/-1->439->438 [1] -1/-1/-1->439->438
  7: hkn0404:1363854:1363975 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
367: hkn0711:608376:608500 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
354: hkn0707:4044308:4044418 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
162: hkn0520:2737243:2737371 [2] NCCL INFO Trees [0] 163/-1/-1->162->161 [1] 163/-1/-1->162->161
 28: hkn0411:2340281:2340396 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
463: hkn0802:1224700:1224850 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
403: hkn0720:33744:33905 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
347: hkn0705:807550:807681 [3] NCCL INFO Trees [0] -1/-1/-1->347->346 [1] -1/-1/-1->347->346
358: hkn0708:437599:437701 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
164: hkn0521:1222169:1222292 [0] NCCL INFO Trees [0] 165/-1/-1->164->169 [1] 165/160/-1->164->172
164: hkn0521:1222169:1222292 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
374: hkn0713:494590:494707 [2] NCCL INFO Trees [0] 375/-1/-1->374->373 [1] 375/-1/-1->374->373
  8: hkn0405:3231491:3231618 [0] NCCL INFO Trees [0] 9/12/-1->8->17 [1] 9/-1/-1->8->5
  8: hkn0405:3231491:3231618 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
413: hkn0724:1740329:1740471 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
391: hkn0717:19437:19568 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
468: hkn0804:1230018:1230142 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
392: hkn0718:3941435:3941546 [0] NCCL INFO Trees [0] 393/396/-1->392->401 [1] 393/-1/-1->392->389
397: hkn0719:1330259:1330375 [1] NCCL INFO Trees [0] 398/-1/-1->397->396 [1] 398/404/-1->397->396
467: hkn0803:900994:901110 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  3: hkn0403:1808445:1808808 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 19: hkn0408:2915270:2915393 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
294: hkn0626:1322810:1322935 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
378: hkn0714:456363:456478 [2] NCCL INFO Trees [0] 379/-1/-1->378->377 [1] 379/-1/-1->378->377
432: hkn0730:1426065:1426190 [0] NCCL INFO Trees [0] 433/440/-1->432->416 [1] 433/-1/-1->432->436
408: hkn0723:232560:232720 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
348: hkn0706:776612:776722 [0] NCCL INFO Trees [0] 349/-1/-1->348->344 [1] 349/332/-1->348->317
441: hkn0732:1236021:1236128 [1] NCCL INFO Trees [0] 442/436/-1->441->440 [1] 442/-1/-1->441->440
296: hkn0627:1812310:1812420 [0] NCCL INFO Trees [0] 297/300/-1->296->305 [1] 297/-1/-1->296->293
 24: hkn0410:1184043:1184151 [0] NCCL INFO Trees [0] 25/28/-1->24->16 [1] 25/-1/-1->24->21
 24: hkn0410:1184043:1184151 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
158: hkn0516:2940330:2940431 [2] NCCL INFO Trees [0] 159/-1/-1->158->157 [1] 159/-1/-1->158->157
158: hkn0516:2940330:2940431 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 14: hkn0407:1840633:1840731 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
 14: hkn0407:1840633:1840731 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
439: hkn0731:1411104:1411206 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  7: hkn0404:1363854:1363975 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
364: hkn0711:608404:608498 [0] NCCL INFO Trees [0] 365/-1/-1->364->360 [1] 365/356/-1->364->349
355: hkn0707:4044292:4044419 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
162: hkn0520:2737243:2737371 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
462: hkn0802:1224692:1224849 [2] NCCL INFO Trees [0] 463/-1/-1->462->461 [1] 463/-1/-1->462->461
400: hkn0720:33752:33908 [0] NCCL INFO Trees [0] 401/408/-1->400->417 [1] 401/-1/-1->400->404
347: hkn0705:807550:807681 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 21: hkn0409:2610008:2610115 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/24/-1->21->20
357: hkn0708:437583:437699 [1] NCCL INFO Trees [0] 358/-1/-1->357->356 [1] 358/360/-1->357->356
357: hkn0708:437583:437699 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
165: hkn0521:1222177:1222293 [1] NCCL INFO Trees [0] 166/-1/-1->165->164 [1] 166/168/-1->165->164
165: hkn0521:1222177:1222293 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
372: hkn0713:494598:494713 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 10: hkn0405:3231519:3231613 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
 10: hkn0405:3231519:3231613 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
415: hkn0724:1740349:1740479 [3] NCCL INFO Trees [0] -1/-1/-1->415->414 [1] -1/-1/-1->415->414
389: hkn0717:19453:19564 [1] NCCL INFO Trees [0] 390/-1/-1->389->388 [1] 390/392/-1->389->388
389: hkn0717:19453:19564 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
392: hkn0718:3941435:3941546 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
398: hkn0719:1330251:1330374 [2] NCCL INFO Trees [0] 399/-1/-1->398->397 [1] 399/-1/-1->398->397
398: hkn0719:1330251:1330374 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
465: hkn0803:900978:901109 [1] NCCL INFO Trees [0] 466/456/-1->465->464 [1] 466/-1/-1->465->464
  0: hkn0403:1808436:1808801 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 17: hkn0408:2915262:2915390 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] 18/-1/-1->17->16
379: hkn0714:456355:456477 [3] NCCL INFO Trees [0] -1/-1/-1->379->378 [1] -1/-1/-1->379->378
434: hkn0730:1426053:1426183 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
301: hkn0628:696372:696489 [1] NCCL INFO Trees [0] 302/-1/-1->301->300 [1] 302/308/-1->301->300
349: hkn0706:776624:776729 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
441: hkn0732:1236021:1236128 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
297: hkn0627:1812302:1812414 [1] NCCL INFO Trees [0] 298/292/-1->297->296 [1] 298/-1/-1->297->296
297: hkn0627:1812302:1812414 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 27: hkn0410:1184055:1184150 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26
 27: hkn0410:1184055:1184150 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 15: hkn0407:1840605:1840730 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
447: hkn0733:1413735:1413846 [3] NCCL INFO Trees [0] -1/-1/-1->447->446 [1] -1/-1/-1->447->446
437: hkn0731:1411116:1411213 [1] NCCL INFO Trees [0] 438/-1/-1->437->436 [1] 438/440/-1->437->436
  6: hkn0404:1363846:1363970 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
  6: hkn0404:1363846:1363970 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
364: hkn0711:608404:608498 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
352: hkn0707:4044320:4044416 [0] NCCL INFO Trees [0] 353/368/-1->352->320 [1] 353/-1/-1->352->356
352: hkn0707:4044320:4044416 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
160: hkn0520:2737215:2737368 [0] NCCL INFO Trees [0] 161/176/-1->160->193 [1] 161/-1/-1->160->164
160: hkn0520:2737215:2737368 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
462: hkn0802:1224692:1224849 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
400: hkn0720:33752:33908 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
450: hkn0734:1180905:1181006 [2] NCCL INFO Trees [0] 451/-1/-1->450->449 [1] 451/-1/-1->450->449
 21: hkn0409:2610008:2610115 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
356: hkn0708:437611:437707 [0] NCCL INFO Trees [0] 357/-1/-1->356->361 [1] 357/352/-1->356->364
167: hkn0521:1222197:1222291 [3] NCCL INFO Trees [0] -1/-1/-1->167->166 [1] -1/-1/-1->167->166
167: hkn0521:1222197:1222291 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
455: hkn0736:1532608:1532732 [3] NCCL INFO Trees [0] -1/-1/-1->455->454 [1] -1/-1/-1->455->454
374: hkn0713:494590:494707 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  9: hkn0405:3231499:3231610 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/-1/-1->9->8
  9: hkn0405:3231499:3231610 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
415: hkn0724:1740349:1740479 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
390: hkn0717:19445:19567 [2] NCCL INFO Trees [0] 391/-1/-1->390->389 [1] 391/-1/-1->390->389
397: hkn0719:1330259:1330375 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
465: hkn0803:900978:901109 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  2: hkn0403:1808457:1808810 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
 17: hkn0408:2915262:2915390 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
378: hkn0714:456363:456478 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
432: hkn0730:1426065:1426190 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
300: hkn0628:696392:696486 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
348: hkn0706:776612:776722 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
443: hkn0732:1236005:1236121 [3] NCCL INFO Trees [0] -1/-1/-1->443->442 [1] -1/-1/-1->443->442
299: hkn0627:1812294:1812419 [3] NCCL INFO Trees [0] -1/-1/-1->299->298 [1] -1/-1/-1->299->298
 25: hkn0410:1184035:1184153 [1] NCCL INFO Trees [0] 26/20/-1->25->24 [1] 26/-1/-1->25->24
 25: hkn0410:1184035:1184153 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 15: hkn0407:1840605:1840730 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
444: hkn0733:1413747:1413848 [0] NCCL INFO Trees [0] 445/-1/-1->444->440 [1] 445/412/-1->444->381
438: hkn0731:1411096:1411207 [2] NCCL INFO Trees [0] 439/-1/-1->438->437 [1] 439/-1/-1->438->437
  5: hkn0404:1363874:1363976 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/8/-1->5->4
353: hkn0707:4044300:4044417 [1] NCCL INFO Trees [0] 354/336/-1->353->352 [1] 354/-1/-1->353->352
353: hkn0707:4044300:4044417 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
163: hkn0520:2737223:2737364 [3] NCCL INFO Trees [0] -1/-1/-1->163->162 [1] -1/-1/-1->163->162
460: hkn0802:1224720:1224848 [0] NCCL INFO Trees [0] 461/-1/-1->460->456 [1] 461/452/-1->460->476
401: hkn0720:33760:33906 [1] NCCL INFO Trees [0] 402/392/-1->401->400 [1] 402/-1/-1->401->400
451: hkn0734:1180877:1181004 [3] NCCL INFO Trees [0] -1/-1/-1->451->450 [1] -1/-1/-1->451->450
451: hkn0734:1180877:1181004 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 23: hkn0409:2610020:2610114 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22
380: hkn0715:426268:426388 [0] NCCL INFO Trees [0] 381/-1/-1->380->376 [1] 381/316/-1->380->253
356: hkn0708:437611:437707 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
166: hkn0521:1222185:1222296 [2] NCCL INFO Trees [0] 167/-1/-1->166->165 [1] 167/-1/-1->166->165
455: hkn0736:1532608:1532732 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
168: hkn0523:1572589:1572686 [0] NCCL INFO Trees [0] 169/172/-1->168->177 [1] 169/-1/-1->168->165
168: hkn0523:1572589:1572686 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
373: hkn0713:494610:494705 [1] NCCL INFO Trees [0] 374/-1/-1->373->372 [1] 374/376/-1->373->372
 11: hkn0405:3231507:3231615 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10
 11: hkn0405:3231507:3231615 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
390: hkn0717:19445:19567 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
457: hkn0801:2264557:2264657 [1] NCCL INFO Trees [0] 458/452/-1->457->456 [1] 458/-1/-1->457->456
464: hkn0803:901006:901108 [0] NCCL INFO Trees [0] 465/472/-1->464->481 [1] 465/-1/-1->464->468
  2: hkn0403:1808457:1808810 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 18: hkn0408:2915278:2915387 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17
293: hkn0626:1322798:1322932 [1] NCCL INFO Trees [0] 294/-1/-1->293->292 [1] 294/296/-1->293->292
379: hkn0714:456355:456477 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
386: hkn0716:132819:132964 [2] NCCL INFO Trees [0] 387/-1/-1->386->385 [1] 387/-1/-1->386->385
386: hkn0716:132819:132964 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
301: hkn0628:696372:696489 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
442: hkn0732:1236013:1236130 [2] NCCL INFO Trees [0] 443/-1/-1->442->441 [1] 443/-1/-1->442->441
296: hkn0627:1812310:1812420 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 12: hkn0407:1840613:1840723 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/4/-1->12->28
447: hkn0733:1413735:1413846 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
437: hkn0731:1411116:1411213 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  5: hkn0404:1363874:1363976 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
163: hkn0520:2737223:2737364 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
460: hkn0802:1224720:1224848 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
401: hkn0720:33760:33906 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
450: hkn0734:1180905:1181006 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 22: hkn0409:2609992:2610120 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21
380: hkn0715:426268:426388 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
166: hkn0521:1222185:1222296 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
452: hkn0736:1532636:1532735 [0] NCCL INFO Trees [0] 453/-1/-1->452->457 [1] 453/448/-1->452->460
169: hkn0523:1572569:1572689 [1] NCCL INFO Trees [0] 170/164/-1->169->168 [1] 170/-1/-1->169->168
375: hkn0713:494582:494711 [3] NCCL INFO Trees [0] -1/-1/-1->375->374 [1] -1/-1/-1->375->374
375: hkn0713:494582:494711 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
388: hkn0717:19465:19565 [0] NCCL INFO Trees [0] 389/-1/-1->388->393 [1] 389/384/-1->388->396
457: hkn0801:2264557:2264657 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
464: hkn0803:901006:901108 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 16: hkn0408:2915290:2915389 [0] NCCL INFO Trees [0] 17/24/-1->16->33 [1] 17/-1/-1->16->20
 16: hkn0408:2915290:2915389 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
293: hkn0626:1322798:1322932 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
377: hkn0714:456383:456480 [1] NCCL INFO Trees [0] 378/372/-1->377->376 [1] 378/-1/-1->377->376
377: hkn0714:456383:456480 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
385: hkn0716:132811:132965 [1] NCCL INFO Trees [0] 386/320/-1->385->384 [1] 386/-1/-1->385->384
385: hkn0716:132811:132965 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
443: hkn0732:1236005:1236121 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
299: hkn0627:1812294:1812419 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 13: hkn0407:1840621:1840725 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/20/-1->13->12
 13: hkn0407:1840621:1840725 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
444: hkn0733:1413747:1413848 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
438: hkn0731:1411096:1411207 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
448: hkn0734:1180893:1180999 [0] NCCL INFO Trees [0] 449/480/-1->448->384 [1] 449/-1/-1->448->452
 20: hkn0409:2610000:2610117 [0] NCCL INFO Trees [0] 21/-1/-1->20->25 [1] 21/16/-1->20->13
 20: hkn0409:2610000:2610117 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
383: hkn0715:426284:426389 [3] NCCL INFO Trees [0] -1/-1/-1->383->382 [1] -1/-1/-1->383->382
453: hkn0736:1532616:1532726 [1] NCCL INFO Trees [0] 454/-1/-1->453->452 [1] 454/456/-1->453->452
453: hkn0736:1532616:1532726 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
169: hkn0523:1572569:1572689 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
373: hkn0713:494610:494705 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
458: hkn0801:2264537:2264649 [2] NCCL INFO Trees [0] 459/-1/-1->458->457 [1] 459/-1/-1->458->457
 18: hkn0408:2915278:2915387 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
376: hkn0714:456371:456476 [0] NCCL INFO Trees [0] 377/380/-1->376->368 [1] 377/-1/-1->376->373
376: hkn0714:456371:456476 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
387: hkn0716:132839:132970 [3] NCCL INFO Trees [0] -1/-1/-1->387->386 [1] -1/-1/-1->387->386
442: hkn0732:1236013:1236130 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 12: hkn0407:1840613:1840723 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
445: hkn0733:1413727:1413845 [1] NCCL INFO Trees [0] 446/-1/-1->445->444 [1] 446/476/-1->445->444
449: hkn0734:1180885:1181000 [1] NCCL INFO Trees [0] 450/416/-1->449->448 [1] 450/-1/-1->449->448
 22: hkn0409:2609992:2610120 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
383: hkn0715:426284:426389 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
452: hkn0736:1532636:1532735 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
171: hkn0523:1572561:1572684 [3] NCCL INFO Trees [0] -1/-1/-1->171->170 [1] -1/-1/-1->171->170
459: hkn0801:2264529:2264651 [3] NCCL INFO Trees [0] -1/-1/-1->459->458 [1] -1/-1/-1->459->458
459: hkn0801:2264529:2264651 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
384: hkn0716:132827:132967 [0] NCCL INFO Trees [0] 385/448/-1->384->256 [1] 385/-1/-1->384->388
440: hkn0732:1236033:1236129 [0] NCCL INFO Trees [0] 441/444/-1->440->432 [1] 441/-1/-1->440->437
446: hkn0733:1413719:1413842 [2] NCCL INFO Trees [0] 447/-1/-1->446->445 [1] 447/-1/-1->446->445
446: hkn0733:1413719:1413842 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
448: hkn0734:1180893:1180999 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 23: hkn0409:2610020:2610114 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
381: hkn0715:426296:426395 [1] NCCL INFO Trees [0] 382/-1/-1->381->380 [1] 382/444/-1->381->380
454: hkn0736:1532624:1532729 [2] NCCL INFO Trees [0] 455/-1/-1->454->453 [1] 455/-1/-1->454->453
171: hkn0523:1572561:1572684 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
388: hkn0717:19465:19565 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
458: hkn0801:2264537:2264649 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
387: hkn0716:132839:132970 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
440: hkn0732:1236033:1236129 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
445: hkn0733:1413727:1413845 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
449: hkn0734:1180885:1181000 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
381: hkn0715:426296:426395 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
454: hkn0736:1532624:1532729 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
170: hkn0523:1572577:1572685 [2] NCCL INFO Trees [0] 171/-1/-1->170->169 [1] 171/-1/-1->170->169
170: hkn0523:1572577:1572685 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
456: hkn0801:2264545:2264656 [0] NCCL INFO Trees [0] 457/460/-1->456->465 [1] 457/-1/-1->456->453
384: hkn0716:132827:132967 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
175: hkn0524:1158128:1158251 [3] NCCL INFO Trees [0] -1/-1/-1->175->174 [1] -1/-1/-1->175->174
177: hkn0525:1011146:1011240 [1] NCCL INFO Trees [0] 178/168/-1->177->176 [1] 178/-1/-1->177->176
382: hkn0715:426276:426394 [2] NCCL INFO Trees [0] 383/-1/-1->382->381 [1] 383/-1/-1->382->381
456: hkn0801:2264545:2264656 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
292: hkn0626:1322782:1322938 [0] NCCL INFO Trees [0] 293/-1/-1->292->297 [1] 293/288/-1->292->300
461: hkn0802:1224708:1224841 [1] NCCL INFO Trees [0] 462/-1/-1->461->460 [1] 462/468/-1->461->460
382: hkn0715:426276:426394 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
292: hkn0626:1322782:1322938 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
174: hkn0524:1158156:1158250 [2] NCCL INFO Trees [0] 175/-1/-1->174->173 [1] 175/-1/-1->174->173
461: hkn0802:1224708:1224841 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
177: hkn0525:1011146:1011240 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
175: hkn0524:1158128:1158251 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
179: hkn0525:1011126:1011245 [3] NCCL INFO Trees [0] -1/-1/-1->179->178 [1] -1/-1/-1->179->178
172: hkn0524:1158136:1158254 [0] NCCL INFO Trees [0] 173/-1/-1->172->168 [1] 173/164/-1->172->157
172: hkn0524:1158136:1158254 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
179: hkn0525:1011126:1011245 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
173: hkn0524:1158144:1158252 [1] NCCL INFO Trees [0] 174/-1/-1->173->172 [1] 174/180/-1->173->172
173: hkn0524:1158144:1158252 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
178: hkn0525:1011134:1011249 [2] NCCL INFO Trees [0] 179/-1/-1->178->177 [1] 179/-1/-1->178->177
178: hkn0525:1011134:1011249 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
174: hkn0524:1158156:1158250 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
176: hkn0525:1011118:1011248 [0] NCCL INFO Trees [0] 177/184/-1->176->160 [1] 177/-1/-1->176->180
176: hkn0525:1011118:1011248 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
186: hkn0527:1373294:1373422 [2] NCCL INFO Trees [0] 187/-1/-1->186->185 [1] 187/-1/-1->186->185
186: hkn0527:1373294:1373422 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
188: hkn0528:1326072:1326164 [0] NCCL INFO Trees [0] 189/-1/-1->188->184 [1] 189/156/-1->188->125
183: hkn0526:1452786:1452878 [3] NCCL INFO Trees [0] -1/-1/-1->183->182 [1] -1/-1/-1->183->182
187: hkn0527:1373302:1373417 [3] NCCL INFO Trees [0] -1/-1/-1->187->186 [1] -1/-1/-1->187->186
183: hkn0526:1452786:1452878 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
188: hkn0528:1326072:1326164 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
187: hkn0527:1373302:1373417 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
185: hkn0527:1373310:1373415 [1] NCCL INFO Trees [0] 186/180/-1->185->184 [1] 186/-1/-1->185->184
185: hkn0527:1373310:1373415 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
291: hkn0624:1797274:1797389 [3] NCCL INFO Trees [0] -1/-1/-1->291->290 [1] -1/-1/-1->291->290
184: hkn0527:1373322:1373423 [0] NCCL INFO Trees [0] 185/188/-1->184->176 [1] 185/-1/-1->184->181
184: hkn0527:1373322:1373423 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
189: hkn0528:1326044:1326167 [1] NCCL INFO Trees [0] 190/-1/-1->189->188 [1] 190/220/-1->189->188
291: hkn0624:1797274:1797389 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
195: hkn0529:1565159:1565265 [3] NCCL INFO Trees [0] -1/-1/-1->195->194 [1] -1/-1/-1->195->194
180: hkn0526:1452766:1452877 [0] NCCL INFO Trees [0] 181/-1/-1->180->185 [1] 181/176/-1->180->173
180: hkn0526:1452766:1452877 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
193: hkn0529:1565171:1565268 [1] NCCL INFO Trees [0] 194/160/-1->193->192 [1] 194/-1/-1->193->192
181: hkn0526:1452758:1452883 [1] NCCL INFO Trees [0] 182/-1/-1->181->180 [1] 182/184/-1->181->180
196: hkn0530:1282482:1282590 [0] NCCL INFO Trees [0] 197/-1/-1->196->201 [1] 197/192/-1->196->204
189: hkn0528:1326044:1326167 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
195: hkn0529:1565159:1565265 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
181: hkn0526:1452758:1452883 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
197: hkn0530:1282466:1282581 [1] NCCL INFO Trees [0] 198/-1/-1->197->196 [1] 198/200/-1->197->196
190: hkn0528:1326060:1326165 [2] NCCL INFO Trees [0] 191/-1/-1->190->189 [1] 191/-1/-1->190->189
190: hkn0528:1326060:1326165 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
193: hkn0529:1565171:1565268 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
182: hkn0526:1452774:1452881 [2] NCCL INFO Trees [0] 183/-1/-1->182->181 [1] 183/-1/-1->182->181
182: hkn0526:1452774:1452881 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
196: hkn0530:1282482:1282590 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
191: hkn0528:1326052:1326169 [3] NCCL INFO Trees [0] -1/-1/-1->191->190 [1] -1/-1/-1->191->190
191: hkn0528:1326052:1326169 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
197: hkn0530:1282466:1282581 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
194: hkn0529:1565143:1565270 [2] NCCL INFO Trees [0] 195/-1/-1->194->193 [1] 195/-1/-1->194->193
204: hkn0532:950481:950779 [0] NCCL INFO Trees [0] 205/-1/-1->204->200 [1] 205/196/-1->204->220
194: hkn0529:1565143:1565270 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
198: hkn0530:1282474:1282589 [2] NCCL INFO Trees [0] 199/-1/-1->198->197 [1] 199/-1/-1->198->197
202: hkn0531:1255138:1255243 [2] NCCL INFO Trees [0] 203/-1/-1->202->201 [1] 203/-1/-1->202->201
156: hkn0516:2940342:2940437 [0] NCCL INFO Trees [0] 157/-1/-1->156->152 [1] 157/140/-1->156->188
192: hkn0529:1565151:1565262 [0] NCCL INFO Trees [0] 193/224/-1->192->128 [1] 193/-1/-1->192->196
199: hkn0530:1282494:1282588 [3] NCCL INFO Trees [0] -1/-1/-1->199->198 [1] -1/-1/-1->199->198
202: hkn0531:1255138:1255243 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
206: hkn0532:950453:950783 [2] NCCL INFO Trees [0] 207/-1/-1->206->205 [1] 207/-1/-1->206->205
192: hkn0529:1565151:1565262 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
198: hkn0530:1282474:1282589 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
204: hkn0532:950481:950779 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
156: hkn0516:2940342:2940437 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
199: hkn0530:1282494:1282588 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
206: hkn0532:950453:950783 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
289: hkn0624:1797266:1797383 [1] NCCL INFO Trees [0] 290/272/-1->289->288 [1] 290/-1/-1->289->288
289: hkn0624:1797266:1797383 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
201: hkn0531:1255130:1255248 [1] NCCL INFO Trees [0] 202/196/-1->201->200 [1] 202/-1/-1->201->200
201: hkn0531:1255130:1255248 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
205: hkn0532:950469:950780 [1] NCCL INFO Trees [0] 206/-1/-1->205->204 [1] 206/212/-1->205->204
203: hkn0531:1255122:1255246 [3] NCCL INFO Trees [0] -1/-1/-1->203->202 [1] -1/-1/-1->203->202
203: hkn0531:1255122:1255246 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
207: hkn0532:950461:950778 [3] NCCL INFO Trees [0] -1/-1/-1->207->206 [1] -1/-1/-1->207->206
290: hkn0624:1797282:1797386 [2] NCCL INFO Trees [0] 291/-1/-1->290->289 [1] 291/-1/-1->290->289
205: hkn0532:950469:950780 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
200: hkn0531:1255150:1255251 [0] NCCL INFO Trees [0] 201/204/-1->200->209 [1] 201/-1/-1->200->197
200: hkn0531:1255150:1255251 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
207: hkn0532:950461:950778 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
290: hkn0624:1797282:1797386 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
288: hkn0624:1797296:1797392 [0] NCCL INFO Trees [0] 289/304/-1->288->321 [1] 289/-1/-1->288->292
214: hkn0535:2423350:2423446 [2] NCCL INFO Trees [0] 215/-1/-1->214->213 [1] 215/-1/-1->214->213
288: hkn0624:1797296:1797392 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
214: hkn0535:2423350:2423446 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
208: hkn0534:1172769:1172865 [0] NCCL INFO Trees [0] 209/216/-1->208->225 [1] 209/-1/-1->208->212
208: hkn0534:1172769:1172865 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
217: hkn0601:142232:142341 [1] NCCL INFO Trees [0] 218/212/-1->217->216 [1] 218/-1/-1->217->216
221: hkn0602:3390370:3390573 [1] NCCL INFO Trees [0] 222/-1/-1->221->220 [1] 222/236/-1->221->220
282: hkn0622:2045008:2045126 [2] NCCL INFO Trees [0] 283/-1/-1->282->281 [1] 283/-1/-1->282->281
209: hkn0534:1172749:1172871 [1] NCCL INFO Trees [0] 210/200/-1->209->208 [1] 210/-1/-1->209->208
209: hkn0534:1172749:1172871 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
221: hkn0602:3390370:3390573 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
216: hkn0601:142244:142342 [0] NCCL INFO Trees [0] 217/220/-1->216->208 [1] 217/-1/-1->216->213
213: hkn0535:2423328:2423441 [1] NCCL INFO Trees [0] 214/-1/-1->213->212 [1] 214/216/-1->213->212
210: hkn0534:1172741:1172868 [2] NCCL INFO Trees [0] 211/-1/-1->210->209 [1] 211/-1/-1->210->209
210: hkn0534:1172741:1172868 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
223: hkn0602:3390378:3390578 [3] NCCL INFO Trees [0] -1/-1/-1->223->222 [1] -1/-1/-1->223->222
283: hkn0622:2045028:2045131 [3] NCCL INFO Trees [0] -1/-1/-1->283->282 [1] -1/-1/-1->283->282
217: hkn0601:142232:142341 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
215: hkn0535:2423320:2423450 [3] NCCL INFO Trees [0] -1/-1/-1->215->214 [1] -1/-1/-1->215->214
211: hkn0534:1172757:1172866 [3] NCCL INFO Trees [0] -1/-1/-1->211->210 [1] -1/-1/-1->211->210
211: hkn0534:1172757:1172866 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
220: hkn0602:3390398:3390575 [0] NCCL INFO Trees [0] 221/-1/-1->220->216 [1] 221/204/-1->220->189
220: hkn0602:3390398:3390575 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
282: hkn0622:2045008:2045126 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
219: hkn0601:142224:142344 [3] NCCL INFO Trees [0] -1/-1/-1->219->218 [1] -1/-1/-1->219->218
212: hkn0535:2423336:2423447 [0] NCCL INFO Trees [0] 213/-1/-1->212->217 [1] 213/208/-1->212->205
223: hkn0602:3390378:3390578 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
283: hkn0622:2045028:2045131 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
216: hkn0601:142244:142342 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
225: hkn0603:1437591:1437698 [1] NCCL INFO Trees [0] 226/208/-1->225->224 [1] 226/-1/-1->225->224
225: hkn0603:1437591:1437698 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
213: hkn0535:2423328:2423441 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
222: hkn0602:3390386:3390580 [2] NCCL INFO Trees [0] 223/-1/-1->222->221 [1] 223/-1/-1->222->221
281: hkn0622:2045016:2045130 [1] NCCL INFO Trees [0] 282/276/-1->281->280 [1] 282/-1/-1->281->280
219: hkn0601:142224:142344 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
227: hkn0603:1437583:1437701 [3] NCCL INFO Trees [0] -1/-1/-1->227->226 [1] -1/-1/-1->227->226
215: hkn0535:2423320:2423450 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
222: hkn0602:3390386:3390580 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
281: hkn0622:2045016:2045130 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
218: hkn0601:142216:142337 [2] NCCL INFO Trees [0] 219/-1/-1->218->217 [1] 219/-1/-1->218->217
218: hkn0601:142216:142337 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
227: hkn0603:1437583:1437701 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
284: hkn0623:1897127:1897252 [0] NCCL INFO Trees [0] 285/-1/-1->284->280 [1] 285/268/-1->284->316
212: hkn0535:2423336:2423447 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
231: hkn0604:713531:713661 [3] NCCL INFO Trees [0] -1/-1/-1->231->230 [1] -1/-1/-1->231->230
273: hkn0617:2319212:2319310 [1] NCCL INFO Trees [0] 274/264/-1->273->272 [1] 274/-1/-1->273->272
232: hkn0605:736552:736663 [0] NCCL INFO Trees [0] 233/236/-1->232->241 [1] 233/-1/-1->232->229
278: hkn0621:2016125:2016216 [2] NCCL INFO Trees [0] 279/-1/-1->278->277 [1] 279/-1/-1->278->277
224: hkn0603:1437575:1437699 [0] NCCL INFO Trees [0] 225/240/-1->224->192 [1] 225/-1/-1->224->228
231: hkn0604:713531:713661 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
273: hkn0617:2319212:2319310 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
226: hkn0603:1437603:1437704 [2] NCCL INFO Trees [0] 227/-1/-1->226->225 [1] 227/-1/-1->226->225
226: hkn0603:1437603:1437704 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
285: hkn0623:1897135:1897250 [1] NCCL INFO Trees [0] 286/-1/-1->285->284 [1] 286/300/-1->285->284
229: hkn0604:713547:713656 [1] NCCL INFO Trees [0] 230/-1/-1->229->228 [1] 230/232/-1->229->228
234: hkn0605:736544:736667 [2] NCCL INFO Trees [0] 235/-1/-1->234->233 [1] 235/-1/-1->234->233
278: hkn0621:2016125:2016216 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
224: hkn0603:1437575:1437699 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
286: hkn0623:1897143:1897243 [2] NCCL INFO Trees [0] 287/-1/-1->286->285 [1] 287/-1/-1->286->285
230: hkn0604:713539:713662 [2] NCCL INFO Trees [0] 231/-1/-1->230->229 [1] 231/-1/-1->230->229
275: hkn0617:2319192:2319312 [3] NCCL INFO Trees [0] -1/-1/-1->275->274 [1] -1/-1/-1->275->274
232: hkn0605:736552:736663 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
280: hkn0622:2045000:2045127 [0] NCCL INFO Trees [0] 281/284/-1->280->272 [1] 281/-1/-1->280->277
279: hkn0621:2016105:2016220 [3] NCCL INFO Trees [0] -1/-1/-1->279->278 [1] -1/-1/-1->279->278
287: hkn0623:1897155:1897246 [3] NCCL INFO Trees [0] -1/-1/-1->287->286 [1] -1/-1/-1->287->286
228: hkn0604:713559:713655 [0] NCCL INFO Trees [0] 229/-1/-1->228->233 [1] 229/224/-1->228->236
228: hkn0604:713559:713655 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
275: hkn0617:2319192:2319312 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
234: hkn0605:736544:736667 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
280: hkn0622:2045000:2045127 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
279: hkn0621:2016105:2016220 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
284: hkn0623:1897127:1897252 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
229: hkn0604:713547:713656 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
233: hkn0605:736560:736669 [1] NCCL INFO Trees [0] 234/228/-1->233->232 [1] 234/-1/-1->233->232
233: hkn0605:736560:736669 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
277: hkn0621:2016097:2016215 [1] NCCL INFO Trees [0] 278/-1/-1->277->276 [1] 278/280/-1->277->276
285: hkn0623:1897135:1897250 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
230: hkn0604:713539:713662 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
272: hkn0617:2319184:2319311 [0] NCCL INFO Trees [0] 273/280/-1->272->289 [1] 273/-1/-1->272->276
235: hkn0605:736572:736668 [3] NCCL INFO Trees [0] -1/-1/-1->235->234 [1] -1/-1/-1->235->234
276: hkn0621:2016113:2016222 [0] NCCL INFO Trees [0] 277/-1/-1->276->281 [1] 277/272/-1->276->269
276: hkn0621:2016113:2016222 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
286: hkn0623:1897143:1897243 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
272: hkn0617:2319184:2319311 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
235: hkn0605:736572:736668 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
277: hkn0621:2016097:2016215 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
287: hkn0623:1897155:1897246 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
258: hkn0612:941345:941470 [2] NCCL INFO Trees [0] 259/-1/-1->258->257 [1] 259/-1/-1->258->257
242: hkn0607:928725:928850 [2] NCCL INFO Trees [0] 243/-1/-1->242->241 [1] 243/-1/-1->242->241
240: hkn0607:928741:928852 [0] NCCL INFO Trees [0] 241/248/-1->240->224 [1] 241/-1/-1->240->244
274: hkn0617:2319200:2319315 [2] NCCL INFO Trees [0] 275/-1/-1->274->273 [1] 275/-1/-1->274->273
271: hkn0616:429414:429520 [3] NCCL INFO Trees [0] -1/-1/-1->271->270 [1] -1/-1/-1->271->270
258: hkn0612:941345:941470 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
242: hkn0607:928725:928850 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
255: hkn0611:734150:734278 [3] NCCL INFO Trees [0] -1/-1/-1->255->254 [1] -1/-1/-1->255->254
236: hkn0606:2396583:2396678 [0] NCCL INFO Trees [0] 237/-1/-1->236->232 [1] 237/228/-1->236->221
246: hkn0608:510072:510180 [2] NCCL INFO Trees [0] 247/-1/-1->246->245 [1] 247/-1/-1->246->245
271: hkn0616:429414:429520 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
259: hkn0612:941325:941471 [3] NCCL INFO Trees [0] -1/-1/-1->259->258 [1] -1/-1/-1->259->258
240: hkn0607:928741:928852 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
263: hkn0613:927090:927213 [3] NCCL INFO Trees [0] -1/-1/-1->263->262 [1] -1/-1/-1->263->262
251: hkn0609:735154:735263 [3] NCCL INFO Trees [0] -1/-1/-1->251->250 [1] -1/-1/-1->251->250
274: hkn0617:2319200:2319315 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
259: hkn0612:941325:941471 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
241: hkn0607:928753:928855 [1] NCCL INFO Trees [0] 242/232/-1->241->240 [1] 242/-1/-1->241->240
265: hkn0615:438714:438810 [1] NCCL INFO Trees [0] 266/260/-1->265->264 [1] 266/-1/-1->265->264
265: hkn0615:438714:438810 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
255: hkn0611:734150:734278 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
237: hkn0606:2396555:2396677 [1] NCCL INFO Trees [0] 238/-1/-1->237->236 [1] 238/244/-1->237->236
251: hkn0609:735154:735263 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
246: hkn0608:510072:510180 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
269: hkn0616:429426:429521 [1] NCCL INFO Trees [0] 270/-1/-1->269->268 [1] 270/276/-1->269->268
269: hkn0616:429426:429521 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
256: hkn0612:941333:941464 [0] NCCL INFO Trees [0] 257/384/-1->256->0 [1] 257/-1/-1->256->260
256: hkn0612:941333:941464 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
243: hkn0607:928733:928851 [3] NCCL INFO Trees [0] -1/-1/-1->243->242 [1] -1/-1/-1->243->242
266: hkn0615:438703:438813 [2] NCCL INFO Trees [0] 267/-1/-1->266->265 [1] 267/-1/-1->266->265
263: hkn0613:927090:927213 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
238: hkn0606:2396571:2396682 [2] NCCL INFO Trees [0] 239/-1/-1->238->237 [1] 239/-1/-1->238->237
248: hkn0609:735146:735265 [0] NCCL INFO Trees [0] 249/252/-1->248->240 [1] 249/-1/-1->248->245
248: hkn0609:735146:735265 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
245: hkn0608:510084:510183 [1] NCCL INFO Trees [0] 246/-1/-1->245->244 [1] 246/248/-1->245->244
257: hkn0612:941317:941465 [1] NCCL INFO Trees [0] 258/128/-1->257->256 [1] 258/-1/-1->257->256
241: hkn0607:928753:928855 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
267: hkn0615:438695:438811 [3] NCCL INFO Trees [0] -1/-1/-1->267->266 [1] -1/-1/-1->267->266
267: hkn0615:438695:438811 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
254: hkn0611:734166:734276 [2] NCCL INFO Trees [0] 255/-1/-1->254->253 [1] 255/-1/-1->254->253
 70: hkn0422:4177477:4177595 [2] NCCL INFO Channel 00 : 70[ca000] -> 69[4b000] via P2P/IPC/read
239: hkn0606:2396563:2396679 [3] NCCL INFO Trees [0] -1/-1/-1->239->238 [1] -1/-1/-1->239->238
249: hkn0609:735138:735259 [1] NCCL INFO Trees [0] 250/244/-1->249->248 [1] 250/-1/-1->249->248
249: hkn0609:735138:735259 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
247: hkn0608:510056:510185 [3] NCCL INFO Trees [0] -1/-1/-1->247->246 [1] -1/-1/-1->247->246
247: hkn0608:510056:510185 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
270: hkn0616:429406:429526 [2] NCCL INFO Trees [0] 271/-1/-1->270->269 [1] 271/-1/-1->270->269
257: hkn0612:941317:941465 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
243: hkn0607:928733:928851 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
266: hkn0615:438703:438813 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
252: hkn0611:734178:734279 [0] NCCL INFO Trees [0] 253/-1/-1->252->248 [1] 253/124/-1->252->508
260: hkn0613:927106:927208 [0] NCCL INFO Trees [0] 261/-1/-1->260->265 [1] 261/256/-1->260->268
236: hkn0606:2396583:2396678 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
250: hkn0609:735166:735258 [2] NCCL INFO Trees [0] 251/-1/-1->250->249 [1] 251/-1/-1->250->249
250: hkn0609:735166:735258 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
245: hkn0608:510084:510183 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
268: hkn0616:429398:429527 [0] NCCL INFO Trees [0] 269/-1/-1->268->264 [1] 269/260/-1->268->284
264: hkn0615:438687:438806 [0] NCCL INFO Trees [0] 265/268/-1->264->273 [1] 265/-1/-1->264->261
253: hkn0611:734158:734277 [1] NCCL INFO Trees [0] 254/-1/-1->253->252 [1] 254/380/-1->253->252
253: hkn0611:734158:734277 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
261: hkn0613:927098:927209 [1] NCCL INFO Trees [0] 262/-1/-1->261->260 [1] 262/264/-1->261->260
237: hkn0606:2396555:2396677 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
270: hkn0616:429406:429526 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
264: hkn0615:438687:438806 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
254: hkn0611:734166:734276 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
262: hkn0613:927118:927210 [2] NCCL INFO Trees [0] 263/-1/-1->262->261 [1] 263/-1/-1->262->261
238: hkn0606:2396571:2396682 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
244: hkn0608:510064:510177 [0] NCCL INFO Trees [0] 245/-1/-1->244->249 [1] 245/240/-1->244->237
268: hkn0616:429398:429527 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
252: hkn0611:734178:734279 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
260: hkn0613:927106:927208 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
239: hkn0606:2396563:2396679 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 62: hkn0420:3234575:3234691 [2] NCCL INFO Channel 00 : 62[ca000] -> 61[4b000] via P2P/IPC/read
261: hkn0613:927098:927209 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
262: hkn0613:927118:927210 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
244: hkn0608:510064:510177 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 66: hkn0421:2208703:2208881 [2] NCCL INFO Channel 00 : 66[ca000] -> 65[4b000] via P2P/IPC/read
 86: hkn0426:838372:838511 [2] NCCL INFO Channel 00 : 86[ca000] -> 85[4b000] via P2P/IPC/read
 78: hkn0424:2972321:2972426 [2] NCCL INFO Channel 00 : 78[ca000] -> 77[4b000] via P2P/IPC/read
 58: hkn0419:1568591:1568715 [2] NCCL INFO Channel 00 : 58[ca000] -> 57[4b000] via P2P/IPC/read
 82: hkn0425:2108517:2108637 [2] NCCL INFO Channel 00 : 82[ca000] -> 81[4b000] via P2P/IPC/read
 62: hkn0420:3234575:3234691 [2] NCCL INFO Channel 01 : 62[ca000] -> 61[4b000] via P2P/IPC/read
 46: hkn0415:2520763:2520859 [2] NCCL INFO Channel 00 : 46[ca000] -> 45[4b000] via P2P/IPC/read
 54: hkn0418:1893557:1893666 [2] NCCL INFO Channel 00 : 54[ca000] -> 53[4b000] via P2P/IPC/read
 70: hkn0422:4177477:4177595 [2] NCCL INFO Channel 01 : 70[ca000] -> 69[4b000] via P2P/IPC/read
 50: hkn0417:2292055:2292170 [2] NCCL INFO Channel 00 : 50[ca000] -> 49[4b000] via P2P/IPC/read
 74: hkn0423:1729414:1729511 [2] NCCL INFO Channel 00 : 74[ca000] -> 73[4b000] via P2P/IPC/read
 78: hkn0424:2972321:2972426 [2] NCCL INFO Channel 01 : 78[ca000] -> 77[4b000] via P2P/IPC/read
 30: hkn0411:2340293:2340389 [2] NCCL INFO Channel 00 : 30[ca000] -> 29[4b000] via P2P/IPC/read
 58: hkn0419:1568591:1568715 [2] NCCL INFO Channel 01 : 58[ca000] -> 57[4b000] via P2P/IPC/read
 90: hkn0427:1159498:1159622 [2] NCCL INFO Channel 00 : 90[ca000] -> 89[4b000] via P2P/IPC/read
 66: hkn0421:2208703:2208881 [2] NCCL INFO Channel 01 : 66[ca000] -> 65[4b000] via P2P/IPC/read
134: hkn0510:2786427:2786528 [2] NCCL INFO Channel 00 : 134[ca000] -> 133[4b000] via P2P/IPC/read
 82: hkn0425:2108517:2108637 [2] NCCL INFO Channel 01 : 82[ca000] -> 81[4b000] via P2P/IPC/read
 94: hkn0428:691716:691838 [2] NCCL INFO Channel 00 : 94[ca000] -> 93[4b000] via P2P/IPC/read
 86: hkn0426:838372:838511 [2] NCCL INFO Channel 01 : 86[ca000] -> 85[4b000] via P2P/IPC/read
 54: hkn0418:1893557:1893666 [2] NCCL INFO Channel 01 : 54[ca000] -> 53[4b000] via P2P/IPC/read
 50: hkn0417:2292055:2292170 [2] NCCL INFO Channel 01 : 50[ca000] -> 49[4b000] via P2P/IPC/read
130: hkn0509:3148779:3148872 [2] NCCL INFO Channel 00 : 130[ca000] -> 129[4b000] via P2P/IPC/read
138: hkn0511:3090897:3090992 [2] NCCL INFO Channel 00 : 138[ca000] -> 137[4b000] via P2P/IPC/read
 38: hkn0413:2391078:2391198 [2] NCCL INFO Channel 00 : 38[ca000] -> 37[4b000] via P2P/IPC/read
 46: hkn0415:2520763:2520859 [2] NCCL INFO Channel 01 : 46[ca000] -> 45[4b000] via P2P/IPC/read
126: hkn0508:3163478:3163601 [2] NCCL INFO Channel 00 : 126[ca000] -> 125[4b000] via P2P/IPC/read
106: hkn0503:2924162:2924287 [2] NCCL INFO Channel 00 : 106[ca000] -> 105[4b000] via P2P/IPC/read
142: hkn0512:3068454:3068574 [2] NCCL INFO Channel 00 : 142[ca000] -> 141[4b000] via P2P/IPC/read
118: hkn0506:862450:862548 [2] NCCL INFO Channel 00 : 118[ca000] -> 117[4b000] via P2P/IPC/read
490: hkn0809:961680:961778 [2] NCCL INFO Channel 00 : 490[ca000] -> 489[4b000] via P2P/IPC/read
322: hkn0633:1550649:1550756 [2] NCCL INFO Channel 00 : 322[ca000] -> 321[4b000] via P2P/IPC/read
326: hkn0634:1545229:1545344 [2] NCCL INFO Channel 00 : 326[ca000] -> 325[4b000] via P2P/IPC/read
122: hkn0507:3211459:3211565 [2] NCCL INFO Channel 00 : 122[ca000] -> 121[4b000] via P2P/IPC/read
 34: hkn0412:2286727:2286850 [2] NCCL INFO Channel 00 : 34[ca000] -> 33[4b000] via P2P/IPC/read
 98: hkn0501:1352394:1352503 [2] NCCL INFO Channel 00 : 98[ca000] -> 97[4b000] via P2P/IPC/read
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
130: hkn0509:3148779:3148872 [2] NCCL INFO Channel 01 : 130[ca000] -> 129[4b000] via P2P/IPC/read
134: hkn0510:2786427:2786528 [2] NCCL INFO Channel 01 : 134[ca000] -> 133[4b000] via P2P/IPC/read
 30: hkn0411:2340293:2340389 [2] NCCL INFO Channel 01 : 30[ca000] -> 29[4b000] via P2P/IPC/read
 90: hkn0427:1159498:1159622 [2] NCCL INFO Channel 01 : 90[ca000] -> 89[4b000] via P2P/IPC/read
494: hkn0810:963913:964023 [2] NCCL INFO Channel 00 : 494[ca000] -> 493[4b000] via P2P/IPC/read
150: hkn0514:2975099:2975195 [2] NCCL INFO Channel 00 : 150[ca000] -> 149[4b000] via P2P/IPC/read
138: hkn0511:3090897:3090992 [2] NCCL INFO Channel 01 : 138[ca000] -> 137[4b000] via P2P/IPC/read
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
102: hkn0502:253394:253516 [2] NCCL INFO Channel 00 : 102[ca000] -> 101[4b000] via P2P/IPC/read
146: hkn0513:3037323:3037444 [2] NCCL INFO Channel 00 : 146[ca000] -> 145[4b000] via P2P/IPC/read
 74: hkn0423:1729414:1729511 [2] NCCL INFO Channel 01 : 74[ca000] -> 73[4b000] via P2P/IPC/read
502: hkn0814:700184:700311 [2] NCCL INFO Channel 00 : 502[ca000] -> 501[4b000] via P2P/IPC/read
126: hkn0508:3163478:3163601 [2] NCCL INFO Channel 01 : 126[ca000] -> 125[4b000] via P2P/IPC/read
106: hkn0503:2924162:2924287 [2] NCCL INFO Channel 01 : 106[ca000] -> 105[4b000] via P2P/IPC/read
118: hkn0506:862450:862548 [2] NCCL INFO Channel 01 : 118[ca000] -> 117[4b000] via P2P/IPC/read
322: hkn0633:1550649:1550756 [2] NCCL INFO Channel 01 : 322[ca000] -> 321[4b000] via P2P/IPC/read
 38: hkn0413:2391078:2391198 [2] NCCL INFO Channel 01 : 38[ca000] -> 37[4b000] via P2P/IPC/read
318: hkn0632:1782963:1783087 [2] NCCL INFO Channel 00 : 318[ca000] -> 317[4b000] via P2P/IPC/read
122: hkn0507:3211459:3211565 [2] NCCL INFO Channel 01 : 122[ca000] -> 121[4b000] via P2P/IPC/read
486: hkn0808:995058:995152 [2] NCCL INFO Channel 00 : 486[ca000] -> 485[4b000] via P2P/IPC/read
326: hkn0634:1545229:1545344 [2] NCCL INFO Channel 01 : 326[ca000] -> 325[4b000] via P2P/IPC/read
478: hkn0806:1078688:1078789 [2] NCCL INFO Channel 00 : 478[ca000] -> 477[4b000] via P2P/IPC/read
306: hkn0629:1616375:1616505 [2] NCCL INFO Channel 00 : 306[ca000] -> 305[4b000] via P2P/IPC/read
474: hkn0805:1136461:1136592 [2] NCCL INFO Channel 00 : 474[ca000] -> 473[4b000] via P2P/IPC/read
490: hkn0809:961680:961778 [2] NCCL INFO Channel 01 : 490[ca000] -> 489[4b000] via P2P/IPC/read
 94: hkn0428:691716:691838 [2] NCCL INFO Channel 01 : 94[ca000] -> 93[4b000] via P2P/IPC/read
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
154: hkn0515:2921182:2921328 [2] NCCL INFO Channel 00 : 154[ca000] -> 153[4b000] via P2P/IPC/read
506: hkn0815:419477:419589 [2] NCCL INFO Channel 00 : 506[ca000] -> 505[4b000] via P2P/IPC/read
 34: hkn0412:2286727:2286850 [2] NCCL INFO Channel 01 : 34[ca000] -> 33[4b000] via P2P/IPC/read
334: hkn0636:1678724:1678867 [2] NCCL INFO Channel 00 : 334[ca000] -> 333[4b000] via P2P/IPC/read
394: hkn0718:3941447:3941548 [2] NCCL INFO Channel 00 : 394[ca000] -> 393[4b000] via P2P/IPC/read
398: hkn0719:1330251:1330374 [2] NCCL INFO Channel 00 : 398[ca000] -> 397[4b000] via P2P/IPC/read
362: hkn0710:379915:380012 [2] NCCL INFO Channel 00 : 362[ca000] -> 361[4b000] via P2P/IPC/read
142: hkn0512:3068454:3068574 [2] NCCL INFO Channel 01 : 142[ca000] -> 141[4b000] via P2P/IPC/read
330: hkn0635:1249906:1250023 [2] NCCL INFO Channel 00 : 330[ca000] -> 329[4b000] via P2P/IPC/read
510: hkn0816:399918:400045 [2] NCCL INFO Channel 00 : 510[ca000] -> 509[4b000] via P2P/IPC/read
498: hkn0812:718237:718348 [2] NCCL INFO Channel 00 : 498[ca000] -> 497[4b000] via P2P/IPC/read
302: hkn0628:696364:696481 [2] NCCL INFO Channel 00 : 302[ca000] -> 301[4b000] via P2P/IPC/read
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
406: hkn0721:2323879:2323993 [2] NCCL INFO Channel 00 : 406[ca000] -> 405[4b000] via P2P/IPC/read
366: hkn0711:608384:608505 [2] NCCL INFO Channel 00 : 366[ca000] -> 365[4b000] via P2P/IPC/read
150: hkn0514:2975099:2975195 [2] NCCL INFO Channel 01 : 150[ca000] -> 149[4b000] via P2P/IPC/read
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
 69: hkn0422:4177485:4177589 [1] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
470: hkn0804:1230046:1230140 [2] NCCL INFO Channel 00 : 470[ca000] -> 469[4b000] via P2P/IPC/read
  2: hkn0403:1808457:1808810 [2] NCCL INFO Channel 00 : 2[ca000] -> 1[4b000] via P2P/IPC/read
  6: hkn0404:1363846:1363970 [2] NCCL INFO Channel 00 : 6[ca000] -> 5[4b000] via P2P/IPC/read
346: hkn0705:807578:807672 [2] NCCL INFO Channel 00 : 346[ca000] -> 345[4b000] via P2P/IPC/read
430: hkn0728:1348501:1348594 [2] NCCL INFO Channel 00 : 430[ca000] -> 429[4b000] via P2P/IPC/read
102: hkn0502:253394:253516 [2] NCCL INFO Channel 01 : 102[ca000] -> 101[4b000] via P2P/IPC/read
414: hkn0724:1740337:1740474 [2] NCCL INFO Channel 00 : 414[ca000] -> 413[4b000] via P2P/IPC/read
390: hkn0717:19445:19567 [2] NCCL INFO Channel 00 : 390[ca000] -> 389[4b000] via P2P/IPC/read
482: hkn0807:1043406:1043538 [2] NCCL INFO Channel 00 : 482[ca000] -> 481[4b000] via P2P/IPC/read
314: hkn0631:1046179:1046288 [2] NCCL INFO Channel 00 : 314[ca000] -> 313[4b000] via P2P/IPC/read
418: hkn0725:3136324:3136423 [2] NCCL INFO Channel 00 : 418[ca000] -> 417[4b000] via P2P/IPC/read
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
294: hkn0626:1322810:1322935 [2] NCCL INFO Channel 00 : 294[ca000] -> 293[4b000] via P2P/IPC/read
486: hkn0808:995058:995152 [2] NCCL INFO Channel 01 : 486[ca000] -> 485[4b000] via P2P/IPC/read
502: hkn0814:700184:700311 [2] NCCL INFO Channel 01 : 502[ca000] -> 501[4b000] via P2P/IPC/read
350: hkn0706:776596:776723 [2] NCCL INFO Channel 00 : 350[ca000] -> 349[4b000] via P2P/IPC/read
442: hkn0732:1236013:1236130 [2] NCCL INFO Channel 00 : 442[ca000] -> 441[4b000] via P2P/IPC/read
310: hkn0630:1622852:1622969 [2] NCCL INFO Channel 00 : 310[ca000] -> 309[4b000] via P2P/IPC/read
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
478: hkn0806:1078688:1078789 [2] NCCL INFO Channel 01 : 478[ca000] -> 477[4b000] via P2P/IPC/read
110: hkn0504:65463:65554 [2] NCCL INFO Channel 00 : 110[ca000] -> 109[4b000] via P2P/IPC/read
410: hkn0723:232552:232722 [2] NCCL INFO Channel 00 : 410[ca000] -> 409[4b000] via P2P/IPC/read
146: hkn0513:3037323:3037444 [2] NCCL INFO Channel 01 : 146[ca000] -> 145[4b000] via P2P/IPC/read
374: hkn0713:494590:494707 [2] NCCL INFO Channel 00 : 374[ca000] -> 373[4b000] via P2P/IPC/read
434: hkn0730:1426053:1426183 [2] NCCL INFO Channel 00 : 434[ca000] -> 433[4b000] via P2P/IPC/read
342: hkn0704:816326:816455 [2] NCCL INFO Channel 00 : 342[ca000] -> 341[4b000] via P2P/IPC/read
462: hkn0802:1224692:1224849 [2] NCCL INFO Channel 00 : 462[ca000] -> 461[4b000] via P2P/IPC/read
426: hkn0727:1370159:1370281 [2] NCCL INFO Channel 00 : 426[ca000] -> 425[4b000] via P2P/IPC/read
 98: hkn0501:1352394:1352503 [2] NCCL INFO Channel 01 : 98[ca000] -> 97[4b000] via P2P/IPC/read
358: hkn0708:437599:437701 [2] NCCL INFO Channel 00 : 358[ca000] -> 357[4b000] via P2P/IPC/read
318: hkn0632:1782963:1783087 [2] NCCL INFO Channel 01 : 318[ca000] -> 317[4b000] via P2P/IPC/read
302: hkn0628:696364:696481 [2] NCCL INFO Channel 01 : 302[ca000] -> 301[4b000] via P2P/IPC/read
298: hkn0627:1812322:1812413 [2] NCCL INFO Channel 00 : 298[ca000] -> 297[4b000] via P2P/IPC/read
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
 85: hkn0426:838392:838518 [1] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
330: hkn0635:1249906:1250023 [2] NCCL INFO Channel 01 : 330[ca000] -> 329[4b000] via P2P/IPC/read
166: hkn0521:1222185:1222296 [2] NCCL INFO Channel 00 : 166[ca000] -> 165[4b000] via P2P/IPC/read
154: hkn0515:2921182:2921328 [2] NCCL INFO Channel 01 : 154[ca000] -> 153[4b000] via P2P/IPC/read
446: hkn0733:1413719:1413842 [2] NCCL INFO Channel 00 : 446[ca000] -> 445[4b000] via P2P/IPC/read
338: hkn0703:765558:765658 [2] NCCL INFO Channel 00 : 338[ca000] -> 337[4b000] via P2P/IPC/read
354: hkn0707:4044308:4044418 [2] NCCL INFO Channel 00 : 354[ca000] -> 353[4b000] via P2P/IPC/read
494: hkn0810:963913:964023 [2] NCCL INFO Channel 01 : 494[ca000] -> 493[4b000] via P2P/IPC/read
466: hkn0803:900986:901105 [2] NCCL INFO Channel 00 : 466[ca000] -> 465[4b000] via P2P/IPC/read
406: hkn0721:2323879:2323993 [2] NCCL INFO Channel 01 : 406[ca000] -> 405[4b000] via P2P/IPC/read
 26: hkn0410:1184027:1184146 [2] NCCL INFO Channel 00 : 26[ca000] -> 25[4b000] via P2P/IPC/read
133: hkn0510:2786407:2786523 [1] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
498: hkn0812:718237:718348 [2] NCCL INFO Channel 01 : 498[ca000] -> 497[4b000] via P2P/IPC/read
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
506: hkn0815:419477:419589 [2] NCCL INFO Channel 01 : 506[ca000] -> 505[4b000] via P2P/IPC/read
430: hkn0728:1348501:1348594 [2] NCCL INFO Channel 01 : 430[ca000] -> 429[4b000] via P2P/IPC/read
418: hkn0725:3136324:3136423 [2] NCCL INFO Channel 01 : 418[ca000] -> 417[4b000] via P2P/IPC/read
306: hkn0629:1616375:1616505 [2] NCCL INFO Channel 01 : 306[ca000] -> 305[4b000] via P2P/IPC/read
 42: hkn0414:2006114:2006224 [2] NCCL INFO Channel 00 : 42[ca000] -> 41[4b000] via P2P/IPC/read
474: hkn0805:1136461:1136592 [2] NCCL INFO Channel 01 : 474[ca000] -> 473[4b000] via P2P/IPC/read
314: hkn0631:1046179:1046288 [2] NCCL INFO Channel 01 : 314[ca000] -> 313[4b000] via P2P/IPC/read
158: hkn0516:2940330:2940431 [2] NCCL INFO Channel 00 : 158[ca000] -> 157[4b000] via P2P/IPC/read
438: hkn0731:1411096:1411207 [2] NCCL INFO Channel 00 : 438[ca000] -> 437[4b000] via P2P/IPC/read
170: hkn0523:1572577:1572685 [2] NCCL INFO Channel 00 : 170[ca000] -> 169[4b000] via P2P/IPC/read
362: hkn0710:379915:380012 [2] NCCL INFO Channel 01 : 362[ca000] -> 361[4b000] via P2P/IPC/read
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
382: hkn0715:426276:426394 [2] NCCL INFO Channel 00 : 382[ca000] -> 381[4b000] via P2P/IPC/read
454: hkn0736:1532624:1532729 [2] NCCL INFO Channel 00 : 454[ca000] -> 453[4b000] via P2P/IPC/read
 10: hkn0405:3231519:3231613 [2] NCCL INFO Channel 00 : 10[ca000] -> 9[4b000] via P2P/IPC/read
394: hkn0718:3941447:3941548 [2] NCCL INFO Channel 01 : 394[ca000] -> 393[4b000] via P2P/IPC/read
398: hkn0719:1330251:1330374 [2] NCCL INFO Channel 01 : 398[ca000] -> 397[4b000] via P2P/IPC/read
294: hkn0626:1322810:1322935 [2] NCCL INFO Channel 01 : 294[ca000] -> 293[4b000] via P2P/IPC/read
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
366: hkn0711:608384:608505 [2] NCCL INFO Channel 01 : 366[ca000] -> 365[4b000] via P2P/IPC/read
510: hkn0816:399918:400045 [2] NCCL INFO Channel 01 : 510[ca000] -> 509[4b000] via P2P/IPC/read
310: hkn0630:1622852:1622969 [2] NCCL INFO Channel 01 : 310[ca000] -> 309[4b000] via P2P/IPC/read
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
114: hkn0505:2328143:2328257 [2] NCCL INFO Channel 00 : 114[ca000] -> 113[4b000] via P2P/IPC/read
350: hkn0706:776596:776723 [2] NCCL INFO Channel 01 : 350[ca000] -> 349[4b000] via P2P/IPC/read
402: hkn0720:33772:33907 [2] NCCL INFO Channel 00 : 402[ca000] -> 401[4b000] via P2P/IPC/read
 22: hkn0409:2609992:2610120 [2] NCCL INFO Channel 00 : 22[ca000] -> 21[4b000] via P2P/IPC/read
458: hkn0801:2264537:2264649 [2] NCCL INFO Channel 00 : 458[ca000] -> 457[4b000] via P2P/IPC/read
 53: hkn0418:1893541:1893660 [1] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
378: hkn0714:456363:456478 [2] NCCL INFO Channel 00 : 378[ca000] -> 377[4b000] via P2P/IPC/read
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
162: hkn0520:2737243:2737371 [2] NCCL INFO Channel 00 : 162[ca000] -> 161[4b000] via P2P/IPC/read
414: hkn0724:1740337:1740474 [2] NCCL INFO Channel 01 : 414[ca000] -> 413[4b000] via P2P/IPC/read
470: hkn0804:1230046:1230140 [2] NCCL INFO Channel 01 : 470[ca000] -> 469[4b000] via P2P/IPC/read
  6: hkn0404:1363846:1363970 [2] NCCL INFO Channel 01 : 6[ca000] -> 5[4b000] via P2P/IPC/read
390: hkn0717:19445:19567 [2] NCCL INFO Channel 01 : 390[ca000] -> 389[4b000] via P2P/IPC/read
434: hkn0730:1426053:1426183 [2] NCCL INFO Channel 01 : 434[ca000] -> 433[4b000] via P2P/IPC/read
462: hkn0802:1224692:1224849 [2] NCCL INFO Channel 01 : 462[ca000] -> 461[4b000] via P2P/IPC/read
426: hkn0727:1370159:1370281 [2] NCCL INFO Channel 01 : 426[ca000] -> 425[4b000] via P2P/IPC/read
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
 37: hkn0413:2391086:2391193 [1] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
358: hkn0708:437599:437701 [2] NCCL INFO Channel 01 : 358[ca000] -> 357[4b000] via P2P/IPC/read
298: hkn0627:1812322:1812413 [2] NCCL INFO Channel 01 : 298[ca000] -> 297[4b000] via P2P/IPC/read
  2: hkn0403:1808457:1808810 [2] NCCL INFO Channel 01 : 2[ca000] -> 1[4b000] via P2P/IPC/read
354: hkn0707:4044308:4044418 [2] NCCL INFO Channel 01 : 354[ca000] -> 353[4b000] via P2P/IPC/read
450: hkn0734:1180905:1181006 [2] NCCL INFO Channel 00 : 450[ca000] -> 449[4b000] via P2P/IPC/read
166: hkn0521:1222185:1222296 [2] NCCL INFO Channel 01 : 166[ca000] -> 165[4b000] via P2P/IPC/read
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
466: hkn0803:900986:901105 [2] NCCL INFO Channel 01 : 466[ca000] -> 465[4b000] via P2P/IPC/read
290: hkn0624:1797282:1797386 [2] NCCL INFO Channel 00 : 290[ca000] -> 289[4b000] via P2P/IPC/read
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
410: hkn0723:232552:232722 [2] NCCL INFO Channel 01 : 410[ca000] -> 409[4b000] via P2P/IPC/read
386: hkn0716:132819:132964 [2] NCCL INFO Channel 00 : 386[ca000] -> 385[4b000] via P2P/IPC/read
342: hkn0704:816326:816455 [2] NCCL INFO Channel 01 : 342[ca000] -> 341[4b000] via P2P/IPC/read
442: hkn0732:1236013:1236130 [2] NCCL INFO Channel 01 : 442[ca000] -> 441[4b000] via P2P/IPC/read
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
 42: hkn0414:2006114:2006224 [2] NCCL INFO Channel 01 : 42[ca000] -> 41[4b000] via P2P/IPC/read
110: hkn0504:65463:65554 [2] NCCL INFO Channel 01 : 110[ca000] -> 109[4b000] via P2P/IPC/read
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
178: hkn0525:1011134:1011249 [2] NCCL INFO Channel 00 : 178[ca000] -> 177[4b000] via P2P/IPC/read
 10: hkn0405:3231519:3231613 [2] NCCL INFO Channel 01 : 10[ca000] -> 9[4b000] via P2P/IPC/read
334: hkn0636:1678724:1678867 [2] NCCL INFO Channel 01 : 334[ca000] -> 333[4b000] via P2P/IPC/read
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
338: hkn0703:765558:765658 [2] NCCL INFO Channel 01 : 338[ca000] -> 337[4b000] via P2P/IPC/read
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
158: hkn0516:2940330:2940431 [2] NCCL INFO Channel 01 : 158[ca000] -> 157[4b000] via P2P/IPC/read
198: hkn0530:1282474:1282589 [2] NCCL INFO Channel 00 : 198[ca000] -> 197[4b000] via P2P/IPC/read
 22: hkn0409:2609992:2610120 [2] NCCL INFO Channel 01 : 22[ca000] -> 21[4b000] via P2P/IPC/read
374: hkn0713:494590:494707 [2] NCCL INFO Channel 01 : 374[ca000] -> 373[4b000] via P2P/IPC/read
190: hkn0528:1326060:1326165 [2] NCCL INFO Channel 00 : 190[ca000] -> 189[4b000] via P2P/IPC/read
458: hkn0801:2264537:2264649 [2] NCCL INFO Channel 01 : 458[ca000] -> 457[4b000] via P2P/IPC/read
482: hkn0807:1043406:1043538 [2] NCCL INFO Channel 01 : 482[ca000] -> 481[4b000] via P2P/IPC/read
488: hkn0809:961652:961773 [0] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
114: hkn0505:2328143:2328257 [2] NCCL INFO Channel 01 : 114[ca000] -> 113[4b000] via P2P/IPC/read
378: hkn0714:456363:456478 [2] NCCL INFO Channel 01 : 378[ca000] -> 377[4b000] via P2P/IPC/read
446: hkn0733:1413719:1413842 [2] NCCL INFO Channel 01 : 446[ca000] -> 445[4b000] via P2P/IPC/read
438: hkn0731:1411096:1411207 [2] NCCL INFO Channel 01 : 438[ca000] -> 437[4b000] via P2P/IPC/read
454: hkn0736:1532624:1532729 [2] NCCL INFO Channel 01 : 454[ca000] -> 453[4b000] via P2P/IPC/read
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
346: hkn0705:807578:807672 [2] NCCL INFO Channel 01 : 346[ca000] -> 345[4b000] via P2P/IPC/read
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
361: hkn0710:379895:380014 [1] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
170: hkn0523:1572577:1572685 [2] NCCL INFO Channel 01 : 170[ca000] -> 169[4b000] via P2P/IPC/read
497: hkn0812:718229:718349 [1] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
382: hkn0715:426276:426394 [2] NCCL INFO Channel 01 : 382[ca000] -> 381[4b000] via P2P/IPC/read
174: hkn0524:1158156:1158250 [2] NCCL INFO Channel 00 : 174[ca000] -> 173[4b000] via P2P/IPC/read
162: hkn0520:2737243:2737371 [2] NCCL INFO Channel 01 : 162[ca000] -> 161[4b000] via P2P/IPC/read
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
206: hkn0532:950453:950783 [2] NCCL INFO Channel 00 : 206[ca000] -> 205[4b000] via P2P/IPC/read
386: hkn0716:132819:132964 [2] NCCL INFO Channel 01 : 386[ca000] -> 385[4b000] via P2P/IPC/read
186: hkn0527:1373294:1373422 [2] NCCL INFO Channel 00 : 186[ca000] -> 185[4b000] via P2P/IPC/read
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
290: hkn0624:1797282:1797386 [2] NCCL INFO Channel 01 : 290[ca000] -> 289[4b000] via P2P/IPC/read
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
450: hkn0734:1180905:1181006 [2] NCCL INFO Channel 01 : 450[ca000] -> 449[4b000] via P2P/IPC/read
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
202: hkn0531:1255138:1255243 [2] NCCL INFO Channel 00 : 202[ca000] -> 201[4b000] via P2P/IPC/read
500: hkn0814:700164:700310 [0] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
489: hkn0809:961668:961775 [1] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
 26: hkn0410:1184027:1184146 [2] NCCL INFO Channel 01 : 26[ca000] -> 25[4b000] via P2P/IPC/read
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
190: hkn0528:1326060:1326165 [2] NCCL INFO Channel 01 : 190[ca000] -> 189[4b000] via P2P/IPC/read
493: hkn0810:963905:964027 [1] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
194: hkn0529:1565143:1565270 [2] NCCL INFO Channel 00 : 194[ca000] -> 193[4b000] via P2P/IPC/read
198: hkn0530:1282474:1282589 [2] NCCL INFO Channel 01 : 198[ca000] -> 197[4b000] via P2P/IPC/read
402: hkn0720:33772:33907 [2] NCCL INFO Channel 01 : 402[ca000] -> 401[4b000] via P2P/IPC/read
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
222: hkn0602:3390386:3390580 [2] NCCL INFO Channel 00 : 222[ca000] -> 221[4b000] via P2P/IPC/read
149: hkn0514:2975087:2975198 [1] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
492: hkn0810:963933:964030 [0] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
218: hkn0601:142216:142337 [2] NCCL INFO Channel 00 : 218[ca000] -> 217[4b000] via P2P/IPC/read
409: hkn0723:232568:232721 [1] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
365: hkn0711:608392:608506 [1] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
174: hkn0524:1158156:1158250 [2] NCCL INFO Channel 01 : 174[ca000] -> 173[4b000] via P2P/IPC/read
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
282: hkn0622:2045008:2045126 [2] NCCL INFO Channel 00 : 282[ca000] -> 281[4b000] via P2P/IPC/read
325: hkn0634:1545237:1545343 [1] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
101: hkn0502:253402:253515 [1] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
178: hkn0525:1011134:1011249 [2] NCCL INFO Channel 01 : 178[ca000] -> 177[4b000] via P2P/IPC/read
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
509: hkn0816:399926:400042 [1] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
389: hkn0717:19453:19564 [1] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
505: hkn0815:419461:419585 [1] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
210: hkn0534:1172741:1172868 [2] NCCL INFO Channel 00 : 210[ca000] -> 209[4b000] via P2P/IPC/read
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
186: hkn0527:1373294:1373422 [2] NCCL INFO Channel 01 : 186[ca000] -> 185[4b000] via P2P/IPC/read
116: hkn0506:862438:862546 [0] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
421: hkn0726:1572490:1572596 [1] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
501: hkn0814:700172:700309 [1] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
372: hkn0713:494598:494713 [0] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
469: hkn0804:1230034:1230144 [1] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
214: hkn0535:2423350:2423446 [2] NCCL INFO Channel 00 : 214[ca000] -> 213[4b000] via P2P/IPC/read
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
100: hkn0502:253422:253519 [0] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
360: hkn0710:379903:380006 [0] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
226: hkn0603:1437603:1437704 [2] NCCL INFO Channel 00 : 226[ca000] -> 225[4b000] via P2P/IPC/read
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
117: hkn0506:862422:862551 [1] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
496: hkn0812:718245:718354 [0] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
202: hkn0531:1255138:1255243 [2] NCCL INFO Channel 01 : 202[ca000] -> 201[4b000] via P2P/IPC/read
234: hkn0605:736544:736667 [2] NCCL INFO Channel 00 : 234[ca000] -> 233[4b000] via P2P/IPC/read
504: hkn0815:419469:419586 [0] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
230: hkn0604:713539:713662 [2] NCCL INFO Channel 00 : 230[ca000] -> 229[4b000] via P2P/IPC/read
 14: hkn0407:1840633:1840731 [2] NCCL INFO Channel 00 : 14[ca000] -> 13[4b000] via P2P/IPC/read
194: hkn0529:1565143:1565270 [2] NCCL INFO Channel 01 : 194[ca000] -> 193[4b000] via P2P/IPC/read
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
345: hkn0705:807558:807678 [1] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
109: hkn0504:65443:65560 [1] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
300: hkn0628:696392:696486 [0] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
278: hkn0621:2016125:2016216 [2] NCCL INFO Channel 00 : 278[ca000] -> 277[4b000] via P2P/IPC/read
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
344: hkn0705:807566:807679 [0] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
282: hkn0622:2045008:2045126 [2] NCCL INFO Channel 01 : 282[ca000] -> 281[4b000] via P2P/IPC/read
206: hkn0532:950453:950783 [2] NCCL INFO Channel 01 : 206[ca000] -> 205[4b000] via P2P/IPC/read
286: hkn0623:1897143:1897243 [2] NCCL INFO Channel 00 : 286[ca000] -> 285[4b000] via P2P/IPC/read
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
485: hkn0808:995038:995153 [1] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
508: hkn0816:399946:400046 [0] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
210: hkn0534:1172741:1172868 [2] NCCL INFO Channel 01 : 210[ca000] -> 209[4b000] via P2P/IPC/read
242: hkn0607:928725:928850 [2] NCCL INFO Channel 00 : 242[ca000] -> 241[4b000] via P2P/IPC/read
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
388: hkn0717:19465:19565 [0] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
  1: hkn0403:1808437:1808809 [1] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
266: hkn0615:438703:438813 [2] NCCL INFO Channel 00 : 266[ca000] -> 265[4b000] via P2P/IPC/read
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
182: hkn0526:1452774:1452881 [2] NCCL INFO Channel 00 : 182[ca000] -> 181[4b000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
370: hkn0712:319448:319543 [2] NCCL INFO Channel 00 : 370[ca000] -> 369[4b000] via P2P/IPC/read
484: hkn0808:995046:995154 [0] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
408: hkn0723:232560:232720 [0] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
405: hkn0721:2323871:2323991 [1] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
238: hkn0606:2396571:2396682 [2] NCCL INFO Channel 00 : 238[ca000] -> 237[4b000] via P2P/IPC/read
214: hkn0535:2423350:2423446 [2] NCCL INFO Channel 01 : 214[ca000] -> 213[4b000] via P2P/IPC/read
  5: hkn0404:1363874:1363976 [1] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
380: hkn0715:426268:426388 [0] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
368: hkn0712:319436:319546 [0] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
246: hkn0608:510072:510180 [2] NCCL INFO Channel 00 : 246[ca000] -> 245[4b000] via P2P/IPC/read
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
262: hkn0613:927118:927210 [2] NCCL INFO Channel 00 : 262[ca000] -> 261[4b000] via P2P/IPC/read
230: hkn0604:713539:713662 [2] NCCL INFO Channel 01 : 230[ca000] -> 229[4b000] via P2P/IPC/read
437: hkn0731:1411116:1411213 [1] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
 18: hkn0408:2915278:2915387 [2] NCCL INFO Channel 00 : 18[ca000] -> 17[4b000] via P2P/IPC/read
293: hkn0626:1322798:1322932 [1] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
108: hkn0504:65435:65559 [0] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
278: hkn0621:2016125:2016216 [2] NCCL INFO Channel 01 : 278[ca000] -> 277[4b000] via P2P/IPC/read
341: hkn0704:816354:816450 [1] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
356: hkn0708:437611:437707 [0] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
270: hkn0616:429406:429526 [2] NCCL INFO Channel 00 : 270[ca000] -> 269[4b000] via P2P/IPC/read
222: hkn0602:3390386:3390580 [2] NCCL INFO Channel 01 : 222[ca000] -> 221[4b000] via P2P/IPC/read
218: hkn0601:142216:142337 [2] NCCL INFO Channel 01 : 218[ca000] -> 217[4b000] via P2P/IPC/read
337: hkn0703:765546:765657 [1] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
453: hkn0736:1532616:1532726 [1] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
286: hkn0623:1897143:1897243 [2] NCCL INFO Channel 01 : 286[ca000] -> 285[4b000] via P2P/IPC/read
226: hkn0603:1437603:1437704 [2] NCCL INFO Channel 01 : 226[ca000] -> 225[4b000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
258: hkn0612:941345:941470 [2] NCCL INFO Channel 00 : 258[ca000] -> 257[4b000] via P2P/IPC/read
369: hkn0712:319420:319542 [1] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
373: hkn0713:494610:494705 [1] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
234: hkn0605:736544:736667 [2] NCCL INFO Channel 01 : 234[ca000] -> 233[4b000] via P2P/IPC/read
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
 14: hkn0407:1840633:1840731 [2] NCCL INFO Channel 01 : 14[ca000] -> 13[4b000] via P2P/IPC/read
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
238: hkn0606:2396571:2396682 [2] NCCL INFO Channel 01 : 238[ca000] -> 237[4b000] via P2P/IPC/read
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
182: hkn0526:1452774:1452881 [2] NCCL INFO Channel 01 : 182[ca000] -> 181[4b000] via P2P/IPC/read
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
370: hkn0712:319448:319543 [2] NCCL INFO Channel 01 : 370[ca000] -> 369[4b000] via P2P/IPC/read
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
274: hkn0617:2319200:2319315 [2] NCCL INFO Channel 00 : 274[ca000] -> 273[4b000] via P2P/IPC/read
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
262: hkn0613:927118:927210 [2] NCCL INFO Channel 01 : 262[ca000] -> 261[4b000] via P2P/IPC/read
246: hkn0608:510072:510180 [2] NCCL INFO Channel 01 : 246[ca000] -> 245[4b000] via P2P/IPC/read
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
465: hkn0803:900978:901109 [1] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
266: hkn0615:438703:438813 [2] NCCL INFO Channel 01 : 266[ca000] -> 265[4b000] via P2P/IPC/read
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
204: hkn0532:950481:950779 [0] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
242: hkn0607:928725:928850 [2] NCCL INFO Channel 01 : 242[ca000] -> 241[4b000] via P2P/IPC/read
 18: hkn0408:2915278:2915387 [2] NCCL INFO Channel 01 : 18[ca000] -> 17[4b000] via P2P/IPC/read
270: hkn0616:429406:429526 [2] NCCL INFO Channel 01 : 270[ca000] -> 269[4b000] via P2P/IPC/read
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
381: hkn0715:426296:426395 [1] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
309: hkn0630:1622860:1622960 [1] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
384: hkn0716:132827:132967 [0] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
258: hkn0612:941345:941470 [2] NCCL INFO Channel 01 : 258[ca000] -> 257[4b000] via P2P/IPC/read
422: hkn0726:1572474:1572594 [2] NCCL INFO Channel 00 : 422[ca000] -> 421[4b000] via P2P/IPC/read
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
348: hkn0706:776612:776722 [0] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
165: hkn0521:1222177:1222293 [1] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
 21: hkn0409:2610008:2610115 [1] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
349: hkn0706:776624:776729 [1] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
197: hkn0530:1282466:1282581 [1] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
400: hkn0720:33752:33908 [0] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
274: hkn0617:2319200:2319315 [2] NCCL INFO Channel 01 : 274[ca000] -> 273[4b000] via P2P/IPC/read
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
254: hkn0611:734166:734276 [2] NCCL INFO Channel 00 : 254[ca000] -> 253[4b000] via P2P/IPC/read
376: hkn0714:456371:456476 [0] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
250: hkn0609:735166:735258 [2] NCCL INFO Channel 00 : 250[ca000] -> 249[4b000] via P2P/IPC/read
232: hkn0605:736552:736663 [0] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
377: hkn0714:456383:456480 [1] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
422: hkn0726:1572474:1572594 [2] NCCL INFO Channel 01 : 422[ca000] -> 421[4b000] via P2P/IPC/read
217: hkn0601:142232:142341 [1] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
216: hkn0601:142244:142342 [0] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
250: hkn0609:735166:735258 [2] NCCL INFO Channel 01 : 250[ca000] -> 249[4b000] via P2P/IPC/read
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
256: hkn0612:941333:941464 [0] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
301: hkn0628:696372:696489 [1] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
254: hkn0611:734166:734276 [2] NCCL INFO Channel 01 : 254[ca000] -> 253[4b000] via P2P/IPC/read
240: hkn0607:928741:928852 [0] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
205: hkn0532:950469:950780 [1] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 00 : 68[31000] -> 71[e3000] via P2P/IPC/read
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
357: hkn0708:437583:437699 [1] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
 69: hkn0422:4177485:4177589 [1] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
401: hkn0720:33760:33906 [1] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
233: hkn0605:736560:736669 [1] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
265: hkn0615:438714:438810 [1] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
464: hkn0803:901006:901108 [0] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
264: hkn0615:438687:438806 [0] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
133: hkn0510:2786407:2786523 [1] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
257: hkn0612:941317:941465 [1] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 01 : 68[31000] -> 71[e3000] via P2P/IPC/read
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 00 : 84[31000] -> 87[e3000] via P2P/IPC/read
 85: hkn0426:838392:838518 [1] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
268: hkn0616:429398:429527 [0] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
241: hkn0607:928753:928855 [1] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
229: hkn0604:713547:713656 [1] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
213: hkn0535:2423328:2423441 [1] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 00 : 64[31000] -> 67[e3000] via P2P/IPC/read
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
385: hkn0716:132811:132965 [1] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
181: hkn0526:1452758:1452883 [1] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
245: hkn0608:510084:510183 [1] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
 37: hkn0413:2391086:2391193 [1] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 01 : 84[31000] -> 87[e3000] via P2P/IPC/read
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
228: hkn0604:713559:713655 [0] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 00 : 72[31000] -> 75[e3000] via P2P/IPC/read
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 00 : 136[31000] -> 139[e3000] via P2P/IPC/read
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
 53: hkn0418:1893541:1893660 [1] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
277: hkn0621:2016097:2016215 [1] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
488: hkn0809:961652:961773 [0] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 01 : 64[31000] -> 67[e3000] via P2P/IPC/read
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
261: hkn0613:927098:927209 [1] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
361: hkn0710:379895:380014 [1] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
260: hkn0613:927106:927208 [0] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 00 : 44[31000] -> 47[e3000] via P2P/IPC/read
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 00 : 88[31000] -> 91[e3000] via P2P/IPC/read
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 00 : 76[31000] -> 79[e3000] via P2P/IPC/read
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
497: hkn0812:718229:718349 [1] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 00 : 60[31000] -> 63[e3000] via P2P/IPC/read
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 01 : 72[31000] -> 75[e3000] via P2P/IPC/read
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 01 : 136[31000] -> 139[e3000] via P2P/IPC/read
489: hkn0809:961668:961775 [1] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 00 : 92[31000] -> 95[e3000] via P2P/IPC/read
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 00 : 152[31000] -> 155[e3000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
488: hkn0809:961652:961773 [0] NCCL INFO Channel 00 : 488[31000] -> 491[e3000] via P2P/IPC/read
409: hkn0723:232568:232721 [1] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 00 : 132[31000] -> 135[e3000] via P2P/IPC/read
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 00 : 104[31000] -> 107[e3000] via P2P/IPC/read
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 00 : 56[31000] -> 59[e3000] via P2P/IPC/read
365: hkn0711:608392:608506 [1] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
500: hkn0814:700164:700310 [0] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 01 : 44[31000] -> 47[e3000] via P2P/IPC/read
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 01 : 76[31000] -> 79[e3000] via P2P/IPC/read
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 01 : 88[31000] -> 91[e3000] via P2P/IPC/read
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 00 : 80[31000] -> 83[e3000] via P2P/IPC/read
389: hkn0717:19453:19564 [1] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 00 : 52[31000] -> 55[e3000] via P2P/IPC/read
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 01 : 60[31000] -> 63[e3000] via P2P/IPC/read
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 00 : 36[31000] -> 39[e3000] via P2P/IPC/read
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 00 : 96[31000] -> 99[e3000] via P2P/IPC/read
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
509: hkn0816:399926:400042 [1] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
493: hkn0810:963905:964027 [1] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
149: hkn0514:2975087:2975198 [1] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 01 : 92[31000] -> 95[e3000] via P2P/IPC/read
372: hkn0713:494598:494713 [0] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
101: hkn0502:253402:253515 [1] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 01 : 152[31000] -> 155[e3000] via P2P/IPC/read
360: hkn0710:379903:380006 [0] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
492: hkn0810:963933:964030 [0] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
269: hkn0616:429426:429521 [1] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
505: hkn0815:419461:419585 [1] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 00 : 112[31000] -> 115[e3000] via P2P/IPC/read
109: hkn0504:65443:65560 [1] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
300: hkn0628:696392:696486 [0] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
325: hkn0634:1545237:1545343 [1] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
501: hkn0814:700172:700309 [1] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
249: hkn0609:735138:735259 [1] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
488: hkn0809:961652:961773 [0] NCCL INFO Channel 01 : 488[31000] -> 491[e3000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 00 : 40[31000] -> 43[e3000] via P2P/IPC/read
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 01 : 104[31000] -> 107[e3000] via P2P/IPC/read
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
388: hkn0717:19465:19565 [0] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
469: hkn0804:1230034:1230144 [1] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
248: hkn0609:735146:735265 [0] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 01 : 132[31000] -> 135[e3000] via P2P/IPC/read
100: hkn0502:253422:253519 [0] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 01 : 56[31000] -> 59[e3000] via P2P/IPC/read
421: hkn0726:1572490:1572596 [1] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
504: hkn0815:419469:419586 [0] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 00 : 140[31000] -> 143[e3000] via P2P/IPC/read
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 01 : 80[31000] -> 83[e3000] via P2P/IPC/read
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 01 : 52[31000] -> 55[e3000] via P2P/IPC/read
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
116: hkn0506:862438:862546 [0] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 00 : 304[31000] -> 307[e3000] via P2P/IPC/read
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 00 : 436[31000] -> 439[e3000] via P2P/IPC/read
364: hkn0711:608404:608498 [0] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
244: hkn0608:510064:510177 [0] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
500: hkn0814:700164:700310 [0] NCCL INFO Channel 00 : 500[31000] -> 503[e3000] via P2P/IPC/read
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 01 : 36[31000] -> 39[e3000] via P2P/IPC/read
117: hkn0506:862422:862551 [1] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 00 : 396[31000] -> 399[e3000] via P2P/IPC/read
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 00 : 316[31000] -> 319[e3000] via P2P/IPC/read
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 00 : 28[31000] -> 31[e3000] via P2P/IPC/read
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 01 : 96[31000] -> 99[e3000] via P2P/IPC/read
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 00 : 128[31000] -> 131[e3000] via P2P/IPC/read
485: hkn0808:995038:995153 [1] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 00 : 120[31000] -> 123[e3000] via P2P/IPC/read
345: hkn0705:807558:807678 [1] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
380: hkn0715:426268:426388 [0] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
408: hkn0723:232560:232720 [0] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
  5: hkn0404:1363874:1363976 [1] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
508: hkn0816:399946:400046 [0] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
496: hkn0812:718245:718354 [0] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
368: hkn0712:319436:319546 [0] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
344: hkn0705:807566:807679 [0] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
484: hkn0808:995046:995154 [0] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 01 : 112[31000] -> 115[e3000] via P2P/IPC/read
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
437: hkn0731:1411116:1411213 [1] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 00 : 4[31000] -> 7[e3000] via P2P/IPC/read
372: hkn0713:494598:494713 [0] NCCL INFO Channel 00 : 372[31000] -> 375[e3000] via P2P/IPC/read
  1: hkn0403:1808437:1808809 [1] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 01 : 40[31000] -> 43[e3000] via P2P/IPC/read
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 00 : 144[31000] -> 147[e3000] via P2P/IPC/read
492: hkn0810:963933:964030 [0] NCCL INFO Channel 00 : 492[31000] -> 495[e3000] via P2P/IPC/read
108: hkn0504:65435:65559 [0] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
360: hkn0710:379903:380006 [0] NCCL INFO Channel 00 : 360[31000] -> 363[e3000] via P2P/IPC/read
300: hkn0628:696392:696486 [0] NCCL INFO Channel 00 : 300[31000] -> 303[e3000] via P2P/IPC/read
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
405: hkn0721:2323871:2323991 [1] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 00 : 148[31000] -> 151[e3000] via P2P/IPC/read
356: hkn0708:437611:437707 [0] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 00 : 124[31000] -> 127[e3000] via P2P/IPC/read
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 00 : 332[31000] -> 335[e3000] via P2P/IPC/read
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 00 : 420[31000] -> 423[e3000] via P2P/IPC/read
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 01 : 304[31000] -> 307[e3000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 01 : 140[31000] -> 143[e3000] via P2P/IPC/read
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
373: hkn0713:494610:494705 [1] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 00 : 320[31000] -> 323[e3000] via P2P/IPC/read
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 01 : 436[31000] -> 439[e3000] via P2P/IPC/read
341: hkn0704:816354:816450 [1] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
500: hkn0814:700164:700310 [0] NCCL INFO Channel 01 : 500[31000] -> 503[e3000] via P2P/IPC/read
388: hkn0717:19465:19565 [0] NCCL INFO Channel 00 : 388[31000] -> 391[e3000] via P2P/IPC/read
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 01 : 396[31000] -> 399[e3000] via P2P/IPC/read
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 00 : 444[31000] -> 447[e3000] via P2P/IPC/read
337: hkn0703:765546:765657 [1] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
100: hkn0502:253422:253519 [0] NCCL INFO Channel 00 : 100[31000] -> 103[e3000] via P2P/IPC/read
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 01 : 28[31000] -> 31[e3000] via P2P/IPC/read
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
453: hkn0736:1532616:1532726 [1] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
504: hkn0815:419469:419586 [0] NCCL INFO Channel 00 : 504[31000] -> 507[e3000] via P2P/IPC/read
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 01 : 128[31000] -> 131[e3000] via P2P/IPC/read
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 00 : 480[31000] -> 483[e3000] via P2P/IPC/read
465: hkn0803:900978:901109 [1] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
293: hkn0626:1322798:1322932 [1] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
369: hkn0712:319420:319542 [1] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 01 : 120[31000] -> 123[e3000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 00 : 468[31000] -> 471[e3000] via P2P/IPC/read
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 00 : 392[31000] -> 395[e3000] via P2P/IPC/read
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 00 : 472[31000] -> 475[e3000] via P2P/IPC/read
204: hkn0532:950481:950779 [0] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 00 : 324[31000] -> 327[e3000] via P2P/IPC/read
116: hkn0506:862438:862546 [0] NCCL INFO Channel 00 : 116[31000] -> 119[e3000] via P2P/IPC/read
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
252: hkn0611:734178:734279 [0] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 00 : 364[31000] -> 367[e3000] via P2P/IPC/read
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
372: hkn0713:494598:494713 [0] NCCL INFO Channel 01 : 372[31000] -> 375[e3000] via P2P/IPC/read
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 01 : 4[31000] -> 7[e3000] via P2P/IPC/read
380: hkn0715:426268:426388 [0] NCCL INFO Channel 00 : 380[31000] -> 383[e3000] via P2P/IPC/read
384: hkn0716:132827:132967 [0] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
368: hkn0712:319436:319546 [0] NCCL INFO Channel 00 : 368[31000] -> 371[e3000] via P2P/IPC/read
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
492: hkn0810:963933:964030 [0] NCCL INFO Channel 01 : 492[31000] -> 495[e3000] via P2P/IPC/read
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 00 : 0[31000] -> 3[e3000] via P2P/IPC/read
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 01 : 144[31000] -> 147[e3000] via P2P/IPC/read
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
344: hkn0705:807566:807679 [0] NCCL INFO Channel 00 : 344[31000] -> 347[e3000] via P2P/IPC/read
381: hkn0715:426296:426395 [1] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 00 : 412[31000] -> 415[e3000] via P2P/IPC/read
408: hkn0723:232560:232720 [0] NCCL INFO Channel 00 : 408[31000] -> 411[e3000] via P2P/IPC/read
360: hkn0710:379903:380006 [0] NCCL INFO Channel 01 : 360[31000] -> 363[e3000] via P2P/IPC/read
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 00 : 24[31000] -> 27[e3000] via P2P/IPC/read
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 01 : 148[31000] -> 151[e3000] via P2P/IPC/read
508: hkn0816:399946:400046 [0] NCCL INFO Channel 00 : 508[31000] -> 511[e3000] via P2P/IPC/read
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
484: hkn0808:995046:995154 [0] NCCL INFO Channel 00 : 484[31000] -> 487[e3000] via P2P/IPC/read
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 01 : 124[31000] -> 127[e3000] via P2P/IPC/read
 71: hkn0422:4177497:4177588 [3] NCCL INFO Channel 00 : 71[e3000] -> 70[ca000] via P2P/IPC/read
356: hkn0708:437611:437707 [0] NCCL INFO Channel 00 : 356[31000] -> 359[e3000] via P2P/IPC/read
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 01 : 420[31000] -> 423[e3000] via P2P/IPC/read
496: hkn0812:718245:718354 [0] NCCL INFO Channel 00 : 496[31000] -> 499[e3000] via P2P/IPC/read
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 01 : 320[31000] -> 323[e3000] via P2P/IPC/read
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
388: hkn0717:19465:19565 [0] NCCL INFO Channel 01 : 388[31000] -> 391[e3000] via P2P/IPC/read
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 00 : 476[31000] -> 479[e3000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 00 : 32[31000] -> 35[e3000] via P2P/IPC/read
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 01 : 444[31000] -> 447[e3000] via P2P/IPC/read
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 01 : 332[31000] -> 335[e3000] via P2P/IPC/read
108: hkn0504:65435:65559 [0] NCCL INFO Channel 00 : 108[31000] -> 111[e3000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 00 : 404[31000] -> 407[e3000] via P2P/IPC/read
340: hkn0704:816342:816447 [0] NCCL INFO Channel 00 : 340[31000] -> 343[e3000] via P2P/IPC/read
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
100: hkn0502:253422:253519 [0] NCCL INFO Channel 01 : 100[31000] -> 103[e3000] via P2P/IPC/read
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
504: hkn0815:419469:419586 [0] NCCL INFO Channel 01 : 504[31000] -> 507[e3000] via P2P/IPC/read
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 01 : 480[31000] -> 483[e3000] via P2P/IPC/read
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 01 : 316[31000] -> 319[e3000] via P2P/IPC/read
309: hkn0630:1622860:1622960 [1] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
300: hkn0628:696392:696486 [0] NCCL INFO Channel 01 : 300[31000] -> 303[e3000] via P2P/IPC/read
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 01 : 324[31000] -> 327[e3000] via P2P/IPC/read
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 00 : 168[31000] -> 171[e3000] via P2P/IPC/read
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 01 : 468[31000] -> 471[e3000] via P2P/IPC/read
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 01 : 392[31000] -> 395[e3000] via P2P/IPC/read
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 01 : 472[31000] -> 475[e3000] via P2P/IPC/read
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
116: hkn0506:862438:862546 [0] NCCL INFO Channel 01 : 116[31000] -> 119[e3000] via P2P/IPC/read
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 00 : 452[31000] -> 455[e3000] via P2P/IPC/read
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 01 : 364[31000] -> 367[e3000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 00 : 336[31000] -> 339[e3000] via P2P/IPC/read
380: hkn0715:426268:426388 [0] NCCL INFO Channel 01 : 380[31000] -> 383[e3000] via P2P/IPC/read
368: hkn0712:319436:319546 [0] NCCL INFO Channel 01 : 368[31000] -> 371[e3000] via P2P/IPC/read
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 01 : 412[31000] -> 415[e3000] via P2P/IPC/read
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 01 : 0[31000] -> 3[e3000] via P2P/IPC/read
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 00 : 292[31000] -> 295[e3000] via P2P/IPC/read
400: hkn0720:33752:33908 [0] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 00 : 448[31000] -> 451[e3000] via P2P/IPC/read
344: hkn0705:807566:807679 [0] NCCL INFO Channel 01 : 344[31000] -> 347[e3000] via P2P/IPC/read
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
408: hkn0723:232560:232720 [0] NCCL INFO Channel 01 : 408[31000] -> 411[e3000] via P2P/IPC/read
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 00 : 312[31000] -> 315[e3000] via P2P/IPC/read
508: hkn0816:399946:400046 [0] NCCL INFO Channel 01 : 508[31000] -> 511[e3000] via P2P/IPC/read
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 00 : 416[31000] -> 419[e3000] via P2P/IPC/read
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 01 : 24[31000] -> 27[e3000] via P2P/IPC/read
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 00 : 424[31000] -> 427[e3000] via P2P/IPC/read
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
 87: hkn0426:838380:838520 [3] NCCL INFO Channel 00 : 87[e3000] -> 86[ca000] via P2P/IPC/read
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
484: hkn0808:995046:995154 [0] NCCL INFO Channel 01 : 484[31000] -> 487[e3000] via P2P/IPC/read
348: hkn0706:776612:776722 [0] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
356: hkn0708:437611:437707 [0] NCCL INFO Channel 01 : 356[31000] -> 359[e3000] via P2P/IPC/read
496: hkn0812:718245:718354 [0] NCCL INFO Channel 01 : 496[31000] -> 499[e3000] via P2P/IPC/read
384: hkn0716:132827:132967 [0] NCCL INFO Channel 00 : 384[31000] -> 387[e3000] via P2P/IPC/read
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 00 : 296[31000] -> 299[e3000] via P2P/IPC/read
165: hkn0521:1222177:1222293 [1] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 01 : 476[31000] -> 479[e3000] via P2P/IPC/read
232: hkn0605:736552:736663 [0] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
204: hkn0532:950481:950779 [0] NCCL INFO Channel 00 : 204[31000] -> 207[e3000] via P2P/IPC/read
 71: hkn0422:4177497:4177588 [3] NCCL INFO Channel 01 : 71[e3000] -> 70[ca000] via P2P/IPC/read
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 01 : 32[31000] -> 35[e3000] via P2P/IPC/read
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
 21: hkn0409:2610008:2610115 [1] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
108: hkn0504:65435:65559 [0] NCCL INFO Channel 01 : 108[31000] -> 111[e3000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 01 : 404[31000] -> 407[e3000] via P2P/IPC/read
340: hkn0704:816342:816447 [0] NCCL INFO Channel 01 : 340[31000] -> 343[e3000] via P2P/IPC/read
 67: hkn0421:2208711:2208878 [3] NCCL INFO Channel 00 : 67[e3000] -> 66[ca000] via P2P/IPC/read
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 00 : 428[31000] -> 431[e3000] via P2P/IPC/read
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 01 : 168[31000] -> 171[e3000] via P2P/IPC/read
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 00 : 328[31000] -> 331[e3000] via P2P/IPC/read
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 01 : 452[31000] -> 455[e3000] via P2P/IPC/read
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 00 : 352[31000] -> 355[e3000] via P2P/IPC/read
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 00 : 308[31000] -> 311[e3000] via P2P/IPC/read
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
197: hkn0530:1282466:1282581 [1] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 00 : 16[31000] -> 19[e3000] via P2P/IPC/read
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
301: hkn0628:696372:696489 [1] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
336: hkn0703:765538:765661 [0] NCCL INFO Channel 01 : 336[31000] -> 339[e3000] via P2P/IPC/read
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 00 : 460[31000] -> 463[e3000] via P2P/IPC/read
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 01 : 292[31000] -> 295[e3000] via P2P/IPC/read
376: hkn0714:456371:456476 [0] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 00 : 288[31000] -> 291[e3000] via P2P/IPC/read
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 00 : 8[31000] -> 11[e3000] via P2P/IPC/read
256: hkn0612:941333:941464 [0] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 01 : 448[31000] -> 451[e3000] via P2P/IPC/read
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 01 : 312[31000] -> 315[e3000] via P2P/IPC/read
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 01 : 424[31000] -> 427[e3000] via P2P/IPC/read
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 01 : 416[31000] -> 419[e3000] via P2P/IPC/read
377: hkn0714:456383:456480 [1] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
240: hkn0607:928741:928852 [0] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
 87: hkn0426:838380:838520 [3] NCCL INFO Channel 01 : 87[e3000] -> 86[ca000] via P2P/IPC/read
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
139: hkn0511:3090869:3090995 [3] NCCL INFO Channel 00 : 139[e3000] -> 138[ca000] via P2P/IPC/read
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
384: hkn0716:132827:132967 [0] NCCL INFO Channel 01 : 384[31000] -> 387[e3000] via P2P/IPC/read
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 01 : 296[31000] -> 299[e3000] via P2P/IPC/read
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 00 : 188[31000] -> 191[e3000] via P2P/IPC/read
204: hkn0532:950481:950779 [0] NCCL INFO Channel 01 : 204[31000] -> 207[e3000] via P2P/IPC/read
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 00 : 176[31000] -> 179[e3000] via P2P/IPC/read
349: hkn0706:776624:776729 [1] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
217: hkn0601:142232:142341 [1] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
 67: hkn0421:2208711:2208878 [3] NCCL INFO Channel 01 : 67[e3000] -> 66[ca000] via P2P/IPC/read
205: hkn0532:950469:950780 [1] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 01 : 428[31000] -> 431[e3000] via P2P/IPC/read
232: hkn0605:736552:736663 [0] NCCL INFO Channel 00 : 232[31000] -> 235[e3000] via P2P/IPC/read
348: hkn0706:776612:776722 [0] NCCL INFO Channel 00 : 348[31000] -> 351[e3000] via P2P/IPC/read
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
216: hkn0601:142244:142342 [0] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
265: hkn0615:438714:438810 [1] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 01 : 328[31000] -> 331[e3000] via P2P/IPC/read
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 00 : 164[31000] -> 167[e3000] via P2P/IPC/read
 79: hkn0424:2972333:2972431 [3] NCCL INFO Channel 00 : 79[e3000] -> 78[ca000] via P2P/IPC/read
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 01 : 308[31000] -> 311[e3000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
 47: hkn0415:2520751:2520864 [3] NCCL INFO Channel 00 : 47[e3000] -> 46[ca000] via P2P/IPC/read
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 00 : 12[31000] -> 15[e3000] via P2P/IPC/read
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 01 : 352[31000] -> 355[e3000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 01 : 16[31000] -> 19[e3000] via P2P/IPC/read
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 00 : 172[31000] -> 175[e3000] via P2P/IPC/read
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 00 : 196[31000] -> 199[e3000] via P2P/IPC/read
233: hkn0605:736560:736669 [1] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
 63: hkn0420:3234583:3234690 [3] NCCL INFO Channel 00 : 63[e3000] -> 62[ca000] via P2P/IPC/read
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 01 : 288[31000] -> 291[e3000] via P2P/IPC/read
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 01 : 460[31000] -> 463[e3000] via P2P/IPC/read
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 01 : 8[31000] -> 11[e3000] via P2P/IPC/read
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 00 : 220[31000] -> 223[e3000] via P2P/IPC/read
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 00 : 432[31000] -> 435[e3000] via P2P/IPC/read
 91: hkn0427:1159506:1159619 [3] NCCL INFO Channel 00 : 91[e3000] -> 90[ca000] via P2P/IPC/read
400: hkn0720:33752:33908 [0] NCCL INFO Channel 00 : 400[31000] -> 403[e3000] via P2P/IPC/read
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 00 : 272[31000] -> 275[e3000] via P2P/IPC/read
 75: hkn0423:1729394:1729515 [3] NCCL INFO Channel 00 : 75[e3000] -> 74[ca000] via P2P/IPC/read
155: hkn0515:2921202:2921330 [3] NCCL INFO Channel 00 : 155[e3000] -> 154[ca000] via P2P/IPC/read
256: hkn0612:941333:941464 [0] NCCL INFO Channel 00 : 256[31000] -> 259[e3000] via P2P/IPC/read
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 00 : 48[31000] -> 51[e3000] via P2P/IPC/read
268: hkn0616:429398:429527 [0] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
139: hkn0511:3090869:3090995 [3] NCCL INFO Channel 01 : 139[e3000] -> 138[ca000] via P2P/IPC/read
 95: hkn0428:691724:691842 [3] NCCL INFO Channel 00 : 95[e3000] -> 94[ca000] via P2P/IPC/read
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 01 : 188[31000] -> 191[e3000] via P2P/IPC/read
376: hkn0714:456371:456476 [0] NCCL INFO Channel 00 : 376[31000] -> 379[e3000] via P2P/IPC/read
240: hkn0607:928741:928852 [0] NCCL INFO Channel 00 : 240[31000] -> 243[e3000] via P2P/IPC/read
253: hkn0611:734158:734277 [1] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
257: hkn0612:941317:941465 [1] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 01 : 176[31000] -> 179[e3000] via P2P/IPC/read
264: hkn0615:438687:438806 [0] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
232: hkn0605:736552:736663 [0] NCCL INFO Channel 01 : 232[31000] -> 235[e3000] via P2P/IPC/read
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 00 : 456[31000] -> 459[e3000] via P2P/IPC/read
491: hkn0809:961660:961772 [3] NCCL INFO Channel 00 : 491[e3000] -> 490[ca000] via P2P/IPC/read
348: hkn0706:776612:776722 [0] NCCL INFO Channel 01 : 348[31000] -> 351[e3000] via P2P/IPC/read
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 00 : 184[31000] -> 187[e3000] via P2P/IPC/read
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 01 : 164[31000] -> 167[e3000] via P2P/IPC/read
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
363: hkn0710:379887:380008 [3] NCCL INFO Channel 00 : 363[e3000] -> 362[ca000] via P2P/IPC/read
241: hkn0607:928753:928855 [1] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
135: hkn0510:2786399:2786524 [3] NCCL INFO Channel 00 : 135[e3000] -> 134[ca000] via P2P/IPC/read
 59: hkn0419:1568607:1568710 [3] NCCL INFO Channel 00 : 59[e3000] -> 58[ca000] via P2P/IPC/read
 47: hkn0415:2520751:2520864 [3] NCCL INFO Channel 01 : 47[e3000] -> 46[ca000] via P2P/IPC/read
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 01 : 12[31000] -> 15[e3000] via P2P/IPC/read
 79: hkn0424:2972333:2972431 [3] NCCL INFO Channel 01 : 79[e3000] -> 78[ca000] via P2P/IPC/read
 83: hkn0425:2108537:2108638 [3] NCCL INFO Channel 00 : 83[e3000] -> 82[ca000] via P2P/IPC/read
 71: hkn0422:4177497:4177588 [3] NCCL INFO Connected all rings
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
229: hkn0604:713547:713656 [1] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 01 : 172[31000] -> 175[e3000] via P2P/IPC/read
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 01 : 196[31000] -> 199[e3000] via P2P/IPC/read
216: hkn0601:142244:142342 [0] NCCL INFO Channel 00 : 216[31000] -> 219[e3000] via P2P/IPC/read
 39: hkn0413:2391070:2391199 [3] NCCL INFO Channel 00 : 39[e3000] -> 38[ca000] via P2P/IPC/read
 63: hkn0420:3234583:3234690 [3] NCCL INFO Channel 01 : 63[e3000] -> 62[ca000] via P2P/IPC/read
391: hkn0717:19437:19568 [3] NCCL INFO Channel 00 : 391[e3000] -> 390[ca000] via P2P/IPC/read
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 00 : 280[31000] -> 283[e3000] via P2P/IPC/read
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 01 : 432[31000] -> 435[e3000] via P2P/IPC/read
 91: hkn0427:1159506:1159619 [3] NCCL INFO Channel 01 : 91[e3000] -> 90[ca000] via P2P/IPC/read
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 01 : 272[31000] -> 275[e3000] via P2P/IPC/read
 55: hkn0418:1893549:1893663 [3] NCCL INFO Channel 00 : 55[e3000] -> 54[ca000] via P2P/IPC/read
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 01 : 220[31000] -> 223[e3000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 00 : 224[31000] -> 227[e3000] via P2P/IPC/read
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
245: hkn0608:510084:510183 [1] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
 99: hkn0501:1352386:1352510 [3] NCCL INFO Channel 00 : 99[e3000] -> 98[ca000] via P2P/IPC/read
155: hkn0515:2921202:2921330 [3] NCCL INFO Channel 01 : 155[e3000] -> 154[ca000] via P2P/IPC/read
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
256: hkn0612:941333:941464 [0] NCCL INFO Channel 01 : 256[31000] -> 259[e3000] via P2P/IPC/read
213: hkn0535:2423328:2423441 [1] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
 95: hkn0428:691724:691842 [3] NCCL INFO Channel 01 : 95[e3000] -> 94[ca000] via P2P/IPC/read
115: hkn0505:2328163:2328258 [3] NCCL INFO Channel 00 : 115[e3000] -> 114[ca000] via P2P/IPC/read
376: hkn0714:456371:456476 [0] NCCL INFO Channel 01 : 376[31000] -> 379[e3000] via P2P/IPC/read
240: hkn0607:928741:928852 [0] NCCL INFO Channel 01 : 240[31000] -> 243[e3000] via P2P/IPC/read
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 01 : 48[31000] -> 51[e3000] via P2P/IPC/read
 75: hkn0423:1729394:1729515 [3] NCCL INFO Channel 01 : 75[e3000] -> 74[ca000] via P2P/IPC/read
400: hkn0720:33752:33908 [0] NCCL INFO Channel 01 : 400[31000] -> 403[e3000] via P2P/IPC/read
 87: hkn0426:838380:838520 [3] NCCL INFO Connected all rings
228: hkn0604:713559:713655 [0] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
181: hkn0526:1452758:1452883 [1] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 01 : 456[31000] -> 459[e3000] via P2P/IPC/read
268: hkn0616:429398:429527 [0] NCCL INFO Channel 00 : 268[31000] -> 271[e3000] via P2P/IPC/read
 43: hkn0414:2006106:2006225 [3] NCCL INFO Channel 00 : 43[e3000] -> 42[ca000] via P2P/IPC/read
363: hkn0710:379887:380008 [3] NCCL INFO Channel 01 : 363[e3000] -> 362[ca000] via P2P/IPC/read
135: hkn0510:2786399:2786524 [3] NCCL INFO Channel 01 : 135[e3000] -> 134[ca000] via P2P/IPC/read
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 01 : 184[31000] -> 187[e3000] via P2P/IPC/read
107: hkn0503:2924178:2924282 [3] NCCL INFO Channel 00 : 107[e3000] -> 106[ca000] via P2P/IPC/read
 59: hkn0419:1568607:1568710 [3] NCCL INFO Channel 01 : 59[e3000] -> 58[ca000] via P2P/IPC/read
491: hkn0809:961660:961772 [3] NCCL INFO Channel 01 : 491[e3000] -> 490[ca000] via P2P/IPC/read
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
 67: hkn0421:2208711:2208878 [3] NCCL INFO Connected all rings
264: hkn0615:438687:438806 [0] NCCL INFO Channel 00 : 264[31000] -> 267[e3000] via P2P/IPC/read
 83: hkn0425:2108537:2108638 [3] NCCL INFO Channel 01 : 83[e3000] -> 82[ca000] via P2P/IPC/read
216: hkn0601:142244:142342 [0] NCCL INFO Channel 01 : 216[31000] -> 219[e3000] via P2P/IPC/read
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
143: hkn0512:3068470:3068579 [3] NCCL INFO Channel 00 : 143[e3000] -> 142[ca000] via P2P/IPC/read
277: hkn0621:2016097:2016215 [1] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
 39: hkn0413:2391070:2391199 [3] NCCL INFO Channel 01 : 39[e3000] -> 38[ca000] via P2P/IPC/read
391: hkn0717:19437:19568 [3] NCCL INFO Channel 01 : 391[e3000] -> 390[ca000] via P2P/IPC/read
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 01 : 280[31000] -> 283[e3000] via P2P/IPC/read
 31: hkn0411:2340265:2340393 [3] NCCL INFO Channel 00 : 31[e3000] -> 30[ca000] via P2P/IPC/read
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 00 : 200[31000] -> 203[e3000] via P2P/IPC/read
503: hkn0814:700156:700314 [3] NCCL INFO Channel 00 : 503[e3000] -> 502[ca000] via P2P/IPC/read
407: hkn0721:2323889:2323992 [3] NCCL INFO Channel 00 : 407[e3000] -> 406[ca000] via P2P/IPC/read
 55: hkn0418:1893549:1893663 [3] NCCL INFO Channel 01 : 55[e3000] -> 54[ca000] via P2P/IPC/read
307: hkn0629:1616387:1616511 [3] NCCL INFO Channel 00 : 307[e3000] -> 306[ca000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 01 : 224[31000] -> 227[e3000] via P2P/IPC/read
131: hkn0509:3148767:3148876 [3] NCCL INFO Channel 00 : 131[e3000] -> 130[ca000] via P2P/IPC/read
123: hkn0507:3211443:3211567 [3] NCCL INFO Channel 00 : 123[e3000] -> 122[ca000] via P2P/IPC/read
439: hkn0731:1411104:1411206 [3] NCCL INFO Channel 00 : 439[e3000] -> 438[ca000] via P2P/IPC/read
 99: hkn0501:1352386:1352510 [3] NCCL INFO Channel 01 : 99[e3000] -> 98[ca000] via P2P/IPC/read
399: hkn0719:1330267:1330376 [3] NCCL INFO Channel 00 : 399[e3000] -> 398[ca000] via P2P/IPC/read
115: hkn0505:2328163:2328258 [3] NCCL INFO Channel 01 : 115[e3000] -> 114[ca000] via P2P/IPC/read
375: hkn0713:494582:494711 [3] NCCL INFO Channel 00 : 375[e3000] -> 374[ca000] via P2P/IPC/read
  7: hkn0404:1363854:1363975 [3] NCCL INFO Channel 00 : 7[e3000] -> 6[ca000] via P2P/IPC/read
261: hkn0613:927098:927209 [1] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
464: hkn0803:901006:901108 [0] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 00 : 440[31000] -> 443[e3000] via P2P/IPC/read
260: hkn0613:927106:927208 [0] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 00 : 212[31000] -> 215[e3000] via P2P/IPC/read
 43: hkn0414:2006106:2006225 [3] NCCL INFO Channel 01 : 43[e3000] -> 42[ca000] via P2P/IPC/read
495: hkn0810:963921:964028 [3] NCCL INFO Channel 00 : 495[e3000] -> 494[ca000] via P2P/IPC/read
268: hkn0616:429398:429527 [0] NCCL INFO Channel 01 : 268[31000] -> 271[e3000] via P2P/IPC/read
151: hkn0514:2975071:2975199 [3] NCCL INFO Channel 00 : 151[e3000] -> 150[ca000] via P2P/IPC/read
139: hkn0511:3090869:3090995 [3] NCCL INFO Connected all rings
107: hkn0503:2924178:2924282 [3] NCCL INFO Channel 01 : 107[e3000] -> 106[ca000] via P2P/IPC/read
147: hkn0513:3037315:3037440 [3] NCCL INFO Channel 00 : 147[e3000] -> 146[ca000] via P2P/IPC/read
228: hkn0604:713559:713655 [0] NCCL INFO Channel 00 : 228[31000] -> 231[e3000] via P2P/IPC/read
127: hkn0508:3163486:3163600 [3] NCCL INFO Channel 00 : 127[e3000] -> 126[ca000] via P2P/IPC/read
264: hkn0615:438687:438806 [0] NCCL INFO Channel 01 : 264[31000] -> 267[e3000] via P2P/IPC/read
323: hkn0633:1550641:1550758 [3] NCCL INFO Channel 00 : 323[e3000] -> 322[ca000] via P2P/IPC/read
401: hkn0720:33760:33906 [1] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 00 : 208[31000] -> 211[e3000] via P2P/IPC/read
143: hkn0512:3068470:3068579 [3] NCCL INFO Channel 01 : 143[e3000] -> 142[ca000] via P2P/IPC/read
 79: hkn0424:2972333:2972431 [3] NCCL INFO Connected all rings
503: hkn0814:700156:700314 [3] NCCL INFO Channel 01 : 503[e3000] -> 502[ca000] via P2P/IPC/read
447: hkn0733:1413735:1413846 [3] NCCL INFO Channel 00 : 447[e3000] -> 446[ca000] via P2P/IPC/read
319: hkn0632:1782991:1783084 [3] NCCL INFO Channel 00 : 319[e3000] -> 318[ca000] via P2P/IPC/read
407: hkn0721:2323889:2323992 [3] NCCL INFO Channel 01 : 407[e3000] -> 406[ca000] via P2P/IPC/read
 31: hkn0411:2340265:2340393 [3] NCCL INFO Channel 01 : 31[e3000] -> 30[ca000] via P2P/IPC/read
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 01 : 200[31000] -> 203[e3000] via P2P/IPC/read
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 00 : 284[31000] -> 287[e3000] via P2P/IPC/read
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 00 : 180[31000] -> 183[e3000] via P2P/IPC/read
423: hkn0726:1572482:1572597 [3] NCCL INFO Channel 00 : 423[e3000] -> 422[ca000] via P2P/IPC/read
307: hkn0629:1616387:1616511 [3] NCCL INFO Channel 01 : 307[e3000] -> 306[ca000] via P2P/IPC/read
303: hkn0628:696380:696485 [3] NCCL INFO Channel 00 : 303[e3000] -> 302[ca000] via P2P/IPC/read
123: hkn0507:3211443:3211567 [3] NCCL INFO Channel 01 : 123[e3000] -> 122[ca000] via P2P/IPC/read
439: hkn0731:1411104:1411206 [3] NCCL INFO Channel 01 : 439[e3000] -> 438[ca000] via P2P/IPC/read
335: hkn0636:1678732:1678872 [3] NCCL INFO Channel 00 : 335[e3000] -> 334[ca000] via P2P/IPC/read
131: hkn0509:3148767:3148876 [3] NCCL INFO Channel 01 : 131[e3000] -> 130[ca000] via P2P/IPC/read
 47: hkn0415:2520751:2520864 [3] NCCL INFO Connected all rings
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
327: hkn0634:1545249:1545346 [3] NCCL INFO Channel 00 : 327[e3000] -> 326[ca000] via P2P/IPC/read
507: hkn0815:419489:419590 [3] NCCL INFO Channel 00 : 507[e3000] -> 506[ca000] via P2P/IPC/read
395: hkn0718:3941427:3941539 [3] NCCL INFO Channel 00 : 395[e3000] -> 394[ca000] via P2P/IPC/read
431: hkn0728:1348489:1348596 [3] NCCL INFO Channel 00 : 431[e3000] -> 430[ca000] via P2P/IPC/read
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 00 : 276[31000] -> 279[e3000] via P2P/IPC/read
367: hkn0711:608376:608500 [3] NCCL INFO Channel 00 : 367[e3000] -> 366[ca000] via P2P/IPC/read
 91: hkn0427:1159506:1159619 [3] NCCL INFO Connected all rings
375: hkn0713:494582:494711 [3] NCCL INFO Channel 01 : 375[e3000] -> 374[ca000] via P2P/IPC/read
471: hkn0804:1230026:1230141 [3] NCCL INFO Channel 00 : 471[e3000] -> 470[ca000] via P2P/IPC/read
399: hkn0719:1330267:1330376 [3] NCCL INFO Channel 01 : 399[e3000] -> 398[ca000] via P2P/IPC/read
475: hkn0805:1136477:1136585 [3] NCCL INFO Channel 00 : 475[e3000] -> 474[ca000] via P2P/IPC/read
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
 63: hkn0420:3234583:3234690 [3] NCCL INFO Connected all rings
103: hkn0502:253410:253517 [3] NCCL INFO Channel 00 : 103[e3000] -> 102[ca000] via P2P/IPC/read
383: hkn0715:426284:426389 [3] NCCL INFO Channel 00 : 383[e3000] -> 382[ca000] via P2P/IPC/read
119: hkn0506:862430:862542 [3] NCCL INFO Channel 00 : 119[e3000] -> 118[ca000] via P2P/IPC/read
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 01 : 212[31000] -> 215[e3000] via P2P/IPC/read
  7: hkn0404:1363854:1363975 [3] NCCL INFO Channel 01 : 7[e3000] -> 6[ca000] via P2P/IPC/read
415: hkn0724:1740349:1740479 [3] NCCL INFO Channel 00 : 415[e3000] -> 414[ca000] via P2P/IPC/read
483: hkn0807:1043414:1043536 [3] NCCL INFO Channel 00 : 483[e3000] -> 482[ca000] via P2P/IPC/read
371: hkn0712:319428:319537 [3] NCCL INFO Channel 00 : 371[e3000] -> 370[ca000] via P2P/IPC/read
357: hkn0708:437583:437699 [1] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
 95: hkn0428:691724:691842 [3] NCCL INFO Connected all rings
495: hkn0810:963921:964028 [3] NCCL INFO Channel 01 : 495[e3000] -> 494[ca000] via P2P/IPC/read
 27: hkn0410:1184055:1184150 [3] NCCL INFO Channel 00 : 27[e3000] -> 26[ca000] via P2P/IPC/read
151: hkn0514:2975071:2975199 [3] NCCL INFO Channel 01 : 151[e3000] -> 150[ca000] via P2P/IPC/read
155: hkn0515:2921202:2921330 [3] NCCL INFO Connected all rings
  3: hkn0403:1808445:1808808 [3] NCCL INFO Channel 00 : 3[e3000] -> 2[ca000] via P2P/IPC/read
111: hkn0504:65451:65555 [3] NCCL INFO Channel 00 : 111[e3000] -> 110[ca000] via P2P/IPC/read
411: hkn0723:232580:232725 [3] NCCL INFO Channel 00 : 411[e3000] -> 410[ca000] via P2P/IPC/read
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 01 : 440[31000] -> 443[e3000] via P2P/IPC/read
147: hkn0513:3037315:3037440 [3] NCCL INFO Channel 01 : 147[e3000] -> 146[ca000] via P2P/IPC/read
228: hkn0604:713559:713655 [0] NCCL INFO Channel 01 : 228[31000] -> 231[e3000] via P2P/IPC/read
127: hkn0508:3163486:3163600 [3] NCCL INFO Channel 01 : 127[e3000] -> 126[ca000] via P2P/IPC/read
511: hkn0816:399934:400048 [3] NCCL INFO Channel 00 : 511[e3000] -> 510[ca000] via P2P/IPC/read
291: hkn0624:1797274:1797389 [3] NCCL INFO Channel 00 : 291[e3000] -> 290[ca000] via P2P/IPC/read
323: hkn0633:1550641:1550758 [3] NCCL INFO Channel 01 : 323[e3000] -> 322[ca000] via P2P/IPC/read
260: hkn0613:927106:927208 [0] NCCL INFO Channel 00 : 260[31000] -> 263[e3000] via P2P/IPC/read
347: hkn0705:807550:807681 [3] NCCL INFO Channel 00 : 347[e3000] -> 346[ca000] via P2P/IPC/read
487: hkn0808:995030:995156 [3] NCCL INFO Channel 00 : 487[e3000] -> 486[ca000] via P2P/IPC/read
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 01 : 208[31000] -> 211[e3000] via P2P/IPC/read
363: hkn0710:379887:380008 [3] NCCL INFO Connected all rings
499: hkn0812:718257:718355 [3] NCCL INFO Channel 00 : 499[e3000] -> 498[ca000] via P2P/IPC/read
135: hkn0510:2786399:2786524 [3] NCCL INFO Connected all rings
 75: hkn0423:1729394:1729515 [3] NCCL INFO Connected all rings
 59: hkn0419:1568607:1568710 [3] NCCL INFO Connected all rings
491: hkn0809:961660:961772 [3] NCCL INFO Connected all rings
319: hkn0632:1782991:1783084 [3] NCCL INFO Channel 01 : 319[e3000] -> 318[ca000] via P2P/IPC/read
447: hkn0733:1413735:1413846 [3] NCCL INFO Channel 01 : 447[e3000] -> 446[ca000] via P2P/IPC/read
343: hkn0704:816334:816453 [3] NCCL INFO Channel 00 : 343[e3000] -> 342[ca000] via P2P/IPC/read
479: hkn0806:1078660:1078785 [3] NCCL INFO Channel 00 : 479[e3000] -> 478[ca000] via P2P/IPC/read
303: hkn0628:696380:696485 [3] NCCL INFO Channel 01 : 303[e3000] -> 302[ca000] via P2P/IPC/read
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 01 : 180[31000] -> 183[e3000] via P2P/IPC/read
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
 83: hkn0425:2108537:2108638 [3] NCCL INFO Connected all rings
423: hkn0726:1572482:1572597 [3] NCCL INFO Channel 01 : 423[e3000] -> 422[ca000] via P2P/IPC/read
 35: hkn0412:2286751:2286844 [3] NCCL INFO Channel 00 : 35[e3000] -> 34[ca000] via P2P/IPC/read
249: hkn0609:735138:735259 [1] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 00 : 160[31000] -> 163[e3000] via P2P/IPC/read
335: hkn0636:1678732:1678872 [3] NCCL INFO Channel 01 : 335[e3000] -> 334[ca000] via P2P/IPC/read
507: hkn0815:419489:419590 [3] NCCL INFO Channel 01 : 507[e3000] -> 506[ca000] via P2P/IPC/read
395: hkn0718:3941427:3941539 [3] NCCL INFO Channel 01 : 395[e3000] -> 394[ca000] via P2P/IPC/read
327: hkn0634:1545249:1545346 [3] NCCL INFO Channel 01 : 327[e3000] -> 326[ca000] via P2P/IPC/read
455: hkn0736:1532608:1532732 [3] NCCL INFO Channel 00 : 455[e3000] -> 454[ca000] via P2P/IPC/read
431: hkn0728:1348489:1348596 [3] NCCL INFO Channel 01 : 431[e3000] -> 430[ca000] via P2P/IPC/read
248: hkn0609:735146:735265 [0] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
 39: hkn0413:2391070:2391199 [3] NCCL INFO Connected all rings
367: hkn0711:608376:608500 [3] NCCL INFO Channel 01 : 367[e3000] -> 366[ca000] via P2P/IPC/read
391: hkn0717:19437:19568 [3] NCCL INFO Connected all rings
471: hkn0804:1230026:1230141 [3] NCCL INFO Channel 01 : 471[e3000] -> 470[ca000] via P2P/IPC/read
 55: hkn0418:1893549:1893663 [3] NCCL INFO Connected all rings
475: hkn0805:1136477:1136585 [3] NCCL INFO Channel 01 : 475[e3000] -> 474[ca000] via P2P/IPC/read
103: hkn0502:253410:253517 [3] NCCL INFO Channel 01 : 103[e3000] -> 102[ca000] via P2P/IPC/read
383: hkn0715:426284:426389 [3] NCCL INFO Channel 01 : 383[e3000] -> 382[ca000] via P2P/IPC/read
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
119: hkn0506:862430:862542 [3] NCCL INFO Channel 01 : 119[e3000] -> 118[ca000] via P2P/IPC/read
171: hkn0523:1572561:1572684 [3] NCCL INFO Channel 00 : 171[e3000] -> 170[ca000] via P2P/IPC/read
415: hkn0724:1740349:1740479 [3] NCCL INFO Channel 01 : 415[e3000] -> 414[ca000] via P2P/IPC/read
295: hkn0626:1322790:1322933 [3] NCCL INFO Channel 00 : 295[e3000] -> 294[ca000] via P2P/IPC/read
371: hkn0712:319428:319537 [3] NCCL INFO Channel 01 : 371[e3000] -> 370[ca000] via P2P/IPC/read
275: hkn0617:2319192:2319312 [3] NCCL INFO Channel 00 : 275[e3000] -> 274[ca000] via P2P/IPC/read
 99: hkn0501:1352386:1352510 [3] NCCL INFO Connected all rings
115: hkn0505:2328163:2328258 [3] NCCL INFO Connected all rings
 27: hkn0410:1184055:1184150 [3] NCCL INFO Channel 01 : 27[e3000] -> 26[ca000] via P2P/IPC/read
339: hkn0703:765530:765656 [3] NCCL INFO Channel 00 : 339[e3000] -> 338[ca000] via P2P/IPC/read
451: hkn0734:1180877:1181004 [3] NCCL INFO Channel 00 : 451[e3000] -> 450[ca000] via P2P/IPC/read
419: hkn0725:3136296:3136421 [3] NCCL INFO Channel 00 : 419[e3000] -> 418[ca000] via P2P/IPC/read
  3: hkn0403:1808445:1808808 [3] NCCL INFO Channel 01 : 3[e3000] -> 2[ca000] via P2P/IPC/read
411: hkn0723:232580:232725 [3] NCCL INFO Channel 01 : 411[e3000] -> 410[ca000] via P2P/IPC/read
315: hkn0631:1046171:1046285 [3] NCCL INFO Channel 00 : 315[e3000] -> 314[ca000] via P2P/IPC/read
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 00 : 236[31000] -> 239[e3000] via P2P/IPC/read
511: hkn0816:399934:400048 [3] NCCL INFO Channel 01 : 511[e3000] -> 510[ca000] via P2P/IPC/read
291: hkn0624:1797274:1797389 [3] NCCL INFO Channel 01 : 291[e3000] -> 290[ca000] via P2P/IPC/read
260: hkn0613:927106:927208 [0] NCCL INFO Channel 01 : 260[31000] -> 263[e3000] via P2P/IPC/read
299: hkn0627:1812294:1812419 [3] NCCL INFO Channel 00 : 299[e3000] -> 298[ca000] via P2P/IPC/read
347: hkn0705:807550:807681 [3] NCCL INFO Channel 01 : 347[e3000] -> 346[ca000] via P2P/IPC/read
483: hkn0807:1043414:1043536 [3] NCCL INFO Channel 01 : 483[e3000] -> 482[ca000] via P2P/IPC/read
487: hkn0808:995030:995156 [3] NCCL INFO Channel 01 : 487[e3000] -> 486[ca000] via P2P/IPC/read
359: hkn0708:437591:437704 [3] NCCL INFO Channel 00 : 359[e3000] -> 358[ca000] via P2P/IPC/read
 43: hkn0414:2006106:2006225 [3] NCCL INFO Connected all rings
207: hkn0532:950461:950778 [3] NCCL INFO Channel 00 : 207[e3000] -> 206[ca000] via P2P/IPC/read
499: hkn0812:718257:718355 [3] NCCL INFO Channel 01 : 499[e3000] -> 498[ca000] via P2P/IPC/read
343: hkn0704:816334:816453 [3] NCCL INFO Channel 01 : 343[e3000] -> 342[ca000] via P2P/IPC/read
107: hkn0503:2924178:2924282 [3] NCCL INFO Connected all rings
259: hkn0612:941325:941471 [3] NCCL INFO Channel 00 : 259[e3000] -> 258[ca000] via P2P/IPC/read
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 00 : 20[31000] -> 23[e3000] via P2P/IPC/read
479: hkn0806:1078660:1078785 [3] NCCL INFO Channel 01 : 479[e3000] -> 478[ca000] via P2P/IPC/read
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 01 : 284[31000] -> 287[e3000] via P2P/IPC/read
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 01 : 276[31000] -> 279[e3000] via P2P/IPC/read
 35: hkn0412:2286751:2286844 [3] NCCL INFO Channel 01 : 35[e3000] -> 34[ca000] via P2P/IPC/read
143: hkn0512:3068470:3068579 [3] NCCL INFO Connected all rings
455: hkn0736:1532608:1532732 [3] NCCL INFO Channel 01 : 455[e3000] -> 454[ca000] via P2P/IPC/read
331: hkn0635:1249914:1250018 [3] NCCL INFO Channel 00 : 331[e3000] -> 330[ca000] via P2P/IPC/read
355: hkn0707:4044292:4044419 [3] NCCL INFO Channel 00 : 355[e3000] -> 354[ca000] via P2P/IPC/read
503: hkn0814:700156:700314 [3] NCCL INFO Connected all rings
385: hkn0716:132811:132965 [1] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
 31: hkn0411:2340265:2340393 [3] NCCL INFO Connected all rings
111: hkn0504:65451:65555 [3] NCCL INFO Channel 01 : 111[e3000] -> 110[ca000] via P2P/IPC/read
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 01 : 160[31000] -> 163[e3000] via P2P/IPC/read
439: hkn0731:1411104:1411206 [3] NCCL INFO Connected all rings
463: hkn0802:1224700:1224850 [3] NCCL INFO Channel 00 : 463[e3000] -> 462[ca000] via P2P/IPC/read
311: hkn0630:1622872:1622968 [3] NCCL INFO Channel 00 : 311[e3000] -> 310[ca000] via P2P/IPC/read
131: hkn0509:3148767:3148876 [3] NCCL INFO Connected all rings
 11: hkn0405:3231507:3231615 [3] NCCL INFO Channel 00 : 11[e3000] -> 10[ca000] via P2P/IPC/read
295: hkn0626:1322790:1322933 [3] NCCL INFO Channel 01 : 295[e3000] -> 294[ca000] via P2P/IPC/read
307: hkn0629:1616387:1616511 [3] NCCL INFO Connected all rings
123: hkn0507:3211443:3211567 [3] NCCL INFO Connected all rings
171: hkn0523:1572561:1572684 [3] NCCL INFO Channel 01 : 171[e3000] -> 170[ca000] via P2P/IPC/read
252: hkn0611:734178:734279 [0] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
248: hkn0609:735146:735265 [0] NCCL INFO Channel 00 : 248[31000] -> 251[e3000] via P2P/IPC/read
339: hkn0703:765530:765656 [3] NCCL INFO Channel 01 : 339[e3000] -> 338[ca000] via P2P/IPC/read
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 00 : 192[31000] -> 195[e3000] via P2P/IPC/read
451: hkn0734:1180877:1181004 [3] NCCL INFO Channel 01 : 451[e3000] -> 450[ca000] via P2P/IPC/read
275: hkn0617:2319192:2319312 [3] NCCL INFO Channel 01 : 275[e3000] -> 274[ca000] via P2P/IPC/read
375: hkn0713:494582:494711 [3] NCCL INFO Connected all rings
419: hkn0725:3136296:3136421 [3] NCCL INFO Channel 01 : 419[e3000] -> 418[ca000] via P2P/IPC/read
399: hkn0719:1330267:1330376 [3] NCCL INFO Connected all rings
464: hkn0803:901006:901108 [0] NCCL INFO Channel 00 : 464[31000] -> 467[e3000] via P2P/IPC/read
 19: hkn0408:2915270:2915393 [3] NCCL INFO Channel 00 : 19[e3000] -> 18[ca000] via P2P/IPC/read
315: hkn0631:1046171:1046285 [3] NCCL INFO Channel 01 : 315[e3000] -> 314[ca000] via P2P/IPC/read
299: hkn0627:1812294:1812419 [3] NCCL INFO Channel 01 : 299[e3000] -> 298[ca000] via P2P/IPC/read
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 01 : 236[31000] -> 239[e3000] via P2P/IPC/read
  7: hkn0404:1363854:1363975 [3] NCCL INFO Connected all rings
387: hkn0716:132839:132970 [3] NCCL INFO Channel 00 : 387[e3000] -> 386[ca000] via P2P/IPC/read
359: hkn0708:437591:437704 [3] NCCL INFO Channel 01 : 359[e3000] -> 358[ca000] via P2P/IPC/read
151: hkn0514:2975071:2975199 [3] NCCL INFO Connected all rings
207: hkn0532:950461:950778 [3] NCCL INFO Channel 01 : 207[e3000] -> 206[ca000] via P2P/IPC/read
427: hkn0727:1370167:1370284 [3] NCCL INFO Channel 00 : 427[e3000] -> 426[ca000] via P2P/IPC/read
191: hkn0528:1326052:1326169 [3] NCCL INFO Channel 00 : 191[e3000] -> 190[ca000] via P2P/IPC/read
127: hkn0508:3163486:3163600 [3] NCCL INFO Connected all rings
235: hkn0605:736572:736668 [3] NCCL INFO Channel 00 : 235[e3000] -> 234[ca000] via P2P/IPC/read
323: hkn0633:1550641:1550758 [3] NCCL INFO Connected all rings
147: hkn0513:3037315:3037440 [3] NCCL INFO Connected all rings
259: hkn0612:941325:941471 [3] NCCL INFO Channel 01 : 259[e3000] -> 258[ca000] via P2P/IPC/read
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 00 : 156[31000] -> 159[e3000] via P2P/IPC/read
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 01 : 20[31000] -> 23[e3000] via P2P/IPC/read
495: hkn0810:963921:964028 [3] NCCL INFO Connected all rings
351: hkn0706:776604:776726 [3] NCCL INFO Channel 00 : 351[e3000] -> 350[ca000] via P2P/IPC/read
167: hkn0521:1222197:1222291 [3] NCCL INFO Channel 00 : 167[e3000] -> 166[ca000] via P2P/IPC/read
319: hkn0632:1782991:1783084 [3] NCCL INFO Connected all rings
331: hkn0635:1249914:1250018 [3] NCCL INFO Channel 01 : 331[e3000] -> 330[ca000] via P2P/IPC/read
355: hkn0707:4044292:4044419 [3] NCCL INFO Channel 01 : 355[e3000] -> 354[ca000] via P2P/IPC/read
179: hkn0525:1011126:1011245 [3] NCCL INFO Channel 00 : 179[e3000] -> 178[ca000] via P2P/IPC/read
447: hkn0733:1413735:1413846 [3] NCCL INFO Connected all rings
199: hkn0530:1282494:1282588 [3] NCCL INFO Channel 00 : 199[e3000] -> 198[ca000] via P2P/IPC/read
 15: hkn0407:1840605:1840730 [3] NCCL INFO Channel 00 : 15[e3000] -> 14[ca000] via P2P/IPC/read
175: hkn0524:1158128:1158251 [3] NCCL INFO Channel 00 : 175[e3000] -> 174[ca000] via P2P/IPC/read
303: hkn0628:696380:696485 [3] NCCL INFO Connected all rings
463: hkn0802:1224700:1224850 [3] NCCL INFO Channel 01 : 463[e3000] -> 462[ca000] via P2P/IPC/read
311: hkn0630:1622872:1622968 [3] NCCL INFO Channel 01 : 311[e3000] -> 310[ca000] via P2P/IPC/read
335: hkn0636:1678732:1678872 [3] NCCL INFO Connected all rings
423: hkn0726:1572482:1572597 [3] NCCL INFO Connected all rings
327: hkn0634:1545249:1545346 [3] NCCL INFO Connected all rings
 11: hkn0405:3231507:3231615 [3] NCCL INFO Channel 01 : 11[e3000] -> 10[ca000] via P2P/IPC/read
507: hkn0815:419489:419590 [3] NCCL INFO Connected all rings
395: hkn0718:3941427:3941539 [3] NCCL INFO Connected all rings
248: hkn0609:735146:735265 [0] NCCL INFO Channel 01 : 248[31000] -> 251[e3000] via P2P/IPC/read
223: hkn0602:3390378:3390578 [3] NCCL INFO Channel 00 : 223[e3000] -> 222[ca000] via P2P/IPC/read
475: hkn0805:1136477:1136585 [3] NCCL INFO Connected all rings
435: hkn0730:1426037:1426189 [3] NCCL INFO Channel 00 : 435[e3000] -> 434[ca000] via P2P/IPC/read
367: hkn0711:608376:608500 [3] NCCL INFO Connected all rings
471: hkn0804:1230026:1230141 [3] NCCL INFO Connected all rings
 19: hkn0408:2915270:2915393 [3] NCCL INFO Channel 01 : 19[e3000] -> 18[ca000] via P2P/IPC/read
103: hkn0502:253410:253517 [3] NCCL INFO Connected all rings
383: hkn0715:426284:426389 [3] NCCL INFO Connected all rings
415: hkn0724:1740349:1740479 [3] NCCL INFO Connected all rings
119: hkn0506:862430:862542 [3] NCCL INFO Connected all rings
464: hkn0803:901006:901108 [0] NCCL INFO Channel 01 : 464[31000] -> 467[e3000] via P2P/IPC/read
243: hkn0607:928733:928851 [3] NCCL INFO Channel 00 : 243[e3000] -> 242[ca000] via P2P/IPC/read
387: hkn0716:132839:132970 [3] NCCL INFO Channel 01 : 387[e3000] -> 386[ca000] via P2P/IPC/read
371: hkn0712:319428:319537 [3] NCCL INFO Connected all rings
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 01 : 192[31000] -> 195[e3000] via P2P/IPC/read
 27: hkn0410:1184055:1184150 [3] NCCL INFO Connected all rings
427: hkn0727:1370167:1370284 [3] NCCL INFO Channel 01 : 427[e3000] -> 426[ca000] via P2P/IPC/read
191: hkn0528:1326052:1326169 [3] NCCL INFO Channel 01 : 191[e3000] -> 190[ca000] via P2P/IPC/read
  3: hkn0403:1808445:1808808 [3] NCCL INFO Connected all rings
379: hkn0714:456355:456477 [3] NCCL INFO Channel 00 : 379[e3000] -> 378[ca000] via P2P/IPC/read
411: hkn0723:232580:232725 [3] NCCL INFO Connected all rings
244: hkn0608:510064:510177 [0] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
511: hkn0816:399934:400048 [3] NCCL INFO Connected all rings
235: hkn0605:736572:736668 [3] NCCL INFO Channel 01 : 235[e3000] -> 234[ca000] via P2P/IPC/read
252: hkn0611:734178:734279 [0] NCCL INFO Channel 00 : 252[31000] -> 255[e3000] via P2P/IPC/read
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
347: hkn0705:807550:807681 [3] NCCL INFO Connected all rings
291: hkn0624:1797274:1797389 [3] NCCL INFO Connected all rings
351: hkn0706:776604:776726 [3] NCCL INFO Channel 01 : 351[e3000] -> 350[ca000] via P2P/IPC/read
459: hkn0801:2264529:2264651 [3] NCCL INFO Channel 00 : 459[e3000] -> 458[ca000] via P2P/IPC/read
 51: hkn0417:2292063:2292173 [3] NCCL INFO Channel 00 : 51[e3000] -> 50[ca000] via P2P/IPC/read
167: hkn0521:1222197:1222291 [3] NCCL INFO Channel 01 : 167[e3000] -> 166[ca000] via P2P/IPC/read
499: hkn0812:718257:718355 [3] NCCL INFO Connected all rings
187: hkn0527:1373302:1373417 [3] NCCL INFO Channel 00 : 187[e3000] -> 186[ca000] via P2P/IPC/read
483: hkn0807:1043414:1043536 [3] NCCL INFO Connected all rings
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 01 : 156[31000] -> 159[e3000] via P2P/IPC/read
343: hkn0704:816334:816453 [3] NCCL INFO Connected all rings
403: hkn0720:33744:33905 [3] NCCL INFO Channel 00 : 403[e3000] -> 402[ca000] via P2P/IPC/read
179: hkn0525:1011126:1011245 [3] NCCL INFO Channel 01 : 179[e3000] -> 178[ca000] via P2P/IPC/read
487: hkn0808:995030:995156 [3] NCCL INFO Connected all rings
269: hkn0616:429426:429521 [1] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
 15: hkn0407:1840605:1840730 [3] NCCL INFO Channel 01 : 15[e3000] -> 14[ca000] via P2P/IPC/read
175: hkn0524:1158128:1158251 [3] NCCL INFO Channel 01 : 175[e3000] -> 174[ca000] via P2P/IPC/read
199: hkn0530:1282494:1282588 [3] NCCL INFO Channel 01 : 199[e3000] -> 198[ca000] via P2P/IPC/read
283: hkn0622:2045028:2045131 [3] NCCL INFO Channel 00 : 283[e3000] -> 282[ca000] via P2P/IPC/read
 35: hkn0412:2286751:2286844 [3] NCCL INFO Connected all rings
407: hkn0721:2323889:2323992 [3] NCCL INFO Connected all rings
455: hkn0736:1532608:1532732 [3] NCCL INFO Connected all rings
223: hkn0602:3390378:3390578 [3] NCCL INFO Channel 01 : 223[e3000] -> 222[ca000] via P2P/IPC/read
111: hkn0504:65451:65555 [3] NCCL INFO Connected all rings
435: hkn0730:1426037:1426189 [3] NCCL INFO Channel 01 : 435[e3000] -> 434[ca000] via P2P/IPC/read
227: hkn0603:1437583:1437701 [3] NCCL INFO Channel 00 : 227[e3000] -> 226[ca000] via P2P/IPC/read
219: hkn0601:142224:142344 [3] NCCL INFO Channel 00 : 219[e3000] -> 218[ca000] via P2P/IPC/read
295: hkn0626:1322790:1322933 [3] NCCL INFO Connected all rings
243: hkn0607:928733:928851 [3] NCCL INFO Channel 01 : 243[e3000] -> 242[ca000] via P2P/IPC/read
451: hkn0734:1180877:1181004 [3] NCCL INFO Connected all rings
275: hkn0617:2319192:2319312 [3] NCCL INFO Connected all rings
419: hkn0725:3136296:3136421 [3] NCCL INFO Connected all rings
339: hkn0703:765530:765656 [3] NCCL INFO Connected all rings
431: hkn0728:1348489:1348596 [3] NCCL INFO Connected all rings
379: hkn0714:456355:456477 [3] NCCL INFO Channel 01 : 379[e3000] -> 378[ca000] via P2P/IPC/read
252: hkn0611:734178:734279 [0] NCCL INFO Channel 01 : 252[31000] -> 255[e3000] via P2P/IPC/read
299: hkn0627:1812294:1812419 [3] NCCL INFO Connected all rings
171: hkn0523:1572561:1572684 [3] NCCL INFO Connected all rings
315: hkn0631:1046171:1046285 [3] NCCL INFO Connected all rings
359: hkn0708:437591:437704 [3] NCCL INFO Connected all rings
459: hkn0801:2264529:2264651 [3] NCCL INFO Channel 01 : 459[e3000] -> 458[ca000] via P2P/IPC/read
207: hkn0532:950461:950778 [3] NCCL INFO Connected all rings
 51: hkn0417:2292063:2292173 [3] NCCL INFO Channel 01 : 51[e3000] -> 50[ca000] via P2P/IPC/read
187: hkn0527:1373302:1373417 [3] NCCL INFO Channel 01 : 187[e3000] -> 186[ca000] via P2P/IPC/read
403: hkn0720:33744:33905 [3] NCCL INFO Channel 01 : 403[e3000] -> 402[ca000] via P2P/IPC/read
267: hkn0615:438695:438811 [3] NCCL INFO Channel 00 : 267[e3000] -> 266[ca000] via P2P/IPC/read
283: hkn0622:2045028:2045131 [3] NCCL INFO Channel 01 : 283[e3000] -> 282[ca000] via P2P/IPC/read
259: hkn0612:941325:941471 [3] NCCL INFO Connected all rings
479: hkn0806:1078660:1078785 [3] NCCL INFO Connected all rings
203: hkn0531:1255122:1255246 [3] NCCL INFO Channel 00 : 203[e3000] -> 202[ca000] via P2P/IPC/read
331: hkn0635:1249914:1250018 [3] NCCL INFO Connected all rings
227: hkn0603:1437583:1437701 [3] NCCL INFO Channel 01 : 227[e3000] -> 226[ca000] via P2P/IPC/read
244: hkn0608:510064:510177 [0] NCCL INFO Channel 00 : 244[31000] -> 247[e3000] via P2P/IPC/read
355: hkn0707:4044292:4044419 [3] NCCL INFO Connected all rings
311: hkn0630:1622872:1622968 [3] NCCL INFO Connected all rings
219: hkn0601:142224:142344 [3] NCCL INFO Channel 01 : 219[e3000] -> 218[ca000] via P2P/IPC/read
 11: hkn0405:3231507:3231615 [3] NCCL INFO Connected all rings
 19: hkn0408:2915270:2915393 [3] NCCL INFO Connected all rings
463: hkn0802:1224700:1224850 [3] NCCL INFO Connected all rings
215: hkn0535:2423320:2423450 [3] NCCL INFO Channel 00 : 215[e3000] -> 214[ca000] via P2P/IPC/read
271: hkn0616:429414:429520 [3] NCCL INFO Channel 00 : 271[e3000] -> 270[ca000] via P2P/IPC/read
427: hkn0727:1370167:1370284 [3] NCCL INFO Connected all rings
191: hkn0528:1326052:1326169 [3] NCCL INFO Connected all rings
235: hkn0605:736572:736668 [3] NCCL INFO Connected all rings
387: hkn0716:132839:132970 [3] NCCL INFO Connected all rings
211: hkn0534:1172757:1172866 [3] NCCL INFO Channel 00 : 211[e3000] -> 210[ca000] via P2P/IPC/read
351: hkn0706:776604:776726 [3] NCCL INFO Connected all rings
267: hkn0615:438695:438811 [3] NCCL INFO Channel 01 : 267[e3000] -> 266[ca000] via P2P/IPC/read
167: hkn0521:1222197:1222291 [3] NCCL INFO Connected all rings
203: hkn0531:1255122:1255246 [3] NCCL INFO Channel 01 : 203[e3000] -> 202[ca000] via P2P/IPC/read
183: hkn0526:1452786:1452878 [3] NCCL INFO Channel 00 : 183[e3000] -> 182[ca000] via P2P/IPC/read
179: hkn0525:1011126:1011245 [3] NCCL INFO Connected all rings
443: hkn0732:1236005:1236121 [3] NCCL INFO Channel 00 : 443[e3000] -> 442[ca000] via P2P/IPC/read
 15: hkn0407:1840605:1840730 [3] NCCL INFO Connected all rings
199: hkn0530:1282494:1282588 [3] NCCL INFO Connected all rings
231: hkn0604:713531:713661 [3] NCCL INFO Channel 00 : 231[e3000] -> 230[ca000] via P2P/IPC/read
175: hkn0524:1158128:1158251 [3] NCCL INFO Connected all rings
223: hkn0602:3390378:3390578 [3] NCCL INFO Connected all rings
244: hkn0608:510064:510177 [0] NCCL INFO Channel 01 : 244[31000] -> 247[e3000] via P2P/IPC/read
435: hkn0730:1426037:1426189 [3] NCCL INFO Connected all rings
215: hkn0535:2423320:2423450 [3] NCCL INFO Channel 01 : 215[e3000] -> 214[ca000] via P2P/IPC/read
271: hkn0616:429414:429520 [3] NCCL INFO Channel 01 : 271[e3000] -> 270[ca000] via P2P/IPC/read
243: hkn0607:928733:928851 [3] NCCL INFO Connected all rings
379: hkn0714:456355:456477 [3] NCCL INFO Connected all rings
211: hkn0534:1172757:1172866 [3] NCCL INFO Channel 01 : 211[e3000] -> 210[ca000] via P2P/IPC/read
459: hkn0801:2264529:2264651 [3] NCCL INFO Connected all rings
 51: hkn0417:2292063:2292173 [3] NCCL INFO Connected all rings
263: hkn0613:927090:927213 [3] NCCL INFO Channel 00 : 263[e3000] -> 262[ca000] via P2P/IPC/read
183: hkn0526:1452786:1452878 [3] NCCL INFO Channel 01 : 183[e3000] -> 182[ca000] via P2P/IPC/read
187: hkn0527:1373302:1373417 [3] NCCL INFO Connected all rings
443: hkn0732:1236005:1236121 [3] NCCL INFO Channel 01 : 443[e3000] -> 442[ca000] via P2P/IPC/read
231: hkn0604:713531:713661 [3] NCCL INFO Channel 01 : 231[e3000] -> 230[ca000] via P2P/IPC/read
283: hkn0622:2045028:2045131 [3] NCCL INFO Connected all rings
287: hkn0623:1897155:1897246 [3] NCCL INFO Channel 00 : 287[e3000] -> 286[ca000] via P2P/IPC/read
403: hkn0720:33744:33905 [3] NCCL INFO Connected all rings
227: hkn0603:1437583:1437701 [3] NCCL INFO Connected all rings
219: hkn0601:142224:142344 [3] NCCL INFO Connected all rings
279: hkn0621:2016105:2016220 [3] NCCL INFO Channel 00 : 279[e3000] -> 278[ca000] via P2P/IPC/read
239: hkn0606:2396563:2396679 [3] NCCL INFO Channel 00 : 239[e3000] -> 238[ca000] via P2P/IPC/read
163: hkn0520:2737223:2737364 [3] NCCL INFO Channel 00 : 163[e3000] -> 162[ca000] via P2P/IPC/read
263: hkn0613:927090:927213 [3] NCCL INFO Channel 01 : 263[e3000] -> 262[ca000] via P2P/IPC/read
287: hkn0623:1897155:1897246 [3] NCCL INFO Channel 01 : 287[e3000] -> 286[ca000] via P2P/IPC/read
 23: hkn0409:2610020:2610114 [3] NCCL INFO Channel 00 : 23[e3000] -> 22[ca000] via P2P/IPC/read
267: hkn0615:438695:438811 [3] NCCL INFO Connected all rings
203: hkn0531:1255122:1255246 [3] NCCL INFO Connected all rings
279: hkn0621:2016105:2016220 [3] NCCL INFO Channel 01 : 279[e3000] -> 278[ca000] via P2P/IPC/read
239: hkn0606:2396563:2396679 [3] NCCL INFO Channel 01 : 239[e3000] -> 238[ca000] via P2P/IPC/read
163: hkn0520:2737223:2737364 [3] NCCL INFO Channel 01 : 163[e3000] -> 162[ca000] via P2P/IPC/read
215: hkn0535:2423320:2423450 [3] NCCL INFO Connected all rings
251: hkn0609:735154:735263 [3] NCCL INFO Channel 00 : 251[e3000] -> 250[ca000] via P2P/IPC/read
271: hkn0616:429414:429520 [3] NCCL INFO Connected all rings
211: hkn0534:1172757:1172866 [3] NCCL INFO Connected all rings
 23: hkn0409:2610020:2610114 [3] NCCL INFO Channel 01 : 23[e3000] -> 22[ca000] via P2P/IPC/read
467: hkn0803:900994:901110 [3] NCCL INFO Channel 00 : 467[e3000] -> 466[ca000] via P2P/IPC/read
195: hkn0529:1565159:1565265 [3] NCCL INFO Channel 00 : 195[e3000] -> 194[ca000] via P2P/IPC/read
443: hkn0732:1236005:1236121 [3] NCCL INFO Connected all rings
183: hkn0526:1452786:1452878 [3] NCCL INFO Connected all rings
231: hkn0604:713531:713661 [3] NCCL INFO Connected all rings
 65: hkn0421:2208731:2208877 [1] NCCL INFO Connected all rings
159: hkn0516:2940322:2940429 [3] NCCL INFO Channel 00 : 159[e3000] -> 158[ca000] via P2P/IPC/read
253: hkn0611:734158:734277 [1] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
251: hkn0609:735154:735263 [3] NCCL INFO Channel 01 : 251[e3000] -> 250[ca000] via P2P/IPC/read
467: hkn0803:900994:901110 [3] NCCL INFO Channel 01 : 467[e3000] -> 466[ca000] via P2P/IPC/read
195: hkn0529:1565159:1565265 [3] NCCL INFO Channel 01 : 195[e3000] -> 194[ca000] via P2P/IPC/read
263: hkn0613:927090:927213 [3] NCCL INFO Connected all rings
 68: hkn0422:4177469:4177594 [0] NCCL INFO Connected all rings
287: hkn0623:1897155:1897246 [3] NCCL INFO Connected all rings
 64: hkn0421:2208719:2208879 [0] NCCL INFO Connected all rings
 72: hkn0423:1729386:1729506 [0] NCCL INFO Connected all rings
159: hkn0516:2940322:2940429 [3] NCCL INFO Channel 01 : 159[e3000] -> 158[ca000] via P2P/IPC/read
279: hkn0621:2016105:2016220 [3] NCCL INFO Connected all rings
239: hkn0606:2396563:2396679 [3] NCCL INFO Connected all rings
255: hkn0611:734150:734278 [3] NCCL INFO Channel 00 : 255[e3000] -> 254[ca000] via P2P/IPC/read
163: hkn0520:2737223:2737364 [3] NCCL INFO Connected all rings
 23: hkn0409:2610020:2610114 [3] NCCL INFO Connected all rings
 61: hkn0420:3234595:3234696 [1] NCCL INFO Connected all rings
 84: hkn0426:838364:838519 [0] NCCL INFO Connected all rings
 92: hkn0428:691744:691845 [0] NCCL INFO Connected all rings
255: hkn0611:734150:734278 [3] NCCL INFO Channel 01 : 255[e3000] -> 254[ca000] via P2P/IPC/read
251: hkn0609:735154:735263 [3] NCCL INFO Connected all rings
133: hkn0510:2786407:2786523 [1] NCCL INFO Connected all rings
 69: hkn0422:4177485:4177589 [1] NCCL INFO Connected all rings
 88: hkn0427:1159526:1159625 [0] NCCL INFO Connected all rings
247: hkn0608:510056:510185 [3] NCCL INFO Channel 00 : 247[e3000] -> 246[ca000] via P2P/IPC/read
195: hkn0529:1565159:1565265 [3] NCCL INFO Connected all rings
 60: hkn0420:3234567:3234693 [0] NCCL INFO Connected all rings
 89: hkn0427:1159514:1159627 [1] NCCL INFO Connected all rings
 81: hkn0425:2108525:2108632 [1] NCCL INFO Connected all rings
467: hkn0803:900994:901110 [3] NCCL INFO Connected all rings
 73: hkn0423:1729402:1729514 [1] NCCL INFO Connected all rings
132: hkn0510:2786415:2786525 [0] NCCL INFO Connected all rings
 80: hkn0425:2108509:2108631 [0] NCCL INFO Connected all rings
 66: hkn0421:2208703:2208881 [2] NCCL INFO Connected all rings
 36: hkn0413:2391098:2391192 [0] NCCL INFO Connected all rings
 56: hkn0419:1568599:1568716 [0] NCCL INFO Connected all rings
159: hkn0516:2940322:2940429 [3] NCCL INFO Connected all rings
247: hkn0608:510056:510185 [3] NCCL INFO Channel 01 : 247[e3000] -> 246[ca000] via P2P/IPC/read
 52: hkn0418:1893569:1893661 [0] NCCL INFO Connected all rings
 76: hkn0424:2972313:2972427 [0] NCCL INFO Connected all rings
101: hkn0502:253402:253515 [1] NCCL INFO Connected all rings
 85: hkn0426:838392:838518 [1] NCCL INFO Connected all rings
148: hkn0514:2975079:2975202 [0] NCCL INFO Connected all rings
488: hkn0809:961652:961773 [0] NCCL INFO Connected all rings
485: hkn0808:995038:995153 [1] NCCL INFO Connected all rings
 40: hkn0414:2006126:2006221 [0] NCCL INFO Connected all rings
 57: hkn0419:1568619:1568709 [1] NCCL INFO Connected all rings
368: hkn0712:319436:319546 [0] NCCL INFO Connected all rings
 53: hkn0418:1893541:1893660 [1] NCCL INFO Connected all rings
112: hkn0505:2328135:2328264 [0] NCCL INFO Connected all rings
392: hkn0718:3941435:3941546 [0] NCCL INFO Connected all rings
 93: hkn0428:691732:691841 [1] NCCL INFO Connected all rings
497: hkn0812:718229:718349 [1] NCCL INFO Connected all rings
255: hkn0611:734150:734278 [3] NCCL INFO Connected all rings
136: hkn0511:3090885:3090991 [0] NCCL INFO Connected all rings
128: hkn0509:3148759:3148874 [0] NCCL INFO Connected all rings
480: hkn0807:1043422:1043530 [0] NCCL INFO Connected all rings
109: hkn0504:65443:65560 [1] NCCL INFO Connected all rings
 49: hkn0417:2292047:2292172 [1] NCCL INFO Connected all rings
 28: hkn0411:2340281:2340396 [0] NCCL INFO Connected all rings
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 00 : 64[31000] -> 65[4b000] via P2P/IPC/read
100: hkn0502:253422:253519 [0] NCCL INFO Connected all rings
149: hkn0514:2975087:2975198 [1] NCCL INFO Connected all rings
129: hkn0509:3148751:3148873 [1] NCCL INFO Connected all rings
500: hkn0814:700164:700310 [0] NCCL INFO Connected all rings
145: hkn0513:3037331:3037435 [1] NCCL INFO Connected all rings
140: hkn0512:3068482:3068576 [0] NCCL INFO Connected all rings
 37: hkn0413:2391086:2391193 [1] NCCL INFO Connected all rings
124: hkn0508:3163506:3163602 [0] NCCL INFO Connected all rings
 33: hkn0412:2286731:2286842 [1] NCCL INFO Connected all rings
 25: hkn0410:1184035:1184153 [1] NCCL INFO Connected all rings
 62: hkn0420:3234575:3234691 [2] NCCL INFO Connected all rings
 32: hkn0412:2286739:2286849 [0] NCCL INFO Connected all rings
408: hkn0723:232560:232720 [0] NCCL INFO Connected all rings
364: hkn0711:608404:608498 [0] NCCL INFO Connected all rings
365: hkn0711:608392:608506 [1] NCCL INFO Connected all rings
492: hkn0810:963933:964030 [0] NCCL INFO Connected all rings
  1: hkn0403:1808437:1808809 [1] NCCL INFO Connected all rings
321: hkn0633:1550661:1550752 [1] NCCL INFO Connected all rings
297: hkn0627:1812302:1812414 [1] NCCL INFO Connected all rings
484: hkn0808:995046:995154 [0] NCCL INFO Connected all rings
472: hkn0805:1136489:1136590 [0] NCCL INFO Connected all rings
369: hkn0712:319420:319542 [1] NCCL INFO Connected all rings
121: hkn0507:3211451:3211566 [1] NCCL INFO Connected all rings
316: hkn0632:1782979:1783083 [0] NCCL INFO Connected all rings
361: hkn0710:379895:380014 [1] NCCL INFO Connected all rings
247: hkn0608:510056:510185 [3] NCCL INFO Connected all rings
393: hkn0718:3941419:3941544 [1] NCCL INFO Connected all rings
 96: hkn0501:1352378:1352508 [0] NCCL INFO Connected all rings
416: hkn0725:3136304:3136419 [0] NCCL INFO Connected all rings
  0: hkn0403:1808436:1808801 [0] NCCL INFO Connected all rings
 70: hkn0422:4177477:4177595 [2] NCCL INFO Connected all rings
 77: hkn0424:2972305:2972428 [1] NCCL INFO Connected all rings
389: hkn0717:19453:19564 [1] NCCL INFO Connected all rings
144: hkn0513:3037343:3037441 [0] NCCL INFO Connected all rings
320: hkn0633:1550633:1550753 [0] NCCL INFO Connected all rings
444: hkn0733:1413747:1413848 [0] NCCL INFO Connected all rings
504: hkn0815:419469:419586 [0] NCCL INFO Connected all rings
300: hkn0628:696392:696486 [0] NCCL INFO Connected all rings
134: hkn0510:2786427:2786528 [2] NCCL INFO Connected all rings
469: hkn0804:1230034:1230144 [1] NCCL INFO Connected all rings
481: hkn0807:1043434:1043534 [1] NCCL INFO Connected all rings
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 00 : 68[31000] -> 69[4b000] via P2P/IPC/read
 24: hkn0410:1184043:1184151 [0] NCCL INFO Connected all rings
496: hkn0812:718245:718354 [0] NCCL INFO Connected all rings
 41: hkn0414:2006098:2006227 [1] NCCL INFO Connected all rings
116: hkn0506:862438:862546 [0] NCCL INFO Connected all rings
352: hkn0707:4044320:4044416 [0] NCCL INFO Connected all rings
 82: hkn0425:2108517:2108637 [2] NCCL INFO Connected all rings
165: hkn0521:1222177:1222293 [1] NCCL INFO Connected all rings
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 00 : 60[31000] -> 61[4b000] via P2P/IPC/read
340: hkn0704:816342:816447 [0] NCCL INFO Connected all rings
137: hkn0511:3090877:3090993 [1] NCCL INFO Connected all rings
104: hkn0503:2924170:2924284 [0] NCCL INFO Connected all rings
501: hkn0814:700172:700309 [1] NCCL INFO Connected all rings
449: hkn0734:1180885:1181000 [1] NCCL INFO Connected all rings
 29: hkn0411:2340273:2340391 [1] NCCL INFO Connected all rings
508: hkn0816:399946:400046 [0] NCCL INFO Connected all rings
468: hkn0804:1230018:1230142 [0] NCCL INFO Connected all rings
441: hkn0732:1236021:1236128 [1] NCCL INFO Connected all rings
 74: hkn0423:1729414:1729511 [2] NCCL INFO Connected all rings
289: hkn0624:1797266:1797383 [1] NCCL INFO Connected all rings
332: hkn0636:1678716:1678871 [0] NCCL INFO Connected all rings
477: hkn0806:1078668:1078787 [1] NCCL INFO Connected all rings
409: hkn0723:232568:232721 [1] NCCL INFO Connected all rings
341: hkn0704:816354:816450 [1] NCCL INFO Connected all rings
308: hkn0630:1622844:1622963 [0] NCCL INFO Connected all rings
113: hkn0505:2328151:2328263 [1] NCCL INFO Connected all rings
336: hkn0703:765538:765661 [0] NCCL INFO Connected all rings
353: hkn0707:4044300:4044417 [1] NCCL INFO Connected all rings
476: hkn0806:1078676:1078786 [0] NCCL INFO Connected all rings
141: hkn0512:3068462:3068573 [1] NCCL INFO Connected all rings
324: hkn0634:1545221:1545345 [0] NCCL INFO Connected all rings
120: hkn0507:3211471:3211570 [0] NCCL INFO Connected all rings
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 00 : 72[31000] -> 73[4b000] via P2P/IPC/read
 90: hkn0427:1159498:1159622 [2] NCCL INFO Connected all rings
 86: hkn0426:838372:838511 [2] NCCL INFO Connected all rings
489: hkn0809:961668:961775 [1] NCCL INFO Connected all rings
 94: hkn0428:691716:691838 [2] NCCL INFO Connected all rings
292: hkn0626:1322782:1322938 [0] NCCL INFO Connected all rings
125: hkn0508:3163494:3163603 [1] NCCL INFO Connected all rings
486: hkn0808:995058:995152 [2] NCCL INFO Connected all rings
102: hkn0502:253394:253516 [2] NCCL INFO Connected all rings
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 00 : 132[31000] -> 133[4b000] via P2P/IPC/read
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 01 : 64[31000] -> 65[4b000] via P2P/IPC/read
 97: hkn0501:1352406:1352507 [1] NCCL INFO Connected all rings
420: hkn0726:1572502:1572595 [0] NCCL INFO Connected all rings
405: hkn0721:2323871:2323991 [1] NCCL INFO Connected all rings
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 00 : 88[31000] -> 89[4b000] via P2P/IPC/read
417: hkn0725:3136312:3136416 [1] NCCL INFO Connected all rings
317: hkn0632:1782971:1783088 [1] NCCL INFO Connected all rings
473: hkn0805:1136469:1136586 [1] NCCL INFO Connected all rings
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 00 : 84[31000] -> 85[4b000] via P2P/IPC/read
312: hkn0631:1046191:1046283 [0] NCCL INFO Connected all rings
184: hkn0527:1373322:1373423 [0] NCCL INFO Connected all rings
433: hkn0730:1426045:1426192 [1] NCCL INFO Connected all rings
 44: hkn0415:2520735:2520862 [0] NCCL INFO Connected all rings
509: hkn0816:399926:400042 [1] NCCL INFO Connected all rings
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 00 : 80[31000] -> 81[4b000] via P2P/IPC/read
448: hkn0734:1180893:1180999 [0] NCCL INFO Connected all rings
344: hkn0705:807566:807679 [0] NCCL INFO Connected all rings
380: hkn0715:426268:426388 [0] NCCL INFO Connected all rings
493: hkn0810:963905:964027 [1] NCCL INFO Connected all rings
313: hkn0631:1046163:1046282 [1] NCCL INFO Connected all rings
 50: hkn0417:2292055:2292170 [2] NCCL INFO Connected all rings
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 00 : 92[31000] -> 93[4b000] via P2P/IPC/read
110: hkn0504:65463:65554 [2] NCCL INFO Connected all rings
296: hkn0627:1812310:1812420 [0] NCCL INFO Connected all rings
168: hkn0523:1572589:1572686 [0] NCCL INFO Connected all rings
108: hkn0504:65435:65559 [0] NCCL INFO Connected all rings
337: hkn0703:765546:765657 [1] NCCL INFO Connected all rings
452: hkn0736:1532636:1532735 [0] NCCL INFO Connected all rings
 58: hkn0419:1568591:1568715 [2] NCCL INFO Connected all rings
498: hkn0812:718237:718348 [2] NCCL INFO Connected all rings
390: hkn0717:19445:19567 [2] NCCL INFO Connected all rings
348: hkn0706:776612:776722 [0] NCCL INFO Connected all rings
172: hkn0524:1158136:1158254 [0] NCCL INFO Connected all rings
328: hkn0635:1249926:1250020 [0] NCCL INFO Connected all rings
505: hkn0815:419461:419585 [1] NCCL INFO Connected all rings
146: hkn0513:3037323:3037444 [2] NCCL INFO Connected all rings
445: hkn0733:1413727:1413845 [1] NCCL INFO Connected all rings
333: hkn0636:1678744:1678868 [1] NCCL INFO Connected all rings
304: hkn0629:1616359:1616509 [0] NCCL INFO Connected all rings
301: hkn0628:696372:696489 [1] NCCL INFO Connected all rings
349: hkn0706:776624:776729 [1] NCCL INFO Connected all rings
412: hkn0724:1740321:1740477 [0] NCCL INFO Connected all rings
 54: hkn0418:1893557:1893666 [2] NCCL INFO Connected all rings
164: hkn0521:1222169:1222292 [0] NCCL INFO Connected all rings
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 00 : 56[31000] -> 57[4b000] via P2P/IPC/read
305: hkn0629:1616367:1616506 [1] NCCL INFO Connected all rings
 26: hkn0410:1184027:1184146 [2] NCCL INFO Connected all rings
 38: hkn0413:2391078:2391198 [2] NCCL INFO Connected all rings
377: hkn0714:456383:456480 [1] NCCL INFO Connected all rings
 34: hkn0412:2286727:2286850 [2] NCCL INFO Connected all rings
100: hkn0502:253422:253519 [0] NCCL INFO Channel 00 : 100[31000] -> 101[4b000] via P2P/IPC/read
381: hkn0715:426296:426395 [1] NCCL INFO Connected all rings
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 00 : 65[4b000] -> 66[ca000] via P2P/IPC/read
150: hkn0514:2975099:2975195 [2] NCCL INFO Connected all rings
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 00 : 104[31000] -> 105[4b000] via P2P/IPC/read
362: hkn0710:379915:380012 [2] NCCL INFO Connected all rings
421: hkn0726:1572490:1572596 [1] NCCL INFO Connected all rings
432: hkn0730:1426065:1426190 [0] NCCL INFO Connected all rings
298: hkn0627:1812322:1812413 [2] NCCL INFO Connected all rings
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 00 : 36[31000] -> 37[4b000] via P2P/IPC/read
130: hkn0509:3148779:3148872 [2] NCCL INFO Connected all rings
 13: hkn0407:1840621:1840725 [1] NCCL INFO Connected all rings
  4: hkn0404:1363862:1363969 [0] NCCL INFO Connected all rings
345: hkn0705:807558:807678 [1] NCCL INFO Connected all rings
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 00 : 148[31000] -> 149[4b000] via P2P/IPC/read
309: hkn0630:1622860:1622960 [1] NCCL INFO Connected all rings
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 00 : 52[31000] -> 53[4b000] via P2P/IPC/read
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 01 : 68[31000] -> 69[4b000] via P2P/IPC/read
413: hkn0724:1740329:1740471 [1] NCCL INFO Connected all rings
 42: hkn0414:2006114:2006224 [2] NCCL INFO Connected all rings
325: hkn0634:1545237:1545343 [1] NCCL INFO Connected all rings
229: hkn0604:713547:713656 [1] NCCL INFO Connected all rings
  2: hkn0403:1808457:1808810 [2] NCCL INFO Connected all rings
220: hkn0602:3390398:3390575 [0] NCCL INFO Connected all rings
376: hkn0714:456371:456476 [0] NCCL INFO Connected all rings
122: hkn0507:3211459:3211565 [2] NCCL INFO Connected all rings
366: hkn0711:608384:608505 [2] NCCL INFO Connected all rings
 21: hkn0409:2610008:2610115 [1] NCCL INFO Connected all rings
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 01 : 60[31000] -> 61[4b000] via P2P/IPC/read
396: hkn0719:1330279:1330367 [0] NCCL INFO Connected all rings
484: hkn0808:995046:995154 [0] NCCL INFO Channel 00 : 484[31000] -> 485[4b000] via P2P/IPC/read
322: hkn0633:1550649:1550756 [2] NCCL INFO Connected all rings
185: hkn0527:1373310:1373415 [1] NCCL INFO Connected all rings
293: hkn0626:1322798:1322932 [1] NCCL INFO Connected all rings
370: hkn0712:319448:319543 [2] NCCL INFO Connected all rings
169: hkn0523:1572569:1572689 [1] NCCL INFO Connected all rings
217: hkn0601:142232:142341 [1] NCCL INFO Connected all rings
 78: hkn0424:2972321:2972426 [2] NCCL INFO Connected all rings
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 00 : 128[31000] -> 129[4b000] via P2P/IPC/read
394: hkn0718:3941447:3941548 [2] NCCL INFO Connected all rings
342: hkn0704:816326:816455 [2] NCCL INFO Connected all rings
161: hkn0520:2737231:2737367 [1] NCCL INFO Connected all rings
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 00 : 32[31000] -> 33[4b000] via P2P/IPC/read
329: hkn0635:1249898:1250021 [1] NCCL INFO Connected all rings
424: hkn0727:1370187:1370280 [0] NCCL INFO Connected all rings
356: hkn0708:437611:437707 [0] NCCL INFO Connected all rings
372: hkn0713:494598:494713 [0] NCCL INFO Connected all rings
368: hkn0712:319436:319546 [0] NCCL INFO Channel 00 : 368[31000] -> 369[4b000] via P2P/IPC/read
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 00 : 144[31000] -> 145[4b000] via P2P/IPC/read
 12: hkn0407:1840613:1840723 [0] NCCL INFO Connected all rings
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 01 : 72[31000] -> 73[4b000] via P2P/IPC/read
406: hkn0721:2323879:2323993 [2] NCCL INFO Connected all rings
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 00 : 76[31000] -> 77[4b000] via P2P/IPC/read
482: hkn0807:1043406:1043538 [2] NCCL INFO Connected all rings
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 00 : 40[31000] -> 41[4b000] via P2P/IPC/read
277: hkn0621:2016097:2016215 [1] NCCL INFO Connected all rings
142: hkn0512:3068454:3068574 [2] NCCL INFO Connected all rings
 48: hkn0417:2292075:2292171 [0] NCCL INFO Connected all rings
 66: hkn0421:2208703:2208881 [2] NCCL INFO Channel 00 : 66[ca000] -> 67[e3000] via P2P/IPC/read
470: hkn0804:1230046:1230140 [2] NCCL INFO Connected all rings
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 00 : 392[31000] -> 393[4b000] via P2P/IPC/read
488: hkn0809:961652:961773 [0] NCCL INFO Channel 00 : 488[31000] -> 489[4b000] via P2P/IPC/read
265: hkn0615:438714:438810 [1] NCCL INFO Connected all rings
 45: hkn0415:2520743:2520858 [1] NCCL INFO Connected all rings
442: hkn0732:1236013:1236130 [2] NCCL INFO Connected all rings
404: hkn0721:2323901:2323996 [0] NCCL INFO Connected all rings
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 00 : 24[31000] -> 25[4b000] via P2P/IPC/read
166: hkn0521:1222185:1222296 [2] NCCL INFO Connected all rings
290: hkn0624:1797282:1797386 [2] NCCL INFO Connected all rings
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 01 : 132[31000] -> 133[4b000] via P2P/IPC/read
181: hkn0526:1452758:1452883 [1] NCCL INFO Connected all rings
138: hkn0511:3090897:3090992 [2] NCCL INFO Connected all rings
490: hkn0809:961680:961778 [2] NCCL INFO Connected all rings
465: hkn0803:900978:901109 [1] NCCL INFO Connected all rings
364: hkn0711:608404:608498 [0] NCCL INFO Channel 00 : 364[31000] -> 365[4b000] via P2P/IPC/read
196: hkn0530:1282482:1282590 [0] NCCL INFO Connected all rings
400: hkn0720:33752:33908 [0] NCCL INFO Connected all rings
201: hkn0531:1255130:1255248 [1] NCCL INFO Connected all rings
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 00 : 480[31000] -> 481[4b000] via P2P/IPC/read
397: hkn0719:1330259:1330375 [1] NCCL INFO Connected all rings
436: hkn0731:1411088:1411212 [0] NCCL INFO Connected all rings
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 01 : 88[31000] -> 89[4b000] via P2P/IPC/read
450: hkn0734:1180905:1181006 [2] NCCL INFO Connected all rings
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 01 : 84[31000] -> 85[4b000] via P2P/IPC/read
502: hkn0814:700184:700311 [2] NCCL INFO Connected all rings
496: hkn0812:718245:718354 [0] NCCL INFO Channel 00 : 496[31000] -> 497[4b000] via P2P/IPC/read
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via P2P/IPC/read
 30: hkn0411:2340293:2340389 [2] NCCL INFO Connected all rings
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 01 : 80[31000] -> 81[4b000] via P2P/IPC/read
  8: hkn0405:3231491:3231618 [0] NCCL INFO Connected all rings
429: hkn0728:1348481:1348599 [1] NCCL INFO Connected all rings
216: hkn0601:142244:142342 [0] NCCL INFO Connected all rings
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 00 : 136[31000] -> 137[4b000] via P2P/IPC/read
494: hkn0810:963913:964023 [2] NCCL INFO Connected all rings
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 00 : 320[31000] -> 321[4b000] via P2P/IPC/read
193: hkn0529:1565171:1565268 [1] NCCL INFO Connected all rings
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 00 : 61[4b000] -> 62[ca000] via P2P/IPC/read
510: hkn0816:399918:400045 [2] NCCL INFO Connected all rings
176: hkn0525:1011118:1011248 [0] NCCL INFO Connected all rings
428: hkn0728:1348473:1348595 [0] NCCL INFO Connected all rings
478: hkn0806:1078688:1078789 [2] NCCL INFO Connected all rings
114: hkn0505:2328143:2328257 [2] NCCL INFO Connected all rings
221: hkn0602:3390370:3390573 [1] NCCL INFO Connected all rings
410: hkn0723:232552:232722 [2] NCCL INFO Connected all rings
224: hkn0603:1437575:1437699 [0] NCCL INFO Connected all rings
116: hkn0506:862438:862546 [0] NCCL INFO Channel 00 : 116[31000] -> 117[4b000] via P2P/IPC/read
453: hkn0736:1532616:1532726 [1] NCCL INFO Connected all rings
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 01 : 92[31000] -> 93[4b000] via P2P/IPC/read
457: hkn0801:2264557:2264657 [1] NCCL INFO Connected all rings
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 00 : 120[31000] -> 121[4b000] via P2P/IPC/read
173: hkn0524:1158144:1158252 [1] NCCL INFO Connected all rings
354: hkn0707:4044308:4044418 [2] NCCL INFO Connected all rings
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 00 : 28[31000] -> 29[4b000] via P2P/IPC/read
500: hkn0814:700164:700310 [0] NCCL INFO Channel 00 : 500[31000] -> 501[4b000] via P2P/IPC/read
314: hkn0631:1046179:1046288 [2] NCCL INFO Connected all rings
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 00 : 140[31000] -> 141[4b000] via P2P/IPC/read
126: hkn0508:3163478:3163601 [2] NCCL INFO Connected all rings
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 00 : 112[31000] -> 113[4b000] via P2P/IPC/read
408: hkn0723:232560:232720 [0] NCCL INFO Channel 00 : 408[31000] -> 409[4b000] via P2P/IPC/read
264: hkn0615:438687:438806 [0] NCCL INFO Connected all rings
340: hkn0704:816342:816447 [0] NCCL INFO Channel 00 : 340[31000] -> 341[4b000] via P2P/IPC/read
108: hkn0504:65435:65559 [0] NCCL INFO Channel 00 : 108[31000] -> 109[4b000] via P2P/IPC/read
384: hkn0716:132827:132967 [0] NCCL INFO Connected all rings
360: hkn0710:379903:380006 [0] NCCL INFO Connected all rings
180: hkn0526:1452766:1452877 [0] NCCL INFO Connected all rings
200: hkn0531:1255150:1255251 [0] NCCL INFO Connected all rings
152: hkn0515:2921174:2921332 [0] NCCL INFO Connected all rings
232: hkn0605:736552:736663 [0] NCCL INFO Connected all rings
261: hkn0613:927098:927209 [1] NCCL INFO Connected all rings
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 00 : 468[31000] -> 469[4b000] via P2P/IPC/read
474: hkn0805:1136461:1136592 [2] NCCL INFO Connected all rings
237: hkn0606:2396555:2396677 [1] NCCL INFO Connected all rings
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 00 : 124[31000] -> 125[4b000] via P2P/IPC/read
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 01 : 56[31000] -> 57[4b000] via P2P/IPC/read
318: hkn0632:1782963:1783087 [2] NCCL INFO Connected all rings
204: hkn0532:950481:950779 [0] NCCL INFO Connected all rings
440: hkn0732:1236033:1236129 [0] NCCL INFO Connected all rings
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 00 : 296[31000] -> 297[4b000] via P2P/IPC/read
 98: hkn0501:1352394:1352503 [2] NCCL INFO Connected all rings
418: hkn0725:3136324:3136423 [2] NCCL INFO Connected all rings
212: hkn0535:2423336:2423447 [0] NCCL INFO Connected all rings
492: hkn0810:963933:964030 [0] NCCL INFO Channel 00 : 492[31000] -> 493[4b000] via P2P/IPC/read
 69: hkn0422:4177485:4177589 [1] NCCL INFO Channel 00 : 69[4b000] -> 70[ca000] via P2P/IPC/read
456: hkn0801:2264545:2264656 [0] NCCL INFO Connected all rings
133: hkn0510:2786407:2786523 [1] NCCL INFO Channel 00 : 133[4b000] -> 134[ca000] via P2P/IPC/read
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 01 : 65[4b000] -> 66[ca000] via P2P/IPC/read
100: hkn0502:253422:253519 [0] NCCL INFO Channel 01 : 100[31000] -> 101[4b000] via P2P/IPC/read
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 00 : 424[31000] -> 425[4b000] via P2P/IPC/read
117: hkn0506:862422:862551 [1] NCCL INFO Connected all rings
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 00 : 476[31000] -> 477[4b000] via P2P/IPC/read
280: hkn0622:2045000:2045127 [0] NCCL INFO Connected all rings
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 00 : 472[31000] -> 473[4b000] via P2P/IPC/read
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 01 : 36[31000] -> 37[4b000] via P2P/IPC/read
 66: hkn0421:2208703:2208881 [2] NCCL INFO Channel 01 : 66[ca000] -> 67[e3000] via P2P/IPC/read
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 00 : 448[31000] -> 449[4b000] via P2P/IPC/read
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 00 : 96[31000] -> 97[4b000] via P2P/IPC/read
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 00 : 416[31000] -> 417[4b000] via P2P/IPC/read
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 01 : 52[31000] -> 53[4b000] via P2P/IPC/read
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 00 : 316[31000] -> 317[4b000] via P2P/IPC/read
434: hkn0730:1426053:1426183 [2] NCCL INFO Connected all rings
  5: hkn0404:1363874:1363976 [1] NCCL INFO Connected all rings
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 00 : 352[31000] -> 353[4b000] via P2P/IPC/read
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 01 : 148[31000] -> 149[4b000] via P2P/IPC/read
356: hkn0708:437611:437707 [0] NCCL INFO Channel 00 : 356[31000] -> 357[4b000] via P2P/IPC/read
508: hkn0816:399946:400046 [0] NCCL INFO Channel 00 : 508[31000] -> 509[4b000] via P2P/IPC/read
446: hkn0733:1413719:1413842 [2] NCCL INFO Connected all rings
338: hkn0703:765558:765658 [2] NCCL INFO Connected all rings
162: hkn0520:2737243:2737371 [2] NCCL INFO Connected all rings
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 00 : 73[4b000] -> 74[ca000] via P2P/IPC/read
188: hkn0528:1326072:1326164 [0] NCCL INFO Connected all rings
228: hkn0604:713559:713655 [0] NCCL INFO Connected all rings
460: hkn0802:1224720:1224848 [0] NCCL INFO Connected all rings
334: hkn0636:1678724:1678867 [2] NCCL INFO Connected all rings
484: hkn0808:995046:995154 [0] NCCL INFO Channel 01 : 484[31000] -> 485[4b000] via P2P/IPC/read
302: hkn0628:696364:696481 [2] NCCL INFO Connected all rings
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 00 : 312[31000] -> 313[4b000] via P2P/IPC/read
350: hkn0706:776596:776723 [2] NCCL INFO Connected all rings
230: hkn0604:713539:713662 [2] NCCL INFO Connected all rings
 62: hkn0420:3234575:3234691 [2] NCCL INFO Channel 00 : 62[ca000] -> 63[e3000] via P2P/IPC/read
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 00 : 81[4b000] -> 82[ca000] via P2P/IPC/read
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 00 : 164[31000] -> 165[4b000] via P2P/IPC/read
506: hkn0815:419477:419589 [2] NCCL INFO Connected all rings
336: hkn0703:765538:765661 [0] NCCL INFO Channel 00 : 336[31000] -> 337[4b000] via P2P/IPC/read
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 01 : 61[4b000] -> 62[ca000] via P2P/IPC/read
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 01 : 128[31000] -> 129[4b000] via P2P/IPC/read
300: hkn0628:696392:696486 [0] NCCL INFO Channel 00 : 300[31000] -> 301[4b000] via P2P/IPC/read
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 01 : 32[31000] -> 33[4b000] via P2P/IPC/read
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 00 : 444[31000] -> 445[4b000] via P2P/IPC/read
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 00 : 89[4b000] -> 90[ca000] via P2P/IPC/read
 70: hkn0422:4177477:4177595 [2] NCCL INFO Channel 00 : 70[ca000] -> 71[e3000] via P2P/IPC/read
 22: hkn0409:2609992:2610120 [2] NCCL INFO Connected all rings
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 00 : 332[31000] -> 333[4b000] via P2P/IPC/read
  9: hkn0405:3231499:3231610 [1] NCCL INFO Connected all rings
306: hkn0629:1616375:1616505 [2] NCCL INFO Connected all rings
276: hkn0621:2016113:2016222 [0] NCCL INFO Connected all rings
208: hkn0534:1172769:1172865 [0] NCCL INFO Connected all rings
382: hkn0715:426276:426394 [2] NCCL INFO Connected all rings
504: hkn0815:419469:419586 [0] NCCL INFO Channel 00 : 504[31000] -> 505[4b000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Connected all rings
368: hkn0712:319436:319546 [0] NCCL INFO Channel 01 : 368[31000] -> 369[4b000] via P2P/IPC/read
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 01 : 144[31000] -> 145[4b000] via P2P/IPC/read
197: hkn0530:1282466:1282581 [1] NCCL INFO Connected all rings
177: hkn0525:1011146:1011240 [1] NCCL INFO Connected all rings
 20: hkn0409:2610000:2610117 [0] NCCL INFO Connected all rings
310: hkn0630:1622852:1622969 [2] NCCL INFO Connected all rings
488: hkn0809:961652:961773 [0] NCCL INFO Channel 01 : 488[31000] -> 489[4b000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 01 : 40[31000] -> 41[4b000] via P2P/IPC/read
378: hkn0714:456363:456478 [2] NCCL INFO Connected all rings
225: hkn0603:1437591:1437698 [1] NCCL INFO Connected all rings
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 01 : 76[31000] -> 77[4b000] via P2P/IPC/read
 85: hkn0426:838392:838518 [1] NCCL INFO Channel 00 : 85[4b000] -> 86[ca000] via P2P/IPC/read
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 01 : 392[31000] -> 393[4b000] via P2P/IPC/read
437: hkn0731:1411116:1411213 [1] NCCL INFO Connected all rings
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 01 : 24[31000] -> 25[4b000] via P2P/IPC/read
101: hkn0502:253402:253515 [1] NCCL INFO Channel 00 : 101[4b000] -> 102[ca000] via P2P/IPC/read
346: hkn0705:807578:807672 [2] NCCL INFO Connected all rings
389: hkn0717:19453:19564 [1] NCCL INFO Channel 00 : 389[4b000] -> 390[ca000] via P2P/IPC/read
 14: hkn0407:1840633:1840731 [2] NCCL INFO Connected all rings
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 00 : 93[4b000] -> 94[ca000] via P2P/IPC/read
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 00 : 152[31000] -> 153[4b000] via P2P/IPC/read
422: hkn0726:1572474:1572594 [2] NCCL INFO Connected all rings
236: hkn0606:2396583:2396678 [0] NCCL INFO Connected all rings
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 01 : 104[31000] -> 105[4b000] via P2P/IPC/read
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 01 : 480[31000] -> 481[4b000] via P2P/IPC/read
496: hkn0812:718245:718354 [0] NCCL INFO Channel 01 : 496[31000] -> 497[4b000] via P2P/IPC/read
209: hkn0534:1172749:1172871 [1] NCCL INFO Connected all rings
294: hkn0626:1322810:1322935 [2] NCCL INFO Connected all rings
218: hkn0601:142216:142337 [2] NCCL INFO Connected all rings
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 00 : 432[31000] -> 433[4b000] via P2P/IPC/read
364: hkn0711:608404:608498 [0] NCCL INFO Channel 01 : 364[31000] -> 365[4b000] via P2P/IPC/read
186: hkn0527:1373294:1373422 [2] NCCL INFO Connected all rings
380: hkn0715:426268:426388 [0] NCCL INFO Channel 00 : 380[31000] -> 381[4b000] via P2P/IPC/read
 82: hkn0425:2108517:2108637 [2] NCCL INFO Channel 00 : 82[ca000] -> 83[e3000] via P2P/IPC/read
414: hkn0724:1740337:1740474 [2] NCCL INFO Connected all rings
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via P2P/IPC/read
281: hkn0622:2045016:2045130 [1] NCCL INFO Connected all rings
278: hkn0621:2016125:2016216 [2] NCCL INFO Connected all rings
348: hkn0706:776612:776722 [0] NCCL INFO Channel 00 : 348[31000] -> 349[4b000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 00 : 404[31000] -> 405[4b000] via P2P/IPC/read
326: hkn0634:1545229:1545344 [2] NCCL INFO Connected all rings
344: hkn0705:807566:807679 [0] NCCL INFO Channel 00 : 344[31000] -> 345[4b000] via P2P/IPC/read
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 00 : 308[31000] -> 309[4b000] via P2P/IPC/read
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 00 : 304[31000] -> 305[4b000] via P2P/IPC/read
 69: hkn0422:4177485:4177589 [1] NCCL INFO Channel 01 : 69[4b000] -> 70[ca000] via P2P/IPC/read
260: hkn0613:927106:927208 [0] NCCL INFO Connected all rings
134: hkn0510:2786427:2786528 [2] NCCL INFO Channel 00 : 134[ca000] -> 135[e3000] via P2P/IPC/read
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 01 : 136[31000] -> 137[4b000] via P2P/IPC/read
170: hkn0523:1572577:1572685 [2] NCCL INFO Connected all rings
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 00 : 420[31000] -> 421[4b000] via P2P/IPC/read
485: hkn0808:995038:995153 [1] NCCL INFO Channel 00 : 485[4b000] -> 486[ca000] via P2P/IPC/read
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 01 : 320[31000] -> 321[4b000] via P2P/IPC/read
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 00 : 324[31000] -> 325[4b000] via P2P/IPC/read
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 01 : 120[31000] -> 121[4b000] via P2P/IPC/read
466: hkn0803:900986:901105 [2] NCCL INFO Connected all rings
376: hkn0714:456371:456476 [0] NCCL INFO Channel 00 : 376[31000] -> 377[4b000] via P2P/IPC/read
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 01 : 140[31000] -> 141[4b000] via P2P/IPC/read
133: hkn0510:2786407:2786523 [1] NCCL INFO Channel 01 : 133[4b000] -> 134[ca000] via P2P/IPC/read
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 01 : 28[31000] -> 29[4b000] via P2P/IPC/read
273: hkn0617:2319212:2319310 [1] NCCL INFO Connected all rings
 74: hkn0423:1729414:1729511 [2] NCCL INFO Channel 00 : 74[ca000] -> 75[e3000] via P2P/IPC/read
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 00 : 57[4b000] -> 58[ca000] via P2P/IPC/read
 53: hkn0418:1893541:1893660 [1] NCCL INFO Channel 00 : 53[4b000] -> 54[ca000] via P2P/IPC/read
108: hkn0504:65435:65559 [0] NCCL INFO Channel 01 : 108[31000] -> 109[4b000] via P2P/IPC/read
330: hkn0635:1249906:1250023 [2] NCCL INFO Connected all rings
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 00 : 184[31000] -> 185[4b000] via P2P/IPC/read
 86: hkn0426:838372:838511 [2] NCCL INFO Channel 00 : 86[ca000] -> 87[e3000] via P2P/IPC/read
500: hkn0814:700164:700310 [0] NCCL INFO Channel 01 : 500[31000] -> 501[4b000] via P2P/IPC/read
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 00 : 292[31000] -> 293[4b000] via P2P/IPC/read
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 01 : 112[31000] -> 113[4b000] via P2P/IPC/read
408: hkn0723:232560:232720 [0] NCCL INFO Channel 01 : 408[31000] -> 409[4b000] via P2P/IPC/read
 46: hkn0415:2520763:2520859 [2] NCCL INFO Connected all rings
213: hkn0535:2423328:2423441 [1] NCCL INFO Connected all rings
233: hkn0605:736560:736669 [1] NCCL INFO Connected all rings
266: hkn0615:438703:438813 [2] NCCL INFO Connected all rings
384: hkn0716:132827:132967 [0] NCCL INFO Channel 00 : 384[31000] -> 385[4b000] via P2P/IPC/read
194: hkn0529:1565143:1565270 [2] NCCL INFO Connected all rings
182: hkn0526:1452774:1452881 [2] NCCL INFO Connected all rings
340: hkn0704:816342:816447 [0] NCCL INFO Channel 01 : 340[31000] -> 341[4b000] via P2P/IPC/read
 90: hkn0427:1159498:1159622 [2] NCCL INFO Channel 00 : 90[ca000] -> 91[e3000] via P2P/IPC/read
149: hkn0514:2975087:2975198 [1] NCCL INFO Channel 00 : 149[4b000] -> 150[ca000] via P2P/IPC/read
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 01 : 73[4b000] -> 74[ca000] via P2P/IPC/read
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 00 : 168[31000] -> 169[4b000] via P2P/IPC/read
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 00 : 412[31000] -> 413[4b000] via P2P/IPC/read
390: hkn0717:19445:19567 [2] NCCL INFO Channel 00 : 390[ca000] -> 391[e3000] via P2P/IPC/read
109: hkn0504:65443:65560 [1] NCCL INFO Channel 00 : 109[4b000] -> 110[ca000] via P2P/IPC/read
360: hkn0710:379903:380006 [0] NCCL INFO Channel 00 : 360[31000] -> 361[4b000] via P2P/IPC/read
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 00 : 12[31000] -> 13[4b000] via P2P/IPC/read
 94: hkn0428:691716:691838 [2] NCCL INFO Channel 00 : 94[ca000] -> 95[e3000] via P2P/IPC/read
497: hkn0812:718229:718349 [1] NCCL INFO Channel 00 : 497[4b000] -> 498[ca000] via P2P/IPC/read
398: hkn0719:1330251:1330374 [2] NCCL INFO Connected all rings
268: hkn0616:429398:429527 [0] NCCL INFO Connected all rings
 37: hkn0413:2391086:2391193 [1] NCCL INFO Channel 00 : 37[4b000] -> 38[ca000] via P2P/IPC/read
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 00 : 328[31000] -> 329[4b000] via P2P/IPC/read
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 01 : 124[31000] -> 125[4b000] via P2P/IPC/read
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 01 : 89[4b000] -> 90[ca000] via P2P/IPC/read
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 01 : 81[4b000] -> 82[ca000] via P2P/IPC/read
388: hkn0717:19465:19565 [0] NCCL INFO Connected all rings
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 01 : 468[31000] -> 469[4b000] via P2P/IPC/read
492: hkn0810:963933:964030 [0] NCCL INFO Channel 01 : 492[31000] -> 493[4b000] via P2P/IPC/read
205: hkn0532:950469:950780 [1] NCCL INFO Connected all rings
361: hkn0710:379895:380014 [1] NCCL INFO Channel 00 : 361[4b000] -> 362[ca000] via P2P/IPC/read
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 00 : 44[31000] -> 45[4b000] via P2P/IPC/read
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 00 : 33[4b000] -> 34[ca000] via P2P/IPC/read
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 01 : 296[31000] -> 297[4b000] via P2P/IPC/read
202: hkn0531:1255138:1255243 [2] NCCL INFO Connected all rings
430: hkn0728:1348501:1348594 [2] NCCL INFO Connected all rings
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 00 : 289[4b000] -> 290[ca000] via P2P/IPC/read
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 01 : 448[31000] -> 449[4b000] via P2P/IPC/read
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 00 : 129[4b000] -> 130[ca000] via P2P/IPC/read
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 01 : 96[31000] -> 97[4b000] via P2P/IPC/read
373: hkn0713:494610:494705 [1] NCCL INFO Connected all rings
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 01 : 476[31000] -> 477[4b000] via P2P/IPC/read
486: hkn0808:995058:995152 [2] NCCL INFO Channel 00 : 486[ca000] -> 487[e3000] via P2P/IPC/read
222: hkn0602:3390386:3390580 [2] NCCL INFO Connected all rings
257: hkn0612:941317:941465 [1] NCCL INFO Connected all rings
216: hkn0601:142244:142342 [0] NCCL INFO Channel 00 : 216[31000] -> 217[4b000] via P2P/IPC/read
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 00 : 440[31000] -> 441[4b000] via P2P/IPC/read
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 00 : 145[4b000] -> 146[ca000] via P2P/IPC/read
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 00 : 48[31000] -> 49[4b000] via P2P/IPC/read
105: hkn0503:2924190:2924283 [1] NCCL INFO Connected all rings
454: hkn0736:1532624:1532729 [2] NCCL INFO Connected all rings
458: hkn0801:2264537:2264649 [2] NCCL INFO Connected all rings
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 01 : 416[31000] -> 417[4b000] via P2P/IPC/read
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 01 : 316[31000] -> 317[4b000] via P2P/IPC/read
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 01 : 472[31000] -> 473[4b000] via P2P/IPC/read
  6: hkn0404:1363846:1363970 [2] NCCL INFO Connected all rings
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 01 : 352[31000] -> 353[4b000] via P2P/IPC/read
102: hkn0502:253394:253516 [2] NCCL INFO Channel 00 : 102[ca000] -> 103[e3000] via P2P/IPC/read
 85: hkn0426:838392:838518 [1] NCCL INFO Channel 01 : 85[4b000] -> 86[ca000] via P2P/IPC/read
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 00 : 396[31000] -> 397[4b000] via P2P/IPC/read
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 00 : 41[4b000] -> 42[ca000] via P2P/IPC/read
365: hkn0711:608392:608506 [1] NCCL INFO Channel 00 : 365[4b000] -> 366[ca000] via P2P/IPC/read
508: hkn0816:399946:400046 [0] NCCL INFO Channel 01 : 508[31000] -> 509[4b000] via P2P/IPC/read
401: hkn0720:33760:33906 [1] NCCL INFO Connected all rings
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 00 : 220[31000] -> 221[4b000] via P2P/IPC/read
240: hkn0607:928741:928852 [0] NCCL INFO Connected all rings
369: hkn0712:319420:319542 [1] NCCL INFO Channel 00 : 369[4b000] -> 370[ca000] via P2P/IPC/read
284: hkn0623:1897127:1897252 [0] NCCL INFO Connected all rings
238: hkn0606:2396571:2396682 [2] NCCL INFO Connected all rings
101: hkn0502:253402:253515 [1] NCCL INFO Channel 01 : 101[4b000] -> 102[ca000] via P2P/IPC/read
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 00 : 452[31000] -> 453[4b000] via P2P/IPC/read
228: hkn0604:713559:713655 [0] NCCL INFO Channel 00 : 228[31000] -> 229[4b000] via P2P/IPC/read
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 00 : 121[4b000] -> 122[ca000] via P2P/IPC/read
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 00 : 172[31000] -> 173[4b000] via P2P/IPC/read
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 01 : 93[4b000] -> 94[ca000] via P2P/IPC/read
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 00 : 393[4b000] -> 394[ca000] via P2P/IPC/read
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 01 : 312[31000] -> 313[4b000] via P2P/IPC/read
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 00 : 297[4b000] -> 298[ca000] via P2P/IPC/read
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 00 : 25[4b000] -> 26[ca000] via P2P/IPC/read
 38: hkn0413:2391078:2391198 [2] NCCL INFO Channel 00 : 38[ca000] -> 39[e3000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 01 : 336[31000] -> 337[4b000] via P2P/IPC/read
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 01 : 164[31000] -> 165[4b000] via P2P/IPC/read
 58: hkn0419:1568591:1568715 [2] NCCL INFO Channel 00 : 58[ca000] -> 59[e3000] via P2P/IPC/read
  1: hkn0403:1808437:1808809 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[ca000] via P2P/IPC/read
262: hkn0613:927118:927210 [2] NCCL INFO Connected all rings
248: hkn0609:735146:735265 [0] NCCL INFO Connected all rings
 62: hkn0420:3234575:3234691 [2] NCCL INFO Channel 01 : 62[ca000] -> 63[e3000] via P2P/IPC/read
174: hkn0524:1158156:1158250 [2] NCCL INFO Connected all rings
389: hkn0717:19453:19564 [1] NCCL INFO Channel 01 : 389[4b000] -> 390[ca000] via P2P/IPC/read
 70: hkn0422:4177477:4177595 [2] NCCL INFO Channel 01 : 70[ca000] -> 71[e3000] via P2P/IPC/read
 26: hkn0410:1184027:1184146 [2] NCCL INFO Channel 00 : 26[ca000] -> 27[e3000] via P2P/IPC/read
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 00 : 4[31000] -> 5[4b000] via P2P/IPC/read
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 00 : 77[4b000] -> 78[ca000] via P2P/IPC/read
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 01 : 332[31000] -> 333[4b000] via P2P/IPC/read
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 00 : 481[4b000] -> 482[ca000] via P2P/IPC/read
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 00 : 321[4b000] -> 322[ca000] via P2P/IPC/read
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 01 : 444[31000] -> 445[4b000] via P2P/IPC/read
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 00 : 180[31000] -> 181[4b000] via P2P/IPC/read
485: hkn0808:995038:995153 [1] NCCL INFO Channel 01 : 485[4b000] -> 486[ca000] via P2P/IPC/read
264: hkn0615:438687:438806 [0] NCCL INFO Channel 00 : 264[31000] -> 265[4b000] via P2P/IPC/read
146: hkn0513:3037323:3037444 [2] NCCL INFO Channel 00 : 146[ca000] -> 147[e3000] via P2P/IPC/read
118: hkn0506:862450:862548 [2] NCCL INFO Connected all rings
374: hkn0713:494590:494707 [2] NCCL INFO Connected all rings
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 01 : 57[4b000] -> 58[ca000] via P2P/IPC/read
504: hkn0815:419469:419586 [0] NCCL INFO Channel 01 : 504[31000] -> 505[4b000] via P2P/IPC/read
 54: hkn0418:1893557:1893666 [2] NCCL INFO Channel 00 : 54[ca000] -> 55[e3000] via P2P/IPC/read
288: hkn0624:1797296:1797392 [0] NCCL INFO Connected all rings
300: hkn0628:696392:696486 [0] NCCL INFO Channel 01 : 300[31000] -> 301[4b000] via P2P/IPC/read
438: hkn0731:1411096:1411207 [2] NCCL INFO Connected all rings
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 00 : 137[4b000] -> 138[ca000] via P2P/IPC/read
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 00 : 428[31000] -> 429[4b000] via P2P/IPC/read
498: hkn0812:718237:718348 [2] NCCL INFO Channel 00 : 498[ca000] -> 499[e3000] via P2P/IPC/read
150: hkn0514:2975099:2975195 [2] NCCL INFO Channel 00 : 150[ca000] -> 151[e3000] via P2P/IPC/read
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 00 : 200[31000] -> 201[4b000] via P2P/IPC/read
 53: hkn0418:1893541:1893660 [1] NCCL INFO Channel 01 : 53[4b000] -> 54[ca000] via P2P/IPC/read
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 00 : 29[4b000] -> 30[ca000] via P2P/IPC/read
149: hkn0514:2975087:2975198 [1] NCCL INFO Channel 01 : 149[4b000] -> 150[ca000] via P2P/IPC/read
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 00 : 20[31000] -> 21[4b000] via P2P/IPC/read
501: hkn0814:700172:700309 [1] NCCL INFO Channel 00 : 501[4b000] -> 502[ca000] via P2P/IPC/read
489: hkn0809:961668:961775 [1] NCCL INFO Channel 00 : 489[4b000] -> 490[ca000] via P2P/IPC/read
 34: hkn0412:2286727:2286850 [2] NCCL INFO Channel 00 : 34[ca000] -> 35[e3000] via P2P/IPC/read
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 00 : 141[4b000] -> 142[ca000] via P2P/IPC/read
341: hkn0704:816354:816450 [1] NCCL INFO Channel 00 : 341[4b000] -> 342[ca000] via P2P/IPC/read
245: hkn0608:510084:510183 [1] NCCL INFO Connected all rings
380: hkn0715:426268:426388 [0] NCCL INFO Channel 01 : 380[31000] -> 381[4b000] via P2P/IPC/read
372: hkn0713:494598:494713 [0] NCCL INFO Channel 00 : 372[31000] -> 373[4b000] via P2P/IPC/read
469: hkn0804:1230034:1230144 [1] NCCL INFO Channel 00 : 469[4b000] -> 470[ca000] via P2P/IPC/read
497: hkn0812:718229:718349 [1] NCCL INFO Channel 01 : 497[4b000] -> 498[ca000] via P2P/IPC/read
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 00 : 113[4b000] -> 114[ca000] via P2P/IPC/read
110: hkn0504:65463:65554 [2] NCCL INFO Channel 00 : 110[ca000] -> 111[e3000] via P2P/IPC/read
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 01 : 432[31000] -> 433[4b000] via P2P/IPC/read
409: hkn0723:232568:232721 [1] NCCL INFO Channel 00 : 409[4b000] -> 410[ca000] via P2P/IPC/read
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 00 : 441[4b000] -> 442[ca000] via P2P/IPC/read
130: hkn0509:3148779:3148872 [2] NCCL INFO Channel 00 : 130[ca000] -> 131[e3000] via P2P/IPC/read
165: hkn0521:1222177:1222293 [1] NCCL INFO Channel 00 : 165[4b000] -> 166[ca000] via P2P/IPC/read
210: hkn0534:1172741:1172868 [2] NCCL INFO Connected all rings
109: hkn0504:65443:65560 [1] NCCL INFO Channel 01 : 109[4b000] -> 110[ca000] via P2P/IPC/read
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 00 : 276[31000] -> 277[4b000] via P2P/IPC/read
 37: hkn0413:2391086:2391193 [1] NCCL INFO Channel 01 : 37[4b000] -> 38[ca000] via P2P/IPC/read
272: hkn0617:2319184:2319311 [0] NCCL INFO Connected all rings
344: hkn0705:807566:807679 [0] NCCL INFO Channel 01 : 344[31000] -> 345[4b000] via P2P/IPC/read
 82: hkn0425:2108517:2108637 [2] NCCL INFO Channel 01 : 82[ca000] -> 83[e3000] via P2P/IPC/read
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 00 : 456[31000] -> 457[4b000] via P2P/IPC/read
290: hkn0624:1797282:1797386 [2] NCCL INFO Channel 00 : 290[ca000] -> 291[e3000] via P2P/IPC/read
348: hkn0706:776612:776722 [0] NCCL INFO Channel 01 : 348[31000] -> 349[4b000] via P2P/IPC/read
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 01 : 33[4b000] -> 34[ca000] via P2P/IPC/read
192: hkn0529:1565151:1565262 [0] NCCL INFO Connected all rings
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 00 : 436[31000] -> 437[4b000] via P2P/IPC/read
 78: hkn0424:2972321:2972426 [2] NCCL INFO Channel 00 : 78[ca000] -> 79[e3000] via P2P/IPC/read
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 01 : 308[31000] -> 309[4b000] via P2P/IPC/read
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 01 : 129[4b000] -> 130[ca000] via P2P/IPC/read
 10: hkn0405:3231519:3231613 [2] NCCL INFO Connected all rings
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 00 : 477[4b000] -> 478[ca000] via P2P/IPC/read
  2: hkn0403:1808457:1808810 [2] NCCL INFO Channel 00 : 2[ca000] -> 3[e3000] via P2P/IPC/read
 42: hkn0414:2006114:2006224 [2] NCCL INFO Channel 00 : 42[ca000] -> 43[e3000] via P2P/IPC/read
376: hkn0714:456371:456476 [0] NCCL INFO Channel 01 : 376[31000] -> 377[4b000] via P2P/IPC/read
362: hkn0710:379915:380012 [2] NCCL INFO Channel 00 : 362[ca000] -> 363[e3000] via P2P/IPC/read
322: hkn0633:1550649:1550756 [2] NCCL INFO Channel 00 : 322[ca000] -> 323[e3000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 01 : 404[31000] -> 405[4b000] via P2P/IPC/read
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 01 : 324[31000] -> 325[4b000] via P2P/IPC/read
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 00 : 125[4b000] -> 126[ca000] via P2P/IPC/read
116: hkn0506:862438:862546 [0] NCCL INFO Channel 01 : 116[31000] -> 117[4b000] via P2P/IPC/read
390: hkn0717:19445:19567 [2] NCCL INFO Channel 01 : 390[ca000] -> 391[e3000] via P2P/IPC/read
493: hkn0810:963905:964027 [1] NCCL INFO Channel 00 : 493[4b000] -> 494[ca000] via P2P/IPC/read
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 01 : 304[31000] -> 305[4b000] via P2P/IPC/read
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 00 : 212[31000] -> 213[4b000] via P2P/IPC/read
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 01 : 145[4b000] -> 146[ca000] via P2P/IPC/read
134: hkn0510:2786427:2786528 [2] NCCL INFO Channel 01 : 134[ca000] -> 135[e3000] via P2P/IPC/read
366: hkn0711:608384:608505 [2] NCCL INFO Channel 00 : 366[ca000] -> 367[e3000] via P2P/IPC/read
198: hkn0530:1282474:1282589 [2] NCCL INFO Connected all rings
178: hkn0525:1011134:1011249 [2] NCCL INFO Connected all rings
394: hkn0718:3941447:3941548 [2] NCCL INFO Channel 00 : 394[ca000] -> 395[e3000] via P2P/IPC/read
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 01 : 420[31000] -> 421[4b000] via P2P/IPC/read
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 01 : 292[31000] -> 293[4b000] via P2P/IPC/read
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 00 : 473[4b000] -> 474[ca000] via P2P/IPC/read
405: hkn0721:2323871:2323991 [1] NCCL INFO Channel 00 : 405[4b000] -> 406[ca000] via P2P/IPC/read
298: hkn0627:1812322:1812413 [2] NCCL INFO Channel 00 : 298[ca000] -> 299[e3000] via P2P/IPC/read
370: hkn0712:319448:319543 [2] NCCL INFO Channel 00 : 370[ca000] -> 371[e3000] via P2P/IPC/read
122: hkn0507:3211459:3211565 [2] NCCL INFO Channel 00 : 122[ca000] -> 123[e3000] via P2P/IPC/read
365: hkn0711:608392:608506 [1] NCCL INFO Channel 01 : 365[4b000] -> 366[ca000] via P2P/IPC/read
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 00 : 353[4b000] -> 354[ca000] via P2P/IPC/read
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 00 : 460[31000] -> 461[4b000] via P2P/IPC/read
509: hkn0816:399926:400042 [1] NCCL INFO Channel 00 : 509[4b000] -> 510[ca000] via P2P/IPC/read
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 01 : 184[31000] -> 185[4b000] via P2P/IPC/read
356: hkn0708:437611:437707 [0] NCCL INFO Channel 01 : 356[31000] -> 357[4b000] via P2P/IPC/read
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 00 : 97[4b000] -> 98[ca000] via P2P/IPC/read
 86: hkn0426:838372:838511 [2] NCCL INFO Channel 01 : 86[ca000] -> 87[e3000] via P2P/IPC/read
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 00 : 8[31000] -> 9[4b000] via P2P/IPC/read
388: hkn0717:19465:19565 [0] NCCL INFO Channel 00 : 388[31000] -> 389[4b000] via P2P/IPC/read
 17: hkn0408:2915262:2915390 [1] NCCL INFO Connected all rings
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 01 : 41[4b000] -> 42[ca000] via P2P/IPC/read
360: hkn0710:379903:380006 [0] NCCL INFO Channel 01 : 360[31000] -> 361[4b000] via P2P/IPC/read
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 01 : 289[4b000] -> 290[ca000] via P2P/IPC/read
240: hkn0607:928741:928852 [0] NCCL INFO Channel 00 : 240[31000] -> 241[4b000] via P2P/IPC/read
385: hkn0716:132811:132965 [1] NCCL INFO Connected all rings
226: hkn0603:1437603:1437704 [2] NCCL INFO Connected all rings
369: hkn0712:319420:319542 [1] NCCL INFO Channel 01 : 369[4b000] -> 370[ca000] via P2P/IPC/read
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 00 : 284[31000] -> 285[4b000] via P2P/IPC/read
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 01 : 121[4b000] -> 122[ca000] via P2P/IPC/read
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 00 : 49[4b000] -> 50[ca000] via P2P/IPC/read
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 00 : 161[4b000] -> 162[ca000] via P2P/IPC/read
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 00 : 196[31000] -> 197[4b000] via P2P/IPC/read
425: hkn0727:1370175:1370283 [1] NCCL INFO Connected all rings
 74: hkn0423:1729414:1729511 [2] NCCL INFO Channel 01 : 74[ca000] -> 75[e3000] via P2P/IPC/read
189: hkn0528:1326044:1326167 [1] NCCL INFO Connected all rings
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 01 : 412[31000] -> 413[4b000] via P2P/IPC/read
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 01 : 393[4b000] -> 394[ca000] via P2P/IPC/read
482: hkn0807:1043406:1043538 [2] NCCL INFO Channel 00 : 482[ca000] -> 483[e3000] via P2P/IPC/read
490: hkn0809:961680:961778 [2] NCCL INFO Channel 00 : 490[ca000] -> 491[e3000] via P2P/IPC/read
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 00 : 417[4b000] -> 418[ca000] via P2P/IPC/read
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 00 : 317[4b000] -> 318[ca000] via P2P/IPC/read
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 00 : 313[4b000] -> 314[ca000] via P2P/IPC/read
361: hkn0710:379895:380014 [1] NCCL INFO Channel 01 : 361[4b000] -> 362[ca000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 00 : 224[31000] -> 225[4b000] via P2P/IPC/read
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 01 : 44[31000] -> 45[4b000] via P2P/IPC/read
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 01 : 297[4b000] -> 298[ca000] via P2P/IPC/read
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 01 : 25[4b000] -> 26[ca000] via P2P/IPC/read
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 01 : 12[31000] -> 13[4b000] via P2P/IPC/read
342: hkn0704:816326:816455 [2] NCCL INFO Channel 00 : 342[ca000] -> 343[e3000] via P2P/IPC/read
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 01 : 328[31000] -> 329[4b000] via P2P/IPC/read
160: hkn0520:2737215:2737368 [0] NCCL INFO Connected all rings
 90: hkn0427:1159498:1159622 [2] NCCL INFO Channel 01 : 90[ca000] -> 91[e3000] via P2P/IPC/read
450: hkn0734:1180905:1181006 [2] NCCL INFO Channel 00 : 450[ca000] -> 451[e3000] via P2P/IPC/read
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 00 : 176[31000] -> 177[4b000] via P2P/IPC/read
106: hkn0503:2924162:2924287 [2] NCCL INFO Connected all rings
 94: hkn0428:691716:691838 [2] NCCL INFO Channel 01 : 94[ca000] -> 95[e3000] via P2P/IPC/read
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 01 : 168[31000] -> 169[4b000] via P2P/IPC/read
470: hkn0804:1230046:1230140 [2] NCCL INFO Channel 00 : 470[ca000] -> 471[e3000] via P2P/IPC/read
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 01 : 396[31000] -> 397[4b000] via P2P/IPC/read
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 00 : 280[31000] -> 281[4b000] via P2P/IPC/read
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 01 : 321[4b000] -> 322[ca000] via P2P/IPC/read
260: hkn0613:927106:927208 [0] NCCL INFO Channel 00 : 260[31000] -> 261[4b000] via P2P/IPC/read
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 00 : 236[31000] -> 237[4b000] via P2P/IPC/read
 26: hkn0410:1184027:1184146 [2] NCCL INFO Channel 01 : 26[ca000] -> 27[e3000] via P2P/IPC/read
157: hkn0516:2940314:2940436 [1] NCCL INFO Connected all rings
337: hkn0703:765546:765657 [1] NCCL INFO Channel 00 : 337[4b000] -> 338[ca000] via P2P/IPC/read
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 01 : 77[4b000] -> 78[ca000] via P2P/IPC/read
138: hkn0511:3090897:3090992 [2] NCCL INFO Channel 00 : 138[ca000] -> 139[e3000] via P2P/IPC/read
357: hkn0708:437583:437699 [1] NCCL INFO Connected all rings
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 01 : 481[4b000] -> 482[ca000] via P2P/IPC/read
464: hkn0803:901006:901108 [0] NCCL INFO Connected all rings
486: hkn0808:995058:995152 [2] NCCL INFO Channel 01 : 486[ca000] -> 487[e3000] via P2P/IPC/read
  1: hkn0403:1808437:1808809 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[ca000] via P2P/IPC/read
268: hkn0616:429398:429527 [0] NCCL INFO Channel 00 : 268[31000] -> 269[4b000] via P2P/IPC/read
301: hkn0628:696372:696489 [1] NCCL INFO Channel 00 : 301[4b000] -> 302[ca000] via P2P/IPC/read
142: hkn0512:3068454:3068574 [2] NCCL INFO Channel 00 : 142[ca000] -> 143[e3000] via P2P/IPC/read
214: hkn0535:2423350:2423446 [2] NCCL INFO Connected all rings
249: hkn0609:735138:735259 [1] NCCL INFO Connected all rings
 67: hkn0421:2208711:2208878 [3] NCCL INFO Connected all trees
 30: hkn0411:2340293:2340389 [2] NCCL INFO Channel 00 : 30[ca000] -> 31[e3000] via P2P/IPC/read
461: hkn0802:1224708:1224841 [1] NCCL INFO Connected all rings
274: hkn0617:2319200:2319315 [2] NCCL INFO Connected all rings
502: hkn0814:700184:700311 [2] NCCL INFO Channel 00 : 502[ca000] -> 503[e3000] via P2P/IPC/read
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 00 : 208[31000] -> 209[4b000] via P2P/IPC/read
114: hkn0505:2328143:2328257 [2] NCCL INFO Channel 00 : 114[ca000] -> 115[e3000] via P2P/IPC/read
410: hkn0723:232552:232722 [2] NCCL INFO Channel 00 : 410[ca000] -> 411[e3000] via P2P/IPC/read
406: hkn0721:2323879:2323993 [2] NCCL INFO Channel 00 : 406[ca000] -> 407[e3000] via P2P/IPC/read
156: hkn0516:2940342:2940437 [0] NCCL INFO Connected all rings
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 00 : 445[4b000] -> 446[ca000] via P2P/IPC/read
354: hkn0707:4044308:4044418 [2] NCCL INFO Channel 00 : 354[ca000] -> 355[e3000] via P2P/IPC/read
 67: hkn0421:2208711:2208878 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
510: hkn0816:399918:400045 [2] NCCL INFO Channel 00 : 510[ca000] -> 511[e3000] via P2P/IPC/read
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 00 : 449[4b000] -> 450[ca000] via P2P/IPC/read
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 00 : 333[4b000] -> 334[ca000] via P2P/IPC/read
166: hkn0521:1222185:1222296 [2] NCCL INFO Channel 00 : 166[ca000] -> 167[e3000] via P2P/IPC/read
153: hkn0515:2921190:2921327 [1] NCCL INFO Connected all rings
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 01 : 440[31000] -> 441[4b000] via P2P/IPC/read
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 01 : 141[4b000] -> 142[ca000] via P2P/IPC/read
228: hkn0604:713559:713655 [0] NCCL INFO Channel 01 : 228[31000] -> 229[4b000] via P2P/IPC/read
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 01 : 48[31000] -> 49[4b000] via P2P/IPC/read
 67: hkn0421:2208711:2208878 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
102: hkn0502:253394:253516 [2] NCCL INFO Channel 01 : 102[ca000] -> 103[e3000] via P2P/IPC/read
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 01 : 29[4b000] -> 30[ca000] via P2P/IPC/read
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 01 : 137[4b000] -> 138[ca000] via P2P/IPC/read
400: hkn0720:33752:33908 [0] NCCL INFO Channel 00 : 400[31000] -> 401[4b000] via P2P/IPC/read
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 01 : 452[31000] -> 453[4b000] via P2P/IPC/read
501: hkn0814:700172:700309 [1] NCCL INFO Channel 01 : 501[4b000] -> 502[ca000] via P2P/IPC/read
505: hkn0815:419461:419585 [1] NCCL INFO Channel 00 : 505[4b000] -> 506[ca000] via P2P/IPC/read
489: hkn0809:961668:961775 [1] NCCL INFO Channel 01 : 489[4b000] -> 490[ca000] via P2P/IPC/read
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 01 : 113[4b000] -> 114[ca000] via P2P/IPC/read
232: hkn0605:736552:736663 [0] NCCL INFO Channel 00 : 232[31000] -> 233[4b000] via P2P/IPC/read
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 01 : 220[31000] -> 221[4b000] via P2P/IPC/read
258: hkn0612:941345:941470 [2] NCCL INFO Connected all rings
409: hkn0723:232568:232721 [1] NCCL INFO Channel 01 : 409[4b000] -> 410[ca000] via P2P/IPC/read
 38: hkn0413:2391078:2391198 [2] NCCL INFO Channel 01 : 38[ca000] -> 39[e3000] via P2P/IPC/read
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 01 : 172[31000] -> 173[4b000] via P2P/IPC/read
341: hkn0704:816354:816450 [1] NCCL INFO Channel 01 : 341[4b000] -> 342[ca000] via P2P/IPC/read
126: hkn0508:3163478:3163601 [2] NCCL INFO Channel 00 : 126[ca000] -> 127[e3000] via P2P/IPC/read
165: hkn0521:1222177:1222293 [1] NCCL INFO Channel 01 : 165[4b000] -> 166[ca000] via P2P/IPC/read
469: hkn0804:1230034:1230144 [1] NCCL INFO Channel 01 : 469[4b000] -> 470[ca000] via P2P/IPC/read
494: hkn0810:963913:964023 [2] NCCL INFO Channel 00 : 494[ca000] -> 495[e3000] via P2P/IPC/read
478: hkn0806:1078688:1078789 [2] NCCL INFO Channel 00 : 478[ca000] -> 479[e3000] via P2P/IPC/read
234: hkn0605:736544:736667 [2] NCCL INFO Connected all rings
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 00 : 305[4b000] -> 306[ca000] via P2P/IPC/read
204: hkn0532:950481:950779 [0] NCCL INFO Channel 00 : 204[31000] -> 205[4b000] via P2P/IPC/read
314: hkn0631:1046179:1046288 [2] NCCL INFO Channel 00 : 314[ca000] -> 315[e3000] via P2P/IPC/read
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 00 : 288[31000] -> 289[4b000] via P2P/IPC/read
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 01 : 4[31000] -> 5[4b000] via P2P/IPC/read
381: hkn0715:426296:426395 [1] NCCL INFO Channel 00 : 381[4b000] -> 382[ca000] via P2P/IPC/read
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 01 : 477[4b000] -> 478[ca000] via P2P/IPC/read
206: hkn0532:950453:950783 [2] NCCL INFO Connected all rings
349: hkn0706:776624:776729 [1] NCCL INFO Channel 00 : 349[4b000] -> 350[ca000] via P2P/IPC/read
442: hkn0732:1236013:1236130 [2] NCCL INFO Channel 00 : 442[ca000] -> 443[e3000] via P2P/IPC/read
162: hkn0520:2737243:2737371 [2] NCCL INFO Channel 00 : 162[ca000] -> 163[e3000] via P2P/IPC/read
309: hkn0630:1622860:1622960 [1] NCCL INFO Channel 00 : 309[4b000] -> 310[ca000] via P2P/IPC/read
493: hkn0810:963905:964027 [1] NCCL INFO Channel 01 : 493[4b000] -> 494[ca000] via P2P/IPC/read
474: hkn0805:1136461:1136592 [2] NCCL INFO Channel 00 : 474[ca000] -> 475[e3000] via P2P/IPC/read
290: hkn0624:1797282:1797386 [2] NCCL INFO Channel 01 : 290[ca000] -> 291[e3000] via P2P/IPC/read
264: hkn0615:438687:438806 [0] NCCL INFO Channel 01 : 264[31000] -> 265[4b000] via P2P/IPC/read
146: hkn0513:3037323:3037444 [2] NCCL INFO Channel 01 : 146[ca000] -> 147[e3000] via P2P/IPC/read
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 01 : 125[4b000] -> 126[ca000] via P2P/IPC/read
345: hkn0705:807558:807678 [1] NCCL INFO Channel 00 : 345[4b000] -> 346[ca000] via P2P/IPC/read
 58: hkn0419:1568591:1568715 [2] NCCL INFO Channel 01 : 58[ca000] -> 59[e3000] via P2P/IPC/read
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 00 : 188[31000] -> 189[4b000] via P2P/IPC/read
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 01 : 428[31000] -> 429[4b000] via P2P/IPC/read
465: hkn0803:900978:901109 [1] NCCL INFO Channel 00 : 465[4b000] -> 466[ca000] via P2P/IPC/read
377: hkn0714:456383:456480 [1] NCCL INFO Channel 00 : 377[4b000] -> 378[ca000] via P2P/IPC/read
434: hkn0730:1426053:1426183 [2] NCCL INFO Channel 00 : 434[ca000] -> 435[e3000] via P2P/IPC/read
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 01 : 180[31000] -> 181[4b000] via P2P/IPC/read
 98: hkn0501:1352394:1352503 [2] NCCL INFO Channel 00 : 98[ca000] -> 99[e3000] via P2P/IPC/read
418: hkn0725:3136324:3136423 [2] NCCL INFO Channel 00 : 418[ca000] -> 419[e3000] via P2P/IPC/read
318: hkn0632:1782963:1783087 [2] NCCL INFO Channel 00 : 318[ca000] -> 319[e3000] via P2P/IPC/read
282: hkn0622:2045008:2045126 [2] NCCL INFO Connected all rings
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 01 : 441[4b000] -> 442[ca000] via P2P/IPC/read
405: hkn0721:2323871:2323991 [1] NCCL INFO Channel 01 : 405[4b000] -> 406[ca000] via P2P/IPC/read
325: hkn0634:1545237:1545343 [1] NCCL INFO Channel 00 : 325[4b000] -> 326[ca000] via P2P/IPC/read
229: hkn0604:713547:713656 [1] NCCL INFO Channel 00 : 229[4b000] -> 230[ca000] via P2P/IPC/read
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 01 : 353[4b000] -> 354[ca000] via P2P/IPC/read
509: hkn0816:399926:400042 [1] NCCL INFO Channel 01 : 509[4b000] -> 510[ca000] via P2P/IPC/read
450: hkn0734:1180905:1181006 [2] NCCL INFO Channel 01 : 450[ca000] -> 451[e3000] via P2P/IPC/read
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 01 : 200[31000] -> 201[4b000] via P2P/IPC/read
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 00 : 13[4b000] -> 14[ca000] via P2P/IPC/read
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 01 : 20[31000] -> 21[4b000] via P2P/IPC/read
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 01 : 97[4b000] -> 98[ca000] via P2P/IPC/read
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 00 : 413[4b000] -> 414[ca000] via P2P/IPC/read
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 01 : 417[4b000] -> 418[ca000] via P2P/IPC/read
293: hkn0626:1322798:1322932 [1] NCCL INFO Channel 00 : 293[4b000] -> 294[ca000] via P2P/IPC/read
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 01 : 473[4b000] -> 474[ca000] via P2P/IPC/read
150: hkn0514:2975099:2975195 [2] NCCL INFO Channel 01 : 150[ca000] -> 151[e3000] via P2P/IPC/read
372: hkn0713:494598:494713 [0] NCCL INFO Channel 01 : 372[31000] -> 373[4b000] via P2P/IPC/read
 54: hkn0418:1893557:1893666 [2] NCCL INFO Channel 01 : 54[ca000] -> 55[e3000] via P2P/IPC/read
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 01 : 317[4b000] -> 318[ca000] via P2P/IPC/read
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 00 : 433[4b000] -> 434[ca000] via P2P/IPC/read
338: hkn0703:765558:765658 [2] NCCL INFO Channel 00 : 338[ca000] -> 339[e3000] via P2P/IPC/read
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 01 : 424[31000] -> 425[4b000] via P2P/IPC/read
402: hkn0720:33772:33907 [2] NCCL INFO Connected all rings
 21: hkn0409:2610008:2610115 [1] NCCL INFO Channel 00 : 21[4b000] -> 22[ca000] via P2P/IPC/read
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 01 : 456[31000] -> 457[4b000] via P2P/IPC/read
110: hkn0504:65463:65554 [2] NCCL INFO Channel 01 : 110[ca000] -> 111[e3000] via P2P/IPC/read
 50: hkn0417:2292055:2292170 [2] NCCL INFO Channel 00 : 50[ca000] -> 51[e3000] via P2P/IPC/read
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 01 : 436[31000] -> 437[4b000] via P2P/IPC/read
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 00 : 169[4b000] -> 170[ca000] via P2P/IPC/read
498: hkn0812:718237:718348 [2] NCCL INFO Channel 01 : 498[ca000] -> 499[e3000] via P2P/IPC/read
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 01 : 313[4b000] -> 314[ca000] via P2P/IPC/read
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 01 : 276[31000] -> 277[4b000] via P2P/IPC/read
 34: hkn0412:2286727:2286850 [2] NCCL INFO Channel 01 : 34[ca000] -> 35[e3000] via P2P/IPC/read
122: hkn0507:3211459:3211565 [2] NCCL INFO Channel 01 : 122[ca000] -> 123[e3000] via P2P/IPC/read
421: hkn0726:1572490:1572596 [1] NCCL INFO Channel 00 : 421[4b000] -> 422[ca000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 00 : 16[31000] -> 17[4b000] via P2P/IPC/read
322: hkn0633:1550649:1550756 [2] NCCL INFO Channel 01 : 322[ca000] -> 323[e3000] via P2P/IPC/read
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 01 : 49[4b000] -> 50[ca000] via P2P/IPC/read
337: hkn0703:765546:765657 [1] NCCL INFO Channel 01 : 337[4b000] -> 338[ca000] via P2P/IPC/read
 78: hkn0424:2972321:2972426 [2] NCCL INFO Channel 01 : 78[ca000] -> 79[e3000] via P2P/IPC/read
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 00 : 185[4b000] -> 186[ca000] via P2P/IPC/read
130: hkn0509:3148779:3148872 [2] NCCL INFO Channel 01 : 130[ca000] -> 131[e3000] via P2P/IPC/read
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 01 : 152[31000] -> 153[4b000] via P2P/IPC/read
  2: hkn0403:1808457:1808810 [2] NCCL INFO Channel 01 : 2[ca000] -> 3[e3000] via P2P/IPC/read
302: hkn0628:696364:696481 [2] NCCL INFO Channel 00 : 302[ca000] -> 303[e3000] via P2P/IPC/read
350: hkn0706:776596:776723 [2] NCCL INFO Channel 00 : 350[ca000] -> 351[e3000] via P2P/IPC/read
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 00 : 45[4b000] -> 46[ca000] via P2P/IPC/read
446: hkn0733:1413719:1413842 [2] NCCL INFO Channel 00 : 446[ca000] -> 447[e3000] via P2P/IPC/read
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 00 : 193[4b000] -> 194[ca000] via P2P/IPC/read
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 00 : 329[4b000] -> 330[ca000] via P2P/IPC/read
334: hkn0636:1678724:1678867 [2] NCCL INFO Channel 00 : 334[ca000] -> 335[e3000] via P2P/IPC/read
506: hkn0815:419477:419589 [2] NCCL INFO Channel 00 : 506[ca000] -> 507[e3000] via P2P/IPC/read
301: hkn0628:696372:696489 [1] NCCL INFO Channel 01 : 301[4b000] -> 302[ca000] via P2P/IPC/read
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 01 : 8[31000] -> 9[4b000] via P2P/IPC/read
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 01 : 333[4b000] -> 334[ca000] via P2P/IPC/read
 42: hkn0414:2006114:2006224 [2] NCCL INFO Channel 01 : 42[ca000] -> 43[e3000] via P2P/IPC/read
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 01 : 445[4b000] -> 446[ca000] via P2P/IPC/read
366: hkn0711:608384:608505 [2] NCCL INFO Channel 01 : 366[ca000] -> 367[e3000] via P2P/IPC/read
505: hkn0815:419461:419585 [1] NCCL INFO Channel 01 : 505[4b000] -> 506[ca000] via P2P/IPC/read
306: hkn0629:1616375:1616505 [2] NCCL INFO Channel 00 : 306[ca000] -> 307[e3000] via P2P/IPC/read
277: hkn0621:2016097:2016215 [1] NCCL INFO Channel 00 : 277[4b000] -> 278[ca000] via P2P/IPC/read
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 00 : 192[31000] -> 193[4b000] via P2P/IPC/read
246: hkn0608:510072:510180 [2] NCCL INFO Connected all rings
426: hkn0727:1370159:1370281 [2] NCCL INFO Connected all rings
362: hkn0710:379915:380012 [2] NCCL INFO Channel 01 : 362[ca000] -> 363[e3000] via P2P/IPC/read
370: hkn0712:319448:319543 [2] NCCL INFO Channel 01 : 370[ca000] -> 371[e3000] via P2P/IPC/read
 63: hkn0420:3234583:3234690 [3] NCCL INFO Connected all trees
181: hkn0526:1452758:1452883 [1] NCCL INFO Channel 00 : 181[4b000] -> 182[ca000] via P2P/IPC/read
342: hkn0704:816326:816455 [2] NCCL INFO Channel 01 : 342[ca000] -> 343[e3000] via P2P/IPC/read
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 01 : 161[4b000] -> 162[ca000] via P2P/IPC/read
358: hkn0708:437599:437701 [2] NCCL INFO Connected all rings
394: hkn0718:3941447:3941548 [2] NCCL INFO Channel 01 : 394[ca000] -> 395[e3000] via P2P/IPC/read
490: hkn0809:961680:961778 [2] NCCL INFO Channel 01 : 490[ca000] -> 491[e3000] via P2P/IPC/read
 18: hkn0408:2915278:2915387 [2] NCCL INFO Connected all rings
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 01 : 280[31000] -> 281[4b000] via P2P/IPC/read
265: hkn0615:438714:438810 [1] NCCL INFO Channel 00 : 265[4b000] -> 266[ca000] via P2P/IPC/read
298: hkn0627:1812322:1812413 [2] NCCL INFO Channel 01 : 298[ca000] -> 299[e3000] via P2P/IPC/read
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 01 : 212[31000] -> 213[4b000] via P2P/IPC/read
 63: hkn0420:3234583:3234690 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 01 : 196[31000] -> 197[4b000] via P2P/IPC/read
382: hkn0715:426276:426394 [2] NCCL INFO Channel 00 : 382[ca000] -> 383[e3000] via P2P/IPC/read
310: hkn0630:1622852:1622969 [2] NCCL INFO Channel 00 : 310[ca000] -> 311[e3000] via P2P/IPC/read
378: hkn0714:456363:456478 [2] NCCL INFO Channel 00 : 378[ca000] -> 379[e3000] via P2P/IPC/read
 63: hkn0420:3234583:3234690 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 00 : 272[31000] -> 273[4b000] via P2P/IPC/read
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 01 : 176[31000] -> 177[4b000] via P2P/IPC/read
470: hkn0804:1230046:1230140 [2] NCCL INFO Channel 01 : 470[ca000] -> 471[e3000] via P2P/IPC/read
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 00 : 221[4b000] -> 222[ca000] via P2P/IPC/read
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 01 : 305[4b000] -> 306[ca000] via P2P/IPC/read
384: hkn0716:132827:132967 [0] NCCL INFO Channel 01 : 384[31000] -> 385[4b000] via P2P/IPC/read
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 01 : 236[31000] -> 237[4b000] via P2P/IPC/read
346: hkn0705:807578:807672 [2] NCCL INFO Channel 00 : 346[ca000] -> 347[e3000] via P2P/IPC/read
381: hkn0715:426296:426395 [1] NCCL INFO Channel 01 : 381[4b000] -> 382[ca000] via P2P/IPC/read
256: hkn0612:941333:941464 [0] NCCL INFO Connected all rings
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 01 : 224[31000] -> 225[4b000] via P2P/IPC/read
260: hkn0613:927106:927208 [0] NCCL INFO Channel 01 : 260[31000] -> 261[4b000] via P2P/IPC/read
326: hkn0634:1545229:1545344 [2] NCCL INFO Channel 00 : 326[ca000] -> 327[e3000] via P2P/IPC/read
230: hkn0604:713539:713662 [2] NCCL INFO Channel 00 : 230[ca000] -> 231[e3000] via P2P/IPC/read
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 00 : 173[4b000] -> 174[ca000] via P2P/IPC/read
186: hkn0527:1373294:1373422 [2] NCCL INFO Channel 00 : 186[ca000] -> 187[e3000] via P2P/IPC/read
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 01 : 449[4b000] -> 450[ca000] via P2P/IPC/read
309: hkn0630:1622860:1622960 [1] NCCL INFO Channel 01 : 309[4b000] -> 310[ca000] via P2P/IPC/read
453: hkn0736:1532616:1532726 [1] NCCL INFO Channel 00 : 453[4b000] -> 454[ca000] via P2P/IPC/read
377: hkn0714:456383:456480 [1] NCCL INFO Channel 01 : 377[4b000] -> 378[ca000] via P2P/IPC/read
349: hkn0706:776624:776729 [1] NCCL INFO Channel 01 : 349[4b000] -> 350[ca000] via P2P/IPC/read
 71: hkn0422:4177497:4177588 [3] NCCL INFO Connected all trees
345: hkn0705:807558:807678 [1] NCCL INFO Channel 01 : 345[4b000] -> 346[ca000] via P2P/IPC/read
414: hkn0724:1740337:1740474 [2] NCCL INFO Channel 00 : 414[ca000] -> 415[e3000] via P2P/IPC/read
391: hkn0717:19437:19568 [3] NCCL INFO Connected all trees
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 00 : 429[4b000] -> 430[ca000] via P2P/IPC/read
482: hkn0807:1043406:1043538 [2] NCCL INFO Channel 01 : 482[ca000] -> 483[e3000] via P2P/IPC/read
398: hkn0719:1330251:1330374 [2] NCCL INFO Channel 00 : 398[ca000] -> 399[e3000] via P2P/IPC/read
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 01 : 208[31000] -> 209[4b000] via P2P/IPC/read
294: hkn0626:1322810:1322935 [2] NCCL INFO Channel 00 : 294[ca000] -> 295[e3000] via P2P/IPC/read
434: hkn0730:1426053:1426183 [2] NCCL INFO Channel 01 : 434[ca000] -> 435[e3000] via P2P/IPC/read
 71: hkn0422:4177497:4177588 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
138: hkn0511:3090897:3090992 [2] NCCL INFO Channel 01 : 138[ca000] -> 139[e3000] via P2P/IPC/read
510: hkn0816:399918:400045 [2] NCCL INFO Channel 01 : 510[ca000] -> 511[e3000] via P2P/IPC/read
190: hkn0528:1326060:1326165 [2] NCCL INFO Connected all rings
 71: hkn0422:4177497:4177588 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
406: hkn0721:2323879:2323993 [2] NCCL INFO Channel 01 : 406[ca000] -> 407[e3000] via P2P/IPC/read
142: hkn0512:3068454:3068574 [2] NCCL INFO Channel 01 : 142[ca000] -> 143[e3000] via P2P/IPC/read
229: hkn0604:713547:713656 [1] NCCL INFO Channel 01 : 229[4b000] -> 230[ca000] via P2P/IPC/read
 14: hkn0407:1840633:1840731 [2] NCCL INFO Channel 00 : 14[ca000] -> 15[e3000] via P2P/IPC/read
354: hkn0707:4044308:4044418 [2] NCCL INFO Channel 01 : 354[ca000] -> 355[e3000] via P2P/IPC/read
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 00 : 160[31000] -> 161[4b000] via P2P/IPC/read
 30: hkn0411:2340293:2340389 [2] NCCL INFO Channel 01 : 30[ca000] -> 31[e3000] via P2P/IPC/read
244: hkn0608:510064:510177 [0] NCCL INFO Connected all rings
293: hkn0626:1322798:1322932 [1] NCCL INFO Channel 01 : 293[4b000] -> 294[ca000] via P2P/IPC/read
232: hkn0605:736552:736663 [0] NCCL INFO Channel 01 : 232[31000] -> 233[4b000] via P2P/IPC/read
114: hkn0505:2328143:2328257 [2] NCCL INFO Channel 01 : 114[ca000] -> 115[e3000] via P2P/IPC/read
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 01 : 433[4b000] -> 434[ca000] via P2P/IPC/read
474: hkn0805:1136461:1136592 [2] NCCL INFO Channel 01 : 474[ca000] -> 475[e3000] via P2P/IPC/read
204: hkn0532:950481:950779 [0] NCCL INFO Channel 01 : 204[31000] -> 205[4b000] via P2P/IPC/read
269: hkn0616:429426:429521 [1] NCCL INFO Connected all rings
410: hkn0723:232552:232722 [2] NCCL INFO Channel 01 : 410[ca000] -> 411[e3000] via P2P/IPC/read
314: hkn0631:1046179:1046288 [2] NCCL INFO Channel 01 : 314[ca000] -> 315[e3000] via P2P/IPC/read
386: hkn0716:132819:132964 [2] NCCL INFO Connected all rings
252: hkn0611:734178:734279 [0] NCCL INFO Connected all rings
 46: hkn0415:2520763:2520859 [2] NCCL INFO Channel 00 : 46[ca000] -> 47[e3000] via P2P/IPC/read
241: hkn0607:928753:928855 [1] NCCL INFO Connected all rings
278: hkn0621:2016125:2016216 [2] NCCL INFO Channel 00 : 278[ca000] -> 279[e3000] via P2P/IPC/read
266: hkn0615:438703:438813 [2] NCCL INFO Channel 00 : 266[ca000] -> 267[e3000] via P2P/IPC/read
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 01 : 45[4b000] -> 46[ca000] via P2P/IPC/read
277: hkn0621:2016097:2016215 [1] NCCL INFO Channel 01 : 277[4b000] -> 278[ca000] via P2P/IPC/read
261: hkn0613:927098:927209 [1] NCCL INFO Channel 00 : 261[4b000] -> 262[ca000] via P2P/IPC/read
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 00 : 237[4b000] -> 238[ca000] via P2P/IPC/read
250: hkn0609:735166:735258 [2] NCCL INFO Connected all rings
222: hkn0602:3390386:3390580 [2] NCCL INFO Channel 00 : 222[ca000] -> 223[e3000] via P2P/IPC/read
442: hkn0732:1236013:1236130 [2] NCCL INFO Channel 01 : 442[ca000] -> 443[e3000] via P2P/IPC/read
318: hkn0632:1782963:1783087 [2] NCCL INFO Channel 01 : 318[ca000] -> 319[e3000] via P2P/IPC/read
265: hkn0615:438714:438810 [1] NCCL INFO Channel 01 : 265[4b000] -> 266[ca000] via P2P/IPC/read
285: hkn0623:1897135:1897250 [1] NCCL INFO Connected all rings
248: hkn0609:735146:735265 [0] NCCL INFO Channel 00 : 248[31000] -> 249[4b000] via P2P/IPC/read
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 01 : 221[4b000] -> 222[ca000] via P2P/IPC/read
291: hkn0624:1797274:1797389 [3] NCCL INFO Connected all trees
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 00 : 281[4b000] -> 282[ca000] via P2P/IPC/read
350: hkn0706:776596:776723 [2] NCCL INFO Channel 01 : 350[ca000] -> 351[e3000] via P2P/IPC/read
291: hkn0624:1797274:1797389 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1545237:1545343 [1] NCCL INFO Channel 01 : 325[4b000] -> 326[ca000] via P2P/IPC/read
306: hkn0629:1616375:1616505 [2] NCCL INFO Channel 01 : 306[ca000] -> 307[e3000] via P2P/IPC/read
291: hkn0624:1797274:1797389 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
302: hkn0628:696364:696481 [2] NCCL INFO Channel 01 : 302[ca000] -> 303[e3000] via P2P/IPC/read
158: hkn0516:2940330:2940431 [2] NCCL INFO Connected all rings
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 00 : 209[4b000] -> 210[ca000] via P2P/IPC/read
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 00 : 225[4b000] -> 226[ca000] via P2P/IPC/read
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 01 : 288[31000] -> 289[4b000] via P2P/IPC/read
238: hkn0606:2396571:2396682 [2] NCCL INFO Channel 00 : 238[ca000] -> 239[e3000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 01 : 16[31000] -> 17[4b000] via P2P/IPC/read
213: hkn0535:2423328:2423441 [1] NCCL INFO Channel 00 : 213[4b000] -> 214[ca000] via P2P/IPC/read
262: hkn0613:927118:927210 [2] NCCL INFO Channel 00 : 262[ca000] -> 263[e3000] via P2P/IPC/read
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 00 : 156[31000] -> 157[4b000] via P2P/IPC/read
135: hkn0510:2786399:2786524 [3] NCCL INFO Connected all trees
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 01 : 13[4b000] -> 14[ca000] via P2P/IPC/read
 50: hkn0417:2292055:2292170 [2] NCCL INFO Channel 01 : 50[ca000] -> 51[e3000] via P2P/IPC/read
 39: hkn0413:2391070:2391199 [3] NCCL INFO Connected all trees
261: hkn0613:927098:927209 [1] NCCL INFO Channel 01 : 261[4b000] -> 262[ca000] via P2P/IPC/read
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 01 : 237[4b000] -> 238[ca000] via P2P/IPC/read
135: hkn0510:2786399:2786524 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 39: hkn0413:2391070:2391199 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 27: hkn0410:1184055:1184150 [3] NCCL INFO Connected all trees
135: hkn0510:2786399:2786524 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:941333:941464 [0] NCCL INFO Channel 00 : 256[31000] -> 257[4b000] via P2P/IPC/read
378: hkn0714:456363:456478 [2] NCCL INFO Channel 01 : 378[ca000] -> 379[e3000] via P2P/IPC/read
210: hkn0534:1172741:1172868 [2] NCCL INFO Channel 00 : 210[ca000] -> 211[e3000] via P2P/IPC/read
257: hkn0612:941317:941465 [1] NCCL INFO Channel 00 : 257[4b000] -> 258[ca000] via P2P/IPC/read
 55: hkn0418:1893549:1893663 [3] NCCL INFO Connected all trees
240: hkn0607:928741:928852 [0] NCCL INFO Channel 01 : 240[31000] -> 241[4b000] via P2P/IPC/read
 55: hkn0418:1893549:1893663 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
147: hkn0513:3037315:3037440 [3] NCCL INFO Connected all trees
 55: hkn0418:1893549:1893663 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
326: hkn0634:1545229:1545344 [2] NCCL INFO Channel 01 : 326[ca000] -> 327[e3000] via P2P/IPC/read
294: hkn0626:1322810:1322935 [2] NCCL INFO Channel 01 : 294[ca000] -> 295[e3000] via P2P/IPC/read
233: hkn0605:736560:736669 [1] NCCL INFO Channel 00 : 233[4b000] -> 234[ca000] via P2P/IPC/read
216: hkn0601:142244:142342 [0] NCCL INFO Channel 01 : 216[31000] -> 217[4b000] via P2P/IPC/read
111: hkn0504:65451:65555 [3] NCCL INFO Connected all trees
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 01 : 281[4b000] -> 282[ca000] via P2P/IPC/read
205: hkn0532:950469:950780 [1] NCCL INFO Channel 00 : 205[4b000] -> 206[ca000] via P2P/IPC/read
270: hkn0616:429406:429526 [2] NCCL INFO Connected all rings
111: hkn0504:65451:65555 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
111: hkn0504:65451:65555 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
226: hkn0603:1437603:1437704 [2] NCCL INFO Channel 00 : 226[ca000] -> 227[e3000] via P2P/IPC/read
 43: hkn0414:2006106:2006225 [3] NCCL INFO Connected all trees
 46: hkn0415:2520763:2520859 [2] NCCL INFO Channel 01 : 46[ca000] -> 47[e3000] via P2P/IPC/read
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 01 : 209[4b000] -> 210[ca000] via P2P/IPC/read
 43: hkn0414:2006106:2006225 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 43: hkn0414:2006106:2006225 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
363: hkn0710:379887:380008 [3] NCCL INFO Connected all trees
  3: hkn0403:1808445:1808808 [3] NCCL INFO Connected all trees
268: hkn0616:429398:429527 [0] NCCL INFO Channel 01 : 268[31000] -> 269[4b000] via P2P/IPC/read
  3: hkn0403:1808445:1808808 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  3: hkn0403:1808445:1808808 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
363: hkn0710:379887:380008 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
234: hkn0605:736544:736667 [2] NCCL INFO Channel 00 : 234[ca000] -> 235[e3000] via P2P/IPC/read
363: hkn0710:379887:380008 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
206: hkn0532:950453:950783 [2] NCCL INFO Channel 00 : 206[ca000] -> 207[e3000] via P2P/IPC/read
266: hkn0615:438703:438813 [2] NCCL INFO Channel 01 : 266[ca000] -> 267[e3000] via P2P/IPC/read
222: hkn0602:3390386:3390580 [2] NCCL INFO Channel 01 : 222[ca000] -> 223[e3000] via P2P/IPC/read
242: hkn0607:928725:928850 [2] NCCL INFO Connected all rings
278: hkn0621:2016125:2016216 [2] NCCL INFO Channel 01 : 278[ca000] -> 279[e3000] via P2P/IPC/read
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 01 : 225[4b000] -> 226[ca000] via P2P/IPC/read
 70: hkn0422:4177477:4177595 [2] NCCL INFO Connected all trees
323: hkn0633:1550641:1550758 [3] NCCL INFO Connected all trees
 70: hkn0422:4177477:4177595 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 35: hkn0412:2286751:2286844 [3] NCCL INFO Connected all trees
 70: hkn0422:4177477:4177595 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
323: hkn0633:1550641:1550758 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
115: hkn0505:2328163:2328258 [3] NCCL INFO Connected all trees
411: hkn0723:232580:232725 [3] NCCL INFO Connected all trees
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 00 : 17[4b000] -> 18[ca000] via P2P/IPC/read
217: hkn0601:142232:142341 [1] NCCL INFO Channel 00 : 217[4b000] -> 218[ca000] via P2P/IPC/read
115: hkn0505:2328163:2328258 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
258: hkn0612:941345:941470 [2] NCCL INFO Channel 00 : 258[ca000] -> 259[e3000] via P2P/IPC/read
115: hkn0505:2328163:2328258 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
233: hkn0605:736560:736669 [1] NCCL INFO Channel 01 : 233[4b000] -> 234[ca000] via P2P/IPC/read
435: hkn0730:1426037:1426189 [3] NCCL INFO Connected all trees
411: hkn0723:232580:232725 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
282: hkn0622:2045008:2045126 [2] NCCL INFO Channel 00 : 282[ca000] -> 283[e3000] via P2P/IPC/read
205: hkn0532:950469:950780 [1] NCCL INFO Channel 01 : 205[4b000] -> 206[ca000] via P2P/IPC/read
435: hkn0730:1426037:1426189 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
411: hkn0723:232580:232725 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
475: hkn0805:1136477:1136585 [3] NCCL INFO Connected all trees
435: hkn0730:1426037:1426189 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:941333:941464 [0] NCCL INFO Channel 01 : 256[31000] -> 257[4b000] via P2P/IPC/read
315: hkn0631:1046171:1046285 [3] NCCL INFO Connected all trees
210: hkn0534:1172741:1172868 [2] NCCL INFO Channel 01 : 210[ca000] -> 211[e3000] via P2P/IPC/read
257: hkn0612:941317:941465 [1] NCCL INFO Channel 01 : 257[4b000] -> 258[ca000] via P2P/IPC/read
319: hkn0632:1782991:1783084 [3] NCCL INFO Connected all trees
475: hkn0805:1136477:1136585 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
475: hkn0805:1136477:1136585 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
218: hkn0601:142216:142337 [2] NCCL INFO Channel 00 : 218[ca000] -> 219[e3000] via P2P/IPC/read
 18: hkn0408:2915278:2915387 [2] NCCL INFO Channel 00 : 18[ca000] -> 19[e3000] via P2P/IPC/read
319: hkn0632:1782991:1783084 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
319: hkn0632:1782991:1783084 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
315: hkn0631:1046171:1046285 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
315: hkn0631:1046171:1046285 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
290: hkn0624:1797282:1797386 [2] NCCL INFO Connected all trees
385: hkn0716:132811:132965 [1] NCCL INFO Channel 00 : 385[4b000] -> 386[ca000] via P2P/IPC/read
252: hkn0611:734178:734279 [0] NCCL INFO Channel 00 : 252[31000] -> 253[4b000] via P2P/IPC/read
290: hkn0624:1797282:1797386 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
303: hkn0628:696380:696485 [3] NCCL INFO Connected all trees
290: hkn0624:1797282:1797386 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:132819:132964 [2] NCCL INFO Channel 00 : 386[ca000] -> 387[e3000] via P2P/IPC/read
351: hkn0706:776604:776726 [3] NCCL INFO Connected all trees
443: hkn0732:1236005:1236121 [3] NCCL INFO Connected all trees
307: hkn0629:1616387:1616511 [3] NCCL INFO Connected all trees
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [receive] via NET/IBext/0
303: hkn0628:696380:696485 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
253: hkn0611:734158:734277 [1] NCCL INFO Connected all rings
307: hkn0629:1616387:1616511 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
217: hkn0601:142232:142341 [1] NCCL INFO Channel 01 : 217[4b000] -> 218[ca000] via P2P/IPC/read
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 01 : 17[4b000] -> 18[ca000] via P2P/IPC/read
307: hkn0629:1616387:1616511 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
282: hkn0622:2045008:2045126 [2] NCCL INFO Channel 01 : 282[ca000] -> 283[e3000] via P2P/IPC/read
385: hkn0716:132811:132965 [1] NCCL INFO Channel 01 : 385[4b000] -> 386[ca000] via P2P/IPC/read
303: hkn0628:696380:696485 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
351: hkn0706:776604:776726 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
234: hkn0605:736544:736667 [2] NCCL INFO Channel 01 : 234[ca000] -> 235[e3000] via P2P/IPC/read
206: hkn0532:950453:950783 [2] NCCL INFO Channel 01 : 206[ca000] -> 207[e3000] via P2P/IPC/read
351: hkn0706:776604:776726 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
226: hkn0603:1437603:1437704 [2] NCCL INFO Channel 01 : 226[ca000] -> 227[e3000] via P2P/IPC/read
443: hkn0732:1236005:1236121 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
323: hkn0633:1550641:1550758 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 54: hkn0418:1893557:1893666 [2] NCCL INFO Connected all trees
379: hkn0714:456355:456477 [3] NCCL INFO Connected all trees
 54: hkn0418:1893557:1893666 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
443: hkn0732:1236005:1236121 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 54: hkn0418:1893557:1893666 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
379: hkn0714:456355:456477 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
379: hkn0714:456355:456477 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
262: hkn0613:927118:927210 [2] NCCL INFO Channel 01 : 262[ca000] -> 263[e3000] via P2P/IPC/read
295: hkn0626:1322790:1322933 [3] NCCL INFO Connected all trees
110: hkn0504:65463:65554 [2] NCCL INFO Connected all trees
 35: hkn0412:2286751:2286844 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
407: hkn0721:2323889:2323992 [3] NCCL INFO Connected all trees
295: hkn0626:1322790:1322933 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
110: hkn0504:65463:65554 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
295: hkn0626:1322790:1322933 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 42: hkn0414:2006114:2006224 [2] NCCL INFO Connected all trees
 42: hkn0414:2006114:2006224 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
110: hkn0504:65463:65554 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 42: hkn0414:2006114:2006224 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
362: hkn0710:379915:380012 [2] NCCL INFO Connected all trees
362: hkn0710:379915:380012 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
362: hkn0710:379915:380012 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
322: hkn0633:1550649:1550756 [2] NCCL INFO Connected all trees
258: hkn0612:941345:941470 [2] NCCL INFO Channel 01 : 258[ca000] -> 259[e3000] via P2P/IPC/read
 47: hkn0415:2520751:2520864 [3] NCCL INFO Connected all trees
108: hkn0504:65435:65559 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [receive] via NET/IBext/0
 47: hkn0415:2520751:2520864 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  2: hkn0403:1808457:1808810 [2] NCCL INFO Connected all trees
279: hkn0621:2016105:2016220 [3] NCCL INFO Connected all trees
  2: hkn0403:1808457:1808810 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
218: hkn0601:142216:142337 [2] NCCL INFO Channel 01 : 218[ca000] -> 219[e3000] via P2P/IPC/read
  2: hkn0403:1808457:1808810 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 18: hkn0408:2915278:2915387 [2] NCCL INFO Channel 01 : 18[ca000] -> 19[e3000] via P2P/IPC/read
223: hkn0602:3390378:3390578 [3] NCCL INFO Connected all trees
241: hkn0607:928753:928855 [1] NCCL INFO Channel 00 : 241[4b000] -> 242[ca000] via P2P/IPC/read
223: hkn0602:3390378:3390578 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [send] via NET/IBext/0
223: hkn0602:3390378:3390578 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:379903:380006 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [send] via NET/IBext/0
269: hkn0616:429426:429521 [1] NCCL INFO Channel 00 : 269[4b000] -> 270[ca000] via P2P/IPC/read
386: hkn0716:132819:132964 [2] NCCL INFO Channel 01 : 386[ca000] -> 387[e3000] via P2P/IPC/read
410: hkn0723:232552:232722 [2] NCCL INFO Connected all trees
279: hkn0621:2016105:2016220 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
114: hkn0505:2328143:2328257 [2] NCCL INFO Connected all trees
267: hkn0615:438695:438811 [3] NCCL INFO Connected all trees
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [send] via NET/IBext/0
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [receive] via NET/IBext/0
114: hkn0505:2328143:2328257 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
267: hkn0615:438695:438811 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
114: hkn0505:2328143:2328257 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
410: hkn0723:232552:232722 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
410: hkn0723:232552:232722 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
267: hkn0615:438695:438811 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
314: hkn0631:1046179:1046288 [2] NCCL INFO Connected all trees
279: hkn0621:2016105:2016220 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
474: hkn0805:1136461:1136592 [2] NCCL INFO Connected all trees
254: hkn0611:734166:734276 [2] NCCL INFO Connected all rings
474: hkn0805:1136461:1136592 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
314: hkn0631:1046179:1046288 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
474: hkn0805:1136461:1136592 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
314: hkn0631:1046179:1046288 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
270: hkn0616:429406:429526 [2] NCCL INFO Channel 00 : 270[ca000] -> 271[e3000] via P2P/IPC/read
 47: hkn0415:2520751:2520864 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  1: hkn0403:1808437:1808809 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via P2P/IPC/read
242: hkn0607:928725:928850 [2] NCCL INFO Channel 00 : 242[ca000] -> 243[e3000] via P2P/IPC/read
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [send] via NET/IBext/0
322: hkn0633:1550649:1550756 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:232560:232720 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [send] via NET/IBext/0
322: hkn0633:1550649:1550756 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
211: hkn0534:1172757:1172866 [3] NCCL INFO Connected all trees
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [send] via NET/IBext/0
241: hkn0607:928753:928855 [1] NCCL INFO Channel 01 : 241[4b000] -> 242[ca000] via P2P/IPC/read
302: hkn0628:696364:696481 [2] NCCL INFO Connected all trees
211: hkn0534:1172757:1172866 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
263: hkn0613:927090:927213 [3] NCCL INFO Connected all trees
211: hkn0534:1172757:1172866 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
434: hkn0730:1426053:1426183 [2] NCCL INFO Connected all trees
318: hkn0632:1782963:1783087 [2] NCCL INFO Connected all trees
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [send] via NET/IBext/0
306: hkn0629:1616375:1616505 [2] NCCL INFO Connected all trees
434: hkn0730:1426053:1426183 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
318: hkn0632:1782963:1783087 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
434: hkn0730:1426053:1426183 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
318: hkn0632:1782963:1783087 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
306: hkn0629:1616375:1616505 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  1: hkn0403:1808437:1808809 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via P2P/IPC/read
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [receive] via NET/IBext/0
269: hkn0616:429426:429521 [1] NCCL INFO Channel 01 : 269[4b000] -> 270[ca000] via P2P/IPC/read
306: hkn0629:1616375:1616505 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [send] via NET/IBext/0
302: hkn0628:696364:696481 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
302: hkn0628:696364:696481 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
283: hkn0622:2045028:2045131 [3] NCCL INFO Connected all trees
283: hkn0622:2045028:2045131 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:734178:734279 [0] NCCL INFO Channel 01 : 252[31000] -> 253[4b000] via P2P/IPC/read
283: hkn0622:2045028:2045131 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
350: hkn0706:776596:776723 [2] NCCL INFO Connected all trees
227: hkn0603:1437583:1437701 [3] NCCL INFO Connected all trees
442: hkn0732:1236013:1236130 [2] NCCL INFO Connected all trees
378: hkn0714:456363:456478 [2] NCCL INFO Connected all trees
350: hkn0706:776596:776723 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
350: hkn0706:776596:776723 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
227: hkn0603:1437583:1437701 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
294: hkn0626:1322810:1322935 [2] NCCL INFO Connected all trees
378: hkn0714:456363:456478 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [send] via NET/IBext/0
378: hkn0714:456363:456478 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
294: hkn0626:1322810:1322935 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
235: hkn0605:736572:736668 [3] NCCL INFO Connected all trees
235: hkn0605:736572:736668 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
294: hkn0626:1322810:1322935 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
235: hkn0605:736572:736668 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
207: hkn0532:950461:950778 [3] NCCL INFO Connected all trees
207: hkn0532:950461:950778 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:776612:776722 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [receive] via NET/IBext/0
207: hkn0532:950461:950778 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
227: hkn0603:1437583:1437701 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
300: hkn0628:696392:696486 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [receive] via NET/IBext/0
442: hkn0732:1236013:1236130 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
442: hkn0732:1236013:1236130 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
263: hkn0613:927090:927213 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
263: hkn0613:927090:927213 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 35: hkn0412:2286751:2286844 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 34: hkn0412:2286727:2286850 [2] NCCL INFO Connected all trees
407: hkn0721:2323889:2323992 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
407: hkn0721:2323889:2323992 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 34: hkn0412:2286727:2286850 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
406: hkn0721:2323879:2323993 [2] NCCL INFO Connected all trees
376: hkn0714:456371:456476 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [send] via NET/IBext/0
 46: hkn0415:2520763:2520859 [2] NCCL INFO Connected all trees
259: hkn0612:941325:941471 [3] NCCL INFO Connected all trees
 46: hkn0415:2520763:2520859 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [receive] via NET/IBext/0
 46: hkn0415:2520763:2520859 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
270: hkn0616:429406:429526 [2] NCCL INFO Channel 01 : 270[ca000] -> 271[e3000] via P2P/IPC/read
259: hkn0612:941325:941471 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
222: hkn0602:3390386:3390580 [2] NCCL INFO Connected all trees
259: hkn0612:941325:941471 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [send] via NET/IBext/0
 34: hkn0412:2286727:2286850 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3390386:3390580 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
242: hkn0607:928725:928850 [2] NCCL INFO Channel 01 : 242[ca000] -> 243[e3000] via P2P/IPC/read
222: hkn0602:3390386:3390580 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [receive] via NET/IBext/0
219: hkn0601:142224:142344 [3] NCCL INFO Connected all trees
278: hkn0621:2016125:2016216 [2] NCCL INFO Connected all trees
 19: hkn0408:2915270:2915393 [3] NCCL INFO Connected all trees
 69: hkn0422:4177485:4177589 [1] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [receive] via NET/IBext/0
 19: hkn0408:2915270:2915393 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
219: hkn0601:142224:142344 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 19: hkn0408:2915270:2915393 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [receive] via NET/IBext/0
219: hkn0601:142224:142344 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
266: hkn0615:438703:438813 [2] NCCL INFO Connected all trees
387: hkn0716:132839:132970 [3] NCCL INFO Connected all trees
278: hkn0621:2016125:2016216 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
266: hkn0615:438703:438813 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
278: hkn0621:2016125:2016216 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
266: hkn0615:438703:438813 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
387: hkn0716:132839:132970 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [receive] via NET/IBext/0
264: hkn0615:438687:438806 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [send] via NET/IBext/0
387: hkn0716:132839:132970 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
262: hkn0613:927118:927210 [2] NCCL INFO Connected all trees
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [send] via NET/IBext/0
406: hkn0721:2323879:2323993 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
262: hkn0613:927118:927210 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
406: hkn0721:2323879:2323993 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
262: hkn0613:927118:927210 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [receive] via NET/IBext/0
299: hkn0627:1812294:1812419 [3] NCCL INFO Connected all trees
371: hkn0712:319428:319537 [3] NCCL INFO Connected all trees
210: hkn0534:1172741:1172868 [2] NCCL INFO Connected all trees
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 01 : 284[31000] -> 285[4b000] via P2P/IPC/read
299: hkn0627:1812294:1812419 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
371: hkn0712:319428:319537 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
210: hkn0534:1172741:1172868 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
299: hkn0627:1812294:1812419 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
210: hkn0534:1172741:1172868 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
298: hkn0627:1812322:1812413 [2] NCCL INFO Connected all trees
298: hkn0627:1812322:1812413 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
371: hkn0712:319428:319537 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
298: hkn0627:1812322:1812413 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
370: hkn0712:319448:319543 [2] NCCL INFO Connected all trees
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [send] via NET/IBext/0
370: hkn0712:319448:319543 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
370: hkn0712:319448:319543 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
286: hkn0623:1897143:1897243 [2] NCCL INFO Connected all rings
368: hkn0712:319436:319546 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [send] via NET/IBext/0
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 00 : 285[4b000] -> 286[ca000] via P2P/IPC/read
253: hkn0611:734158:734277 [1] NCCL INFO Channel 00 : 253[4b000] -> 254[ca000] via P2P/IPC/read
286: hkn0623:1897143:1897243 [2] NCCL INFO Channel 00 : 286[ca000] -> 287[e3000] via P2P/IPC/read
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 01 : 285[4b000] -> 286[ca000] via P2P/IPC/read
238: hkn0606:2396571:2396682 [2] NCCL INFO Channel 01 : 238[ca000] -> 239[e3000] via P2P/IPC/read
286: hkn0623:1897143:1897243 [2] NCCL INFO Channel 01 : 286[ca000] -> 287[e3000] via P2P/IPC/read
143: hkn0512:3068470:3068579 [3] NCCL INFO Connected all trees
282: hkn0622:2045008:2045126 [2] NCCL INFO Connected all trees
282: hkn0622:2045008:2045126 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
226: hkn0603:1437603:1437704 [2] NCCL INFO Connected all trees
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [send] via NET/IBext/0
260: hkn0613:927106:927208 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [receive] via NET/IBext/0
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [send] via NET/IBext/0
282: hkn0622:2045008:2045126 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
226: hkn0603:1437603:1437704 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
239: hkn0606:2396563:2396679 [3] NCCL INFO Connected all trees
226: hkn0603:1437603:1437704 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
239: hkn0606:2396563:2396679 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
206: hkn0532:950453:950783 [2] NCCL INFO Connected all trees
239: hkn0606:2396563:2396679 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [send] via NET/IBext/0
238: hkn0606:2396571:2396682 [2] NCCL INFO Connected all trees
234: hkn0605:736544:736667 [2] NCCL INFO Connected all trees
206: hkn0532:950453:950783 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
234: hkn0605:736544:736667 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
206: hkn0532:950453:950783 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
234: hkn0605:736544:736667 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:734166:734276 [2] NCCL INFO Channel 00 : 254[ca000] -> 255[e3000] via P2P/IPC/read
109: hkn0504:65443:65560 [1] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [send] via NET/IBext/0
238: hkn0606:2396571:2396682 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 53: hkn0418:1893541:1893660 [1] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [receive] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [send] via NET/IBext/0
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [send] via NET/IBext/0
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [receive] via NET/IBext/0
238: hkn0606:2396571:2396682 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
143: hkn0512:3068470:3068579 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [receive] via NET/IBext/0
143: hkn0512:3068470:3068579 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [receive] via NET/IBext/0
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [receive] via NET/IBext/0
361: hkn0710:379895:380014 [1] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [receive] via NET/IBext/0
369: hkn0712:319420:319542 [1] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [receive] via NET/IBext/0
258: hkn0612:941345:941470 [2] NCCL INFO Connected all trees
142: hkn0512:3068454:3068574 [2] NCCL INFO Connected all trees
142: hkn0512:3068454:3068574 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [receive] via NET/IBext/0
142: hkn0512:3068454:3068574 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
258: hkn0612:941345:941470 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [receive] via NET/IBext/0
232: hkn0605:736552:736663 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [send] via NET/IBext/0
258: hkn0612:941345:941470 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:734158:734277 [1] NCCL INFO Channel 01 : 253[4b000] -> 254[ca000] via P2P/IPC/read
214: hkn0535:2423350:2423446 [2] NCCL INFO Channel 00 : 214[ca000] -> 215[e3000] via P2P/IPC/read
218: hkn0601:142216:142337 [2] NCCL INFO Connected all trees
248: hkn0609:735146:735265 [0] NCCL INFO Channel 01 : 248[31000] -> 249[4b000] via P2P/IPC/read
218: hkn0601:142216:142337 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
213: hkn0535:2423328:2423441 [1] NCCL INFO Channel 01 : 213[4b000] -> 214[ca000] via P2P/IPC/read
 18: hkn0408:2915278:2915387 [2] NCCL INFO Connected all trees
218: hkn0601:142216:142337 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 18: hkn0408:2915278:2915387 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
243: hkn0607:928733:928851 [3] NCCL INFO Connected all trees
 18: hkn0408:2915278:2915387 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:950481:950779 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [receive] via NET/IBext/0
409: hkn0723:232568:232721 [1] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [receive] via NET/IBext/0
243: hkn0607:928733:928851 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [receive] via NET/IBext/0
256: hkn0612:941333:941464 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [send] via NET/IBext/0
271: hkn0616:429414:429520 [3] NCCL INFO Connected all trees
243: hkn0607:928733:928851 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:132819:132964 [2] NCCL INFO Connected all trees
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [receive] via NET/IBext/0
271: hkn0616:429414:429520 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [receive] via NET/IBext/0
271: hkn0616:429414:429520 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:132819:132964 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [send] via NET/IBext/0
386: hkn0716:132819:132964 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2323871:2323991 [1] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [receive] via NET/IBext/0
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [send] via NET/IBext/0
214: hkn0535:2423350:2423446 [2] NCCL INFO Channel 01 : 214[ca000] -> 215[e3000] via P2P/IPC/read
249: hkn0609:735138:735259 [1] NCCL INFO Channel 00 : 249[4b000] -> 250[ca000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [send] via NET/IBext/0
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [receive] via NET/IBext/0
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [receive] via NET/IBext/0
215: hkn0535:2423320:2423450 [3] NCCL INFO Connected all trees
384: hkn0716:132827:132967 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [send] via NET/IBext/0
287: hkn0623:1897155:1897246 [3] NCCL INFO Connected all trees
215: hkn0535:2423320:2423450 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
250: hkn0609:735166:735258 [2] NCCL INFO Channel 00 : 250[ca000] -> 251[e3000] via P2P/IPC/read
287: hkn0623:1897155:1897246 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
215: hkn0535:2423320:2423450 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:734166:734276 [2] NCCL INFO Channel 01 : 254[ca000] -> 255[e3000] via P2P/IPC/read
287: hkn0623:1897155:1897246 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
301: hkn0628:696372:696489 [1] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [send] via NET/IBext/0
214: hkn0535:2423350:2423446 [2] NCCL INFO Connected all trees
214: hkn0535:2423350:2423446 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:735138:735259 [1] NCCL INFO Channel 01 : 249[4b000] -> 250[ca000] via P2P/IPC/read
214: hkn0535:2423350:2423446 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
250: hkn0609:735166:735258 [2] NCCL INFO Channel 01 : 250[ca000] -> 251[e3000] via P2P/IPC/read
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [receive] via NET/IBext/0
251: hkn0609:735154:735263 [3] NCCL INFO Connected all trees
251: hkn0609:735154:735263 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
147: hkn0513:3037315:3037440 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
251: hkn0609:735154:735263 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
147: hkn0513:3037315:3037440 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
250: hkn0609:735166:735258 [2] NCCL INFO Connected all trees
146: hkn0513:3037323:3037444 [2] NCCL INFO Connected all trees
327: hkn0634:1545249:1545346 [3] NCCL INFO Connected all trees
 27: hkn0410:1184055:1184150 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [receive] via NET/IBext/0
250: hkn0609:735166:735258 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
349: hkn0706:776624:776729 [1] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [send] via NET/IBext/0
250: hkn0609:735166:735258 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
216: hkn0601:142244:142342 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [send] via NET/IBext/0
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [receive] via NET/IBext/0
146: hkn0513:3037323:3037444 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
327: hkn0634:1545249:1545346 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
146: hkn0513:3037323:3037444 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
327: hkn0634:1545249:1545346 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [send] via NET/IBext/0
326: hkn0634:1545229:1545344 [2] NCCL INFO Connected all trees
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [receive] via NET/IBext/0
326: hkn0634:1545229:1545344 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
326: hkn0634:1545229:1545344 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 27: hkn0410:1184055:1184150 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [receive] via NET/IBext/0
 26: hkn0410:1184027:1184146 [2] NCCL INFO Connected all trees
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [send] via NET/IBext/0
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 01 : 156[31000] -> 157[4b000] via P2P/IPC/read
 26: hkn0410:1184027:1184146 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
230: hkn0604:713539:713662 [2] NCCL INFO Channel 01 : 230[ca000] -> 231[e3000] via P2P/IPC/read
 26: hkn0410:1184027:1184146 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 00 : 157[4b000] -> 158[ca000] via P2P/IPC/read
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [send] via NET/IBext/0
158: hkn0516:2940330:2940431 [2] NCCL INFO Channel 00 : 158[ca000] -> 159[e3000] via P2P/IPC/read
265: hkn0615:438714:438810 [1] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [receive] via NET/IBext/0
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [receive] via NET/IBext/0
293: hkn0626:1322798:1322932 [1] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [receive] via NET/IBext/0
277: hkn0621:2016097:2016215 [1] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [receive] via NET/IBext/0
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 01 : 157[4b000] -> 158[ca000] via P2P/IPC/read
231: hkn0604:713531:713661 [3] NCCL INFO Connected all trees
377: hkn0714:456383:456480 [1] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [receive] via NET/IBext/0
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [send] via NET/IBext/0
158: hkn0516:2940330:2940431 [2] NCCL INFO Channel 01 : 158[ca000] -> 159[e3000] via P2P/IPC/read
231: hkn0604:713531:713661 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [send] via NET/IBext/0
159: hkn0516:2940322:2940429 [3] NCCL INFO Connected all trees
360: hkn0710:379903:380006 [0] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [send] via NET/IBext/0
159: hkn0516:2940322:2940429 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1545237:1545343 [1] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [receive] via NET/IBext/0
159: hkn0516:2940322:2940429 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
158: hkn0516:2940330:2940431 [2] NCCL INFO Connected all trees
231: hkn0604:713531:713661 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [send] via NET/IBext/0
158: hkn0516:2940330:2940431 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
158: hkn0516:2940330:2940431 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
230: hkn0604:713539:713662 [2] NCCL INFO Connected all trees
230: hkn0604:713539:713662 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
123: hkn0507:3211443:3211567 [3] NCCL INFO Connected all trees
242: hkn0607:928725:928850 [2] NCCL INFO Connected all trees
248: hkn0609:735146:735265 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [send] via NET/IBext/0
242: hkn0607:928725:928850 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
230: hkn0604:713539:713662 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
242: hkn0607:928725:928850 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:713559:713655 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [receive] via NET/IBext/0
229: hkn0604:713547:713656 [1] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [receive] via NET/IBext/0
123: hkn0507:3211443:3211567 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
123: hkn0507:3211443:3211567 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
134: hkn0510:2786427:2786528 [2] NCCL INFO Connected all trees
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [send] via NET/IBext/0
122: hkn0507:3211459:3211565 [2] NCCL INFO Connected all trees
122: hkn0507:3211459:3211565 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
134: hkn0510:2786427:2786528 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
270: hkn0616:429406:429526 [2] NCCL INFO Connected all trees
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [send] via NET/IBext/0
122: hkn0507:3211459:3211565 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
134: hkn0510:2786427:2786528 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
270: hkn0616:429406:429526 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [send] via NET/IBext/0
270: hkn0616:429406:429526 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [receive] via NET/IBext/0
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [receive] via NET/IBext/0
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [receive] via NET/IBext/0
240: hkn0607:928741:928852 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [send] via NET/IBext/0
133: hkn0510:2786407:2786523 [1] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [receive] via NET/IBext/0
261: hkn0613:927098:927209 [1] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [receive] via NET/IBext/0
 14: hkn0407:1840633:1840731 [2] NCCL INFO Channel 01 : 14[ca000] -> 15[e3000] via P2P/IPC/read
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [receive] via NET/IBext/0
 51: hkn0417:2292063:2292173 [3] NCCL INFO Connected all trees
 15: hkn0407:1840605:1840730 [3] NCCL INFO Connected all trees
 39: hkn0413:2391070:2391199 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1840605:1840730 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 51: hkn0417:2292063:2292173 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
286: hkn0623:1897143:1897243 [2] NCCL INFO Connected all trees
 15: hkn0407:1840605:1840730 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 14: hkn0407:1840633:1840731 [2] NCCL INFO Connected all trees
 51: hkn0417:2292063:2292173 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [receive] via NET/IBext/0
286: hkn0623:1897143:1897243 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
268: hkn0616:429398:429527 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [receive] via NET/IBext/0
286: hkn0623:1897143:1897243 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [receive] via NET/IBext/0
 14: hkn0407:1840633:1840731 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 14: hkn0407:1840633:1840731 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 50: hkn0417:2292055:2292170 [2] NCCL INFO Connected all trees
213: hkn0535:2423328:2423441 [1] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [receive] via NET/IBext/0
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [receive] via NET/IBext/0
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [send] via NET/IBext/0
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [send] via NET/IBext/0
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [send] via NET/IBext/0
 50: hkn0417:2292055:2292170 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
255: hkn0611:734150:734278 [3] NCCL INFO Connected all trees
 50: hkn0417:2292055:2292170 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [receive] via NET/IBext/0
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [send] via NET/IBext/0
255: hkn0611:734150:734278 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [receive] via NET/IBext/0
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [receive] via NET/IBext/0
255: hkn0611:734150:734278 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [receive] via NET/IBext/0
 38: hkn0413:2391078:2391198 [2] NCCL INFO Connected all trees
446: hkn0733:1413719:1413842 [2] NCCL INFO Channel 01 : 446[ca000] -> 447[e3000] via P2P/IPC/read
338: hkn0703:765558:765658 [2] NCCL INFO Channel 01 : 338[ca000] -> 339[e3000] via P2P/IPC/read
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [send] via NET/IBext/0
 38: hkn0413:2391078:2391198 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [receive] via NET/IBext/0
 38: hkn0413:2391078:2391198 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [receive] via NET/IBext/0
447: hkn0733:1413735:1413846 [3] NCCL INFO Connected all trees
 37: hkn0413:2391086:2391193 [1] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [receive] via NET/IBext/0
447: hkn0733:1413735:1413846 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [send] via NET/IBext/0
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [send] via NET/IBext/0
447: hkn0733:1413735:1413846 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
339: hkn0703:765530:765656 [3] NCCL INFO Connected all trees
205: hkn0532:950469:950780 [1] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [send] via NET/IBext/0
446: hkn0733:1413719:1413842 [2] NCCL INFO Connected all trees
446: hkn0733:1413719:1413842 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:232560:232720 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [receive] via NET/IBext/0
446: hkn0733:1413719:1413842 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [send] via NET/IBext/0
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [receive] via NET/IBext/0
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [send] via NET/IBext/0
376: hkn0714:456371:456476 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [receive] via NET/IBext/0
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [send] via NET/IBext/0
339: hkn0703:765530:765656 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
233: hkn0605:736560:736669 [1] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [receive] via NET/IBext/0
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [receive] via NET/IBext/0
339: hkn0703:765530:765656 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
194: hkn0529:1565143:1565270 [2] NCCL INFO Channel 00 : 194[ca000] -> 195[e3000] via P2P/IPC/read
338: hkn0703:765558:765658 [2] NCCL INFO Connected all trees
 62: hkn0420:3234575:3234691 [2] NCCL INFO Connected all trees
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [receive] via NET/IBext/0
338: hkn0703:765558:765658 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [receive] via NET/IBext/0
338: hkn0703:765558:765658 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
336: hkn0703:765538:765661 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [send] via NET/IBext/0
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 01 : 193[4b000] -> 194[ca000] via P2P/IPC/read
337: hkn0703:765546:765657 [1] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [receive] via NET/IBext/0
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 01 : 192[31000] -> 193[4b000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [send] via NET/IBext/0
194: hkn0529:1565143:1565270 [2] NCCL INFO Channel 01 : 194[ca000] -> 195[e3000] via P2P/IPC/read
195: hkn0529:1565159:1565265 [3] NCCL INFO Connected all trees
 62: hkn0420:3234575:3234691 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:941317:941465 [1] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [receive] via NET/IBext/0
217: hkn0601:142232:142341 [1] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [receive] via NET/IBext/0
195: hkn0529:1565159:1565265 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 62: hkn0420:3234575:3234691 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
195: hkn0529:1565159:1565265 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [receive] via NET/IBext/0
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [receive] via NET/IBext/0
194: hkn0529:1565143:1565270 [2] NCCL INFO Connected all trees
194: hkn0529:1565143:1565270 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
194: hkn0529:1565143:1565270 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [send] via NET/IBext/0
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [send] via NET/IBext/0
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [send] via NET/IBext/0
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [receive] via NET/IBext/0
385: hkn0716:132811:132965 [1] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [receive] via NET/IBext/0
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [receive] via NET/IBext/0
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [receive] via NET/IBext/0
182: hkn0526:1452774:1452881 [2] NCCL INFO Channel 00 : 182[ca000] -> 183[e3000] via P2P/IPC/read
437: hkn0731:1411116:1411213 [1] NCCL INFO Channel 00 : 437[4b000] -> 438[ca000] via P2P/IPC/read
  5: hkn0404:1363874:1363976 [1] NCCL INFO Channel 00 : 5[4b000] -> 6[ca000] via P2P/IPC/read
367: hkn0711:608376:608500 [3] NCCL INFO Connected all trees
181: hkn0526:1452758:1452883 [1] NCCL INFO Channel 01 : 181[4b000] -> 182[ca000] via P2P/IPC/read
438: hkn0731:1411096:1411207 [2] NCCL INFO Channel 00 : 438[ca000] -> 439[e3000] via P2P/IPC/read
182: hkn0526:1452774:1452881 [2] NCCL INFO Channel 01 : 182[ca000] -> 183[e3000] via P2P/IPC/read
437: hkn0731:1411116:1411213 [1] NCCL INFO Channel 01 : 437[4b000] -> 438[ca000] via P2P/IPC/read
249: hkn0609:735138:735259 [1] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [receive] via NET/IBext/0
183: hkn0526:1452786:1452878 [3] NCCL INFO Connected all trees
183: hkn0526:1452786:1452878 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
438: hkn0731:1411096:1411207 [2] NCCL INFO Channel 01 : 438[ca000] -> 439[e3000] via P2P/IPC/read
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [send] via NET/IBext/0
183: hkn0526:1452786:1452878 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
182: hkn0526:1452774:1452881 [2] NCCL INFO Connected all trees
439: hkn0731:1411104:1411206 [3] NCCL INFO Connected all trees
300: hkn0628:696392:696486 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [receive] via NET/IBext/0
182: hkn0526:1452774:1452881 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
182: hkn0526:1452774:1452881 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
439: hkn0731:1411104:1411206 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [receive] via NET/IBext/0
439: hkn0731:1411104:1411206 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1452758:1452883 [1] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [receive] via NET/IBext/0
438: hkn0731:1411096:1411207 [2] NCCL INFO Connected all trees
368: hkn0712:319436:319546 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [send] via NET/IBext/0
438: hkn0731:1411096:1411207 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
438: hkn0731:1411096:1411207 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1363846:1363970 [2] NCCL INFO Channel 00 : 6[ca000] -> 7[e3000] via P2P/IPC/read
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [receive] via NET/IBext/0
  5: hkn0404:1363874:1363976 [1] NCCL INFO Channel 01 : 5[4b000] -> 6[ca000] via P2P/IPC/read
437: hkn0731:1411116:1411213 [1] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [receive] via NET/IBext/0
  6: hkn0404:1363846:1363970 [2] NCCL INFO Channel 01 : 6[ca000] -> 7[e3000] via P2P/IPC/read
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [send] via NET/IBext/0
  7: hkn0404:1363854:1363975 [3] NCCL INFO Connected all trees
348: hkn0706:776612:776722 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [receive] via NET/IBext/0
  7: hkn0404:1363854:1363975 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [send] via NET/IBext/0
  7: hkn0404:1363854:1363975 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:734166:734276 [2] NCCL INFO Connected all trees
  6: hkn0404:1363846:1363970 [2] NCCL INFO Connected all trees
  6: hkn0404:1363846:1363970 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [receive] via NET/IBext/0
  6: hkn0404:1363846:1363970 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:734166:734276 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [receive] via NET/IBext/0
254: hkn0611:734166:734276 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  5: hkn0404:1363874:1363976 [1] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [receive] via NET/IBext/0
367: hkn0711:608376:608500 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
174: hkn0524:1158156:1158250 [2] NCCL INFO Channel 00 : 174[ca000] -> 175[e3000] via P2P/IPC/read
367: hkn0711:608376:608500 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 79: hkn0424:2972333:2972431 [3] NCCL INFO Connected all trees
 79: hkn0424:2972333:2972431 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [send] via NET/IBext/0
366: hkn0711:608384:608505 [2] NCCL INFO Connected all trees
366: hkn0711:608384:608505 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 01 : 173[4b000] -> 174[ca000] via P2P/IPC/read
366: hkn0711:608384:608505 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
174: hkn0524:1158156:1158250 [2] NCCL INFO Channel 01 : 174[ca000] -> 175[e3000] via P2P/IPC/read
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [send] via NET/IBext/0
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [receive] via NET/IBext/0
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [send] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [receive] via NET/IBext/0
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [send] via NET/IBext/0
365: hkn0711:608392:608506 [1] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [send] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [receive] via NET/IBext/0
175: hkn0524:1158128:1158251 [3] NCCL INFO Connected all trees
175: hkn0524:1158128:1158251 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 79: hkn0424:2972333:2972431 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [send] via NET/IBext/0
252: hkn0611:734178:734279 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [receive] via NET/IBext/0
232: hkn0605:736552:736663 [0] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [send] via NET/IBext/0
175: hkn0524:1158128:1158251 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
174: hkn0524:1158156:1158250 [2] NCCL INFO Connected all trees
343: hkn0704:816334:816453 [3] NCCL INFO Connected all trees
256: hkn0612:941333:941464 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [send] via NET/IBext/0
174: hkn0524:1158156:1158250 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [receive] via NET/IBext/0
174: hkn0524:1158156:1158250 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [receive] via NET/IBext/0
343: hkn0704:816334:816453 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [send] via NET/IBext/0
343: hkn0704:816334:816453 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [receive] via NET/IBext/0
 78: hkn0424:2972321:2972426 [2] NCCL INFO Connected all trees
 78: hkn0424:2972321:2972426 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
342: hkn0704:816326:816455 [2] NCCL INFO Connected all trees
 78: hkn0424:2972321:2972426 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
342: hkn0704:816326:816455 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [receive] via NET/IBext/0
342: hkn0704:816326:816455 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
108: hkn0504:65435:65559 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [receive] via NET/IBext/0
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [send] via NET/IBext/0
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [receive] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [receive] via NET/IBext/0
341: hkn0704:816354:816450 [1] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [receive] via NET/IBext/0
330: hkn0635:1249906:1250023 [2] NCCL INFO Channel 00 : 330[ca000] -> 331[e3000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [send] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [send] via NET/IBext/0
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 01 : 329[4b000] -> 330[ca000] via P2P/IPC/read
355: hkn0707:4044292:4044419 [3] NCCL INFO Connected all trees
330: hkn0635:1249906:1250023 [2] NCCL INFO Channel 01 : 330[ca000] -> 331[e3000] via P2P/IPC/read
 66: hkn0421:2208703:2208881 [2] NCCL INFO Connected all trees
384: hkn0716:132827:132967 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [send] via NET/IBext/0
331: hkn0635:1249914:1250018 [3] NCCL INFO Connected all trees
331: hkn0635:1249914:1250018 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
355: hkn0707:4044292:4044419 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
241: hkn0607:928753:928855 [1] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [receive] via NET/IBext/0
331: hkn0635:1249914:1250018 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
330: hkn0635:1249906:1250023 [2] NCCL INFO Connected all trees
355: hkn0707:4044292:4044419 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
330: hkn0635:1249906:1250023 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
354: hkn0707:4044308:4044418 [2] NCCL INFO Connected all trees
330: hkn0635:1249906:1250023 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
354: hkn0707:4044308:4044418 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [send] via NET/IBext/0
354: hkn0707:4044308:4044418 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [receive] via NET/IBext/0
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [send] via NET/IBext/0
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [send] via NET/IBext/0
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [receive] via NET/IBext/0
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [send] via NET/IBext/0
 66: hkn0421:2208703:2208881 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [send] via NET/IBext/0
 66: hkn0421:2208703:2208881 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [send] via NET/IBext/0
162: hkn0520:2737243:2737371 [2] NCCL INFO Channel 01 : 162[ca000] -> 163[e3000] via P2P/IPC/read
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [send] via NET/IBext/0
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [receive] via NET/IBext/0
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [send] via NET/IBext/0
163: hkn0520:2737223:2737364 [3] NCCL INFO Connected all trees
163: hkn0520:2737223:2737364 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
103: hkn0502:253410:253517 [3] NCCL INFO Connected all trees
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [send] via NET/IBext/0
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [receive] via NET/IBext/0
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [send] via NET/IBext/0
163: hkn0520:2737223:2737364 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 01 : 160[31000] -> 161[4b000] via P2P/IPC/read
103: hkn0502:253410:253517 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
162: hkn0520:2737243:2737371 [2] NCCL INFO Connected all trees
103: hkn0502:253410:253517 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
162: hkn0520:2737243:2737371 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
102: hkn0502:253394:253516 [2] NCCL INFO Connected all trees
102: hkn0502:253394:253516 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
216: hkn0601:142244:142342 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [receive] via NET/IBext/0
228: hkn0604:713559:713655 [0] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [send] via NET/IBext/0
204: hkn0532:950481:950779 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [receive] via NET/IBext/0
260: hkn0613:927106:927208 [0] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [send] via NET/IBext/0
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [send] via NET/IBext/0
162: hkn0520:2737243:2737371 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [receive] via NET/IBext/0
102: hkn0502:253394:253516 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:379903:380006 [0] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [receive] via NET/IBext/0
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [send] via NET/IBext/0
100: hkn0502:253422:253519 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [receive] via NET/IBext/0
 31: hkn0411:2340265:2340393 [3] NCCL INFO Connected all trees
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [receive] via NET/IBext/0
101: hkn0502:253402:253515 [1] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [receive] via NET/IBext/0
100: hkn0502:253422:253519 [0] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [send] via NET/IBext/0
 31: hkn0411:2340265:2340393 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 31: hkn0411:2340265:2340393 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
126: hkn0508:3163478:3163601 [2] NCCL INFO Channel 01 : 126[ca000] -> 127[e3000] via P2P/IPC/read
 30: hkn0411:2340293:2340389 [2] NCCL INFO Connected all trees
 91: hkn0427:1159506:1159619 [3] NCCL INFO Connected all trees
 91: hkn0427:1159506:1159619 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 30: hkn0411:2340293:2340389 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
127: hkn0508:3163486:3163600 [3] NCCL INFO Connected all trees
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [send] via NET/IBext/0
 30: hkn0411:2340293:2340389 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [receive] via NET/IBext/0
127: hkn0508:3163486:3163600 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [send] via NET/IBext/0
127: hkn0508:3163486:3163600 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [receive] via NET/IBext/0
126: hkn0508:3163478:3163601 [2] NCCL INFO Connected all trees
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [send] via NET/IBext/0
126: hkn0508:3163478:3163601 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
126: hkn0508:3163478:3163601 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 91: hkn0427:1159506:1159619 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [send] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [receive] via NET/IBext/0
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [send] via NET/IBext/0
 90: hkn0427:1159498:1159622 [2] NCCL INFO Connected all trees
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [receive] via NET/IBext/0
 90: hkn0427:1159498:1159622 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 90: hkn0427:1159498:1159622 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
462: hkn0802:1224692:1224849 [2] NCCL INFO Connected all rings
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [send] via NET/IBext/0
244: hkn0608:510064:510177 [0] NCCL INFO Channel 00 : 244[31000] -> 245[4b000] via P2P/IPC/read
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [receive] via NET/IBext/0
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 01 : 460[31000] -> 461[4b000] via P2P/IPC/read
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [receive] via NET/IBext/0
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 00 : 461[4b000] -> 462[ca000] via P2P/IPC/read
269: hkn0616:429426:429521 [1] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [send] via NET/IBext/0
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [send] via NET/IBext/0
462: hkn0802:1224692:1224849 [2] NCCL INFO Channel 00 : 462[ca000] -> 463[e3000] via P2P/IPC/read
245: hkn0608:510084:510183 [1] NCCL INFO Channel 00 : 245[4b000] -> 246[ca000] via P2P/IPC/read
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 01 : 461[4b000] -> 462[ca000] via P2P/IPC/read
244: hkn0608:510064:510177 [0] NCCL INFO Channel 01 : 244[31000] -> 245[4b000] via P2P/IPC/read
462: hkn0802:1224692:1224849 [2] NCCL INFO Channel 01 : 462[ca000] -> 463[e3000] via P2P/IPC/read
245: hkn0608:510084:510183 [1] NCCL INFO Channel 01 : 245[4b000] -> 246[ca000] via P2P/IPC/read
463: hkn0802:1224700:1224850 [3] NCCL INFO Connected all trees
246: hkn0608:510072:510180 [2] NCCL INFO Channel 00 : 246[ca000] -> 247[e3000] via P2P/IPC/read
240: hkn0607:928741:928852 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [send] via NET/IBext/0
463: hkn0802:1224700:1224850 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
463: hkn0802:1224700:1224850 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
246: hkn0608:510072:510180 [2] NCCL INFO Channel 01 : 246[ca000] -> 247[e3000] via P2P/IPC/read
462: hkn0802:1224692:1224849 [2] NCCL INFO Connected all trees
247: hkn0608:510056:510185 [3] NCCL INFO Connected all trees
462: hkn0802:1224692:1224849 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
247: hkn0608:510056:510185 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [receive] via NET/IBext/0
462: hkn0802:1224692:1224849 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [send] via NET/IBext/0
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [receive] via NET/IBext/0
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [send] via NET/IBext/0
247: hkn0608:510056:510185 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
246: hkn0608:510072:510180 [2] NCCL INFO Connected all trees
151: hkn0514:2975071:2975199 [3] NCCL INFO Connected all trees
246: hkn0608:510072:510180 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
139: hkn0511:3090869:3090995 [3] NCCL INFO Connected all trees
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [receive] via NET/IBext/0
264: hkn0615:438687:438806 [0] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [send] via NET/IBext/0
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [send] via NET/IBext/0
246: hkn0608:510072:510180 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
244: hkn0608:510064:510177 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [receive] via NET/IBext/0
151: hkn0514:2975071:2975199 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:510084:510183 [1] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [receive] via NET/IBext/0
151: hkn0514:2975071:2975199 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
150: hkn0514:2975099:2975195 [2] NCCL INFO Connected all trees
139: hkn0511:3090869:3090995 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
150: hkn0514:2975099:2975195 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
139: hkn0511:3090869:3090995 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
150: hkn0514:2975099:2975195 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
138: hkn0511:3090897:3090992 [2] NCCL INFO Connected all trees
138: hkn0511:3090897:3090992 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [receive] via NET/IBext/0
138: hkn0511:3090897:3090992 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [receive] via NET/IBext/0
149: hkn0514:2975087:2975198 [1] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [receive] via NET/IBext/0
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [send] via NET/IBext/0
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [send] via NET/IBext/0
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [receive] via NET/IBext/0
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [send] via NET/IBext/0
369: hkn0712:319420:319542 [1] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [send] via NET/IBext/0
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [send] via NET/IBext/0
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [receive] via NET/IBext/0
197: hkn0530:1282466:1282581 [1] NCCL INFO Channel 00 : 197[4b000] -> 198[ca000] via P2P/IPC/read
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [receive] via NET/IBext/0
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [send] via NET/IBext/0
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [receive] via NET/IBext/0
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [receive] via NET/IBext/0
198: hkn0530:1282474:1282589 [2] NCCL INFO Channel 00 : 198[ca000] -> 199[e3000] via P2P/IPC/read
511: hkn0816:399934:400048 [3] NCCL INFO Connected all trees
197: hkn0530:1282466:1282581 [1] NCCL INFO Channel 01 : 197[4b000] -> 198[ca000] via P2P/IPC/read
426: hkn0727:1370159:1370281 [2] NCCL INFO Channel 00 : 426[ca000] -> 427[e3000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [send] via NET/IBext/0
198: hkn0530:1282474:1282589 [2] NCCL INFO Channel 01 : 198[ca000] -> 199[e3000] via P2P/IPC/read
199: hkn0530:1282494:1282588 [3] NCCL INFO Connected all trees
511: hkn0816:399934:400048 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
199: hkn0530:1282494:1282588 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
511: hkn0816:399934:400048 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
199: hkn0530:1282494:1282588 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
510: hkn0816:399918:400045 [2] NCCL INFO Connected all trees
510: hkn0816:399918:400045 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
198: hkn0530:1282474:1282589 [2] NCCL INFO Connected all trees
510: hkn0816:399918:400045 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
198: hkn0530:1282474:1282589 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
508: hkn0816:399946:400046 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [receive] via NET/IBext/0
198: hkn0530:1282474:1282589 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
509: hkn0816:399926:400042 [1] NCCL INFO Channel 00 : 509[4b000] -> 508[31000] via P2P/IPC/read
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [receive] via NET/IBext/0
509: hkn0816:399926:400042 [1] NCCL INFO Channel 01 : 509[4b000] -> 508[31000] via P2P/IPC/read
197: hkn0530:1282466:1282581 [1] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [receive] via NET/IBext/0
508: hkn0816:399946:400046 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [receive] via NET/IBext/0
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [send] via NET/IBext/0
508: hkn0816:399946:400046 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [send] via NET/IBext/0
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [receive] via NET/IBext/0
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 00 : 425[4b000] -> 426[ca000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [receive] via NET/IBext/0
426: hkn0727:1370159:1370281 [2] NCCL INFO Channel 01 : 426[ca000] -> 427[e3000] via P2P/IPC/read
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 01 : 425[4b000] -> 426[ca000] via P2P/IPC/read
400: hkn0720:33752:33908 [0] NCCL INFO Channel 01 : 400[31000] -> 401[4b000] via P2P/IPC/read
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [receive] via NET/IBext/0
427: hkn0727:1370167:1370284 [3] NCCL INFO Connected all trees
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [send] via NET/IBext/0
427: hkn0727:1370167:1370284 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
427: hkn0727:1370167:1370284 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:33760:33906 [1] NCCL INFO Channel 00 : 401[4b000] -> 402[ca000] via P2P/IPC/read
340: hkn0704:816342:816447 [0] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [receive] via NET/IBext/0
426: hkn0727:1370159:1370281 [2] NCCL INFO Connected all trees
426: hkn0727:1370159:1370281 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [receive] via NET/IBext/0
426: hkn0727:1370159:1370281 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [send] via NET/IBext/0
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [send] via NET/IBext/0
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [receive] via NET/IBext/0
402: hkn0720:33772:33907 [2] NCCL INFO Channel 00 : 402[ca000] -> 403[e3000] via P2P/IPC/read
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [send] via NET/IBext/0
401: hkn0720:33760:33906 [1] NCCL INFO Channel 01 : 401[4b000] -> 402[ca000] via P2P/IPC/read
402: hkn0720:33772:33907 [2] NCCL INFO Channel 01 : 402[ca000] -> 403[e3000] via P2P/IPC/read
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 01 : 185[4b000] -> 186[ca000] via P2P/IPC/read
403: hkn0720:33744:33905 [3] NCCL INFO Connected all trees
451: hkn0734:1180877:1181004 [3] NCCL INFO Connected all trees
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [send] via NET/IBext/0
403: hkn0720:33744:33905 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
403: hkn0720:33744:33905 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
186: hkn0527:1373294:1373422 [2] NCCL INFO Channel 01 : 186[ca000] -> 187[e3000] via P2P/IPC/read
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [send] via NET/IBext/0
402: hkn0720:33772:33907 [2] NCCL INFO Connected all trees
402: hkn0720:33772:33907 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
187: hkn0527:1373302:1373417 [3] NCCL INFO Connected all trees
402: hkn0720:33772:33907 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
187: hkn0527:1373302:1373417 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
268: hkn0616:429398:429527 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [receive] via NET/IBext/0
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [send] via NET/IBext/0
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [send] via NET/IBext/0
400: hkn0720:33752:33908 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [send] via NET/IBext/0
401: hkn0720:33760:33906 [1] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [receive] via NET/IBext/0
187: hkn0527:1373302:1373417 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [send] via NET/IBext/0
400: hkn0720:33752:33908 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [send] via NET/IBext/0
368: hkn0712:319436:319546 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [receive] via NET/IBext/0
186: hkn0527:1373294:1373422 [2] NCCL INFO Connected all trees
186: hkn0527:1373294:1373422 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
451: hkn0734:1180877:1181004 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
186: hkn0527:1373294:1373422 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
451: hkn0734:1180877:1181004 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [send] via NET/IBext/0
450: hkn0734:1180905:1181006 [2] NCCL INFO Connected all trees
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [receive] via NET/IBext/0
450: hkn0734:1180905:1181006 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [receive] via NET/IBext/0
450: hkn0734:1180905:1181006 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
100: hkn0502:253422:253519 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [send] via NET/IBext/0
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [send] via NET/IBext/0
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [receive] via NET/IBext/0
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 01 : 272[31000] -> 273[4b000] via P2P/IPC/read
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [send] via NET/IBext/0
346: hkn0705:807578:807672 [2] NCCL INFO Channel 01 : 346[ca000] -> 347[e3000] via P2P/IPC/read
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 00 : 273[4b000] -> 274[ca000] via P2P/IPC/read
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 00 : 177[4b000] -> 178[ca000] via P2P/IPC/read
274: hkn0617:2319200:2319315 [2] NCCL INFO Channel 00 : 274[ca000] -> 275[e3000] via P2P/IPC/read
347: hkn0705:807550:807681 [3] NCCL INFO Connected all trees
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 01 : 273[4b000] -> 274[ca000] via P2P/IPC/read
347: hkn0705:807550:807681 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
253: hkn0611:734158:734277 [1] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [send] via NET/IBext/0
274: hkn0617:2319200:2319315 [2] NCCL INFO Channel 01 : 274[ca000] -> 275[e3000] via P2P/IPC/read
275: hkn0617:2319192:2319312 [3] NCCL INFO Connected all trees
347: hkn0705:807550:807681 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
369: hkn0712:319420:319542 [1] NCCL INFO Channel 00 : 369[4b000] -> 368[31000] via P2P/IPC/read
275: hkn0617:2319192:2319312 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [receive] via NET/IBext/0
275: hkn0617:2319192:2319312 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [send] via NET/IBext/0
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [send] via NET/IBext/0
274: hkn0617:2319200:2319315 [2] NCCL INFO Connected all trees
346: hkn0705:807578:807672 [2] NCCL INFO Connected all trees
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 00 : 145[4b000] -> 144[31000] via P2P/IPC/read
274: hkn0617:2319200:2319315 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
274: hkn0617:2319200:2319315 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
346: hkn0705:807578:807672 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [receive] via NET/IBext/0
346: hkn0705:807578:807672 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [send] via NET/IBext/0
337: hkn0703:765546:765657 [1] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [send] via NET/IBext/0
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [send] via NET/IBext/0
344: hkn0705:807566:807679 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [send] via NET/IBext/0
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [send] via NET/IBext/0
345: hkn0705:807558:807678 [1] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [receive] via NET/IBext/0
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [send] via NET/IBext/0
344: hkn0705:807566:807679 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [receive] via NET/IBext/0
344: hkn0705:807566:807679 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [send] via NET/IBext/0
178: hkn0525:1011134:1011249 [2] NCCL INFO Channel 00 : 178[ca000] -> 179[e3000] via P2P/IPC/read
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 01 : 177[4b000] -> 178[ca000] via P2P/IPC/read
 22: hkn0409:2609992:2610120 [2] NCCL INFO Channel 00 : 22[ca000] -> 23[e3000] via P2P/IPC/read
369: hkn0712:319420:319542 [1] NCCL INFO Channel 01 : 369[4b000] -> 368[31000] via P2P/IPC/read
178: hkn0525:1011134:1011249 [2] NCCL INFO Channel 01 : 178[ca000] -> 179[e3000] via P2P/IPC/read
179: hkn0525:1011126:1011245 [3] NCCL INFO Connected all trees
 21: hkn0409:2610008:2610115 [1] NCCL INFO Channel 01 : 21[4b000] -> 22[ca000] via P2P/IPC/read
179: hkn0525:1011126:1011245 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 22: hkn0409:2609992:2610120 [2] NCCL INFO Channel 01 : 22[ca000] -> 23[e3000] via P2P/IPC/read
248: hkn0609:735146:735265 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [receive] via NET/IBext/0
179: hkn0525:1011126:1011245 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
145: hkn0513:3037331:3037435 [1] NCCL INFO Channel 01 : 145[4b000] -> 144[31000] via P2P/IPC/read
178: hkn0525:1011134:1011249 [2] NCCL INFO Connected all trees
178: hkn0525:1011134:1011249 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [send] via NET/IBext/0
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [receive] via NET/IBext/0
178: hkn0525:1011134:1011249 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 23: hkn0409:2610020:2610114 [3] NCCL INFO Connected all trees
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [send] via NET/IBext/0
 23: hkn0409:2610020:2610114 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [receive] via NET/IBext/0
 23: hkn0409:2610020:2610114 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [send] via NET/IBext/0
 22: hkn0409:2609992:2610120 [2] NCCL INFO Connected all trees
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [send] via NET/IBext/0
 22: hkn0409:2609992:2610120 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [receive] via NET/IBext/0
 22: hkn0409:2609992:2610120 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [receive] via NET/IBext/0
382: hkn0715:426276:426394 [2] NCCL INFO Channel 01 : 382[ca000] -> 383[e3000] via P2P/IPC/read
 21: hkn0409:2610008:2610115 [1] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [receive] via NET/IBext/0
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 00 : 105[4b000] -> 106[ca000] via P2P/IPC/read
376: hkn0714:456371:456476 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [send] via NET/IBext/0
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [send] via NET/IBext/0
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [receive] via NET/IBext/0
383: hkn0715:426284:426389 [3] NCCL INFO Connected all trees
232: hkn0605:736552:736663 [0] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [receive] via NET/IBext/0
383: hkn0715:426284:426389 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
383: hkn0715:426284:426389 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
106: hkn0503:2924162:2924287 [2] NCCL INFO Channel 00 : 106[ca000] -> 107[e3000] via P2P/IPC/read
382: hkn0715:426276:426394 [2] NCCL INFO Connected all trees
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 01 : 105[4b000] -> 106[ca000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [send] via NET/IBext/0
382: hkn0715:426276:426394 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
382: hkn0715:426276:426394 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
106: hkn0503:2924162:2924287 [2] NCCL INFO Channel 01 : 106[ca000] -> 107[e3000] via P2P/IPC/read
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [send] via NET/IBext/0
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 00 : 305[4b000] -> 304[31000] via P2P/IPC/read
380: hkn0715:426268:426388 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [receive] via NET/IBext/0
107: hkn0503:2924178:2924282 [3] NCCL INFO Connected all trees
381: hkn0715:426296:426395 [1] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [send] via NET/IBext/0
107: hkn0503:2924178:2924282 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:426268:426388 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [receive] via NET/IBext/0
107: hkn0503:2924178:2924282 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
106: hkn0503:2924162:2924287 [2] NCCL INFO Connected all trees
310: hkn0630:1622852:1622969 [2] NCCL INFO Channel 01 : 310[ca000] -> 311[e3000] via P2P/IPC/read
106: hkn0503:2924162:2924287 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
357: hkn0708:437583:437699 [1] NCCL INFO Channel 00 : 357[4b000] -> 358[ca000] via P2P/IPC/read
106: hkn0503:2924162:2924287 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
311: hkn0630:1622872:1622968 [3] NCCL INFO Connected all trees
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [send] via NET/IBext/0
311: hkn0630:1622872:1622968 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [receive] via NET/IBext/0
345: hkn0705:807558:807678 [1] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [send] via NET/IBext/0
260: hkn0613:927106:927208 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [send] via NET/IBext/0
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [receive] via NET/IBext/0
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [send] via NET/IBext/0
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [send] via NET/IBext/0
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [send] via NET/IBext/0
311: hkn0630:1622872:1622968 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [receive] via NET/IBext/0
310: hkn0630:1622852:1622969 [2] NCCL INFO Connected all trees
305: hkn0629:1616367:1616506 [1] NCCL INFO Channel 01 : 305[4b000] -> 304[31000] via P2P/IPC/read
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [receive] via NET/IBext/0
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [send] via NET/IBext/0
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [send] via NET/IBext/0
310: hkn0630:1622852:1622969 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
358: hkn0708:437599:437701 [2] NCCL INFO Channel 00 : 358[ca000] -> 359[e3000] via P2P/IPC/read
310: hkn0630:1622852:1622969 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:437583:437699 [1] NCCL INFO Channel 01 : 357[4b000] -> 358[ca000] via P2P/IPC/read
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [receive] via NET/IBext/0
358: hkn0708:437599:437701 [2] NCCL INFO Channel 01 : 358[ca000] -> 359[e3000] via P2P/IPC/read
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [send] via NET/IBext/0
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [receive] via NET/IBext/0
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [send] via NET/IBext/0
309: hkn0630:1622860:1622960 [1] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [receive] via NET/IBext/0
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [receive] via NET/IBext/0
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [send] via NET/IBext/0
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [send] via NET/IBext/0
359: hkn0708:437591:437704 [3] NCCL INFO Connected all trees
359: hkn0708:437591:437704 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
334: hkn0636:1678724:1678867 [2] NCCL INFO Channel 01 : 334[ca000] -> 335[e3000] via P2P/IPC/read
359: hkn0708:437591:437704 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 83: hkn0425:2108537:2108638 [3] NCCL INFO Connected all trees
337: hkn0703:765546:765657 [1] NCCL INFO Channel 00 : 337[4b000] -> 336[31000] via P2P/IPC/read
358: hkn0708:437599:437701 [2] NCCL INFO Connected all trees
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [receive] via NET/IBext/0
358: hkn0708:437599:437701 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
358: hkn0708:437599:437701 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
335: hkn0636:1678732:1678872 [3] NCCL INFO Connected all trees
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [send] via NET/IBext/0
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [receive] via NET/IBext/0
356: hkn0708:437611:437707 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [receive] via NET/IBext/0
335: hkn0636:1678732:1678872 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [send] via NET/IBext/0
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 00 : 49[4b000] -> 48[31000] via P2P/IPC/read
241: hkn0607:928753:928855 [1] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [send] via NET/IBext/0
401: hkn0720:33760:33906 [1] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [send] via NET/IBext/0
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [receive] via NET/IBext/0
357: hkn0708:437583:437699 [1] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [receive] via NET/IBext/0
356: hkn0708:437611:437707 [0] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [send] via NET/IBext/0
335: hkn0636:1678732:1678872 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
377: hkn0714:456383:456480 [1] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [send] via NET/IBext/0
334: hkn0636:1678724:1678867 [2] NCCL INFO Connected all trees
334: hkn0636:1678724:1678867 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 83: hkn0425:2108537:2108638 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
334: hkn0636:1678724:1678867 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 83: hkn0425:2108537:2108638 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:734178:734279 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [receive] via NET/IBext/0
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [receive] via NET/IBext/0
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [send] via NET/IBext/0
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [receive] via NET/IBext/0
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 00 : 113[4b000] -> 112[31000] via P2P/IPC/read
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [send] via NET/IBext/0
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [receive] via NET/IBext/0
 82: hkn0425:2108517:2108637 [2] NCCL INFO Connected all trees
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [receive] via NET/IBext/0
337: hkn0703:765546:765657 [1] NCCL INFO Channel 01 : 337[4b000] -> 336[31000] via P2P/IPC/read
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [send] via NET/IBext/0
 49: hkn0417:2292047:2292172 [1] NCCL INFO Channel 01 : 49[4b000] -> 48[31000] via P2P/IPC/read
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 00 : 177[4b000] -> 176[31000] via P2P/IPC/read
 82: hkn0425:2108517:2108637 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 82: hkn0425:2108517:2108637 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
131: hkn0509:3148767:3148876 [3] NCCL INFO Connected all trees
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [send] via NET/IBext/0
166: hkn0521:1222185:1222296 [2] NCCL INFO Channel 01 : 166[ca000] -> 167[e3000] via P2P/IPC/read
356: hkn0708:437611:437707 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [send] via NET/IBext/0
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [receive] via NET/IBext/0
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [send] via NET/IBext/0
131: hkn0509:3148767:3148876 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [send] via NET/IBext/0
131: hkn0509:3148767:3148876 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [send] via NET/IBext/0
130: hkn0509:3148779:3148872 [2] NCCL INFO Connected all trees
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [receive] via NET/IBext/0
130: hkn0509:3148779:3148872 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 00 : 81[4b000] -> 80[31000] via P2P/IPC/read
130: hkn0509:3148779:3148872 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 81: hkn0425:2108525:2108632 [1] NCCL INFO Channel 01 : 81[4b000] -> 80[31000] via P2P/IPC/read
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [send] via NET/IBext/0
113: hkn0505:2328151:2328263 [1] NCCL INFO Channel 01 : 113[4b000] -> 112[31000] via P2P/IPC/read
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [receive] via NET/IBext/0
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [send] via NET/IBext/0
167: hkn0521:1222197:1222291 [3] NCCL INFO Connected all trees
177: hkn0525:1011146:1011240 [1] NCCL INFO Channel 01 : 177[4b000] -> 176[31000] via P2P/IPC/read
167: hkn0521:1222197:1222291 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
167: hkn0521:1222197:1222291 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
117: hkn0506:862422:862551 [1] NCCL INFO Channel 00 : 117[4b000] -> 118[ca000] via P2P/IPC/read
166: hkn0521:1222185:1222296 [2] NCCL INFO Connected all trees
454: hkn0736:1532624:1532729 [2] NCCL INFO Channel 00 : 454[ca000] -> 455[e3000] via P2P/IPC/read
166: hkn0521:1222185:1222296 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
118: hkn0506:862450:862548 [2] NCCL INFO Channel 00 : 118[ca000] -> 119[e3000] via P2P/IPC/read
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [send] via NET/IBext/0
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [send] via NET/IBext/0
400: hkn0720:33752:33908 [0] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [send] via NET/IBext/0
166: hkn0521:1222185:1222296 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
217: hkn0601:142232:142341 [1] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [send] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [send] via NET/IBext/0
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [send] via NET/IBext/0
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [send] via NET/IBext/0
216: hkn0601:142244:142342 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [send] via NET/IBext/0
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [receive] via NET/IBext/0
228: hkn0604:713559:713655 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [send] via NET/IBext/0
165: hkn0521:1222177:1222293 [1] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [receive] via NET/IBext/0
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [send] via NET/IBext/0
117: hkn0506:862422:862551 [1] NCCL INFO Channel 01 : 117[4b000] -> 118[ca000] via P2P/IPC/read
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [send] via NET/IBext/0
118: hkn0506:862450:862548 [2] NCCL INFO Channel 01 : 118[ca000] -> 119[e3000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [receive] via NET/IBext/0
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [send] via NET/IBext/0
119: hkn0506:862430:862542 [3] NCCL INFO Connected all trees
453: hkn0736:1532616:1532726 [1] NCCL INFO Channel 01 : 453[4b000] -> 454[ca000] via P2P/IPC/read
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [send] via NET/IBext/0
119: hkn0506:862430:862542 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 00 : 17[4b000] -> 16[31000] via P2P/IPC/read
119: hkn0506:862430:862542 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [receive] via NET/IBext/0
118: hkn0506:862450:862548 [2] NCCL INFO Connected all trees
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [send] via NET/IBext/0
118: hkn0506:862450:862548 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [receive] via NET/IBext/0
118: hkn0506:862450:862548 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
116: hkn0506:862438:862546 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [receive] via NET/IBext/0
454: hkn0736:1532624:1532729 [2] NCCL INFO Channel 01 : 454[ca000] -> 455[e3000] via P2P/IPC/read
117: hkn0506:862422:862551 [1] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [receive] via NET/IBext/0
455: hkn0736:1532608:1532732 [3] NCCL INFO Connected all trees
116: hkn0506:862438:862546 [0] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [send] via NET/IBext/0
455: hkn0736:1532608:1532732 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:862438:862546 [0] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [receive] via NET/IBext/0
455: hkn0736:1532608:1532732 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:438714:438810 [1] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [send] via NET/IBext/0
454: hkn0736:1532624:1532729 [2] NCCL INFO Connected all trees
454: hkn0736:1532624:1532729 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [send] via NET/IBext/0
454: hkn0736:1532624:1532729 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [receive] via NET/IBext/0
 95: hkn0428:691724:691842 [3] NCCL INFO Connected all trees
264: hkn0615:438687:438806 [0] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [receive] via NET/IBext/0
453: hkn0736:1532616:1532726 [1] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [receive] via NET/IBext/0
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [send] via NET/IBext/0
 95: hkn0428:691724:691842 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [send] via NET/IBext/0
 95: hkn0428:691724:691842 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:379895:380014 [1] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [send] via NET/IBext/0
 94: hkn0428:691716:691838 [2] NCCL INFO Connected all trees
241: hkn0607:928753:928855 [1] NCCL INFO Channel 00 : 241[4b000] -> 240[31000] via P2P/IPC/read
 94: hkn0428:691716:691838 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 00 : 209[4b000] -> 208[31000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [receive] via NET/IBext/0
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [send] via NET/IBext/0
401: hkn0720:33760:33906 [1] NCCL INFO Channel 00 : 401[4b000] -> 400[31000] via P2P/IPC/read
244: hkn0608:510064:510177 [0] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [send] via NET/IBext/0
 94: hkn0428:691716:691838 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [receive] via NET/IBext/0
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [send] via NET/IBext/0
 75: hkn0423:1729394:1729515 [3] NCCL INFO Connected all trees
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [receive] via NET/IBext/0
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [receive] via NET/IBext/0
170: hkn0523:1572577:1572685 [2] NCCL INFO Channel 00 : 170[ca000] -> 171[e3000] via P2P/IPC/read
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [send] via NET/IBext/0
360: hkn0710:379903:380006 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [receive] via NET/IBext/0
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [send] via NET/IBext/0
 75: hkn0423:1729394:1729515 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2915262:2915390 [1] NCCL INFO Channel 01 : 17[4b000] -> 16[31000] via P2P/IPC/read
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [receive] via NET/IBext/0
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [receive] via NET/IBext/0
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [send] via NET/IBext/0
209: hkn0534:1172749:1172871 [1] NCCL INFO Channel 01 : 209[4b000] -> 208[31000] via P2P/IPC/read
233: hkn0605:736560:736669 [1] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [send] via NET/IBext/0
408: hkn0723:232560:232720 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [send] via NET/IBext/0
241: hkn0607:928753:928855 [1] NCCL INFO Channel 01 : 241[4b000] -> 240[31000] via P2P/IPC/read
401: hkn0720:33760:33906 [1] NCCL INFO Channel 01 : 401[4b000] -> 400[31000] via P2P/IPC/read
 75: hkn0423:1729394:1729515 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 74: hkn0423:1729414:1729511 [2] NCCL INFO Connected all trees
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 01 : 169[4b000] -> 170[ca000] via P2P/IPC/read
 74: hkn0423:1729414:1729511 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
170: hkn0523:1572577:1572685 [2] NCCL INFO Channel 01 : 170[ca000] -> 171[e3000] via P2P/IPC/read
 74: hkn0423:1729414:1729511 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
171: hkn0523:1572561:1572684 [3] NCCL INFO Connected all trees
171: hkn0523:1572561:1572684 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [send] via NET/IBext/0
171: hkn0523:1572561:1572684 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [receive] via NET/IBext/0
170: hkn0523:1572577:1572685 [2] NCCL INFO Connected all trees
170: hkn0523:1572577:1572685 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [receive] via NET/IBext/0
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [send] via NET/IBext/0
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [receive] via NET/IBext/0
170: hkn0523:1572577:1572685 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [send] via NET/IBext/0
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [send] via NET/IBext/0
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [receive] via NET/IBext/0
 98: hkn0501:1352394:1352503 [2] NCCL INFO Channel 01 : 98[ca000] -> 99[e3000] via P2P/IPC/read
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [send] via NET/IBext/0
373: hkn0713:494610:494705 [1] NCCL INFO Channel 00 : 373[4b000] -> 374[ca000] via P2P/IPC/read
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [receive] via NET/IBext/0
 99: hkn0501:1352386:1352510 [3] NCCL INFO Connected all trees
 99: hkn0501:1352386:1352510 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 99: hkn0501:1352386:1352510 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
374: hkn0713:494590:494707 [2] NCCL INFO Channel 00 : 374[ca000] -> 375[e3000] via P2P/IPC/read
100: hkn0502:253422:253519 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [receive] via NET/IBext/0
 98: hkn0501:1352394:1352503 [2] NCCL INFO Connected all trees
 98: hkn0501:1352394:1352503 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 98: hkn0501:1352394:1352503 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [send] via NET/IBext/0
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [send] via NET/IBext/0
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [receive] via NET/IBext/0
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [receive] via NET/IBext/0
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [send] via NET/IBext/0
373: hkn0713:494610:494705 [1] NCCL INFO Channel 01 : 373[4b000] -> 374[ca000] via P2P/IPC/read
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [receive] via NET/IBext/0
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [send] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [send] via NET/IBext/0
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [send] via NET/IBext/0
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [receive] via NET/IBext/0
374: hkn0713:494590:494707 [2] NCCL INFO Channel 01 : 374[ca000] -> 375[e3000] via P2P/IPC/read
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 00 : 97[4b000] -> 96[31000] via P2P/IPC/read
375: hkn0713:494582:494711 [3] NCCL INFO Connected all trees
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [receive] via NET/IBext/0
 97: hkn0501:1352406:1352507 [1] NCCL INFO Channel 01 : 97[4b000] -> 96[31000] via P2P/IPC/read
375: hkn0713:494582:494711 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 87: hkn0426:838380:838520 [3] NCCL INFO Connected all trees
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [send] via NET/IBext/0
375: hkn0713:494582:494711 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
374: hkn0713:494590:494707 [2] NCCL INFO Connected all trees
 87: hkn0426:838380:838520 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [send] via NET/IBext/0
374: hkn0713:494590:494707 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
374: hkn0713:494590:494707 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 87: hkn0426:838380:838520 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [send] via NET/IBext/0
372: hkn0713:494598:494713 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [receive] via NET/IBext/0
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [receive] via NET/IBext/0
373: hkn0713:494610:494705 [1] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [receive] via NET/IBext/0
409: hkn0723:232568:232721 [1] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [send] via NET/IBext/0
372: hkn0713:494598:494713 [0] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [send] via NET/IBext/0
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [send] via NET/IBext/0
372: hkn0713:494598:494713 [0] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [receive] via NET/IBext/0
109: hkn0504:65443:65560 [1] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [receive] via NET/IBext/0
 86: hkn0426:838372:838511 [2] NCCL INFO Connected all trees
 86: hkn0426:838372:838511 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 00 : 201[4b000] -> 202[ca000] via P2P/IPC/read
 86: hkn0426:838372:838511 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 59: hkn0419:1568607:1568710 [3] NCCL INFO Connected all trees
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [receive] via NET/IBext/0
202: hkn0531:1255138:1255243 [2] NCCL INFO Channel 00 : 202[ca000] -> 203[e3000] via P2P/IPC/read
 85: hkn0426:838392:838518 [1] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [receive] via NET/IBext/0
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 01 : 201[4b000] -> 202[ca000] via P2P/IPC/read
368: hkn0712:319436:319546 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [send] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [send] via NET/IBext/0
365: hkn0711:608392:608506 [1] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [receive] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [receive] via NET/IBext/0
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [send] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [send] via NET/IBext/0
202: hkn0531:1255138:1255243 [2] NCCL INFO Channel 01 : 202[ca000] -> 203[e3000] via P2P/IPC/read
 59: hkn0419:1568607:1568710 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [receive] via NET/IBext/0
203: hkn0531:1255122:1255246 [3] NCCL INFO Connected all trees
203: hkn0531:1255122:1255246 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 59: hkn0419:1568607:1568710 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:928741:928852 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [receive] via NET/IBext/0
203: hkn0531:1255122:1255246 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 00 : 273[4b000] -> 272[31000] via P2P/IPC/read
202: hkn0531:1255138:1255243 [2] NCCL INFO Connected all trees
202: hkn0531:1255138:1255243 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 58: hkn0419:1568591:1568715 [2] NCCL INFO Connected all trees
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 00 : 433[4b000] -> 432[31000] via P2P/IPC/read
202: hkn0531:1255138:1255243 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [send] via NET/IBext/0
 58: hkn0419:1568591:1568715 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [receive] via NET/IBext/0
 58: hkn0419:1568591:1568715 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [send] via NET/IBext/0
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [send] via NET/IBext/0
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [receive] via NET/IBext/0
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [receive] via NET/IBext/0
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [send] via NET/IBext/0
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [receive] via NET/IBext/0
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [receive] via NET/IBext/0
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [send] via NET/IBext/0
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [receive] via NET/IBext/0
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [send] via NET/IBext/0
260: hkn0613:927106:927208 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [receive] via NET/IBext/0
502: hkn0814:700184:700311 [2] NCCL INFO Channel 01 : 502[ca000] -> 503[e3000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [receive] via NET/IBext/0
108: hkn0504:65435:65559 [0] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [receive] via NET/IBext/0
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 00 : 77[4b000] -> 76[31000] via P2P/IPC/read
273: hkn0617:2319212:2319310 [1] NCCL INFO Channel 01 : 273[4b000] -> 272[31000] via P2P/IPC/read
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [send] via NET/IBext/0
503: hkn0814:700156:700314 [3] NCCL INFO Connected all trees
503: hkn0814:700156:700314 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
154: hkn0515:2921182:2921328 [2] NCCL INFO Connected all rings
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [receive] via NET/IBext/0
503: hkn0814:700156:700314 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
502: hkn0814:700184:700311 [2] NCCL INFO Connected all trees
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 00 : 153[4b000] -> 154[ca000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [receive] via NET/IBext/0
502: hkn0814:700184:700311 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [receive] via NET/IBext/0
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [send] via NET/IBext/0
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [receive] via NET/IBext/0
502: hkn0814:700184:700311 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [receive] via NET/IBext/0
500: hkn0814:700164:700310 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [receive] via NET/IBext/0
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [receive] via NET/IBext/0
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [receive] via NET/IBext/0
433: hkn0730:1426045:1426192 [1] NCCL INFO Channel 01 : 433[4b000] -> 432[31000] via P2P/IPC/read
501: hkn0814:700172:700309 [1] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [receive] via NET/IBext/0
 77: hkn0424:2972305:2972428 [1] NCCL INFO Channel 01 : 77[4b000] -> 76[31000] via P2P/IPC/read
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [receive] via NET/IBext/0
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [send] via NET/IBext/0
116: hkn0506:862438:862546 [0] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [send] via NET/IBext/0
500: hkn0814:700164:700310 [0] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [send] via NET/IBext/0
154: hkn0515:2921182:2921328 [2] NCCL INFO Channel 00 : 154[ca000] -> 155[e3000] via P2P/IPC/read
500: hkn0814:700164:700310 [0] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [receive] via NET/IBext/0
154: hkn0515:2921182:2921328 [2] NCCL INFO Channel 01 : 154[ca000] -> 155[e3000] via P2P/IPC/read
500: hkn0814:700164:700310 [0] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [send] via NET/IBext/0
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 01 : 153[4b000] -> 154[ca000] via P2P/IPC/read
155: hkn0515:2921202:2921330 [3] NCCL INFO Connected all trees
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 01 : 188[31000] -> 189[4b000] via P2P/IPC/read
155: hkn0515:2921202:2921330 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 00 : 9[4b000] -> 10[ca000] via P2P/IPC/read
155: hkn0515:2921202:2921330 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 00 : 189[4b000] -> 190[ca000] via P2P/IPC/read
154: hkn0515:2921182:2921328 [2] NCCL INFO Connected all trees
190: hkn0528:1326060:1326165 [2] NCCL INFO Channel 00 : 190[ca000] -> 191[e3000] via P2P/IPC/read
154: hkn0515:2921182:2921328 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 01 : 189[4b000] -> 190[ca000] via P2P/IPC/read
154: hkn0515:2921182:2921328 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
190: hkn0528:1326060:1326165 [2] NCCL INFO Channel 01 : 190[ca000] -> 191[e3000] via P2P/IPC/read
205: hkn0532:950469:950780 [1] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [receive] via NET/IBext/0
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [send] via NET/IBext/0
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [receive] via NET/IBext/0
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [receive] via NET/IBext/0
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [send] via NET/IBext/0
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [receive] via NET/IBext/0
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [receive] via NET/IBext/0
191: hkn0528:1326052:1326169 [3] NCCL INFO Connected all trees
301: hkn0628:696372:696489 [1] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [receive] via NET/IBext/0
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [send] via NET/IBext/0
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [send] via NET/IBext/0
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [send] via NET/IBext/0
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [send] via NET/IBext/0
191: hkn0528:1326052:1326169 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:735146:735265 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [send] via NET/IBext/0
191: hkn0528:1326052:1326169 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
190: hkn0528:1326060:1326165 [2] NCCL INFO Connected all trees
 10: hkn0405:3231519:3231613 [2] NCCL INFO Channel 00 : 10[ca000] -> 11[e3000] via P2P/IPC/read
372: hkn0713:494598:494713 [0] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [send] via NET/IBext/0
190: hkn0528:1326060:1326165 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
190: hkn0528:1326060:1326165 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 01 : 9[4b000] -> 10[ca000] via P2P/IPC/read
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 00 : 353[4b000] -> 352[31000] via P2P/IPC/read
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [receive] via NET/IBext/0
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [send] via NET/IBext/0
 10: hkn0405:3231519:3231613 [2] NCCL INFO Channel 01 : 10[ca000] -> 11[e3000] via P2P/IPC/read
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [receive] via NET/IBext/0
 11: hkn0405:3231507:3231615 [3] NCCL INFO Connected all trees
 11: hkn0405:3231507:3231615 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 01 : 413[4b000] -> 414[ca000] via P2P/IPC/read
 11: hkn0405:3231507:3231615 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
391: hkn0717:19437:19568 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 10: hkn0405:3231519:3231613 [2] NCCL INFO Connected all trees
414: hkn0724:1740337:1740474 [2] NCCL INFO Channel 01 : 414[ca000] -> 415[e3000] via P2P/IPC/read
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [send] via NET/IBext/0
204: hkn0532:950481:950779 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [send] via NET/IBext/0
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [send] via NET/IBext/0
415: hkn0724:1740349:1740479 [3] NCCL INFO Connected all trees
 10: hkn0405:3231519:3231613 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
415: hkn0724:1740349:1740479 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 10: hkn0405:3231519:3231613 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
415: hkn0724:1740349:1740479 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [receive] via NET/IBext/0
414: hkn0724:1740337:1740474 [2] NCCL INFO Connected all trees
268: hkn0616:429398:429527 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [send] via NET/IBext/0
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [receive] via NET/IBext/0
356: hkn0708:437611:437707 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [receive] via NET/IBext/0
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [send] via NET/IBext/0
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [send] via NET/IBext/0
353: hkn0707:4044300:4044417 [1] NCCL INFO Channel 01 : 353[4b000] -> 352[31000] via P2P/IPC/read
300: hkn0628:696392:696486 [0] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [receive] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [receive] via NET/IBext/0
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [receive] via NET/IBext/0
414: hkn0724:1740337:1740474 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [send] via NET/IBext/0
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [send] via NET/IBext/0
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [receive] via NET/IBext/0
414: hkn0724:1740337:1740474 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [send] via NET/IBext/0
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 00 : 333[4b000] -> 332[31000] via P2P/IPC/read
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [receive] via NET/IBext/0
391: hkn0717:19437:19568 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [send] via NET/IBext/0
388: hkn0717:19465:19565 [0] NCCL INFO Channel 01 : 388[31000] -> 389[4b000] via P2P/IPC/read
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [receive] via NET/IBext/0
400: hkn0720:33752:33908 [0] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [receive] via NET/IBext/0
232: hkn0605:736552:736663 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [receive] via NET/IBext/0
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [send] via NET/IBext/0
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [receive] via NET/IBext/0
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [receive] via NET/IBext/0
228: hkn0604:713559:713655 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [receive] via NET/IBext/0
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [send] via NET/IBext/0
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [receive] via NET/IBext/0
390: hkn0717:19445:19567 [2] NCCL INFO Connected all trees
390: hkn0717:19445:19567 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:419477:419589 [2] NCCL INFO Channel 01 : 506[ca000] -> 507[e3000] via P2P/IPC/read
390: hkn0717:19445:19567 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1230026:1230141 [3] NCCL INFO Connected all trees
388: hkn0717:19465:19565 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [receive] via NET/IBext/0
507: hkn0815:419489:419590 [3] NCCL INFO Connected all trees
389: hkn0717:19453:19564 [1] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [receive] via NET/IBext/0
507: hkn0815:419489:419590 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [receive] via NET/IBext/0
333: hkn0636:1678744:1678868 [1] NCCL INFO Channel 01 : 333[4b000] -> 332[31000] via P2P/IPC/read
388: hkn0717:19465:19565 [0] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [send] via NET/IBext/0
507: hkn0815:419489:419590 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [send] via NET/IBext/0
388: hkn0717:19465:19565 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [send] via NET/IBext/0
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [receive] via NET/IBext/0
388: hkn0717:19465:19565 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [receive] via NET/IBext/0
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [send] via NET/IBext/0
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [receive] via NET/IBext/0
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [receive] via NET/IBext/0
506: hkn0815:419477:419589 [2] NCCL INFO Connected all trees
506: hkn0815:419477:419589 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
471: hkn0804:1230026:1230141 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [receive] via NET/IBext/0
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [send] via NET/IBext/0
506: hkn0815:419477:419589 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1230026:1230141 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:608404:608498 [0] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [receive] via NET/IBext/0
504: hkn0815:419469:419586 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [send] via NET/IBext/0
505: hkn0815:419461:419585 [1] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [receive] via NET/IBext/0
470: hkn0804:1230046:1230140 [2] NCCL INFO Connected all trees
504: hkn0815:419469:419586 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [receive] via NET/IBext/0
470: hkn0804:1230046:1230140 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:419469:419586 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [send] via NET/IBext/0
470: hkn0804:1230046:1230140 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
505: hkn0815:419461:419585 [1] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [send] via NET/IBext/0
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [receive] via NET/IBext/0
469: hkn0804:1230034:1230144 [1] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [receive] via NET/IBext/0
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 00 : 457[4b000] -> 458[ca000] via P2P/IPC/read
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [send] via NET/IBext/0
395: hkn0718:3941427:3941539 [3] NCCL INFO Connected all trees
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [receive] via NET/IBext/0
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [receive] via NET/IBext/0
458: hkn0801:2264537:2264649 [2] NCCL INFO Channel 00 : 458[ca000] -> 459[e3000] via P2P/IPC/read
395: hkn0718:3941427:3941539 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 01 : 457[4b000] -> 458[ca000] via P2P/IPC/read
395: hkn0718:3941427:3941539 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
458: hkn0801:2264537:2264649 [2] NCCL INFO Channel 01 : 458[ca000] -> 459[e3000] via P2P/IPC/read
394: hkn0718:3941447:3941548 [2] NCCL INFO Connected all trees
459: hkn0801:2264529:2264651 [3] NCCL INFO Connected all trees
394: hkn0718:3941447:3941548 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
459: hkn0801:2264529:2264651 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
394: hkn0718:3941447:3941548 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
459: hkn0801:2264529:2264651 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [send] via NET/IBext/0
458: hkn0801:2264537:2264649 [2] NCCL INFO Connected all trees
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [receive] via NET/IBext/0
458: hkn0801:2264537:2264649 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [send] via NET/IBext/0
458: hkn0801:2264537:2264649 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [receive] via NET/IBext/0
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [send] via NET/IBext/0
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [send] via NET/IBext/0
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [receive] via NET/IBext/0
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [receive] via NET/IBext/0
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [receive] via NET/IBext/0
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [send] via NET/IBext/0
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [send] via NET/IBext/0
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [send] via NET/IBext/0
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [receive] via NET/IBext/0
430: hkn0728:1348501:1348594 [2] NCCL INFO Channel 00 : 430[ca000] -> 431[e3000] via P2P/IPC/read
422: hkn0726:1572474:1572594 [2] NCCL INFO Channel 00 : 422[ca000] -> 423[e3000] via P2P/IPC/read
483: hkn0807:1043414:1043536 [3] NCCL INFO Connected all trees
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 01 : 429[4b000] -> 430[ca000] via P2P/IPC/read
491: hkn0809:961660:961772 [3] NCCL INFO Connected all trees
430: hkn0728:1348501:1348594 [2] NCCL INFO Channel 01 : 430[ca000] -> 431[e3000] via P2P/IPC/read
421: hkn0726:1572490:1572596 [1] NCCL INFO Channel 01 : 421[4b000] -> 422[ca000] via P2P/IPC/read
109: hkn0504:65443:65560 [1] NCCL INFO Channel 00 : 109[4b000] -> 108[31000] via P2P/IPC/read
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [send] via NET/IBext/0
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [send] via NET/IBext/0
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 00 : 33[4b000] -> 32[31000] via P2P/IPC/read
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [receive] via NET/IBext/0
431: hkn0728:1348489:1348596 [3] NCCL INFO Connected all trees
431: hkn0728:1348489:1348596 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
422: hkn0726:1572474:1572594 [2] NCCL INFO Channel 01 : 422[ca000] -> 423[e3000] via P2P/IPC/read
431: hkn0728:1348489:1348596 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
423: hkn0726:1572482:1572597 [3] NCCL INFO Connected all trees
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [receive] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [receive] via NET/IBext/0
430: hkn0728:1348501:1348594 [2] NCCL INFO Connected all trees
430: hkn0728:1348501:1348594 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
423: hkn0726:1572482:1572597 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [receive] via NET/IBext/0
430: hkn0728:1348501:1348594 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [receive] via NET/IBext/0
423: hkn0726:1572482:1572597 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [send] via NET/IBext/0
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [receive] via NET/IBext/0
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [send] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [receive] via NET/IBext/0
109: hkn0504:65443:65560 [1] NCCL INFO Channel 01 : 109[4b000] -> 108[31000] via P2P/IPC/read
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [send] via NET/IBext/0
 33: hkn0412:2286731:2286842 [1] NCCL INFO Channel 01 : 33[4b000] -> 32[31000] via P2P/IPC/read
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [receive] via NET/IBext/0
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 00 : 89[4b000] -> 88[31000] via P2P/IPC/read
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [receive] via NET/IBext/0
422: hkn0726:1572474:1572594 [2] NCCL INFO Connected all trees
483: hkn0807:1043414:1043536 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
422: hkn0726:1572474:1572594 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
483: hkn0807:1043414:1043536 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [send] via NET/IBext/0
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [send] via NET/IBext/0
422: hkn0726:1572474:1572594 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
482: hkn0807:1043406:1043538 [2] NCCL INFO Connected all trees
264: hkn0615:438687:438806 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [receive] via NET/IBext/0
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 00 : 429[4b000] -> 428[31000] via P2P/IPC/read
421: hkn0726:1572490:1572596 [1] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [receive] via NET/IBext/0
482: hkn0807:1043406:1043538 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [send] via NET/IBext/0
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [send] via NET/IBext/0
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [send] via NET/IBext/0
482: hkn0807:1043406:1043538 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [receive] via NET/IBext/0
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [send] via NET/IBext/0
269: hkn0616:429426:429521 [1] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [receive] via NET/IBext/0
249: hkn0609:735138:735259 [1] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [send] via NET/IBext/0
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [receive] via NET/IBext/0
491: hkn0809:961660:961772 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
500: hkn0814:700164:700310 [0] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [receive] via NET/IBext/0
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [send] via NET/IBext/0
365: hkn0711:608392:608506 [1] NCCL INFO Channel 00 : 365[4b000] -> 364[31000] via P2P/IPC/read
 89: hkn0427:1159514:1159627 [1] NCCL INFO Channel 01 : 89[4b000] -> 88[31000] via P2P/IPC/read
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [send] via NET/IBext/0
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [receive] via NET/IBext/0
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [receive] via NET/IBext/0
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [send] via NET/IBext/0
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 00 : 225[4b000] -> 224[31000] via P2P/IPC/read
491: hkn0809:961660:961772 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 00 : 45[4b000] -> 44[31000] via P2P/IPC/read
490: hkn0809:961680:961778 [2] NCCL INFO Connected all trees
429: hkn0728:1348481:1348599 [1] NCCL INFO Channel 01 : 429[4b000] -> 428[31000] via P2P/IPC/read
490: hkn0809:961680:961778 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
490: hkn0809:961680:961778 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
494: hkn0810:963913:964023 [2] NCCL INFO Channel 01 : 494[ca000] -> 495[e3000] via P2P/IPC/read
488: hkn0809:961652:961773 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [send] via NET/IBext/0
418: hkn0725:3136324:3136423 [2] NCCL INFO Channel 01 : 418[ca000] -> 419[e3000] via P2P/IPC/read
489: hkn0809:961668:961775 [1] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [receive] via NET/IBext/0
495: hkn0810:963921:964028 [3] NCCL INFO Connected all trees
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [receive] via NET/IBext/0
488: hkn0809:961652:961773 [0] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [send] via NET/IBext/0
488: hkn0809:961652:961773 [0] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [receive] via NET/IBext/0
495: hkn0810:963921:964028 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
244: hkn0608:510064:510177 [0] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [receive] via NET/IBext/0
489: hkn0809:961668:961775 [1] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [send] via NET/IBext/0
488: hkn0809:961652:961773 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [receive] via NET/IBext/0
495: hkn0810:963921:964028 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
365: hkn0711:608392:608506 [1] NCCL INFO Channel 01 : 365[4b000] -> 364[31000] via P2P/IPC/read
494: hkn0810:963913:964023 [2] NCCL INFO Connected all trees
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [receive] via NET/IBext/0
494: hkn0810:963913:964023 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
494: hkn0810:963913:964023 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
419: hkn0725:3136296:3136421 [3] NCCL INFO Connected all trees
225: hkn0603:1437591:1437698 [1] NCCL INFO Channel 01 : 225[4b000] -> 224[31000] via P2P/IPC/read
 45: hkn0415:2520743:2520858 [1] NCCL INFO Channel 01 : 45[4b000] -> 44[31000] via P2P/IPC/read
492: hkn0810:963933:964030 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [receive] via NET/IBext/0
419: hkn0725:3136296:3136421 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:963905:964027 [1] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [send] via NET/IBext/0
419: hkn0725:3136296:3136421 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [receive] via NET/IBext/0
492: hkn0810:963933:964030 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [receive] via NET/IBext/0
493: hkn0810:963905:964027 [1] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [receive] via NET/IBext/0
418: hkn0725:3136324:3136423 [2] NCCL INFO Connected all trees
492: hkn0810:963933:964030 [0] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [receive] via NET/IBext/0
418: hkn0725:3136324:3136423 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:963905:964027 [1] NCCL INFO Channel 00 : 493[4b000] -> 492[31000] via P2P/IPC/read
418: hkn0725:3136324:3136423 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [receive] via NET/IBext/0
493: hkn0810:963905:964027 [1] NCCL INFO Channel 01 : 493[4b000] -> 492[31000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [receive] via NET/IBext/0
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 00 : 173[4b000] -> 172[31000] via P2P/IPC/read
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [receive] via NET/IBext/0
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [send] via NET/IBext/0
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [receive] via NET/IBext/0
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [receive] via NET/IBext/0
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [send] via NET/IBext/0
478: hkn0806:1078688:1078789 [2] NCCL INFO Channel 01 : 478[ca000] -> 479[e3000] via P2P/IPC/read
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [send] via NET/IBext/0
499: hkn0812:718257:718355 [3] NCCL INFO Connected all trees
301: hkn0628:696372:696489 [1] NCCL INFO Channel 00 : 301[4b000] -> 300[31000] via P2P/IPC/read
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [send] via NET/IBext/0
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 00 : 141[4b000] -> 140[31000] via P2P/IPC/read
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [receive] via NET/IBext/0
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 00 : 13[4b000] -> 12[31000] via P2P/IPC/read
492: hkn0810:963933:964030 [0] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [send] via NET/IBext/0
116: hkn0506:862438:862546 [0] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [receive] via NET/IBext/0
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 00 : 417[4b000] -> 416[31000] via P2P/IPC/read
479: hkn0806:1078660:1078785 [3] NCCL INFO Connected all trees
499: hkn0812:718257:718355 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
479: hkn0806:1078660:1078785 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
499: hkn0812:718257:718355 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [receive] via NET/IBext/0
479: hkn0806:1078660:1078785 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 00 : 321[4b000] -> 320[31000] via P2P/IPC/read
173: hkn0524:1158144:1158252 [1] NCCL INFO Channel 01 : 173[4b000] -> 172[31000] via P2P/IPC/read
345: hkn0705:807558:807678 [1] NCCL INFO Channel 00 : 345[4b000] -> 344[31000] via P2P/IPC/read
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [send] via NET/IBext/0
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 00 : 161[4b000] -> 160[31000] via P2P/IPC/read
478: hkn0806:1078688:1078789 [2] NCCL INFO Connected all trees
478: hkn0806:1078688:1078789 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
498: hkn0812:718237:718348 [2] NCCL INFO Connected all trees
301: hkn0628:696372:696489 [1] NCCL INFO Channel 01 : 301[4b000] -> 300[31000] via P2P/IPC/read
478: hkn0806:1078688:1078789 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [receive] via NET/IBext/0
498: hkn0812:718237:718348 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 00 : 289[4b000] -> 288[31000] via P2P/IPC/read
141: hkn0512:3068462:3068573 [1] NCCL INFO Channel 01 : 141[4b000] -> 140[31000] via P2P/IPC/read
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [receive] via NET/IBext/0
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [send] via NET/IBext/0
205: hkn0532:950469:950780 [1] NCCL INFO Channel 00 : 205[4b000] -> 204[31000] via P2P/IPC/read
 13: hkn0407:1840621:1840725 [1] NCCL INFO Channel 01 : 13[4b000] -> 12[31000] via P2P/IPC/read
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [receive] via NET/IBext/0
498: hkn0812:718237:718348 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
496: hkn0812:718245:718354 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [send] via NET/IBext/0
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 00 : 397[4b000] -> 398[ca000] via P2P/IPC/read
240: hkn0607:928741:928852 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [send] via NET/IBext/0
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 00 : 65[4b000] -> 64[31000] via P2P/IPC/read
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [send] via NET/IBext/0
321: hkn0633:1550661:1550752 [1] NCCL INFO Channel 01 : 321[4b000] -> 320[31000] via P2P/IPC/read
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [send] via NET/IBext/0
345: hkn0705:807558:807678 [1] NCCL INFO Channel 01 : 345[4b000] -> 344[31000] via P2P/IPC/read
161: hkn0520:2737231:2737367 [1] NCCL INFO Channel 01 : 161[4b000] -> 160[31000] via P2P/IPC/read
497: hkn0812:718229:718349 [1] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [receive] via NET/IBext/0
496: hkn0812:718245:718354 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [send] via NET/IBext/0
398: hkn0719:1330251:1330374 [2] NCCL INFO Channel 01 : 398[ca000] -> 399[e3000] via P2P/IPC/read
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [receive] via NET/IBext/0
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [send] via NET/IBext/0
372: hkn0713:494598:494713 [0] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [receive] via NET/IBext/0
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [receive] via NET/IBext/0
289: hkn0624:1797266:1797383 [1] NCCL INFO Channel 01 : 289[4b000] -> 288[31000] via P2P/IPC/read
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [receive] via NET/IBext/0
496: hkn0812:718245:718354 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [receive] via NET/IBext/0
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 01 : 397[4b000] -> 398[ca000] via P2P/IPC/read
205: hkn0532:950469:950780 [1] NCCL INFO Channel 01 : 205[4b000] -> 204[31000] via P2P/IPC/read
497: hkn0812:718229:718349 [1] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [send] via NET/IBext/0
497: hkn0812:718229:718349 [1] NCCL INFO Channel 00 : 497[4b000] -> 496[31000] via P2P/IPC/read
399: hkn0719:1330267:1330376 [3] NCCL INFO Connected all trees
497: hkn0812:718229:718349 [1] NCCL INFO Channel 01 : 497[4b000] -> 496[31000] via P2P/IPC/read
399: hkn0719:1330267:1330376 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 65: hkn0421:2208731:2208877 [1] NCCL INFO Channel 01 : 65[4b000] -> 64[31000] via P2P/IPC/read
505: hkn0815:419461:419585 [1] NCCL INFO Channel 00 : 505[4b000] -> 504[31000] via P2P/IPC/read
496: hkn0812:718245:718354 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [send] via NET/IBext/0
399: hkn0719:1330267:1330376 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
398: hkn0719:1330251:1330374 [2] NCCL INFO Connected all trees
464: hkn0803:901006:901108 [0] NCCL INFO Channel 00 : 464[31000] -> 465[4b000] via P2P/IPC/read
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [receive] via NET/IBext/0
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 00 : 461[4b000] -> 460[31000] via P2P/IPC/read
204: hkn0532:950481:950779 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [receive] via NET/IBext/0
398: hkn0719:1330251:1330374 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
398: hkn0719:1330251:1330374 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
466: hkn0803:900986:901105 [2] NCCL INFO Channel 00 : 466[ca000] -> 467[e3000] via P2P/IPC/read
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [receive] via NET/IBext/0
465: hkn0803:900978:901109 [1] NCCL INFO Channel 01 : 465[4b000] -> 466[ca000] via P2P/IPC/read
384: hkn0716:132827:132967 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [receive] via NET/IBext/0
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [send] via NET/IBext/0
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [receive] via NET/IBext/0
464: hkn0803:901006:901108 [0] NCCL INFO Channel 01 : 464[31000] -> 465[4b000] via P2P/IPC/read
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [send] via NET/IBext/0
466: hkn0803:900986:901105 [2] NCCL INFO Channel 01 : 466[ca000] -> 467[e3000] via P2P/IPC/read
417: hkn0725:3136312:3136416 [1] NCCL INFO Channel 01 : 417[4b000] -> 416[31000] via P2P/IPC/read
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [receive] via NET/IBext/0
268: hkn0616:429398:429527 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [receive] via NET/IBext/0
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [receive] via NET/IBext/0
348: hkn0706:776612:776722 [0] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [receive] via NET/IBext/0
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [send] via NET/IBext/0
505: hkn0815:419461:419585 [1] NCCL INFO Channel 01 : 505[4b000] -> 504[31000] via P2P/IPC/read
467: hkn0803:900994:901110 [3] NCCL INFO Connected all trees
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [receive] via NET/IBext/0
467: hkn0803:900994:901110 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1224708:1224841 [1] NCCL INFO Channel 01 : 461[4b000] -> 460[31000] via P2P/IPC/read
467: hkn0803:900994:901110 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [send] via NET/IBext/0
466: hkn0803:900986:901105 [2] NCCL INFO Connected all trees
466: hkn0803:900986:901105 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
487: hkn0808:995030:995156 [3] NCCL INFO Connected all trees
466: hkn0803:900986:901105 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
464: hkn0803:901006:901108 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [send] via NET/IBext/0
465: hkn0803:900978:901109 [1] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [receive] via NET/IBext/0
487: hkn0808:995030:995156 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
464: hkn0803:901006:901108 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [send] via NET/IBext/0
487: hkn0808:995030:995156 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:900978:901109 [1] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [send] via NET/IBext/0
486: hkn0808:995058:995152 [2] NCCL INFO Connected all trees
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 00 : 397[4b000] -> 396[31000] via P2P/IPC/read
464: hkn0803:901006:901108 [0] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [send] via NET/IBext/0
486: hkn0808:995058:995152 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:900978:901109 [1] NCCL INFO Channel 00 : 465[4b000] -> 464[31000] via P2P/IPC/read
486: hkn0808:995058:995152 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [receive] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [send] via NET/IBext/0
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 00 : 153[4b000] -> 152[31000] via P2P/IPC/read
465: hkn0803:900978:901109 [1] NCCL INFO Channel 01 : 465[4b000] -> 464[31000] via P2P/IPC/read
464: hkn0803:901006:901108 [0] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [receive] via NET/IBext/0
484: hkn0808:995046:995154 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [receive] via NET/IBext/0
485: hkn0808:995038:995153 [1] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [receive] via NET/IBext/0
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [receive] via NET/IBext/0
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [receive] via NET/IBext/0
484: hkn0808:995046:995154 [0] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [send] via NET/IBext/0
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 00 : 121[4b000] -> 120[31000] via P2P/IPC/read
484: hkn0808:995046:995154 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [send] via NET/IBext/0
484: hkn0808:995046:995154 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [receive] via NET/IBext/0
108: hkn0504:65435:65559 [0] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [send] via NET/IBext/0
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [receive] via NET/IBext/0
397: hkn0719:1330259:1330375 [1] NCCL INFO Channel 01 : 397[4b000] -> 396[31000] via P2P/IPC/read
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [receive] via NET/IBext/0
153: hkn0515:2921190:2921327 [1] NCCL INFO Channel 01 : 153[4b000] -> 152[31000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [receive] via NET/IBext/0
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 00 : 441[4b000] -> 440[31000] via P2P/IPC/read
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 00 : 481[4b000] -> 480[31000] via P2P/IPC/read
121: hkn0507:3211451:3211566 [1] NCCL INFO Channel 01 : 121[4b000] -> 120[31000] via P2P/IPC/read
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [send] via NET/IBext/0
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [send] via NET/IBext/0
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [send] via NET/IBext/0
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 00 : 449[4b000] -> 448[31000] via P2P/IPC/read
 84: hkn0426:838364:838519 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [send] via NET/IBext/0
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [receive] via NET/IBext/0
349: hkn0706:776624:776729 [1] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [receive] via NET/IBext/0
441: hkn0732:1236021:1236128 [1] NCCL INFO Channel 01 : 441[4b000] -> 440[31000] via P2P/IPC/read
377: hkn0714:456383:456480 [1] NCCL INFO Channel 00 : 377[4b000] -> 376[31000] via P2P/IPC/read
300: hkn0628:696392:696486 [0] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [send] via NET/IBext/0
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [receive] via NET/IBext/0
481: hkn0807:1043434:1043534 [1] NCCL INFO Channel 01 : 481[4b000] -> 480[31000] via P2P/IPC/read
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [receive] via NET/IBext/0
 80: hkn0425:2108509:2108631 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [receive] via NET/IBext/0
269: hkn0616:429426:429521 [1] NCCL INFO Channel 00 : 269[4b000] -> 268[31000] via P2P/IPC/read
449: hkn0734:1180885:1181000 [1] NCCL INFO Channel 01 : 449[4b000] -> 448[31000] via P2P/IPC/read
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [receive] via NET/IBext/0
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 00 : 57[4b000] -> 56[31000] via P2P/IPC/read
377: hkn0714:456383:456480 [1] NCCL INFO Channel 01 : 377[4b000] -> 376[31000] via P2P/IPC/read
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [receive] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [send] via NET/IBext/0
217: hkn0601:142232:142341 [1] NCCL INFO Channel 00 : 217[4b000] -> 216[31000] via P2P/IPC/read
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [receive] via NET/IBext/0
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [receive] via NET/IBext/0
269: hkn0616:429426:429521 [1] NCCL INFO Channel 01 : 269[4b000] -> 268[31000] via P2P/IPC/read
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 00 : 29[4b000] -> 28[31000] via P2P/IPC/read
 57: hkn0419:1568619:1568709 [1] NCCL INFO Channel 01 : 57[4b000] -> 56[31000] via P2P/IPC/read
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [receive] via NET/IBext/0
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [receive] via NET/IBext/0
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [receive] via NET/IBext/0
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [receive] via NET/IBext/0
217: hkn0601:142232:142341 [1] NCCL INFO Channel 01 : 217[4b000] -> 216[31000] via P2P/IPC/read
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [receive] via NET/IBext/0
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 00 : 477[4b000] -> 476[31000] via P2P/IPC/read
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 00 : 185[4b000] -> 184[31000] via P2P/IPC/read
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [send] via NET/IBext/0
 29: hkn0411:2340273:2340391 [1] NCCL INFO Channel 01 : 29[4b000] -> 28[31000] via P2P/IPC/read
400: hkn0720:33752:33908 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [receive] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [send] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [receive] via NET/IBext/0
477: hkn0806:1078668:1078787 [1] NCCL INFO Channel 01 : 477[4b000] -> 476[31000] via P2P/IPC/read
185: hkn0527:1373310:1373415 [1] NCCL INFO Channel 01 : 185[4b000] -> 184[31000] via P2P/IPC/read
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 00 : 25[4b000] -> 24[31000] via P2P/IPC/read
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [send] via NET/IBext/0
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [receive] via NET/IBext/0
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [send] via NET/IBext/0
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [receive] via NET/IBext/0
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [receive] via NET/IBext/0
 25: hkn0410:1184035:1184153 [1] NCCL INFO Channel 01 : 25[4b000] -> 24[31000] via P2P/IPC/read
344: hkn0705:807566:807679 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [receive] via NET/IBext/0
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [receive] via NET/IBext/0
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 00 : 473[4b000] -> 472[31000] via P2P/IPC/read
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [send] via NET/IBext/0
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 00 : 93[4b000] -> 92[31000] via P2P/IPC/read
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 00 : 413[4b000] -> 412[31000] via P2P/IPC/read
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [send] via NET/IBext/0
473: hkn0805:1136469:1136586 [1] NCCL INFO Channel 01 : 473[4b000] -> 472[31000] via P2P/IPC/read
 93: hkn0428:691732:691841 [1] NCCL INFO Channel 01 : 93[4b000] -> 92[31000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [send] via NET/IBext/0
500: hkn0814:700164:700310 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [send] via NET/IBext/0
385: hkn0716:132811:132965 [1] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [send] via NET/IBext/0
413: hkn0724:1740329:1740471 [1] NCCL INFO Channel 01 : 413[4b000] -> 412[31000] via P2P/IPC/read
492: hkn0810:963933:964030 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [send] via NET/IBext/0
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 00 : 281[4b000] -> 280[31000] via P2P/IPC/read
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 00 : 193[4b000] -> 192[31000] via P2P/IPC/read
336: hkn0703:765538:765661 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [receive] via NET/IBext/0
148: hkn0514:2975079:2975202 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [send] via NET/IBext/0
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [receive] via NET/IBext/0
116: hkn0506:862438:862546 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [send] via NET/IBext/0
281: hkn0622:2045016:2045130 [1] NCCL INFO Channel 01 : 281[4b000] -> 280[31000] via P2P/IPC/read
193: hkn0529:1565171:1565268 [1] NCCL INFO Channel 01 : 193[4b000] -> 192[31000] via P2P/IPC/read
349: hkn0706:776624:776729 [1] NCCL INFO Channel 00 : 349[4b000] -> 348[31000] via P2P/IPC/read
256: hkn0612:941333:941464 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [receive] via NET/IBext/0
409: hkn0723:232568:232721 [1] NCCL INFO Channel 00 : 409[4b000] -> 408[31000] via P2P/IPC/read
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 00 : 313[4b000] -> 312[31000] via P2P/IPC/read
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [receive] via NET/IBext/0
349: hkn0706:776624:776729 [1] NCCL INFO Channel 01 : 349[4b000] -> 348[31000] via P2P/IPC/read
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [receive] via NET/IBext/0
436: hkn0731:1411088:1411212 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [send] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [send] via NET/IBext/0
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 00 : 129[4b000] -> 128[31000] via P2P/IPC/read
409: hkn0723:232568:232721 [1] NCCL INFO Channel 01 : 409[4b000] -> 408[31000] via P2P/IPC/read
313: hkn0631:1046163:1046282 [1] NCCL INFO Channel 01 : 313[4b000] -> 312[31000] via P2P/IPC/read
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [receive] via NET/IBext/0
372: hkn0713:494598:494713 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [send] via NET/IBext/0
108: hkn0504:65435:65559 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [send] via NET/IBext/0
129: hkn0509:3148751:3148873 [1] NCCL INFO Channel 01 : 129[4b000] -> 128[31000] via P2P/IPC/read
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [receive] via NET/IBext/0
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [receive] via NET/IBext/0
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [receive] via NET/IBext/0
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [receive] via NET/IBext/0
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 00 : 285[4b000] -> 284[31000] via P2P/IPC/read
244: hkn0608:510064:510177 [0] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [send] via NET/IBext/0
385: hkn0716:132811:132965 [1] NCCL INFO Channel 00 : 385[4b000] -> 384[31000] via P2P/IPC/read
 80: hkn0425:2108509:2108631 [0] NCCL INFO Connected all trees
 52: hkn0418:1893569:1893661 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [send] via NET/IBext/0
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 00 : 157[4b000] -> 156[31000] via P2P/IPC/read
 80: hkn0425:2108509:2108631 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2108509:2108631 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [receive] via NET/IBext/0
384: hkn0716:132827:132967 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [send] via NET/IBext/0
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [receive] via NET/IBext/0
212: hkn0535:2423336:2423447 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [send] via NET/IBext/0
 81: hkn0425:2108525:2108632 [1] NCCL INFO Connected all trees
 81: hkn0425:2108525:2108632 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2108525:2108632 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
285: hkn0623:1897135:1897250 [1] NCCL INFO Channel 01 : 285[4b000] -> 284[31000] via P2P/IPC/read
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [receive] via NET/IBext/0
385: hkn0716:132811:132965 [1] NCCL INFO Channel 01 : 385[4b000] -> 384[31000] via P2P/IPC/read
157: hkn0516:2940314:2940436 [1] NCCL INFO Channel 01 : 157[4b000] -> 156[31000] via P2P/IPC/read
348: hkn0706:776612:776722 [0] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [send] via NET/IBext/0
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [send] via NET/IBext/0
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 00 : 61[4b000] -> 60[31000] via P2P/IPC/read
 83: hkn0425:2108537:2108638 [3] NCCL INFO comm 0x14e2dc008fb0 rank 83 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
216: hkn0601:142244:142342 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [receive] via NET/IBext/0
 82: hkn0425:2108517:2108637 [2] NCCL INFO comm 0x148e14008fb0 rank 82 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
464: hkn0803:901006:901108 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [receive] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [send] via NET/IBext/0
 80: hkn0425:2108509:2108631 [0] NCCL INFO comm 0x149e34008fb0 rank 80 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
180: hkn0526:1452766:1452877 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [send] via NET/IBext/0
 81: hkn0425:2108525:2108632 [1] NCCL INFO comm 0x146e7c008fb0 rank 81 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 00 : 221[4b000] -> 220[31000] via P2P/IPC/read
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [send] via NET/IBext/0
300: hkn0628:696392:696486 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [send] via NET/IBext/0
 61: hkn0420:3234595:3234696 [1] NCCL INFO Channel 01 : 61[4b000] -> 60[31000] via P2P/IPC/read
 16: hkn0408:2915290:2915389 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [receive] via NET/IBext/0
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [send] via NET/IBext/0
221: hkn0602:3390370:3390573 [1] NCCL INFO Channel 01 : 221[4b000] -> 220[31000] via P2P/IPC/read
 20: hkn0409:2610000:2610117 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [send] via NET/IBext/0
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [send] via NET/IBext/0
468: hkn0804:1230018:1230142 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [send] via NET/IBext/0
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [receive] via NET/IBext/0
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [receive] via NET/IBext/0
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [send] via NET/IBext/0
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [receive] via NET/IBext/0
408: hkn0723:232560:232720 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [receive] via NET/IBext/0
208: hkn0534:1172769:1172865 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [receive] via NET/IBext/0
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [receive] via NET/IBext/0
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [receive] via NET/IBext/0
256: hkn0612:941333:941464 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [send] via NET/IBext/0
276: hkn0621:2016113:2016222 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [send] via NET/IBext/0
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [send] via NET/IBext/0
 44: hkn0415:2520735:2520862 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [send] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [receive] via NET/IBext/0
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 00 : 237[4b000] -> 236[31000] via P2P/IPC/read
337: hkn0703:765546:765657 [1] NCCL INFO Connected all trees
404: hkn0721:2323901:2323996 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [send] via NET/IBext/0
337: hkn0703:765546:765657 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
337: hkn0703:765546:765657 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2286739:2286849 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [receive] via NET/IBext/0
144: hkn0513:3037343:3037441 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [receive] via NET/IBext/0
308: hkn0630:1622844:1622963 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [send] via NET/IBext/0
492: hkn0810:963933:964030 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [send] via NET/IBext/0
336: hkn0703:765538:765661 [0] NCCL INFO Connected all trees
272: hkn0617:2319184:2319311 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [receive] via NET/IBext/0
336: hkn0703:765538:765661 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [receive] via NET/IBext/0
336: hkn0703:765538:765661 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:33752:33908 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [receive] via NET/IBext/0
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [send] via NET/IBext/0
237: hkn0606:2396555:2396677 [1] NCCL INFO Channel 01 : 237[4b000] -> 236[31000] via P2P/IPC/read
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 00 : 317[4b000] -> 316[31000] via P2P/IPC/read
337: hkn0703:765546:765657 [1] NCCL INFO comm 0x147b40008fb0 rank 337 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
336: hkn0703:765538:765661 [0] NCCL INFO comm 0x149ee0008fb0 rank 336 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
338: hkn0703:765558:765658 [2] NCCL INFO comm 0x14ded0008fb0 rank 338 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
339: hkn0703:765530:765656 [3] NCCL INFO comm 0x14bf2c008fb0 rank 339 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
317: hkn0632:1782971:1783088 [1] NCCL INFO Channel 01 : 317[4b000] -> 316[31000] via P2P/IPC/read
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 00 : 445[4b000] -> 444[31000] via P2P/IPC/read
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [receive] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [send] via NET/IBext/0
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 00 : 189[4b000] -> 188[31000] via P2P/IPC/read
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [receive] via NET/IBext/0
108: hkn0504:65435:65559 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [send] via NET/IBext/0
445: hkn0733:1413727:1413845 [1] NCCL INFO Channel 01 : 445[4b000] -> 444[31000] via P2P/IPC/read
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [receive] via NET/IBext/0
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [receive] via NET/IBext/0
189: hkn0528:1326044:1326167 [1] NCCL INFO Channel 01 : 189[4b000] -> 188[31000] via P2P/IPC/read
484: hkn0808:995046:995154 [0] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [receive] via NET/IBext/0
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [receive] via NET/IBext/0
348: hkn0706:776612:776722 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [send] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [send] via NET/IBext/0
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [receive] via NET/IBext/0
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [receive] via NET/IBext/0
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [receive] via NET/IBext/0
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [send] via NET/IBext/0
416: hkn0725:3136304:3136419 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [receive] via NET/IBext/0
300: hkn0628:696392:696486 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [send] via NET/IBext/0
 17: hkn0408:2915262:2915390 [1] NCCL INFO Connected all trees
100: hkn0502:253422:253519 [0] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [receive] via NET/IBext/0
 17: hkn0408:2915262:2915390 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2915262:2915390 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 45: hkn0415:2520743:2520858 [1] NCCL INFO Connected all trees
 45: hkn0415:2520743:2520858 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 45: hkn0415:2520743:2520858 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 16: hkn0408:2915290:2915389 [0] NCCL INFO Connected all trees
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [send] via NET/IBext/0
 16: hkn0408:2915290:2915389 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 16: hkn0408:2915290:2915389 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [receive] via NET/IBext/0
 44: hkn0415:2520735:2520862 [0] NCCL INFO Connected all trees
 44: hkn0415:2520735:2520862 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2520735:2520862 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [send] via NET/IBext/0
 17: hkn0408:2915262:2915390 [1] NCCL INFO comm 0x145bd4008fb0 rank 17 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 18: hkn0408:2915278:2915387 [2] NCCL INFO comm 0x14f5f8008fb0 rank 18 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 16: hkn0408:2915290:2915389 [0] NCCL INFO comm 0x14f188008fb0 rank 16 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 19: hkn0408:2915270:2915393 [3] NCCL INFO comm 0x145fd4008fb0 rank 19 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 44: hkn0415:2520735:2520862 [0] NCCL INFO comm 0x149d04008fb0 rank 44 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 00 : 41[4b000] -> 40[31000] via P2P/IPC/read
244: hkn0608:510064:510177 [0] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [receive] via NET/IBext/0
 45: hkn0415:2520743:2520858 [1] NCCL INFO comm 0x153678008fb0 rank 45 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
492: hkn0810:963933:964030 [0] NCCL INFO Connected all trees
492: hkn0810:963933:964030 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 47: hkn0415:2520751:2520864 [3] NCCL INFO comm 0x151c78008fb0 rank 47 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 46: hkn0415:2520763:2520859 [2] NCCL INFO comm 0x147644008fb0 rank 46 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
489: hkn0809:961668:961775 [1] NCCL INFO Channel 00 : 489[4b000] -> 488[31000] via P2P/IPC/read
492: hkn0810:963933:964030 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [send] via NET/IBext/0
209: hkn0534:1172749:1172871 [1] NCCL INFO Connected all trees
209: hkn0534:1172749:1172871 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1172749:1172871 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
172: hkn0524:1158136:1158254 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [send] via NET/IBext/0
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [receive] via NET/IBext/0
493: hkn0810:963905:964027 [1] NCCL INFO Connected all trees
208: hkn0534:1172769:1172865 [0] NCCL INFO Connected all trees
493: hkn0810:963905:964027 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:437611:437707 [0] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [receive] via NET/IBext/0
493: hkn0810:963905:964027 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
208: hkn0534:1172769:1172865 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1172769:1172865 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 41: hkn0414:2006098:2006227 [1] NCCL INFO Channel 01 : 41[4b000] -> 40[31000] via P2P/IPC/read
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [receive] via NET/IBext/0
209: hkn0534:1172749:1172871 [1] NCCL INFO comm 0x14d8b8008fb0 rank 209 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 92: hkn0428:691744:691845 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [send] via NET/IBext/0
495: hkn0810:963921:964028 [3] NCCL INFO comm 0x14db10008fb0 rank 495 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
208: hkn0534:1172769:1172865 [0] NCCL INFO comm 0x14cddc008fb0 rank 208 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
493: hkn0810:963905:964027 [1] NCCL INFO comm 0x14dc98008fb0 rank 493 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
492: hkn0810:963933:964030 [0] NCCL INFO comm 0x154a48008fb0 rank 492 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
494: hkn0810:963913:964023 [2] NCCL INFO comm 0x14c7dc008fb0 rank 494 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
210: hkn0534:1172741:1172868 [2] NCCL INFO comm 0x1546fc008fb0 rank 210 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
211: hkn0534:1172757:1172866 [3] NCCL INFO comm 0x149480008fb0 rank 211 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
381: hkn0715:426296:426395 [1] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [receive] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO Connected all trees
489: hkn0809:961668:961775 [1] NCCL INFO Channel 01 : 489[4b000] -> 488[31000] via P2P/IPC/read
428: hkn0728:1348473:1348595 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [receive] via NET/IBext/0
428: hkn0728:1348473:1348595 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
236: hkn0606:2396583:2396678 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [send] via NET/IBext/0
429: hkn0728:1348481:1348599 [1] NCCL INFO Connected all trees
109: hkn0504:65443:65560 [1] NCCL INFO Connected all trees
145: hkn0513:3037331:3037435 [1] NCCL INFO Connected all trees
429: hkn0728:1348481:1348599 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
109: hkn0504:65443:65560 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
429: hkn0728:1348481:1348599 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
109: hkn0504:65443:65560 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
145: hkn0513:3037331:3037435 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:426268:426388 [0] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [receive] via NET/IBext/0
145: hkn0513:3037331:3037435 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 00 : 425[4b000] -> 424[31000] via P2P/IPC/read
273: hkn0617:2319212:2319310 [1] NCCL INFO Connected all trees
273: hkn0617:2319212:2319310 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:65435:65559 [0] NCCL INFO Connected all trees
273: hkn0617:2319212:2319310 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
144: hkn0513:3037343:3037441 [0] NCCL INFO Connected all trees
304: hkn0629:1616359:1616509 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [receive] via NET/IBext/0
108: hkn0504:65435:65559 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:65435:65559 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
144: hkn0513:3037343:3037441 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
144: hkn0513:3037343:3037441 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1348473:1348595 [0] NCCL INFO comm 0x150fb4008fb0 rank 428 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [send] via NET/IBext/0
429: hkn0728:1348481:1348599 [1] NCCL INFO comm 0x1522f4008fb0 rank 429 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
272: hkn0617:2319184:2319311 [0] NCCL INFO Connected all trees
430: hkn0728:1348501:1348594 [2] NCCL INFO comm 0x14d2bc008fb0 rank 430 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
431: hkn0728:1348489:1348596 [3] NCCL INFO comm 0x151718008fb0 rank 431 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
272: hkn0617:2319184:2319311 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
272: hkn0617:2319184:2319311 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [receive] via NET/IBext/0
 48: hkn0417:2292075:2292171 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [receive] via NET/IBext/0
401: hkn0720:33760:33906 [1] NCCL INFO Connected all trees
109: hkn0504:65443:65560 [1] NCCL INFO comm 0x14bef4008fb0 rank 109 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
145: hkn0513:3037331:3037435 [1] NCCL INFO comm 0x152140008fb0 rank 145 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
401: hkn0720:33760:33906 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
401: hkn0720:33760:33906 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
110: hkn0504:65463:65554 [2] NCCL INFO comm 0x14ddcc008fb0 rank 110 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
144: hkn0513:3037343:3037441 [0] NCCL INFO comm 0x145678008fb0 rank 144 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
108: hkn0504:65435:65559 [0] NCCL INFO comm 0x149ca0008fb0 rank 108 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [receive] via NET/IBext/0
146: hkn0513:3037323:3037444 [2] NCCL INFO comm 0x152c20008fb0 rank 146 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
425: hkn0727:1370175:1370283 [1] NCCL INFO Channel 01 : 425[4b000] -> 424[31000] via P2P/IPC/read
273: hkn0617:2319212:2319310 [1] NCCL INFO comm 0x14e620008fb0 rank 273 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
111: hkn0504:65451:65555 [3] NCCL INFO comm 0x148a18008fb0 rank 111 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
147: hkn0513:3037315:3037440 [3] NCCL INFO comm 0x146f98008fb0 rank 147 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
275: hkn0617:2319192:2319312 [3] NCCL INFO comm 0x14fa70008fb0 rank 275 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
274: hkn0617:2319200:2319315 [2] NCCL INFO comm 0x1530d8008fb0 rank 274 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
249: hkn0609:735138:735259 [1] NCCL INFO Channel 00 : 249[4b000] -> 248[31000] via P2P/IPC/read
272: hkn0617:2319184:2319311 [0] NCCL INFO comm 0x15433c008fb0 rank 272 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
464: hkn0803:901006:901108 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [receive] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [send] via NET/IBext/0
228: hkn0604:713559:713655 [0] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [receive] via NET/IBext/0
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [send] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO Connected all trees
361: hkn0710:379895:380014 [1] NCCL INFO Channel 00 : 361[4b000] -> 360[31000] via P2P/IPC/read
364: hkn0711:608404:608498 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
400: hkn0720:33752:33908 [0] NCCL INFO Connected all trees
256: hkn0612:941333:941464 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [receive] via NET/IBext/0
364: hkn0711:608404:608498 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:33752:33908 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
400: hkn0720:33752:33908 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
249: hkn0609:735138:735259 [1] NCCL INFO Channel 01 : 249[4b000] -> 248[31000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [send] via NET/IBext/0
  0: hkn0403:1808436:1808801 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [receive] via NET/IBext/0
365: hkn0711:608392:608506 [1] NCCL INFO Connected all trees
365: hkn0711:608392:608506 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
365: hkn0711:608392:608506 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:33760:33906 [1] NCCL INFO comm 0x14f304008fb0 rank 401 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
301: hkn0628:696372:696489 [1] NCCL INFO Connected all trees
400: hkn0720:33752:33908 [0] NCCL INFO comm 0x14bd50008fb0 rank 400 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [receive] via NET/IBext/0
301: hkn0628:696372:696489 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
301: hkn0628:696372:696489 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:379895:380014 [1] NCCL INFO Channel 01 : 361[4b000] -> 360[31000] via P2P/IPC/read
402: hkn0720:33772:33907 [2] NCCL INFO comm 0x14f570008fb0 rank 402 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 00 : 297[4b000] -> 296[31000] via P2P/IPC/read
365: hkn0711:608392:608506 [1] NCCL INFO comm 0x145f64008fb0 rank 365 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [receive] via NET/IBext/0
488: hkn0809:961652:961773 [0] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [send] via NET/IBext/0
300: hkn0628:696392:696486 [0] NCCL INFO Connected all trees
367: hkn0711:608376:608500 [3] NCCL INFO comm 0x153718008fb0 rank 367 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
300: hkn0628:696392:696486 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
366: hkn0711:608384:608505 [2] NCCL INFO comm 0x146a9c008fb0 rank 366 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
300: hkn0628:696392:696486 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:608404:608498 [0] NCCL INFO comm 0x1456e4008fb0 rank 364 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 64: hkn0421:2208719:2208879 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [receive] via NET/IBext/0
403: hkn0720:33744:33905 [3] NCCL INFO comm 0x1477b0008fb0 rank 403 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 00 : 125[4b000] -> 124[31000] via P2P/IPC/read
301: hkn0628:696372:696489 [1] NCCL INFO comm 0x146a54008fb0 rank 301 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
302: hkn0628:696364:696481 [2] NCCL INFO comm 0x15143c008fb0 rank 302 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
297: hkn0627:1812302:1812414 [1] NCCL INFO Channel 01 : 297[4b000] -> 296[31000] via P2P/IPC/read
300: hkn0628:696392:696486 [0] NCCL INFO comm 0x1533c0008fb0 rank 300 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
257: hkn0612:941317:941465 [1] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [send] via NET/IBext/0
303: hkn0628:696380:696485 [3] NCCL INFO comm 0x154d64008fb0 rank 303 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
173: hkn0524:1158144:1158252 [1] NCCL INFO Connected all trees
173: hkn0524:1158144:1158252 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1158144:1158252 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
125: hkn0508:3163494:3163603 [1] NCCL INFO Channel 01 : 125[4b000] -> 124[31000] via P2P/IPC/read
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 00 : 169[4b000] -> 168[31000] via P2P/IPC/read
172: hkn0524:1158136:1158254 [0] NCCL INFO Connected all trees
172: hkn0524:1158136:1158254 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1158136:1158254 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1078676:1078786 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [send] via NET/IBext/0
 93: hkn0428:691732:691841 [1] NCCL INFO Connected all trees
320: hkn0633:1550633:1550753 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [receive] via NET/IBext/0
424: hkn0727:1370187:1370280 [0] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [send] via NET/IBext/0
 93: hkn0428:691732:691841 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1158136:1158254 [0] NCCL INFO comm 0x14f0c4008fb0 rank 172 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 93: hkn0428:691732:691841 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
169: hkn0523:1572569:1572689 [1] NCCL INFO Channel 01 : 169[4b000] -> 168[31000] via P2P/IPC/read
432: hkn0730:1426065:1426190 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [receive] via NET/IBext/0
173: hkn0524:1158144:1158252 [1] NCCL INFO comm 0x152df0008fb0 rank 173 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 00 : 105[4b000] -> 104[31000] via P2P/IPC/read
 36: hkn0413:2391098:2391192 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [send] via NET/IBext/0
348: hkn0706:776612:776722 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO Connected all trees
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [receive] via NET/IBext/0
104: hkn0503:2924170:2924284 [0] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [send] via NET/IBext/0
 92: hkn0428:691744:691845 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
174: hkn0524:1158156:1158250 [2] NCCL INFO comm 0x14b304008fb0 rank 174 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 92: hkn0428:691744:691845 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:995046:995154 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [send] via NET/IBext/0
175: hkn0524:1158128:1158251 [3] NCCL INFO comm 0x14bcd8008fb0 rank 175 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
220: hkn0602:3390398:3390575 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [send] via NET/IBext/0
233: hkn0605:736560:736669 [1] NCCL INFO Channel 00 : 233[4b000] -> 232[31000] via P2P/IPC/read
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [receive] via NET/IBext/0
237: hkn0606:2396555:2396677 [1] NCCL INFO Connected all trees
 93: hkn0428:691732:691841 [1] NCCL INFO comm 0x15165c008fb0 rank 93 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
105: hkn0503:2924190:2924283 [1] NCCL INFO Channel 01 : 105[4b000] -> 104[31000] via P2P/IPC/read
237: hkn0606:2396555:2396677 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 95: hkn0428:691724:691842 [3] NCCL INFO comm 0x14b374008fb0 rank 95 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
237: hkn0606:2396555:2396677 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:691744:691845 [0] NCCL INFO comm 0x14cddc008fb0 rank 92 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 94: hkn0428:691716:691838 [2] NCCL INFO comm 0x151a14008fb0 rank 94 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
236: hkn0606:2396583:2396678 [0] NCCL INFO Connected all trees
233: hkn0605:736560:736669 [1] NCCL INFO Channel 01 : 233[4b000] -> 232[31000] via P2P/IPC/read
236: hkn0606:2396583:2396678 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2396583:2396678 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [send] via NET/IBext/0
420: hkn0726:1572502:1572595 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [send] via NET/IBext/0
360: hkn0710:379903:380006 [0] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [send] via NET/IBext/0
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [send] via NET/IBext/0
238: hkn0606:2396571:2396682 [2] NCCL INFO comm 0x1539e0008fb0 rank 238 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
236: hkn0606:2396583:2396678 [0] NCCL INFO comm 0x1486f8008fb0 rank 236 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
239: hkn0606:2396563:2396679 [3] NCCL INFO comm 0x152a24008fb0 rank 239 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
237: hkn0606:2396555:2396677 [1] NCCL INFO comm 0x150138008fb0 rank 237 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [send] via NET/IBext/0
160: hkn0520:2737215:2737368 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [receive] via NET/IBext/0
296: hkn0627:1812310:1812420 [0] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [send] via NET/IBext/0
204: hkn0532:950481:950779 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [send] via NET/IBext/0
 37: hkn0413:2391086:2391193 [1] NCCL INFO Channel 00 : 37[4b000] -> 36[31000] via P2P/IPC/read
 41: hkn0414:2006098:2006227 [1] NCCL INFO Connected all trees
 41: hkn0414:2006098:2006227 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 41: hkn0414:2006098:2006227 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:995038:995153 [1] NCCL INFO Channel 00 : 485[4b000] -> 484[31000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO Connected all trees
 40: hkn0414:2006126:2006221 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 40: hkn0414:2006126:2006221 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
304: hkn0629:1616359:1616509 [0] NCCL INFO Connected all trees
257: hkn0612:941317:941465 [1] NCCL INFO Channel 00 : 257[4b000] -> 256[31000] via P2P/IPC/read
489: hkn0809:961668:961775 [1] NCCL INFO Connected all trees
304: hkn0629:1616359:1616509 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [send] via NET/IBext/0
304: hkn0629:1616359:1616509 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
489: hkn0809:961668:961775 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
489: hkn0809:961668:961775 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:995038:995153 [1] NCCL INFO Channel 01 : 485[4b000] -> 484[31000] via P2P/IPC/read
 40: hkn0414:2006126:2006221 [0] NCCL INFO comm 0x146f28008fb0 rank 40 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
488: hkn0809:961652:961773 [0] NCCL INFO Connected all trees
 41: hkn0414:2006098:2006227 [1] NCCL INFO comm 0x14d380008fb0 rank 41 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 37: hkn0413:2391086:2391193 [1] NCCL INFO Channel 01 : 37[4b000] -> 36[31000] via P2P/IPC/read
305: hkn0629:1616367:1616506 [1] NCCL INFO Connected all trees
 42: hkn0414:2006114:2006224 [2] NCCL INFO comm 0x148298008fb0 rank 42 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
488: hkn0809:961652:961773 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:961652:961773 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1616367:1616506 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
168: hkn0523:1572589:1572686 [0] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [send] via NET/IBext/0
305: hkn0629:1616367:1616506 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 43: hkn0414:2006106:2006225 [3] NCCL INFO comm 0x148df0008fb0 rank 43 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
257: hkn0612:941317:941465 [1] NCCL INFO Channel 01 : 257[4b000] -> 256[31000] via P2P/IPC/read
356: hkn0708:437611:437707 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [send] via NET/IBext/0
 48: hkn0417:2292075:2292171 [0] NCCL INFO Connected all trees
 48: hkn0417:2292075:2292171 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 48: hkn0417:2292075:2292171 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
304: hkn0629:1616359:1616509 [0] NCCL INFO comm 0x148e54008fb0 rank 304 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
488: hkn0809:961652:961773 [0] NCCL INFO comm 0x14b85c008fb0 rank 488 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
306: hkn0629:1616375:1616505 [2] NCCL INFO comm 0x1506cc008fb0 rank 306 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
491: hkn0809:961660:961772 [3] NCCL INFO comm 0x14a994008fb0 rank 491 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
489: hkn0809:961668:961775 [1] NCCL INFO comm 0x148690008fb0 rank 489 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [receive] via NET/IBext/0
307: hkn0629:1616387:1616511 [3] NCCL INFO comm 0x151a5c008fb0 rank 307 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
490: hkn0809:961680:961778 [2] NCCL INFO comm 0x15337c008fb0 rank 490 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
305: hkn0629:1616367:1616506 [1] NCCL INFO comm 0x1538e4008fb0 rank 305 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 49: hkn0417:2292047:2292172 [1] NCCL INFO Connected all trees
 49: hkn0417:2292047:2292172 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 49: hkn0417:2292047:2292172 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 88: hkn0427:1159526:1159625 [0] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [send] via NET/IBext/0
384: hkn0716:132827:132967 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [receive] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [receive] via NET/IBext/0
476: hkn0806:1078676:1078786 [0] NCCL INFO Connected all trees
476: hkn0806:1078676:1078786 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 48: hkn0417:2292075:2292171 [0] NCCL INFO comm 0x14d794008fb0 rank 48 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 76: hkn0424:2972313:2972427 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [send] via NET/IBext/0
421: hkn0726:1572490:1572596 [1] NCCL INFO Channel 00 : 421[4b000] -> 420[31000] via P2P/IPC/read
476: hkn0806:1078676:1078786 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1322782:1322938 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [send] via NET/IBext/0
232: hkn0605:736552:736663 [0] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [send] via NET/IBext/0
 49: hkn0417:2292047:2292172 [1] NCCL INFO comm 0x152388008fb0 rank 49 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 50: hkn0417:2292055:2292170 [2] NCCL INFO comm 0x1470a0008fb0 rank 50 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 51: hkn0417:2292063:2292173 [3] NCCL INFO comm 0x150d9c008fb0 rank 51 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
104: hkn0503:2924170:2924284 [0] NCCL INFO Connected all trees
477: hkn0806:1078668:1078787 [1] NCCL INFO Connected all trees
101: hkn0502:253402:253515 [1] NCCL INFO Channel 00 : 101[4b000] -> 100[31000] via P2P/IPC/read
425: hkn0727:1370175:1370283 [1] NCCL INFO Connected all trees
104: hkn0503:2924170:2924284 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1078668:1078787 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
349: hkn0706:776624:776729 [1] NCCL INFO Connected all trees
425: hkn0727:1370175:1370283 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
104: hkn0503:2924170:2924284 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1078668:1078787 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1370175:1370283 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
381: hkn0715:426296:426395 [1] NCCL INFO Channel 00 : 381[4b000] -> 380[31000] via P2P/IPC/read
349: hkn0706:776624:776729 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
349: hkn0706:776624:776729 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [receive] via NET/IBext/0
221: hkn0602:3390370:3390573 [1] NCCL INFO Connected all trees
465: hkn0803:900978:901109 [1] NCCL INFO Connected all trees
221: hkn0602:3390370:3390573 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
424: hkn0727:1370187:1370280 [0] NCCL INFO Connected all trees
221: hkn0602:3390370:3390573 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2924190:2924283 [1] NCCL INFO Connected all trees
465: hkn0803:900978:901109 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
424: hkn0727:1370187:1370280 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:900978:901109 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:776612:776722 [0] NCCL INFO Connected all trees
424: hkn0727:1370187:1370280 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2924190:2924283 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
105: hkn0503:2924190:2924283 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
478: hkn0806:1078688:1078789 [2] NCCL INFO comm 0x14a994008fb0 rank 478 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
348: hkn0706:776612:776722 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:319436:319546 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [receive] via NET/IBext/0
164: hkn0521:1222169:1222292 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [send] via NET/IBext/0
348: hkn0706:776612:776722 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 37: hkn0413:2391086:2391193 [1] NCCL INFO Connected all trees
476: hkn0806:1078676:1078786 [0] NCCL INFO comm 0x149244008fb0 rank 476 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
220: hkn0602:3390398:3390575 [0] NCCL INFO Connected all trees
 37: hkn0413:2391086:2391193 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:253402:253515 [1] NCCL INFO Channel 01 : 101[4b000] -> 100[31000] via P2P/IPC/read
244: hkn0608:510064:510177 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [send] via NET/IBext/0
477: hkn0806:1078668:1078787 [1] NCCL INFO comm 0x1528fc008fb0 rank 477 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
220: hkn0602:3390398:3390575 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 37: hkn0413:2391086:2391193 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
464: hkn0803:901006:901108 [0] NCCL INFO Connected all trees
220: hkn0602:3390398:3390575 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
421: hkn0726:1572490:1572596 [1] NCCL INFO Channel 01 : 421[4b000] -> 420[31000] via P2P/IPC/read
479: hkn0806:1078660:1078785 [3] NCCL INFO comm 0x14e684008fb0 rank 479 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
464: hkn0803:901006:901108 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
464: hkn0803:901006:901108 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
104: hkn0503:2924170:2924284 [0] NCCL INFO comm 0x14f310008fb0 rank 104 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 36: hkn0413:2391098:2391192 [0] NCCL INFO Connected all trees
424: hkn0727:1370187:1370280 [0] NCCL INFO comm 0x14ebe4008fb0 rank 424 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
380: hkn0715:426268:426388 [0] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [send] via NET/IBext/0
105: hkn0503:2924190:2924283 [1] NCCL INFO comm 0x153dbc008fb0 rank 105 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
348: hkn0706:776612:776722 [0] NCCL INFO comm 0x14c288008fb0 rank 348 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 36: hkn0413:2391098:2391192 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
427: hkn0727:1370167:1370284 [3] NCCL INFO comm 0x14bc04008fb0 rank 427 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
381: hkn0715:426296:426395 [1] NCCL INFO Channel 01 : 381[4b000] -> 380[31000] via P2P/IPC/read
107: hkn0503:2924178:2924282 [3] NCCL INFO comm 0x14bc38008fb0 rank 107 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 36: hkn0413:2391098:2391192 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
426: hkn0727:1370159:1370281 [2] NCCL INFO comm 0x14aeb4008fb0 rank 426 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
349: hkn0706:776624:776729 [1] NCCL INFO comm 0x147044008fb0 rank 349 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
425: hkn0727:1370175:1370283 [1] NCCL INFO comm 0x154db8008fb0 rank 425 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
220: hkn0602:3390398:3390575 [0] NCCL INFO comm 0x149b64008fb0 rank 220 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
350: hkn0706:776596:776723 [2] NCCL INFO comm 0x1507cc008fb0 rank 350 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
351: hkn0706:776604:776726 [3] NCCL INFO comm 0x152a34008fb0 rank 351 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
100: hkn0502:253422:253519 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [send] via NET/IBext/0
106: hkn0503:2924162:2924287 [2] NCCL INFO comm 0x14939c008fb0 rank 106 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
221: hkn0602:3390370:3390573 [1] NCCL INFO comm 0x1535b0008fb0 rank 221 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 96: hkn0501:1352378:1352508 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [receive] via NET/IBext/0
222: hkn0602:3390386:3390580 [2] NCCL INFO comm 0x1453ec008fb0 rank 222 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
223: hkn0602:3390378:3390578 [3] NCCL INFO comm 0x1535c8008fb0 rank 223 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
256: hkn0612:941333:941464 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [receive] via NET/IBext/0
 36: hkn0413:2391098:2391192 [0] NCCL INFO comm 0x14fa00008fb0 rank 36 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
466: hkn0803:900986:901105 [2] NCCL INFO comm 0x152808008fb0 rank 466 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 39: hkn0413:2391070:2391199 [3] NCCL INFO comm 0x149168008fb0 rank 39 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
464: hkn0803:901006:901108 [0] NCCL INFO comm 0x1476fc008fb0 rank 464 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 38: hkn0413:2391078:2391198 [2] NCCL INFO comm 0x14e984008fb0 rank 38 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
357: hkn0708:437583:437699 [1] NCCL INFO Channel 00 : 357[4b000] -> 356[31000] via P2P/IPC/read
228: hkn0604:713559:713655 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [send] via NET/IBext/0
 37: hkn0413:2391086:2391193 [1] NCCL INFO comm 0x1539ac008fb0 rank 37 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
467: hkn0803:900994:901110 [3] NCCL INFO comm 0x152624008fb0 rank 467 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [receive] via NET/IBext/0
465: hkn0803:900978:901109 [1] NCCL INFO comm 0x14fadc008fb0 rank 465 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 33: hkn0412:2286731:2286842 [1] NCCL INFO Connected all trees
361: hkn0710:379895:380014 [1] NCCL INFO Connected all trees
 33: hkn0412:2286731:2286842 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
361: hkn0710:379895:380014 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 33: hkn0412:2286731:2286842 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:379895:380014 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2286739:2286849 [0] NCCL INFO Connected all trees
176: hkn0525:1011118:1011248 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [receive] via NET/IBext/0
433: hkn0730:1426045:1426192 [1] NCCL INFO Connected all trees
360: hkn0710:379903:380006 [0] NCCL INFO Connected all trees
357: hkn0708:437583:437699 [1] NCCL INFO Channel 01 : 357[4b000] -> 356[31000] via P2P/IPC/read
 32: hkn0412:2286739:2286849 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
433: hkn0730:1426045:1426192 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:379903:380006 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2286739:2286849 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1426045:1426192 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:379903:380006 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
352: hkn0707:4044320:4044416 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [receive] via NET/IBext/0
253: hkn0611:734158:734277 [1] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [receive] via NET/IBext/0
252: hkn0611:734178:734279 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [receive] via NET/IBext/0
420: hkn0726:1572502:1572595 [0] NCCL INFO Connected all trees
432: hkn0730:1426065:1426190 [0] NCCL INFO Connected all trees
420: hkn0726:1572502:1572595 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1426065:1426190 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
420: hkn0726:1572502:1572595 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
432: hkn0730:1426065:1426190 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 33: hkn0412:2286731:2286842 [1] NCCL INFO comm 0x14b944008fb0 rank 33 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
297: hkn0627:1812302:1812414 [1] NCCL INFO Connected all trees
 32: hkn0412:2286739:2286849 [0] NCCL INFO comm 0x148968008fb0 rank 32 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
360: hkn0710:379903:380006 [0] NCCL INFO comm 0x147f98008fb0 rank 360 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
297: hkn0627:1812302:1812414 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 34: hkn0412:2286727:2286850 [2] NCCL INFO comm 0x14b690008fb0 rank 34 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
297: hkn0627:1812302:1812414 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
363: hkn0710:379887:380008 [3] NCCL INFO comm 0x14ef64008fb0 rank 363 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 35: hkn0412:2286751:2286844 [3] NCCL INFO comm 0x154e2c008fb0 rank 35 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
293: hkn0626:1322798:1322932 [1] NCCL INFO Channel 00 : 293[4b000] -> 292[31000] via P2P/IPC/read
421: hkn0726:1572490:1572596 [1] NCCL INFO Connected all trees
361: hkn0710:379895:380014 [1] NCCL INFO comm 0x14dd6c008fb0 rank 361 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
362: hkn0710:379915:380012 [2] NCCL INFO comm 0x145940008fb0 rank 362 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
421: hkn0726:1572490:1572596 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
421: hkn0726:1572490:1572596 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
296: hkn0627:1812310:1812420 [0] NCCL INFO Connected all trees
296: hkn0627:1812310:1812420 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1426065:1426190 [0] NCCL INFO comm 0x1509f0008fb0 rank 432 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
434: hkn0730:1426053:1426183 [2] NCCL INFO comm 0x155078008fb0 rank 434 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
296: hkn0627:1812310:1812420 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1426045:1426192 [1] NCCL INFO comm 0x14e3cc008fb0 rank 433 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
435: hkn0730:1426037:1426189 [3] NCCL INFO comm 0x154b50008fb0 rank 435 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
420: hkn0726:1572502:1572595 [0] NCCL INFO comm 0x152d10008fb0 rank 420 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
421: hkn0726:1572490:1572596 [1] NCCL INFO comm 0x1455d8008fb0 rank 421 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
417: hkn0725:3136312:3136416 [1] NCCL INFO Connected all trees
298: hkn0627:1812322:1812413 [2] NCCL INFO comm 0x152cd0008fb0 rank 298 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
423: hkn0726:1572482:1572597 [3] NCCL INFO comm 0x14a8a4008fb0 rank 423 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
417: hkn0725:3136312:3136416 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
296: hkn0627:1812310:1812420 [0] NCCL INFO comm 0x148d9c008fb0 rank 296 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
417: hkn0725:3136312:3136416 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
297: hkn0627:1812302:1812414 [1] NCCL INFO comm 0x1472d4008fb0 rank 297 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
422: hkn0726:1572474:1572594 [2] NCCL INFO comm 0x14a934008fb0 rank 422 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
299: hkn0627:1812294:1812419 [3] NCCL INFO comm 0x149588008fb0 rank 299 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
188: hkn0528:1326072:1326164 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [send] via NET/IBext/0
472: hkn0805:1136489:1136590 [0] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [send] via NET/IBext/0
416: hkn0725:3136304:3136419 [0] NCCL INFO Connected all trees
165: hkn0521:1222177:1222293 [1] NCCL INFO Channel 00 : 165[4b000] -> 164[31000] via P2P/IPC/read
416: hkn0725:3136304:3136419 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
416: hkn0725:3136304:3136419 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1322798:1322932 [1] NCCL INFO Channel 01 : 293[4b000] -> 292[31000] via P2P/IPC/read
169: hkn0523:1572569:1572689 [1] NCCL INFO Connected all trees
169: hkn0523:1572569:1572689 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
332: hkn0636:1678716:1678871 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [send] via NET/IBext/0
169: hkn0523:1572569:1572689 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3136312:3136416 [1] NCCL INFO comm 0x1500d4008fb0 rank 417 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
416: hkn0725:3136304:3136419 [0] NCCL INFO comm 0x15506c008fb0 rank 416 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [receive] via NET/IBext/0
418: hkn0725:3136324:3136423 [2] NCCL INFO comm 0x147444008fb0 rank 418 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
460: hkn0802:1224720:1224848 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [send] via NET/IBext/0
419: hkn0725:3136296:3136421 [3] NCCL INFO comm 0x152774008fb0 rank 419 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
344: hkn0705:807566:807679 [0] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [send] via NET/IBext/0
216: hkn0601:142244:142342 [0] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [send] via NET/IBext/0
165: hkn0521:1222177:1222293 [1] NCCL INFO Channel 01 : 165[4b000] -> 164[31000] via P2P/IPC/read
229: hkn0604:713547:713656 [1] NCCL INFO Channel 00 : 229[4b000] -> 228[31000] via P2P/IPC/read
 88: hkn0427:1159526:1159625 [0] NCCL INFO Connected all trees
 85: hkn0426:838392:838518 [1] NCCL INFO Channel 00 : 85[4b000] -> 84[31000] via P2P/IPC/read
204: hkn0532:950481:950779 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [send] via NET/IBext/0
 88: hkn0427:1159526:1159625 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 88: hkn0427:1159526:1159625 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 89: hkn0427:1159514:1159627 [1] NCCL INFO Connected all trees
233: hkn0605:736560:736669 [1] NCCL INFO Connected all trees
168: hkn0523:1572589:1572686 [0] NCCL INFO Connected all trees
 89: hkn0427:1159514:1159627 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 00 : 73[4b000] -> 72[31000] via P2P/IPC/read
233: hkn0605:736560:736669 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 89: hkn0427:1159514:1159627 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1572589:1572686 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
233: hkn0605:736560:736669 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1572589:1572686 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2972313:2972427 [0] NCCL INFO Connected all trees
 76: hkn0424:2972313:2972427 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1413747:1413848 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [send] via NET/IBext/0
 76: hkn0424:2972313:2972427 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 85: hkn0426:838392:838518 [1] NCCL INFO Channel 01 : 85[4b000] -> 84[31000] via P2P/IPC/read
232: hkn0605:736552:736663 [0] NCCL INFO Connected all trees
232: hkn0605:736552:736663 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
232: hkn0605:736552:736663 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 88: hkn0427:1159526:1159625 [0] NCCL INFO comm 0x14c42c008fb0 rank 88 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 89: hkn0427:1159514:1159627 [1] NCCL INFO comm 0x14d300008fb0 rank 89 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 91: hkn0427:1159506:1159619 [3] NCCL INFO comm 0x14cf9c008fb0 rank 91 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
169: hkn0523:1572569:1572689 [1] NCCL INFO comm 0x14952c008fb0 rank 169 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 77: hkn0424:2972305:2972428 [1] NCCL INFO Connected all trees
 90: hkn0427:1159498:1159622 [2] NCCL INFO comm 0x1485c4008fb0 rank 90 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 77: hkn0424:2972305:2972428 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1729402:1729514 [1] NCCL INFO Channel 01 : 73[4b000] -> 72[31000] via P2P/IPC/read
168: hkn0523:1572589:1572686 [0] NCCL INFO comm 0x14ef0c008fb0 rank 168 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 77: hkn0424:2972305:2972428 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
170: hkn0523:1572577:1572685 [2] NCCL INFO comm 0x146630008fb0 rank 170 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
171: hkn0523:1572561:1572684 [3] NCCL INFO comm 0x15021c008fb0 rank 171 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
229: hkn0604:713547:713656 [1] NCCL INFO Channel 01 : 229[4b000] -> 228[31000] via P2P/IPC/read
233: hkn0605:736560:736669 [1] NCCL INFO comm 0x1519a0008fb0 rank 233 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
293: hkn0626:1322798:1322932 [1] NCCL INFO Connected all trees
293: hkn0626:1322798:1322932 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
293: hkn0626:1322798:1322932 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:736552:736663 [0] NCCL INFO comm 0x14cadc008fb0 rank 232 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 76: hkn0424:2972313:2972427 [0] NCCL INFO comm 0x154bf4008fb0 rank 76 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
235: hkn0605:736572:736668 [3] NCCL INFO comm 0x146ac0008fb0 rank 235 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [receive] via NET/IBext/0
234: hkn0605:736544:736667 [2] NCCL INFO comm 0x14f7bc008fb0 rank 234 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 77: hkn0424:2972305:2972428 [1] NCCL INFO comm 0x149560008fb0 rank 77 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
292: hkn0626:1322782:1322938 [0] NCCL INFO Connected all trees
 78: hkn0424:2972321:2972426 [2] NCCL INFO comm 0x14e3b8008fb0 rank 78 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
292: hkn0626:1322782:1322938 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 79: hkn0424:2972333:2972431 [3] NCCL INFO comm 0x14a404008fb0 rank 79 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
292: hkn0626:1322782:1322938 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
101: hkn0502:253402:253515 [1] NCCL INFO Connected all trees
101: hkn0502:253402:253515 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:253402:253515 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1322782:1322938 [0] NCCL INFO comm 0x1546b0008fb0 rank 292 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
293: hkn0626:1322798:1322932 [1] NCCL INFO comm 0x149884008fb0 rank 293 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
100: hkn0502:253422:253519 [0] NCCL INFO Connected all trees
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [receive] via NET/IBext/0
100: hkn0502:253422:253519 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 84: hkn0426:838364:838519 [0] NCCL INFO Connected all trees
294: hkn0626:1322810:1322935 [2] NCCL INFO comm 0x154ab4008fb0 rank 294 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
100: hkn0502:253422:253519 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [receive] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
295: hkn0626:1322790:1322933 [3] NCCL INFO comm 0x14e73c008fb0 rank 295 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [receive] via NET/IBext/0
 84: hkn0426:838364:838519 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [receive] via NET/IBext/0
289: hkn0624:1797266:1797383 [1] NCCL INFO Connected all trees
165: hkn0521:1222177:1222293 [1] NCCL INFO Connected all trees
 85: hkn0426:838392:838518 [1] NCCL INFO Connected all trees
289: hkn0624:1797266:1797383 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:253402:253515 [1] NCCL INFO comm 0x14fa20008fb0 rank 101 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
289: hkn0624:1797266:1797383 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
165: hkn0521:1222177:1222293 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:838392:838518 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:253422:253519 [0] NCCL INFO comm 0x151aa8008fb0 rank 100 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
165: hkn0521:1222177:1222293 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 85: hkn0426:838392:838518 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
102: hkn0502:253394:253516 [2] NCCL INFO comm 0x14596c008fb0 rank 102 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
103: hkn0502:253410:253517 [3] NCCL INFO comm 0x145aac008fb0 rank 103 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [send] via NET/IBext/0
288: hkn0624:1797296:1797392 [0] NCCL INFO Connected all trees
357: hkn0708:437583:437699 [1] NCCL INFO Connected all trees
288: hkn0624:1797296:1797392 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
164: hkn0521:1222169:1222292 [0] NCCL INFO Connected all trees
288: hkn0624:1797296:1797392 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1222169:1222292 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
164: hkn0521:1222169:1222292 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:437583:437699 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
357: hkn0708:437583:437699 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 84: hkn0426:838364:838519 [0] NCCL INFO comm 0x15144c008fb0 rank 84 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
252: hkn0611:734178:734279 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [send] via NET/IBext/0
356: hkn0708:437611:437707 [0] NCCL INFO Connected all trees
356: hkn0708:437611:437707 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 86: hkn0426:838372:838511 [2] NCCL INFO comm 0x14ff14008fb0 rank 86 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 85: hkn0426:838392:838518 [1] NCCL INFO comm 0x14a484008fb0 rank 85 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 87: hkn0426:838380:838520 [3] NCCL INFO comm 0x14a76c008fb0 rank 87 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
253: hkn0611:734158:734277 [1] NCCL INFO Channel 00 : 253[4b000] -> 252[31000] via P2P/IPC/read
289: hkn0624:1797266:1797383 [1] NCCL INFO comm 0x151a18008fb0 rank 289 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
356: hkn0708:437611:437707 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
165: hkn0521:1222177:1222293 [1] NCCL INFO comm 0x14b818008fb0 rank 165 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
290: hkn0624:1797282:1797386 [2] NCCL INFO comm 0x1527d0008fb0 rank 290 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
288: hkn0624:1797296:1797392 [0] NCCL INFO comm 0x14dc98008fb0 rank 288 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
291: hkn0624:1797274:1797389 [3] NCCL INFO comm 0x14d06c008fb0 rank 291 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [send] via NET/IBext/0
164: hkn0521:1222169:1222292 [0] NCCL INFO comm 0x1489a0008fb0 rank 164 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
167: hkn0521:1222197:1222291 [3] NCCL INFO comm 0x150190008fb0 rank 167 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
166: hkn0521:1222185:1222296 [2] NCCL INFO comm 0x153938008fb0 rank 166 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
356: hkn0708:437611:437707 [0] NCCL INFO comm 0x147fd8008fb0 rank 356 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
357: hkn0708:437583:437699 [1] NCCL INFO comm 0x145898008fb0 rank 357 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
359: hkn0708:437591:437704 [3] NCCL INFO comm 0x14bb64008fb0 rank 359 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
188: hkn0528:1326072:1326164 [0] NCCL INFO Connected all trees
188: hkn0528:1326072:1326164 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1230034:1230144 [1] NCCL INFO Channel 00 : 469[4b000] -> 468[31000] via P2P/IPC/read
358: hkn0708:437599:437701 [2] NCCL INFO comm 0x1520a8008fb0 rank 358 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 96: hkn0501:1352378:1352508 [0] NCCL INFO Connected all trees
188: hkn0528:1326072:1326164 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 96: hkn0501:1352378:1352508 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 96: hkn0501:1352378:1352508 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
112: hkn0505:2328135:2328264 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [receive] via NET/IBext/0
384: hkn0716:132827:132967 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [receive] via NET/IBext/0
253: hkn0611:734158:734277 [1] NCCL INFO Channel 01 : 253[4b000] -> 252[31000] via P2P/IPC/read
473: hkn0805:1136469:1136586 [1] NCCL INFO Connected all trees
376: hkn0714:456371:456476 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [receive] via NET/IBext/0
161: hkn0520:2737231:2737367 [1] NCCL INFO Connected all trees
473: hkn0805:1136469:1136586 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
473: hkn0805:1136469:1136586 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
161: hkn0520:2737231:2737367 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2737231:2737367 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 97: hkn0501:1352406:1352507 [1] NCCL INFO Connected all trees
189: hkn0528:1326044:1326167 [1] NCCL INFO Connected all trees
 97: hkn0501:1352406:1352507 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
189: hkn0528:1326044:1326167 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 97: hkn0501:1352406:1352507 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1326044:1326167 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1678716:1678871 [0] NCCL INFO Connected all trees
332: hkn0636:1678716:1678871 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1230034:1230144 [1] NCCL INFO Channel 01 : 469[4b000] -> 468[31000] via P2P/IPC/read
472: hkn0805:1136489:1136590 [0] NCCL INFO Connected all trees
160: hkn0520:2737215:2737368 [0] NCCL INFO Connected all trees
332: hkn0636:1678716:1678871 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1136489:1136590 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
160: hkn0520:2737215:2737368 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1136489:1136590 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
353: hkn0707:4044300:4044417 [1] NCCL INFO Connected all trees
160: hkn0520:2737215:2737368 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
353: hkn0707:4044300:4044417 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
353: hkn0707:4044300:4044417 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
460: hkn0802:1224720:1224848 [0] NCCL INFO Connected all trees
191: hkn0528:1326052:1326169 [3] NCCL INFO comm 0x147844008fb0 rank 191 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 72: hkn0423:1729386:1729506 [0] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [send] via NET/IBext/0
 96: hkn0501:1352378:1352508 [0] NCCL INFO comm 0x14b48c008fb0 rank 96 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
460: hkn0802:1224720:1224848 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:1011146:1011240 [1] NCCL INFO Connected all trees
333: hkn0636:1678744:1678868 [1] NCCL INFO Connected all trees
190: hkn0528:1326060:1326165 [2] NCCL INFO comm 0x15246c008fb0 rank 190 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
460: hkn0802:1224720:1224848 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 98: hkn0501:1352394:1352503 [2] NCCL INFO comm 0x146fa8008fb0 rank 98 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
188: hkn0528:1326072:1326164 [0] NCCL INFO comm 0x154be8008fb0 rank 188 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
205: hkn0532:950469:950780 [1] NCCL INFO Connected all trees
352: hkn0707:4044320:4044416 [0] NCCL INFO Connected all trees
177: hkn0525:1011146:1011240 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
333: hkn0636:1678744:1678868 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 97: hkn0501:1352406:1352507 [1] NCCL INFO comm 0x151a90008fb0 rank 97 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
189: hkn0528:1326044:1326167 [1] NCCL INFO comm 0x14b4e4008fb0 rank 189 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
177: hkn0525:1011146:1011240 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
333: hkn0636:1678744:1678868 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 99: hkn0501:1352386:1352510 [3] NCCL INFO comm 0x14c8d4008fb0 rank 99 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
205: hkn0532:950469:950780 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
341: hkn0704:816354:816450 [1] NCCL INFO Channel 00 : 341[4b000] -> 340[31000] via P2P/IPC/read
352: hkn0707:4044320:4044416 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4044320:4044416 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1136489:1136590 [0] NCCL INFO comm 0x150d7c008fb0 rank 472 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
205: hkn0532:950469:950780 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:426268:426388 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [send] via NET/IBext/0
461: hkn0802:1224708:1224841 [1] NCCL INFO Connected all trees
176: hkn0525:1011118:1011248 [0] NCCL INFO Connected all trees
473: hkn0805:1136469:1136586 [1] NCCL INFO comm 0x148ffc008fb0 rank 473 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
204: hkn0532:950481:950779 [0] NCCL INFO Connected all trees
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 00 : 329[4b000] -> 328[31000] via P2P/IPC/read
163: hkn0520:2737223:2737364 [3] NCCL INFO comm 0x154c8c008fb0 rank 163 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
217: hkn0601:142232:142341 [1] NCCL INFO Connected all trees
213: hkn0535:2423328:2423441 [1] NCCL INFO Channel 00 : 213[4b000] -> 212[31000] via P2P/IPC/read
461: hkn0802:1224708:1224841 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
345: hkn0705:807558:807678 [1] NCCL INFO Connected all trees
176: hkn0525:1011118:1011248 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 00 : 457[4b000] -> 456[31000] via P2P/IPC/read
475: hkn0805:1136477:1136585 [3] NCCL INFO comm 0x1533c4008fb0 rank 475 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
204: hkn0532:950481:950779 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:1011118:1011248 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
217: hkn0601:142232:142341 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
204: hkn0532:950481:950779 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2737215:2737368 [0] NCCL INFO comm 0x14a968008fb0 rank 160 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
461: hkn0802:1224708:1224841 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
345: hkn0705:807558:807678 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
332: hkn0636:1678716:1678871 [0] NCCL INFO comm 0x15082c008fb0 rank 332 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
474: hkn0805:1136461:1136592 [2] NCCL INFO comm 0x149f64008fb0 rank 474 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
217: hkn0601:142232:142341 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
345: hkn0705:807558:807678 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
161: hkn0520:2737231:2737367 [1] NCCL INFO comm 0x1488cc008fb0 rank 161 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
334: hkn0636:1678724:1678867 [2] NCCL INFO comm 0x14cc6c008fb0 rank 334 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
352: hkn0707:4044320:4044416 [0] NCCL INFO comm 0x1491a0008fb0 rank 352 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
162: hkn0520:2737243:2737371 [2] NCCL INFO comm 0x148170008fb0 rank 162 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
333: hkn0636:1678744:1678868 [1] NCCL INFO comm 0x14d5c0008fb0 rank 333 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
353: hkn0707:4044300:4044417 [1] NCCL INFO comm 0x14db98008fb0 rank 353 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
216: hkn0601:142244:142342 [0] NCCL INFO Connected all trees
344: hkn0705:807566:807679 [0] NCCL INFO Connected all trees
335: hkn0636:1678732:1678872 [3] NCCL INFO comm 0x14d928008fb0 rank 335 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
354: hkn0707:4044308:4044418 [2] NCCL INFO comm 0x147298008fb0 rank 354 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
216: hkn0601:142244:142342 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
341: hkn0704:816354:816450 [1] NCCL INFO Channel 01 : 341[4b000] -> 340[31000] via P2P/IPC/read
344: hkn0705:807566:807679 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
216: hkn0601:142244:142342 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:950481:950779 [0] NCCL INFO comm 0x14b300008fb0 rank 204 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
355: hkn0707:4044292:4044419 [3] NCCL INFO comm 0x14d994008fb0 rank 355 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
344: hkn0705:807566:807679 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
176: hkn0525:1011118:1011248 [0] NCCL INFO comm 0x153958008fb0 rank 176 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
368: hkn0712:319436:319546 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [receive] via NET/IBext/0
205: hkn0532:950469:950780 [1] NCCL INFO comm 0x148f30008fb0 rank 205 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
445: hkn0733:1413727:1413845 [1] NCCL INFO Connected all trees
178: hkn0525:1011134:1011249 [2] NCCL INFO comm 0x149df4008fb0 rank 178 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
460: hkn0802:1224720:1224848 [0] NCCL INFO comm 0x14cc4c008fb0 rank 460 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
177: hkn0525:1011146:1011240 [1] NCCL INFO comm 0x1527a4008fb0 rank 177 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
206: hkn0532:950453:950783 [2] NCCL INFO comm 0x151bc0008fb0 rank 206 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
445: hkn0733:1413727:1413845 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 00 : 201[4b000] -> 200[31000] via P2P/IPC/read
445: hkn0733:1413727:1413845 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
329: hkn0635:1249898:1250021 [1] NCCL INFO Channel 01 : 329[4b000] -> 328[31000] via P2P/IPC/read
462: hkn0802:1224692:1224849 [2] NCCL INFO comm 0x150738008fb0 rank 462 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
179: hkn0525:1011126:1011245 [3] NCCL INFO comm 0x147a58008fb0 rank 179 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
207: hkn0532:950461:950778 [3] NCCL INFO comm 0x154f08008fb0 rank 207 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
213: hkn0535:2423328:2423441 [1] NCCL INFO Channel 01 : 213[4b000] -> 212[31000] via P2P/IPC/read
457: hkn0801:2264557:2264657 [1] NCCL INFO Channel 01 : 457[4b000] -> 456[31000] via P2P/IPC/read
344: hkn0705:807566:807679 [0] NCCL INFO comm 0x14a09c008fb0 rank 344 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
216: hkn0601:142244:142342 [0] NCCL INFO comm 0x14f10c008fb0 rank 216 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
444: hkn0733:1413747:1413848 [0] NCCL INFO Connected all trees
347: hkn0705:807550:807681 [3] NCCL INFO comm 0x151abc008fb0 rank 347 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
219: hkn0601:142224:142344 [3] NCCL INFO comm 0x145588008fb0 rank 219 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
444: hkn0733:1413747:1413848 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
345: hkn0705:807558:807678 [1] NCCL INFO comm 0x1526f0008fb0 rank 345 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
444: hkn0733:1413747:1413848 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
463: hkn0802:1224700:1224850 [3] NCCL INFO comm 0x14d71c008fb0 rank 463 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
346: hkn0705:807578:807672 [2] NCCL INFO comm 0x148e58008fb0 rank 346 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
217: hkn0601:142232:142341 [1] NCCL INFO comm 0x14ba98008fb0 rank 217 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
218: hkn0601:142216:142337 [2] NCCL INFO comm 0x14ca84008fb0 rank 218 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
461: hkn0802:1224708:1224841 [1] NCCL INFO comm 0x14afec008fb0 rank 461 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
468: hkn0804:1230018:1230142 [0] NCCL INFO Connected all trees
468: hkn0804:1230018:1230142 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
468: hkn0804:1230018:1230142 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
201: hkn0531:1255130:1255248 [1] NCCL INFO Channel 01 : 201[4b000] -> 200[31000] via P2P/IPC/read
444: hkn0733:1413747:1413848 [0] NCCL INFO comm 0x147bd4008fb0 rank 444 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 68: hkn0422:4177469:4177594 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [send] via NET/IBext/0
445: hkn0733:1413727:1413845 [1] NCCL INFO comm 0x153a68008fb0 rank 445 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
469: hkn0804:1230034:1230144 [1] NCCL INFO Connected all trees
469: hkn0804:1230034:1230144 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1230034:1230144 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
446: hkn0733:1413719:1413842 [2] NCCL INFO comm 0x152640008fb0 rank 446 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
447: hkn0733:1413735:1413846 [3] NCCL INFO comm 0x1488b8008fb0 rank 447 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
469: hkn0804:1230034:1230144 [1] NCCL INFO comm 0x152018008fb0 rank 469 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
470: hkn0804:1230046:1230140 [2] NCCL INFO comm 0x14a648008fb0 rank 470 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
468: hkn0804:1230018:1230142 [0] NCCL INFO comm 0x1477cc008fb0 rank 468 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
471: hkn0804:1230026:1230141 [3] NCCL INFO comm 0x155384008fb0 rank 471 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
340: hkn0704:816342:816447 [0] NCCL INFO Connected all trees
340: hkn0704:816342:816447 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:816342:816447 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
213: hkn0535:2423328:2423441 [1] NCCL INFO Connected all trees
213: hkn0535:2423328:2423441 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
341: hkn0704:816354:816450 [1] NCCL INFO Connected all trees
213: hkn0535:2423328:2423441 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:816354:816450 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
341: hkn0704:816354:816450 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
212: hkn0535:2423336:2423447 [0] NCCL INFO Connected all trees
212: hkn0535:2423336:2423447 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
212: hkn0535:2423336:2423447 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1373322:1373423 [0] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [send] via NET/IBext/0
340: hkn0704:816342:816447 [0] NCCL INFO comm 0x14cefc008fb0 rank 340 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
341: hkn0704:816354:816450 [1] NCCL INFO comm 0x150da8008fb0 rank 341 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
343: hkn0704:816334:816453 [3] NCCL INFO comm 0x14be34008fb0 rank 343 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
342: hkn0704:816326:816455 [2] NCCL INFO comm 0x14be00008fb0 rank 342 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
213: hkn0535:2423328:2423441 [1] NCCL INFO comm 0x14df94008fb0 rank 213 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
215: hkn0535:2423320:2423450 [3] NCCL INFO comm 0x152268008fb0 rank 215 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
214: hkn0535:2423350:2423446 [2] NCCL INFO comm 0x1470b8008fb0 rank 214 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
212: hkn0535:2423336:2423447 [0] NCCL INFO comm 0x146164008fb0 rank 212 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
128: hkn0509:3148759:3148874 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [receive] via NET/IBext/0
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [receive] via NET/IBext/0
328: hkn0635:1249926:1250020 [0] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [send] via NET/IBext/0
456: hkn0801:2264545:2264656 [0] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [send] via NET/IBext/0
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [receive] via NET/IBext/0
 69: hkn0422:4177485:4177589 [1] NCCL INFO Channel 00 : 69[4b000] -> 68[31000] via P2P/IPC/read
200: hkn0531:1255150:1255251 [0] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [send] via NET/IBext/0
412: hkn0724:1740321:1740477 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [send] via NET/IBext/0
 73: hkn0423:1729402:1729514 [1] NCCL INFO Connected all trees
 73: hkn0423:1729402:1729514 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1729402:1729514 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 72: hkn0423:1729386:1729506 [0] NCCL INFO Connected all trees
 72: hkn0423:1729386:1729506 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 72: hkn0423:1729386:1729506 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4177485:4177589 [1] NCCL INFO Channel 01 : 69[4b000] -> 68[31000] via P2P/IPC/read
 73: hkn0423:1729402:1729514 [1] NCCL INFO comm 0x14fd4c008fb0 rank 73 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 74: hkn0423:1729414:1729511 [2] NCCL INFO comm 0x147cb8008fb0 rank 74 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 72: hkn0423:1729386:1729506 [0] NCCL INFO comm 0x15345c008fb0 rank 72 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 75: hkn0423:1729394:1729515 [3] NCCL INFO comm 0x14a22c008fb0 rank 75 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
452: hkn0736:1532636:1532735 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [send] via NET/IBext/0
448: hkn0734:1180893:1180999 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [receive] via NET/IBext/0
113: hkn0505:2328151:2328263 [1] NCCL INFO Connected all trees
440: hkn0732:1236033:1236129 [0] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [send] via NET/IBext/0
113: hkn0505:2328151:2328263 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2328151:2328263 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:426268:426388 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [send] via NET/IBext/0
324: hkn0634:1545221:1545345 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [send] via NET/IBext/0
196: hkn0530:1282482:1282590 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [send] via NET/IBext/0
112: hkn0505:2328135:2328264 [0] NCCL INFO Connected all trees
112: hkn0505:2328135:2328264 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [send] via NET/IBext/0
112: hkn0505:2328135:2328264 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4177485:4177589 [1] NCCL INFO Connected all trees
114: hkn0505:2328143:2328257 [2] NCCL INFO comm 0x154458008fb0 rank 114 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 69: hkn0422:4177485:4177589 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2328135:2328264 [0] NCCL INFO comm 0x1533b0008fb0 rank 112 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 69: hkn0422:4177485:4177589 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
113: hkn0505:2328151:2328263 [1] NCCL INFO comm 0x14c0dc008fb0 rank 113 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
252: hkn0611:734178:734279 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [send] via NET/IBext/0
115: hkn0505:2328163:2328258 [3] NCCL INFO comm 0x145604008fb0 rank 115 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
369: hkn0712:319420:319542 [1] NCCL INFO Connected all trees
 68: hkn0422:4177469:4177594 [0] NCCL INFO Connected all trees
369: hkn0712:319420:319542 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:319420:319542 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4177469:4177594 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2940342:2940437 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [send] via NET/IBext/0
 68: hkn0422:4177469:4177594 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1452758:1452883 [1] NCCL INFO Channel 00 : 181[4b000] -> 180[31000] via P2P/IPC/read
368: hkn0712:319436:319546 [0] NCCL INFO Connected all trees
368: hkn0712:319436:319546 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:319436:319546 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
185: hkn0527:1373310:1373415 [1] NCCL INFO Connected all trees
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [send] via NET/IBext/0
185: hkn0527:1373310:1373415 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 64: hkn0421:2208719:2208879 [0] NCCL INFO Connected all trees
185: hkn0527:1373310:1373415 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4177469:4177594 [0] NCCL INFO comm 0x14b258008fb0 rank 68 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 64: hkn0421:2208719:2208879 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
508: hkn0816:399946:400046 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [send] via NET/IBext/0
 64: hkn0421:2208719:2208879 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 70: hkn0422:4177477:4177595 [2] NCCL INFO comm 0x152924008fb0 rank 70 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 69: hkn0422:4177485:4177589 [1] NCCL INFO comm 0x14d724008fb0 rank 69 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 71: hkn0422:4177497:4177588 [3] NCCL INFO comm 0x149528008fb0 rank 71 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
184: hkn0527:1373322:1373423 [0] NCCL INFO Connected all trees
184: hkn0527:1373322:1373423 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:319436:319546 [0] NCCL INFO comm 0x14d5b8008fb0 rank 368 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
181: hkn0526:1452758:1452883 [1] NCCL INFO Channel 01 : 181[4b000] -> 180[31000] via P2P/IPC/read
184: hkn0527:1373322:1373423 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
371: hkn0712:319428:319537 [3] NCCL INFO comm 0x1497ac008fb0 rank 371 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 65: hkn0421:2208731:2208877 [1] NCCL INFO Connected all trees
369: hkn0712:319420:319542 [1] NCCL INFO comm 0x148788008fb0 rank 369 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 65: hkn0421:2208731:2208877 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [send] via NET/IBext/0
370: hkn0712:319448:319543 [2] NCCL INFO comm 0x148718008fb0 rank 370 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 65: hkn0421:2208731:2208877 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
186: hkn0527:1373294:1373422 [2] NCCL INFO comm 0x14e79c008fb0 rank 186 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
185: hkn0527:1373310:1373415 [1] NCCL INFO comm 0x14d534008fb0 rank 185 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
184: hkn0527:1373322:1373423 [0] NCCL INFO comm 0x146f24008fb0 rank 184 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 67: hkn0421:2208711:2208878 [3] NCCL INFO comm 0x14df58008fb0 rank 67 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
187: hkn0527:1373302:1373417 [3] NCCL INFO comm 0x14a754008fb0 rank 187 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 64: hkn0421:2208719:2208879 [0] NCCL INFO comm 0x14a918008fb0 rank 64 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
329: hkn0635:1249898:1250021 [1] NCCL INFO Connected all trees
 65: hkn0421:2208731:2208877 [1] NCCL INFO comm 0x14e330008fb0 rank 65 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 66: hkn0421:2208703:2208881 [2] NCCL INFO comm 0x149a2c008fb0 rank 66 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
329: hkn0635:1249898:1250021 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
329: hkn0635:1249898:1250021 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1532616:1532726 [1] NCCL INFO Channel 00 : 453[4b000] -> 452[31000] via P2P/IPC/read
328: hkn0635:1249926:1250020 [0] NCCL INFO Connected all trees
328: hkn0635:1249926:1250020 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1249926:1250020 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
457: hkn0801:2264557:2264657 [1] NCCL INFO Connected all trees
457: hkn0801:2264557:2264657 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1740329:1740471 [1] NCCL INFO Connected all trees
457: hkn0801:2264557:2264657 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
200: hkn0531:1255150:1255251 [0] NCCL INFO Connected all trees
197: hkn0530:1282466:1282581 [1] NCCL INFO Channel 00 : 197[4b000] -> 196[31000] via P2P/IPC/read
413: hkn0724:1740329:1740471 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
200: hkn0531:1255150:1255251 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1740329:1740471 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
456: hkn0801:2264545:2264656 [0] NCCL INFO Connected all trees
328: hkn0635:1249926:1250020 [0] NCCL INFO comm 0x1508d4008fb0 rank 328 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
200: hkn0531:1255150:1255251 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
456: hkn0801:2264545:2264656 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
330: hkn0635:1249906:1250023 [2] NCCL INFO comm 0x1505b0008fb0 rank 330 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
456: hkn0801:2264545:2264656 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
331: hkn0635:1249914:1250018 [3] NCCL INFO comm 0x14e1e4008fb0 rank 331 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
412: hkn0724:1740321:1740477 [0] NCCL INFO Connected all trees
329: hkn0635:1249898:1250021 [1] NCCL INFO comm 0x145b78008fb0 rank 329 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
325: hkn0634:1545237:1545343 [1] NCCL INFO Channel 00 : 325[4b000] -> 324[31000] via P2P/IPC/read
181: hkn0526:1452758:1452883 [1] NCCL INFO Connected all trees
181: hkn0526:1452758:1452883 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
181: hkn0526:1452758:1452883 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
201: hkn0531:1255130:1255248 [1] NCCL INFO Connected all trees
412: hkn0724:1740321:1740477 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
201: hkn0531:1255130:1255248 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
412: hkn0724:1740321:1740477 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
201: hkn0531:1255130:1255248 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
458: hkn0801:2264537:2264649 [2] NCCL INFO comm 0x145e5c008fb0 rank 458 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
459: hkn0801:2264529:2264651 [3] NCCL INFO comm 0x15200c008fb0 rank 459 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
456: hkn0801:2264545:2264656 [0] NCCL INFO comm 0x14d8c4008fb0 rank 456 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
180: hkn0526:1452766:1452877 [0] NCCL INFO Connected all trees
197: hkn0530:1282466:1282581 [1] NCCL INFO Channel 01 : 197[4b000] -> 196[31000] via P2P/IPC/read
453: hkn0736:1532616:1532726 [1] NCCL INFO Channel 01 : 453[4b000] -> 452[31000] via P2P/IPC/read
457: hkn0801:2264557:2264657 [1] NCCL INFO comm 0x14c050008fb0 rank 457 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
415: hkn0724:1740349:1740479 [3] NCCL INFO comm 0x1539e0008fb0 rank 415 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
180: hkn0526:1452766:1452877 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
180: hkn0526:1452766:1452877 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
412: hkn0724:1740321:1740477 [0] NCCL INFO comm 0x14d1a8008fb0 rank 412 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
201: hkn0531:1255130:1255248 [1] NCCL INFO comm 0x15154c008fb0 rank 201 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
414: hkn0724:1740337:1740474 [2] NCCL INFO comm 0x149780008fb0 rank 414 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
413: hkn0724:1740329:1740471 [1] NCCL INFO comm 0x152650008fb0 rank 413 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
200: hkn0531:1255150:1255251 [0] NCCL INFO comm 0x1460a0008fb0 rank 200 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
202: hkn0531:1255138:1255243 [2] NCCL INFO comm 0x148dbc008fb0 rank 202 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
182: hkn0526:1452774:1452881 [2] NCCL INFO comm 0x149674008fb0 rank 182 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
180: hkn0526:1452766:1452877 [0] NCCL INFO comm 0x14cfdc008fb0 rank 180 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
325: hkn0634:1545237:1545343 [1] NCCL INFO Channel 01 : 325[4b000] -> 324[31000] via P2P/IPC/read
181: hkn0526:1452758:1452883 [1] NCCL INFO comm 0x150ebc008fb0 rank 181 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
183: hkn0526:1452786:1452878 [3] NCCL INFO comm 0x14b454008fb0 rank 183 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
437: hkn0731:1411116:1411213 [1] NCCL INFO Channel 00 : 437[4b000] -> 436[31000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [receive] via NET/IBext/0
381: hkn0715:426296:426395 [1] NCCL INFO Connected all trees
381: hkn0715:426296:426395 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
381: hkn0715:426296:426395 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:426268:426388 [0] NCCL INFO Connected all trees
380: hkn0715:426268:426388 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:426268:426388 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
203: hkn0531:1255122:1255246 [3] NCCL INFO comm 0x14e35c008fb0 rank 203 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
437: hkn0731:1411116:1411213 [1] NCCL INFO Channel 01 : 437[4b000] -> 436[31000] via P2P/IPC/read
453: hkn0736:1532616:1532726 [1] NCCL INFO Connected all trees
453: hkn0736:1532616:1532726 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:718245:718354 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [receive] via NET/IBext/0
380: hkn0715:426268:426388 [0] NCCL INFO comm 0x14cad4008fb0 rank 380 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
453: hkn0736:1532616:1532726 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
382: hkn0715:426276:426394 [2] NCCL INFO comm 0x147be8008fb0 rank 382 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
441: hkn0732:1236021:1236128 [1] NCCL INFO Connected all trees
381: hkn0715:426296:426395 [1] NCCL INFO comm 0x147f30008fb0 rank 381 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
441: hkn0732:1236021:1236128 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
441: hkn0732:1236021:1236128 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1545221:1545345 [0] NCCL INFO Connected all trees
383: hkn0715:426284:426389 [3] NCCL INFO comm 0x14fedc008fb0 rank 383 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
452: hkn0736:1532636:1532735 [0] NCCL INFO Connected all trees
452: hkn0736:1532636:1532735 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1532636:1532735 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1545221:1545345 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1545221:1545345 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1236033:1236129 [0] NCCL INFO Connected all trees
440: hkn0732:1236033:1236129 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1236033:1236129 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
325: hkn0634:1545237:1545343 [1] NCCL INFO Connected all trees
449: hkn0734:1180885:1181000 [1] NCCL INFO Connected all trees
449: hkn0734:1180885:1181000 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
449: hkn0734:1180885:1181000 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1532636:1532735 [0] NCCL INFO comm 0x14e960008fb0 rank 452 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
325: hkn0634:1545237:1545343 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
455: hkn0736:1532608:1532732 [3] NCCL INFO comm 0x1470b8008fb0 rank 455 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
325: hkn0634:1545237:1545343 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1532616:1532726 [1] NCCL INFO comm 0x149ee8008fb0 rank 453 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
454: hkn0736:1532624:1532729 [2] NCCL INFO comm 0x148abc008fb0 rank 454 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
448: hkn0734:1180893:1180999 [0] NCCL INFO Connected all trees
448: hkn0734:1180893:1180999 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1180893:1180999 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1545221:1545345 [0] NCCL INFO comm 0x148ff4008fb0 rank 324 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
442: hkn0732:1236013:1236130 [2] NCCL INFO comm 0x145514008fb0 rank 442 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
157: hkn0516:2940314:2940436 [1] NCCL INFO Connected all trees
325: hkn0634:1545237:1545343 [1] NCCL INFO comm 0x14ebe4008fb0 rank 325 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
441: hkn0732:1236021:1236128 [1] NCCL INFO comm 0x154020008fb0 rank 441 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
157: hkn0516:2940314:2940436 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
326: hkn0634:1545229:1545344 [2] NCCL INFO comm 0x149634008fb0 rank 326 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
157: hkn0516:2940314:2940436 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
443: hkn0732:1236005:1236121 [3] NCCL INFO comm 0x1543e8008fb0 rank 443 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
327: hkn0634:1545249:1545346 [3] NCCL INFO comm 0x14a2f0008fb0 rank 327 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
436: hkn0731:1411088:1411212 [0] NCCL INFO Connected all trees
448: hkn0734:1180893:1180999 [0] NCCL INFO comm 0x149000008fb0 rank 448 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
440: hkn0732:1236033:1236129 [0] NCCL INFO comm 0x14ea00008fb0 rank 440 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
436: hkn0731:1411088:1411212 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
449: hkn0734:1180885:1181000 [1] NCCL INFO comm 0x153184008fb0 rank 449 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
436: hkn0731:1411088:1411212 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1180905:1181006 [2] NCCL INFO comm 0x14f2f4008fb0 rank 450 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
321: hkn0633:1550661:1550752 [1] NCCL INFO Connected all trees
451: hkn0734:1180877:1181004 [3] NCCL INFO comm 0x149770008fb0 rank 451 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
156: hkn0516:2940342:2940437 [0] NCCL INFO Connected all trees
321: hkn0633:1550661:1550752 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
321: hkn0633:1550661:1550752 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
156: hkn0516:2940342:2940437 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:232560:232720 [0] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [send] via NET/IBext/0
156: hkn0516:2940342:2940437 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
480: hkn0807:1043422:1043530 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [receive] via NET/IBext/0
320: hkn0633:1550633:1550753 [0] NCCL INFO Connected all trees
437: hkn0731:1411116:1411213 [1] NCCL INFO Connected all trees
320: hkn0633:1550633:1550753 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
437: hkn0731:1411116:1411213 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
320: hkn0633:1550633:1550753 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
437: hkn0731:1411116:1411213 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1330279:1330367 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [send] via NET/IBext/0
320: hkn0633:1550633:1550753 [0] NCCL INFO comm 0x146348008fb0 rank 320 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
436: hkn0731:1411088:1411212 [0] NCCL INFO comm 0x14c96c008fb0 rank 436 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
323: hkn0633:1550641:1550758 [3] NCCL INFO comm 0x148fd4008fb0 rank 323 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
157: hkn0516:2940314:2940436 [1] NCCL INFO comm 0x151aa8008fb0 rank 157 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
321: hkn0633:1550661:1550752 [1] NCCL INFO comm 0x14a9ac008fb0 rank 321 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
437: hkn0731:1411116:1411213 [1] NCCL INFO comm 0x14c5e8008fb0 rank 437 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
322: hkn0633:1550649:1550756 [2] NCCL INFO comm 0x151374008fb0 rank 322 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
159: hkn0516:2940322:2940429 [3] NCCL INFO comm 0x1457f8008fb0 rank 159 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
252: hkn0611:734178:734279 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [send] via NET/IBext/0
158: hkn0516:2940330:2940431 [2] NCCL INFO comm 0x151ee0008fb0 rank 158 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
156: hkn0516:2940342:2940437 [0] NCCL INFO comm 0x154040008fb0 rank 156 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
438: hkn0731:1411096:1411207 [2] NCCL INFO comm 0x14684c008fb0 rank 438 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
439: hkn0731:1411104:1411206 [3] NCCL INFO comm 0x153284008fb0 rank 439 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
140: hkn0512:3068482:3068576 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [send] via NET/IBext/0
316: hkn0632:1782979:1783083 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [send] via NET/IBext/0
192: hkn0529:1565151:1565262 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [receive] via NET/IBext/0
376: hkn0714:456371:456476 [0] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [send] via NET/IBext/0
388: hkn0717:19465:19565 [0] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [receive] via NET/IBext/0
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [send] via NET/IBext/0
152: hkn0515:2921174:2921332 [0] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [send] via NET/IBext/0
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [receive] via NET/IBext/0
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [send] via NET/IBext/0
405: hkn0721:2323871:2323991 [1] NCCL INFO Channel 00 : 405[4b000] -> 404[31000] via P2P/IPC/read
396: hkn0719:1330279:1330367 [0] NCCL INFO Connected all trees
409: hkn0723:232568:232721 [1] NCCL INFO Connected all trees
240: hkn0607:928741:928852 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [receive] via NET/IBext/0
396: hkn0719:1330279:1330367 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
396: hkn0719:1330279:1330367 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
409: hkn0723:232568:232721 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
409: hkn0723:232568:232721 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:232560:232720 [0] NCCL INFO Connected all trees
405: hkn0721:2323871:2323991 [1] NCCL INFO Channel 01 : 405[4b000] -> 404[31000] via P2P/IPC/read
397: hkn0719:1330259:1330375 [1] NCCL INFO Connected all trees
485: hkn0808:995038:995153 [1] NCCL INFO Connected all trees
485: hkn0808:995038:995153 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 00 : 393[4b000] -> 392[31000] via P2P/IPC/read
397: hkn0719:1330259:1330375 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
485: hkn0808:995038:995153 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:232560:232720 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
397: hkn0719:1330259:1330375 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:232560:232720 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:995046:995154 [0] NCCL INFO Connected all trees
484: hkn0808:995046:995154 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
409: hkn0723:232568:232721 [1] NCCL INFO comm 0x151048008fb0 rank 409 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
484: hkn0808:995046:995154 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1330279:1330367 [0] NCCL INFO comm 0x1482b8008fb0 rank 396 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
504: hkn0815:419469:419586 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [receive] via NET/IBext/0
408: hkn0723:232560:232720 [0] NCCL INFO comm 0x154ba4008fb0 rank 408 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
141: hkn0512:3068462:3068573 [1] NCCL INFO Connected all trees
410: hkn0723:232552:232722 [2] NCCL INFO comm 0x14b584008fb0 rank 410 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
141: hkn0512:3068462:3068573 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3941419:3941544 [1] NCCL INFO Channel 01 : 393[4b000] -> 392[31000] via P2P/IPC/read
141: hkn0512:3068462:3068573 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
398: hkn0719:1330251:1330374 [2] NCCL INFO comm 0x14b928008fb0 rank 398 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
485: hkn0808:995038:995153 [1] NCCL INFO comm 0x14dc74008fb0 rank 485 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
411: hkn0723:232580:232725 [3] NCCL INFO comm 0x14a238008fb0 rank 411 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
399: hkn0719:1330267:1330376 [3] NCCL INFO comm 0x14c608008fb0 rank 399 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
487: hkn0808:995030:995156 [3] NCCL INFO comm 0x150f2c008fb0 rank 487 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
397: hkn0719:1330259:1330375 [1] NCCL INFO comm 0x14dc00008fb0 rank 397 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
140: hkn0512:3068482:3068576 [0] NCCL INFO Connected all trees
140: hkn0512:3068482:3068576 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
140: hkn0512:3068482:3068576 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:995046:995154 [0] NCCL INFO comm 0x1550ec008fb0 rank 484 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
317: hkn0632:1782971:1783088 [1] NCCL INFO Connected all trees
486: hkn0808:995058:995152 [2] NCCL INFO comm 0x147d90008fb0 rank 486 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
317: hkn0632:1782971:1783088 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
317: hkn0632:1782971:1783088 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1782979:1783083 [0] NCCL INFO Connected all trees
197: hkn0530:1282466:1282581 [1] NCCL INFO Connected all trees
316: hkn0632:1782979:1783083 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
377: hkn0714:456383:456480 [1] NCCL INFO Connected all trees
316: hkn0632:1782979:1783083 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
140: hkn0512:3068482:3068576 [0] NCCL INFO comm 0x1470e8008fb0 rank 140 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
197: hkn0530:1282466:1282581 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
377: hkn0714:456383:456480 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2323901:2323996 [0] NCCL INFO Connected all trees
197: hkn0530:1282466:1282581 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
377: hkn0714:456383:456480 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:494610:494705 [1] NCCL INFO Channel 00 : 373[4b000] -> 372[31000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [receive] via NET/IBext/0
404: hkn0721:2323901:2323996 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
141: hkn0512:3068462:3068573 [1] NCCL INFO comm 0x14a9d8008fb0 rank 141 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
481: hkn0807:1043434:1043534 [1] NCCL INFO Connected all trees
481: hkn0807:1043434:1043534 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2323901:2323996 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 00 : 137[4b000] -> 136[31000] via P2P/IPC/read
481: hkn0807:1043434:1043534 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
143: hkn0512:3068470:3068579 [3] NCCL INFO comm 0x1471fc008fb0 rank 143 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
142: hkn0512:3068454:3068574 [2] NCCL INFO comm 0x14bce0008fb0 rank 142 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
196: hkn0530:1282482:1282590 [0] NCCL INFO Connected all trees
376: hkn0714:456371:456476 [0] NCCL INFO Connected all trees
196: hkn0530:1282482:1282590 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
196: hkn0530:1282482:1282590 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1782979:1783083 [0] NCCL INFO comm 0x148438008fb0 rank 316 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
376: hkn0714:456371:456476 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
376: hkn0714:456371:456476 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2323871:2323991 [1] NCCL INFO Connected all trees
318: hkn0632:1782963:1783087 [2] NCCL INFO comm 0x1528b8008fb0 rank 318 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
317: hkn0632:1782971:1783088 [1] NCCL INFO comm 0x147274008fb0 rank 317 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
405: hkn0721:2323871:2323991 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1043422:1043530 [0] NCCL INFO Connected all trees
405: hkn0721:2323871:2323991 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
480: hkn0807:1043422:1043530 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1043422:1043530 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:494610:494705 [1] NCCL INFO Channel 01 : 373[4b000] -> 372[31000] via P2P/IPC/read
319: hkn0632:1782991:1783084 [3] NCCL INFO comm 0x151760008fb0 rank 319 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
196: hkn0530:1282482:1282590 [0] NCCL INFO comm 0x152240008fb0 rank 196 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
376: hkn0714:456371:456476 [0] NCCL INFO comm 0x153c6c008fb0 rank 376 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
137: hkn0511:3090877:3090993 [1] NCCL INFO Channel 01 : 137[4b000] -> 136[31000] via P2P/IPC/read
197: hkn0530:1282466:1282581 [1] NCCL INFO comm 0x1524e0008fb0 rank 197 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
199: hkn0530:1282494:1282588 [3] NCCL INFO comm 0x14d920008fb0 rank 199 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
198: hkn0530:1282474:1282589 [2] NCCL INFO comm 0x152f70008fb0 rank 198 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
496: hkn0812:718245:718354 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [receive] via NET/IBext/0
404: hkn0721:2323901:2323996 [0] NCCL INFO comm 0x14906c008fb0 rank 404 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
407: hkn0721:2323889:2323992 [3] NCCL INFO comm 0x1514a8008fb0 rank 407 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
377: hkn0714:456383:456480 [1] NCCL INFO comm 0x150ca0008fb0 rank 377 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
480: hkn0807:1043422:1043530 [0] NCCL INFO comm 0x1547b0008fb0 rank 480 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
378: hkn0714:456363:456478 [2] NCCL INFO comm 0x14dd80008fb0 rank 378 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
379: hkn0714:456355:456477 [3] NCCL INFO comm 0x153e08008fb0 rank 379 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
481: hkn0807:1043434:1043534 [1] NCCL INFO comm 0x15412c008fb0 rank 481 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
482: hkn0807:1043406:1043538 [2] NCCL INFO comm 0x15078c008fb0 rank 482 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
483: hkn0807:1043414:1043536 [3] NCCL INFO comm 0x14dc9c008fb0 rank 483 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
406: hkn0721:2323879:2323993 [2] NCCL INFO comm 0x148bdc008fb0 rank 406 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
405: hkn0721:2323871:2323991 [1] NCCL INFO comm 0x1494ec008fb0 rank 405 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
153: hkn0515:2921190:2921327 [1] NCCL INFO Connected all trees
149: hkn0514:2975087:2975198 [1] NCCL INFO Channel 00 : 149[4b000] -> 148[31000] via P2P/IPC/read
153: hkn0515:2921190:2921327 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
153: hkn0515:2921190:2921327 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
152: hkn0515:2921174:2921332 [0] NCCL INFO Connected all trees
152: hkn0515:2921174:2921332 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
152: hkn0515:2921174:2921332 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
149: hkn0514:2975087:2975198 [1] NCCL INFO Channel 01 : 149[4b000] -> 148[31000] via P2P/IPC/read
152: hkn0515:2921174:2921332 [0] NCCL INFO comm 0x147ea4008fb0 rank 152 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
155: hkn0515:2921202:2921330 [3] NCCL INFO comm 0x145e2c008fb0 rank 155 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
153: hkn0515:2921190:2921327 [1] NCCL INFO comm 0x14f504008fb0 rank 153 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
372: hkn0713:494598:494713 [0] NCCL INFO Connected all trees
372: hkn0713:494598:494713 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:494598:494713 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
154: hkn0515:2921182:2921328 [2] NCCL INFO comm 0x153278008fb0 rank 154 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
193: hkn0529:1565171:1565268 [1] NCCL INFO Connected all trees
193: hkn0529:1565171:1565268 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
193: hkn0529:1565171:1565268 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:494610:494705 [1] NCCL INFO Connected all trees
373: hkn0713:494610:494705 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
373: hkn0713:494610:494705 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
192: hkn0529:1565151:1565262 [0] NCCL INFO Connected all trees
392: hkn0718:3941435:3941546 [0] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [send] via NET/IBext/0
192: hkn0529:1565151:1565262 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1565151:1565262 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3163506:3163602 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [send] via NET/IBext/0
373: hkn0713:494610:494705 [1] NCCL INFO comm 0x155240008fb0 rank 373 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
375: hkn0713:494582:494711 [3] NCCL INFO comm 0x153b08008fb0 rank 375 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
372: hkn0713:494598:494713 [0] NCCL INFO comm 0x1527d0008fb0 rank 372 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
374: hkn0713:494590:494707 [2] NCCL INFO comm 0x14cfb4008fb0 rank 374 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
194: hkn0529:1565143:1565270 [2] NCCL INFO comm 0x14d1a0008fb0 rank 194 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
195: hkn0529:1565159:1565265 [3] NCCL INFO comm 0x151728008fb0 rank 195 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
149: hkn0514:2975087:2975198 [1] NCCL INFO Connected all trees
193: hkn0529:1565171:1565268 [1] NCCL INFO comm 0x149574008fb0 rank 193 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
192: hkn0529:1565151:1565262 [0] NCCL INFO comm 0x145a00008fb0 rank 192 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
149: hkn0514:2975087:2975198 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
149: hkn0514:2975087:2975198 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
136: hkn0511:3090885:3090991 [0] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [send] via NET/IBext/0
312: hkn0631:1046191:1046283 [0] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [send] via NET/IBext/0
509: hkn0816:399926:400042 [1] NCCL INFO Connected all trees
509: hkn0816:399926:400042 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2975079:2975202 [0] NCCL INFO Connected all trees
509: hkn0816:399926:400042 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
148: hkn0514:2975079:2975202 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2975079:2975202 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
508: hkn0816:399946:400046 [0] NCCL INFO Connected all trees
508: hkn0816:399946:400046 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
508: hkn0816:399946:400046 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1897127:1897252 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [send] via NET/IBext/0
151: hkn0514:2975071:2975199 [3] NCCL INFO comm 0x14e7e4008fb0 rank 151 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
149: hkn0514:2975087:2975198 [1] NCCL INFO comm 0x14a6a0008fb0 rank 149 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
148: hkn0514:2975079:2975202 [0] NCCL INFO comm 0x148164008fb0 rank 148 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
150: hkn0514:2975099:2975195 [2] NCCL INFO comm 0x150094008fb0 rank 150 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
388: hkn0717:19465:19565 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [send] via NET/IBext/0
509: hkn0816:399926:400042 [1] NCCL INFO comm 0x1528a4008fb0 rank 509 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
508: hkn0816:399946:400046 [0] NCCL INFO comm 0x14ebd4008fb0 rank 508 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
510: hkn0816:399918:400045 [2] NCCL INFO comm 0x146bc8008fb0 rank 510 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
511: hkn0816:399934:400048 [3] NCCL INFO comm 0x154c24008fb0 rank 511 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [send] via NET/IBext/0
229: hkn0604:713547:713656 [1] NCCL INFO Connected all trees
229: hkn0604:713547:713656 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
229: hkn0604:713547:713656 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:713559:713655 [0] NCCL INFO Connected all trees
248: hkn0609:735146:735265 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [receive] via NET/IBext/0
228: hkn0604:713559:713655 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:713559:713655 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2786415:2786525 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [send] via NET/IBext/0
228: hkn0604:713559:713655 [0] NCCL INFO comm 0x153d54008fb0 rank 228 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
230: hkn0604:713539:713662 [2] NCCL INFO comm 0x153518008fb0 rank 230 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
231: hkn0604:713531:713661 [3] NCCL INFO comm 0x14f724008fb0 rank 231 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
229: hkn0604:713547:713656 [1] NCCL INFO comm 0x14e168008fb0 rank 229 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
268: hkn0616:429398:429527 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [send] via NET/IBext/0
225: hkn0603:1437591:1437698 [1] NCCL INFO Connected all trees
225: hkn0603:1437591:1437698 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
225: hkn0603:1437591:1437698 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1437575:1437699 [0] NCCL INFO Connected all trees
224: hkn0603:1437575:1437699 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:19453:19564 [1] NCCL INFO Channel 00 : 389[4b000] -> 388[31000] via P2P/IPC/read
224: hkn0603:1437575:1437699 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3941419:3941544 [1] NCCL INFO Connected all trees
393: hkn0718:3941419:3941544 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3941419:3941544 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:928741:928852 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [receive] via NET/IBext/0
227: hkn0603:1437583:1437701 [3] NCCL INFO comm 0x152794008fb0 rank 227 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
392: hkn0718:3941435:3941546 [0] NCCL INFO Connected all trees
224: hkn0603:1437575:1437699 [0] NCCL INFO comm 0x153b28008fb0 rank 224 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
225: hkn0603:1437591:1437698 [1] NCCL INFO comm 0x145a38008fb0 rank 225 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
392: hkn0718:3941435:3941546 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3941435:3941546 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
226: hkn0603:1437603:1437704 [2] NCCL INFO comm 0x14a130008fb0 rank 226 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
497: hkn0812:718229:718349 [1] NCCL INFO Connected all trees
125: hkn0508:3163494:3163603 [1] NCCL INFO Connected all trees
497: hkn0812:718229:718349 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
125: hkn0508:3163494:3163603 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:718229:718349 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
125: hkn0508:3163494:3163603 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3941435:3941546 [0] NCCL INFO comm 0x1509e8008fb0 rank 392 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
389: hkn0717:19453:19564 [1] NCCL INFO Channel 01 : 389[4b000] -> 388[31000] via P2P/IPC/read
395: hkn0718:3941427:3941539 [3] NCCL INFO comm 0x14d5c8008fb0 rank 395 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
496: hkn0812:718245:718354 [0] NCCL INFO Connected all trees
124: hkn0508:3163506:3163602 [0] NCCL INFO Connected all trees
393: hkn0718:3941419:3941544 [1] NCCL INFO comm 0x1549c8008fb0 rank 393 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
394: hkn0718:3941447:3941548 [2] NCCL INFO comm 0x1464e0008fb0 rank 394 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
496: hkn0812:718245:718354 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
124: hkn0508:3163506:3163602 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:718245:718354 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3163506:3163602 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3090877:3090993 [1] NCCL INFO Connected all trees
497: hkn0812:718229:718349 [1] NCCL INFO comm 0x152a88008fb0 rank 497 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
133: hkn0510:2786407:2786523 [1] NCCL INFO Channel 00 : 133[4b000] -> 132[31000] via P2P/IPC/read
125: hkn0508:3163494:3163603 [1] NCCL INFO comm 0x1547dc008fb0 rank 125 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
137: hkn0511:3090877:3090993 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
137: hkn0511:3090877:3090993 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
499: hkn0812:718257:718355 [3] NCCL INFO comm 0x1510a0008fb0 rank 499 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
126: hkn0508:3163478:3163601 [2] NCCL INFO comm 0x14c200008fb0 rank 126 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
496: hkn0812:718245:718354 [0] NCCL INFO comm 0x14c360008fb0 rank 496 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
124: hkn0508:3163506:3163602 [0] NCCL INFO comm 0x1536a8008fb0 rank 124 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
127: hkn0508:3163486:3163600 [3] NCCL INFO comm 0x14a020008fb0 rank 127 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
498: hkn0812:718237:718348 [2] NCCL INFO comm 0x14cd00008fb0 rank 498 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
136: hkn0511:3090885:3090991 [0] NCCL INFO Connected all trees
136: hkn0511:3090885:3090991 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3090885:3090991 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
313: hkn0631:1046163:1046282 [1] NCCL INFO Connected all trees
313: hkn0631:1046163:1046282 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
313: hkn0631:1046163:1046282 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1897127:1897252 [0] NCCL INFO Connected all trees
136: hkn0511:3090885:3090991 [0] NCCL INFO comm 0x153dc0008fb0 rank 136 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
284: hkn0623:1897127:1897252 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
139: hkn0511:3090869:3090995 [3] NCCL INFO comm 0x14c120008fb0 rank 139 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
284: hkn0623:1897127:1897252 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
138: hkn0511:3090897:3090992 [2] NCCL INFO comm 0x1510cc008fb0 rank 138 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
312: hkn0631:1046191:1046283 [0] NCCL INFO Connected all trees
137: hkn0511:3090877:3090993 [1] NCCL INFO comm 0x145d44008fb0 rank 137 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
312: hkn0631:1046191:1046283 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
312: hkn0631:1046191:1046283 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
133: hkn0510:2786407:2786523 [1] NCCL INFO Channel 01 : 133[4b000] -> 132[31000] via P2P/IPC/read
309: hkn0630:1622860:1622960 [1] NCCL INFO Channel 00 : 309[4b000] -> 308[31000] via P2P/IPC/read
285: hkn0623:1897135:1897250 [1] NCCL INFO Connected all trees
285: hkn0623:1897135:1897250 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
285: hkn0623:1897135:1897250 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1046191:1046283 [0] NCCL INFO comm 0x151e84008fb0 rank 312 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
315: hkn0631:1046171:1046285 [3] NCCL INFO comm 0x150f38008fb0 rank 315 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
314: hkn0631:1046179:1046288 [2] NCCL INFO comm 0x14df04008fb0 rank 314 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
389: hkn0717:19453:19564 [1] NCCL INFO Connected all trees
389: hkn0717:19453:19564 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1622860:1622960 [1] NCCL INFO Channel 01 : 309[4b000] -> 308[31000] via P2P/IPC/read
389: hkn0717:19453:19564 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
313: hkn0631:1046163:1046282 [1] NCCL INFO comm 0x14d200008fb0 rank 313 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
284: hkn0623:1897127:1897252 [0] NCCL INFO comm 0x152198008fb0 rank 284 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
253: hkn0611:734158:734277 [1] NCCL INFO Connected all trees
287: hkn0623:1897155:1897246 [3] NCCL INFO comm 0x1500d8008fb0 rank 287 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
388: hkn0717:19465:19565 [0] NCCL INFO Connected all trees
253: hkn0611:734158:734277 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
286: hkn0623:1897143:1897243 [2] NCCL INFO comm 0x154bd4008fb0 rank 286 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
253: hkn0611:734158:734277 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
285: hkn0623:1897135:1897250 [1] NCCL INFO comm 0x154990008fb0 rank 285 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
388: hkn0717:19465:19565 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
388: hkn0717:19465:19565 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:734178:734279 [0] NCCL INFO Connected all trees
252: hkn0611:734178:734279 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:734178:734279 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
389: hkn0717:19453:19564 [1] NCCL INFO comm 0x14eaec008fb0 rank 389 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
388: hkn0717:19465:19565 [0] NCCL INFO comm 0x151b34008fb0 rank 388 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
390: hkn0717:19445:19567 [2] NCCL INFO comm 0x152670008fb0 rank 390 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
391: hkn0717:19437:19568 [3] NCCL INFO comm 0x14e828008fb0 rank 391 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
252: hkn0611:734178:734279 [0] NCCL INFO comm 0x153afc008fb0 rank 252 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
385: hkn0716:132811:132965 [1] NCCL INFO Connected all trees
133: hkn0510:2786407:2786523 [1] NCCL INFO Connected all trees
254: hkn0611:734166:734276 [2] NCCL INFO comm 0x1464e4008fb0 rank 254 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
385: hkn0716:132811:132965 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
133: hkn0510:2786407:2786523 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:419469:419586 [0] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [send] via NET/IBext/0
385: hkn0716:132811:132965 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
133: hkn0510:2786407:2786523 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:734158:734277 [1] NCCL INFO comm 0x14a460008fb0 rank 253 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
255: hkn0611:734150:734278 [3] NCCL INFO comm 0x14c82c008fb0 rank 255 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
132: hkn0510:2786415:2786525 [0] NCCL INFO Connected all trees
384: hkn0716:132827:132967 [0] NCCL INFO Connected all trees
132: hkn0510:2786415:2786525 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
132: hkn0510:2786415:2786525 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:132827:132967 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
384: hkn0716:132827:132967 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
308: hkn0630:1622844:1622963 [0] NCCL INFO Connected all trees
308: hkn0630:1622844:1622963 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
308: hkn0630:1622844:1622963 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3234567:3234693 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [send] via NET/IBext/0
133: hkn0510:2786407:2786523 [1] NCCL INFO comm 0x14abcc008fb0 rank 133 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
384: hkn0716:132827:132967 [0] NCCL INFO comm 0x14cea4008fb0 rank 384 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
132: hkn0510:2786415:2786525 [0] NCCL INFO comm 0x147dd4008fb0 rank 132 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
309: hkn0630:1622860:1622960 [1] NCCL INFO Connected all trees
385: hkn0716:132811:132965 [1] NCCL INFO comm 0x153da0008fb0 rank 385 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
120: hkn0507:3211471:3211570 [0] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [send] via NET/IBext/0
134: hkn0510:2786427:2786528 [2] NCCL INFO comm 0x145fe0008fb0 rank 134 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
309: hkn0630:1622860:1622960 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1622860:1622960 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
135: hkn0510:2786399:2786524 [3] NCCL INFO comm 0x149e18008fb0 rank 135 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
387: hkn0716:132839:132970 [3] NCCL INFO comm 0x146fa8008fb0 rank 387 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
386: hkn0716:132819:132964 [2] NCCL INFO comm 0x14b4d8008fb0 rank 386 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
308: hkn0630:1622844:1622963 [0] NCCL INFO comm 0x14ebac008fb0 rank 308 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
129: hkn0509:3148751:3148873 [1] NCCL INFO Connected all trees
309: hkn0630:1622860:1622960 [1] NCCL INFO comm 0x14f894008fb0 rank 309 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
310: hkn0630:1622852:1622969 [2] NCCL INFO comm 0x14cf4c008fb0 rank 310 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
129: hkn0509:3148751:3148873 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
311: hkn0630:1622872:1622968 [3] NCCL INFO comm 0x148a80008fb0 rank 311 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
129: hkn0509:3148751:3148873 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
128: hkn0509:3148759:3148874 [0] NCCL INFO Connected all trees
128: hkn0509:3148759:3148874 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
128: hkn0509:3148759:3148874 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
129: hkn0509:3148751:3148873 [1] NCCL INFO comm 0x147760008fb0 rank 129 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
128: hkn0509:3148759:3148874 [0] NCCL INFO comm 0x1517f4008fb0 rank 128 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
268: hkn0616:429398:429527 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [send] via NET/IBext/0
131: hkn0509:3148767:3148876 [3] NCCL INFO comm 0x147650008fb0 rank 131 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
130: hkn0509:3148779:3148872 [2] NCCL INFO comm 0x14605c008fb0 rank 130 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
280: hkn0622:2045000:2045127 [0] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [send] via NET/IBext/0
248: hkn0609:735146:735265 [0] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [send] via NET/IBext/0
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [send] via NET/IBext/0
241: hkn0607:928753:928855 [1] NCCL INFO Connected all trees
241: hkn0607:928753:928855 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
241: hkn0607:928753:928855 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:928741:928852 [0] NCCL INFO Connected all trees
240: hkn0607:928741:928852 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
240: hkn0607:928741:928852 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
242: hkn0607:928725:928850 [2] NCCL INFO comm 0x14c3ac008fb0 rank 242 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
241: hkn0607:928753:928855 [1] NCCL INFO comm 0x14e390008fb0 rank 241 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
240: hkn0607:928741:928852 [0] NCCL INFO comm 0x14c04c008fb0 rank 240 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
243: hkn0607:928733:928851 [3] NCCL INFO comm 0x146658008fb0 rank 243 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
260: hkn0613:927106:927208 [0] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [receive] via NET/IBext/0
505: hkn0815:419461:419585 [1] NCCL INFO Connected all trees
505: hkn0815:419461:419585 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
505: hkn0815:419461:419585 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:419469:419586 [0] NCCL INFO Connected all trees
504: hkn0815:419469:419586 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:419469:419586 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 61: hkn0420:3234595:3234696 [1] NCCL INFO Connected all trees
 61: hkn0420:3234595:3234696 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 61: hkn0420:3234595:3234696 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3234567:3234693 [0] NCCL INFO Connected all trees
505: hkn0815:419461:419585 [1] NCCL INFO comm 0x14dde8008fb0 rank 505 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 60: hkn0420:3234567:3234693 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:419477:419589 [2] NCCL INFO comm 0x14b2a0008fb0 rank 506 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 60: hkn0420:3234567:3234693 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:419469:419586 [0] NCCL INFO comm 0x14bf28008fb0 rank 504 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
121: hkn0507:3211451:3211566 [1] NCCL INFO Connected all trees
121: hkn0507:3211451:3211566 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
117: hkn0506:862422:862551 [1] NCCL INFO Channel 00 : 117[4b000] -> 116[31000] via P2P/IPC/read
121: hkn0507:3211451:3211566 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
507: hkn0815:419489:419590 [3] NCCL INFO comm 0x151a70008fb0 rank 507 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
120: hkn0507:3211471:3211570 [0] NCCL INFO Connected all trees
 62: hkn0420:3234575:3234691 [2] NCCL INFO comm 0x150f18008fb0 rank 62 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
120: hkn0507:3211471:3211570 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3211471:3211570 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3234567:3234693 [0] NCCL INFO comm 0x14c3c4008fb0 rank 60 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
501: hkn0814:700172:700309 [1] NCCL INFO Channel 00 : 501[4b000] -> 500[31000] via P2P/IPC/read
 61: hkn0420:3234595:3234696 [1] NCCL INFO comm 0x148ec8008fb0 rank 61 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 63: hkn0420:3234583:3234690 [3] NCCL INFO comm 0x14d0ec008fb0 rank 63 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
117: hkn0506:862422:862551 [1] NCCL INFO Channel 01 : 117[4b000] -> 116[31000] via P2P/IPC/read
121: hkn0507:3211451:3211566 [1] NCCL INFO comm 0x14b4c0008fb0 rank 121 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
268: hkn0616:429398:429527 [0] NCCL INFO Connected all trees
122: hkn0507:3211459:3211565 [2] NCCL INFO comm 0x14d188008fb0 rank 122 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
268: hkn0616:429398:429527 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
268: hkn0616:429398:429527 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
123: hkn0507:3211443:3211567 [3] NCCL INFO comm 0x14ae28008fb0 rank 123 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
120: hkn0507:3211471:3211570 [0] NCCL INFO comm 0x147a50008fb0 rank 120 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
501: hkn0814:700172:700309 [1] NCCL INFO Channel 01 : 501[4b000] -> 500[31000] via P2P/IPC/read
281: hkn0622:2045016:2045130 [1] NCCL INFO Connected all trees
281: hkn0622:2045016:2045130 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2045016:2045130 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:2016097:2016215 [1] NCCL INFO Channel 00 : 277[4b000] -> 276[31000] via P2P/IPC/read
249: hkn0609:735138:735259 [1] NCCL INFO Connected all trees
249: hkn0609:735138:735259 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:510084:510183 [1] NCCL INFO Channel 00 : 245[4b000] -> 244[31000] via P2P/IPC/read
269: hkn0616:429426:429521 [1] NCCL INFO Connected all trees
280: hkn0622:2045000:2045127 [0] NCCL INFO Connected all trees
269: hkn0616:429426:429521 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:735138:735259 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2045000:2045127 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
280: hkn0622:2045000:2045127 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:438714:438810 [1] NCCL INFO Channel 00 : 265[4b000] -> 264[31000] via P2P/IPC/read
269: hkn0616:429426:429521 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:735146:735265 [0] NCCL INFO Connected all trees
248: hkn0609:735146:735265 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:735146:735265 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
281: hkn0622:2045016:2045130 [1] NCCL INFO comm 0x14ba30008fb0 rank 281 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
283: hkn0622:2045028:2045131 [3] NCCL INFO comm 0x149d54008fb0 rank 283 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
277: hkn0621:2016097:2016215 [1] NCCL INFO Channel 01 : 277[4b000] -> 276[31000] via P2P/IPC/read
280: hkn0622:2045000:2045127 [0] NCCL INFO comm 0x1474f0008fb0 rank 280 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
245: hkn0608:510084:510183 [1] NCCL INFO Channel 01 : 245[4b000] -> 244[31000] via P2P/IPC/read
500: hkn0814:700164:700310 [0] NCCL INFO Connected all trees
500: hkn0814:700164:700310 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
250: hkn0609:735166:735258 [2] NCCL INFO comm 0x14dab8008fb0 rank 250 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
500: hkn0814:700164:700310 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
282: hkn0622:2045008:2045126 [2] NCCL INFO comm 0x153594008fb0 rank 282 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
265: hkn0615:438714:438810 [1] NCCL INFO Channel 01 : 265[4b000] -> 264[31000] via P2P/IPC/read
249: hkn0609:735138:735259 [1] NCCL INFO comm 0x14e8dc008fb0 rank 249 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
116: hkn0506:862438:862546 [0] NCCL INFO Connected all trees
270: hkn0616:429406:429526 [2] NCCL INFO comm 0x148c44008fb0 rank 270 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
116: hkn0506:862438:862546 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
271: hkn0616:429414:429520 [3] NCCL INFO comm 0x14dcd4008fb0 rank 271 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
116: hkn0506:862438:862546 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:735146:735265 [0] NCCL INFO comm 0x1471ec008fb0 rank 248 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
268: hkn0616:429398:429527 [0] NCCL INFO comm 0x14fa78008fb0 rank 268 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
251: hkn0609:735154:735263 [3] NCCL INFO comm 0x152484008fb0 rank 251 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
269: hkn0616:429426:429521 [1] NCCL INFO comm 0x151d24008fb0 rank 269 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
117: hkn0506:862422:862551 [1] NCCL INFO Connected all trees
117: hkn0506:862422:862551 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
117: hkn0506:862422:862551 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
116: hkn0506:862438:862546 [0] NCCL INFO comm 0x153c1c008fb0 rank 116 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
118: hkn0506:862450:862548 [2] NCCL INFO comm 0x14b220008fb0 rank 118 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
117: hkn0506:862422:862551 [1] NCCL INFO comm 0x14cbac008fb0 rank 117 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
119: hkn0506:862430:862542 [3] NCCL INFO comm 0x154a2c008fb0 rank 119 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
501: hkn0814:700172:700309 [1] NCCL INFO Connected all trees
276: hkn0621:2016113:2016222 [0] NCCL INFO Connected all trees
501: hkn0814:700172:700309 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
276: hkn0621:2016113:2016222 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
501: hkn0814:700172:700309 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2340281:2340396 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [send] via NET/IBext/0
276: hkn0621:2016113:2016222 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:510084:510183 [1] NCCL INFO Connected all trees
245: hkn0608:510084:510183 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:510084:510183 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:2016097:2016215 [1] NCCL INFO Connected all trees
277: hkn0621:2016097:2016215 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
277: hkn0621:2016097:2016215 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
502: hkn0814:700184:700311 [2] NCCL INFO comm 0x152e4c008fb0 rank 502 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
244: hkn0608:510064:510177 [0] NCCL INFO Connected all trees
503: hkn0814:700156:700314 [3] NCCL INFO comm 0x14f964008fb0 rank 503 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 56: hkn0419:1568599:1568716 [0] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [send] via NET/IBext/0
500: hkn0814:700164:700310 [0] NCCL INFO comm 0x150088008fb0 rank 500 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
244: hkn0608:510064:510177 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
244: hkn0608:510064:510177 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:700172:700309 [1] NCCL INFO comm 0x14cbb8008fb0 rank 501 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
277: hkn0621:2016097:2016215 [1] NCCL INFO comm 0x1472f8008fb0 rank 277 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
279: hkn0621:2016105:2016220 [3] NCCL INFO comm 0x152548008fb0 rank 279 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
278: hkn0621:2016125:2016216 [2] NCCL INFO comm 0x14a890008fb0 rank 278 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
276: hkn0621:2016113:2016222 [0] NCCL INFO comm 0x14c9b4008fb0 rank 276 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
244: hkn0608:510064:510177 [0] NCCL INFO comm 0x14b7a4008fb0 rank 244 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
245: hkn0608:510084:510183 [1] NCCL INFO comm 0x14dbec008fb0 rank 245 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
246: hkn0608:510072:510180 [2] NCCL INFO comm 0x148f5c008fb0 rank 246 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
247: hkn0608:510056:510185 [3] NCCL INFO comm 0x151d1c008fb0 rank 247 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
264: hkn0615:438687:438806 [0] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [send] via NET/IBext/0
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [send] via NET/IBext/0
260: hkn0613:927106:927208 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [send] via NET/IBext/0
 29: hkn0411:2340273:2340391 [1] NCCL INFO Connected all trees
 29: hkn0411:2340273:2340391 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 29: hkn0411:2340273:2340391 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2340281:2340396 [0] NCCL INFO Connected all trees
 28: hkn0411:2340281:2340396 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 28: hkn0411:2340281:2340396 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 56: hkn0419:1568599:1568716 [0] NCCL INFO Connected all trees
 56: hkn0419:1568599:1568716 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 28: hkn0411:2340281:2340396 [0] NCCL INFO comm 0x145474008fb0 rank 28 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 56: hkn0419:1568599:1568716 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2340273:2340391 [1] NCCL INFO comm 0x152f1c008fb0 rank 29 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 30: hkn0411:2340293:2340389 [2] NCCL INFO comm 0x1503d4008fb0 rank 30 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 31: hkn0411:2340265:2340393 [3] NCCL INFO comm 0x150f58008fb0 rank 31 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 57: hkn0419:1568619:1568709 [1] NCCL INFO Connected all trees
 57: hkn0419:1568619:1568709 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 57: hkn0419:1568619:1568709 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1893541:1893660 [1] NCCL INFO Channel 00 : 53[4b000] -> 52[31000] via P2P/IPC/read
 56: hkn0419:1568599:1568716 [0] NCCL INFO comm 0x14caf8008fb0 rank 56 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 57: hkn0419:1568619:1568709 [1] NCCL INFO comm 0x146010008fb0 rank 57 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 59: hkn0419:1568607:1568710 [3] NCCL INFO comm 0x14fb24008fb0 rank 59 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 58: hkn0419:1568591:1568715 [2] NCCL INFO comm 0x14d16c008fb0 rank 58 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 53: hkn0418:1893541:1893660 [1] NCCL INFO Channel 01 : 53[4b000] -> 52[31000] via P2P/IPC/read
265: hkn0615:438714:438810 [1] NCCL INFO Connected all trees
265: hkn0615:438714:438810 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
265: hkn0615:438714:438810 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
261: hkn0613:927098:927209 [1] NCCL INFO Channel 00 : 261[4b000] -> 260[31000] via P2P/IPC/read
264: hkn0615:438687:438806 [0] NCCL INFO Connected all trees
264: hkn0615:438687:438806 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
264: hkn0615:438687:438806 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:438714:438810 [1] NCCL INFO comm 0x145bd8008fb0 rank 265 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
264: hkn0615:438687:438806 [0] NCCL INFO comm 0x148f18008fb0 rank 264 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
266: hkn0615:438703:438813 [2] NCCL INFO comm 0x14e414008fb0 rank 266 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
267: hkn0615:438695:438811 [3] NCCL INFO comm 0x1456b0008fb0 rank 267 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
261: hkn0613:927098:927209 [1] NCCL INFO Channel 01 : 261[4b000] -> 260[31000] via P2P/IPC/read
 52: hkn0418:1893569:1893661 [0] NCCL INFO Connected all trees
 52: hkn0418:1893569:1893661 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1893569:1893661 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1893541:1893660 [1] NCCL INFO Connected all trees
 53: hkn0418:1893541:1893660 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 53: hkn0418:1893541:1893660 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1893541:1893660 [1] NCCL INFO comm 0x149150008fb0 rank 53 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 55: hkn0418:1893549:1893663 [3] NCCL INFO comm 0x147f18008fb0 rank 55 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 52: hkn0418:1893569:1893661 [0] NCCL INFO comm 0x15484c008fb0 rank 52 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 54: hkn0418:1893557:1893666 [2] NCCL INFO comm 0x14796c008fb0 rank 54 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 24: hkn0410:1184043:1184151 [0] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [send] via NET/IBext/0
 12: hkn0407:1840613:1840723 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [send] via NET/IBext/0
261: hkn0613:927098:927209 [1] NCCL INFO Connected all trees
261: hkn0613:927098:927209 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
261: hkn0613:927098:927209 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:927106:927208 [0] NCCL INFO Connected all trees
260: hkn0613:927106:927208 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
260: hkn0613:927106:927208 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:927106:927208 [0] NCCL INFO comm 0x14b728008fb0 rank 260 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
261: hkn0613:927098:927209 [1] NCCL INFO comm 0x14adfc008fb0 rank 261 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
262: hkn0613:927118:927210 [2] NCCL INFO comm 0x154278008fb0 rank 262 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
263: hkn0613:927090:927213 [3] NCCL INFO comm 0x14e6f4008fb0 rank 263 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
257: hkn0612:941317:941465 [1] NCCL INFO Connected all trees
257: hkn0612:941317:941465 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:941317:941465 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:941333:941464 [0] NCCL INFO Connected all trees
256: hkn0612:941333:941464 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
256: hkn0612:941333:941464 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:941333:941464 [0] NCCL INFO comm 0x152a3c008fb0 rank 256 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
259: hkn0612:941325:941471 [3] NCCL INFO comm 0x147850008fb0 rank 259 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
257: hkn0612:941317:941465 [1] NCCL INFO comm 0x14bd54008fb0 rank 257 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
258: hkn0612:941345:941470 [2] NCCL INFO comm 0x1528a0008fb0 rank 258 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [receive] via NET/IBext/0
 12: hkn0407:1840613:1840723 [0] NCCL INFO Connected all trees
 12: hkn0407:1840613:1840723 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 12: hkn0407:1840613:1840723 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 25: hkn0410:1184035:1184153 [1] NCCL INFO Connected all trees
 25: hkn0410:1184035:1184153 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 25: hkn0410:1184035:1184153 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1840621:1840725 [1] NCCL INFO Connected all trees
 13: hkn0407:1840621:1840725 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 13: hkn0407:1840621:1840725 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1184043:1184151 [0] NCCL INFO Connected all trees
 24: hkn0410:1184043:1184151 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 24: hkn0410:1184043:1184151 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1840613:1840723 [0] NCCL INFO comm 0x154700008fb0 rank 12 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 21: hkn0409:2610008:2610115 [1] NCCL INFO Channel 00 : 21[4b000] -> 20[31000] via P2P/IPC/read
 13: hkn0407:1840621:1840725 [1] NCCL INFO comm 0x149900008fb0 rank 13 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 15: hkn0407:1840605:1840730 [3] NCCL INFO comm 0x149ec0008fb0 rank 15 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 24: hkn0410:1184043:1184151 [0] NCCL INFO comm 0x14e634008fb0 rank 24 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 25: hkn0410:1184035:1184153 [1] NCCL INFO comm 0x14dd6c008fb0 rank 25 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 27: hkn0410:1184055:1184150 [3] NCCL INFO comm 0x14d944008fb0 rank 27 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 26: hkn0410:1184027:1184146 [2] NCCL INFO comm 0x14dd14008fb0 rank 26 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 14: hkn0407:1840633:1840731 [2] NCCL INFO comm 0x14a900008fb0 rank 14 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 00 : 9[4b000] -> 8[31000] via P2P/IPC/read
  9: hkn0405:3231499:3231610 [1] NCCL INFO Channel 01 : 9[4b000] -> 8[31000] via P2P/IPC/read
 21: hkn0409:2610008:2610115 [1] NCCL INFO Channel 01 : 21[4b000] -> 20[31000] via P2P/IPC/read
 20: hkn0409:2610000:2610117 [0] NCCL INFO Connected all trees
 20: hkn0409:2610000:2610117 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 20: hkn0409:2610000:2610117 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2610008:2610115 [1] NCCL INFO Connected all trees
 21: hkn0409:2610008:2610115 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 21: hkn0409:2610008:2610115 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  8: hkn0405:3231491:3231618 [0] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [send] via NET/IBext/0
 22: hkn0409:2609992:2610120 [2] NCCL INFO comm 0x14d2b0008fb0 rank 22 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 23: hkn0409:2610020:2610114 [3] NCCL INFO comm 0x153d38008fb0 rank 23 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 20: hkn0409:2610000:2610117 [0] NCCL INFO comm 0x152574008fb0 rank 20 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 21: hkn0409:2610008:2610115 [1] NCCL INFO comm 0x14680c008fb0 rank 21 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  4: hkn0404:1363862:1363969 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [send] via NET/IBext/0
  9: hkn0405:3231499:3231610 [1] NCCL INFO Connected all trees
  9: hkn0405:3231499:3231610 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  9: hkn0405:3231499:3231610 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  8: hkn0405:3231491:3231618 [0] NCCL INFO Connected all trees
  8: hkn0405:3231491:3231618 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  8: hkn0405:3231491:3231618 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3231499:3231610 [1] NCCL INFO comm 0x14649c008fb0 rank 9 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  8: hkn0405:3231491:3231618 [0] NCCL INFO comm 0x14622c008fb0 rank 8 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  5: hkn0404:1363874:1363976 [1] NCCL INFO Channel 00 : 5[4b000] -> 4[31000] via P2P/IPC/read
 10: hkn0405:3231519:3231613 [2] NCCL INFO comm 0x14abf4008fb0 rank 10 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 11: hkn0405:3231507:3231615 [3] NCCL INFO comm 0x148e7c008fb0 rank 11 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  5: hkn0404:1363874:1363976 [1] NCCL INFO Channel 01 : 5[4b000] -> 4[31000] via P2P/IPC/read
  4: hkn0404:1363862:1363969 [0] NCCL INFO Connected all trees
  4: hkn0404:1363862:1363969 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1363862:1363969 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  5: hkn0404:1363874:1363976 [1] NCCL INFO Connected all trees
  5: hkn0404:1363874:1363976 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  5: hkn0404:1363874:1363976 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  4: hkn0404:1363862:1363969 [0] NCCL INFO comm 0x14c35c008fb0 rank 4 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  7: hkn0404:1363854:1363975 [3] NCCL INFO comm 0x14d1a4008fb0 rank 7 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  6: hkn0404:1363846:1363970 [2] NCCL INFO comm 0x14bd08008fb0 rank 6 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  5: hkn0404:1363874:1363976 [1] NCCL INFO comm 0x154dec008fb0 rank 5 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  1: hkn0403:1808437:1808809 [1] NCCL INFO Connected all trees
  1: hkn0403:1808437:1808809 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  1: hkn0403:1808437:1808809 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1808436:1808801 [0] NCCL INFO Connected all trees
  0: hkn0403:1808436:1808801 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1808436:1808801 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  1: hkn0403:1808437:1808809 [1] NCCL INFO comm 0x14632c008fb0 rank 1 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  0: hkn0403:1808436:1808801 [0] NCCL INFO comm 0x1511b4008fb0 rank 0 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  2: hkn0403:1808457:1808810 [2] NCCL INFO comm 0x1531a0008fb0 rank 2 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  3: hkn0403:1808445:1808808 [3] NCCL INFO comm 0x14d458008fb0 rank 3 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  0: hkn0403:1808436:1808436 [0] NCCL INFO Launch mode Parallel
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801031, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "deepcam", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 55}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801096, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HelmholtzAI", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 58}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801096, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 61}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801097, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 64}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801097, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "HoreKa", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 67}}
211: hdf5!!
232: hdf5!!
320: hdf5!!
193: hdf5!!
355: hdf5!!
160: hdf5!!
 91: hdf5!!
  2: hdf5!!
316: hdf5!!
268: hdf5!!
221: hdf5!!
304: hdf5!!
256: hdf5!!
 42: hdf5!!
379: hdf5!!
217: hdf5!!
109: hdf5!!
433: hdf5!!
204: hdf5!!
362: hdf5!!
384: hdf5!!
300: hdf5!!
 45: hdf5!!
321: hdf5!!
263: hdf5!!
369: hdf5!!
287: hdf5!!
142: hdf5!!
250: hdf5!!
 26: hdf5!!
158: hdf5!!
133: hdf5!!
 13: hdf5!!
 79: hdf5!!
162: hdf5!!
196: hdf5!!
424: hdf5!!
403: hdf5!!
274: hdf5!!
382: hdf5!!
107: hdf5!!
359: hdf5!!
 92: hdf5!!
169: hdf5!!
 84: hdf5!!
 56: hdf5!!
502: hdf5!!
152: hdf5!!
191: hdf5!!
507: hdf5!!
492: hdf5!!
476: hdf5!!
467: hdf5!!
  3: hdf5!!
 53: hdf5!!
208: hdf5!!
 17: hdf5!!
269: hdf5!!
113: hdf5!!
234: hdf5!!
222: hdf5!!
281: hdf5!!
306: hdf5!!
259: hdf5!!
 40: hdf5!!
376: hdf5!!
218: hdf5!!
110: hdf5!!
435: hdf5!!
205: hdf5!!
410: hdf5!!
360: hdf5!!
290: hdf5!!
242: hdf5!!
267: hdf5!!
386: hdf5!!
302: hdf5!!
 47: hdf5!!
442: hdf5!!
323: hdf5!!
 35: hdf5!!
407: hdf5!!
296: hdf5!!
285: hdf5!!
212: hdf5!!
249: hdf5!!
144: hdf5!!
 24: hdf5!!
159: hdf5!!
230: hdf5!!
122: hdf5!!
134: hdf5!!
 14: hdf5!!
 48: hdf5!!
 38: hdf5!!
194: hdf5!!
 61: hdf5!!
182: hdf5!!
436: hdf5!!
  6: hdf5!!
365: hdf5!!
174: hdf5!!
 78: hdf5!!
354: hdf5!!
 67: hdf5!!
161: hdf5!!
101: hdf5!!
 30: hdf5!!
125: hdf5!!
 88: hdf5!!
247: hdf5!!
151: hdf5!!
136: hdf5!!
508: hdf5!!
426: hdf5!!
400: hdf5!!
184: hdf5!!
451: hdf5!!
275: hdf5!!
178: hdf5!!
 23: hdf5!!
383: hdf5!!
106: hdf5!!
311: hdf5!!
358: hdf5!!
 83: hdf5!!
130: hdf5!!
164: hdf5!!
117: hdf5!!
452: hdf5!!
 95: hdf5!!
 73: hdf5!!
170: hdf5!!
 98: hdf5!!
 87: hdf5!!
202: hdf5!!
 58: hdf5!!
154: hdf5!!
190: hdf5!!
  8: hdf5!!
413: hdf5!!
388: hdf5!!
504: hdf5!!
468: hdf5!!
393: hdf5!!
430: hdf5!!
421: hdf5!!
482: hdf5!!
490: hdf5!!
493: hdf5!!
417: hdf5!!
497: hdf5!!
399: hdf5!!
465: hdf5!!
486: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801217, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 98}}
 52: hdf5!!
209: hdf5!!
 18: hdf5!!
318: hdf5!!
295: hdf5!!
271: hdf5!!
112: hdf5!!
235: hdf5!!
223: hdf5!!
280: hdf5!!
305: hdf5!!
258: hdf5!!
 43: hdf5!!
475: hdf5!!
377: hdf5!!
219: hdf5!!
111: hdf5!!
432: hdf5!!
206: hdf5!!
409: hdf5!!
314: hdf5!!
363: hdf5!!
291: hdf5!!
240: hdf5!!
264: hdf5!!
385: hdf5!!
301: hdf5!!
277: hdf5!!
254: hdf5!!
349: hdf5!!
224: hdf5!!
 46: hdf5!!
443: hdf5!!
 68: hdf5!!
322: hdf5!!
260: hdf5!!
 34: hdf5!!
404: hdf5!!
299: hdf5!!
370: hdf5!!
286: hdf5!!
236: hdf5!!
140: hdf5!!
213: hdf5!!
248: hdf5!!
145: hdf5!!
 25: hdf5!!
157: hdf5!!
231: hdf5!!
121: hdf5!!
132: hdf5!!
 15: hdf5!!
 51: hdf5!!
 36: hdf5!!
444: hdf5!!
336: hdf5!!
195: hdf5!!
 60: hdf5!!
180: hdf5!!
439: hdf5!!
  7: hdf5!!
366: hdf5!!
175: hdf5!!
 77: hdf5!!
340: hdf5!!
328: hdf5!!
352: hdf5!!
 65: hdf5!!
163: hdf5!!
103: hdf5!!
 29: hdf5!!
126: hdf5!!
 89: hdf5!!
460: hdf5!!
245: hdf5!!
149: hdf5!!
137: hdf5!!
198: hdf5!!
509: hdf5!!
425: hdf5!!
402: hdf5!!
185: hdf5!!
450: hdf5!!
272: hdf5!!
345: hdf5!!
179: hdf5!!
 20: hdf5!!
380: hdf5!!
105: hdf5!!
308: hdf5!!
357: hdf5!!
334: hdf5!!
 80: hdf5!!
129: hdf5!!
166: hdf5!!
118: hdf5!!
453: hdf5!!
 93: hdf5!!
 74: hdf5!!
171: hdf5!!
 97: hdf5!!
373: hdf5!!
 85: hdf5!!
200: hdf5!!
 59: hdf5!!
500: hdf5!!
155: hdf5!!
188: hdf5!!
  9: hdf5!!
415: hdf5!!
391: hdf5!!
506: hdf5!!
470: hdf5!!
458: hdf5!!
394: hdf5!!
428: hdf5!!
422: hdf5!!
483: hdf5!!
488: hdf5!!
494: hdf5!!
418: hdf5!!
478: hdf5!!
498: hdf5!!
397: hdf5!!
466: hdf5!!
487: hdf5!!
  1: hdf5!!
 54: hdf5!!
210: hdf5!!
 16: hdf5!!
319: hdf5!!
292: hdf5!!
270: hdf5!!
114: hdf5!!
233: hdf5!!
220: hdf5!!
283: hdf5!!
307: hdf5!!
257: hdf5!!
 41: hdf5!!
472: hdf5!!
378: hdf5!!
216: hdf5!!
108: hdf5!!
434: hdf5!!
207: hdf5!!
408: hdf5!!
312: hdf5!!
361: hdf5!!
289: hdf5!!
241: hdf5!!
265: hdf5!!
387: hdf5!!
303: hdf5!!
276: hdf5!!
253: hdf5!!
350: hdf5!!
225: hdf5!!
 44: hdf5!!
440: hdf5!!
 69: hdf5!!
262: hdf5!!
 32: hdf5!!
405: hdf5!!
297: hdf5!!
368: hdf5!!
284: hdf5!!
238: hdf5!!
141: hdf5!!
215: hdf5!!
251: hdf5!!
147: hdf5!!
327: hdf5!!
 27: hdf5!!
156: hdf5!!
228: hdf5!!
123: hdf5!!
135: hdf5!!
 12: hdf5!!
 50: hdf5!!
 39: hdf5!!
446: hdf5!!
338: hdf5!!
192: hdf5!!
 62: hdf5!!
183: hdf5!!
438: hdf5!!
  4: hdf5!!
364: hdf5!!
172: hdf5!!
 76: hdf5!!
341: hdf5!!
330: hdf5!!
353: hdf5!!
 66: hdf5!!
102: hdf5!!
 31: hdf5!!
124: hdf5!!
 90: hdf5!!
461: hdf5!!
246: hdf5!!
148: hdf5!!
139: hdf5!!
197: hdf5!!
511: hdf5!!
427: hdf5!!
401: hdf5!!
186: hdf5!!
448: hdf5!!
273: hdf5!!
347: hdf5!!
177: hdf5!!
 22: hdf5!!
381: hdf5!!
104: hdf5!!
309: hdf5!!
356: hdf5!!
333: hdf5!!
 82: hdf5!!
131: hdf5!!
167: hdf5!!
116: hdf5!!
454: hdf5!!
 94: hdf5!!
 75: hdf5!!
168: hdf5!!
 99: hdf5!!
374: hdf5!!
 86: hdf5!!
201: hdf5!!
 57: hdf5!!
501: hdf5!!
153: hdf5!!
189: hdf5!!
 10: hdf5!!
412: hdf5!!
389: hdf5!!
505: hdf5!!
469: hdf5!!
459: hdf5!!
395: hdf5!!
429: hdf5!!
423: hdf5!!
481: hdf5!!
491: hdf5!!
495: hdf5!!
419: hdf5!!
479: hdf5!!
496: hdf5!!
396: hdf5!!
464: hdf5!!
484: hdf5!!
 55: hdf5!!
 19: hdf5!!
317: hdf5!!
294: hdf5!!
115: hdf5!!
282: hdf5!!
473: hdf5!!
411: hdf5!!
313: hdf5!!
288: hdf5!!
243: hdf5!!
266: hdf5!!
278: hdf5!!
255: hdf5!!
351: hdf5!!
226: hdf5!!
441: hdf5!!
 70: hdf5!!
261: hdf5!!
 33: hdf5!!
406: hdf5!!
298: hdf5!!
371: hdf5!!
239: hdf5!!
143: hdf5!!
214: hdf5!!
146: hdf5!!
325: hdf5!!
229: hdf5!!
120: hdf5!!
 49: hdf5!!
 37: hdf5!!
447: hdf5!!
339: hdf5!!
 63: hdf5!!
181: hdf5!!
  5: hdf5!!
367: hdf5!!
173: hdf5!!
342: hdf5!!
331: hdf5!!
 64: hdf5!!
100: hdf5!!
 28: hdf5!!
127: hdf5!!
463: hdf5!!
244: hdf5!!
150: hdf5!!
138: hdf5!!
199: hdf5!!
510: hdf5!!
187: hdf5!!
449: hdf5!!
344: hdf5!!
176: hdf5!!
 21: hdf5!!
310: hdf5!!
332: hdf5!!
 81: hdf5!!
128: hdf5!!
165: hdf5!!
119: hdf5!!
455: hdf5!!
 72: hdf5!!
 96: hdf5!!
375: hdf5!!
203: hdf5!!
503: hdf5!!
 11: hdf5!!
414: hdf5!!
390: hdf5!!
471: hdf5!!
456: hdf5!!
392: hdf5!!
431: hdf5!!
420: hdf5!!
480: hdf5!!
489: hdf5!!
416: hdf5!!
477: hdf5!!
499: hdf5!!
398: hdf5!!
485: hdf5!!
293: hdf5!!
474: hdf5!!
315: hdf5!!
279: hdf5!!
252: hdf5!!
348: hdf5!!
227: hdf5!!
 71: hdf5!!
237: hdf5!!
326: hdf5!!
445: hdf5!!
337: hdf5!!
343: hdf5!!
329: hdf5!!
462: hdf5!!
346: hdf5!!
335: hdf5!!
372: hdf5!!
457: hdf5!!
324: hdf5!!
437: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801221, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 99}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415801221, "event_type": "POINT_IN_TIME", "key": "seed", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 103}}
  0: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
 45: root_dir: /tmp/deepcam/instance0
 17: root_dir: /tmp/deepcam/instance0
398: root_dir: /tmp/deepcam/instance0
138: root_dir: /tmp/deepcam/instance0
 41: root_dir: /tmp/deepcam/instance0
 64: root_dir: /tmp/deepcam/instance0
 43: root_dir: /tmp/deepcam/instance0
213: root_dir: /tmp/deepcam/instance0
274: root_dir: /tmp/deepcam/instance0
431: root_dir: /tmp/deepcam/instance0
153: root_dir: /tmp/deepcam/instance0
317: root_dir: /tmp/deepcam/instance0
155: root_dir: /tmp/deepcam/instance0
 67: root_dir: /tmp/deepcam/instance0
136: root_dir: /tmp/deepcam/instance0
182: root_dir: /tmp/deepcam/instance0
407: root_dir: /tmp/deepcam/instance0
418: root_dir: /tmp/deepcam/instance0
285: root_dir: /tmp/deepcam/instance0
419: root_dir: /tmp/deepcam/instance0
293: root_dir: /tmp/deepcam/instance0
279: root_dir: /tmp/deepcam/instance0
404: root_dir: /tmp/deepcam/instance0
275: root_dir: /tmp/deepcam/instance0
444: root_dir: /tmp/deepcam/instance0
167: root_dir: /tmp/deepcam/instance0
255: root_dir: /tmp/deepcam/instance0
318: root_dir: /tmp/deepcam/instance0
181: root_dir: /tmp/deepcam/instance0
287: root_dir: /tmp/deepcam/instance0
101: root_dir: /tmp/deepcam/instance0
 85: root_dir: /tmp/deepcam/instance0
165: root_dir: /tmp/deepcam/instance0
395: root_dir: /tmp/deepcam/instance0
215: root_dir: /tmp/deepcam/instance0
432: root_dir: /tmp/deepcam/instance0
458: root_dir: /tmp/deepcam/instance0
 86: root_dir: /tmp/deepcam/instance0
184: root_dir: /tmp/deepcam/instance0
426: root_dir: /tmp/deepcam/instance0
484: root_dir: /tmp/deepcam/instance0
490: root_dir: /tmp/deepcam/instance0
456: root_dir: /tmp/deepcam/instance0
 53: root_dir: /tmp/deepcam/instance0
277: root_dir: /tmp/deepcam/instance0
479: root_dir: /tmp/deepcam/instance0
427: root_dir: /tmp/deepcam/instance0
147: root_dir: /tmp/deepcam/instance0
 20: root_dir: /tmp/deepcam/instance0
112: root_dir: /tmp/deepcam/instance0
 31: root_dir: /tmp/deepcam/instance0
271: root_dir: /tmp/deepcam/instance0
429: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
186: root_dir: /tmp/deepcam/instance0
332: root_dir: /tmp/deepcam/instance0
253: root_dir: /tmp/deepcam/instance0
225: root_dir: /tmp/deepcam/instance0
 21: root_dir: /tmp/deepcam/instance0
145: root_dir: /tmp/deepcam/instance0
222: root_dir: /tmp/deepcam/instance0
 51: root_dir: /tmp/deepcam/instance0
114: root_dir: /tmp/deepcam/instance0
477: root_dir: /tmp/deepcam/instance0
 74: root_dir: /tmp/deepcam/instance0
365: root_dir: /tmp/deepcam/instance0
295: root_dir: /tmp/deepcam/instance0
435: root_dir: /tmp/deepcam/instance0
144: root_dir: /tmp/deepcam/instance0
357: root_dir: /tmp/deepcam/instance0
164: root_dir: /tmp/deepcam/instance0
 50: root_dir: /tmp/deepcam/instance0
491: root_dir: /tmp/deepcam/instance0
364: root_dir: /tmp/deepcam/instance0
375: root_dir: /tmp/deepcam/instance0
 12: root_dir: /tmp/deepcam/instance0
192: root_dir: /tmp/deepcam/instance0
360: root_dir: /tmp/deepcam/instance0
 91: root_dir: /tmp/deepcam/instance0
  5: root_dir: /tmp/deepcam/instance0
489: root_dir: /tmp/deepcam/instance0
268: root_dir: /tmp/deepcam/instance0
478: root_dir: /tmp/deepcam/instance0
387: root_dir: /tmp/deepcam/instance0
322: root_dir: /tmp/deepcam/instance0
 29: root_dir: /tmp/deepcam/instance0
234: root_dir: /tmp/deepcam/instance0
 23: root_dir: /tmp/deepcam/instance0
 54: root_dir: /tmp/deepcam/instance0
470: root_dir: /tmp/deepcam/instance0
 75: root_dir: /tmp/deepcam/instance0
169: root_dir: /tmp/deepcam/instance0
448: root_dir: /tmp/deepcam/instance0
469: root_dir: /tmp/deepcam/instance0
  7: root_dir: /tmp/deepcam/instance0
 15: root_dir: /tmp/deepcam/instance0
133: root_dir: /tmp/deepcam/instance0
500: root_dir: /tmp/deepcam/instance0
450: root_dir: /tmp/deepcam/instance0
231: root_dir: /tmp/deepcam/instance0
236: root_dir: /tmp/deepcam/instance0
314: root_dir: /tmp/deepcam/instance0
198: root_dir: /tmp/deepcam/instance0
467: root_dir: /tmp/deepcam/instance0
170: root_dir: /tmp/deepcam/instance0
 89: root_dir: /tmp/deepcam/instance0
376: root_dir: /tmp/deepcam/instance0
400: root_dir: /tmp/deepcam/instance0
323: root_dir: /tmp/deepcam/instance0
502: root_dir: /tmp/deepcam/instance0
 55: root_dir: /tmp/deepcam/instance0
 30: root_dir: /tmp/deepcam/instance0
235: root_dir: /tmp/deepcam/instance0
 58: root_dir: /tmp/deepcam/instance0
388: root_dir: /tmp/deepcam/instance0
363: root_dir: /tmp/deepcam/instance0
218: root_dir: /tmp/deepcam/instance0
492: root_dir: /tmp/deepcam/instance0
 25: root_dir: /tmp/deepcam/instance0
199: root_dir: /tmp/deepcam/instance0
501: root_dir: /tmp/deepcam/instance0
122: root_dir: /tmp/deepcam/instance0
 32: root_dir: /tmp/deepcam/instance0
250: root_dir: /tmp/deepcam/instance0
103: root_dir: /tmp/deepcam/instance0
216: root_dir: /tmp/deepcam/instance0
 26: root_dir: /tmp/deepcam/instance0
197: root_dir: /tmp/deepcam/instance0
171: root_dir: /tmp/deepcam/instance0
 80: root_dir: /tmp/deepcam/instance0
434: root_dir: /tmp/deepcam/instance0
466: root_dir: /tmp/deepcam/instance0
508: root_dir: /tmp/deepcam/instance0
423: root_dir: /tmp/deepcam/instance0
402: root_dir: /tmp/deepcam/instance0
421: root_dir: /tmp/deepcam/instance0
 27: root_dir: /tmp/deepcam/instance0
451: root_dir: /tmp/deepcam/instance0
248: root_dir: /tmp/deepcam/instance0
445: root_dir: /tmp/deepcam/instance0
425: root_dir: /tmp/deepcam/instance0
390: root_dir: /tmp/deepcam/instance0
509: root_dir: /tmp/deepcam/instance0
377: root_dir: /tmp/deepcam/instance0
134: root_dir: /tmp/deepcam/instance0
  2: root_dir: /tmp/deepcam/instance0
 90: root_dir: /tmp/deepcam/instance0
158: root_dir: /tmp/deepcam/instance0
496: root_dir: /tmp/deepcam/instance0
315: root_dir: /tmp/deepcam/instance0
 14: root_dir: /tmp/deepcam/instance0
202: root_dir: /tmp/deepcam/instance0
355: root_dir: /tmp/deepcam/instance0
 92: root_dir: /tmp/deepcam/instance0
 63: root_dir: /tmp/deepcam/instance0
220: root_dir: /tmp/deepcam/instance0
384: root_dir: /tmp/deepcam/instance0
282: root_dir: /tmp/deepcam/instance0
380: root_dir: /tmp/deepcam/instance0
 95: root_dir: /tmp/deepcam/instance0
401: root_dir: /tmp/deepcam/instance0
 34: root_dir: /tmp/deepcam/instance0
 72: root_dir: /tmp/deepcam/instance0
224: root_dir: /tmp/deepcam/instance0
280: root_dir: /tmp/deepcam/instance0
232: root_dir: /tmp/deepcam/instance0
372: root_dir: /tmp/deepcam/instance0
126: root_dir: /tmp/deepcam/instance0
349: root_dir: /tmp/deepcam/instance0
333: root_dir: /tmp/deepcam/instance0
104: root_dir: /tmp/deepcam/instance0
482: root_dir: /tmp/deepcam/instance0
481: root_dir: /tmp/deepcam/instance0
338: root_dir: /tmp/deepcam/instance0
200: root_dir: /tmp/deepcam/instance0
485: root_dir: /tmp/deepcam/instance0
 83: root_dir: /tmp/deepcam/instance0
124: root_dir: /tmp/deepcam/instance0
472: root_dir: /tmp/deepcam/instance0
383: root_dir: /tmp/deepcam/instance0
172: root_dir: /tmp/deepcam/instance0
211: root_dir: /tmp/deepcam/instance0
156: root_dir: /tmp/deepcam/instance0
352: root_dir: /tmp/deepcam/instance0
221: root_dir: /tmp/deepcam/instance0
473: root_dir: /tmp/deepcam/instance0
373: root_dir: /tmp/deepcam/instance0
409: root_dir: /tmp/deepcam/instance0
265: root_dir: /tmp/deepcam/instance0
283: root_dir: /tmp/deepcam/instance0
125: root_dir: /tmp/deepcam/instance0
257: root_dir: /tmp/deepcam/instance0
264: root_dir: /tmp/deepcam/instance0
141: root_dir: /tmp/deepcam/instance0
123: root_dir: /tmp/deepcam/instance0
381: root_dir: /tmp/deepcam/instance0
436: root_dir: /tmp/deepcam/instance0
143: root_dir: /tmp/deepcam/instance0
 37: root_dir: /tmp/deepcam/instance0
511: root_dir: /tmp/deepcam/instance0
267: root_dir: /tmp/deepcam/instance0
452: root_dir: /tmp/deepcam/instance0
 82: root_dir: /tmp/deepcam/instance0
453: root_dir: /tmp/deepcam/instance0
353: root_dir: /tmp/deepcam/instance0
309: root_dir: /tmp/deepcam/instance0
 61: root_dir: /tmp/deepcam/instance0
313: root_dir: /tmp/deepcam/instance0
 35: root_dir: /tmp/deepcam/instance0
306: root_dir: /tmp/deepcam/instance0
497: root_dir: /tmp/deepcam/instance0
 78: root_dir: /tmp/deepcam/instance0
242: root_dir: /tmp/deepcam/instance0
480: root_dir: /tmp/deepcam/instance0
201: root_dir: /tmp/deepcam/instance0
422: root_dir: /tmp/deepcam/instance0
159: root_dir: /tmp/deepcam/instance0
 93: root_dir: /tmp/deepcam/instance0
207: root_dir: /tmp/deepcam/instance0
308: root_dir: /tmp/deepcam/instance0
 76: root_dir: /tmp/deepcam/instance0
157: root_dir: /tmp/deepcam/instance0
260: root_dir: /tmp/deepcam/instance0
339: root_dir: /tmp/deepcam/instance0
194: root_dir: /tmp/deepcam/instance0
336: root_dir: /tmp/deepcam/instance0
258: root_dir: /tmp/deepcam/instance0
441: root_dir: /tmp/deepcam/instance0
127: root_dir: /tmp/deepcam/instance0
142: root_dir: /tmp/deepcam/instance0
439: root_dir: /tmp/deepcam/instance0
493: root_dir: /tmp/deepcam/instance0
118: root_dir: /tmp/deepcam/instance0
230: root_dir: /tmp/deepcam/instance0
110: root_dir: /tmp/deepcam/instance0
 62: root_dir: /tmp/deepcam/instance0
454: root_dir: /tmp/deepcam/instance0
474: root_dir: /tmp/deepcam/instance0
486: root_dir: /tmp/deepcam/instance0
455: root_dir: /tmp/deepcam/instance0
475: root_dir: /tmp/deepcam/instance0
148: root_dir: /tmp/deepcam/instance0
266: root_dir: /tmp/deepcam/instance0
 57: root_dir: /tmp/deepcam/instance0
120: root_dir: /tmp/deepcam/instance0
382: root_dir: /tmp/deepcam/instance0
109: root_dir: /tmp/deepcam/instance0
150: root_dir: /tmp/deepcam/instance0
 60: root_dir: /tmp/deepcam/instance0
440: root_dir: /tmp/deepcam/instance0
 77: root_dir: /tmp/deepcam/instance0
238: root_dir: /tmp/deepcam/instance0
465: root_dir: /tmp/deepcam/instance0
305: root_dir: /tmp/deepcam/instance0
111: root_dir: /tmp/deepcam/instance0
354: root_dir: /tmp/deepcam/instance0
358: root_dir: /tmp/deepcam/instance0
 96: root_dir: /tmp/deepcam/instance0
240: root_dir: /tmp/deepcam/instance0
237: root_dir: /tmp/deepcam/instance0
174: root_dir: /tmp/deepcam/instance0
208: root_dir: /tmp/deepcam/instance0
130: root_dir: /tmp/deepcam/instance0
347: root_dir: /tmp/deepcam/instance0
219: root_dir: /tmp/deepcam/instance0
 71: root_dir: /tmp/deepcam/instance0
117: root_dir: /tmp/deepcam/instance0
 38: root_dir: /tmp/deepcam/instance0
483: root_dir: /tmp/deepcam/instance0
498: root_dir: /tmp/deepcam/instance0
259: root_dir: /tmp/deepcam/instance0
135: root_dir: /tmp/deepcam/instance0
443: root_dir: /tmp/deepcam/instance0
359: root_dir: /tmp/deepcam/instance0
350: root_dir: /tmp/deepcam/instance0
 36: root_dir: /tmp/deepcam/instance0
108: root_dir: /tmp/deepcam/instance0
420: root_dir: /tmp/deepcam/instance0
270: root_dir: /tmp/deepcam/instance0
495: root_dir: /tmp/deepcam/instance0
411: root_dir: /tmp/deepcam/instance0
128: root_dir: /tmp/deepcam/instance0
328: root_dir: /tmp/deepcam/instance0
327: root_dir: /tmp/deepcam/instance0
249: root_dir: /tmp/deepcam/instance0
437: root_dir: /tmp/deepcam/instance0
368: root_dir: /tmp/deepcam/instance0
442: root_dir: /tmp/deepcam/instance0
326: root_dir: /tmp/deepcam/instance0
149: root_dir: /tmp/deepcam/instance0
  1: root_dir: /tmp/deepcam/instance0
262: root_dir: /tmp/deepcam/instance0
  3: root_dir: /tmp/deepcam/instance0
459: root_dir: /tmp/deepcam/instance0
371: root_dir: /tmp/deepcam/instance0
464: root_dir: /tmp/deepcam/instance0
209: root_dir: /tmp/deepcam/instance0
173: root_dir: /tmp/deepcam/instance0
370: root_dir: /tmp/deepcam/instance0
298: root_dir: /tmp/deepcam/instance0
190: root_dir: /tmp/deepcam/instance0
226: root_dir: /tmp/deepcam/instance0
499: root_dir: /tmp/deepcam/instance0
310: root_dir: /tmp/deepcam/instance0
243: root_dir: /tmp/deepcam/instance0
 69: root_dir: /tmp/deepcam/instance0
116: root_dir: /tmp/deepcam/instance0
 70: root_dir: /tmp/deepcam/instance0
494: root_dir: /tmp/deepcam/instance0
256: root_dir: /tmp/deepcam/instance0
299: root_dir: /tmp/deepcam/instance0
140: root_dir: /tmp/deepcam/instance0
 33: root_dir: /tmp/deepcam/instance0
348: root_dir: /tmp/deepcam/instance0
301: root_dir: /tmp/deepcam/instance0
311: root_dir: /tmp/deepcam/instance0
  9: root_dir: /tmp/deepcam/instance0
307: root_dir: /tmp/deepcam/instance0
229: root_dir: /tmp/deepcam/instance0
345: root_dir: /tmp/deepcam/instance0
245: root_dir: /tmp/deepcam/instance0
341: root_dir: /tmp/deepcam/instance0
367: root_dir: /tmp/deepcam/instance0
410: root_dir: /tmp/deepcam/instance0
415: root_dir: /tmp/deepcam/instance0
346: root_dir: /tmp/deepcam/instance0
438: root_dir: /tmp/deepcam/instance0
504: root_dir: /tmp/deepcam/instance0
204: root_dir: /tmp/deepcam/instance0
191: root_dir: /tmp/deepcam/instance0
261: root_dir: /tmp/deepcam/instance0
 11: root_dir: /tmp/deepcam/instance0
325: root_dir: /tmp/deepcam/instance0
 79: root_dir: /tmp/deepcam/instance0
344: root_dir: /tmp/deepcam/instance0
263: root_dir: /tmp/deepcam/instance0
335: root_dir: /tmp/deepcam/instance0
160: root_dir: /tmp/deepcam/instance0
369: root_dir: /tmp/deepcam/instance0
 68: root_dir: /tmp/deepcam/instance0
175: root_dir: /tmp/deepcam/instance0
105: root_dir: /tmp/deepcam/instance0
205: root_dir: /tmp/deepcam/instance0
129: root_dir: /tmp/deepcam/instance0
385: root_dir: /tmp/deepcam/instance0
471: root_dir: /tmp/deepcam/instance0
379: root_dir: /tmp/deepcam/instance0
324: root_dir: /tmp/deepcam/instance0
462: root_dir: /tmp/deepcam/instance0
343: root_dir: /tmp/deepcam/instance0
342: root_dir: /tmp/deepcam/instance0
246: root_dir: /tmp/deepcam/instance0
151: root_dir: /tmp/deepcam/instance0
 10: root_dir: /tmp/deepcam/instance0
413: root_dir: /tmp/deepcam/instance0
414: root_dir: /tmp/deepcam/instance0
161: root_dir: /tmp/deepcam/instance0
506: root_dir: /tmp/deepcam/instance0
297: root_dir: /tmp/deepcam/instance0
302: root_dir: /tmp/deepcam/instance0
106: root_dir: /tmp/deepcam/instance0
460: root_dir: /tmp/deepcam/instance0
340: root_dir: /tmp/deepcam/instance0
163: root_dir: /tmp/deepcam/instance0
374: root_dir: /tmp/deepcam/instance0
244: root_dir: /tmp/deepcam/instance0
241: root_dir: /tmp/deepcam/instance0
463: root_dir: /tmp/deepcam/instance0
121: root_dir: /tmp/deepcam/instance0
412: root_dir: /tmp/deepcam/instance0
188: root_dir: /tmp/deepcam/instance0
507: root_dir: /tmp/deepcam/instance0
247: root_dir: /tmp/deepcam/instance0
162: root_dir: /tmp/deepcam/instance0
330: root_dir: /tmp/deepcam/instance0
361: root_dir: /tmp/deepcam/instance0
176: root_dir: /tmp/deepcam/instance0
505: root_dir: /tmp/deepcam/instance0
 59: root_dir: /tmp/deepcam/instance0
461: root_dir: /tmp/deepcam/instance0
179: root_dir: /tmp/deepcam/instance0
206: root_dir: /tmp/deepcam/instance0
 48: root_dir: /tmp/deepcam/instance0
178: root_dir: /tmp/deepcam/instance0
 97: root_dir: /tmp/deepcam/instance0
177: root_dir: /tmp/deepcam/instance0
303: root_dir: /tmp/deepcam/instance0
329: root_dir: /tmp/deepcam/instance0
  8: root_dir: /tmp/deepcam/instance0
 18: root_dir: /tmp/deepcam/instance0
331: root_dir: /tmp/deepcam/instance0
291: root_dir: /tmp/deepcam/instance0
189: root_dir: /tmp/deepcam/instance0
195: root_dir: /tmp/deepcam/instance0
300: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
446: root_dir: /tmp/deepcam/instance0
288: root_dir: /tmp/deepcam/instance0
131: root_dir: /tmp/deepcam/instance0
289: root_dir: /tmp/deepcam/instance0
  0: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890286, "event_type": "POINT_IN_TIME", "key": "number_of_ranks", "value": 512, "metadata": {"file": "./train_instance.py", "lineno": 211}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890288, "event_type": "POINT_IN_TIME", "key": "number_of_nodes", "value": 128, "metadata": {"file": "./train_instance.py", "lineno": 212}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890288, "event_type": "POINT_IN_TIME", "key": "accelerators_per_node", "value": 4, "metadata": {"file": "./train_instance.py", "lineno": 213}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890288, "event_type": "POINT_IN_TIME", "key": "instance_id", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 215}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890289, "event_type": "POINT_IN_TIME", "key": "checkpoint", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 217}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890289, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "./train_instance.py", "lineno": 218}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890289, "event_type": "POINT_IN_TIME", "key": "batchnorm_group_size", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 219}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890289, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_frequency", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890289, "event_type": "POINT_IN_TIME", "key": "data_format", "value": "dali-numpy/hdf5", "metadata": {"file": "./train_instance.py", "lineno": 222}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890289, "event_type": "POINT_IN_TIME", "key": "shuffle_mode", "value": "global", "metadata": {"file": "./train_instance.py", "lineno": 223}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890289, "event_type": "POINT_IN_TIME", "key": "data_oversampling_factor", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 224}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890296, "event_type": "POINT_IN_TIME", "key": "stage_dir_prefix", "value": "/tmp/deepcam", "metadata": {"file": "./train_instance.py", "lineno": 226}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890296, "event_type": "POINT_IN_TIME", "key": "stage_mode", "value": "node", "metadata": {"file": "./train_instance.py", "lineno": 227}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890296, "event_type": "POINT_IN_TIME", "key": "stage_batch_size", "value": -1, "metadata": {"file": "./train_instance.py", "lineno": 228}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890296, "event_type": "POINT_IN_TIME", "key": "stage_verify", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 229}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890296, "event_type": "POINT_IN_TIME", "key": "stage_full_data_per_node", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890296, "event_type": "POINT_IN_TIME", "key": "stage_use_direct_io", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 231}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890296, "event_type": "POINT_IN_TIME", "key": "precision_mode", "value": "amp", "metadata": {"file": "./train_instance.py", "lineno": 233}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890297, "event_type": "POINT_IN_TIME", "key": "enable_nhwc", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 234}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890297, "event_type": "POINT_IN_TIME", "key": "enable_graph", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 235}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890297, "event_type": "POINT_IN_TIME", "key": "enable_jit", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415890297, "event_type": "POINT_IN_TIME", "key": "disable_comm_overlap", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 237}}
  0: Constructing DeepLabv3+ model...
  0: Number of output channels: 3
  0: Output stride: 16
  0: Number of Input Channels: 16
290: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891020, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "LAMB", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 144}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891021, "event_type": "POINT_IN_TIME", "key": "opt_lr", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891021, "event_type": "POINT_IN_TIME", "key": "opt_bias_correction", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891021, "event_type": "POINT_IN_TIME", "key": "opt_betas", "value": [0.9, 0.999], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891021, "event_type": "POINT_IN_TIME", "key": "opt_eps", "value": 1e-06, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891021, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.01, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891021, "event_type": "POINT_IN_TIME", "key": "opt_grad_averaging", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891022, "event_type": "POINT_IN_TIME", "key": "opt_max_grad_norm", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891022, "event_type": "POINT_IN_TIME", "key": "scheduler_type", "value": "multistep", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891023, "event_type": "POINT_IN_TIME", "key": "scheduler_milestones", "value": [1100, 4096], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891023, "event_type": "POINT_IN_TIME", "key": "scheduler_decay_rate", "value": 0.1, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891023, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_steps", "value": 200, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415891023, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_factor", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: DeepLabv3_plus(
  0:   (xception_features): Xception(
  0:     (relu): ReLU()
  0:     (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  0:     (bn1): Sequential(
  0:       (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:     (bn2): Sequential(
  0:       (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (block1): Block(
  0:       (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
  0:           (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Seque
  0: ntial(
  0:           (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block2): Block(
  0:       (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1):
  0:  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block3): Block(
  0:       (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), 
  0: bias=False)
  0:       (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (2): ReLU()
  0:         (3): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (5): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2
  0: d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block4): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size
  0: =(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block5): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm
  0: 2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block6): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), 
  0: padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block7): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, mome
  0: ntum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block8): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=
  0: 728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block
  0: 9): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d
  0: (728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block10): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU
  0: ()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block11): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_siz
  0: e=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block12): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (
  0: 2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block13): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1
  0: ), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block14): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_s
  0: ame(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchN
  0: orm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block15): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kern
  0: el_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block16): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): B
  0: atchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block17): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), strid
  0: e=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block18): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1
  0: e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block19): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 
  0: 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0: 
  0:     (block20): Block(
  0:       (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:        
  0:    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
  0:           (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (conv3): SeparableConv2d_same(
  0:       (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1024, bias=False)
  0:       (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn3): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv4): SeparableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn4): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv5): Separ
  0: ableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn5): Sequential(
  0:       (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (bottleneck): Bottleneck(
  0:     (aspp1): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp2): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp3): ASPP_module(
  0:       (atrous_co
  0: nvolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp4): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (global_avg_pool): GlobalAveragePool(
  0:       (global_average_pool): Sequential(
  0:         (0): AdaptiveAvgPool2d(output_size=(1, 1))
  0:         (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         (2): TrainableAffine()
  0:         (3): ReLU(inplace=True)
  0:       )
  0:     )
  0:     (tiling): Tiling()
  0:     (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     (bn): Sequential(
  0:       (0): BatchNorm2d(256, eps=1e-05, 
  0: momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (conv2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:   (bn2): Sequential(
  0:     (0): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:     (1): ReLU()
  0:   )
  0:   (upsample): DeconvUpsampler(
  0:     (deconv1): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (conv1): Sequential(
  0:       (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0: 
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  0:     )
  0:     (deconv2): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (last_deconv): Sequential(
  0:       (0): ConvTranspose2d(256, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:     )
  0:   )
  0: )
  0: Number of trainable parameters: 56454720
  0: Creating Dataloaders
351: root_dir: /tmp/deepcam/instance0
115: root_dir: /tmp/deepcam/instance0
  6: root_dir: /tmp/deepcam/instance0
 56: root_dir: /tmp/deepcam/instance0
281: root_dir: /tmp/deepcam/instance0
304: root_dir: /tmp/deepcam/instance0
 39: root_dir: /tmp/deepcam/instance0
196: root_dir: /tmp/deepcam/instance0
510: root_dir: /tmp/deepcam/instance0
408: root_dir: /tmp/deepcam/instance0
378: root_dir: /tmp/deepcam/instance0
180: root_dir: /tmp/deepcam/instance0
 19: root_dir: /tmp/deepcam/instance0
424: root_dir: /tmp/deepcam/instance0
212: root_dir: /tmp/deepcam/instance0
 40: root_dir: /tmp/deepcam/instance0
428: root_dir: /tmp/deepcam/instance0
227: root_dir: /tmp/deepcam/instance0
146: root_dir: /tmp/deepcam/instance0
102: root_dir: /tmp/deepcam/instance0
 52: root_dir: /tmp/deepcam/instance0
278: root_dir: /tmp/deepcam/instance0
 47: root_dir: /tmp/deepcam/instance0
312: root_dir: /tmp/deepcam/instance0
 28: root_dir: /tmp/deepcam/instance0
334: root_dir: /tmp/deepcam/instance0
132: root_dir: /tmp/deepcam/instance0
389: root_dir: /tmp/deepcam/instance0
 22: root_dir: /tmp/deepcam/instance0
417: root_dir: /tmp/deepcam/instance0
393: root_dir: /tmp/deepcam/instance0
 16: root_dir: /tmp/deepcam/instance0
168: root_dir: /tmp/deepcam/instance0
252: root_dir: /tmp/deepcam/instance0
 49: root_dir: /tmp/deepcam/instance0
214: root_dir: /tmp/deepcam/instance0
403: root_dir: /tmp/deepcam/instance0
319: root_dir: /tmp/deepcam/instance0
251: root_dir: /tmp/deepcam/instance0
119: root_dir: /tmp/deepcam/instance0
392: root_dir: /tmp/deepcam/instance0
272: root_dir: /tmp/deepcam/instance0
 88: root_dir: /tmp/deepcam/instance0
107: root_dir: /tmp/deepcam/instance0
503: root_dir: /tmp/deepcam/instance0
 65: root_dir: /tmp/deepcam/instance0
139: root_dir: /tmp/deepcam/instance0
137: root_dir: /tmp/deepcam/instance0
337: root_dir: /tmp/deepcam/instance0
457: root_dir: /tmp/deepcam/instance0
166: root_dir: /tmp/deepcam/instance0
316: root_dir: /tmp/deepcam/instance0
321: root_dir: /tmp/deepcam/instance0
187: root_dir: /tmp/deepcam/instance0
152: root_dir: /tmp/deepcam/instance0
405: root_dir: /tmp/deepcam/instance0
 87: root_dir: /tmp/deepcam/instance0
488: root_dir: /tmp/deepcam/instance0
320: root_dir: /tmp/deepcam/instance0
468: root_dir: /tmp/deepcam/instance0
296: root_dir: /tmp/deepcam/instance0
 99: root_dir: /tmp/deepcam/instance0
217: root_dir: /tmp/deepcam/instance0
356: root_dir: /tmp/deepcam/instance0
391: root_dir: /tmp/deepcam/instance0
269: root_dir: /tmp/deepcam/instance0
433: root_dir: /tmp/deepcam/instance0
233: root_dir: /tmp/deepcam/instance0
113: root_dir: /tmp/deepcam/instance0
386: root_dir: /tmp/deepcam/instance0
397: root_dir: /tmp/deepcam/instance0
 81: root_dir: /tmp/deepcam/instance0
394: root_dir: /tmp/deepcam/instance0
362: root_dir: /tmp/deepcam/instance0
487: root_dir: /tmp/deepcam/instance0
 94: root_dir: /tmp/deepcam/instance0
 98: root_dir: /tmp/deepcam/instance0
406: root_dir: /tmp/deepcam/instance0
100: root_dir: /tmp/deepcam/instance0
 46: root_dir: /tmp/deepcam/instance0
 84: root_dir: /tmp/deepcam/instance0
366: root_dir: /tmp/deepcam/instance0
416: root_dir: /tmp/deepcam/instance0
  4: root_dir: /tmp/deepcam/instance0
449: root_dir: /tmp/deepcam/instance0
193: root_dir: /tmp/deepcam/instance0
476: root_dir: /tmp/deepcam/instance0
 24: root_dir: /tmp/deepcam/instance0
276: root_dir: /tmp/deepcam/instance0
 42: root_dir: /tmp/deepcam/instance0
185: root_dir: /tmp/deepcam/instance0
154: root_dir: /tmp/deepcam/instance0
183: root_dir: /tmp/deepcam/instance0
 13: root_dir: /tmp/deepcam/instance0
 73: root_dir: /tmp/deepcam/instance0
223: root_dir: /tmp/deepcam/instance0
 66: root_dir: /tmp/deepcam/instance0
447: root_dir: /tmp/deepcam/instance0
239: root_dir: /tmp/deepcam/instance0
228: root_dir: /tmp/deepcam/instance0
254: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633415911989, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 121266, "metadata": {"file": "./train_instance.py", "lineno": 353}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633415911990, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 15158, "metadata": {"file": "./train_instance.py", "lineno": 354}}
  0: Number of steps per epoch 118
  0: Creating Trainer
  0: Creating Validator
203: root_dir: /tmp/deepcam/instance0
430: root_dir: /tmp/deepcam/instance0
294: root_dir: /tmp/deepcam/instance0
273: root_dir: /tmp/deepcam/instance0
292: root_dir: /tmp/deepcam/instance0
396: root_dir: /tmp/deepcam/instance0
210: root_dir: /tmp/deepcam/instance0
286: root_dir: /tmp/deepcam/instance0
399: root_dir: /tmp/deepcam/instance0
284: root_dir: /tmp/deepcam/instance0
 44: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633415954299, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 398}}
  2: hdf5!!
  3: hdf5!!
  1: hdf5!!
256: hdf5!!
432: hdf5!!
204: hdf5!!
288: hdf5!!
320: hdf5!!
192: hdf5!!
160: hdf5!!
448: hdf5!!
128: hdf5!!
388: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633415954302, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 401}}
 16: hdf5!!
316: hdf5!!
292: hdf5!!
112: hdf5!!
233: hdf5!!
220: hdf5!!
280: hdf5!!
304: hdf5!!
257: hdf5!!
 40: hdf5!!
472: hdf5!!
216: hdf5!!
408: hdf5!!
312: hdf5!!
360: hdf5!!
240: hdf5!!
264: hdf5!!
252: hdf5!!
 44: hdf5!!
440: hdf5!!
 68: hdf5!!
260: hdf5!!
 32: hdf5!!
404: hdf5!!
284: hdf5!!
142: hdf5!!
248: hdf5!!
144: hdf5!!
324: hdf5!!
 24: hdf5!!
156: hdf5!!
132: hdf5!!
 12: hdf5!!
 48: hdf5!!
 36: hdf5!!
444: hdf5!!
336: hdf5!!
 60: hdf5!!
  4: hdf5!!
364: hdf5!!
172: hdf5!!
340: hdf5!!
328: hdf5!!
352: hdf5!!
 64: hdf5!!
 29: hdf5!!
124: hdf5!!
 88: hdf5!!
460: hdf5!!
148: hdf5!!
136: hdf5!!
509: hdf5!!
424: hdf5!!
400: hdf5!!
272: hdf5!!
380: hdf5!!
104: hdf5!!
357: hdf5!!
332: hdf5!!
 80: hdf5!!
164: hdf5!!
 92: hdf5!!
 73: hdf5!!
168: hdf5!!
 96: hdf5!!
372: hdf5!!
 84: hdf5!!
500: hdf5!!
412: hdf5!!
468: hdf5!!
456: hdf5!!
392: hdf5!!
428: hdf5!!
420: hdf5!!
488: hdf5!!
492: hdf5!!
417: hdf5!!
476: hdf5!!
496: hdf5!!
396: hdf5!!
464: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633415954302, "event_type": "INTERVAL_START", "key": "staging_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 405}}
 52: hdf5!!
208: hdf5!!
 17: hdf5!!
317: hdf5!!
293: hdf5!!
268: hdf5!!
113: hdf5!!
234: hdf5!!
221: hdf5!!
283: hdf5!!
305: hdf5!!
258: hdf5!!
 41: hdf5!!
473: hdf5!!
376: hdf5!!
217: hdf5!!
108: hdf5!!
434: hdf5!!
205: hdf5!!
409: hdf5!!
313: hdf5!!
361: hdf5!!
290: hdf5!!
241: hdf5!!
265: hdf5!!
384: hdf5!!
300: hdf5!!
276: hdf5!!
253: hdf5!!
350: hdf5!!
224: hdf5!!
 45: hdf5!!
441: hdf5!!
 69: hdf5!!
321: hdf5!!
261: hdf5!!
 33: hdf5!!
405: hdf5!!
296: hdf5!!
368: hdf5!!
285: hdf5!!
236: hdf5!!
143: hdf5!!
212: hdf5!!
249: hdf5!!
145: hdf5!!
325: hdf5!!
 25: hdf5!!
157: hdf5!!
228: hdf5!!
120: hdf5!!
133: hdf5!!
 13: hdf5!!
 49: hdf5!!
 37: hdf5!!
445: hdf5!!
337: hdf5!!
193: hdf5!!
 61: hdf5!!
181: hdf5!!
436: hdf5!!
  5: hdf5!!
365: hdf5!!
173: hdf5!!
 76: hdf5!!
341: hdf5!!
329: hdf5!!
353: hdf5!!
 65: hdf5!!
161: hdf5!!
100: hdf5!!
 30: hdf5!!
125: hdf5!!
 89: hdf5!!
461: hdf5!!
244: hdf5!!
149: hdf5!!
137: hdf5!!
196: hdf5!!
510: hdf5!!
425: hdf5!!
402: hdf5!!
184: hdf5!!
449: hdf5!!
273: hdf5!!
344: hdf5!!
176: hdf5!!
 20: hdf5!!
381: hdf5!!
106: hdf5!!
308: hdf5!!
358: hdf5!!
333: hdf5!!
 81: hdf5!!
129: hdf5!!
165: hdf5!!
116: hdf5!!
452: hdf5!!
 93: hdf5!!
 75: hdf5!!
169: hdf5!!
 97: hdf5!!
373: hdf5!!
 85: hdf5!!
200: hdf5!!
 56: hdf5!!
501: hdf5!!
152: hdf5!!
188: hdf5!!
  8: hdf5!!
413: hdf5!!
389: hdf5!!
504: hdf5!!
469: hdf5!!
457: hdf5!!
393: hdf5!!
429: hdf5!!
421: hdf5!!
480: hdf5!!
489: hdf5!!
493: hdf5!!
418: hdf5!!
477: hdf5!!
497: hdf5!!
397: hdf5!!
465: hdf5!!
484: hdf5!!
  0: hdf5!!
 53: hdf5!!
209: hdf5!!
 18: hdf5!!
318: hdf5!!
294: hdf5!!
269: hdf5!!
114: hdf5!!
235: hdf5!!
222: hdf5!!
281: hdf5!!
306: hdf5!!
259: hdf5!!
 42: hdf5!!
474: hdf5!!
377: hdf5!!
218: hdf5!!
109: hdf5!!
435: hdf5!!
206: hdf5!!
410: hdf5!!
314: hdf5!!
362: hdf5!!
291: hdf5!!
242: hdf5!!
266: hdf5!!
385: hdf5!!
301: hdf5!!
277: hdf5!!
254: hdf5!!
351: hdf5!!
225: hdf5!!
 46: hdf5!!
443: hdf5!!
 70: hdf5!!
322: hdf5!!
262: hdf5!!
 34: hdf5!!
406: hdf5!!
297: hdf5!!
369: hdf5!!
286: hdf5!!
237: hdf5!!
140: hdf5!!
213: hdf5!!
250: hdf5!!
146: hdf5!!
327: hdf5!!
 26: hdf5!!
158: hdf5!!
229: hdf5!!
121: hdf5!!
134: hdf5!!
 14: hdf5!!
 50: hdf5!!
 38: hdf5!!
446: hdf5!!
338: hdf5!!
194: hdf5!!
 62: hdf5!!
182: hdf5!!
437: hdf5!!
  6: hdf5!!
366: hdf5!!
174: hdf5!!
 77: hdf5!!
342: hdf5!!
331: hdf5!!
354: hdf5!!
 67: hdf5!!
163: hdf5!!
101: hdf5!!
 31: hdf5!!
126: hdf5!!
 90: hdf5!!
462: hdf5!!
245: hdf5!!
150: hdf5!!
138: hdf5!!
197: hdf5!!
511: hdf5!!
427: hdf5!!
403: hdf5!!
186: hdf5!!
450: hdf5!!
274: hdf5!!
345: hdf5!!
177: hdf5!!
 21: hdf5!!
382: hdf5!!
107: hdf5!!
309: hdf5!!
359: hdf5!!
334: hdf5!!
 82: hdf5!!
131: hdf5!!
166: hdf5!!
117: hdf5!!
454: hdf5!!
 94: hdf5!!
 72: hdf5!!
170: hdf5!!
 98: hdf5!!
374: hdf5!!
 86: hdf5!!
201: hdf5!!
 57: hdf5!!
502: hdf5!!
153: hdf5!!
189: hdf5!!
  9: hdf5!!
414: hdf5!!
390: hdf5!!
506: hdf5!!
470: hdf5!!
458: hdf5!!
394: hdf5!!
431: hdf5!!
422: hdf5!!
481: hdf5!!
490: hdf5!!
494: hdf5!!
419: hdf5!!
478: hdf5!!
498: hdf5!!
398: hdf5!!
466: hdf5!!
485: hdf5!!
 54: hdf5!!
210: hdf5!!
 19: hdf5!!
319: hdf5!!
295: hdf5!!
271: hdf5!!
115: hdf5!!
232: hdf5!!
223: hdf5!!
282: hdf5!!
307: hdf5!!
 43: hdf5!!
475: hdf5!!
378: hdf5!!
219: hdf5!!
110: hdf5!!
433: hdf5!!
207: hdf5!!
411: hdf5!!
315: hdf5!!
363: hdf5!!
289: hdf5!!
243: hdf5!!
267: hdf5!!
386: hdf5!!
302: hdf5!!
278: hdf5!!
255: hdf5!!
348: hdf5!!
226: hdf5!!
 47: hdf5!!
442: hdf5!!
 71: hdf5!!
323: hdf5!!
263: hdf5!!
 35: hdf5!!
407: hdf5!!
298: hdf5!!
370: hdf5!!
287: hdf5!!
238: hdf5!!
141: hdf5!!
214: hdf5!!
251: hdf5!!
147: hdf5!!
326: hdf5!!
 27: hdf5!!
159: hdf5!!
230: hdf5!!
122: hdf5!!
135: hdf5!!
 15: hdf5!!
 51: hdf5!!
 39: hdf5!!
447: hdf5!!
339: hdf5!!
195: hdf5!!
 63: hdf5!!
183: hdf5!!
438: hdf5!!
  7: hdf5!!
367: hdf5!!
175: hdf5!!
 78: hdf5!!
343: hdf5!!
330: hdf5!!
355: hdf5!!
 66: hdf5!!
162: hdf5!!
102: hdf5!!
 28: hdf5!!
127: hdf5!!
 91: hdf5!!
463: hdf5!!
246: hdf5!!
151: hdf5!!
139: hdf5!!
198: hdf5!!
508: hdf5!!
426: hdf5!!
401: hdf5!!
187: hdf5!!
451: hdf5!!
275: hdf5!!
346: hdf5!!
178: hdf5!!
 22: hdf5!!
383: hdf5!!
105: hdf5!!
310: hdf5!!
356: hdf5!!
335: hdf5!!
 83: hdf5!!
130: hdf5!!
167: hdf5!!
118: hdf5!!
455: hdf5!!
 95: hdf5!!
 74: hdf5!!
171: hdf5!!
 99: hdf5!!
375: hdf5!!
 87: hdf5!!
202: hdf5!!
 58: hdf5!!
503: hdf5!!
154: hdf5!!
190: hdf5!!
 10: hdf5!!
415: hdf5!!
391: hdf5!!
507: hdf5!!
471: hdf5!!
459: hdf5!!
395: hdf5!!
430: hdf5!!
423: hdf5!!
482: hdf5!!
491: hdf5!!
495: hdf5!!
416: hdf5!!
479: hdf5!!
499: hdf5!!
399: hdf5!!
467: hdf5!!
486: hdf5!!
 55: hdf5!!
211: hdf5!!
270: hdf5!!
379: hdf5!!
111: hdf5!!
387: hdf5!!
303: hdf5!!
279: hdf5!!
349: hdf5!!
227: hdf5!!
299: hdf5!!
371: hdf5!!
239: hdf5!!
215: hdf5!!
231: hdf5!!
123: hdf5!!
180: hdf5!!
439: hdf5!!
 79: hdf5!!
103: hdf5!!
247: hdf5!!
199: hdf5!!
185: hdf5!!
347: hdf5!!
179: hdf5!!
 23: hdf5!!
311: hdf5!!
119: hdf5!!
453: hdf5!!
203: hdf5!!
 59: hdf5!!
155: hdf5!!
191: hdf5!!
 11: hdf5!!
505: hdf5!!
483: hdf5!!
487: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
  0: :::MLLOG {"namespace": "", "time_ms": 1633416052097, "event_type": "INTERVAL_END", "key": "staging_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 425}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416052101, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 1, "step_num": 0}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416057839, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00017999999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416057850, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.16184696555137634, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416057850, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.4767520427703857, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416059888, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00038, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416059904, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.19543835520744324, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416059904, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.1298030614852905, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416060854, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00058, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416060855, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.2668018937110901, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416060855, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.7706232070922852, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416061795, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0007800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416061795, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3190370202064514, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416061795, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.4452884793281555, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416062731, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00098, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416062731, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.32841193675994873, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416062732, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.22617006301879883, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416063668, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00118, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416063668, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.33191120624542236, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416063668, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.12450672686100006, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416064606, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00138, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416064606, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.37281596660614014, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416064606, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.07975635677576065, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416065537, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00158, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416065538, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.45243898034095764, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416065538, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.060590121895074844, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416066474, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0017800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416066474, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.4902154505252838, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416066475, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.04820147529244423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416067409, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00198, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416067410, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5066564679145813, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416067410, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03939298912882805, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416068342, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00218, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416068342, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5162838101387024, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416068342, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03696427494287491, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416069092, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 1}}
  0: EVAL: first data load time: 0.3395592560991645
  0: EVAL: step 1 time -> 0.055658819153904915
  0: EVAL: step 2 time -> 0.17638396192342043
  0: EVAL: step 3 time -> 0.012360948137938976
  0: EVAL: step 4 time -> 0.02284480631351471
  0: EVAL: full eval time -> 0.9933425765484571
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070104, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.507180420920471, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070105, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.047942326021376915, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070105, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070124, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070128, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 2, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070341, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0023799999999999997, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070342, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5408397912979126, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416070342, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03586249426007271, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416071283, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0025800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416071283, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5661152005195618, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416071283, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.032437387853860855, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416072235, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00278, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416072235, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5651600956916809, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416072235, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03172186017036438, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416073159, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00298, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416073159, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5483044981956482, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416073160, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03262379392981529, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416074096, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00318, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416074096, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5558348894119263, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416074096, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03155900910496712, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416075030, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0033799999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416075030, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5798391103744507, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416075031, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03034290485084057, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416075973, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0035800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416075973, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5919508934020996, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416075974, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.028843464329838753, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416076907, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00378, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416076908, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5926722884178162, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416076908, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.029046369716525078, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416077849, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00398, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416077849, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6078950762748718, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416077849, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.026691729202866554, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416078787, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416078787, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6060688495635986, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416078787, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02558811567723751, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416079719, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416079719, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6026480197906494, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416079719, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.025062022730708122, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416080652, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416080652, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.619261622428894, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416080652, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.023843863978981972, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416081214, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 2}}
  0: EVAL: first data load time: 0.001546991989016533
  0: EVAL: step 1 time -> 0.03509003948420286
  0: EVAL: step 2 time -> 0.03218924067914486
  0: EVAL: step 3 time -> 0.032118041068315506
  0: EVAL: step 4 time -> 0.13282025698572397
  0: EVAL: full eval time -> 1.071727680042386
  0: :::MLLOG {"namespace": "", "time_ms": 1633416082288, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5928879217038857, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416082289, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.027741998555965704, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416082289, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 2}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416082290, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416082309, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 3, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416083536, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416083536, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6141538023948669, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416083537, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.024966783821582794, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416085216, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416085216, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6274329423904419, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416085216, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02261904813349247, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416086231, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416086231, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6316285133361816, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416086231, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02167634852230549, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416087162, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416087163, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6324957013130188, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416087163, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02183949016034603, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416088090, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416088090, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6328679919242859, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416088091, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02279498428106308, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416089024, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416089024, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6391032934188843, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416089025, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021945742890238762, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416089962, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416089962, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6339573860168457, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416089962, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020511217415332794, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416090895, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416090895, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6364437937736511, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416090895, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020914457738399506, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416091830, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416091831, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6427766680717468, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416091831, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020019592717289925, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416092766, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416092767, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.647991955280304, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416092767, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019881535321474075, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416093702, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416093703, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6491981148719788, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416093703, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019709333777427673, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416094639, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416094639, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6531855463981628, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416094639, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01934954524040222, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416095014, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 3}}
  0: EVAL: first data load time: 0.0012194942682981491
  0: EVAL: step 1 time -> 0.01336422935128212
  0: EVAL: step 2 time -> 0.01175801083445549
  0: EVAL: step 3 time -> 0.012022072449326515
  0: EVAL: step 4 time -> 0.01133567001670599
  0: EVAL: full eval time -> 0.36163024324923754
  0: :::MLLOG {"namespace": "", "time_ms": 1633416095379, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6337454464020649, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416095379, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.020321838080938077, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416095379, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 3}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416095399, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416095420, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 4, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416097263, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416097263, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6559991240501404, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416097264, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018544599413871765, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416099049, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416099049, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6566271781921387, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416099050, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017956342548131943, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416100097, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416100097, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6605868935585022, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416100097, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018724309280514717, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416101032, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416101033, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6612166166305542, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416101033, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017696384340524673, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416101965, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416101965, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6585259437561035, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416101966, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017896121367812157, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416102898, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416102898, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6554994583129883, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416102898, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018988456577062607, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416103842, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416103842, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6772438287734985, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416103842, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016513364389538765, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416104778, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416104778, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.659061849117279, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416104779, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01732744090259075, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416105713, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416105713, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6649404168128967, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416105713, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01648044027388096, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416106648, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416106648, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6755760908126831, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416106648, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015109692700207233, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416107589, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416107589, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6748884320259094, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416107589, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016689781099557877, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416108518, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416108518, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6737698316574097, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416108518, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016628175973892212, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416108705, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 4}}
  0: EVAL: first data load time: 0.0012192800641059875
  0: EVAL: step 1 time -> 0.013763198629021645
  0: EVAL: step 2 time -> 0.011810905300080776
  0: EVAL: step 3 time -> 0.012133355252444744
  0: EVAL: step 4 time -> 0.011599641293287277
  0: EVAL: full eval time -> 0.32251779083162546
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109031, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6489558679822536, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109031, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.017656391977807717, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109031, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 4}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109051, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109054, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 5, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109811, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109812, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6853057742118835, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416109812, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015568682923913002, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416110750, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416110750, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6904138326644897, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416110751, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015104656107723713, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416111702, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416111702, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6862348914146423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416111702, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014612569473683834, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416112657, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416112658, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7010611295700073, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416112658, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015384568832814693, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416113670, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416113671, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.68990558385849, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416113671, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014731195755302906, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416114606, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416114607, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6986343264579773, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416114607, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014293745160102844, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416115540, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416115540, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6951329112052917, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416115541, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014422447420656681, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416116482, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416116483, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6942007541656494, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416116483, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015001027844846249, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416117427, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416117427, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6788718700408936, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416117427, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018511010333895683, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416118382, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416118382, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6982115507125854, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416118382, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014922773465514183, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416119323, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416119323, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6972413063049316, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416119323, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01486505102366209, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120258, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120258, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7151554226875305, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120259, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014738788828253746, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120261, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 5}}
  0: EVAL: first data load time: 0.0011905590072274208
  0: EVAL: step 1 time -> 0.012883899733424187
  0: EVAL: step 2 time -> 0.011780933476984501
  0: EVAL: step 3 time -> 0.011918656527996063
  0: EVAL: step 4 time -> 0.011363133788108826
  0: EVAL: full eval time -> 0.5358804520219564
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120800, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6957835152023684, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120800, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.013078058657788997, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120801, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 5}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120820, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416120844, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 6, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416123676, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416123676, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7150516510009766, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416123676, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014155508019030094, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416124842, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416124842, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7103763222694397, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416124842, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013189285062253475, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416125864, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416125865, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7213640809059143, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416125865, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013046281412243843, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416126800, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416126801, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7170357704162598, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416126801, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01346583478152752, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416127730, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416127731, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7045596241950989, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416127731, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013110870495438576, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416128659, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416128660, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7151370644569397, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416128660, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013127363286912441, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416129583, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416129584, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7294313311576843, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416129584, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013086419552564621, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416130515, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416130516, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.732150137424469, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416130516, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012211745604872704, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416131450, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416131450, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7313363552093506, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416131451, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012882838025689125, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416132390, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416132390, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7311389446258545, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416132390, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012562740594148636, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416133322, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416133322, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7311414480209351, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416133323, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013214030303061008, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416134078, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 6}}
  0: EVAL: first data load time: 0.0033984463661909103
  0: EVAL: step 1 time -> 0.013563341461122036
  0: EVAL: step 2 time -> 0.011820337735116482
  0: EVAL: step 3 time -> 0.01197604276239872
  0: EVAL: step 4 time -> 0.011458941735327244
  0: EVAL: full eval time -> 0.5379063989967108
  0: :::MLLOG {"namespace": "", "time_ms": 1633416134619, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6707297714078374, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416134619, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.02370925905333611, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416134619, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 6}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416134638, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416134661, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 7, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416135273, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416135273, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7467607855796814, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416135273, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012600875459611416, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416137691, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416137691, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7307652831077576, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416137691, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012636294588446617, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416138628, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416138628, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.74073725938797, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416138629, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012138898484408855, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416139564, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416139564, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7529721260070801, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416139564, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011125599965453148, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416140496, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416140496, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7527227997779846, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416140496, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01103353500366211, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416141430, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416141431, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7327045798301697, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416141431, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011975055560469627, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416142357, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416142357, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7536134719848633, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416142358, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011992791667580605, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416143292, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416143293, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7501778602600098, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416143293, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011254807934165001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416144234, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416144235, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.757088840007782, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416144235, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011700139380991459, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416145164, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416145165, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.746565043926239, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416145165, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011682962998747826, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416146111, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416146111, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7414560914039612, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416146112, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012816794216632843, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416147050, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416147051, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7564334273338318, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416147051, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012415189296007156, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416147607, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 7}}
  0: EVAL: first data load time: 0.005295521579682827
  0: EVAL: step 1 time -> 0.012916181236505508
  0: EVAL: step 2 time -> 0.012675115838646889
  0: EVAL: step 3 time -> 0.012036810629069805
  0: EVAL: step 4 time -> 0.011388193815946579
  0: EVAL: full eval time -> 0.5588615946471691
  0: :::MLLOG {"namespace": "", "time_ms": 1633416148169, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7518817414896425, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416148169, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.011642562759506118, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416148170, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 7}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416148189, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416148212, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 8, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416149453, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416149454, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7674000859260559, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416149454, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010570281185209751, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416151511, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416151511, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7575458288192749, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416151512, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01132618635892868, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416152699, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416152699, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7593622207641602, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416152699, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010030241683125496, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416153645, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416153645, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7658553719520569, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416153645, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010917835868895054, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416154586, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416154586, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7661119699478149, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416154586, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010396146215498447, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416155539, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416155540, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7622227668762207, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416155540, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010513611137866974, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416156483, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416156484, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.767906129360199, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416156484, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010617249645292759, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416157430, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416157430, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7797737121582031, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416157430, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01084831915795803, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416158371, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416158372, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.778562068939209, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416158372, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010198034346103668, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416159305, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416159306, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7584030628204346, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416159306, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011114091612398624, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416160250, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416160250, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7721272706985474, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416160250, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010714479722082615, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416161190, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416161190, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7682044506072998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416161190, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010348688811063766, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416161567, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 8}}
  0: EVAL: first data load time: 0.004203137941658497
  0: EVAL: step 1 time -> 0.01329868845641613
  0: EVAL: step 2 time -> 0.011680250987410545
  0: EVAL: step 3 time -> 0.011938485316932201
  0: EVAL: step 4 time -> 0.011328233405947685
  0: EVAL: full eval time -> 0.6498409202322364
  0: :::MLLOG {"namespace": "", "time_ms": 1633416162220, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6773379001599815, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416162220, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.028094090231334114, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416162220, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 8}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416162240, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416162264, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 9, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416164122, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416164123, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7739012837409973, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416164123, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01014905795454979, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416165728, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416165728, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7857987284660339, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416165728, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00923797208815813, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416166766, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416166766, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7909477353096008, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416166766, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009661136195063591, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416167699, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416167699, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7914648652076721, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416167699, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010102991946041584, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416168659, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416168659, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7883607745170593, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416168660, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009511129930615425, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416169617, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416169618, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7900853157043457, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416169618, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00970531813800335, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416170573, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416170573, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7756569385528564, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416170573, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00980477873235941, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416171505, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416171506, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7884390354156494, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416171506, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010371696203947067, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416172436, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416172437, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7841413617134094, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416172437, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010055565275251865, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416173364, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416173365, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.782914400100708, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416173365, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009618829004466534, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416174294, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416174295, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7889671325683594, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416174295, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009653019718825817, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175228, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175229, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7750642895698547, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175229, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009643892757594585, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175419, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 9}}
  0: EVAL: first data load time: 0.006929776631295681
  0: EVAL: step 1 time -> 0.012990307062864304
  0: EVAL: step 2 time -> 0.011839221231639385
  0: EVAL: step 3 time -> 0.012074831873178482
  0: EVAL: step 4 time -> 0.011454847641289234
  0: EVAL: full eval time -> 0.3213143730536103
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175743, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7468690470791002, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175743, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.012708465378868626, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175744, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 9}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175763, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416175768, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 10, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416176594, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416176595, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7986236810684204, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416176595, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00898901280015707, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416179491, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416179491, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8133243918418884, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416179491, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008776121772825718, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416180571, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416180571, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7917868494987488, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416180571, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008373637683689594, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416181508, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416181508, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8104118704795837, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416181509, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008729889057576656, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416182447, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416182447, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8048216700553894, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416182447, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008591361343860626, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416183391, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416183391, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7799120545387268, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416183391, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009023795835673809, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416184323, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416184323, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7770815491676331, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416184323, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009227839298546314, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416185267, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416185267, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7958811521530151, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416185267, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008921338245272636, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416186209, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416186209, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8085097670555115, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416186209, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008724252693355083, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416187152, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416187152, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8103131651878357, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416187152, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008662831969559193, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416188093, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416188093, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7783333659172058, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416188093, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009290623478591442, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189040, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189040, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7880787253379822, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189040, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009021559730172157, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189043, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 10}}
  0: EVAL: first data load time: 0.0012109214439988136
  0: EVAL: step 1 time -> 0.013328291475772858
  0: EVAL: step 2 time -> 0.012060221284627914
  0: EVAL: step 3 time -> 0.012048017233610153
  0: EVAL: step 4 time -> 0.011745487339794636
  0: EVAL: full eval time -> 0.8087428230792284
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189855, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7444070246528236, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189855, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01298935675403974, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189856, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189875, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416189897, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 11, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416192216, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416192216, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8192664980888367, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416192216, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007785988040268421, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416193431, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416193431, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7977226376533508, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416193431, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008132360875606537, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416194374, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416194375, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7835074663162231, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416194375, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008835039101541042, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416195314, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416195315, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7992693781852722, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416195315, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008000007830560207, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416196262, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416196262, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7815783023834229, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416196262, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008387195877730846, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416197201, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416197201, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8118864297866821, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416197202, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008488407358527184, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416198142, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416198142, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8111647963523865, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416198142, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00821218267083168, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416199076, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416199077, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7791392207145691, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416199077, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009506010450422764, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416200013, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416200013, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7972637414932251, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416200013, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008249187842011452, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416200941, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416200941, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8075078129768372, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416200941, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008891223929822445, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416201870, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416201871, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8040626049041748, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416201871, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00933519471436739, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416202618, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 11}}
  0: EVAL: first data load time: 0.0012346496805548668
  0: EVAL: step 1 time -> 0.013658693060278893
  0: EVAL: step 2 time -> 0.01192440465092659
  0: EVAL: step 3 time -> 0.01195147167891264
  0: EVAL: step 4 time -> 0.011359995231032372
  0: EVAL: full eval time -> 0.745465868152678
  0: :::MLLOG {"namespace": "", "time_ms": 1633416203367, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7593569737308682, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416203367, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01301674365305243, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416203368, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 11}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416203387, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416203410, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 12, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416204026, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416204026, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8183659911155701, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416204026, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007819567807018757, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416206164, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416206165, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8424550890922546, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416206165, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006370176561176777, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416207258, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416207258, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8416135311126709, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416207258, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00603857496753335, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416208199, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416208199, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.841663658618927, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416208199, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005730492528527975, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416209129, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416209129, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8459651470184326, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416209129, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005629395134747028, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416210070, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416210070, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.84192955493927, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416210071, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005463675130158663, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416211010, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416211011, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8483082056045532, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416211011, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005540434271097183, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416211957, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416211958, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.85345858335495, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416211958, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005248004570603371, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416212896, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416212896, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8493529558181763, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416212897, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00557293463498354, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416213822, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416213822, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8544014096260071, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416213822, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005310559179633856, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416214768, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416214769, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8581098318099976, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416214769, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005196893122047186, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416215713, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416215714, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8502650856971741, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416215714, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005321500822901726, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416216287, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 12}}
  0: EVAL: first data load time: 0.0012431629002094269
  0: EVAL: step 1 time -> 0.013681882992386818
  0: EVAL: step 2 time -> 0.012151425704360008
  0: EVAL: step 3 time -> 0.012143224477767944
  0: EVAL: step 4 time -> 0.011663916520774364
  0: EVAL: full eval time -> 0.678656836040318
  0: :::MLLOG {"namespace": "", "time_ms": 1633416216969, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8200793439314223, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416216969, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.010508611658692501, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416216969, "event_type": "POINT_IN_TIME", "key": "target_accuracy_reached", "value": 0.82, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 374, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416216969, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 12}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416216989, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633416217012, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 507, "status": "success"}}
152: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
152: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
444: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
342: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
444: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
342: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
221: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
216: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
166: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
418: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
221: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
216: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
166: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
418: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
204: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
204: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
214: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
214: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 58: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 58: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
492: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
492: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 71: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 71: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
355: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
355: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
440: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
440: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
255: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
255: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
431: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
431: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
251: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
251: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
509: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
509: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
210: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
210: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
263: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
263: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
340: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
340: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
302: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 34: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
302: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 34: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
318: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
318: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
404: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
404: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
282: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
282: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
  2: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
  2: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
218: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
218: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
122: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
122: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
496: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
496: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
482: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
482: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
386: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
386: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
242: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
242: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 19: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 19: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
339: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
339: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
272: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
272: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
109: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
109: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
232: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
232: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
246: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
246: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
446: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
446: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
423: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
423: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
466: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
466: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 43: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 43: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 45: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 45: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 56: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 56: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
266: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
266: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
289: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
289: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
409: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
409: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 83: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 83: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
257: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
257: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
164: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
164: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
154: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
154: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
366: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
366: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
506: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
506: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
156: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
156: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
479: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
479: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
228: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
228: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
439: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
439: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
310: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
310: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
416: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
416: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
372: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
372: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 65: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 65: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
368: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
368: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
271: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
271: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
343: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
343: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
212: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
212: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
  4: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
  4: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
195: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
195: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
102: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
102: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
292: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
292: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
150: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
150: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
463: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
463: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
435: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
435: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
400: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
400: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
275: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
275: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
279: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
279: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 48: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 48: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 22: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 22: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
436: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
252: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
436: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
252: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 60: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 60: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
344: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
344: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
307: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
307: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
485: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
485: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
206: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
206: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
453: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
453: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 46: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 46: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
405: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
405: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
428: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
428: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
133: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
133: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
223: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
223: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
377: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
377: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
159: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
159: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
331: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
331: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
129: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
129: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
163: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
163: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
443: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
443: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
260: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
260: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
284: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
284: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
136: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
136: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
240: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
240: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
208: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
208: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 54: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 54: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
420: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
420: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
413: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
413: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
104: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
104: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
447: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
447: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
  0: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
  0: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 32: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 32: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
332: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
332: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
325: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
325: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
315: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
315: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
113: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
113: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
280: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
280: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
316: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
316: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
268: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
268: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
248: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
248: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
477: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
477: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
143: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
143: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 68: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 68: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
323: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
323: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
  7: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
  7: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 10: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 10: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
128: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
128: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
395: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
395: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
165: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
165: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
120: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
120: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
155: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
155: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
345: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
345: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
304: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
304: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
174: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
174: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
300: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
300: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
160: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
160: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 31: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 31: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 78: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 78: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
417: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
417: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
308: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
308: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 99: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 99: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 26: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 26: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
147: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
147: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
233: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
233: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
480: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
480: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 16: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 16: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
108: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
108: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
449: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
449: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
244: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
244: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
351: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
351: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
491: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
491: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
320: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
320: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 88: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 88: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
464: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
464: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
213: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
213: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
336: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
369: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
336: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
369: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
264: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
264: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
288: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
288: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 52: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 52: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
381: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
381: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 57: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
362: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 57: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
362: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
470: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
470: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
220: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
220: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
274: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
274: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
364: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
364: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
389: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
389: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 40: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 40: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
396: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
396: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
408: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
408: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
352: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 87: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 87: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
352: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
188: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
188: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
384: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
384: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
437: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
437: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
472: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
472: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
504: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
504: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
148: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
148: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 37: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 37: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
205: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
205: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
254: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
254: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
425: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
425: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
186: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
186: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
107: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
107: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
498: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
498: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
256: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
256: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
196: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
196: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
359: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
359: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
183: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
183: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 33: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 33: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
116: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
116: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 66: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 66: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
484: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
484: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
158: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
158: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
508: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
508: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
430: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
430: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
373: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
373: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
249: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
249: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
261: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
261: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
276: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
276: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
460: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
460: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 92: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 92: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 63: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 63: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
471: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
471: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
209: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
209: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
442: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
442: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
319: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
319: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 81: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 81: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
432: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
432: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
313: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
313: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 86: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 86: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
  3: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
  3: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
161: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
161: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
473: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
473: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
169: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
169: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
  6: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
  6: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
103: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
103: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
311: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
311: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
283: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
283: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 12: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 12: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
376: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
376: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
363: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
363: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
452: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
452: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
231: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
231: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
399: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
399: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
131: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
131: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
346: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
346: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
293: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
293: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
177: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
177: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
132: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
132: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 91: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 91: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 20: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 20: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
301: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
494: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
301: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
494: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
412: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
412: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 70: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
241: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
241: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 70: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
328: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
144: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
503: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
144: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
328: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
503: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
406: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
406: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
235: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
235: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
422: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
422: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
112: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
112: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
324: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
324: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
388: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
388: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
457: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
457: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
402: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
402: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
203: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
203: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
238: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
238: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
380: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
380: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
365: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
365: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
  8: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
  8: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 55: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 55: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 18: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 18: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 50: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 50: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
483: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
483: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
245: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
245: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
385: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
385: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
123: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
123: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
267: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
267: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
337: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
337: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
353: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
353: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
140: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
140: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 28: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 28: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
465: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
465: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
335: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
335: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
172: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
172: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
298: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
298: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
138: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
306: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
138: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
306: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
110: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
110: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
322: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
322: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
370: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
370: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 96: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 96: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 76: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 76: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
291: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
291: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
499: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
499: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 42: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 42: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
424: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
424: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
286: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
286: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 64: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 64: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
393: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
393: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 25: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 25: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
348: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
348: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
486: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
486: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
411: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
100: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
100: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
411: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
117: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
117: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
507: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
507: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
259: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
259: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 73: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 73: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
360: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
360: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
448: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
448: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
194: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
194: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 62: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 62: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
184: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
184: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
375: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
375: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
488: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
488: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
462: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
462: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 15: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
277: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 15: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
277: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
378: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
378: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 80: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 80: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
511: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
511: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
434: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
434: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
270: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
270: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 36: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 36: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 93: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 93: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
151: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
151: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
170: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
170: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
474: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
474: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
229: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
229: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
398: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
398: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
294: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
294: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
455: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
455: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 23: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 23: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
124: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
124: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 89: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 89: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
135: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
135: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
145: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
145: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
391: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
391: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
469: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
469: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
403: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
403: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 24: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 24: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
330: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
330: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
199: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
199: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 49: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 49: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 47: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 47: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
392: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
392: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
180: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
180: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
114: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
114: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
192: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
192: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
415: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
415: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
357: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
357: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
426: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
426: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
296: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
296: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 30: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 30: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
141: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
141: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
191: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
191: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
139: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
139: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
326: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
326: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
175: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
175: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
495: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
495: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 11: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 11: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
118: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
285: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
285: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
118: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
382: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
382: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 98: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 98: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
350: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
350: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 79: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 79: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
451: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
451: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 72: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 72: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
333: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
333: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
500: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
500: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 14: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 14: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
176: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
176: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
225: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
200: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
225: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
200: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
490: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
490: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
456: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
456: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 38: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 38: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
236: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
236: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
168: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
168: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
126: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
126: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
187: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
187: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
314: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
314: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 94: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 94: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
182: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
182: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
190: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
190: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
297: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
297: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
219: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
219: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
198: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
198: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 74: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 74: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
106: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
106: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
356: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
356: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
227: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
227: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
502: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
502: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
201: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
201: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
459: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
459: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
476: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
476: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
237: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
237: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
125: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
125: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
178: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
178: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
 84: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
 84: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
341: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
341: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
224: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
224: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
153: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
167: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
153: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
167: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
419: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
419: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
215: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
215: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
429: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
429: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
262: ENDING TIMING RUN AT 2021-10-05 08:43:42 AM
262: RESULT,DEEPCAM_HPC,,451,qv2382,2021-10-05 08:36:11 AM
281: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
281: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
211: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
211: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
445: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
445: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
253: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
253: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
317: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
317: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
  1: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
  1: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
441: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
441: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
243: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
243: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
111: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
111: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
338: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
338: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
481: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
481: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
497: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
497: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
367: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
367: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
303: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
265: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
265: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
303: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
354: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
354: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 41: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 41: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
258: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
258: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
467: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
467: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
421: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
421: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
207: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
207: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
234: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
234: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
374: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
374: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 67: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 67: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
387: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
387: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 35: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 35: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
505: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
505: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
410: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
410: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
121: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
121: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
222: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
222: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
230: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
230: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
250: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
250: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 82: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 82: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
273: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
273: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
510: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
510: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
461: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
461: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
309: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
309: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
295: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
295: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
454: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
454: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
278: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
278: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 69: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 69: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
433: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
433: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
157: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
157: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
287: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
287: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
115: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
115: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
371: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
371: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
394: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
394: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 61: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 61: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
327: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
327: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
142: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
142: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
  9: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
  9: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 59: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 59: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
247: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
247: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
162: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
162: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 21: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 21: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 77: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 77: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
487: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
487: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
173: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
173: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
193: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
193: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
290: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
290: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 51: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 51: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 27: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 27: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
101: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
101: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
321: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
321: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 29: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 29: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
334: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
334: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 97: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 97: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
146: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
146: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
407: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
407: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 53: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 53: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
414: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
414: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
468: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
468: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 39: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 39: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
493: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
493: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 95: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 95: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
401: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
401: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
197: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
197: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
130: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
130: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
119: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
119: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
438: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
438: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
189: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
189: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
  5: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
  5: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
171: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
171: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
379: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
379: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
329: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
329: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 17: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 17: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
361: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
361: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
390: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
390: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
475: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
475: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
269: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
269: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
185: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
185: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 44: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 44: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
347: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
347: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
134: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
134: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
349: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
349: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
299: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
299: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
450: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
450: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 13: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 13: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
489: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
489: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
358: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
358: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
383: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
383: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 75: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 75: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
239: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
239: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
458: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
458: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
312: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
312: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
217: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
217: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
149: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
149: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
427: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
427: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
305: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
305: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
137: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
137: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
181: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
181: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 85: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 85: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
 90: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
 90: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
127: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
127: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
501: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
501: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
179: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
179: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
397: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
397: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
202: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
202: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
478: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
478: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
105: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
105: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
226: ENDING TIMING RUN AT 2021-10-05 08:43:43 AM
226: RESULT,DEEPCAM_HPC,,452,qv2382,2021-10-05 08:36:11 AM
