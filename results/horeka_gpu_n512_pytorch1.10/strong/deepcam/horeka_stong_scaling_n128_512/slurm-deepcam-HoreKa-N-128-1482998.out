/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/docker/deepcam_optimized-21.09_2.sif
configs/best_configs/config_DGXA100_512GPU_BS1024_graph.sh
#!/bin/bash

# hyperparameters
export LOCAL_BATCH_SIZE=2
export START_LR=0.004
export OPTIMIZER="LAMB"
export LR_SCHEDULE_TYPE="multistep"
export LR_MILESTONES="1100 4096"
export LR_DECAY_RATE="0.1"
export LR_WARMUP_STEPS=200
export LR_WARMUP_FACTOR=1.
export WEIGHT_DECAY=0.01
export BATCHNORM_GROUP_SIZE=1

# data parameters
export SHUFFLE_MODE="global"
export DATA_FORMAT="dali-es/hdf5"
export PRECISION_MODE="amp"
export LOCAL_VALIDATION_BATCH_SIZE=8

# output parameters
#export OUTPUT_ROOT=/results/best

export TRAINING_INSTANCE_SIZE=$((128*4))

# auxiliary parameters
export LOGGING_FREQUENCY=10

# misc args
export ADDITIONAL_ARGS="--enable_jit --enable_graph"
#--disable_comm_overlap
# system parameters
#export DGXNGPU=8
#export DGXNNODES=64
#export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
#export WALLTIME=00:30:00
export DGXNGPU=4
export DGXNNODES=128
export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
export WALLTIME=01:00:00
466: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
465: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
361: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
337: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
337: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
373: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 47: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
246: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
369: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
369: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
464: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
455: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
208: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
303: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
338: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 26: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
447: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
362: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
312: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
227: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
418: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
316: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
480: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 44: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 89: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
376: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
454: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
372: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
359: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
295: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
209: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
345: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
425: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
314: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
247: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
247: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
463: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
378: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
481: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
370: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
457: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
394: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
421: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 88: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
302: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
446: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
385: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
363: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
363: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 59: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
488: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
318: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
266: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
399: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
339: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
356: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
471: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: Running Multi Instance Training
466: Running Multi Instance Training
341: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
464: Running Multi Instance Training
465: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
466: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
464: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 21: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: Running Multi Instance Training
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: Running Multi Instance Training
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: Running Multi Instance Training
219: Running Multi Instance Training
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
376: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: Running Multi Instance Training
303: Running Multi Instance Training
208: Running Multi Instance Training
454: Running Multi Instance Training
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
209: Running Multi Instance Training
455: Running Multi Instance Training
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
246: Running Multi Instance Training
369: Running Multi Instance Training
247: Running Multi Instance Training
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: Running Multi Instance Training
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
384: Running Multi Instance Training
208: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
454: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
385: Running Multi Instance Training
396: Running Multi Instance Training
303: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
246: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
399: Running Multi Instance Training
209: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
455: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
369: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
472: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
370: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
247: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
396: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
385: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
399: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
488: Running Multi Instance Training
488: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
417: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
459: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 18: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
211: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
211: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
130: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
293: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: Running Multi Instance Training
359: Running Multi Instance Training
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
356: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
359: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: Running Multi Instance Training
314: Running Multi Instance Training
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: Running Multi Instance Training
447: Running Multi Instance Training
314: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
446: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: Running Multi Instance Training
481: Running Multi Instance Training
480: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
481: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: Running Multi Instance Training
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
211: Running Multi Instance Training
211: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: Running Multi Instance Training
293: Running Multi Instance Training
354: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 18: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
293: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 36: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
165: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: Running Multi Instance Training
 46: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 46: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
374: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
374: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: Running Multi Instance Training
337: Running Multi Instance Training
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: Running Multi Instance Training
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: Running Multi Instance Training
393: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: Running Multi Instance Training
339: Running Multi Instance Training
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: Running Multi Instance Training
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: Running Multi Instance Training
361: Running Multi Instance Training
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: Running Multi Instance Training
 26: Running Multi Instance Training
318: Running Multi Instance Training
 89: Running Multi Instance Training
345: Running Multi Instance Training
417: Running Multi Instance Training
 24: Running Multi Instance Training
316: Running Multi Instance Training
362: Running Multi Instance Training
373: Running Multi Instance Training
347: Running Multi Instance Training
363: Running Multi Instance Training
372: Running Multi Instance Training
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: Running Multi Instance Training
266: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
338: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
339: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 26: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
337: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 47: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
463: Running Multi Instance Training
 88: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
361: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
418: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 44: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 89: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
318: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
362: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
373: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
425: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
363: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
347: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
417: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 24: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
463: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
457: Running Multi Instance Training
459: Running Multi Instance Training
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: Running Multi Instance Training
457: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
459: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 59: Running Multi Instance Training
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: Running Multi Instance Training
426: Running Multi Instance Training
 59: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
426: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 46: Running Multi Instance Training
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: Running Multi Instance Training
 21: Running Multi Instance Training
 46: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 56: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: Running Multi Instance Training
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
225: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: Running Multi Instance Training
 21: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
225: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
205: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
341: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: Running Multi Instance Training
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 36: Running Multi Instance Training
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
354: Running Multi Instance Training
393: Running Multi Instance Training
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
165: Running Multi Instance Training
393: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
165: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
452: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: Running Multi Instance Training
422: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
225: Running Multi Instance Training
225: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 27: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: Running Multi Instance Training
368: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: Running Multi Instance Training
244: Running Multi Instance Training
452: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
205: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
244: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
315: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: Running Multi Instance Training
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: Running Multi Instance Training
422: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
216: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: Running Multi Instance Training
 27: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
468: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
388: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
368: Running Multi Instance Training
368: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: Running Multi Instance Training
315: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
444: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
300: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: Running Multi Instance Training
483: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: Running Multi Instance Training
468: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
108: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
270: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: Running Multi Instance Training
444: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: Running Multi Instance Training
300: Running Multi Instance Training
483: Running Multi Instance Training
388: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
300: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
483: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: Running Multi Instance Training
 74: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
264: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: Running Multi Instance Training
 10: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
398: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 19: Running Multi Instance Training
 19: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: Running Multi Instance Training
186: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
489: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 91: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: Running Multi Instance Training
270: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: Running Multi Instance Training
 70: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
131: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
379: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: Running Multi Instance Training
264: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: Running Multi Instance Training
 74: Running Multi Instance Training
 74: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
398: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
473: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: Running Multi Instance Training
489: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 10: Running Multi Instance Training
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: Running Multi Instance Training
186: Running Multi Instance Training
379: Running Multi Instance Training
461: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 54: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
131: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
186: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
379: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: Running Multi Instance Training
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: Running Multi Instance Training
166: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
387: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
226: Running Multi Instance Training
226: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: Running Multi Instance Training
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
346: Running Multi Instance Training
317: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: Running Multi Instance Training
342: Running Multi Instance Training
346: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
461: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
160: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: Running Multi Instance Training
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: Running Multi Instance Training
 54: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
387: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
407: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: Running Multi Instance Training
 23: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
317: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
292: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
109: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
364: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
407: Running Multi Instance Training
407: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: Running Multi Instance Training
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: Running Multi Instance Training
 23: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
160: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 68: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: Running Multi Instance Training
292: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
109: Running Multi Instance Training
109: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
353: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: Running Multi Instance Training
390: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
458: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: Running Multi Instance Training
364: Running Multi Instance Training
 68: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
364: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
204: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: Running Multi Instance Training
353: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: Running Multi Instance Training
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
458: Running Multi Instance Training
458: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
424: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 95: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: Running Multi Instance Training
204: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
184: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  0: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
462: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 11: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
218: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: Running Multi Instance Training
424: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
382: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: Running Multi Instance Training
184: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
462: Running Multi Instance Training
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: Running Multi Instance Training
462: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: Running Multi Instance Training
 95: Running Multi Instance Training
423: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
218: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 95: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: Using bindings from SLURM: mask_cpu:
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: Running Multi Instance Training
  0: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: Running Multi Instance Training
382: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: Running Multi Instance Training
423: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
365: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: Running Multi Instance Training
228: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
395: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
236: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
469: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 58: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: Running Multi Instance Training
365: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
267: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: Running Multi Instance Training
 37: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: Running Multi Instance Training
395: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
490: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
469: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: Running Multi Instance Training
 58: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
434: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: Running Multi Instance Training
236: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: Running Multi Instance Training
267: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: Running Multi Instance Training
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
207: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
490: Running Multi Instance Training
 17: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 37: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
490: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
351: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: Running Multi Instance Training
434: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
340: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
284: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 34: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: Running Multi Instance Training
207: Running Multi Instance Training
164: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
207: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: Running Multi Instance Training
 17: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
163: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 55: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
474: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: Running Multi Instance Training
340: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: Running Multi Instance Training
351: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 93: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
230: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
104: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: Running Multi Instance Training
163: Running Multi Instance Training
 22: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: Running Multi Instance Training
284: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
163: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
474: Running Multi Instance Training
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 34: Running Multi Instance Training
474: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 34: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: Running Multi Instance Training
230: Running Multi Instance Training
 93: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
230: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
467: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
269: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: Running Multi Instance Training
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: Running Multi Instance Training
 22: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
104: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
155: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
352: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: Running Multi Instance Training
269: Running Multi Instance Training
269: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
467: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
405: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 39: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: Running Multi Instance Training
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: Running Multi Instance Training
352: Running Multi Instance Training
391: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
391: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
352: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
298: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
249: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
405: Running Multi Instance Training
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: Running Multi Instance Training
405: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 39: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: Running Multi Instance Training
391: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
159: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  8: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
383: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: Running Multi Instance Training
111: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: Running Multi Instance Training
  3: Running Multi Instance Training
 73: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
249: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: Running Multi Instance Training
185: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
261: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: Running Multi Instance Training
 69: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  8: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
484: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: Running Multi Instance Training
383: Running Multi Instance Training
159: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
111: Running Multi Instance Training
111: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: Running Multi Instance Training
 73: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: Running Multi Instance Training
185: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: Running Multi Instance Training
 69: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
238: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: Running Multi Instance Training
484: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: Running Multi Instance Training
238: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
348: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
296: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: Running Multi Instance Training
348: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
286: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 33: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: Running Multi Instance Training
296: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: Running Multi Instance Training
432: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
432: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
307: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 52: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
286: Running Multi Instance Training
286: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: Running Multi Instance Training
366: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
366: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 33: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: Running Multi Instance Training
336: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: Running Multi Instance Training
432: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: Running Multi Instance Training
271: Running Multi Instance Training
 52: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
271: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 75: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
366: Running Multi Instance Training
161: Running Multi Instance Training
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: Running Multi Instance Training
366: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
161: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
307: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
147: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: Running Multi Instance Training
 75: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
154: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
237: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: Running Multi Instance Training
107: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 94: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: Running Multi Instance Training
147: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: Running Multi Instance Training
154: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: Running Multi Instance Training
237: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: Running Multi Instance Training
262: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 94: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
360: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
375: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
170: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: Running Multi Instance Training
  1: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
262: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: Running Multi Instance Training
360: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
285: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: Running Multi Instance Training
231: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
375: Running Multi Instance Training
375: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: Running Multi Instance Training
  1: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: Running Multi Instance Training
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
170: Running Multi Instance Training
170: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
414: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: Running Multi Instance Training
487: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 30: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 32: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 81: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
173: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
215: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
215: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
255: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: Running Multi Instance Training
487: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: Running Multi Instance Training
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
414: Running Multi Instance Training
324: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
414: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
349: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
123: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: Running Multi Instance Training
 81: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
215: Running Multi Instance Training
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: Running Multi Instance Training
215: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
173: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
450: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: Running Multi Instance Training
349: Running Multi Instance Training
255: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
324: Running Multi Instance Training
324: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
453: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: Running Multi Instance Training
115: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
123: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 50: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
210: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
144: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
132: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
256: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
275: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: Running Multi Instance Training
148: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
453: Running Multi Instance Training
450: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
453: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
158: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
377: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
210: Running Multi Instance Training
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: Running Multi Instance Training
210: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 13: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: Running Multi Instance Training
115: Running Multi Instance Training
144: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
115: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: Running Multi Instance Training
263: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 50: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: Running Multi Instance Training
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
158: Running Multi Instance Training
158: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: Running Multi Instance Training
256: Running Multi Instance Training
377: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
256: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
275: Running Multi Instance Training
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
148: Running Multi Instance Training
148: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
106: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: Running Multi Instance Training
301: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
263: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: Running Multi Instance Training
 13: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
153: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
413: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
413: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
297: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
254: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: Running Multi Instance Training
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
301: Running Multi Instance Training
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
176: Running Multi Instance Training
301: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
482: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
176: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
250: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: Running Multi Instance Training
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: Running Multi Instance Training
413: Running Multi Instance Training
153: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
413: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
297: Running Multi Instance Training
171: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
297: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: Running Multi Instance Training
397: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
254: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
327: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
313: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: Running Multi Instance Training
250: Running Multi Instance Training
 98: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
482: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
250: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
493: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: Running Multi Instance Training
171: Running Multi Instance Training
357: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
333: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  4: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
171: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: Running Multi Instance Training
122: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
371: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
371: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: Running Multi Instance Training
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: Running Multi Instance Training
327: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
313: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 80: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 80: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
141: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
357: Running Multi Instance Training
357: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
245: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
122: Running Multi Instance Training
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: Running Multi Instance Training
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 98: Running Multi Instance Training
371: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 98: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: Running Multi Instance Training
 25: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 80: Running Multi Instance Training
493: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: Running Multi Instance Training
 80: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: Running Multi Instance Training
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 79: Running Multi Instance Training
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: Running Multi Instance Training
 79: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
156: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
245: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
103: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: Running Multi Instance Training
141: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: Running Multi Instance Training
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 25: Running Multi Instance Training
 25: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
135: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
486: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 90: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: Running Multi Instance Training
156: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
386: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
445: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: Running Multi Instance Training
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
103: Running Multi Instance Training
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
103: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
486: Running Multi Instance Training
486: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: Running Multi Instance Training
 90: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: Running Multi Instance Training
386: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: Running Multi Instance Training
445: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: Running Multi Instance Training
234: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
224: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: Running Multi Instance Training
309: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
251: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
224: Running Multi Instance Training
224: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
305: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
416: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
274: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
251: Running Multi Instance Training
320: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
251: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
392: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
494: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: Running Multi Instance Training
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: Running Multi Instance Training
283: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
257: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
332: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: Running Multi Instance Training
416: Running Multi Instance Training
344: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
305: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
416: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: Running Multi Instance Training
113: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
274: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: Running Multi Instance Training
179: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 14: Running Multi Instance Training
 28: Running Multi Instance Training
277: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: Running Multi Instance Training
 83: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 67: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 28: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
392: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: Running Multi Instance Training
494: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
217: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: Running Multi Instance Training
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: Running Multi Instance Training
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
344: Running Multi Instance Training
320: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
344: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
117: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
145: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: Running Multi Instance Training
113: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: Running Multi Instance Training
179: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
319: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: Running Multi Instance Training
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
277: Running Multi Instance Training
277: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  7: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
126: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 67: Running Multi Instance Training
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
145: Running Multi Instance Training
145: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: Running Multi Instance Training
214: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
117: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
319: Running Multi Instance Training
319: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
168: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 40: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: Running Multi Instance Training
 78: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 78: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 96: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
412: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
449: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: Running Multi Instance Training
329: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
214: Running Multi Instance Training
214: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: Running Multi Instance Training
 16: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
281: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
168: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
496: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
222: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: Running Multi Instance Training
 78: Running Multi Instance Training
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 78: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 96: Running Multi Instance Training
460: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
460: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 96: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: Running Multi Instance Training
412: Running Multi Instance Training
449: Running Multi Instance Training
 40: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
449: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: Running Multi Instance Training
281: Running Multi Instance Training
102: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 16: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
281: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
438: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: Running Multi Instance Training
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
460: Running Multi Instance Training
 31: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
460: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: Running Multi Instance Training
456: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 60: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
411: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
222: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: Running Multi Instance Training
175: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
149: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
102: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
252: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 49: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: Running Multi Instance Training
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
456: Running Multi Instance Training
491: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
456: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: Running Multi Instance Training
114: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
438: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: Running Multi Instance Training
149: Running Multi Instance Training
175: Running Multi Instance Training
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
175: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
252: Running Multi Instance Training
 60: Running Multi Instance Training
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 60: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
411: Running Multi Instance Training
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 49: Running Multi Instance Training
 49: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
321: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: Running Multi Instance Training
491: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
470: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
114: Running Multi Instance Training
114: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
167: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
167: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
343: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
125: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
183: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
133: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
265: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: Running Multi Instance Training
321: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
475: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
195: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
470: Running Multi Instance Training
177: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
470: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: Running Multi Instance Training
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: Running Multi Instance Training
427: Running Multi Instance Training
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
125: Running Multi Instance Training
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
213: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: Running Multi Instance Training
125: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 64: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: Running Multi Instance Training
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: Running Multi Instance Training
200: Running Multi Instance Training
133: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
183: Running Multi Instance Training
200: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
503: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
183: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 20: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 99: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
195: Running Multi Instance Training
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: Running Multi Instance Training
475: Running Multi Instance Training
195: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
475: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: Running Multi Instance Training
 57: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
213: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 42: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: Running Multi Instance Training
 84: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: Running Multi Instance Training
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 99: Running Multi Instance Training
 38: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: Running Multi Instance Training
496: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
497: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
503: Running Multi Instance Training
 15: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: Running Multi Instance Training
355: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
223: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: Running Multi Instance Training
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: Running Multi Instance Training
189: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 57: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
243: Running Multi Instance Training
 42: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
243: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
279: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
140: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
100: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: Running Multi Instance Training
428: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 84: Running Multi Instance Training
 15: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: Running Multi Instance Training
116: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: Running Multi Instance Training
 38: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
151: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
151: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 51: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: Running Multi Instance Training
279: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: Running Multi Instance Training
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: Running Multi Instance Training
140: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
189: Running Multi Instance Training
495: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
495: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
189: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
334: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
258: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: Running Multi Instance Training
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
151: Running Multi Instance Training
151: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: Running Multi Instance Training
 51: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: Running Multi Instance Training
428: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
451: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
451: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
272: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: Running Multi Instance Training
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: Running Multi Instance Training
495: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
334: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
232: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
258: Running Multi Instance Training
258: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
408: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
311: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: Running Multi Instance Training
272: Running Multi Instance Training
272: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
451: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: Running Multi Instance Training
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: Running Multi Instance Training
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  5: Running Multi Instance Training
232: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
206: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  5: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
408: Running Multi Instance Training
380: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
380: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: Running Multi Instance Training
 63: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 77: Running Multi Instance Training
 77: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
439: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: Running Multi Instance Training
 86: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
206: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: Running Multi Instance Training
380: Running Multi Instance Training
406: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
380: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
389: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 72: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: Running Multi Instance Training
 63: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: Running Multi Instance Training
439: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: Running Multi Instance Training
  9: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 86: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: Running Multi Instance Training
389: Running Multi Instance Training
 71: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 71: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
389: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
143: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
128: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
136: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
276: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
400: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
187: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: Running Multi Instance Training
  9: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
367: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: Running Multi Instance Training
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: Running Multi Instance Training
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
128: Running Multi Instance Training
143: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
128: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
241: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: Running Multi Instance Training
276: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: Running Multi Instance Training
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: Running Multi Instance Training
187: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
136: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: Running Multi Instance Training
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
400: Running Multi Instance Training
400: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
268: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
241: Running Multi Instance Training
162: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
241: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
110: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
502: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
282: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
235: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
310: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
288: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: Running Multi Instance Training
162: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: Running Multi Instance Training
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: Running Multi Instance Training
268: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
110: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
328: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: Running Multi Instance Training
282: Running Multi Instance Training
502: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
282: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: Running Multi Instance Training
235: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: Running Multi Instance Training
310: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
431: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: Running Multi Instance Training
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
328: Running Multi Instance Training
288: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
477: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
328: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 92: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: Running Multi Instance Training
435: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: Running Multi Instance Training
437: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
322: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
127: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 53: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: Running Multi Instance Training
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: Running Multi Instance Training
 92: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
477: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 66: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
194: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: Running Multi Instance Training
435: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: Running Multi Instance Training
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: Running Multi Instance Training
322: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: Running Multi Instance Training
127: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: Running Multi Instance Training
 53: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
118: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: Running Multi Instance Training
 66: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: Running Multi Instance Training
 43: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 43: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
229: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
220: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
203: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: Running Multi Instance Training
 43: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: Running Multi Instance Training
198: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
229: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: Running Multi Instance Training
220: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: Running Multi Instance Training
497: Running Multi Instance Training
203: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
497: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
498: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: Running Multi Instance Training
498: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
139: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  2: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
330: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: Running Multi Instance Training
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
139: Running Multi Instance Training
139: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: Running Multi Instance Training
  2: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
479: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: Running Multi Instance Training
330: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
429: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
350: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
188: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: Running Multi Instance Training
291: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
479: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
181: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: Running Multi Instance Training
239: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
429: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
350: Running Multi Instance Training
409: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: Running Multi Instance Training
188: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: Running Multi Instance Training
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: Running Multi Instance Training
291: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
181: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: Running Multi Instance Training
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: Running Multi Instance Training
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
409: Running Multi Instance Training
409: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 87: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
202: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
196: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
196: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
401: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
500: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
152: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: Running Multi Instance Training
 87: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: Running Multi Instance Training
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
196: Running Multi Instance Training
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
105: Running Multi Instance Training
196: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
105: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: Running Multi Instance Training
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: Running Multi Instance Training
401: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
500: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: Running Multi Instance Training
152: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: Running Multi Instance Training
242: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
442: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 35: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
299: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: Running Multi Instance Training
505: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: Running Multi Instance Training
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 35: Running Multi Instance Training
157: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: Running Multi Instance Training
248: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: Running Multi Instance Training
442: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
190: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
326: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: Running Multi Instance Training
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
157: Running Multi Instance Training
511: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
157: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: Running Multi Instance Training
260: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
326: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: Running Multi Instance Training
287: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
485: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: Running Multi Instance Training
403: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
260: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: Running Multi Instance Training
485: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: Running Multi Instance Training
403: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
138: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: Running Multi Instance Training
138: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
476: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
172: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: Running Multi Instance Training
476: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: Running Multi Instance Training
511: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
508: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: Running Multi Instance Training
 29: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
172: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
169: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
506: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 82: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
290: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: Running Multi Instance Training
 29: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
415: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
169: Running Multi Instance Training
169: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: Running Multi Instance Training
 82: Running Multi Instance Training
506: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 82: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: Running Multi Instance Training
290: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
146: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: Running Multi Instance Training
415: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
197: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: Running Multi Instance Training
146: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
306: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: Running Multi Instance Training
197: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
120: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: Running Multi Instance Training
306: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
448: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: Running Multi Instance Training
120: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
134: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
253: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: Running Multi Instance Training
448: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 12: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
134: Running Multi Instance Training
134: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: Running Multi Instance Training
178: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
253: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 48: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: Running Multi Instance Training
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: Running Multi Instance Training
 12: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
507: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
441: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: Running Multi Instance Training
441: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
178: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
212: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: Running Multi Instance Training
 76: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 48: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: Running Multi Instance Training
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: Running Multi Instance Training
150: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
441: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: Running Multi Instance Training
212: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 97: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: Running Multi Instance Training
 76: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  6: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
259: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: Running Multi Instance Training
 97: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: Running Multi Instance Training
  6: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: Running Multi Instance Training
259: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
112: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
273: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
233: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: Running Multi Instance Training
112: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: Running Multi Instance Training
273: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: Running Multi Instance Training
233: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
308: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
508: Running Multi Instance Training
508: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
510: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: Running Multi Instance Training
510: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: Running Multi Instance Training
335: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
308: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
278: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: Running Multi Instance Training
142: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
492: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: Running Multi Instance Training
335: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: Running Multi Instance Training
278: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: Running Multi Instance Training
142: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
280: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: Running Multi Instance Training
492: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: Running Multi Instance Training
280: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
193: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 65: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: Running Multi Instance Training
101: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
193: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
124: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: Running Multi Instance Training
 65: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: Running Multi Instance Training
101: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: Running Multi Instance Training
124: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
119: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
323: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: Running Multi Instance Training
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
119: Running Multi Instance Training
119: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
221: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
410: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: Running Multi Instance Training
182: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 62: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: Running Multi Instance Training
436: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
499: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: Running Multi Instance Training
410: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: Running Multi Instance Training
182: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: Running Multi Instance Training
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: Running Multi Instance Training
436: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
499: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 85: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 41: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: Running Multi Instance Training
 85: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: Running Multi Instance Training
 41: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
201: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: Running Multi Instance Training
201: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
402: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
402: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
240: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: Running Multi Instance Training
402: Running Multi Instance Training
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
240: Running Multi Instance Training
402: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
191: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
240: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: Running Multi Instance Training
191: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
137: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
331: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
501: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: Running Multi Instance Training
137: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: Running Multi Instance Training
331: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
289: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: Running Multi Instance Training
478: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
478: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: Running Multi Instance Training
289: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: Running Multi Instance Training
478: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
199: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: Running Multi Instance Training
199: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
504: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: Running Multi Instance Training
504: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
509: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
443: STARTING TIMING RUN AT 2021-10-05 07:49:14 AM
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: Running Multi Instance Training
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: Running Multi Instance Training
509: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
443: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482998 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482998 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 72: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
101: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
112: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 64: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 92: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
117: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
141: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 96: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
133: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
168: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 85: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
172: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
124: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
136: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: creating process group
 12: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 88: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
160: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
128: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 73: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
120: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
157: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
102: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
113: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
113: creating process group
 65: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 52: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: creating process group
 68: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 56: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
105: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: creating process group
118: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
142: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
142: creating process group
 60: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 97: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 97: creating process group
134: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
169: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 49: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 86: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
151: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
172: creating process group
125: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: creating process group
  2: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  2: creating process group
 15: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 15: creating process group
 90: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: creating process group
129: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 10: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 10: creating process group
108: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 74: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
120: creating process group
146: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
159: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
103: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
103: creating process group
114: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
114: creating process group
 66: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 54: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 81: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 81: creating process group
 94: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 94: creating process group
 70: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 57: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: creating process group
167: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
119: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
143: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
143: creating process group
 61: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: creating process group
135: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
170: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 50: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 50: creating process group
 87: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
151: creating process group
175: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
126: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
136: creating process group
  3: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: creating process group
 12: creating process group
 91: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
163: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
130: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 11: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 11: creating process group
109: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 75: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 75: creating process group
122: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
147: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
157: creating process group
101: creating process group
115: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
115: creating process group
 67: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 55: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 82: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: creating process group
 68: creating process group
 58: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 58: creating process group
105: creating process group
165: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
117: creating process group
141: creating process group
 62: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: creating process group
134: creating process group
171: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: creating process group
 49: creating process group
 85: creating process group
149: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
175: creating process group
127: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
127: creating process group
  5: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
138: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  0: creating process group
 14: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 88: creating process group
160: creating process group
131: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: creating process group
110: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 72: creating process group
121: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: creating process group
159: creating process group
102: creating process group
112: creating process group
 64: creating process group
 52: creating process group
 83: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 83: creating process group
 92: creating process group
 70: creating process group
 59: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 59: creating process group
106: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
164: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
177: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
188: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
118: creating process group
140: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 63: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 96: creating process group
135: creating process group
168: creating process group
181: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 48: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 86: creating process group
150: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
124: creating process group
  7: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
139: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 13: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 89: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
162: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
128: creating process group
  9: creating process group
111: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
111: creating process group
 73: creating process group
123: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
146: creating process group
158: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
100: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 65: creating process group
 53: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: creating process group
153: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 69: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 57: creating process group
107: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
167: creating process group
178: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
178: creating process group
189: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
119: creating process group
140: creating process group
 60: creating process group
133: creating process group
169: creating process group
183: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
183: creating process group
 51: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 87: creating process group
184: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
148: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
173: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
125: creating process group
  5: creating process group
138: creating process group
 14: creating process group
 90: creating process group
163: creating process group
129: creating process group
108: creating process group
 74: creating process group
122: creating process group
147: creating process group
156: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
100: creating process group
 66: creating process group
 54: creating process group
 82: creating process group
154: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 71: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 56: creating process group
106: creating process group
165: creating process group
179: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
116: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 61: creating process group
132: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
170: creating process group
181: creating process group
 48: creating process group
 84: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
186: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
186: creating process group
149: creating process group
174: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
126: creating process group
  7: creating process group
139: creating process group
 13: creating process group
 91: creating process group
162: creating process group
130: creating process group
109: creating process group
123: creating process group
144: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
156: creating process group
 67: creating process group
 55: creating process group
154: creating process group
 69: creating process group
107: creating process group
164: creating process group
177: creating process group
191: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
116: creating process group
 62: creating process group
132: creating process group
182: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 51: creating process group
 84: creating process group
187: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
150: creating process group
173: creating process group
  4: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 76: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 89: creating process group
131: creating process group
110: creating process group
 36: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
121: creating process group
144: creating process group
158: creating process group
 40: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 53: creating process group
 32: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 44: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
152: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 71: creating process group
179: creating process group
188: creating process group
 63: creating process group
180: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
184: creating process group
148: creating process group
174: creating process group
  6: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 76: creating process group
 37: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 41: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 45: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
153: creating process group
176: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
189: creating process group
182: creating process group
185: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  4: creating process group
 21: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 39: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 39: creating process group
 24: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 42: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 28: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 34: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 34: creating process group
 46: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
155: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
176: creating process group
191: creating process group
180: creating process group
187: creating process group
  6: creating process group
 22: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 36: creating process group
 25: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 43: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 29: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 35: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 35: creating process group
 44: creating process group
152: creating process group
190: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
185: creating process group
 77: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 23: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 37: creating process group
 26: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 16: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 40: creating process group
 30: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 30: creating process group
 32: creating process group
 45: creating process group
155: creating process group
190: creating process group
 79: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 20: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 38: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 27: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 27: creating process group
 17: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 17: creating process group
 41: creating process group
 31: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 31: creating process group
 33: creating process group
 46: creating process group
 78: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 21: creating process group
 38: creating process group
 24: creating process group
 18: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 42: creating process group
 28: creating process group
 47: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 77: creating process group
 22: creating process group
 25: creating process group
 19: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 43: creating process group
 29: creating process group
 47: creating process group
 79: creating process group
 23: creating process group
263: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
264: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 26: creating process group
 16: creating process group
280: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
256: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
444: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
396: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
412: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
425: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
388: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
416: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
416: creating process group
404: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
392: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 20: creating process group
260: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
264: creating process group
 18: creating process group
269: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
292: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
282: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
282: creating process group
285: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
296: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
272: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
288: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
277: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 78: creating process group
440: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
400: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
408: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
428: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
437: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
420: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
432: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
432: creating process group
445: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
384: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
397: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
426: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
426: creating process group
417: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: creating process group
393: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
263: creating process group
301: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: creating process group
270: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
293: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
293: creating process group
280: creating process group
257: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
286: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
286: creating process group
297: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
309: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
278: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
441: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
401: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
409: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
429: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
438: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
433: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
433: creating process group
447: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
387: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
398: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
204: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
412: creating process group
208: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: creating process group
389: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
232: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
419: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
406: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
394: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
224: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
260: creating process group
302: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
216: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
312: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
265: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
228: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
316: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
271: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
294: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
294: creating process group
281: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
304: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
220: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
236: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
285: creating process group
298: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
273: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
273: creating process group
310: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
201: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
192: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
289: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
440: creating process group
402: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
411: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
430: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
439: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
422: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
434: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
336: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
444: creating process group
360: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
384: creating process group
348: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
399: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
399: creating process group
205: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: creating process group
376: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
209: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
341: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
352: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
425: creating process group
364: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
390: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
390: creating process group
233: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
347: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
356: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
380: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: creating process group
407: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
407: creating process group
395: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
395: creating process group
225: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
225: creating process group
368: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
262: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
303: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
217: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
252: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
313: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
313: creating process group
266: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
324: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
229: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
317: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
244: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
269: creating process group
295: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
295: creating process group
283: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
305: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: creating process group
220: creating process group
237: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
248: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
333: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
284: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
299: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
274: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
274: creating process group
311: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
311: creating process group
213: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
202: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
193: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
290: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
277: creating process group
240: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
328: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
197: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
441: creating process group
403: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
403: creating process group
408: creating process group
431: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
431: creating process group
437: creating process group
423: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
423: creating process group
435: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
337: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
445: creating process group
361: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
361: creating process group
480: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
387: creating process group
349: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
349: creating process group
469: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
492: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
396: creating process group
373: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
206: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
206: creating process group
462: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
377: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
210: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
210: creating process group
484: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
342: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
353: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
424: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
365: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
473: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
448: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
391: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
234: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
347: creating process group
357: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
465: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
419: creating process group
404: creating process group
453: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
392: creating process group
227: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
227: creating process group
488: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
369: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
261: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: creating process group
218: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
253: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
253: creating process group
314: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
314: creating process group
267: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
325: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
230: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
456: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
318: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
245: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
270: creating process group
292: creating process group
281: creating process group
306: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
256: creating process group
221: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
238: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
249: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
334: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
476: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: creating process group
284: creating process group
296: creating process group
275: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
275: creating process group
309: creating process group
214: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
203: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
194: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
291: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
278: creating process group
241: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
241: creating process group
329: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
329: creating process group
199: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
501: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
443: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
400: creating process group
409: creating process group
505: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
428: creating process group
438: creating process group
496: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
508: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
420: creating process group
434: creating process group
338: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
447: creating process group
362: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
362: creating process group
481: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
386: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
350: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
350: creating process group
468: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
493: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
493: creating process group
397: creating process group
374: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
207: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
207: creating process group
462: creating process group
413: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
378: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: creating process group
485: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
343: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
343: creating process group
355: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
424: creating process group
366: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
474: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
449: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
388: creating process group
232: creating process group
345: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
358: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
358: creating process group
466: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: creating process group
418: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
406: creating process group
454: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
454: creating process group
393: creating process group
224: creating process group
489: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
370: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
262: creating process group
301: creating process group
219: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
255: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
255: creating process group
315: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
315: creating process group
266: creating process group
326: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
231: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
231: creating process group
457: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
319: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
319: creating process group
246: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
271: creating process group
283: creating process group
307: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
307: creating process group
257: creating process group
222: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
239: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
250: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
250: creating process group
335: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
477: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
477: creating process group
320: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
287: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
297: creating process group
272: creating process group
310: creating process group
215: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
215: creating process group
201: creating process group
195: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: creating process group
289: creating process group
279: creating process group
242: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
242: creating process group
328: creating process group
197: creating process group
502: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
502: creating process group
442: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
401: creating process group
411: creating process group
506: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
429: creating process group
439: creating process group
497: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
510: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: creating process group
435: creating process group
339: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
339: creating process group
446: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
363: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
363: creating process group
482: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
385: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
351: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
351: creating process group
469: creating process group
494: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
398: creating process group
375: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
204: creating process group
460: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: creating process group
376: creating process group
208: creating process group
486: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
341: creating process group
352: creating process group
367: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
367: creating process group
475: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
450: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
389: creating process group
233: creating process group
346: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
356: creating process group
464: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
380: creating process group
418: creating process group
455: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
455: creating process group
394: creating process group
226: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
490: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
368: creating process group
261: creating process group
302: creating process group
216: creating process group
252: creating process group
312: creating process group
267: creating process group
327: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
228: creating process group
458: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
458: creating process group
316: creating process group
247: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
247: creating process group
268: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
304: creating process group
258: creating process group
223: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
236: creating process group
251: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
251: creating process group
333: creating process group
478: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
478: creating process group
322: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
287: creating process group
298: creating process group
308: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
213: creating process group
202: creating process group
192: creating process group
290: creating process group
276: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
243: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
243: creating process group
331: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
198: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
503: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
443: creating process group
402: creating process group
410: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
507: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
430: creating process group
436: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
498: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
498: creating process group
508: creating process group
422: creating process group
336: creating process group
446: creating process group
360: creating process group
483: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
386: creating process group
348: creating process group
471: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
492: creating process group
373: creating process group
205: creating process group
460: creating process group
413: creating process group
377: creating process group
209: creating process group
484: creating process group
342: creating process group
353: creating process group
364: creating process group
473: creating process group
451: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
391: creating process group
234: creating process group
344: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
357: creating process group
465: creating process group
381: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
453: creating process group
226: creating process group
491: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
491: creating process group
369: creating process group
303: creating process group
217: creating process group
254: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
265: creating process group
324: creating process group
229: creating process group
459: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
317: creating process group
244: creating process group
268: creating process group
305: creating process group
221: creating process group
237: creating process group
248: creating process group
334: creating process group
479: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
479: creating process group
323: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
299: creating process group
308: creating process group
214: creating process group
203: creating process group
193: creating process group
291: creating process group
276: creating process group
240: creating process group
330: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
199: creating process group
501: creating process group
442: creating process group
410: creating process group
505: creating process group
436: creating process group
499: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
499: creating process group
509: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
337: creating process group
480: creating process group
385: creating process group
470: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
494: creating process group
374: creating process group
461: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
378: creating process group
486: creating process group
340: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
355: creating process group
365: creating process group
474: creating process group
449: creating process group
235: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
345: creating process group
359: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
466: creating process group
383: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
452: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
488: creating process group
370: creating process group
218: creating process group
254: creating process group
325: creating process group
230: creating process group
456: creating process group
318: creating process group
245: creating process group
306: creating process group
222: creating process group
238: creating process group
249: creating process group
335: creating process group
476: creating process group
322: creating process group
212: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
200: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
194: creating process group
288: creating process group
331: creating process group
196: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
503: creating process group
506: creating process group
496: creating process group
510: creating process group
338: creating process group
481: creating process group
468: creating process group
495: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: creating process group
463: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
485: creating process group
340: creating process group
354: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
366: creating process group
475: creating process group
451: creating process group
235: creating process group
346: creating process group
359: creating process group
467: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
381: creating process group
452: creating process group
489: creating process group
371: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
219: creating process group
326: creating process group
457: creating process group
246: creating process group
223: creating process group
239: creating process group
332: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
320: creating process group
212: creating process group
200: creating process group
330: creating process group
198: creating process group
500: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
507: creating process group
497: creating process group
511: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
482: creating process group
471: creating process group
495: creating process group
372: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
461: creating process group
379: creating process group
487: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: creating process group
472: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
448: creating process group
344: creating process group
464: creating process group
383: creating process group
490: creating process group
371: creating process group
327: creating process group
459: creating process group
332: creating process group
323: creating process group
196: creating process group
500: creating process group
504: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
509: creating process group
483: creating process group
470: creating process group
372: creating process group
463: creating process group
487: creating process group
472: creating process group
450: creating process group
467: creating process group
504: creating process group
511: creating process group
  0: Process group successfully created for rank 0 . Now a global mpi barrier...
  3: Process group successfully created for rank 3 . Now a global mpi barrier...
  8: Process group successfully created for rank 8 . Now a global mpi barrier...
211: Process group successfully created for rank 211 . Now a global mpi barrier...
 11: Process group successfully created for rank 11 . Now a global mpi barrier...
220: Process group successfully created for rank 220 . Now a global mpi barrier...
192: Process group successfully created for rank 192 . Now a global mpi barrier...
255: Process group successfully created for rank 255 . Now a global mpi barrier...
244: Process group successfully created for rank 244 . Now a global mpi barrier...
236: Process group successfully created for rank 236 . Now a global mpi barrier...
190: Process group successfully created for rank 190 . Now a global mpi barrier...
185: Process group successfully created for rank 185 . Now a global mpi barrier...
234: Process group successfully created for rank 234 . Now a global mpi barrier...
231: Process group successfully created for rank 231 . Now a global mpi barrier...
159: Process group successfully created for rank 159 . Now a global mpi barrier...
245: Process group successfully created for rank 245 . Now a global mpi barrier...
257: Process group successfully created for rank 257 . Now a global mpi barrier...
242: Process group successfully created for rank 242 . Now a global mpi barrier...
260: Process group successfully created for rank 260 . Now a global mpi barrier...
270: Process group successfully created for rank 270 . Now a global mpi barrier...
256: Process group successfully created for rank 256 . Now a global mpi barrier...
237: Process group successfully created for rank 237 . Now a global mpi barrier...
249: Process group successfully created for rank 249 . Now a global mpi barrier...
278: Process group successfully created for rank 278 . Now a global mpi barrier...
243: Process group successfully created for rank 243 . Now a global mpi barrier...
261: Process group successfully created for rank 261 . Now a global mpi barrier...
266: Process group successfully created for rank 266 . Now a global mpi barrier...
279: Process group successfully created for rank 279 . Now a global mpi barrier...
262: Process group successfully created for rank 262 . Now a global mpi barrier...
265: Process group successfully created for rank 265 . Now a global mpi barrier...
268: Process group successfully created for rank 268 . Now a global mpi barrier...
285: Process group successfully created for rank 285 . Now a global mpi barrier...
289: Process group successfully created for rank 289 . Now a global mpi barrier...
300: Process group successfully created for rank 300 . Now a global mpi barrier...
247: Process group successfully created for rank 247 . Now a global mpi barrier...
271: Process group successfully created for rank 271 . Now a global mpi barrier...
292: Process group successfully created for rank 292 . Now a global mpi barrier...
248: Process group successfully created for rank 248 . Now a global mpi barrier...
246: Process group successfully created for rank 246 . Now a global mpi barrier...
281: Process group successfully created for rank 281 . Now a global mpi barrier...
287: Process group successfully created for rank 287 . Now a global mpi barrier...
296: Process group successfully created for rank 296 . Now a global mpi barrier...
291: Process group successfully created for rank 291 . Now a global mpi barrier...
301: Process group successfully created for rank 301 . Now a global mpi barrier...
293: Process group successfully created for rank 293 . Now a global mpi barrier...
283: Process group successfully created for rank 283 . Now a global mpi barrier...
298: Process group successfully created for rank 298 . Now a global mpi barrier...
288: Process group successfully created for rank 288 . Now a global mpi barrier...
302: Process group successfully created for rank 302 . Now a global mpi barrier...
295: Process group successfully created for rank 295 . Now a global mpi barrier...
304: Process group successfully created for rank 304 . Now a global mpi barrier...
299: Process group successfully created for rank 299 . Now a global mpi barrier...
290: Process group successfully created for rank 290 . Now a global mpi barrier...
303: Process group successfully created for rank 303 . Now a global mpi barrier...
312: Process group successfully created for rank 312 . Now a global mpi barrier...
294: Process group successfully created for rank 294 . Now a global mpi barrier...
307: Process group successfully created for rank 307 . Now a global mpi barrier...
297: Process group successfully created for rank 297 . Now a global mpi barrier...
308: Process group successfully created for rank 308 . Now a global mpi barrier...
316: Process group successfully created for rank 316 . Now a global mpi barrier...
305: Process group successfully created for rank 305 . Now a global mpi barrier...
309: Process group successfully created for rank 309 . Now a global mpi barrier...
313: Process group successfully created for rank 313 . Now a global mpi barrier...
318: Process group successfully created for rank 318 . Now a global mpi barrier...
306: Process group successfully created for rank 306 . Now a global mpi barrier...
310: Process group successfully created for rank 310 . Now a global mpi barrier...
315: Process group successfully created for rank 315 . Now a global mpi barrier...
317: Process group successfully created for rank 317 . Now a global mpi barrier...
320: Process group successfully created for rank 320 . Now a global mpi barrier...
311: Process group successfully created for rank 311 . Now a global mpi barrier...
314: Process group successfully created for rank 314 . Now a global mpi barrier...
324: Process group successfully created for rank 324 . Now a global mpi barrier...
319: Process group successfully created for rank 319 . Now a global mpi barrier...
332: Process group successfully created for rank 332 . Now a global mpi barrier...
321: Process group successfully created for rank 321 . Now a global mpi barrier...
328: Process group successfully created for rank 328 . Now a global mpi barrier...
337: Process group successfully created for rank 337 . Now a global mpi barrier...
340: Process group successfully created for rank 340 . Now a global mpi barrier...
325: Process group successfully created for rank 325 . Now a global mpi barrier...
333: Process group successfully created for rank 333 . Now a global mpi barrier...
322: Process group successfully created for rank 322 . Now a global mpi barrier...
338: Process group successfully created for rank 338 . Now a global mpi barrier...
342: Process group successfully created for rank 342 . Now a global mpi barrier...
345: Process group successfully created for rank 345 . Now a global mpi barrier...
326: Process group successfully created for rank 326 . Now a global mpi barrier...
335: Process group successfully created for rank 335 . Now a global mpi barrier...
323: Process group successfully created for rank 323 . Now a global mpi barrier...
339: Process group successfully created for rank 339 . Now a global mpi barrier...
348: Process group successfully created for rank 348 . Now a global mpi barrier...
341: Process group successfully created for rank 341 . Now a global mpi barrier...
352: Process group successfully created for rank 352 . Now a global mpi barrier...
327: Process group successfully created for rank 327 . Now a global mpi barrier...
334: Process group successfully created for rank 334 . Now a global mpi barrier...
336: Process group successfully created for rank 336 . Now a global mpi barrier...
343: Process group successfully created for rank 343 . Now a global mpi barrier...
364: Process group successfully created for rank 364 . Now a global mpi barrier...
346: Process group successfully created for rank 346 . Now a global mpi barrier...
329: Process group successfully created for rank 329 . Now a global mpi barrier...
360: Process group successfully created for rank 360 . Now a global mpi barrier...
349: Process group successfully created for rank 349 . Now a global mpi barrier...
353: Process group successfully created for rank 353 . Now a global mpi barrier...
344: Process group successfully created for rank 344 . Now a global mpi barrier...
356: Process group successfully created for rank 356 . Now a global mpi barrier...
330: Process group successfully created for rank 330 . Now a global mpi barrier...
361: Process group successfully created for rank 361 . Now a global mpi barrier...
350: Process group successfully created for rank 350 . Now a global mpi barrier...
373: Process group successfully created for rank 373 . Now a global mpi barrier...
376: Process group successfully created for rank 376 . Now a global mpi barrier...
354: Process group successfully created for rank 354 . Now a global mpi barrier...
366: Process group successfully created for rank 366 . Now a global mpi barrier...
347: Process group successfully created for rank 347 . Now a global mpi barrier...
357: Process group successfully created for rank 357 . Now a global mpi barrier...
368: Process group successfully created for rank 368 . Now a global mpi barrier...
331: Process group successfully created for rank 331 . Now a global mpi barrier...
363: Process group successfully created for rank 363 . Now a global mpi barrier...
372: Process group successfully created for rank 372 . Now a global mpi barrier...
377: Process group successfully created for rank 377 . Now a global mpi barrier...
355: Process group successfully created for rank 355 . Now a global mpi barrier...
367: Process group successfully created for rank 367 . Now a global mpi barrier...
358: Process group successfully created for rank 358 . Now a global mpi barrier...
370: Process group successfully created for rank 370 . Now a global mpi barrier...
362: Process group successfully created for rank 362 . Now a global mpi barrier...
384: Process group successfully created for rank 384 . Now a global mpi barrier...
374: Process group successfully created for rank 374 . Now a global mpi barrier...
378: Process group successfully created for rank 378 . Now a global mpi barrier...
365: Process group successfully created for rank 365 . Now a global mpi barrier...
359: Process group successfully created for rank 359 . Now a global mpi barrier...
380: Process group successfully created for rank 380 . Now a global mpi barrier...
369: Process group successfully created for rank 369 . Now a global mpi barrier...
385: Process group successfully created for rank 385 . Now a global mpi barrier...
375: Process group successfully created for rank 375 . Now a global mpi barrier...
379: Process group successfully created for rank 379 . Now a global mpi barrier...
393: Process group successfully created for rank 393 . Now a global mpi barrier...
371: Process group successfully created for rank 371 . Now a global mpi barrier...
351: Process group successfully created for rank 351 . Now a global mpi barrier...
388: Process group successfully created for rank 388 . Now a global mpi barrier...
394: Process group successfully created for rank 394 . Now a global mpi barrier...
397: Process group successfully created for rank 397 . Now a global mpi barrier...
390: Process group successfully created for rank 390 . Now a global mpi barrier...
382: Process group successfully created for rank 382 . Now a global mpi barrier...
389: Process group successfully created for rank 389 . Now a global mpi barrier...
381: Process group successfully created for rank 381 . Now a global mpi barrier...
486: Process group successfully created for rank 486 . Now a global mpi barrier...
480: Process group successfully created for rank 480 . Now a global mpi barrier...
507: Process group successfully created for rank 507 . Now a global mpi barrier...
509: Process group successfully created for rank 509 . Now a global mpi barrier...
386: Process group successfully created for rank 386 . Now a global mpi barrier...
383: Process group successfully created for rank 383 . Now a global mpi barrier...
392: Process group successfully created for rank 392 . Now a global mpi barrier...
398: Process group successfully created for rank 398 . Now a global mpi barrier...
404: Process group successfully created for rank 404 . Now a global mpi barrier...
409: Process group successfully created for rank 409 . Now a global mpi barrier...
407: Process group successfully created for rank 407 . Now a global mpi barrier...
416: Process group successfully created for rank 416 . Now a global mpi barrier...
406: Process group successfully created for rank 406 . Now a global mpi barrier...
400: Process group successfully created for rank 400 . Now a global mpi barrier...
241: Process group successfully created for rank 241 . Now a global mpi barrier...
402: Process group successfully created for rank 402 . Now a global mpi barrier...
506: Process group successfully created for rank 506 . Now a global mpi barrier...
391: Process group successfully created for rank 391 . Now a global mpi barrier...
395: Process group successfully created for rank 395 . Now a global mpi barrier...
405: Process group successfully created for rank 405 . Now a global mpi barrier...
387: Process group successfully created for rank 387 . Now a global mpi barrier...
412: Process group successfully created for rank 412 . Now a global mpi barrier...
419: Process group successfully created for rank 419 . Now a global mpi barrier...
408: Process group successfully created for rank 408 . Now a global mpi barrier...
396: Process group successfully created for rank 396 . Now a global mpi barrier...
413: Process group successfully created for rank 413 . Now a global mpi barrier...
417: Process group successfully created for rank 417 . Now a global mpi barrier...
403: Process group successfully created for rank 403 . Now a global mpi barrier...
420: Process group successfully created for rank 420 . Now a global mpi barrier...
414: Process group successfully created for rank 414 . Now a global mpi barrier...
418: Process group successfully created for rank 418 . Now a global mpi barrier...
401: Process group successfully created for rank 401 . Now a global mpi barrier...
411: Process group successfully created for rank 411 . Now a global mpi barrier...
430: Process group successfully created for rank 430 . Now a global mpi barrier...
434: Process group successfully created for rank 434 . Now a global mpi barrier...
410: Process group successfully created for rank 410 . Now a global mpi barrier...
422: Process group successfully created for rank 422 . Now a global mpi barrier...
423: Process group successfully created for rank 423 . Now a global mpi barrier...
435: Process group successfully created for rank 435 . Now a global mpi barrier...
496: Process group successfully created for rank 496 . Now a global mpi barrier...
415: Process group successfully created for rank 415 . Now a global mpi barrier...
421: Process group successfully created for rank 421 . Now a global mpi barrier...
433: Process group successfully created for rank 433 . Now a global mpi barrier...
399: Process group successfully created for rank 399 . Now a global mpi barrier...
424: Process group successfully created for rank 424 . Now a global mpi barrier...
428: Process group successfully created for rank 428 . Now a global mpi barrier...
436: Process group successfully created for rank 436 . Now a global mpi barrier...
432: Process group successfully created for rank 432 . Now a global mpi barrier...
441: Process group successfully created for rank 441 . Now a global mpi barrier...
429: Process group successfully created for rank 429 . Now a global mpi barrier...
427: Process group successfully created for rank 427 . Now a global mpi barrier...
431: Process group successfully created for rank 431 . Now a global mpi barrier...
444: Process group successfully created for rank 444 . Now a global mpi barrier...
448: Process group successfully created for rank 448 . Now a global mpi barrier...
453: Process group successfully created for rank 453 . Now a global mpi barrier...
440: Process group successfully created for rank 440 . Now a global mpi barrier...
438: Process group successfully created for rank 438 . Now a global mpi barrier...
446: Process group successfully created for rank 446 . Now a global mpi barrier...
454: Process group successfully created for rank 454 . Now a global mpi barrier...
443: Process group successfully created for rank 443 . Now a global mpi barrier...
437: Process group successfully created for rank 437 . Now a global mpi barrier...
447: Process group successfully created for rank 447 . Now a global mpi barrier...
449: Process group successfully created for rank 449 . Now a global mpi barrier...
457: Process group successfully created for rank 457 . Now a global mpi barrier...
442: Process group successfully created for rank 442 . Now a global mpi barrier...
439: Process group successfully created for rank 439 . Now a global mpi barrier...
445: Process group successfully created for rank 445 . Now a global mpi barrier...
460: Process group successfully created for rank 460 . Now a global mpi barrier...
451: Process group successfully created for rank 451 . Now a global mpi barrier...
465: Process group successfully created for rank 465 . Now a global mpi barrier...
452: Process group successfully created for rank 452 . Now a global mpi barrier...
472: Process group successfully created for rank 472 . Now a global mpi barrier...
450: Process group successfully created for rank 450 . Now a global mpi barrier...
464: Process group successfully created for rank 464 . Now a global mpi barrier...
455: Process group successfully created for rank 455 . Now a global mpi barrier...
459: Process group successfully created for rank 459 . Now a global mpi barrier...
461: Process group successfully created for rank 461 . Now a global mpi barrier...
485: Process group successfully created for rank 485 . Now a global mpi barrier...
467: Process group successfully created for rank 467 . Now a global mpi barrier...
458: Process group successfully created for rank 458 . Now a global mpi barrier...
462: Process group successfully created for rank 462 . Now a global mpi barrier...
474: Process group successfully created for rank 474 . Now a global mpi barrier...
505: Process group successfully created for rank 505 . Now a global mpi barrier...
463: Process group successfully created for rank 463 . Now a global mpi barrier...
425: Process group successfully created for rank 425 . Now a global mpi barrier...
473: Process group successfully created for rank 473 . Now a global mpi barrier...
475: Process group successfully created for rank 475 . Now a global mpi barrier...
497: Process group successfully created for rank 497 . Now a global mpi barrier...
466: Process group successfully created for rank 466 . Now a global mpi barrier...
469: Process group successfully created for rank 469 . Now a global mpi barrier...
487: Process group successfully created for rank 487 . Now a global mpi barrier...
476: Process group successfully created for rank 476 . Now a global mpi barrier...
483: Process group successfully created for rank 483 . Now a global mpi barrier...
426: Process group successfully created for rank 426 . Now a global mpi barrier...
456: Process group successfully created for rank 456 . Now a global mpi barrier...
477: Process group successfully created for rank 477 . Now a global mpi barrier...
492: Process group successfully created for rank 492 . Now a global mpi barrier...
491: Process group successfully created for rank 491 . Now a global mpi barrier...
478: Process group successfully created for rank 478 . Now a global mpi barrier...
488: Process group successfully created for rank 488 . Now a global mpi barrier...
  1: Process group successfully created for rank 1 . Now a global mpi barrier...
  4: Process group successfully created for rank 4 . Now a global mpi barrier...
 13: Process group successfully created for rank 13 . Now a global mpi barrier...
  2: Process group successfully created for rank 2 . Now a global mpi barrier...
 12: Process group successfully created for rank 12 . Now a global mpi barrier...
  5: Process group successfully created for rank 5 . Now a global mpi barrier...
 15: Process group successfully created for rank 15 . Now a global mpi barrier...
 20: Process group successfully created for rank 20 . Now a global mpi barrier...
 18: Process group successfully created for rank 18 . Now a global mpi barrier...
  7: Process group successfully created for rank 7 . Now a global mpi barrier...
 26: Process group successfully created for rank 26 . Now a global mpi barrier...
 19: Process group successfully created for rank 19 . Now a global mpi barrier...
  6: Process group successfully created for rank 6 . Now a global mpi barrier...
 23: Process group successfully created for rank 23 . Now a global mpi barrier...
 16: Process group successfully created for rank 16 . Now a global mpi barrier...
 22: Process group successfully created for rank 22 . Now a global mpi barrier...
 17: Process group successfully created for rank 17 . Now a global mpi barrier...
 24: Process group successfully created for rank 24 . Now a global mpi barrier...
 32: Process group successfully created for rank 32 . Now a global mpi barrier...
 27: Process group successfully created for rank 27 . Now a global mpi barrier...
 33: Process group successfully created for rank 33 . Now a global mpi barrier...
 30: Process group successfully created for rank 30 . Now a global mpi barrier...
 29: Process group successfully created for rank 29 . Now a global mpi barrier...
484: Process group successfully created for rank 484 . Now a global mpi barrier...
470: Process group successfully created for rank 470 . Now a global mpi barrier...
494: Process group successfully created for rank 494 . Now a global mpi barrier...
272: Process group successfully created for rank 272 . Now a global mpi barrier...
502: Process group successfully created for rank 502 . Now a global mpi barrier...
471: Process group successfully created for rank 471 . Now a global mpi barrier...
495: Process group successfully created for rank 495 . Now a global mpi barrier...
273: Process group successfully created for rank 273 . Now a global mpi barrier...
493: Process group successfully created for rank 493 . Now a global mpi barrier...
503: Process group successfully created for rank 503 . Now a global mpi barrier...
 14: Process group successfully created for rank 14 . Now a global mpi barrier...
 21: Process group successfully created for rank 21 . Now a global mpi barrier...
 28: Process group successfully created for rank 28 . Now a global mpi barrier...
 45: Process group successfully created for rank 45 . Now a global mpi barrier...
 25: Process group successfully created for rank 25 . Now a global mpi barrier...
 40: Process group successfully created for rank 40 . Now a global mpi barrier...
 47: Process group successfully created for rank 47 . Now a global mpi barrier...
 36: Process group successfully created for rank 36 . Now a global mpi barrier...
 52: Process group successfully created for rank 52 . Now a global mpi barrier...
 35: Process group successfully created for rank 35 . Now a global mpi barrier...
 46: Process group successfully created for rank 46 . Now a global mpi barrier...
 48: Process group successfully created for rank 48 . Now a global mpi barrier...
 39: Process group successfully created for rank 39 . Now a global mpi barrier...
 64: Process group successfully created for rank 64 . Now a global mpi barrier...
 53: Process group successfully created for rank 53 . Now a global mpi barrier...
 57: Process group successfully created for rank 57 . Now a global mpi barrier...
 61: Process group successfully created for rank 61 . Now a global mpi barrier...
 37: Process group successfully created for rank 37 . Now a global mpi barrier...
 65: Process group successfully created for rank 65 . Now a global mpi barrier...
 54: Process group successfully created for rank 54 . Now a global mpi barrier...
 31: Process group successfully created for rank 31 . Now a global mpi barrier...
 56: Process group successfully created for rank 56 . Now a global mpi barrier...
 62: Process group successfully created for rank 62 . Now a global mpi barrier...
 50: Process group successfully created for rank 50 . Now a global mpi barrier...
 38: Process group successfully created for rank 38 . Now a global mpi barrier...
 75: Process group successfully created for rank 75 . Now a global mpi barrier...
 67: Process group successfully created for rank 67 . Now a global mpi barrier...
 59: Process group successfully created for rank 59 . Now a global mpi barrier...
 60: Process group successfully created for rank 60 . Now a global mpi barrier...
 49: Process group successfully created for rank 49 . Now a global mpi barrier...
 74: Process group successfully created for rank 74 . Now a global mpi barrier...
 41: Process group successfully created for rank 41 . Now a global mpi barrier...
 68: Process group successfully created for rank 68 . Now a global mpi barrier...
 63: Process group successfully created for rank 63 . Now a global mpi barrier...
 51: Process group successfully created for rank 51 . Now a global mpi barrier...
 76: Process group successfully created for rank 76 . Now a global mpi barrier...
 43: Process group successfully created for rank 43 . Now a global mpi barrier...
 69: Process group successfully created for rank 69 . Now a global mpi barrier...
 77: Process group successfully created for rank 77 . Now a global mpi barrier...
 70: Process group successfully created for rank 70 . Now a global mpi barrier...
 78: Process group successfully created for rank 78 . Now a global mpi barrier...
 42: Process group successfully created for rank 42 . Now a global mpi barrier...
481: Process group successfully created for rank 481 . Now a global mpi barrier...
504: Process group successfully created for rank 504 . Now a global mpi barrier...
482: Process group successfully created for rank 482 . Now a global mpi barrier...
468: Process group successfully created for rank 468 . Now a global mpi barrier...
490: Process group successfully created for rank 490 . Now a global mpi barrier...
489: Process group successfully created for rank 489 . Now a global mpi barrier...
 71: Process group successfully created for rank 71 . Now a global mpi barrier...
  9: Process group successfully created for rank 9 . Now a global mpi barrier...
 10: Process group successfully created for rank 10 . Now a global mpi barrier...
 79: Process group successfully created for rank 79 . Now a global mpi barrier...
 55: Process group successfully created for rank 55 . Now a global mpi barrier...
 58: Process group successfully created for rank 58 . Now a global mpi barrier...
 88: Process group successfully created for rank 88 . Now a global mpi barrier...
 72: Process group successfully created for rank 72 . Now a global mpi barrier...
 81: Process group successfully created for rank 81 . Now a global mpi barrier...
 84: Process group successfully created for rank 84 . Now a global mpi barrier...
 89: Process group successfully created for rank 89 . Now a global mpi barrier...
 34: Process group successfully created for rank 34 . Now a global mpi barrier...
 83: Process group successfully created for rank 83 . Now a global mpi barrier...
 91: Process group successfully created for rank 91 . Now a global mpi barrier...
 82: Process group successfully created for rank 82 . Now a global mpi barrier...
 93: Process group successfully created for rank 93 . Now a global mpi barrier...
 86: Process group successfully created for rank 86 . Now a global mpi barrier...
101: Process group successfully created for rank 101 . Now a global mpi barrier...
 94: Process group successfully created for rank 94 . Now a global mpi barrier...
 97: Process group successfully created for rank 97 . Now a global mpi barrier...
 87: Process group successfully created for rank 87 . Now a global mpi barrier...
108: Process group successfully created for rank 108 . Now a global mpi barrier...
102: Process group successfully created for rank 102 . Now a global mpi barrier...
 92: Process group successfully created for rank 92 . Now a global mpi barrier...
105: Process group successfully created for rank 105 . Now a global mpi barrier...
 98: Process group successfully created for rank 98 . Now a global mpi barrier...
 85: Process group successfully created for rank 85 . Now a global mpi barrier...
109: Process group successfully created for rank 109 . Now a global mpi barrier...
100: Process group successfully created for rank 100 . Now a global mpi barrier...
112: Process group successfully created for rank 112 . Now a global mpi barrier...
117: Process group successfully created for rank 117 . Now a global mpi barrier...
111: Process group successfully created for rank 111 . Now a global mpi barrier...
121: Process group successfully created for rank 121 . Now a global mpi barrier...
115: Process group successfully created for rank 115 . Now a global mpi barrier...
104: Process group successfully created for rank 104 . Now a global mpi barrier...
113: Process group successfully created for rank 113 . Now a global mpi barrier...
106: Process group successfully created for rank 106 . Now a global mpi barrier...
122: Process group successfully created for rank 122 . Now a global mpi barrier...
107: Process group successfully created for rank 107 . Now a global mpi barrier...
120: Process group successfully created for rank 120 . Now a global mpi barrier...
 90: Process group successfully created for rank 90 . Now a global mpi barrier...
 44: Process group successfully created for rank 44 . Now a global mpi barrier...
 66: Process group successfully created for rank 66 . Now a global mpi barrier...
116: Process group successfully created for rank 116 . Now a global mpi barrier...
123: Process group successfully created for rank 123 . Now a global mpi barrier...
114: Process group successfully created for rank 114 . Now a global mpi barrier...
 80: Process group successfully created for rank 80 . Now a global mpi barrier...
 95: Process group successfully created for rank 95 . Now a global mpi barrier...
 99: Process group successfully created for rank 99 . Now a global mpi barrier...
125: Process group successfully created for rank 125 . Now a global mpi barrier...
128: Process group successfully created for rank 128 . Now a global mpi barrier...
103: Process group successfully created for rank 103 . Now a global mpi barrier...
118: Process group successfully created for rank 118 . Now a global mpi barrier...
126: Process group successfully created for rank 126 . Now a global mpi barrier...
137: Process group successfully created for rank 137 . Now a global mpi barrier...
130: Process group successfully created for rank 130 . Now a global mpi barrier...
129: Process group successfully created for rank 129 . Now a global mpi barrier...
146: Process group successfully created for rank 146 . Now a global mpi barrier...
110: Process group successfully created for rank 110 . Now a global mpi barrier...
501: Process group successfully created for rank 501 . Now a global mpi barrier...
131: Process group successfully created for rank 131 . Now a global mpi barrier...
124: Process group successfully created for rank 124 . Now a global mpi barrier...
136: Process group successfully created for rank 136 . Now a global mpi barrier...
144: Process group successfully created for rank 144 . Now a global mpi barrier...
 96: Process group successfully created for rank 96 . Now a global mpi barrier...
 73: Process group successfully created for rank 73 . Now a global mpi barrier...
140: Process group successfully created for rank 140 . Now a global mpi barrier...
132: Process group successfully created for rank 132 . Now a global mpi barrier...
138: Process group successfully created for rank 138 . Now a global mpi barrier...
135: Process group successfully created for rank 135 . Now a global mpi barrier...
139: Process group successfully created for rank 139 . Now a global mpi barrier...
147: Process group successfully created for rank 147 . Now a global mpi barrier...
157: Process group successfully created for rank 157 . Now a global mpi barrier...
152: Process group successfully created for rank 152 . Now a global mpi barrier...
166: Process group successfully created for rank 166 . Now a global mpi barrier...
145: Process group successfully created for rank 145 . Now a global mpi barrier...
153: Process group successfully created for rank 153 . Now a global mpi barrier...
141: Process group successfully created for rank 141 . Now a global mpi barrier...
148: Process group successfully created for rank 148 . Now a global mpi barrier...
154: Process group successfully created for rank 154 . Now a global mpi barrier...
165: Process group successfully created for rank 165 . Now a global mpi barrier...
177: Process group successfully created for rank 177 . Now a global mpi barrier...
142: Process group successfully created for rank 142 . Now a global mpi barrier...
168: Process group successfully created for rank 168 . Now a global mpi barrier...
161: Process group successfully created for rank 161 . Now a global mpi barrier...
179: Process group successfully created for rank 179 . Now a global mpi barrier...
143: Process group successfully created for rank 143 . Now a global mpi barrier...
181: Process group successfully created for rank 181 . Now a global mpi barrier...
149: Process group successfully created for rank 149 . Now a global mpi barrier...
162: Process group successfully created for rank 162 . Now a global mpi barrier...
156: Process group successfully created for rank 156 . Now a global mpi barrier...
150: Process group successfully created for rank 150 . Now a global mpi barrier...
163: Process group successfully created for rank 163 . Now a global mpi barrier...
151: Process group successfully created for rank 151 . Now a global mpi barrier...
479: Process group successfully created for rank 479 . Now a global mpi barrier...
167: Process group successfully created for rank 167 . Now a global mpi barrier...
158: Process group successfully created for rank 158 . Now a global mpi barrier...
155: Process group successfully created for rank 155 . Now a global mpi barrier...
170: Process group successfully created for rank 170 . Now a global mpi barrier...
160: Process group successfully created for rank 160 . Now a global mpi barrier...
176: Process group successfully created for rank 176 . Now a global mpi barrier...
172: Process group successfully created for rank 172 . Now a global mpi barrier...
164: Process group successfully created for rank 164 . Now a global mpi barrier...
178: Process group successfully created for rank 178 . Now a global mpi barrier...
189: Process group successfully created for rank 189 . Now a global mpi barrier...
171: Process group successfully created for rank 171 . Now a global mpi barrier...
180: Process group successfully created for rank 180 . Now a global mpi barrier...
184: Process group successfully created for rank 184 . Now a global mpi barrier...
191: Process group successfully created for rank 191 . Now a global mpi barrier...
169: Process group successfully created for rank 169 . Now a global mpi barrier...
186: Process group successfully created for rank 186 . Now a global mpi barrier...
173: Process group successfully created for rank 173 . Now a global mpi barrier...
188: Process group successfully created for rank 188 . Now a global mpi barrier...
183: Process group successfully created for rank 183 . Now a global mpi barrier...
187: Process group successfully created for rank 187 . Now a global mpi barrier...
175: Process group successfully created for rank 175 . Now a global mpi barrier...
205: Process group successfully created for rank 205 . Now a global mpi barrier...
208: Process group successfully created for rank 208 . Now a global mpi barrier...
182: Process group successfully created for rank 182 . Now a global mpi barrier...
210: Process group successfully created for rank 210 . Now a global mpi barrier...
499: Process group successfully created for rank 499 . Now a global mpi barrier...
511: Process group successfully created for rank 511 . Now a global mpi barrier...
510: Process group successfully created for rank 510 . Now a global mpi barrier...
119: Process group successfully created for rank 119 . Now a global mpi barrier...
174: Process group successfully created for rank 174 . Now a global mpi barrier...
196: Process group successfully created for rank 196 . Now a global mpi barrier...
204: Process group successfully created for rank 204 . Now a global mpi barrier...
209: Process group successfully created for rank 209 . Now a global mpi barrier...
193: Process group successfully created for rank 193 . Now a global mpi barrier...
133: Process group successfully created for rank 133 . Now a global mpi barrier...
127: Process group successfully created for rank 127 . Now a global mpi barrier...
206: Process group successfully created for rank 206 . Now a global mpi barrier...
217: Process group successfully created for rank 217 . Now a global mpi barrier...
222: Process group successfully created for rank 222 . Now a global mpi barrier...
212: Process group successfully created for rank 212 . Now a global mpi barrier...
200: Process group successfully created for rank 200 . Now a global mpi barrier...
194: Process group successfully created for rank 194 . Now a global mpi barrier...
134: Process group successfully created for rank 134 . Now a global mpi barrier...
198: Process group successfully created for rank 198 . Now a global mpi barrier...
207: Process group successfully created for rank 207 . Now a global mpi barrier...
218: Process group successfully created for rank 218 . Now a global mpi barrier...
203: Process group successfully created for rank 203 . Now a global mpi barrier...
195: Process group successfully created for rank 195 . Now a global mpi barrier...
197: Process group successfully created for rank 197 . Now a global mpi barrier...
232: Process group successfully created for rank 232 . Now a global mpi barrier...
224: Process group successfully created for rank 224 . Now a global mpi barrier...
216: Process group successfully created for rank 216 . Now a global mpi barrier...
228: Process group successfully created for rank 228 . Now a global mpi barrier...
223: Process group successfully created for rank 223 . Now a global mpi barrier...
213: Process group successfully created for rank 213 . Now a global mpi barrier...
201: Process group successfully created for rank 201 . Now a global mpi barrier...
199: Process group successfully created for rank 199 . Now a global mpi barrier...
235: Process group successfully created for rank 235 . Now a global mpi barrier...
227: Process group successfully created for rank 227 . Now a global mpi barrier...
219: Process group successfully created for rank 219 . Now a global mpi barrier...
229: Process group successfully created for rank 229 . Now a global mpi barrier...
221: Process group successfully created for rank 221 . Now a global mpi barrier...
238: Process group successfully created for rank 238 . Now a global mpi barrier...
250: Process group successfully created for rank 250 . Now a global mpi barrier...
214: Process group successfully created for rank 214 . Now a global mpi barrier...
202: Process group successfully created for rank 202 . Now a global mpi barrier...
233: Process group successfully created for rank 233 . Now a global mpi barrier...
263: Process group successfully created for rank 263 . Now a global mpi barrier...
230: Process group successfully created for rank 230 . Now a global mpi barrier...
258: Process group successfully created for rank 258 . Now a global mpi barrier...
239: Process group successfully created for rank 239 . Now a global mpi barrier...
274: Process group successfully created for rank 274 . Now a global mpi barrier...
215: Process group successfully created for rank 215 . Now a global mpi barrier...
240: Process group successfully created for rank 240 . Now a global mpi barrier...
498: Process group successfully created for rank 498 . Now a global mpi barrier...
508: Process group successfully created for rank 508 . Now a global mpi barrier...
226: Process group successfully created for rank 226 . Now a global mpi barrier...
252: Process group successfully created for rank 252 . Now a global mpi barrier...
264: Process group successfully created for rank 264 . Now a global mpi barrier...
259: Process group successfully created for rank 259 . Now a global mpi barrier...
253: Process group successfully created for rank 253 . Now a global mpi barrier...
267: Process group successfully created for rank 267 . Now a global mpi barrier...
280: Process group successfully created for rank 280 . Now a global mpi barrier...
275: Process group successfully created for rank 275 . Now a global mpi barrier...
277: Process group successfully created for rank 277 . Now a global mpi barrier...
225: Process group successfully created for rank 225 . Now a global mpi barrier...
254: Process group successfully created for rank 254 . Now a global mpi barrier...
251: Process group successfully created for rank 251 . Now a global mpi barrier...
286: Process group successfully created for rank 286 . Now a global mpi barrier...
500: Process group successfully created for rank 500 . Now a global mpi barrier...
282: Process group successfully created for rank 282 . Now a global mpi barrier...
284: Process group successfully created for rank 284 . Now a global mpi barrier...
276: Process group successfully created for rank 276 . Now a global mpi barrier...
269: Process group successfully created for rank 269 . Now a global mpi barrier...
314: ... barrier passed on rank  314 .
 58: ... barrier passed on rank  58 .
186: ... barrier passed on rank  186 .
442: ... barrier passed on rank  442 .
466: ... barrier passed on rank  466 .
338: ... barrier passed on rank  338 .
210: ... barrier passed on rank  210 .
406: ... barrier passed on rank  406 .
 22: ... barrier passed on rank  22 .
 26: ... barrier passed on rank  26 .
282: ... barrier passed on rank  282 .
 54: ... barrier passed on rank  54 .
 82: ... barrier passed on rank  82 .
154: ... barrier passed on rank  154 .
310: ... barrier passed on rank  310 .
182: ... barrier passed on rank  182 .
278: ... barrier passed on rank  278 .
150: ... barrier passed on rank  150 .
410: ... barrier passed on rank  410 .
494: ... barrier passed on rank  494 .
366: ... barrier passed on rank  366 .
302: ... barrier passed on rank  302 .
110: ... barrier passed on rank  110 .
 52: ... barrier passed on rank  52 .
 46: ... barrier passed on rank  46 .
238: ... barrier passed on rank  238 .
308: ... barrier passed on rank  308 .
174: ... barrier passed on rank  174 .
430: ... barrier passed on rank  430 .
438: ... barrier passed on rank  438 .
492: ... barrier passed on rank  492 .
206: ... barrier passed on rank  206 .
462: ... barrier passed on rank  462 .
364: ... barrier passed on rank  364 .
300: ... barrier passed on rank  300 .
108: ... barrier passed on rank  108 .
 18: ... barrier passed on rank  18 .
 44: ... barrier passed on rank  44 .
236: ... barrier passed on rank  236 .
334: ... barrier passed on rank  334 .
274: ... barrier passed on rank  274 .
180: ... barrier passed on rank  180 .
172: ... barrier passed on rank  172 .
 78: ... barrier passed on rank  78 .
428: ... barrier passed on rank  428 .
436: ... barrier passed on rank  436 .
434: ... barrier passed on rank  434 .
 24: ... barrier passed on rank  24 .
146: ... barrier passed on rank  146 .
280: ... barrier passed on rank  280 .
306: ... barrier passed on rank  306 .
152: ... barrier passed on rank  152 .
178: ... barrier passed on rank  178 .
 50: ... barrier passed on rank  50 .
402: ... barrier passed on rank  402 .
408: ... barrier passed on rank  408 .
470: ... barrier passed on rank  470 .
342: ... barrier passed on rank  342 .
424: ... barrier passed on rank  424 .
 40: ... barrier passed on rank  40 .
296: ... barrier passed on rank  296 .
214: ... barrier passed on rank  214 .
168: ... barrier passed on rank  168 .
 86: ... barrier passed on rank  86 .
348: ... barrier passed on rank  348 .
412: ... barrier passed on rank  412 .
 88: ... barrier passed on rank  88 .
452: ... barrier passed on rank  452 .
216: ... barrier passed on rank  216 .
324: ... barrier passed on rank  324 .
156: ... barrier passed on rank  156 .
 28: ... barrier passed on rank  28 .
220: ... barrier passed on rank  220 .
 92: ... barrier passed on rank  92 .
476: ... barrier passed on rank  476 .
284: ... barrier passed on rank  284 .
298: ... barrier passed on rank  298 .
170: ... barrier passed on rank  170 .
196: ... barrier passed on rank  196 .
420: ... barrier passed on rank  420 .
468: ... barrier passed on rank  468 .
463: ... barrier passed on rank  463 .
340: ... barrier passed on rank  340 .
472: ... barrier passed on rank  472 .
162: ... barrier passed on rank  162 .
344: ... barrier passed on rank  344 .
418: ... barrier passed on rank  418 .
 72: ... barrier passed on rank  72 .
456: ... barrier passed on rank  456 .
292: ... barrier passed on rank  292 .
 34: ... barrier passed on rank  34 .
335: ... barrier passed on rank  335 .
164: ... barrier passed on rank  164 .
212: ... barrier passed on rank  212 .
290: ... barrier passed on rank  290 .
 84: ... barrier passed on rank  84 .
 79: ... barrier passed on rank  79 .
422: ... barrier passed on rank  422 .
469: ... barrier passed on rank  469 .
399: ... barrier passed on rank  399 .
207: ... barrier passed on rank  207 .
 15: ... barrier passed on rank  15 .
460: ... barrier passed on rank  460 .
341: ... barrier passed on rank  341 .
426: ... barrier passed on rank  426 .
 90: ... barrier passed on rank  90 .
474: ... barrier passed on rank  474 .
346: ... barrier passed on rank  346 .
405: ... barrier passed on rank  405 .
 21: ... barrier passed on rank  21 .
218: ... barrier passed on rank  218 .
312: ... barrier passed on rank  312 .
 36: ... barrier passed on rank  36 .
271: ... barrier passed on rank  271 .
294: ... barrier passed on rank  294 .
 42: ... barrier passed on rank  42 .
 68: ... barrier passed on rank  68 .
 56: ... barrier passed on rank  56 .
333: ... barrier passed on rank  333 .
166: ... barrier passed on rank  166 .
213: ... barrier passed on rank  213 .
200: ... barrier passed on rank  200 .
143: ... barrier passed on rank  143 .
277: ... barrier passed on rank  277 .
 85: ... barrier passed on rank  85 .
184: ... barrier passed on rank  184 .
149: ... barrier passed on rank  149 .
 76: ... barrier passed on rank  76 .
440: ... barrier passed on rank  440 .
506: ... barrier passed on rank  506 .
421: ... barrier passed on rank  421 .
482: ... barrier passed on rank  482 .
398: ... barrier passed on rank  398 .
372: ... barrier passed on rank  372 .
205: ... barrier passed on rank  205 .
 14: ... barrier passed on rank  14 .
461: ... barrier passed on rank  461 .
378: ... barrier passed on rank  378 .
211: ... barrier passed on rank  211 .
486: ... barrier passed on rank  486 .
354: ... barrier passed on rank  354 .
358: ... barrier passed on rank  358 .
467: ... barrier passed on rank  467 .
407: ... barrier passed on rank  407 .
226: ... barrier passed on rank  226 .
490: ... barrier passed on rank  490 .
 23: ... barrier passed on rank  23 .
 38: ... barrier passed on rank  38 .
122: ... barrier passed on rank  122 .
230: ... barrier passed on rank  230 .
147: ... barrier passed on rank  147 .
244: ... barrier passed on rank  244 .
 19: ... barrier passed on rank  19 .
270: ... barrier passed on rank  270 .
293: ... barrier passed on rank  293 .
102: ... barrier passed on rank  102 .
 53: ... barrier passed on rank  53 .
 83: ... barrier passed on rank  83 .
250: ... barrier passed on rank  250 .
 57: ... barrier passed on rank  57 .
332: ... barrier passed on rank  332 .
275: ... barrier passed on rank  275 .
309: ... barrier passed on rank  309 .
165: ... barrier passed on rank  165 .
116: ... barrier passed on rank  116 .
142: ... barrier passed on rank  142 .
 98: ... barrier passed on rank  98 .
279: ... barrier passed on rank  279 .
185: ... barrier passed on rank  185 .
151: ... barrier passed on rank  151 .
328: ... barrier passed on rank  328 .
 77: ... barrier passed on rank  77 .
500: ... barrier passed on rank  500 .
441: ... barrier passed on rank  441 .
403: ... barrier passed on rank  403 .
437: ... barrier passed on rank  437 .
339: ... barrier passed on rank  339 .
444: ... barrier passed on rank  444 .
360: ... barrier passed on rank  360 .
350: ... barrier passed on rank  350 .
374: ... barrier passed on rank  374 .
204: ... barrier passed on rank  204 .
414: ... barrier passed on rank  414 .
208: ... barrier passed on rank  208 .
388: ... barrier passed on rank  388 .
234: ... barrier passed on rank  234 .
488: ... barrier passed on rank  488 .
370: ... barrier passed on rank  370 .
260: ... barrier passed on rank  260 .
303: ... barrier passed on rank  303 .
313: ... barrier passed on rank  313 .
 37: ... barrier passed on rank  37 .
 74: ... barrier passed on rank  74 .
 25: ... barrier passed on rank  25 .
144: ... barrier passed on rank  144 .
458: ... barrier passed on rank  458 .
158: ... barrier passed on rank  158 .
316: ... barrier passed on rank  316 .
246: ... barrier passed on rank  246 .
 16: ... barrier passed on rank  16 .
281: ... barrier passed on rank  281 .
114: ... barrier passed on rank  114 .
 55: ... barrier passed on rank  55 .
 30: ... barrier passed on rank  30 .
222: ... barrier passed on rank  222 .
 47: ... barrier passed on rank  47 .
 94: ... barrier passed on rank  94 .
153: ... barrier passed on rank  153 .
478: ... barrier passed on rank  478 .
106: ... barrier passed on rank  106 .
286: ... barrier passed on rank  286 .
272: ... barrier passed on rank  272 .
311: ... barrier passed on rank  311 .
202: ... barrier passed on rank  202 .
188: ... barrier passed on rank  188 .
118: ... barrier passed on rank  118 .
 60: ... barrier passed on rank  60 .
132: ... barrier passed on rank  132 .
181: ... barrier passed on rank  181 .
242: ... barrier passed on rank  242 .
  4: ... barrier passed on rank  4 .
330: ... barrier passed on rank  330 .
502: ... barrier passed on rank  502 .
400: ... barrier passed on rank  400 .
409: ... barrier passed on rank  409 .
431: ... barrier passed on rank  431 .
439: ... barrier passed on rank  439 .
498: ... barrier passed on rank  498 .
336: ... barrier passed on rank  336 .
362: ... barrier passed on rank  362 .
351: ... barrier passed on rank  351 .
397: ... barrier passed on rank  397 .
 13: ... barrier passed on rank  13 .
415: ... barrier passed on rank  415 .
376: ... barrier passed on rank  376 .
484: ... barrier passed on rank  484 .
425: ... barrier passed on rank  425 .
450: ... barrier passed on rank  450 .
232: ... barrier passed on rank  232 .
356: ... barrier passed on rank  356 .
464: ... barrier passed on rank  464 .
419: ... barrier passed on rank  419 .
454: ... barrier passed on rank  454 .
392: ... barrier passed on rank  392 .
  8: ... barrier passed on rank  8 .
301: ... barrier passed on rank  301 .
264: ... barrier passed on rank  264 .
326: ... barrier passed on rank  326 .
 27: ... barrier passed on rank  27 .
120: ... barrier passed on rank  120 .
228: ... barrier passed on rank  228 .
159: ... barrier passed on rank  159 .
269: ... barrier passed on rank  269 .
 41: ... barrier passed on rank  41 .
283: ... barrier passed on rank  283 .
100: ... barrier passed on rank  100 .
 67: ... barrier passed on rank  67 .
 31: ... barrier passed on rank  31 .
223: ... barrier passed on rank  223 .
 35: ... barrier passed on rank  35 .
 45: ... barrier passed on rank  45 .
 80: ... barrier passed on rank  80 .
 95: ... barrier passed on rank  95 .
155: ... barrier passed on rank  155 .
 70: ... barrier passed on rank  70 .
248: ... barrier passed on rank  248 .
 59: ... barrier passed on rank  59 .
479: ... barrier passed on rank  479 .
104: ... barrier passed on rank  104 .
322: ... barrier passed on rank  322 .
287: ... barrier passed on rank  287 .
297: ... barrier passed on rank  297 .
141: ... barrier passed on rank  141 .
194: ... barrier passed on rank  194 .
169: ... barrier passed on rank  169 .
183: ... barrier passed on rank  183 .
291: ... barrier passed on rank  291 .
187: ... barrier passed on rank  187 .
175: ... barrier passed on rank  175 .
136: ... barrier passed on rank  136 .
198: ... barrier passed on rank  198 .
443: ... barrier passed on rank  443 .
411: ... barrier passed on rank  411 .
504: ... barrier passed on rank  504 .
429: ... barrier passed on rank  429 .
423: ... barrier passed on rank  423 .
435: ... barrier passed on rank  435 .
349: ... barrier passed on rank  349 .
471: ... barrier passed on rank  471 .
495: ... barrier passed on rank  495 .
396: ... barrier passed on rank  396 .
373: ... barrier passed on rank  373 .
 12: ... barrier passed on rank  12 .
413: ... barrier passed on rank  413 .
377: ... barrier passed on rank  377 .
485: ... barrier passed on rank  485 .
343: ... barrier passed on rank  343 .
 89: ... barrier passed on rank  89 .
367: ... barrier passed on rank  367 .
473: ... barrier passed on rank  473 .
451: ... barrier passed on rank  451 .
163: ... barrier passed on rank  163 .
345: ... barrier passed on rank  345 .
357: ... barrier passed on rank  357 .
380: ... barrier passed on rank  380 .
416: ... barrier passed on rank  416 .
453: ... barrier passed on rank  453 .
395: ... barrier passed on rank  395 .
 11: ... barrier passed on rank  11 .
111: ... barrier passed on rank  111 .
217: ... barrier passed on rank  217 .
252: ... barrier passed on rank  252 .
315: ... barrier passed on rank  315 .
 39: ... barrier passed on rank  39 .
267: ... barrier passed on rank  267 .
325: ... barrier passed on rank  325 .
 73: ... barrier passed on rank  73 .
121: ... barrier passed on rank  121 .
229: ... barrier passed on rank  229 .
457: ... barrier passed on rank  457 .
157: ... barrier passed on rank  157 .
245: ... barrier passed on rank  245 .
268: ... barrier passed on rank  268 .
295: ... barrier passed on rank  295 .
101: ... barrier passed on rank  101 .
 66: ... barrier passed on rank  66 .
307: ... barrier passed on rank  307 .
 29: ... barrier passed on rank  29 .
221: ... barrier passed on rank  221 .
 32: ... barrier passed on rank  32 .
239: ... barrier passed on rank  239 .
 93: ... barrier passed on rank  93 .
 69: ... barrier passed on rank  69 .
249: ... barrier passed on rank  249 .
477: ... barrier passed on rank  477 .
323: ... barrier passed on rank  323 .
285: ... barrier passed on rank  285 .
167: ... barrier passed on rank  167 .
179: ... barrier passed on rank  179 .
215: ... barrier passed on rank  215 .
201: ... barrier passed on rank  201 .
117: ... barrier passed on rank  117 .
140: ... barrier passed on rank  140 .
195: ... barrier passed on rank  195 .
288: ... barrier passed on rank  288 .
 51: ... barrier passed on rank  51 .
 87: ... barrier passed on rank  87 .
173: ... barrier passed on rank  173 .
124: ... barrier passed on rank  124 .
139: ... barrier passed on rank  139 .
197: ... barrier passed on rank  197 .
501: ... barrier passed on rank  501 .
505: ... barrier passed on rank  505 .
508: ... barrier passed on rank  508 .
  2: ... barrier passed on rank  2 .
432: ... barrier passed on rank  432 .
446: ... barrier passed on rank  446 .
361: ... barrier passed on rank  361 .
386: ... barrier passed on rank  386 .
493: ... barrier passed on rank  493 .
375: ... barrier passed on rank  375 .
 91: ... barrier passed on rank  91 .
365: ... barrier passed on rank  365 .
475: ... barrier passed on rank  475 .
448: ... barrier passed on rank  448 .
390: ... barrier passed on rank  390 .
233: ... barrier passed on rank  233 .
160: ... barrier passed on rank  160 .
347: ... barrier passed on rank  347 .
455: ... barrier passed on rank  455 .
394: ... barrier passed on rank  394 .
489: ... barrier passed on rank  489 .
130: ... barrier passed on rank  130 .
 10: ... barrier passed on rank  10 .
262: ... barrier passed on rank  262 .
109: ... barrier passed on rank  109 .
219: ... barrier passed on rank  219 .
266: ... barrier passed on rank  266 .
327: ... barrier passed on rank  327 .
 75: ... barrier passed on rank  75 .
145: ... barrier passed on rank  145 .
459: ... barrier passed on rank  459 .
318: ... barrier passed on rank  318 .
247: ... barrier passed on rank  247 .
 17: ... barrier passed on rank  17 .
 64: ... barrier passed on rank  64 .
304: ... barrier passed on rank  304 .
258: ... barrier passed on rank  258 .
237: ... barrier passed on rank  237 .
 71: ... barrier passed on rank  71 .
105: ... barrier passed on rank  105 .
320: ... barrier passed on rank  320 .
273: ... barrier passed on rank  273 .
176: ... barrier passed on rank  176 .
203: ... barrier passed on rank  203 .
190: ... barrier passed on rank  190 .
119: ... barrier passed on rank  119 .
 62: ... barrier passed on rank  62 .
192: ... barrier passed on rank  192 .
134: ... barrier passed on rank  134 .
 48: ... barrier passed on rank  48 .
  6: ... barrier passed on rank  6 .
329: ... barrier passed on rank  329 .
138: ... barrier passed on rank  138 .
199: ... barrier passed on rank  199 .
503: ... barrier passed on rank  503 .
401: ... barrier passed on rank  401 .
  3: ... barrier passed on rank  3 .
433: ... barrier passed on rank  433 .
445: ... barrier passed on rank  445 .
483: ... barrier passed on rank  483 .
387: ... barrier passed on rank  387 .
379: ... barrier passed on rank  379 .
487: ... barrier passed on rank  487 .
355: ... barrier passed on rank  355 .
427: ... barrier passed on rank  427 .
389: ... barrier passed on rank  389 .
359: ... barrier passed on rank  359 .
393: ... barrier passed on rank  393 .
227: ... barrier passed on rank  227 .
371: ... barrier passed on rank  371 .
131: ... barrier passed on rank  131 .
  9: ... barrier passed on rank  9 .
261: ... barrier passed on rank  261 .
265: ... barrier passed on rank  265 .
123: ... barrier passed on rank  123 .
231: ... barrier passed on rank  231 .
317: ... barrier passed on rank  317 .
 43: ... barrier passed on rank  43 .
103: ... barrier passed on rank  103 .
115: ... barrier passed on rank  115 .
305: ... barrier passed on rank  305 .
259: ... barrier passed on rank  259 .
251: ... barrier passed on rank  251 .
299: ... barrier passed on rank  299 .
177: ... barrier passed on rank  177 .
189: ... barrier passed on rank  189 .
 61: ... barrier passed on rank  61 .
 99: ... barrier passed on rank  99 .
133: ... barrier passed on rank  133 .
171: ... barrier passed on rank  171 .
 49: ... barrier passed on rank  49 .
243: ... barrier passed on rank  243 .
  5: ... barrier passed on rank  5 .
331: ... barrier passed on rank  331 .
137: ... barrier passed on rank  137 .
507: ... barrier passed on rank  507 .
499: ... barrier passed on rank  499 .
  0: ... barrier passed on rank  0 .
337: ... barrier passed on rank  337 .
447: ... barrier passed on rank  447 .
480: ... barrier passed on rank  480 .
384: ... barrier passed on rank  384 .
209: ... barrier passed on rank  209 .
352: ... barrier passed on rank  352 .
391: ... barrier passed on rank  391 .
465: ... barrier passed on rank  465 .
224: ... barrier passed on rank  224 .
368: ... barrier passed on rank  368 .
128: ... barrier passed on rank  128 .
263: ... barrier passed on rank  263 .
319: ... barrier passed on rank  319 .
112: ... barrier passed on rank  112 .
256: ... barrier passed on rank  256 .
 81: ... barrier passed on rank  81 .
191: ... barrier passed on rank  191 .
 63: ... barrier passed on rank  63 .
 96: ... barrier passed on rank  96 .
135: ... barrier passed on rank  135 .
240: ... barrier passed on rank  240 .
  7: ... barrier passed on rank  7 .
496: ... barrier passed on rank  496 .
381: ... barrier passed on rank  381 .
369: ... barrier passed on rank  369 .
253: ... barrier passed on rank  253 .
113: ... barrier passed on rank  113 .
241: ... barrier passed on rank  241 .
125: ... barrier passed on rank  125 .
497: ... barrier passed on rank  497 .
509: ... barrier passed on rank  509 .
382: ... barrier passed on rank  382 .
491: ... barrier passed on rank  491 .
254: ... barrier passed on rank  254 .
126: ... barrier passed on rank  126 .
510: ... barrier passed on rank  510 .
363: ... barrier passed on rank  363 .
235: ... barrier passed on rank  235 .
255: ... barrier passed on rank  255 .
107: ... barrier passed on rank  107 .
127: ... barrier passed on rank  127 .
511: ... barrier passed on rank  511 .
383: ... barrier passed on rank  383 .
449: ... barrier passed on rank  449 .
 65: ... barrier passed on rank  65 .
193: ... barrier passed on rank  193 .
321: ... barrier passed on rank  321 .
417: ... barrier passed on rank  417 .
 33: ... barrier passed on rank  33 .
289: ... barrier passed on rank  289 .
161: ... barrier passed on rank  161 .
  1: ... barrier passed on rank  1 .
385: ... barrier passed on rank  385 .
257: ... barrier passed on rank  257 .
129: ... barrier passed on rank  129 .
481: ... barrier passed on rank  481 .
353: ... barrier passed on rank  353 .
225: ... barrier passed on rank  225 .
 97: ... barrier passed on rank  97 .
 20: ... barrier passed on rank  20 .
276: ... barrier passed on rank  276 .
148: ... barrier passed on rank  148 .
404: ... barrier passed on rank  404 .
  0: hkn0403:1738669:1738669 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  0: hkn0403:1738669:1738669 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  0: hkn0403:1738669:1738669 [0] NCCL INFO P2P plugin IBext
  0: hkn0403:1738669:1738669 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  0: hkn0403:1738669:1738669 [0] NCCL INFO Using network IBext
  0: NCCL version 2.11.4+cuda11.4
  1: hkn0403:1738685:1738685 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  2: hkn0403:1738697:1738697 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  3: hkn0403:1738677:1738677 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  1: hkn0403:1738685:1738685 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  1: hkn0403:1738685:1738685 [1] NCCL INFO P2P plugin IBext
  2: hkn0403:1738697:1738697 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  2: hkn0403:1738697:1738697 [2] NCCL INFO P2P plugin IBext
  3: hkn0403:1738677:1738677 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  3: hkn0403:1738677:1738677 [3] NCCL INFO P2P plugin IBext
 98: hkn0501:1312966:1312966 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
  1: hkn0403:1738685:1738685 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  3: hkn0403:1738677:1738677 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  3: hkn0403:1738677:1738677 [3] NCCL INFO Using network IBext
  1: hkn0403:1738685:1738685 [1] NCCL INFO Using network IBext
  2: hkn0403:1738697:1738697 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  2: hkn0403:1738697:1738697 [2] NCCL INFO Using network IBext
 96: hkn0501:1312974:1312974 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 99: hkn0501:1312982:1312982 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 98: hkn0501:1312966:1312966 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 98: hkn0501:1312966:1312966 [2] NCCL INFO P2P plugin IBext
 97: hkn0501:1312996:1312996 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 96: hkn0501:1312974:1312974 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 96: hkn0501:1312974:1312974 [0] NCCL INFO P2P plugin IBext
 97: hkn0501:1312996:1312996 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 97: hkn0501:1312996:1312996 [1] NCCL INFO P2P plugin IBext
 99: hkn0501:1312982:1312982 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 99: hkn0501:1312982:1312982 [3] NCCL INFO P2P plugin IBext
 96: hkn0501:1312974:1312974 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 96: hkn0501:1312974:1312974 [0] NCCL INFO Using network IBext
 97: hkn0501:1312996:1312996 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 97: hkn0501:1312996:1312996 [1] NCCL INFO Using network IBext
 99: hkn0501:1312982:1312982 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 99: hkn0501:1312982:1312982 [3] NCCL INFO Using network IBext
 98: hkn0501:1312966:1312966 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 98: hkn0501:1312966:1312966 [2] NCCL INFO Using network IBext
418: hkn0725:3097089:3097089 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
419: hkn0725:3097098:3097098 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
417: hkn0725:3097090:3097090 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
416: hkn0725:3097110:3097110 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
280: hkn0622:2005593:2005593 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
282: hkn0622:2005581:2005581 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
418: hkn0725:3097089:3097089 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
418: hkn0725:3097089:3097089 [2] NCCL INFO P2P plugin IBext
283: hkn0622:2005565:2005565 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
419: hkn0725:3097098:3097098 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
419: hkn0725:3097098:3097098 [3] NCCL INFO P2P plugin IBext
417: hkn0725:3097090:3097090 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
417: hkn0725:3097090:3097090 [1] NCCL INFO P2P plugin IBext
416: hkn0725:3097110:3097110 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
416: hkn0725:3097110:3097110 [0] NCCL INFO P2P plugin IBext
368: hkn0712:280251:280251 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
390: hkn0717:4172695:4172695 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
389: hkn0717:4172715:4172715 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
280: hkn0622:2005593:2005593 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
280: hkn0622:2005593:2005593 [0] NCCL INFO P2P plugin IBext
391: hkn0717:4172703:4172703 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
388: hkn0717:4172687:4172687 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
282: hkn0622:2005581:2005581 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
282: hkn0622:2005581:2005581 [2] NCCL INFO P2P plugin IBext
371: hkn0712:280263:280263 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
283: hkn0622:2005565:2005565 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
283: hkn0622:2005565:2005565 [3] NCCL INFO P2P plugin IBext
416: hkn0725:3097110:3097110 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
416: hkn0725:3097110:3097110 [0] NCCL INFO Using network IBext
419: hkn0725:3097098:3097098 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
419: hkn0725:3097098:3097098 [3] NCCL INFO Using network IBext
417: hkn0725:3097090:3097090 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
417: hkn0725:3097090:3097090 [1] NCCL INFO Using network IBext
281: hkn0622:2005573:2005573 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
370: hkn0712:280242:280242 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
  9: hkn0405:3191904:3191904 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 10: hkn0405:3191876:3191876 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
430: hkn0728:1309110:1309110 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
  8: hkn0405:3191892:3191892 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
429: hkn0728:1309098:1309098 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
368: hkn0712:280251:280251 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
368: hkn0712:280251:280251 [0] NCCL INFO P2P plugin IBext
390: hkn0717:4172695:4172695 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
390: hkn0717:4172695:4172695 [2] NCCL INFO P2P plugin IBext
389: hkn0717:4172715:4172715 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
389: hkn0717:4172715:4172715 [1] NCCL INFO P2P plugin IBext
 11: hkn0405:3191884:3191884 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
428: hkn0728:1309082:1309082 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
431: hkn0728:1309090:1309090 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
391: hkn0717:4172703:4172703 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
391: hkn0717:4172703:4172703 [3] NCCL INFO P2P plugin IBext
388: hkn0717:4172687:4172687 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
388: hkn0717:4172687:4172687 [0] NCCL INFO P2P plugin IBext
 49: hkn0417:2252738:2252738 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
282: hkn0622:2005581:2005581 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
283: hkn0622:2005565:2005565 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
283: hkn0622:2005565:2005565 [3] NCCL INFO Using network IBext
282: hkn0622:2005581:2005581 [2] NCCL INFO Using network IBext
369: hkn0712:280243:280243 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
371: hkn0712:280263:280263 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
371: hkn0712:280263:280263 [3] NCCL INFO P2P plugin IBext
418: hkn0725:3097089:3097089 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
418: hkn0725:3097089:3097089 [2] NCCL INFO Using network IBext
281: hkn0622:2005573:2005573 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
281: hkn0622:2005573:2005573 [1] NCCL INFO P2P plugin IBext
370: hkn0712:280242:280242 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
370: hkn0712:280242:280242 [2] NCCL INFO P2P plugin IBext
430: hkn0728:1309110:1309110 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
430: hkn0728:1309110:1309110 [2] NCCL INFO P2P plugin IBext
 10: hkn0405:3191876:3191876 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 10: hkn0405:3191876:3191876 [2] NCCL INFO P2P plugin IBext
429: hkn0728:1309098:1309098 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
429: hkn0728:1309098:1309098 [1] NCCL INFO P2P plugin IBext
  9: hkn0405:3191904:3191904 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  9: hkn0405:3191904:3191904 [1] NCCL INFO P2P plugin IBext
  8: hkn0405:3191892:3191892 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  8: hkn0405:3191892:3191892 [0] NCCL INFO P2P plugin IBext
493: hkn0810:924720:924720 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
 11: hkn0405:3191884:3191884 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 11: hkn0405:3191884:3191884 [3] NCCL INFO P2P plugin IBext
428: hkn0728:1309082:1309082 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
428: hkn0728:1309082:1309082 [0] NCCL INFO P2P plugin IBext
495: hkn0810:924736:924736 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
431: hkn0728:1309090:1309090 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
431: hkn0728:1309090:1309090 [3] NCCL INFO P2P plugin IBext
280: hkn0622:2005593:2005593 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
280: hkn0622:2005593:2005593 [0] NCCL INFO Using network IBext
388: hkn0717:4172687:4172687 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
391: hkn0717:4172703:4172703 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
388: hkn0717:4172687:4172687 [0] NCCL INFO Using network IBext
391: hkn0717:4172703:4172703 [3] NCCL INFO Using network IBext
 48: hkn0417:2252758:2252758 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
 49: hkn0417:2252738:2252738 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 49: hkn0417:2252738:2252738 [1] NCCL INFO P2P plugin IBext
103: hkn0502:214196:214196 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
281: hkn0622:2005573:2005573 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
281: hkn0622:2005573:2005573 [1] NCCL INFO Using network IBext
101: hkn0502:214224:214224 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
369: hkn0712:280243:280243 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
369: hkn0712:280243:280243 [1] NCCL INFO P2P plugin IBext
370: hkn0712:280242:280242 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
371: hkn0712:280263:280263 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
371: hkn0712:280263:280263 [3] NCCL INFO Using network IBext
370: hkn0712:280242:280242 [2] NCCL INFO Using network IBext
 51: hkn0417:2252746:2252746 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
 50: hkn0417:2252730:2252730 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
100: hkn0502:214212:214212 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
102: hkn0502:214204:214204 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
492: hkn0810:924748:924748 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
368: hkn0712:280251:280251 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
368: hkn0712:280251:280251 [0] NCCL INFO Using network IBext
 11: hkn0405:3191884:3191884 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 11: hkn0405:3191884:3191884 [3] NCCL INFO Using network IBext
493: hkn0810:924720:924720 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
493: hkn0810:924720:924720 [1] NCCL INFO P2P plugin IBext
390: hkn0717:4172695:4172695 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
390: hkn0717:4172695:4172695 [2] NCCL INFO Using network IBext
431: hkn0728:1309090:1309090 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
428: hkn0728:1309082:1309082 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
431: hkn0728:1309090:1309090 [3] NCCL INFO Using network IBext
428: hkn0728:1309082:1309082 [0] NCCL INFO Using network IBext
389: hkn0717:4172715:4172715 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
389: hkn0717:4172715:4172715 [1] NCCL INFO Using network IBext
369: hkn0712:280243:280243 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
369: hkn0712:280243:280243 [1] NCCL INFO Using network IBext
495: hkn0810:924736:924736 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
495: hkn0810:924736:924736 [3] NCCL INFO P2P plugin IBext
494: hkn0810:924728:924728 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
103: hkn0502:214196:214196 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
103: hkn0502:214196:214196 [3] NCCL INFO P2P plugin IBext
129: hkn0509:3109564:3109564 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
 48: hkn0417:2252758:2252758 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 48: hkn0417:2252758:2252758 [0] NCCL INFO P2P plugin IBext
101: hkn0502:214224:214224 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
101: hkn0502:214224:214224 [1] NCCL INFO P2P plugin IBext
 51: hkn0417:2252746:2252746 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 51: hkn0417:2252746:2252746 [3] NCCL INFO P2P plugin IBext
 50: hkn0417:2252730:2252730 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 50: hkn0417:2252730:2252730 [2] NCCL INFO P2P plugin IBext
100: hkn0502:214212:214212 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
100: hkn0502:214212:214212 [0] NCCL INFO P2P plugin IBext
290: hkn0624:1758086:1758086 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
131: hkn0509:3109556:3109556 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
130: hkn0509:3109548:3109548 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
102: hkn0502:214204:214204 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
102: hkn0502:214204:214204 [2] NCCL INFO P2P plugin IBext
204: hkn0532:908782:908782 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
  9: hkn0405:3191904:3191904 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  9: hkn0405:3191904:3191904 [1] NCCL INFO Using network IBext
510: hkn0816:360796:360796 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
 10: hkn0405:3191876:3191876 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 10: hkn0405:3191876:3191876 [2] NCCL INFO Using network IBext
  8: hkn0405:3191892:3191892 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  8: hkn0405:3191892:3191892 [0] NCCL INFO Using network IBext
429: hkn0728:1309098:1309098 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
429: hkn0728:1309098:1309098 [1] NCCL INFO Using network IBext
430: hkn0728:1309110:1309110 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
430: hkn0728:1309110:1309110 [2] NCCL INFO Using network IBext
492: hkn0810:924748:924748 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
492: hkn0810:924748:924748 [0] NCCL INFO P2P plugin IBext
128: hkn0509:3109576:3109576 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
288: hkn0624:1758070:1758070 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
508: hkn0816:360788:360788 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
511: hkn0816:360780:360780 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
 60: hkn0420:3195338:3195338 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
494: hkn0810:924728:924728 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
494: hkn0810:924728:924728 [2] NCCL INFO P2P plugin IBext
129: hkn0509:3109564:3109564 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
129: hkn0509:3109564:3109564 [1] NCCL INFO P2P plugin IBext
506: hkn0815:380337:380337 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
 63: hkn0420:3195346:3195346 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
 48: hkn0417:2252758:2252758 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 48: hkn0417:2252758:2252758 [0] NCCL INFO Using network IBext
 50: hkn0417:2252730:2252730 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 51: hkn0417:2252746:2252746 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 50: hkn0417:2252730:2252730 [2] NCCL INFO Using network IBext
 51: hkn0417:2252746:2252746 [3] NCCL INFO Using network IBext
 49: hkn0417:2252738:2252738 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 49: hkn0417:2252738:2252738 [1] NCCL INFO Using network IBext
291: hkn0624:1758078:1758078 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
 61: hkn0420:3195354:3195354 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
467: hkn0803:861681:861681 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
289: hkn0624:1758098:1758098 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
100: hkn0502:214212:214212 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
102: hkn0502:214204:214204 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
102: hkn0502:214204:214204 [2] NCCL INFO Using network IBext
100: hkn0502:214212:214212 [0] NCCL INFO Using network IBext
290: hkn0624:1758086:1758086 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
290: hkn0624:1758086:1758086 [2] NCCL INFO P2P plugin IBext
206: hkn0532:908802:908802 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
130: hkn0509:3109548:3109548 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
130: hkn0509:3109548:3109548 [2] NCCL INFO P2P plugin IBext
131: hkn0509:3109556:3109556 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
131: hkn0509:3109556:3109556 [3] NCCL INFO P2P plugin IBext
204: hkn0532:908782:908782 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
204: hkn0532:908782:908782 [0] NCCL INFO P2P plugin IBext
505: hkn0815:380329:380329 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
510: hkn0816:360796:360796 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
510: hkn0816:360796:360796 [2] NCCL INFO P2P plugin IBext
492: hkn0810:924748:924748 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
492: hkn0810:924748:924748 [0] NCCL INFO Using network IBext
464: hkn0803:861669:861669 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
494: hkn0810:924728:924728 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
494: hkn0810:924728:924728 [2] NCCL INFO Using network IBext
288: hkn0624:1758070:1758070 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
288: hkn0624:1758070:1758070 [0] NCCL INFO P2P plugin IBext
509: hkn0816:360808:360808 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
493: hkn0810:924720:924720 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
493: hkn0810:924720:924720 [1] NCCL INFO Using network IBext
128: hkn0509:3109576:3109576 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
128: hkn0509:3109576:3109576 [0] NCCL INFO P2P plugin IBext
205: hkn0532:908774:908774 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
508: hkn0816:360788:360788 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
508: hkn0816:360788:360788 [0] NCCL INFO P2P plugin IBext
495: hkn0810:924736:924736 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
511: hkn0816:360780:360780 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
511: hkn0816:360780:360780 [3] NCCL INFO P2P plugin IBext
495: hkn0810:924736:924736 [3] NCCL INFO Using network IBext
 60: hkn0420:3195338:3195338 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 60: hkn0420:3195338:3195338 [0] NCCL INFO P2P plugin IBext
 63: hkn0420:3195346:3195346 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 63: hkn0420:3195346:3195346 [3] NCCL INFO P2P plugin IBext
506: hkn0815:380337:380337 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
506: hkn0815:380337:380337 [2] NCCL INFO P2P plugin IBext
504: hkn0815:380357:380357 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
291: hkn0624:1758078:1758078 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
291: hkn0624:1758078:1758078 [3] NCCL INFO P2P plugin IBext
 61: hkn0420:3195354:3195354 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 61: hkn0420:3195354:3195354 [1] NCCL INFO P2P plugin IBext
207: hkn0532:908790:908790 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
507: hkn0815:380345:380345 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
101: hkn0502:214224:214224 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
101: hkn0502:214224:214224 [1] NCCL INFO Using network IBext
467: hkn0803:861681:861681 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
467: hkn0803:861681:861681 [3] NCCL INFO P2P plugin IBext
103: hkn0502:214196:214196 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
103: hkn0502:214196:214196 [3] NCCL INFO Using network IBext
289: hkn0624:1758098:1758098 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
289: hkn0624:1758098:1758098 [1] NCCL INFO P2P plugin IBext
 62: hkn0420:3195366:3195366 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
206: hkn0532:908802:908802 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
206: hkn0532:908802:908802 [2] NCCL INFO P2P plugin IBext
131: hkn0509:3109556:3109556 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
131: hkn0509:3109556:3109556 [3] NCCL INFO Using network IBext
128: hkn0509:3109576:3109576 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
128: hkn0509:3109576:3109576 [0] NCCL INFO Using network IBext
130: hkn0509:3109548:3109548 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
130: hkn0509:3109548:3109548 [2] NCCL INFO Using network IBext
505: hkn0815:380329:380329 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
505: hkn0815:380329:380329 [1] NCCL INFO P2P plugin IBext
464: hkn0803:861669:861669 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
464: hkn0803:861669:861669 [0] NCCL INFO P2P plugin IBext
288: hkn0624:1758070:1758070 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
288: hkn0624:1758070:1758070 [0] NCCL INFO Using network IBext
466: hkn0803:861668:861668 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
465: hkn0803:861667:861667 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
509: hkn0816:360808:360808 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
509: hkn0816:360808:360808 [1] NCCL INFO P2P plugin IBext
508: hkn0816:360788:360788 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
508: hkn0816:360788:360788 [0] NCCL INFO Using network IBext
511: hkn0816:360780:360780 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
205: hkn0532:908774:908774 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
205: hkn0532:908774:908774 [1] NCCL INFO P2P plugin IBext
511: hkn0816:360780:360780 [3] NCCL INFO Using network IBext
291: hkn0624:1758078:1758078 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
291: hkn0624:1758078:1758078 [3] NCCL INFO Using network IBext
289: hkn0624:1758098:1758098 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
289: hkn0624:1758098:1758098 [1] NCCL INFO Using network IBext
129: hkn0509:3109564:3109564 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
129: hkn0509:3109564:3109564 [1] NCCL INFO Using network IBext
504: hkn0815:380357:380357 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
504: hkn0815:380357:380357 [0] NCCL INFO P2P plugin IBext
 61: hkn0420:3195354:3195354 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 61: hkn0420:3195354:3195354 [1] NCCL INFO Using network IBext
207: hkn0532:908790:908790 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
207: hkn0532:908790:908790 [3] NCCL INFO P2P plugin IBext
507: hkn0815:380345:380345 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
507: hkn0815:380345:380345 [3] NCCL INFO P2P plugin IBext
 62: hkn0420:3195366:3195366 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 62: hkn0420:3195366:3195366 [2] NCCL INFO P2P plugin IBext
290: hkn0624:1758086:1758086 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
290: hkn0624:1758086:1758086 [2] NCCL INFO Using network IBext
206: hkn0532:908802:908802 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
206: hkn0532:908802:908802 [2] NCCL INFO Using network IBext
509: hkn0816:360808:360808 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
509: hkn0816:360808:360808 [1] NCCL INFO Using network IBext
505: hkn0815:380329:380329 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
505: hkn0815:380329:380329 [1] NCCL INFO Using network IBext
464: hkn0803:861669:861669 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
464: hkn0803:861669:861669 [0] NCCL INFO Using network IBext
205: hkn0532:908774:908774 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
205: hkn0532:908774:908774 [1] NCCL INFO Using network IBext
204: hkn0532:908782:908782 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
204: hkn0532:908782:908782 [0] NCCL INFO Using network IBext
466: hkn0803:861668:861668 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
466: hkn0803:861668:861668 [2] NCCL INFO P2P plugin IBext
465: hkn0803:861667:861667 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
465: hkn0803:861667:861667 [1] NCCL INFO P2P plugin IBext
208: hkn0534:1133577:1133577 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
510: hkn0816:360796:360796 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
510: hkn0816:360796:360796 [2] NCCL INFO Using network IBext
504: hkn0815:380357:380357 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
504: hkn0815:380357:380357 [0] NCCL INFO Using network IBext
207: hkn0532:908790:908790 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
207: hkn0532:908790:908790 [3] NCCL INFO Using network IBext
507: hkn0815:380345:380345 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
507: hkn0815:380345:380345 [3] NCCL INFO Using network IBext
 63: hkn0420:3195346:3195346 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 63: hkn0420:3195346:3195346 [3] NCCL INFO Using network IBext
 62: hkn0420:3195366:3195366 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 62: hkn0420:3195366:3195366 [2] NCCL INFO Using network IBext
211: hkn0534:1133581:1133581 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
506: hkn0815:380337:380337 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
506: hkn0815:380337:380337 [2] NCCL INFO Using network IBext
 60: hkn0420:3195338:3195338 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 60: hkn0420:3195338:3195338 [0] NCCL INFO Using network IBext
210: hkn0534:1133593:1133593 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
467: hkn0803:861681:861681 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
467: hkn0803:861681:861681 [3] NCCL INFO Using network IBext
466: hkn0803:861668:861668 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
466: hkn0803:861668:861668 [2] NCCL INFO Using network IBext
465: hkn0803:861667:861667 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
465: hkn0803:861667:861667 [1] NCCL INFO Using network IBext
209: hkn0534:1133578:1133578 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
125: hkn0508:3124305:3124305 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
126: hkn0508:3124297:3124297 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
208: hkn0534:1133577:1133577 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
208: hkn0534:1133577:1133577 [0] NCCL INFO P2P plugin IBext
124: hkn0508:3124325:3124325 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
214: hkn0535:2384181:2384181 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
 80: hkn0425:2069098:2069098 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
 25: hkn0410:1144790:1144790 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
211: hkn0534:1133581:1133581 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
211: hkn0534:1133581:1133581 [3] NCCL INFO P2P plugin IBext
210: hkn0534:1133593:1133593 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
210: hkn0534:1133593:1133593 [2] NCCL INFO P2P plugin IBext
127: hkn0508:3124313:3124313 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
 82: hkn0425:2069118:2069118 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
213: hkn0535:2384189:2384189 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
212: hkn0535:2384201:2384201 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
 81: hkn0425:2069090:2069090 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
209: hkn0534:1133578:1133578 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
209: hkn0534:1133578:1133578 [1] NCCL INFO P2P plugin IBext
125: hkn0508:3124305:3124305 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
125: hkn0508:3124305:3124305 [1] NCCL INFO P2P plugin IBext
215: hkn0535:2384173:2384173 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
126: hkn0508:3124297:3124297 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
126: hkn0508:3124297:3124297 [2] NCCL INFO P2P plugin IBext
 26: hkn0410:1144773:1144773 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 83: hkn0425:2069106:2069106 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
124: hkn0508:3124325:3124325 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
124: hkn0508:3124325:3124325 [0] NCCL INFO P2P plugin IBext
214: hkn0535:2384181:2384181 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
214: hkn0535:2384181:2384181 [2] NCCL INFO P2P plugin IBext
 55: hkn0418:1854333:1854333 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
 24: hkn0410:1144774:1144774 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 25: hkn0410:1144790:1144790 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 25: hkn0410:1144790:1144790 [1] NCCL INFO P2P plugin IBext
320: hkn0633:1511506:1511506 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
 80: hkn0425:2069098:2069098 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 80: hkn0425:2069098:2069098 [0] NCCL INFO P2P plugin IBext
210: hkn0534:1133593:1133593 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
211: hkn0534:1133581:1133581 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
211: hkn0534:1133581:1133581 [3] NCCL INFO Using network IBext
210: hkn0534:1133593:1133593 [2] NCCL INFO Using network IBext
209: hkn0534:1133578:1133578 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
209: hkn0534:1133578:1133578 [1] NCCL INFO Using network IBext
127: hkn0508:3124313:3124313 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
127: hkn0508:3124313:3124313 [3] NCCL INFO P2P plugin IBext
213: hkn0535:2384189:2384189 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
213: hkn0535:2384189:2384189 [1] NCCL INFO P2P plugin IBext
 82: hkn0425:2069118:2069118 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 82: hkn0425:2069118:2069118 [2] NCCL INFO P2P plugin IBext
 81: hkn0425:2069090:2069090 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 81: hkn0425:2069090:2069090 [1] NCCL INFO P2P plugin IBext
 27: hkn0410:1144778:1144778 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
212: hkn0535:2384201:2384201 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
212: hkn0535:2384201:2384201 [0] NCCL INFO P2P plugin IBext
215: hkn0535:2384173:2384173 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
215: hkn0535:2384173:2384173 [3] NCCL INFO P2P plugin IBext
358: hkn0708:398424:398424 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
201: hkn0531:1215724:1215724 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
 54: hkn0418:1854325:1854325 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
  5: hkn0404:1324527:1324527 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
 26: hkn0410:1144773:1144773 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 26: hkn0410:1144773:1144773 [2] NCCL INFO P2P plugin IBext
208: hkn0534:1133577:1133577 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
208: hkn0534:1133577:1133577 [0] NCCL INFO Using network IBext
 83: hkn0425:2069106:2069106 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 83: hkn0425:2069106:2069106 [3] NCCL INFO P2P plugin IBext
124: hkn0508:3124325:3124325 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
124: hkn0508:3124325:3124325 [0] NCCL INFO Using network IBext
 55: hkn0418:1854333:1854333 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 55: hkn0418:1854333:1854333 [3] NCCL INFO P2P plugin IBext
 24: hkn0410:1144774:1144774 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 24: hkn0410:1144774:1144774 [0] NCCL INFO P2P plugin IBext
 52: hkn0418:1854341:1854341 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
320: hkn0633:1511506:1511506 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
320: hkn0633:1511506:1511506 [0] NCCL INFO P2P plugin IBext
127: hkn0508:3124313:3124313 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
127: hkn0508:3124313:3124313 [3] NCCL INFO Using network IBext
  4: hkn0404:1324511:1324511 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
 81: hkn0425:2069090:2069090 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 81: hkn0425:2069090:2069090 [1] NCCL INFO Using network IBext
 82: hkn0425:2069118:2069118 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 82: hkn0425:2069118:2069118 [2] NCCL INFO Using network IBext
 53: hkn0418:1854353:1854353 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
 89: hkn0427:1120325:1120325 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
357: hkn0708:398436:398436 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
215: hkn0535:2384173:2384173 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
215: hkn0535:2384173:2384173 [3] NCCL INFO Using network IBext
212: hkn0535:2384201:2384201 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
213: hkn0535:2384189:2384189 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
212: hkn0535:2384201:2384201 [0] NCCL INFO Using network IBext
213: hkn0535:2384189:2384189 [1] NCCL INFO Using network IBext
 27: hkn0410:1144778:1144778 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 27: hkn0410:1144778:1144778 [3] NCCL INFO P2P plugin IBext
 88: hkn0427:1120324:1120324 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
125: hkn0508:3124305:3124305 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
125: hkn0508:3124305:3124305 [1] NCCL INFO Using network IBext
 83: hkn0425:2069106:2069106 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 83: hkn0425:2069106:2069106 [3] NCCL INFO Using network IBext
203: hkn0531:1215704:1215704 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
358: hkn0708:398424:398424 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
358: hkn0708:398424:398424 [2] NCCL INFO P2P plugin IBext
126: hkn0508:3124297:3124297 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
126: hkn0508:3124297:3124297 [2] NCCL INFO Using network IBext
201: hkn0531:1215724:1215724 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
201: hkn0531:1215724:1215724 [1] NCCL INFO P2P plugin IBext
 33: hkn0412:2247562:2247562 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 90: hkn0427:1120345:1120345 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
200: hkn0531:1215696:1215696 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
 54: hkn0418:1854325:1854325 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 54: hkn0418:1854325:1854325 [2] NCCL INFO P2P plugin IBext
 24: hkn0410:1144774:1144774 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 26: hkn0410:1144773:1144773 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 24: hkn0410:1144774:1144774 [0] NCCL INFO Using network IBext
 26: hkn0410:1144773:1144773 [2] NCCL INFO Using network IBext
359: hkn0708:398415:398415 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
 34: hkn0412:2247554:2247554 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 91: hkn0427:1120333:1120333 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
  5: hkn0404:1324527:1324527 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  5: hkn0404:1324527:1324527 [1] NCCL INFO P2P plugin IBext
356: hkn0708:398416:398416 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
378: hkn0714:417196:417196 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
 52: hkn0418:1854341:1854341 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 52: hkn0418:1854341:1854341 [0] NCCL INFO P2P plugin IBext
214: hkn0535:2384181:2384181 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
214: hkn0535:2384181:2384181 [2] NCCL INFO Using network IBext
 25: hkn0410:1144790:1144790 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 25: hkn0410:1144790:1144790 [1] NCCL INFO Using network IBext
 27: hkn0410:1144778:1144778 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 27: hkn0410:1144778:1144778 [3] NCCL INFO Using network IBext
  4: hkn0404:1324511:1324511 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  4: hkn0404:1324511:1324511 [0] NCCL INFO P2P plugin IBext
202: hkn0531:1215712:1215712 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
 80: hkn0425:2069098:2069098 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 80: hkn0425:2069098:2069098 [0] NCCL INFO Using network IBext
323: hkn0633:1511534:1511534 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
 32: hkn0412:2247570:2247570 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 53: hkn0418:1854353:1854353 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 53: hkn0418:1854353:1854353 [1] NCCL INFO P2P plugin IBext
322: hkn0633:1511522:1511522 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
357: hkn0708:398436:398436 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
357: hkn0708:398436:398436 [1] NCCL INFO P2P plugin IBext
 89: hkn0427:1120325:1120325 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 89: hkn0427:1120325:1120325 [1] NCCL INFO P2P plugin IBext
 88: hkn0427:1120324:1120324 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 88: hkn0427:1120324:1120324 [0] NCCL INFO P2P plugin IBext
321: hkn0633:1511514:1511514 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
377: hkn0714:417216:417216 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
203: hkn0531:1215704:1215704 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
203: hkn0531:1215704:1215704 [3] NCCL INFO P2P plugin IBext
137: hkn0511:3051503:3051503 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
379: hkn0714:417204:417204 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
 54: hkn0418:1854325:1854325 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 54: hkn0418:1854325:1854325 [2] NCCL INFO Using network IBext
 33: hkn0412:2247562:2247562 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 33: hkn0412:2247562:2247562 [1] NCCL INFO P2P plugin IBext
200: hkn0531:1215696:1215696 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
200: hkn0531:1215696:1215696 [0] NCCL INFO P2P plugin IBext
 52: hkn0418:1854341:1854341 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 90: hkn0427:1120345:1120345 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 90: hkn0427:1120345:1120345 [2] NCCL INFO P2P plugin IBext
 52: hkn0418:1854341:1854341 [0] NCCL INFO Using network IBext
359: hkn0708:398415:398415 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
359: hkn0708:398415:398415 [3] NCCL INFO P2P plugin IBext
 34: hkn0412:2247554:2247554 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 34: hkn0412:2247554:2247554 [2] NCCL INFO P2P plugin IBext
 91: hkn0427:1120333:1120333 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 91: hkn0427:1120333:1120333 [3] NCCL INFO P2P plugin IBext
 35: hkn0412:2247582:2247582 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
378: hkn0714:417196:417196 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
378: hkn0714:417196:417196 [2] NCCL INFO P2P plugin IBext
356: hkn0708:398416:398416 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
356: hkn0708:398416:398416 [0] NCCL INFO P2P plugin IBext
 55: hkn0418:1854333:1854333 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 55: hkn0418:1854333:1854333 [3] NCCL INFO Using network IBext
138: hkn0511:3051491:3051491 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
 53: hkn0418:1854353:1854353 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 53: hkn0418:1854353:1854353 [1] NCCL INFO Using network IBext
376: hkn0714:417195:417195 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
  4: hkn0404:1324511:1324511 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  4: hkn0404:1324511:1324511 [0] NCCL INFO Using network IBext
202: hkn0531:1215712:1215712 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
202: hkn0531:1215712:1215712 [2] NCCL INFO P2P plugin IBext
139: hkn0511:3051483:3051483 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
323: hkn0633:1511534:1511534 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
323: hkn0633:1511534:1511534 [3] NCCL INFO P2P plugin IBext
 32: hkn0412:2247570:2247570 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 32: hkn0412:2247570:2247570 [0] NCCL INFO P2P plugin IBext
136: hkn0511:3051475:3051475 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
357: hkn0708:398436:398436 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
357: hkn0708:398436:398436 [1] NCCL INFO Using network IBext
320: hkn0633:1511506:1511506 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
320: hkn0633:1511506:1511506 [0] NCCL INFO Using network IBext
322: hkn0633:1511522:1511522 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
322: hkn0633:1511522:1511522 [2] NCCL INFO P2P plugin IBext
321: hkn0633:1511514:1511514 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
321: hkn0633:1511514:1511514 [1] NCCL INFO P2P plugin IBext
359: hkn0708:398415:398415 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
359: hkn0708:398415:398415 [3] NCCL INFO Using network IBext
203: hkn0531:1215704:1215704 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
203: hkn0531:1215704:1215704 [3] NCCL INFO Using network IBext
377: hkn0714:417216:417216 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
377: hkn0714:417216:417216 [1] NCCL INFO P2P plugin IBext
200: hkn0531:1215696:1215696 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
200: hkn0531:1215696:1215696 [0] NCCL INFO Using network IBext
137: hkn0511:3051503:3051503 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
137: hkn0511:3051503:3051503 [1] NCCL INFO P2P plugin IBext
356: hkn0708:398416:398416 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
356: hkn0708:398416:398416 [0] NCCL INFO Using network IBext
379: hkn0714:417204:417204 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
379: hkn0714:417204:417204 [3] NCCL INFO P2P plugin IBext
358: hkn0708:398424:398424 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
358: hkn0708:398424:398424 [2] NCCL INFO Using network IBext
 90: hkn0427:1120345:1120345 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 91: hkn0427:1120333:1120333 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 90: hkn0427:1120345:1120345 [2] NCCL INFO Using network IBext
 91: hkn0427:1120333:1120333 [3] NCCL INFO Using network IBext
  6: hkn0404:1324539:1324539 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
201: hkn0531:1215724:1215724 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
201: hkn0531:1215724:1215724 [1] NCCL INFO Using network IBext
202: hkn0531:1215712:1215712 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
202: hkn0531:1215712:1215712 [2] NCCL INFO Using network IBext
 35: hkn0412:2247582:2247582 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 35: hkn0412:2247582:2247582 [3] NCCL INFO P2P plugin IBext
323: hkn0633:1511534:1511534 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
323: hkn0633:1511534:1511534 [3] NCCL INFO Using network IBext
272: hkn0617:2279782:2279782 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
  5: hkn0404:1324527:1324527 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  5: hkn0404:1324527:1324527 [1] NCCL INFO Using network IBext
376: hkn0714:417195:417195 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
376: hkn0714:417195:417195 [0] NCCL INFO P2P plugin IBext
138: hkn0511:3051491:3051491 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
138: hkn0511:3051491:3051491 [2] NCCL INFO P2P plugin IBext
322: hkn0633:1511522:1511522 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
322: hkn0633:1511522:1511522 [2] NCCL INFO Using network IBext
321: hkn0633:1511514:1511514 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
321: hkn0633:1511514:1511514 [1] NCCL INFO Using network IBext
 32: hkn0412:2247570:2247570 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 32: hkn0412:2247570:2247570 [0] NCCL INFO Using network IBext
139: hkn0511:3051483:3051483 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
139: hkn0511:3051483:3051483 [3] NCCL INFO P2P plugin IBext
136: hkn0511:3051475:3051475 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
136: hkn0511:3051475:3051475 [0] NCCL INFO P2P plugin IBext
273: hkn0617:2279794:2279794 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
377: hkn0714:417216:417216 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
379: hkn0714:417204:417204 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
377: hkn0714:417216:417216 [1] NCCL INFO Using network IBext
379: hkn0714:417204:417204 [3] NCCL INFO Using network IBext
 89: hkn0427:1120325:1120325 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 89: hkn0427:1120325:1120325 [1] NCCL INFO Using network IBext
 88: hkn0427:1120324:1120324 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 88: hkn0427:1120324:1120324 [0] NCCL INFO Using network IBext
 35: hkn0412:2247582:2247582 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 35: hkn0412:2247582:2247582 [3] NCCL INFO Using network IBext
376: hkn0714:417195:417195 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
376: hkn0714:417195:417195 [0] NCCL INFO Using network IBext
 33: hkn0412:2247562:2247562 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 33: hkn0412:2247562:2247562 [1] NCCL INFO Using network IBext
254: hkn0611:694965:694965 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
 34: hkn0412:2247554:2247554 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 34: hkn0412:2247554:2247554 [2] NCCL INFO Using network IBext
255: hkn0611:694957:694957 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
272: hkn0617:2279782:2279782 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
272: hkn0617:2279782:2279782 [0] NCCL INFO P2P plugin IBext
141: hkn0512:3029294:3029294 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
  6: hkn0404:1324539:1324539 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  6: hkn0404:1324539:1324539 [2] NCCL INFO P2P plugin IBext
136: hkn0511:3051475:3051475 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
138: hkn0511:3051491:3051491 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
139: hkn0511:3051483:3051483 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
138: hkn0511:3051491:3051491 [2] NCCL INFO Using network IBext
139: hkn0511:3051483:3051483 [3] NCCL INFO Using network IBext
136: hkn0511:3051475:3051475 [0] NCCL INFO Using network IBext
253: hkn0611:694985:694985 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
378: hkn0714:417196:417196 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
378: hkn0714:417196:417196 [2] NCCL INFO Using network IBext
252: hkn0611:694973:694973 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
275: hkn0617:2279766:2279766 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
142: hkn0512:3029322:3029322 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
273: hkn0617:2279794:2279794 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
273: hkn0617:2279794:2279794 [1] NCCL INFO P2P plugin IBext
  7: hkn0404:1324519:1324519 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
 30: hkn0411:2301012:2301012 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
143: hkn0512:3029310:3029310 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
137: hkn0511:3051503:3051503 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
137: hkn0511:3051503:3051503 [1] NCCL INFO Using network IBext
140: hkn0512:3029302:3029302 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
254: hkn0611:694965:694965 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
254: hkn0611:694965:694965 [2] NCCL INFO P2P plugin IBext
255: hkn0611:694957:694957 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
255: hkn0611:694957:694957 [3] NCCL INFO P2P plugin IBext
141: hkn0512:3029294:3029294 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
141: hkn0512:3029294:3029294 [1] NCCL INFO P2P plugin IBext
  6: hkn0404:1324539:1324539 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  6: hkn0404:1324539:1324539 [2] NCCL INFO Using network IBext
253: hkn0611:694985:694985 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
253: hkn0611:694985:694985 [1] NCCL INFO P2P plugin IBext
252: hkn0611:694973:694973 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
252: hkn0611:694973:694973 [0] NCCL INFO P2P plugin IBext
275: hkn0617:2279766:2279766 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
275: hkn0617:2279766:2279766 [3] NCCL INFO P2P plugin IBext
273: hkn0617:2279794:2279794 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
273: hkn0617:2279794:2279794 [1] NCCL INFO Using network IBext
142: hkn0512:3029322:3029322 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
142: hkn0512:3029322:3029322 [2] NCCL INFO P2P plugin IBext
 28: hkn0411:2301020:2301020 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
274: hkn0617:2279774:2279774 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
 29: hkn0411:2301040:2301040 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
 30: hkn0411:2301012:2301012 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 30: hkn0411:2301012:2301012 [2] NCCL INFO P2P plugin IBext
 31: hkn0411:2301028:2301028 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
413: hkn0724:1701132:1701132 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
  7: hkn0404:1324519:1324519 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  7: hkn0404:1324519:1324519 [3] NCCL INFO P2P plugin IBext
143: hkn0512:3029310:3029310 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
143: hkn0512:3029310:3029310 [3] NCCL INFO P2P plugin IBext
140: hkn0512:3029302:3029302 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
140: hkn0512:3029302:3029302 [0] NCCL INFO P2P plugin IBext
412: hkn0724:1701140:1701140 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
275: hkn0617:2279766:2279766 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
275: hkn0617:2279766:2279766 [3] NCCL INFO Using network IBext
272: hkn0617:2279782:2279782 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
272: hkn0617:2279782:2279782 [0] NCCL INFO Using network IBext
252: hkn0611:694973:694973 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
253: hkn0611:694985:694985 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
252: hkn0611:694973:694973 [0] NCCL INFO Using network IBext
253: hkn0611:694985:694985 [1] NCCL INFO Using network IBext
142: hkn0512:3029322:3029322 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
142: hkn0512:3029322:3029322 [2] NCCL INFO Using network IBext
274: hkn0617:2279774:2279774 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
274: hkn0617:2279774:2279774 [2] NCCL INFO P2P plugin IBext
143: hkn0512:3029310:3029310 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
143: hkn0512:3029310:3029310 [3] NCCL INFO Using network IBext
 28: hkn0411:2301020:2301020 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 28: hkn0411:2301020:2301020 [0] NCCL INFO P2P plugin IBext
140: hkn0512:3029302:3029302 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
140: hkn0512:3029302:3029302 [0] NCCL INFO Using network IBext
 29: hkn0411:2301040:2301040 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 29: hkn0411:2301040:2301040 [1] NCCL INFO P2P plugin IBext
446: hkn0733:1374549:1374549 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
 31: hkn0411:2301028:2301028 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 31: hkn0411:2301028:2301028 [3] NCCL INFO P2P plugin IBext
413: hkn0724:1701132:1701132 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
413: hkn0724:1701132:1701132 [1] NCCL INFO P2P plugin IBext
  7: hkn0404:1324519:1324519 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  7: hkn0404:1324519:1324519 [3] NCCL INFO Using network IBext
447: hkn0733:1374550:1374550 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
412: hkn0724:1701140:1701140 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
412: hkn0724:1701140:1701140 [0] NCCL INFO P2P plugin IBext
255: hkn0611:694957:694957 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
255: hkn0611:694957:694957 [3] NCCL INFO Using network IBext
254: hkn0611:694965:694965 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
254: hkn0611:694965:694965 [2] NCCL INFO Using network IBext
274: hkn0617:2279774:2279774 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
274: hkn0617:2279774:2279774 [2] NCCL INFO Using network IBext
141: hkn0512:3029294:3029294 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
141: hkn0512:3029294:3029294 [1] NCCL INFO Using network IBext
445: hkn0733:1374570:1374570 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
122: hkn0507:3172208:3172208 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
123: hkn0507:3172200:3172200 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
 28: hkn0411:2301020:2301020 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 29: hkn0411:2301040:2301040 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 31: hkn0411:2301028:2301028 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 28: hkn0411:2301020:2301020 [0] NCCL INFO Using network IBext
 29: hkn0411:2301040:2301040 [1] NCCL INFO Using network IBext
 31: hkn0411:2301028:2301028 [3] NCCL INFO Using network IBext
444: hkn0733:1374558:1374558 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
446: hkn0733:1374549:1374549 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
446: hkn0733:1374549:1374549 [2] NCCL INFO P2P plugin IBext
 30: hkn0411:2301012:2301012 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 30: hkn0411:2301012:2301012 [2] NCCL INFO Using network IBext
447: hkn0733:1374550:1374550 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
447: hkn0733:1374550:1374550 [3] NCCL INFO P2P plugin IBext
120: hkn0507:3172228:3172228 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
362: hkn0710:340630:340630 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
415: hkn0724:1701152:1701152 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
121: hkn0507:3172216:3172216 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
312: hkn0631:1006952:1006952 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
445: hkn0733:1374570:1374570 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
445: hkn0733:1374570:1374570 [1] NCCL INFO P2P plugin IBext
314: hkn0631:1006951:1006951 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
122: hkn0507:3172208:3172208 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
122: hkn0507:3172208:3172208 [2] NCCL INFO P2P plugin IBext
123: hkn0507:3172200:3172200 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
123: hkn0507:3172200:3172200 [3] NCCL INFO P2P plugin IBext
444: hkn0733:1374558:1374558 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
444: hkn0733:1374558:1374558 [0] NCCL INFO P2P plugin IBext
315: hkn0631:1006960:1006960 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
447: hkn0733:1374550:1374550 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
447: hkn0733:1374550:1374550 [3] NCCL INFO Using network IBext
313: hkn0631:1006972:1006972 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
337: hkn0703:726148:726148 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
 43: hkn0414:1966712:1966712 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
445: hkn0733:1374570:1374570 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
445: hkn0733:1374570:1374570 [1] NCCL INFO Using network IBext
336: hkn0703:726160:726160 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
120: hkn0507:3172228:3172228 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
120: hkn0507:3172228:3172228 [0] NCCL INFO P2P plugin IBext
219: hkn0601:102808:102808 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
415: hkn0724:1701152:1701152 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
415: hkn0724:1701152:1701152 [3] NCCL INFO P2P plugin IBext
362: hkn0710:340630:340630 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
362: hkn0710:340630:340630 [2] NCCL INFO P2P plugin IBext
121: hkn0507:3172216:3172216 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
121: hkn0507:3172216:3172216 [1] NCCL INFO P2P plugin IBext
413: hkn0724:1701132:1701132 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
413: hkn0724:1701132:1701132 [1] NCCL INFO Using network IBext
412: hkn0724:1701140:1701140 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
412: hkn0724:1701140:1701140 [0] NCCL INFO Using network IBext
312: hkn0631:1006952:1006952 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
312: hkn0631:1006952:1006952 [0] NCCL INFO P2P plugin IBext
444: hkn0733:1374558:1374558 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
444: hkn0733:1374558:1374558 [0] NCCL INFO Using network IBext
314: hkn0631:1006951:1006951 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
314: hkn0631:1006951:1006951 [2] NCCL INFO P2P plugin IBext
414: hkn0724:1701124:1701124 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
216: hkn0601:102816:102816 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
123: hkn0507:3172200:3172200 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
123: hkn0507:3172200:3172200 [3] NCCL INFO Using network IBext
351: hkn0706:737447:737447 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
120: hkn0507:3172228:3172228 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
120: hkn0507:3172228:3172228 [0] NCCL INFO Using network IBext
315: hkn0631:1006960:1006960 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
315: hkn0631:1006960:1006960 [3] NCCL INFO P2P plugin IBext
446: hkn0733:1374549:1374549 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
446: hkn0733:1374549:1374549 [2] NCCL INFO Using network IBext
 41: hkn0414:1966724:1966724 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
415: hkn0724:1701152:1701152 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
415: hkn0724:1701152:1701152 [3] NCCL INFO Using network IBext
313: hkn0631:1006972:1006972 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
313: hkn0631:1006972:1006972 [1] NCCL INFO P2P plugin IBext
337: hkn0703:726148:726148 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
337: hkn0703:726148:726148 [1] NCCL INFO P2P plugin IBext
 43: hkn0414:1966712:1966712 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 43: hkn0414:1966712:1966712 [3] NCCL INFO P2P plugin IBext
 40: hkn0414:1966696:1966696 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
336: hkn0703:726160:726160 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
336: hkn0703:726160:726160 [0] NCCL INFO P2P plugin IBext
350: hkn0706:737475:737475 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
 42: hkn0414:1966704:1966704 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
360: hkn0710:340644:340644 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
121: hkn0507:3172216:3172216 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
121: hkn0507:3172216:3172216 [1] NCCL INFO Using network IBext
219: hkn0601:102808:102808 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
219: hkn0601:102808:102808 [3] NCCL INFO P2P plugin IBext
218: hkn0601:102824:102824 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
122: hkn0507:3172208:3172208 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
122: hkn0507:3172208:3172208 [2] NCCL INFO Using network IBext
349: hkn0706:737463:737463 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
216: hkn0601:102816:102816 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
216: hkn0601:102816:102816 [0] NCCL INFO P2P plugin IBext
414: hkn0724:1701124:1701124 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
414: hkn0724:1701124:1701124 [2] NCCL INFO P2P plugin IBext
351: hkn0706:737447:737447 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
351: hkn0706:737447:737447 [3] NCCL INFO P2P plugin IBext
313: hkn0631:1006972:1006972 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
348: hkn0706:737455:737455 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
315: hkn0631:1006960:1006960 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
313: hkn0631:1006972:1006972 [1] NCCL INFO Using network IBext
315: hkn0631:1006960:1006960 [3] NCCL INFO Using network IBext
338: hkn0703:726147:726147 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
339: hkn0703:726146:726146 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
343: hkn0704:777170:777170 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
 41: hkn0414:1966724:1966724 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 41: hkn0414:1966724:1966724 [1] NCCL INFO P2P plugin IBext
350: hkn0706:737475:737475 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
350: hkn0706:737475:737475 [2] NCCL INFO P2P plugin IBext
360: hkn0710:340644:340644 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
360: hkn0710:340644:340644 [0] NCCL INFO P2P plugin IBext
 40: hkn0414:1966696:1966696 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 40: hkn0414:1966696:1966696 [0] NCCL INFO P2P plugin IBext
217: hkn0601:102836:102836 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
 42: hkn0414:1966704:1966704 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 42: hkn0414:1966704:1966704 [2] NCCL INFO P2P plugin IBext
218: hkn0601:102824:102824 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
218: hkn0601:102824:102824 [2] NCCL INFO P2P plugin IBext
340: hkn0704:777158:777158 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
414: hkn0724:1701124:1701124 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
414: hkn0724:1701124:1701124 [2] NCCL INFO Using network IBext
349: hkn0706:737463:737463 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
349: hkn0706:737463:737463 [1] NCCL INFO P2P plugin IBext
314: hkn0631:1006951:1006951 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
314: hkn0631:1006951:1006951 [2] NCCL INFO Using network IBext
312: hkn0631:1006952:1006952 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
312: hkn0631:1006952:1006952 [0] NCCL INFO Using network IBext
216: hkn0601:102816:102816 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
216: hkn0601:102816:102816 [0] NCCL INFO Using network IBext
362: hkn0710:340630:340630 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
362: hkn0710:340630:340630 [2] NCCL INFO Using network IBext
188: hkn0528:1286855:1286855 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
360: hkn0710:340644:340644 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
360: hkn0710:340644:340644 [0] NCCL INFO Using network IBext
348: hkn0706:737455:737455 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
348: hkn0706:737455:737455 [0] NCCL INFO P2P plugin IBext
338: hkn0703:726147:726147 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
338: hkn0703:726147:726147 [2] NCCL INFO P2P plugin IBext
218: hkn0601:102824:102824 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
218: hkn0601:102824:102824 [2] NCCL INFO Using network IBext
343: hkn0704:777170:777170 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
343: hkn0704:777170:777170 [3] NCCL INFO P2P plugin IBext
339: hkn0703:726146:726146 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
339: hkn0703:726146:726146 [3] NCCL INFO P2P plugin IBext
350: hkn0706:737475:737475 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
350: hkn0706:737475:737475 [2] NCCL INFO Using network IBext
 43: hkn0414:1966712:1966712 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 43: hkn0414:1966712:1966712 [3] NCCL INFO Using network IBext
 42: hkn0414:1966704:1966704 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 40: hkn0414:1966696:1966696 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 42: hkn0414:1966704:1966704 [2] NCCL INFO Using network IBext
 40: hkn0414:1966696:1966696 [0] NCCL INFO Using network IBext
 41: hkn0414:1966724:1966724 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
342: hkn0704:777150:777150 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
 41: hkn0414:1966724:1966724 [1] NCCL INFO Using network IBext
217: hkn0601:102836:102836 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
217: hkn0601:102836:102836 [1] NCCL INFO P2P plugin IBext
341: hkn0704:777142:777142 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
219: hkn0601:102808:102808 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
219: hkn0601:102808:102808 [3] NCCL INFO Using network IBext
349: hkn0706:737463:737463 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
349: hkn0706:737463:737463 [1] NCCL INFO Using network IBext
104: hkn0503:2884789:2884789 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
191: hkn0528:1286875:1286875 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
340: hkn0704:777158:777158 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
340: hkn0704:777158:777158 [0] NCCL INFO P2P plugin IBext
337: hkn0703:726148:726148 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
336: hkn0703:726160:726160 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
337: hkn0703:726148:726148 [1] NCCL INFO Using network IBext
336: hkn0703:726160:726160 [0] NCCL INFO Using network IBext
190: hkn0528:1286863:1286863 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
348: hkn0706:737455:737455 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
348: hkn0706:737455:737455 [0] NCCL INFO Using network IBext
189: hkn0528:1286847:1286847 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
338: hkn0703:726147:726147 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
338: hkn0703:726147:726147 [2] NCCL INFO Using network IBext
339: hkn0703:726146:726146 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
339: hkn0703:726146:726146 [3] NCCL INFO Using network IBext
183: hkn0526:1413553:1413553 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
351: hkn0706:737447:737447 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
351: hkn0706:737447:737447 [3] NCCL INFO Using network IBext
107: hkn0503:2884797:2884797 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
105: hkn0503:2884817:2884817 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
188: hkn0528:1286855:1286855 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
188: hkn0528:1286855:1286855 [0] NCCL INFO P2P plugin IBext
217: hkn0601:102836:102836 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
217: hkn0601:102836:102836 [1] NCCL INFO Using network IBext
266: hkn0615:399419:399419 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
181: hkn0526:1413569:1413569 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
342: hkn0704:777150:777150 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
342: hkn0704:777150:777150 [2] NCCL INFO P2P plugin IBext
341: hkn0704:777142:777142 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
341: hkn0704:777142:777142 [1] NCCL INFO P2P plugin IBext
340: hkn0704:777158:777158 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
340: hkn0704:777158:777158 [0] NCCL INFO Using network IBext
191: hkn0528:1286875:1286875 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
191: hkn0528:1286875:1286875 [3] NCCL INFO P2P plugin IBext
180: hkn0526:1413561:1413561 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
182: hkn0526:1413581:1413581 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
190: hkn0528:1286863:1286863 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
190: hkn0528:1286863:1286863 [2] NCCL INFO P2P plugin IBext
104: hkn0503:2884789:2884789 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
104: hkn0503:2884789:2884789 [0] NCCL INFO P2P plugin IBext
106: hkn0503:2884805:2884805 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
189: hkn0528:1286847:1286847 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
189: hkn0528:1286847:1286847 [1] NCCL INFO P2P plugin IBext
183: hkn0526:1413553:1413553 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
183: hkn0526:1413553:1413553 [3] NCCL INFO P2P plugin IBext
342: hkn0704:777150:777150 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
107: hkn0503:2884797:2884797 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
107: hkn0503:2884797:2884797 [3] NCCL INFO P2P plugin IBext
342: hkn0704:777150:777150 [2] NCCL INFO Using network IBext
105: hkn0503:2884817:2884817 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
105: hkn0503:2884817:2884817 [1] NCCL INFO P2P plugin IBext
341: hkn0704:777142:777142 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
341: hkn0704:777142:777142 [1] NCCL INFO Using network IBext
343: hkn0704:777170:777170 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
343: hkn0704:777170:777170 [3] NCCL INFO Using network IBext
266: hkn0615:399419:399419 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
266: hkn0615:399419:399419 [2] NCCL INFO P2P plugin IBext
181: hkn0526:1413569:1413569 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
181: hkn0526:1413569:1413569 [1] NCCL INFO P2P plugin IBext
167: hkn0521:1182990:1182990 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
180: hkn0526:1413561:1413561 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
180: hkn0526:1413561:1413561 [0] NCCL INFO P2P plugin IBext
363: hkn0710:340631:340631 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
267: hkn0615:399435:399435 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
189: hkn0528:1286847:1286847 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
189: hkn0528:1286847:1286847 [1] NCCL INFO Using network IBext
190: hkn0528:1286863:1286863 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
190: hkn0528:1286863:1286863 [2] NCCL INFO Using network IBext
182: hkn0526:1413581:1413581 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
182: hkn0526:1413581:1413581 [2] NCCL INFO P2P plugin IBext
191: hkn0528:1286875:1286875 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
191: hkn0528:1286875:1286875 [3] NCCL INFO Using network IBext
264: hkn0615:399427:399427 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
106: hkn0503:2884805:2884805 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
106: hkn0503:2884805:2884805 [2] NCCL INFO P2P plugin IBext
105: hkn0503:2884817:2884817 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
105: hkn0503:2884817:2884817 [1] NCCL INFO Using network IBext
107: hkn0503:2884797:2884797 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
107: hkn0503:2884797:2884797 [3] NCCL INFO Using network IBext
265: hkn0615:399447:399447 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
361: hkn0710:340632:340632 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
164: hkn0521:1182978:1182978 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
188: hkn0528:1286855:1286855 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
188: hkn0528:1286855:1286855 [0] NCCL INFO Using network IBext
181: hkn0526:1413569:1413569 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
181: hkn0526:1413569:1413569 [1] NCCL INFO Using network IBext
180: hkn0526:1413561:1413561 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
180: hkn0526:1413561:1413561 [0] NCCL INFO Using network IBext
 36: hkn0413:2351818:2351818 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
182: hkn0526:1413581:1413581 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
182: hkn0526:1413581:1413581 [2] NCCL INFO Using network IBext
 66: hkn0421:2163516:2163516 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
167: hkn0521:1182990:1182990 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
167: hkn0521:1182990:1182990 [3] NCCL INFO P2P plugin IBext
106: hkn0503:2884805:2884805 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
106: hkn0503:2884805:2884805 [2] NCCL INFO Using network IBext
363: hkn0710:340631:340631 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
363: hkn0710:340631:340631 [3] NCCL INFO P2P plugin IBext
267: hkn0615:399435:399435 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
267: hkn0615:399435:399435 [3] NCCL INFO P2P plugin IBext
 38: hkn0413:2351846:2351846 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
264: hkn0615:399427:399427 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
264: hkn0615:399427:399427 [0] NCCL INFO P2P plugin IBext
104: hkn0503:2884789:2884789 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
104: hkn0503:2884789:2884789 [0] NCCL INFO Using network IBext
157: hkn0516:2901164:2901164 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 67: hkn0421:2163500:2163500 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
 65: hkn0421:2163528:2163528 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
183: hkn0526:1413553:1413553 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
183: hkn0526:1413553:1413553 [3] NCCL INFO Using network IBext
159: hkn0516:2901136:2901136 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
361: hkn0710:340632:340632 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
361: hkn0710:340632:340632 [1] NCCL INFO P2P plugin IBext
265: hkn0615:399447:399447 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
265: hkn0615:399447:399447 [1] NCCL INFO P2P plugin IBext
164: hkn0521:1182978:1182978 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
164: hkn0521:1182978:1182978 [0] NCCL INFO P2P plugin IBext
363: hkn0710:340631:340631 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
363: hkn0710:340631:340631 [3] NCCL INFO Using network IBext
 73: hkn0423:1689969:1689969 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 64: hkn0421:2163508:2163508 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
 36: hkn0413:2351818:2351818 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 36: hkn0413:2351818:2351818 [0] NCCL INFO P2P plugin IBext
485: hkn0808:955879:955879 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
 37: hkn0413:2351826:2351826 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
266: hkn0615:399419:399419 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
266: hkn0615:399419:399419 [2] NCCL INFO Using network IBext
267: hkn0615:399435:399435 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
264: hkn0615:399427:399427 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
267: hkn0615:399435:399435 [3] NCCL INFO Using network IBext
264: hkn0615:399427:399427 [0] NCCL INFO Using network IBext
 66: hkn0421:2163516:2163516 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 66: hkn0421:2163516:2163516 [2] NCCL INFO P2P plugin IBext
487: hkn0808:955859:955859 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
 38: hkn0413:2351846:2351846 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 38: hkn0413:2351846:2351846 [2] NCCL INFO P2P plugin IBext
486: hkn0808:955867:955867 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
361: hkn0710:340632:340632 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
361: hkn0710:340632:340632 [1] NCCL INFO Using network IBext
265: hkn0615:399447:399447 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
265: hkn0615:399447:399447 [1] NCCL INFO Using network IBext
156: hkn0516:2901152:2901152 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
157: hkn0516:2901164:2901164 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
157: hkn0516:2901164:2901164 [1] NCCL INFO P2P plugin IBext
 67: hkn0421:2163500:2163500 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 67: hkn0421:2163500:2163500 [3] NCCL INFO P2P plugin IBext
159: hkn0516:2901136:2901136 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
159: hkn0516:2901136:2901136 [3] NCCL INFO P2P plugin IBext
 65: hkn0421:2163528:2163528 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 65: hkn0421:2163528:2163528 [1] NCCL INFO P2P plugin IBext
164: hkn0521:1182978:1182978 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
164: hkn0521:1182978:1182978 [0] NCCL INFO Using network IBext
158: hkn0516:2901144:2901144 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 64: hkn0421:2163508:2163508 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 64: hkn0421:2163508:2163508 [0] NCCL INFO P2P plugin IBext
 73: hkn0423:1689969:1689969 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 73: hkn0423:1689969:1689969 [1] NCCL INFO P2P plugin IBext
485: hkn0808:955879:955879 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
485: hkn0808:955879:955879 [1] NCCL INFO P2P plugin IBext
 37: hkn0413:2351826:2351826 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 37: hkn0413:2351826:2351826 [1] NCCL INFO P2P plugin IBext
167: hkn0521:1182990:1182990 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
167: hkn0521:1182990:1182990 [3] NCCL INFO Using network IBext
 39: hkn0413:2351834:2351834 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
 38: hkn0413:2351846:2351846 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 38: hkn0413:2351846:2351846 [2] NCCL INFO Using network IBext
487: hkn0808:955859:955859 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
487: hkn0808:955859:955859 [3] NCCL INFO P2P plugin IBext
486: hkn0808:955867:955867 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
486: hkn0808:955867:955867 [2] NCCL INFO P2P plugin IBext
484: hkn0808:955851:955851 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
156: hkn0516:2901152:2901152 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
156: hkn0516:2901152:2901152 [0] NCCL INFO P2P plugin IBext
 65: hkn0421:2163528:2163528 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 67: hkn0421:2163500:2163500 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 64: hkn0421:2163508:2163508 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 65: hkn0421:2163528:2163528 [1] NCCL INFO Using network IBext
 67: hkn0421:2163500:2163500 [3] NCCL INFO Using network IBext
 64: hkn0421:2163508:2163508 [0] NCCL INFO Using network IBext
 37: hkn0413:2351826:2351826 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 37: hkn0413:2351826:2351826 [1] NCCL INFO Using network IBext
 15: hkn0407:1801457:1801457 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
158: hkn0516:2901144:2901144 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
158: hkn0516:2901144:2901144 [2] NCCL INFO P2P plugin IBext
 36: hkn0413:2351818:2351818 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 36: hkn0413:2351818:2351818 [0] NCCL INFO Using network IBext
 12: hkn0407:1801469:1801469 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 39: hkn0413:2351834:2351834 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 39: hkn0413:2351834:2351834 [3] NCCL INFO P2P plugin IBext
487: hkn0808:955859:955859 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
487: hkn0808:955859:955859 [3] NCCL INFO Using network IBext
486: hkn0808:955867:955867 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
486: hkn0808:955867:955867 [2] NCCL INFO Using network IBext
484: hkn0808:955851:955851 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
484: hkn0808:955851:955851 [0] NCCL INFO P2P plugin IBext
 66: hkn0421:2163516:2163516 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 66: hkn0421:2163516:2163516 [2] NCCL INFO Using network IBext
156: hkn0516:2901152:2901152 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
156: hkn0516:2901152:2901152 [0] NCCL INFO Using network IBext
158: hkn0516:2901144:2901144 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
158: hkn0516:2901144:2901144 [2] NCCL INFO Using network IBext
159: hkn0516:2901136:2901136 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
159: hkn0516:2901136:2901136 [3] NCCL INFO Using network IBext
 15: hkn0407:1801457:1801457 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 15: hkn0407:1801457:1801457 [3] NCCL INFO P2P plugin IBext
 74: hkn0423:1689961:1689961 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
157: hkn0516:2901164:2901164 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
157: hkn0516:2901164:2901164 [1] NCCL INFO Using network IBext
177: hkn0525:971991:971991 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
179: hkn0525:971983:971983 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
 39: hkn0413:2351834:2351834 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 39: hkn0413:2351834:2351834 [3] NCCL INFO Using network IBext
 92: hkn0428:652537:652537 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
485: hkn0808:955879:955879 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
485: hkn0808:955879:955879 [1] NCCL INFO Using network IBext
178: hkn0525:972003:972003 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
 12: hkn0407:1801469:1801469 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 12: hkn0407:1801469:1801469 [0] NCCL INFO P2P plugin IBext
484: hkn0808:955851:955851 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
484: hkn0808:955851:955851 [0] NCCL INFO Using network IBext
176: hkn0525:971975:971975 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
 73: hkn0423:1689969:1689969 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 73: hkn0423:1689969:1689969 [1] NCCL INFO Using network IBext
 14: hkn0407:1801449:1801449 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 17: hkn0408:2875824:2875824 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
241: hkn0607:889514:889514 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
 75: hkn0423:1689977:1689977 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
300: hkn0628:656995:656995 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
166: hkn0521:1182970:1182970 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
303: hkn0628:656987:656987 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
 74: hkn0423:1689961:1689961 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 74: hkn0423:1689961:1689961 [2] NCCL INFO P2P plugin IBext
302: hkn0628:656986:656986 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
177: hkn0525:971991:971991 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
177: hkn0525:971991:971991 [1] NCCL INFO P2P plugin IBext
 72: hkn0423:1689989:1689989 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
 92: hkn0428:652537:652537 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 92: hkn0428:652537:652537 [0] NCCL INFO P2P plugin IBext
179: hkn0525:971983:971983 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
179: hkn0525:971983:971983 [3] NCCL INFO P2P plugin IBext
 12: hkn0407:1801469:1801469 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 12: hkn0407:1801469:1801469 [0] NCCL INFO Using network IBext
178: hkn0525:972003:972003 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
178: hkn0525:972003:972003 [2] NCCL INFO P2P plugin IBext
176: hkn0525:971975:971975 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
176: hkn0525:971975:971975 [0] NCCL INFO P2P plugin IBext
 23: hkn0409:2570858:2570858 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
 14: hkn0407:1801449:1801449 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 14: hkn0407:1801449:1801449 [2] NCCL INFO P2P plugin IBext
 18: hkn0408:2875808:2875808 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
152: hkn0515:2881970:2881970 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
 13: hkn0407:1801441:1801441 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
153: hkn0515:2881958:2881958 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
301: hkn0628:657007:657007 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
 17: hkn0408:2875824:2875824 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 17: hkn0408:2875824:2875824 [1] NCCL INFO P2P plugin IBext
240: hkn0607:889534:889534 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
154: hkn0515:2881950:2881950 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
503: hkn0814:660981:660981 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
165: hkn0521:1182962:1182962 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
500: hkn0814:660997:660997 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
 19: hkn0408:2875816:2875816 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
241: hkn0607:889514:889514 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
241: hkn0607:889514:889514 [1] NCCL INFO P2P plugin IBext
 22: hkn0409:2570866:2570866 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
 75: hkn0423:1689977:1689977 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 75: hkn0423:1689977:1689977 [3] NCCL INFO P2P plugin IBext
 74: hkn0423:1689961:1689961 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 74: hkn0423:1689961:1689961 [2] NCCL INFO Using network IBext
 95: hkn0428:652509:652509 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
243: hkn0607:889506:889506 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
 94: hkn0428:652525:652525 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
 93: hkn0428:652517:652517 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
 15: hkn0407:1801457:1801457 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 15: hkn0407:1801457:1801457 [3] NCCL INFO Using network IBext
193: hkn0529:1526023:1526023 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
155: hkn0515:2881942:2881942 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
300: hkn0628:656995:656995 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
300: hkn0628:656995:656995 [0] NCCL INFO P2P plugin IBext
303: hkn0628:656987:656987 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
303: hkn0628:656987:656987 [3] NCCL INFO P2P plugin IBext
 14: hkn0407:1801449:1801449 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 14: hkn0407:1801449:1801449 [2] NCCL INFO Using network IBext
 72: hkn0423:1689989:1689989 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 72: hkn0423:1689989:1689989 [0] NCCL INFO P2P plugin IBext
 16: hkn0408:2875836:2875836 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
302: hkn0628:656986:656986 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
302: hkn0628:656986:656986 [2] NCCL INFO P2P plugin IBext
176: hkn0525:971975:971975 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
176: hkn0525:971975:971975 [0] NCCL INFO Using network IBext
178: hkn0525:972003:972003 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
178: hkn0525:972003:972003 [2] NCCL INFO Using network IBext
166: hkn0521:1182970:1182970 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
166: hkn0521:1182970:1182970 [2] NCCL INFO P2P plugin IBext
242: hkn0607:889522:889522 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
 23: hkn0409:2570858:2570858 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 23: hkn0409:2570858:2570858 [3] NCCL INFO P2P plugin IBext
 75: hkn0423:1689977:1689977 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 75: hkn0423:1689977:1689977 [3] NCCL INFO Using network IBext
 18: hkn0408:2875808:2875808 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 18: hkn0408:2875808:2875808 [2] NCCL INFO P2P plugin IBext
 13: hkn0407:1801441:1801441 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 13: hkn0407:1801441:1801441 [1] NCCL INFO P2P plugin IBext
301: hkn0628:657007:657007 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
301: hkn0628:657007:657007 [1] NCCL INFO P2P plugin IBext
240: hkn0607:889534:889534 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
240: hkn0607:889534:889534 [0] NCCL INFO P2P plugin IBext
153: hkn0515:2881958:2881958 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
153: hkn0515:2881958:2881958 [1] NCCL INFO P2P plugin IBext
503: hkn0814:660981:660981 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
503: hkn0814:660981:660981 [3] NCCL INFO P2P plugin IBext
500: hkn0814:660997:660997 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
500: hkn0814:660997:660997 [0] NCCL INFO P2P plugin IBext
154: hkn0515:2881950:2881950 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
154: hkn0515:2881950:2881950 [2] NCCL INFO P2P plugin IBext
 19: hkn0408:2875816:2875816 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 19: hkn0408:2875816:2875816 [3] NCCL INFO P2P plugin IBext
152: hkn0515:2881970:2881970 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
152: hkn0515:2881970:2881970 [0] NCCL INFO P2P plugin IBext
 22: hkn0409:2570866:2570866 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 22: hkn0409:2570866:2570866 [2] NCCL INFO P2P plugin IBext
 72: hkn0423:1689989:1689989 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 72: hkn0423:1689989:1689989 [0] NCCL INFO Using network IBext
243: hkn0607:889506:889506 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
243: hkn0607:889506:889506 [3] NCCL INFO P2P plugin IBext
165: hkn0521:1182962:1182962 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
165: hkn0521:1182962:1182962 [1] NCCL INFO P2P plugin IBext
 95: hkn0428:652509:652509 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 95: hkn0428:652509:652509 [3] NCCL INFO P2P plugin IBext
 94: hkn0428:652525:652525 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 94: hkn0428:652525:652525 [2] NCCL INFO P2P plugin IBext
 93: hkn0428:652517:652517 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 20: hkn0409:2570878:2570878 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
 93: hkn0428:652517:652517 [1] NCCL INFO P2P plugin IBext
 21: hkn0409:2570850:2570850 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
193: hkn0529:1526023:1526023 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
193: hkn0529:1526023:1526023 [1] NCCL INFO P2P plugin IBext
155: hkn0515:2881942:2881942 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
155: hkn0515:2881942:2881942 [3] NCCL INFO P2P plugin IBext
262: hkn0613:887824:887824 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
 16: hkn0408:2875836:2875836 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 16: hkn0408:2875836:2875836 [0] NCCL INFO P2P plugin IBext
177: hkn0525:971991:971991 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
177: hkn0525:971991:971991 [1] NCCL INFO Using network IBext
179: hkn0525:971983:971983 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
179: hkn0525:971983:971983 [3] NCCL INFO Using network IBext
 13: hkn0407:1801441:1801441 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 13: hkn0407:1801441:1801441 [1] NCCL INFO Using network IBext
260: hkn0613:887844:887844 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
242: hkn0607:889522:889522 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
242: hkn0607:889522:889522 [2] NCCL INFO P2P plugin IBext
166: hkn0521:1182970:1182970 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
166: hkn0521:1182970:1182970 [2] NCCL INFO Using network IBext
301: hkn0628:657007:657007 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
301: hkn0628:657007:657007 [1] NCCL INFO Using network IBext
240: hkn0607:889534:889534 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
240: hkn0607:889534:889534 [0] NCCL INFO Using network IBext
 92: hkn0428:652537:652537 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 92: hkn0428:652537:652537 [0] NCCL INFO Using network IBext
 18: hkn0408:2875808:2875808 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 18: hkn0408:2875808:2875808 [2] NCCL INFO Using network IBext
 19: hkn0408:2875816:2875816 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 19: hkn0408:2875816:2875816 [3] NCCL INFO Using network IBext
243: hkn0607:889506:889506 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
243: hkn0607:889506:889506 [3] NCCL INFO Using network IBext
 94: hkn0428:652525:652525 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 94: hkn0428:652525:652525 [2] NCCL INFO Using network IBext
 17: hkn0408:2875824:2875824 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 17: hkn0408:2875824:2875824 [1] NCCL INFO Using network IBext
 93: hkn0428:652517:652517 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 93: hkn0428:652517:652517 [1] NCCL INFO Using network IBext
 95: hkn0428:652509:652509 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 95: hkn0428:652509:652509 [3] NCCL INFO Using network IBext
278: hkn0621:1976647:1976647 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
192: hkn0529:1525995:1525995 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
 22: hkn0409:2570866:2570866 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 22: hkn0409:2570866:2570866 [2] NCCL INFO Using network IBext
263: hkn0613:887832:887832 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
241: hkn0607:889514:889514 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
 16: hkn0408:2875836:2875836 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
241: hkn0607:889514:889514 [1] NCCL INFO Using network IBext
 16: hkn0408:2875836:2875836 [0] NCCL INFO Using network IBext
165: hkn0521:1182962:1182962 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
165: hkn0521:1182962:1182962 [1] NCCL INFO Using network IBext
276: hkn0621:1976635:1976635 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
 20: hkn0409:2570878:2570878 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 20: hkn0409:2570878:2570878 [0] NCCL INFO P2P plugin IBext
 21: hkn0409:2570850:2570850 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 21: hkn0409:2570850:2570850 [1] NCCL INFO P2P plugin IBext
242: hkn0607:889522:889522 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
242: hkn0607:889522:889522 [2] NCCL INFO Using network IBext
194: hkn0529:1526011:1526011 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
155: hkn0515:2881942:2881942 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
155: hkn0515:2881942:2881942 [3] NCCL INFO Using network IBext
262: hkn0613:887824:887824 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
262: hkn0613:887824:887824 [2] NCCL INFO P2P plugin IBext
261: hkn0613:887816:887816 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
473: hkn0805:1097263:1097263 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
195: hkn0529:1526003:1526003 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
302: hkn0628:656986:656986 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
302: hkn0628:656986:656986 [2] NCCL INFO Using network IBext
300: hkn0628:656995:656995 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
300: hkn0628:656995:656995 [0] NCCL INFO Using network IBext
303: hkn0628:656987:656987 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
303: hkn0628:656987:656987 [3] NCCL INFO Using network IBext
260: hkn0613:887844:887844 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
260: hkn0613:887844:887844 [0] NCCL INFO P2P plugin IBext
233: hkn0605:697262:697262 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
234: hkn0605:697234:697234 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
235: hkn0605:697250:697250 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
279: hkn0621:1976627:1976627 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
 23: hkn0409:2570858:2570858 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 23: hkn0409:2570858:2570858 [3] NCCL INFO Using network IBext
387: hkn0716:93654:93654 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
 20: hkn0409:2570878:2570878 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 20: hkn0409:2570878:2570878 [0] NCCL INFO Using network IBext
 21: hkn0409:2570850:2570850 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 21: hkn0409:2570850:2570850 [1] NCCL INFO Using network IBext
278: hkn0621:1976647:1976647 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
278: hkn0621:1976647:1976647 [2] NCCL INFO P2P plugin IBext
192: hkn0529:1525995:1525995 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
192: hkn0529:1525995:1525995 [0] NCCL INFO P2P plugin IBext
263: hkn0613:887832:887832 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
263: hkn0613:887832:887832 [3] NCCL INFO P2P plugin IBext
154: hkn0515:2881950:2881950 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
154: hkn0515:2881950:2881950 [2] NCCL INFO Using network IBext
232: hkn0605:697242:697242 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
152: hkn0515:2881970:2881970 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
152: hkn0515:2881970:2881970 [0] NCCL INFO Using network IBext
153: hkn0515:2881958:2881958 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
153: hkn0515:2881958:2881958 [1] NCCL INFO Using network IBext
276: hkn0621:1976635:1976635 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
276: hkn0621:1976635:1976635 [0] NCCL INFO P2P plugin IBext
384: hkn0716:93645:93645 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
277: hkn0621:1976619:1976619 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
500: hkn0814:660997:660997 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
503: hkn0814:660981:660981 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
500: hkn0814:660997:660997 [0] NCCL INFO Using network IBext
503: hkn0814:660981:660981 [3] NCCL INFO Using network IBext
472: hkn0805:1097255:1097255 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
194: hkn0529:1526011:1526011 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
194: hkn0529:1526011:1526011 [2] NCCL INFO P2P plugin IBext
475: hkn0805:1097283:1097283 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
385: hkn0716:93646:93646 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
261: hkn0613:887816:887816 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
261: hkn0613:887816:887816 [1] NCCL INFO P2P plugin IBext
473: hkn0805:1097263:1097263 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
473: hkn0805:1097263:1097263 [1] NCCL INFO P2P plugin IBext
195: hkn0529:1526003:1526003 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
195: hkn0529:1526003:1526003 [3] NCCL INFO P2P plugin IBext
260: hkn0613:887844:887844 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
260: hkn0613:887844:887844 [0] NCCL INFO Using network IBext
233: hkn0605:697262:697262 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
233: hkn0605:697262:697262 [1] NCCL INFO P2P plugin IBext
234: hkn0605:697234:697234 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
234: hkn0605:697234:697234 [2] NCCL INFO P2P plugin IBext
193: hkn0529:1526023:1526023 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
193: hkn0529:1526023:1526023 [1] NCCL INFO Using network IBext
235: hkn0605:697250:697250 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
235: hkn0605:697250:697250 [3] NCCL INFO P2P plugin IBext
192: hkn0529:1525995:1525995 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
192: hkn0529:1525995:1525995 [0] NCCL INFO Using network IBext
263: hkn0613:887832:887832 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
263: hkn0613:887832:887832 [3] NCCL INFO Using network IBext
279: hkn0621:1976627:1976627 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
279: hkn0621:1976627:1976627 [3] NCCL INFO P2P plugin IBext
386: hkn0716:93666:93666 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
474: hkn0805:1097271:1097271 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
501: hkn0814:661009:661009 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
387: hkn0716:93654:93654 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
387: hkn0716:93654:93654 [3] NCCL INFO P2P plugin IBext
194: hkn0529:1526011:1526011 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
194: hkn0529:1526011:1526011 [2] NCCL INFO Using network IBext
232: hkn0605:697242:697242 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
232: hkn0605:697242:697242 [0] NCCL INFO P2P plugin IBext
261: hkn0613:887816:887816 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
261: hkn0613:887816:887816 [1] NCCL INFO Using network IBext
276: hkn0621:1976635:1976635 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
276: hkn0621:1976635:1976635 [0] NCCL INFO Using network IBext
195: hkn0529:1526003:1526003 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
195: hkn0529:1526003:1526003 [3] NCCL INFO Using network IBext
277: hkn0621:1976619:1976619 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
277: hkn0621:1976619:1976619 [1] NCCL INFO P2P plugin IBext
384: hkn0716:93645:93645 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
384: hkn0716:93645:93645 [0] NCCL INFO P2P plugin IBext
472: hkn0805:1097255:1097255 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
472: hkn0805:1097255:1097255 [0] NCCL INFO P2P plugin IBext
279: hkn0621:1976627:1976627 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
279: hkn0621:1976627:1976627 [3] NCCL INFO Using network IBext
262: hkn0613:887824:887824 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
262: hkn0613:887824:887824 [2] NCCL INFO Using network IBext
475: hkn0805:1097283:1097283 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
475: hkn0805:1097283:1097283 [3] NCCL INFO P2P plugin IBext
385: hkn0716:93646:93646 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
385: hkn0716:93646:93646 [1] NCCL INFO P2P plugin IBext
502: hkn0814:660989:660989 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
333: hkn0636:1639334:1639334 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
393: hkn0718:3902174:3902174 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
501: hkn0814:661009:661009 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
501: hkn0814:661009:661009 [1] NCCL INFO P2P plugin IBext
474: hkn0805:1097271:1097271 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
474: hkn0805:1097271:1097271 [2] NCCL INFO P2P plugin IBext
386: hkn0716:93666:93666 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
386: hkn0716:93666:93666 [2] NCCL INFO P2P plugin IBext
277: hkn0621:1976619:1976619 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
277: hkn0621:1976619:1976619 [1] NCCL INFO Using network IBext
278: hkn0621:1976647:1976647 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
278: hkn0621:1976647:1976647 [2] NCCL INFO Using network IBext
232: hkn0605:697242:697242 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
232: hkn0605:697242:697242 [0] NCCL INFO Using network IBext
384: hkn0716:93645:93645 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
384: hkn0716:93645:93645 [0] NCCL INFO Using network IBext
385: hkn0716:93646:93646 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
385: hkn0716:93646:93646 [1] NCCL INFO Using network IBext
475: hkn0805:1097283:1097283 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
475: hkn0805:1097283:1097283 [3] NCCL INFO Using network IBext
472: hkn0805:1097255:1097255 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
472: hkn0805:1097255:1097255 [0] NCCL INFO Using network IBext
395: hkn0718:3902182:3902182 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
392: hkn0718:3902194:3902194 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
394: hkn0718:3902173:3902173 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
474: hkn0805:1097271:1097271 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
501: hkn0814:661009:661009 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
474: hkn0805:1097271:1097271 [2] NCCL INFO Using network IBext
501: hkn0814:661009:661009 [1] NCCL INFO Using network IBext
502: hkn0814:660989:660989 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
502: hkn0814:660989:660989 [2] NCCL INFO P2P plugin IBext
386: hkn0716:93666:93666 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
386: hkn0716:93666:93666 [2] NCCL INFO Using network IBext
473: hkn0805:1097263:1097263 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
473: hkn0805:1097263:1097263 [1] NCCL INFO Using network IBext
410: hkn0723:192937:192937 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
393: hkn0718:3902174:3902174 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
393: hkn0718:3902174:3902174 [1] NCCL INFO P2P plugin IBext
333: hkn0636:1639334:1639334 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
333: hkn0636:1639334:1639334 [1] NCCL INFO P2P plugin IBext
233: hkn0605:697262:697262 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
233: hkn0605:697262:697262 [1] NCCL INFO Using network IBext
234: hkn0605:697234:697234 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
235: hkn0605:697250:697250 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
234: hkn0605:697234:697234 [2] NCCL INFO Using network IBext
235: hkn0605:697250:697250 [3] NCCL INFO Using network IBext
334: hkn0636:1639350:1639350 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
411: hkn0723:192909:192909 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
387: hkn0716:93654:93654 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
387: hkn0716:93654:93654 [3] NCCL INFO Using network IBext
409: hkn0723:192925:192925 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
502: hkn0814:660989:660989 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
502: hkn0814:660989:660989 [2] NCCL INFO Using network IBext
408: hkn0723:192917:192917 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
395: hkn0718:3902182:3902182 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
395: hkn0718:3902182:3902182 [3] NCCL INFO P2P plugin IBext
392: hkn0718:3902194:3902194 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
392: hkn0718:3902194:3902194 [0] NCCL INFO P2P plugin IBext
394: hkn0718:3902173:3902173 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
394: hkn0718:3902173:3902173 [2] NCCL INFO P2P plugin IBext
332: hkn0636:1639342:1639342 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
410: hkn0723:192937:192937 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
410: hkn0723:192937:192937 [2] NCCL INFO P2P plugin IBext
334: hkn0636:1639350:1639350 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
334: hkn0636:1639350:1639350 [2] NCCL INFO P2P plugin IBext
411: hkn0723:192909:192909 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
411: hkn0723:192909:192909 [3] NCCL INFO P2P plugin IBext
409: hkn0723:192925:192925 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
409: hkn0723:192925:192925 [1] NCCL INFO P2P plugin IBext
394: hkn0718:3902173:3902173 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
395: hkn0718:3902182:3902182 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
392: hkn0718:3902194:3902194 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
394: hkn0718:3902173:3902173 [2] NCCL INFO Using network IBext
395: hkn0718:3902182:3902182 [3] NCCL INFO Using network IBext
392: hkn0718:3902194:3902194 [0] NCCL INFO Using network IBext
408: hkn0723:192917:192917 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
408: hkn0723:192917:192917 [0] NCCL INFO P2P plugin IBext
332: hkn0636:1639342:1639342 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
332: hkn0636:1639342:1639342 [0] NCCL INFO P2P plugin IBext
449: hkn0734:1141728:1141728 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
393: hkn0718:3902174:3902174 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
393: hkn0718:3902174:3902174 [1] NCCL INFO Using network IBext
334: hkn0636:1639350:1639350 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
334: hkn0636:1639350:1639350 [2] NCCL INFO Using network IBext
411: hkn0723:192909:192909 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
411: hkn0723:192909:192909 [3] NCCL INFO Using network IBext
409: hkn0723:192925:192925 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
409: hkn0723:192925:192925 [1] NCCL INFO Using network IBext
333: hkn0636:1639334:1639334 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
333: hkn0636:1639334:1639334 [1] NCCL INFO Using network IBext
408: hkn0723:192917:192917 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
408: hkn0723:192917:192917 [0] NCCL INFO Using network IBext
293: hkn0626:1283586:1283586 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
450: hkn0734:1141720:1141720 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
451: hkn0734:1141736:1141736 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
332: hkn0636:1639342:1639342 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
332: hkn0636:1639342:1639342 [0] NCCL INFO Using network IBext
244: hkn0608:470923:470923 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
335: hkn0636:1639362:1639362 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
448: hkn0734:1141748:1141748 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
449: hkn0734:1141728:1141728 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
449: hkn0734:1141728:1141728 [1] NCCL INFO P2P plugin IBext
410: hkn0723:192937:192937 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
410: hkn0723:192937:192937 [2] NCCL INFO Using network IBext
246: hkn0608:470915:470915 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
256: hkn0612:902120:902120 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
247: hkn0608:470914:470914 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
293: hkn0626:1283586:1283586 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
293: hkn0626:1283586:1283586 [1] NCCL INFO P2P plugin IBext
245: hkn0608:470935:470935 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
451: hkn0734:1141736:1141736 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
451: hkn0734:1141736:1141736 [3] NCCL INFO P2P plugin IBext
498: hkn0812:678929:678929 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
259: hkn0612:902148:902148 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
335: hkn0636:1639362:1639362 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
335: hkn0636:1639362:1639362 [3] NCCL INFO P2P plugin IBext
244: hkn0608:470923:470923 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
244: hkn0608:470923:470923 [0] NCCL INFO P2P plugin IBext
450: hkn0734:1141720:1141720 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
450: hkn0734:1141720:1141720 [2] NCCL INFO P2P plugin IBext
448: hkn0734:1141748:1141748 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
448: hkn0734:1141748:1141748 [0] NCCL INFO P2P plugin IBext
497: hkn0812:678921:678921 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
257: hkn0612:902128:902128 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
258: hkn0612:902136:902136 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
246: hkn0608:470915:470915 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
246: hkn0608:470915:470915 [2] NCCL INFO P2P plugin IBext
256: hkn0612:902120:902120 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
256: hkn0612:902120:902120 [0] NCCL INFO P2P plugin IBext
335: hkn0636:1639362:1639362 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
335: hkn0636:1639362:1639362 [3] NCCL INFO Using network IBext
247: hkn0608:470914:470914 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
247: hkn0608:470914:470914 [3] NCCL INFO P2P plugin IBext
451: hkn0734:1141736:1141736 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
451: hkn0734:1141736:1141736 [3] NCCL INFO Using network IBext
245: hkn0608:470935:470935 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
245: hkn0608:470935:470935 [1] NCCL INFO P2P plugin IBext
450: hkn0734:1141720:1141720 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
450: hkn0734:1141720:1141720 [2] NCCL INFO Using network IBext
259: hkn0612:902148:902148 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
259: hkn0612:902148:902148 [3] NCCL INFO P2P plugin IBext
498: hkn0812:678929:678929 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
498: hkn0812:678929:678929 [2] NCCL INFO P2P plugin IBext
448: hkn0734:1141748:1141748 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
448: hkn0734:1141748:1141748 [0] NCCL INFO Using network IBext
496: hkn0812:678913:678913 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
499: hkn0812:678941:678941 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
497: hkn0812:678921:678921 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
497: hkn0812:678921:678921 [1] NCCL INFO P2P plugin IBext
449: hkn0734:1141728:1141728 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
449: hkn0734:1141728:1141728 [1] NCCL INFO Using network IBext
257: hkn0612:902128:902128 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
257: hkn0612:902128:902128 [1] NCCL INFO P2P plugin IBext
258: hkn0612:902136:902136 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
258: hkn0612:902136:902136 [2] NCCL INFO P2P plugin IBext
477: hkn0806:1039485:1039485 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
246: hkn0608:470915:470915 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
246: hkn0608:470915:470915 [2] NCCL INFO Using network IBext
479: hkn0806:1039493:1039493 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
247: hkn0608:470914:470914 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
247: hkn0608:470914:470914 [3] NCCL INFO Using network IBext
245: hkn0608:470935:470935 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
245: hkn0608:470935:470935 [1] NCCL INFO Using network IBext
295: hkn0626:1283583:1283583 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
259: hkn0612:902148:902148 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
259: hkn0612:902148:902148 [3] NCCL INFO Using network IBext
478: hkn0806:1039513:1039513 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
496: hkn0812:678913:678913 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
496: hkn0812:678913:678913 [0] NCCL INFO P2P plugin IBext
257: hkn0612:902128:902128 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
258: hkn0612:902136:902136 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
258: hkn0612:902136:902136 [2] NCCL INFO Using network IBext
257: hkn0612:902128:902128 [1] NCCL INFO Using network IBext
244: hkn0608:470923:470923 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
244: hkn0608:470923:470923 [0] NCCL INFO Using network IBext
293: hkn0626:1283586:1283586 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
293: hkn0626:1283586:1283586 [1] NCCL INFO Using network IBext
497: hkn0812:678921:678921 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
497: hkn0812:678921:678921 [1] NCCL INFO Using network IBext
476: hkn0806:1039501:1039501 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
499: hkn0812:678941:678941 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
499: hkn0812:678941:678941 [3] NCCL INFO P2P plugin IBext
292: hkn0626:1283594:1283594 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
294: hkn0626:1283606:1283606 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
477: hkn0806:1039485:1039485 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
477: hkn0806:1039485:1039485 [1] NCCL INFO P2P plugin IBext
479: hkn0806:1039493:1039493 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
479: hkn0806:1039493:1039493 [3] NCCL INFO P2P plugin IBext
256: hkn0612:902120:902120 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
256: hkn0612:902120:902120 [0] NCCL INFO Using network IBext
427: hkn0727:1330957:1330957 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
295: hkn0626:1283583:1283583 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
295: hkn0626:1283583:1283583 [3] NCCL INFO P2P plugin IBext
496: hkn0812:678913:678913 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
496: hkn0812:678913:678913 [0] NCCL INFO Using network IBext
424: hkn0727:1330945:1330945 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
478: hkn0806:1039513:1039513 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
478: hkn0806:1039513:1039513 [2] NCCL INFO P2P plugin IBext
499: hkn0812:678941:678941 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
499: hkn0812:678941:678941 [3] NCCL INFO Using network IBext
498: hkn0812:678929:678929 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
498: hkn0812:678929:678929 [2] NCCL INFO Using network IBext
230: hkn0604:674446:674446 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
476: hkn0806:1039501:1039501 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
476: hkn0806:1039501:1039501 [0] NCCL INFO P2P plugin IBext
292: hkn0626:1283594:1283594 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
292: hkn0626:1283594:1283594 [0] NCCL INFO P2P plugin IBext
228: hkn0604:674438:674438 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
295: hkn0626:1283583:1283583 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
295: hkn0626:1283583:1283583 [3] NCCL INFO Using network IBext
294: hkn0626:1283606:1283606 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
294: hkn0626:1283606:1283606 [2] NCCL INFO P2P plugin IBext
427: hkn0727:1330957:1330957 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
427: hkn0727:1330957:1330957 [3] NCCL INFO P2P plugin IBext
229: hkn0604:674466:674466 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
231: hkn0604:674454:674454 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
478: hkn0806:1039513:1039513 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
478: hkn0806:1039513:1039513 [2] NCCL INFO Using network IBext
425: hkn0727:1330936:1330936 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
424: hkn0727:1330945:1330945 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
424: hkn0727:1330945:1330945 [0] NCCL INFO P2P plugin IBext
114: hkn0505:2288957:2288957 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
476: hkn0806:1039501:1039501 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
476: hkn0806:1039501:1039501 [0] NCCL INFO Using network IBext
113: hkn0505:2288949:2288949 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
292: hkn0626:1283594:1283594 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
292: hkn0626:1283594:1283594 [0] NCCL INFO Using network IBext
112: hkn0505:2288969:2288969 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
354: hkn0707:4005065:4005065 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
230: hkn0604:674446:674446 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
230: hkn0604:674446:674446 [2] NCCL INFO P2P plugin IBext
294: hkn0626:1283606:1283606 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
294: hkn0626:1283606:1283606 [2] NCCL INFO Using network IBext
353: hkn0707:4005073:4005073 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
355: hkn0707:4005093:4005093 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
115: hkn0505:2288941:2288941 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
228: hkn0604:674438:674438 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
228: hkn0604:674438:674438 [0] NCCL INFO P2P plugin IBext
479: hkn0806:1039493:1039493 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
479: hkn0806:1039493:1039493 [3] NCCL INFO Using network IBext
426: hkn0727:1330937:1330937 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
477: hkn0806:1039485:1039485 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
477: hkn0806:1039485:1039485 [1] NCCL INFO Using network IBext
229: hkn0604:674466:674466 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
229: hkn0604:674466:674466 [1] NCCL INFO P2P plugin IBext
425: hkn0727:1330936:1330936 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
425: hkn0727:1330936:1330936 [1] NCCL INFO P2P plugin IBext
424: hkn0727:1330945:1330945 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
231: hkn0604:674454:674454 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
231: hkn0604:674454:674454 [3] NCCL INFO P2P plugin IBext
424: hkn0727:1330945:1330945 [0] NCCL INFO Using network IBext
114: hkn0505:2288957:2288957 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
114: hkn0505:2288957:2288957 [2] NCCL INFO P2P plugin IBext
113: hkn0505:2288949:2288949 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
113: hkn0505:2288949:2288949 [1] NCCL INFO P2P plugin IBext
383: hkn0715:387112:387112 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
112: hkn0505:2288969:2288969 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
112: hkn0505:2288969:2288969 [0] NCCL INFO P2P plugin IBext
352: hkn0707:4005081:4005081 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
354: hkn0707:4005065:4005065 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
354: hkn0707:4005065:4005065 [2] NCCL INFO P2P plugin IBext
366: hkn0711:569042:569042 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
353: hkn0707:4005073:4005073 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
353: hkn0707:4005073:4005073 [1] NCCL INFO P2P plugin IBext
115: hkn0505:2288941:2288941 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
115: hkn0505:2288941:2288941 [3] NCCL INFO P2P plugin IBext
355: hkn0707:4005093:4005093 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
355: hkn0707:4005093:4005093 [3] NCCL INFO P2P plugin IBext
175: hkn0524:1118950:1118950 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
228: hkn0604:674438:674438 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
228: hkn0604:674438:674438 [0] NCCL INFO Using network IBext
367: hkn0711:569054:569054 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
380: hkn0715:387124:387124 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
229: hkn0604:674466:674466 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
231: hkn0604:674454:674454 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
231: hkn0604:674454:674454 [3] NCCL INFO Using network IBext
229: hkn0604:674466:674466 [1] NCCL INFO Using network IBext
425: hkn0727:1330936:1330936 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
425: hkn0727:1330936:1330936 [1] NCCL INFO Using network IBext
174: hkn0524:1118942:1118942 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
427: hkn0727:1330957:1330957 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
427: hkn0727:1330957:1330957 [3] NCCL INFO Using network IBext
 76: hkn0424:2933109:2933109 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
426: hkn0727:1330937:1330937 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
426: hkn0727:1330937:1330937 [2] NCCL INFO P2P plugin IBext
 85: hkn0426:799266:799266 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
400: hkn0720:4181520:4181520 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
382: hkn0715:387104:387104 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
365: hkn0711:569034:569034 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
364: hkn0711:569026:569026 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
112: hkn0505:2288969:2288969 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
112: hkn0505:2288969:2288969 [0] NCCL INFO Using network IBext
115: hkn0505:2288941:2288941 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
115: hkn0505:2288941:2288941 [3] NCCL INFO Using network IBext
383: hkn0715:387112:387112 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
383: hkn0715:387112:387112 [3] NCCL INFO P2P plugin IBext
352: hkn0707:4005081:4005081 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
352: hkn0707:4005081:4005081 [0] NCCL INFO P2P plugin IBext
173: hkn0524:1118934:1118934 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
230: hkn0604:674446:674446 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
230: hkn0604:674446:674446 [2] NCCL INFO Using network IBext
355: hkn0707:4005093:4005093 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
355: hkn0707:4005093:4005093 [3] NCCL INFO Using network IBext
 47: hkn0415:2481502:2481502 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
366: hkn0711:569042:569042 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
366: hkn0711:569042:569042 [2] NCCL INFO P2P plugin IBext
172: hkn0524:1118962:1118962 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
175: hkn0524:1118950:1118950 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
175: hkn0524:1118950:1118950 [3] NCCL INFO P2P plugin IBext
 87: hkn0426:799254:799254 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
380: hkn0715:387124:387124 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
426: hkn0727:1330937:1330937 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
380: hkn0715:387124:387124 [0] NCCL INFO P2P plugin IBext
426: hkn0727:1330937:1330937 [2] NCCL INFO Using network IBext
367: hkn0711:569054:569054 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
367: hkn0711:569054:569054 [3] NCCL INFO P2P plugin IBext
381: hkn0715:387096:387096 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
238: hkn0606:2357175:2357175 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
174: hkn0524:1118942:1118942 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
174: hkn0524:1118942:1118942 [2] NCCL INFO P2P plugin IBext
 76: hkn0424:2933109:2933109 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 76: hkn0424:2933109:2933109 [0] NCCL INFO P2P plugin IBext
 85: hkn0426:799266:799266 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 85: hkn0426:799266:799266 [1] NCCL INFO P2P plugin IBext
 45: hkn0415:2481516:2481516 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
400: hkn0720:4181520:4181520 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
400: hkn0720:4181520:4181520 [0] NCCL INFO P2P plugin IBext
382: hkn0715:387104:387104 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
382: hkn0715:387104:387104 [2] NCCL INFO P2P plugin IBext
352: hkn0707:4005081:4005081 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
352: hkn0707:4005081:4005081 [0] NCCL INFO Using network IBext
 46: hkn0415:2481504:2481504 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
365: hkn0711:569034:569034 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
365: hkn0711:569034:569034 [1] NCCL INFO P2P plugin IBext
 44: hkn0415:2481503:2481503 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
364: hkn0711:569026:569026 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
364: hkn0711:569026:569026 [0] NCCL INFO P2P plugin IBext
 78: hkn0424:2933089:2933089 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
 79: hkn0424:2933081:2933081 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
236: hkn0606:2357167:2357167 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
114: hkn0505:2288957:2288957 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
114: hkn0505:2288957:2288957 [2] NCCL INFO Using network IBext
113: hkn0505:2288949:2288949 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
113: hkn0505:2288949:2288949 [1] NCCL INFO Using network IBext
237: hkn0606:2357183:2357183 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
354: hkn0707:4005065:4005065 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
354: hkn0707:4005065:4005065 [2] NCCL INFO Using network IBext
353: hkn0707:4005073:4005073 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
353: hkn0707:4005073:4005073 [1] NCCL INFO Using network IBext
173: hkn0524:1118934:1118934 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
173: hkn0524:1118934:1118934 [1] NCCL INFO P2P plugin IBext
 47: hkn0415:2481502:2481502 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 47: hkn0415:2481502:2481502 [3] NCCL INFO P2P plugin IBext
 77: hkn0424:2933097:2933097 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
434: hkn0730:1386902:1386902 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
380: hkn0715:387124:387124 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
380: hkn0715:387124:387124 [0] NCCL INFO Using network IBext
367: hkn0711:569054:569054 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
367: hkn0711:569054:569054 [3] NCCL INFO Using network IBext
 87: hkn0426:799254:799254 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 87: hkn0426:799254:799254 [3] NCCL INFO P2P plugin IBext
 84: hkn0426:799238:799238 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
199: hkn0530:1243337:1243337 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
239: hkn0606:2357195:2357195 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
382: hkn0715:387104:387104 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
382: hkn0715:387104:387104 [2] NCCL INFO Using network IBext
172: hkn0524:1118962:1118962 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
172: hkn0524:1118962:1118962 [0] NCCL INFO P2P plugin IBext
381: hkn0715:387096:387096 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
381: hkn0715:387096:387096 [1] NCCL INFO P2P plugin IBext
174: hkn0524:1118942:1118942 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
174: hkn0524:1118942:1118942 [2] NCCL INFO Using network IBext
238: hkn0606:2357175:2357175 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
238: hkn0606:2357175:2357175 [2] NCCL INFO P2P plugin IBext
435: hkn0730:1386922:1386922 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
146: hkn0513:2998110:2998110 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
364: hkn0711:569026:569026 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
364: hkn0711:569026:569026 [0] NCCL INFO Using network IBext
198: hkn0530:1243309:1243309 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
365: hkn0711:569034:569034 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
365: hkn0711:569034:569034 [1] NCCL INFO Using network IBext
 86: hkn0426:799246:799246 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
173: hkn0524:1118934:1118934 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
173: hkn0524:1118934:1118934 [1] NCCL INFO Using network IBext
 45: hkn0415:2481516:2481516 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 45: hkn0415:2481516:2481516 [1] NCCL INFO P2P plugin IBext
196: hkn0530:1243317:1243317 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
432: hkn0730:1386910:1386910 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
 46: hkn0415:2481504:2481504 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 46: hkn0415:2481504:2481504 [2] NCCL INFO P2P plugin IBext
236: hkn0606:2357167:2357167 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
236: hkn0606:2357167:2357167 [0] NCCL INFO P2P plugin IBext
 44: hkn0415:2481503:2481503 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 44: hkn0415:2481503:2481503 [0] NCCL INFO P2P plugin IBext
197: hkn0530:1243325:1243325 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
237: hkn0606:2357183:2357183 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
237: hkn0606:2357183:2357183 [1] NCCL INFO P2P plugin IBext
145: hkn0513:2998098:2998098 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
172: hkn0524:1118962:1118962 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
172: hkn0524:1118962:1118962 [0] NCCL INFO Using network IBext
383: hkn0715:387112:387112 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
383: hkn0715:387112:387112 [3] NCCL INFO Using network IBext
381: hkn0715:387096:387096 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
381: hkn0715:387096:387096 [1] NCCL INFO Using network IBext
 79: hkn0424:2933081:2933081 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 79: hkn0424:2933081:2933081 [3] NCCL INFO P2P plugin IBext
 78: hkn0424:2933089:2933089 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 78: hkn0424:2933089:2933089 [2] NCCL INFO P2P plugin IBext
434: hkn0730:1386902:1386902 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
434: hkn0730:1386902:1386902 [2] NCCL INFO P2P plugin IBext
366: hkn0711:569042:569042 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
366: hkn0711:569042:569042 [2] NCCL INFO Using network IBext
 87: hkn0426:799254:799254 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 87: hkn0426:799254:799254 [3] NCCL INFO Using network IBext
421: hkn0726:1533295:1533295 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
 77: hkn0424:2933097:2933097 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 77: hkn0424:2933097:2933097 [1] NCCL INFO P2P plugin IBext
199: hkn0530:1243337:1243337 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
199: hkn0530:1243337:1243337 [3] NCCL INFO P2P plugin IBext
175: hkn0524:1118950:1118950 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
175: hkn0524:1118950:1118950 [3] NCCL INFO Using network IBext
239: hkn0606:2357195:2357195 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
239: hkn0606:2357195:2357195 [3] NCCL INFO P2P plugin IBext
 84: hkn0426:799238:799238 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 84: hkn0426:799238:799238 [0] NCCL INFO P2P plugin IBext
422: hkn0726:1533298:1533298 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
402: hkn0720:4181548:4181548 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
403: hkn0720:4181536:4181536 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
435: hkn0730:1386922:1386922 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
435: hkn0730:1386922:1386922 [3] NCCL INFO P2P plugin IBext
461: hkn0802:1185499:1185499 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
146: hkn0513:2998110:2998110 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
146: hkn0513:2998110:2998110 [2] NCCL INFO P2P plugin IBext
401: hkn0720:4181528:4181528 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
463: hkn0802:1185491:1185491 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
433: hkn0730:1386894:1386894 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
198: hkn0530:1243309:1243309 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
198: hkn0530:1243309:1243309 [2] NCCL INFO P2P plugin IBext
 85: hkn0426:799266:799266 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 85: hkn0426:799266:799266 [1] NCCL INFO Using network IBext
 44: hkn0415:2481503:2481503 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 45: hkn0415:2481516:2481516 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 46: hkn0415:2481504:2481504 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 44: hkn0415:2481503:2481503 [0] NCCL INFO Using network IBext
 45: hkn0415:2481516:2481516 [1] NCCL INFO Using network IBext
 46: hkn0415:2481504:2481504 [2] NCCL INFO Using network IBext
 86: hkn0426:799246:799246 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 86: hkn0426:799246:799246 [2] NCCL INFO P2P plugin IBext
236: hkn0606:2357167:2357167 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
423: hkn0726:1533306:1533306 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
237: hkn0606:2357183:2357183 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
236: hkn0606:2357167:2357167 [0] NCCL INFO Using network IBext
237: hkn0606:2357183:2357183 [1] NCCL INFO Using network IBext
432: hkn0730:1386910:1386910 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
432: hkn0730:1386910:1386910 [0] NCCL INFO P2P plugin IBext
420: hkn0726:1533318:1533318 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
147: hkn0513:2998082:2998082 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
400: hkn0720:4181520:4181520 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
145: hkn0513:2998098:2998098 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
400: hkn0720:4181520:4181520 [0] NCCL INFO Using network IBext
145: hkn0513:2998098:2998098 [1] NCCL INFO P2P plugin IBext
239: hkn0606:2357195:2357195 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
239: hkn0606:2357195:2357195 [3] NCCL INFO Using network IBext
111: hkn0504:25981:25981 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
 84: hkn0426:799238:799238 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
197: hkn0530:1243325:1243325 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
197: hkn0530:1243325:1243325 [1] NCCL INFO P2P plugin IBext
 84: hkn0426:799238:799238 [0] NCCL INFO Using network IBext
196: hkn0530:1243317:1243317 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
196: hkn0530:1243317:1243317 [0] NCCL INFO P2P plugin IBext
 79: hkn0424:2933081:2933081 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 79: hkn0424:2933081:2933081 [3] NCCL INFO Using network IBext
 77: hkn0424:2933097:2933097 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 77: hkn0424:2933097:2933097 [1] NCCL INFO Using network IBext
 76: hkn0424:2933109:2933109 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 78: hkn0424:2933089:2933089 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 76: hkn0424:2933109:2933109 [0] NCCL INFO Using network IBext
 78: hkn0424:2933089:2933089 [2] NCCL INFO Using network IBext
 47: hkn0415:2481502:2481502 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 47: hkn0415:2481502:2481502 [3] NCCL INFO Using network IBext
460: hkn0802:1185519:1185519 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
421: hkn0726:1533295:1533295 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
421: hkn0726:1533295:1533295 [1] NCCL INFO P2P plugin IBext
422: hkn0726:1533298:1533298 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
422: hkn0726:1533298:1533298 [2] NCCL INFO P2P plugin IBext
435: hkn0730:1386922:1386922 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
435: hkn0730:1386922:1386922 [3] NCCL INFO Using network IBext
144: hkn0513:2998090:2998090 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
198: hkn0530:1243309:1243309 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
198: hkn0530:1243309:1243309 [2] NCCL INFO Using network IBext
238: hkn0606:2357175:2357175 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
238: hkn0606:2357175:2357175 [2] NCCL INFO Using network IBext
 86: hkn0426:799246:799246 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 86: hkn0426:799246:799246 [2] NCCL INFO Using network IBext
433: hkn0730:1386894:1386894 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
433: hkn0730:1386894:1386894 [1] NCCL INFO P2P plugin IBext
463: hkn0802:1185491:1185491 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
463: hkn0802:1185491:1185491 [3] NCCL INFO P2P plugin IBext
402: hkn0720:4181548:4181548 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
402: hkn0720:4181548:4181548 [2] NCCL INFO P2P plugin IBext
432: hkn0730:1386910:1386910 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
432: hkn0730:1386910:1386910 [0] NCCL INFO Using network IBext
462: hkn0802:1185507:1185507 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
401: hkn0720:4181528:4181528 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
401: hkn0720:4181528:4181528 [1] NCCL INFO P2P plugin IBext
403: hkn0720:4181536:4181536 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
403: hkn0720:4181536:4181536 [3] NCCL INFO P2P plugin IBext
461: hkn0802:1185499:1185499 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
461: hkn0802:1185499:1185499 [1] NCCL INFO P2P plugin IBext
196: hkn0530:1243317:1243317 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
197: hkn0530:1243325:1243325 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
196: hkn0530:1243317:1243317 [0] NCCL INFO Using network IBext
197: hkn0530:1243325:1243325 [1] NCCL INFO Using network IBext
420: hkn0726:1533318:1533318 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
420: hkn0726:1533318:1533318 [0] NCCL INFO P2P plugin IBext
147: hkn0513:2998082:2998082 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
147: hkn0513:2998082:2998082 [3] NCCL INFO P2P plugin IBext
145: hkn0513:2998098:2998098 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
145: hkn0513:2998098:2998098 [1] NCCL INFO Using network IBext
111: hkn0504:25981:25981 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
111: hkn0504:25981:25981 [3] NCCL INFO P2P plugin IBext
423: hkn0726:1533306:1533306 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
423: hkn0726:1533306:1533306 [3] NCCL INFO P2P plugin IBext
460: hkn0802:1185519:1185519 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
460: hkn0802:1185519:1185519 [0] NCCL INFO P2P plugin IBext
433: hkn0730:1386894:1386894 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
434: hkn0730:1386902:1386902 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
433: hkn0730:1386894:1386894 [1] NCCL INFO Using network IBext
434: hkn0730:1386902:1386902 [2] NCCL INFO Using network IBext
402: hkn0720:4181548:4181548 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
402: hkn0720:4181548:4181548 [2] NCCL INFO Using network IBext
401: hkn0720:4181528:4181528 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
401: hkn0720:4181528:4181528 [1] NCCL INFO Using network IBext
403: hkn0720:4181536:4181536 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
403: hkn0720:4181536:4181536 [3] NCCL INFO Using network IBext
199: hkn0530:1243337:1243337 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
199: hkn0530:1243337:1243337 [3] NCCL INFO Using network IBext
144: hkn0513:2998090:2998090 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
144: hkn0513:2998090:2998090 [0] NCCL INFO P2P plugin IBext
146: hkn0513:2998110:2998110 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
146: hkn0513:2998110:2998110 [2] NCCL INFO Using network IBext
110: hkn0504:25993:25993 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
462: hkn0802:1185507:1185507 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
462: hkn0802:1185507:1185507 [2] NCCL INFO P2P plugin IBext
147: hkn0513:2998082:2998082 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
147: hkn0513:2998082:2998082 [3] NCCL INFO Using network IBext
461: hkn0802:1185499:1185499 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
461: hkn0802:1185499:1185499 [1] NCCL INFO Using network IBext
460: hkn0802:1185519:1185519 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
460: hkn0802:1185519:1185519 [0] NCCL INFO Using network IBext
423: hkn0726:1533306:1533306 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
420: hkn0726:1533318:1533318 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
423: hkn0726:1533306:1533306 [3] NCCL INFO Using network IBext
420: hkn0726:1533318:1533318 [0] NCCL INFO Using network IBext
109: hkn0504:25973:25973 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
144: hkn0513:2998090:2998090 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
144: hkn0513:2998090:2998090 [0] NCCL INFO Using network IBext
108: hkn0504:25965:25965 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
422: hkn0726:1533298:1533298 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
422: hkn0726:1533298:1533298 [2] NCCL INFO Using network IBext
462: hkn0802:1185507:1185507 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
462: hkn0802:1185507:1185507 [2] NCCL INFO Using network IBext
421: hkn0726:1533295:1533295 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
421: hkn0726:1533295:1533295 [1] NCCL INFO Using network IBext
110: hkn0504:25993:25993 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
110: hkn0504:25993:25993 [2] NCCL INFO P2P plugin IBext
463: hkn0802:1185491:1185491 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
463: hkn0802:1185491:1185491 [3] NCCL INFO Using network IBext
116: hkn0506:823193:823193 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
221: hkn0602:3345235:3345235 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
109: hkn0504:25973:25973 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
109: hkn0504:25973:25973 [1] NCCL INFO P2P plugin IBext
119: hkn0506:823213:823213 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
222: hkn0602:3345207:3345207 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
220: hkn0602:3345223:3345223 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
223: hkn0602:3345215:3345215 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
108: hkn0504:25965:25965 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
108: hkn0504:25965:25965 [0] NCCL INFO P2P plugin IBext
111: hkn0504:25981:25981 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
111: hkn0504:25981:25981 [3] NCCL INFO Using network IBext
110: hkn0504:25993:25993 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
110: hkn0504:25993:25993 [2] NCCL INFO Using network IBext
116: hkn0506:823193:823193 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
116: hkn0506:823193:823193 [0] NCCL INFO P2P plugin IBext
109: hkn0504:25973:25973 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
109: hkn0504:25973:25973 [1] NCCL INFO Using network IBext
458: hkn0801:2225110:2225110 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
221: hkn0602:3345235:3345235 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
221: hkn0602:3345235:3345235 [1] NCCL INFO P2P plugin IBext
108: hkn0504:25965:25965 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
108: hkn0504:25965:25965 [0] NCCL INFO Using network IBext
119: hkn0506:823213:823213 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
119: hkn0506:823213:823213 [3] NCCL INFO P2P plugin IBext
222: hkn0602:3345207:3345207 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
222: hkn0602:3345207:3345207 [2] NCCL INFO P2P plugin IBext
441: hkn0732:1196811:1196811 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
220: hkn0602:3345223:3345223 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
220: hkn0602:3345223:3345223 [0] NCCL INFO P2P plugin IBext
223: hkn0602:3345215:3345215 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
223: hkn0602:3345215:3345215 [3] NCCL INFO P2P plugin IBext
443: hkn0732:1196831:1196831 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
117: hkn0506:823185:823185 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
452: hkn0736:1493537:1493537 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
454: hkn0736:1493528:1493528 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
458: hkn0801:2225110:2225110 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
458: hkn0801:2225110:2225110 [2] NCCL INFO P2P plugin IBext
459: hkn0801:2225102:2225102 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
119: hkn0506:823213:823213 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
119: hkn0506:823213:823213 [3] NCCL INFO Using network IBext
222: hkn0602:3345207:3345207 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
223: hkn0602:3345215:3345215 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
220: hkn0602:3345223:3345223 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
222: hkn0602:3345207:3345207 [2] NCCL INFO Using network IBext
223: hkn0602:3345215:3345215 [3] NCCL INFO Using network IBext
220: hkn0602:3345223:3345223 [0] NCCL INFO Using network IBext
441: hkn0732:1196811:1196811 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
441: hkn0732:1196811:1196811 [1] NCCL INFO P2P plugin IBext
453: hkn0736:1493549:1493549 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
187: hkn0527:1334069:1334069 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
442: hkn0732:1196803:1196803 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
118: hkn0506:823201:823201 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
443: hkn0732:1196831:1196831 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
443: hkn0732:1196831:1196831 [3] NCCL INFO P2P plugin IBext
440: hkn0732:1196819:1196819 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
186: hkn0527:1334041:1334041 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
457: hkn0801:2225101:2225101 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
248: hkn0609:696056:696056 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
117: hkn0506:823185:823185 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
117: hkn0506:823185:823185 [1] NCCL INFO P2P plugin IBext
116: hkn0506:823193:823193 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
116: hkn0506:823193:823193 [0] NCCL INFO Using network IBext
452: hkn0736:1493537:1493537 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
452: hkn0736:1493537:1493537 [0] NCCL INFO P2P plugin IBext
454: hkn0736:1493528:1493528 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
454: hkn0736:1493528:1493528 [2] NCCL INFO P2P plugin IBext
459: hkn0801:2225102:2225102 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
459: hkn0801:2225102:2225102 [3] NCCL INFO P2P plugin IBext
407: hkn0721:2284151:2284151 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
221: hkn0602:3345235:3345235 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
221: hkn0602:3345235:3345235 [1] NCCL INFO Using network IBext
456: hkn0801:2225122:2225122 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
187: hkn0527:1334069:1334069 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
187: hkn0527:1334069:1334069 [3] NCCL INFO P2P plugin IBext
453: hkn0736:1493549:1493549 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
453: hkn0736:1493549:1493549 [1] NCCL INFO P2P plugin IBext
455: hkn0736:1493529:1493529 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
443: hkn0732:1196831:1196831 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
443: hkn0732:1196831:1196831 [3] NCCL INFO Using network IBext
442: hkn0732:1196803:1196803 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
442: hkn0732:1196803:1196803 [2] NCCL INFO P2P plugin IBext
118: hkn0506:823201:823201 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
118: hkn0506:823201:823201 [2] NCCL INFO P2P plugin IBext
249: hkn0609:696028:696028 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
117: hkn0506:823185:823185 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
117: hkn0506:823185:823185 [1] NCCL INFO Using network IBext
440: hkn0732:1196819:1196819 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
440: hkn0732:1196819:1196819 [0] NCCL INFO P2P plugin IBext
457: hkn0801:2225101:2225101 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
457: hkn0801:2225101:2225101 [1] NCCL INFO P2P plugin IBext
186: hkn0527:1334041:1334041 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
186: hkn0527:1334041:1334041 [2] NCCL INFO P2P plugin IBext
248: hkn0609:696056:696056 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
248: hkn0609:696056:696056 [0] NCCL INFO P2P plugin IBext
250: hkn0609:696036:696036 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
459: hkn0801:2225102:2225102 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
459: hkn0801:2225102:2225102 [3] NCCL INFO Using network IBext
406: hkn0721:2284171:2284171 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
163: hkn0520:2698007:2698007 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
407: hkn0721:2284151:2284151 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
407: hkn0721:2284151:2284151 [3] NCCL INFO P2P plugin IBext
442: hkn0732:1196803:1196803 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
442: hkn0732:1196803:1196803 [2] NCCL INFO Using network IBext
251: hkn0609:696044:696044 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
118: hkn0506:823201:823201 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
118: hkn0506:823201:823201 [2] NCCL INFO Using network IBext
458: hkn0801:2225110:2225110 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
458: hkn0801:2225110:2225110 [2] NCCL INFO Using network IBext
304: hkn0629:1577186:1577186 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
440: hkn0732:1196819:1196819 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
440: hkn0732:1196819:1196819 [0] NCCL INFO Using network IBext
457: hkn0801:2225101:2225101 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
227: hkn0603:1398303:1398303 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
457: hkn0801:2225101:2225101 [1] NCCL INFO Using network IBext
456: hkn0801:2225122:2225122 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
456: hkn0801:2225122:2225122 [0] NCCL INFO P2P plugin IBext
405: hkn0721:2284159:2284159 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
453: hkn0736:1493549:1493549 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
452: hkn0736:1493537:1493537 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
453: hkn0736:1493549:1493549 [1] NCCL INFO Using network IBext
452: hkn0736:1493537:1493537 [0] NCCL INFO Using network IBext
404: hkn0721:2284143:2284143 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
455: hkn0736:1493529:1493529 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
455: hkn0736:1493529:1493529 [3] NCCL INFO P2P plugin IBext
441: hkn0732:1196811:1196811 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
306: hkn0629:1577206:1577206 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
441: hkn0732:1196811:1196811 [1] NCCL INFO Using network IBext
249: hkn0609:696028:696028 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
249: hkn0609:696028:696028 [1] NCCL INFO P2P plugin IBext
307: hkn0629:1577178:1577178 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
186: hkn0527:1334041:1334041 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
186: hkn0527:1334041:1334041 [2] NCCL INFO Using network IBext
160: hkn0520:2697999:2697999 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
151: hkn0514:2935901:2935901 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
305: hkn0629:1577194:1577194 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
161: hkn0520:2698015:2698015 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
224: hkn0603:1398327:1398327 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
250: hkn0609:696036:696036 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
250: hkn0609:696036:696036 [2] NCCL INFO P2P plugin IBext
170: hkn0523:1533170:1533170 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
456: hkn0801:2225122:2225122 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
456: hkn0801:2225122:2225122 [0] NCCL INFO Using network IBext
163: hkn0520:2698007:2698007 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
163: hkn0520:2698007:2698007 [3] NCCL INFO P2P plugin IBext
226: hkn0603:1398315:1398315 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
455: hkn0736:1493529:1493529 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
455: hkn0736:1493529:1493529 [3] NCCL INFO Using network IBext
 56: hkn0419:1529464:1529464 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
406: hkn0721:2284171:2284171 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
406: hkn0721:2284171:2284171 [2] NCCL INFO P2P plugin IBext
251: hkn0609:696044:696044 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
251: hkn0609:696044:696044 [3] NCCL INFO P2P plugin IBext
185: hkn0527:1334057:1334057 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
454: hkn0736:1493528:1493528 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
454: hkn0736:1493528:1493528 [2] NCCL INFO Using network IBext
304: hkn0629:1577186:1577186 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
304: hkn0629:1577186:1577186 [0] NCCL INFO P2P plugin IBext
227: hkn0603:1398303:1398303 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
227: hkn0603:1398303:1398303 [3] NCCL INFO P2P plugin IBext
169: hkn0523:1533198:1533198 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
184: hkn0527:1334049:1334049 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
404: hkn0721:2284143:2284143 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
404: hkn0721:2284143:2284143 [0] NCCL INFO P2P plugin IBext
405: hkn0721:2284159:2284159 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
405: hkn0721:2284159:2284159 [1] NCCL INFO P2P plugin IBext
162: hkn0520:2698027:2698027 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
187: hkn0527:1334069:1334069 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
187: hkn0527:1334069:1334069 [3] NCCL INFO Using network IBext
225: hkn0603:1398307:1398307 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
249: hkn0609:696028:696028 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
249: hkn0609:696028:696028 [1] NCCL INFO Using network IBext
250: hkn0609:696036:696036 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
250: hkn0609:696036:696036 [2] NCCL INFO Using network IBext
306: hkn0629:1577206:1577206 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
306: hkn0629:1577206:1577206 [2] NCCL INFO P2P plugin IBext
148: hkn0514:2935885:2935885 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
470: hkn0804:1190787:1190787 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
307: hkn0629:1577178:1577178 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
307: hkn0629:1577178:1577178 [3] NCCL INFO P2P plugin IBext
160: hkn0520:2697999:2697999 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
160: hkn0520:2697999:2697999 [0] NCCL INFO P2P plugin IBext
151: hkn0514:2935901:2935901 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
151: hkn0514:2935901:2935901 [3] NCCL INFO P2P plugin IBext
161: hkn0520:2698015:2698015 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
161: hkn0520:2698015:2698015 [1] NCCL INFO P2P plugin IBext
149: hkn0514:2935893:2935893 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
224: hkn0603:1398327:1398327 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
224: hkn0603:1398327:1398327 [0] NCCL INFO P2P plugin IBext
150: hkn0514:2935913:2935913 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
 59: hkn0419:1529462:1529462 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
251: hkn0609:696044:696044 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
251: hkn0609:696044:696044 [3] NCCL INFO Using network IBext
305: hkn0629:1577194:1577194 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
305: hkn0629:1577194:1577194 [1] NCCL INFO P2P plugin IBext
248: hkn0609:696056:696056 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
248: hkn0609:696056:696056 [0] NCCL INFO Using network IBext
170: hkn0523:1533170:1533170 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
170: hkn0523:1533170:1533170 [2] NCCL INFO P2P plugin IBext
226: hkn0603:1398315:1398315 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
226: hkn0603:1398315:1398315 [2] NCCL INFO P2P plugin IBext
 56: hkn0419:1529464:1529464 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 56: hkn0419:1529464:1529464 [0] NCCL INFO P2P plugin IBext
406: hkn0721:2284171:2284171 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
406: hkn0721:2284171:2284171 [2] NCCL INFO Using network IBext
407: hkn0721:2284151:2284151 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
407: hkn0721:2284151:2284151 [3] NCCL INFO Using network IBext
404: hkn0721:2284143:2284143 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
404: hkn0721:2284143:2284143 [0] NCCL INFO Using network IBext
405: hkn0721:2284159:2284159 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
471: hkn0804:1190762:1190762 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
405: hkn0721:2284159:2284159 [1] NCCL INFO Using network IBext
185: hkn0527:1334057:1334057 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
185: hkn0527:1334057:1334057 [1] NCCL INFO P2P plugin IBext
468: hkn0804:1190767:1190767 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
328: hkn0635:1210747:1210747 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
399: hkn0719:1290839:1290839 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
169: hkn0523:1533198:1533198 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
169: hkn0523:1533198:1533198 [1] NCCL INFO P2P plugin IBext
162: hkn0520:2698027:2698027 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
162: hkn0520:2698027:2698027 [2] NCCL INFO P2P plugin IBext
225: hkn0603:1398307:1398307 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
225: hkn0603:1398307:1398307 [1] NCCL INFO P2P plugin IBext
184: hkn0527:1334049:1334049 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
184: hkn0527:1334049:1334049 [0] NCCL INFO P2P plugin IBext
 57: hkn0419:1529484:1529484 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
398: hkn0719:1290848:1290848 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
 58: hkn0419:1529472:1529472 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
305: hkn0629:1577194:1577194 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
306: hkn0629:1577206:1577206 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
307: hkn0629:1577178:1577178 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
307: hkn0629:1577178:1577178 [3] NCCL INFO Using network IBext
305: hkn0629:1577194:1577194 [1] NCCL INFO Using network IBext
306: hkn0629:1577206:1577206 [2] NCCL INFO Using network IBext
148: hkn0514:2935885:2935885 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
148: hkn0514:2935885:2935885 [0] NCCL INFO P2P plugin IBext
330: hkn0635:1210755:1210755 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
470: hkn0804:1190787:1190787 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
470: hkn0804:1190787:1190787 [2] NCCL INFO P2P plugin IBext
329: hkn0635:1210739:1210739 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
469: hkn0804:1190775:1190775 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
160: hkn0520:2697999:2697999 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
160: hkn0520:2697999:2697999 [0] NCCL INFO Using network IBext
161: hkn0520:2698015:2698015 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
161: hkn0520:2698015:2698015 [1] NCCL INFO Using network IBext
 59: hkn0419:1529462:1529462 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 59: hkn0419:1529462:1529462 [3] NCCL INFO P2P plugin IBext
150: hkn0514:2935913:2935913 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
150: hkn0514:2935913:2935913 [2] NCCL INFO P2P plugin IBext
331: hkn0635:1210773:1210773 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
226: hkn0603:1398315:1398315 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
226: hkn0603:1398315:1398315 [2] NCCL INFO Using network IBext
224: hkn0603:1398327:1398327 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
224: hkn0603:1398327:1398327 [0] NCCL INFO Using network IBext
149: hkn0514:2935893:2935893 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
149: hkn0514:2935893:2935893 [1] NCCL INFO P2P plugin IBext
185: hkn0527:1334057:1334057 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
185: hkn0527:1334057:1334057 [1] NCCL INFO Using network IBext
163: hkn0520:2698007:2698007 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
163: hkn0520:2698007:2698007 [3] NCCL INFO Using network IBext
162: hkn0520:2698027:2698027 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
162: hkn0520:2698027:2698027 [2] NCCL INFO Using network IBext
184: hkn0527:1334049:1334049 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
184: hkn0527:1334049:1334049 [0] NCCL INFO Using network IBext
225: hkn0603:1398307:1398307 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
225: hkn0603:1398307:1398307 [1] NCCL INFO Using network IBext
471: hkn0804:1190762:1190762 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
471: hkn0804:1190762:1190762 [3] NCCL INFO P2P plugin IBext
468: hkn0804:1190767:1190767 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
468: hkn0804:1190767:1190767 [0] NCCL INFO P2P plugin IBext
397: hkn0719:1290860:1290860 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
169: hkn0523:1533198:1533198 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
169: hkn0523:1533198:1533198 [1] NCCL INFO Using network IBext
328: hkn0635:1210747:1210747 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
328: hkn0635:1210747:1210747 [0] NCCL INFO P2P plugin IBext
399: hkn0719:1290839:1290839 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
399: hkn0719:1290839:1290839 [3] NCCL INFO P2P plugin IBext
227: hkn0603:1398303:1398303 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
227: hkn0603:1398303:1398303 [3] NCCL INFO Using network IBext
396: hkn0719:1290840:1290840 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
398: hkn0719:1290848:1290848 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
398: hkn0719:1290848:1290848 [2] NCCL INFO P2P plugin IBext
 58: hkn0419:1529472:1529472 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 58: hkn0419:1529472:1529472 [2] NCCL INFO P2P plugin IBext
 57: hkn0419:1529484:1529484 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 57: hkn0419:1529484:1529484 [1] NCCL INFO P2P plugin IBext
304: hkn0629:1577186:1577186 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
304: hkn0629:1577186:1577186 [0] NCCL INFO Using network IBext
150: hkn0514:2935913:2935913 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
150: hkn0514:2935913:2935913 [2] NCCL INFO Using network IBext
149: hkn0514:2935893:2935893 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
149: hkn0514:2935893:2935893 [1] NCCL INFO Using network IBext
148: hkn0514:2935885:2935885 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
148: hkn0514:2935885:2935885 [0] NCCL INFO Using network IBext
311: hkn0630:1583636:1583636 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
330: hkn0635:1210755:1210755 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
330: hkn0635:1210755:1210755 [2] NCCL INFO P2P plugin IBext
469: hkn0804:1190775:1190775 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
469: hkn0804:1190775:1190775 [1] NCCL INFO P2P plugin IBext
308: hkn0630:1583656:1583656 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
329: hkn0635:1210739:1210739 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
329: hkn0635:1210739:1210739 [1] NCCL INFO P2P plugin IBext
 59: hkn0419:1529462:1529462 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 59: hkn0419:1529462:1529462 [3] NCCL INFO Using network IBext
151: hkn0514:2935901:2935901 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
151: hkn0514:2935901:2935901 [3] NCCL INFO Using network IBext
331: hkn0635:1210773:1210773 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
331: hkn0635:1210773:1210773 [3] NCCL INFO P2P plugin IBext
345: hkn0705:768401:768401 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
 56: hkn0419:1529464:1529464 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
170: hkn0523:1533170:1533170 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
 56: hkn0419:1529464:1529464 [0] NCCL INFO Using network IBext
170: hkn0523:1533170:1533170 [2] NCCL INFO Using network IBext
 57: hkn0419:1529484:1529484 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 57: hkn0419:1529484:1529484 [1] NCCL INFO Using network IBext
471: hkn0804:1190762:1190762 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
468: hkn0804:1190767:1190767 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
471: hkn0804:1190762:1190762 [3] NCCL INFO Using network IBext
468: hkn0804:1190767:1190767 [0] NCCL INFO Using network IBext
 58: hkn0419:1529472:1529472 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 58: hkn0419:1529472:1529472 [2] NCCL INFO Using network IBext
397: hkn0719:1290860:1290860 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
397: hkn0719:1290860:1290860 [1] NCCL INFO P2P plugin IBext
310: hkn0630:1583644:1583644 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
469: hkn0804:1190775:1190775 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
469: hkn0804:1190775:1190775 [1] NCCL INFO Using network IBext
309: hkn0630:1583628:1583628 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
398: hkn0719:1290848:1290848 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
398: hkn0719:1290848:1290848 [2] NCCL INFO Using network IBext
396: hkn0719:1290840:1290840 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
396: hkn0719:1290840:1290840 [0] NCCL INFO P2P plugin IBext
134: hkn0510:2747248:2747248 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
311: hkn0630:1583636:1583636 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
311: hkn0630:1583636:1583636 [3] NCCL INFO P2P plugin IBext
329: hkn0635:1210739:1210739 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
331: hkn0635:1210773:1210773 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
329: hkn0635:1210739:1210739 [1] NCCL INFO Using network IBext
331: hkn0635:1210773:1210773 [3] NCCL INFO Using network IBext
330: hkn0635:1210755:1210755 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
330: hkn0635:1210755:1210755 [2] NCCL INFO Using network IBext
308: hkn0630:1583656:1583656 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
308: hkn0630:1583656:1583656 [0] NCCL INFO P2P plugin IBext
470: hkn0804:1190787:1190787 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
470: hkn0804:1190787:1190787 [2] NCCL INFO Using network IBext
133: hkn0510:2747236:2747236 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
171: hkn0523:1533178:1533178 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
345: hkn0705:768401:768401 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
345: hkn0705:768401:768401 [1] NCCL INFO P2P plugin IBext
347: hkn0705:768400:768400 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
397: hkn0719:1290860:1290860 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
397: hkn0719:1290860:1290860 [1] NCCL INFO Using network IBext
168: hkn0523:1533186:1533186 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
396: hkn0719:1290840:1290840 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
396: hkn0719:1290840:1290840 [0] NCCL INFO Using network IBext
310: hkn0630:1583644:1583644 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
310: hkn0630:1583644:1583644 [2] NCCL INFO P2P plugin IBext
132: hkn0510:2747220:2747220 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
309: hkn0630:1583628:1583628 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
309: hkn0630:1583628:1583628 [1] NCCL INFO P2P plugin IBext
399: hkn0719:1290839:1290839 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
399: hkn0719:1290839:1290839 [3] NCCL INFO Using network IBext
375: hkn0713:455441:455441 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
328: hkn0635:1210747:1210747 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
328: hkn0635:1210747:1210747 [0] NCCL INFO Using network IBext
346: hkn0705:768409:768409 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
134: hkn0510:2747248:2747248 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
134: hkn0510:2747248:2747248 [2] NCCL INFO P2P plugin IBext
135: hkn0510:2747228:2747228 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
133: hkn0510:2747236:2747236 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
133: hkn0510:2747236:2747236 [1] NCCL INFO P2P plugin IBext
347: hkn0705:768400:768400 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
347: hkn0705:768400:768400 [3] NCCL INFO P2P plugin IBext
344: hkn0705:768421:768421 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
171: hkn0523:1533178:1533178 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
171: hkn0523:1533178:1533178 [3] NCCL INFO P2P plugin IBext
309: hkn0630:1583628:1583628 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
310: hkn0630:1583644:1583644 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
309: hkn0630:1583628:1583628 [1] NCCL INFO Using network IBext
310: hkn0630:1583644:1583644 [2] NCCL INFO Using network IBext
132: hkn0510:2747220:2747220 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
132: hkn0510:2747220:2747220 [0] NCCL INFO P2P plugin IBext
168: hkn0523:1533186:1533186 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
168: hkn0523:1533186:1533186 [0] NCCL INFO P2P plugin IBext
375: hkn0713:455441:455441 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
375: hkn0713:455441:455441 [3] NCCL INFO P2P plugin IBext
346: hkn0705:768409:768409 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
346: hkn0705:768409:768409 [2] NCCL INFO P2P plugin IBext
311: hkn0630:1583636:1583636 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
311: hkn0630:1583636:1583636 [3] NCCL INFO Using network IBext
308: hkn0630:1583656:1583656 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
308: hkn0630:1583656:1583656 [0] NCCL INFO Using network IBext
135: hkn0510:2747228:2747228 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
135: hkn0510:2747228:2747228 [3] NCCL INFO P2P plugin IBext
372: hkn0713:455428:455428 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
 71: hkn0422:4138193:4138193 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
133: hkn0510:2747236:2747236 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
133: hkn0510:2747236:2747236 [1] NCCL INFO Using network IBext
347: hkn0705:768400:768400 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
347: hkn0705:768400:768400 [3] NCCL INFO Using network IBext
373: hkn0713:455427:455427 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
345: hkn0705:768401:768401 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
345: hkn0705:768401:768401 [1] NCCL INFO Using network IBext
132: hkn0510:2747220:2747220 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
132: hkn0510:2747220:2747220 [0] NCCL INFO Using network IBext
344: hkn0705:768421:768421 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
344: hkn0705:768421:768421 [0] NCCL INFO P2P plugin IBext
346: hkn0705:768409:768409 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
346: hkn0705:768409:768409 [2] NCCL INFO Using network IBext
171: hkn0523:1533178:1533178 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
171: hkn0523:1533178:1533178 [3] NCCL INFO Using network IBext
374: hkn0713:455429:455429 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
168: hkn0523:1533186:1533186 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
168: hkn0523:1533186:1533186 [0] NCCL INFO Using network IBext
135: hkn0510:2747228:2747228 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
135: hkn0510:2747228:2747228 [3] NCCL INFO Using network IBext
271: hkn0616:389985:389985 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
483: hkn0807:1004280:1004280 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
134: hkn0510:2747248:2747248 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
134: hkn0510:2747248:2747248 [2] NCCL INFO Using network IBext
372: hkn0713:455428:455428 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
372: hkn0713:455428:455428 [0] NCCL INFO P2P plugin IBext
 69: hkn0422:4138181:4138181 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 71: hkn0422:4138193:4138193 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 71: hkn0422:4138193:4138193 [3] NCCL INFO P2P plugin IBext
 70: hkn0422:4138165:4138165 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
344: hkn0705:768421:768421 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
344: hkn0705:768421:768421 [0] NCCL INFO Using network IBext
373: hkn0713:455427:455427 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
373: hkn0713:455427:455427 [1] NCCL INFO P2P plugin IBext
481: hkn0807:1004271:1004271 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
374: hkn0713:455429:455429 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
374: hkn0713:455429:455429 [2] NCCL INFO P2P plugin IBext
271: hkn0616:389985:389985 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
271: hkn0616:389985:389985 [3] NCCL INFO P2P plugin IBext
297: hkn0627:1773070:1773070 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
296: hkn0627:1773062:1773062 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
286: hkn0623:1857878:1857878 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
483: hkn0807:1004280:1004280 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
483: hkn0807:1004280:1004280 [3] NCCL INFO P2P plugin IBext
299: hkn0627:1773082:1773082 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
480: hkn0807:1004272:1004272 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
375: hkn0713:455441:455441 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
375: hkn0713:455441:455441 [3] NCCL INFO Using network IBext
372: hkn0713:455428:455428 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
372: hkn0713:455428:455428 [0] NCCL INFO Using network IBext
373: hkn0713:455427:455427 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
373: hkn0713:455427:455427 [1] NCCL INFO Using network IBext
482: hkn0807:1004292:1004292 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
 69: hkn0422:4138181:4138181 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 69: hkn0422:4138181:4138181 [1] NCCL INFO P2P plugin IBext
 68: hkn0422:4138173:4138173 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 70: hkn0422:4138165:4138165 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 70: hkn0422:4138165:4138165 [2] NCCL INFO P2P plugin IBext
374: hkn0713:455429:455429 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
374: hkn0713:455429:455429 [2] NCCL INFO Using network IBext
270: hkn0616:389969:389969 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
285: hkn0623:1857886:1857886 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
268: hkn0616:389997:389997 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
481: hkn0807:1004271:1004271 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
481: hkn0807:1004271:1004271 [1] NCCL INFO P2P plugin IBext
298: hkn0627:1773054:1773054 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
297: hkn0627:1773070:1773070 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
297: hkn0627:1773070:1773070 [1] NCCL INFO P2P plugin IBext
296: hkn0627:1773062:1773062 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
296: hkn0627:1773062:1773062 [0] NCCL INFO P2P plugin IBext
286: hkn0623:1857878:1857878 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
286: hkn0623:1857878:1857878 [2] NCCL INFO P2P plugin IBext
269: hkn0616:389977:389977 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
299: hkn0627:1773082:1773082 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
299: hkn0627:1773082:1773082 [3] NCCL INFO P2P plugin IBext
480: hkn0807:1004272:1004272 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
480: hkn0807:1004272:1004272 [0] NCCL INFO P2P plugin IBext
 70: hkn0422:4138165:4138165 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 70: hkn0422:4138165:4138165 [2] NCCL INFO Using network IBext
 69: hkn0422:4138181:4138181 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 69: hkn0422:4138181:4138181 [1] NCCL INFO Using network IBext
 68: hkn0422:4138173:4138173 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 68: hkn0422:4138173:4138173 [0] NCCL INFO P2P plugin IBext
482: hkn0807:1004292:1004292 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
482: hkn0807:1004292:1004292 [2] NCCL INFO P2P plugin IBext
287: hkn0623:1857898:1857898 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
 71: hkn0422:4138193:4138193 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 71: hkn0422:4138193:4138193 [3] NCCL INFO Using network IBext
270: hkn0616:389969:389969 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
270: hkn0616:389969:389969 [2] NCCL INFO P2P plugin IBext
285: hkn0623:1857886:1857886 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
285: hkn0623:1857886:1857886 [1] NCCL INFO P2P plugin IBext
481: hkn0807:1004271:1004271 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
481: hkn0807:1004271:1004271 [1] NCCL INFO Using network IBext
268: hkn0616:389997:389997 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
268: hkn0616:389997:389997 [0] NCCL INFO P2P plugin IBext
480: hkn0807:1004272:1004272 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
480: hkn0807:1004272:1004272 [0] NCCL INFO Using network IBext
298: hkn0627:1773054:1773054 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
298: hkn0627:1773054:1773054 [2] NCCL INFO P2P plugin IBext
284: hkn0623:1857870:1857870 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
 68: hkn0422:4138173:4138173 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
482: hkn0807:1004292:1004292 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
482: hkn0807:1004292:1004292 [2] NCCL INFO Using network IBext
 68: hkn0422:4138173:4138173 [0] NCCL INFO Using network IBext
483: hkn0807:1004280:1004280 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
269: hkn0616:389977:389977 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
269: hkn0616:389977:389977 [1] NCCL INFO P2P plugin IBext
483: hkn0807:1004280:1004280 [3] NCCL INFO Using network IBext
437: hkn0731:1371908:1371908 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
287: hkn0623:1857898:1857898 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
287: hkn0623:1857898:1857898 [3] NCCL INFO P2P plugin IBext
270: hkn0616:389969:389969 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
270: hkn0616:389969:389969 [2] NCCL INFO Using network IBext
271: hkn0616:389985:389985 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
271: hkn0616:389985:389985 [3] NCCL INFO Using network IBext
268: hkn0616:389997:389997 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
285: hkn0623:1857886:1857886 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
268: hkn0616:389997:389997 [0] NCCL INFO Using network IBext
285: hkn0623:1857886:1857886 [1] NCCL INFO Using network IBext
269: hkn0616:389977:389977 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
269: hkn0616:389977:389977 [1] NCCL INFO Using network IBext
298: hkn0627:1773054:1773054 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
298: hkn0627:1773054:1773054 [2] NCCL INFO Using network IBext
284: hkn0623:1857870:1857870 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
284: hkn0623:1857870:1857870 [0] NCCL INFO P2P plugin IBext
287: hkn0623:1857898:1857898 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
287: hkn0623:1857898:1857898 [3] NCCL INFO Using network IBext
296: hkn0627:1773062:1773062 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
296: hkn0627:1773062:1773062 [0] NCCL INFO Using network IBext
286: hkn0623:1857878:1857878 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
439: hkn0731:1371900:1371900 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
286: hkn0623:1857878:1857878 [2] NCCL INFO Using network IBext
299: hkn0627:1773082:1773082 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
299: hkn0627:1773082:1773082 [3] NCCL INFO Using network IBext
297: hkn0627:1773070:1773070 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
297: hkn0627:1773070:1773070 [1] NCCL INFO Using network IBext
437: hkn0731:1371908:1371908 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
437: hkn0731:1371908:1371908 [1] NCCL INFO P2P plugin IBext
490: hkn0809:922569:922569 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
436: hkn0731:1371920:1371920 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
284: hkn0623:1857870:1857870 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
284: hkn0623:1857870:1857870 [0] NCCL INFO Using network IBext
488: hkn0809:922553:922553 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
438: hkn0731:1371892:1371892 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
489: hkn0809:922561:922561 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
491: hkn0809:922581:922581 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
439: hkn0731:1371900:1371900 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
439: hkn0731:1371900:1371900 [3] NCCL INFO P2P plugin IBext
490: hkn0809:922569:922569 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
490: hkn0809:922569:922569 [2] NCCL INFO P2P plugin IBext
436: hkn0731:1371920:1371920 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
436: hkn0731:1371920:1371920 [0] NCCL INFO P2P plugin IBext
488: hkn0809:922553:922553 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
488: hkn0809:922553:922553 [0] NCCL INFO P2P plugin IBext
438: hkn0731:1371892:1371892 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
438: hkn0731:1371892:1371892 [2] NCCL INFO P2P plugin IBext
318: hkn0632:1743760:1743760 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
489: hkn0809:922561:922561 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
489: hkn0809:922561:922561 [1] NCCL INFO P2P plugin IBext
326: hkn0634:1506052:1506052 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
491: hkn0809:922581:922581 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
491: hkn0809:922581:922581 [3] NCCL INFO P2P plugin IBext
325: hkn0634:1506024:1506024 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
439: hkn0731:1371900:1371900 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
439: hkn0731:1371900:1371900 [3] NCCL INFO Using network IBext
436: hkn0731:1371920:1371920 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
436: hkn0731:1371920:1371920 [0] NCCL INFO Using network IBext
327: hkn0634:1506040:1506040 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
437: hkn0731:1371908:1371908 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
437: hkn0731:1371908:1371908 [1] NCCL INFO Using network IBext
438: hkn0731:1371892:1371892 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
438: hkn0731:1371892:1371892 [2] NCCL INFO Using network IBext
488: hkn0809:922553:922553 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
488: hkn0809:922553:922553 [0] NCCL INFO Using network IBext
489: hkn0809:922561:922561 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
489: hkn0809:922561:922561 [1] NCCL INFO Using network IBext
324: hkn0634:1506032:1506032 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
491: hkn0809:922581:922581 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
491: hkn0809:922581:922581 [3] NCCL INFO Using network IBext
316: hkn0632:1743761:1743761 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
318: hkn0632:1743760:1743760 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
318: hkn0632:1743760:1743760 [2] NCCL INFO P2P plugin IBext
326: hkn0634:1506052:1506052 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
326: hkn0634:1506052:1506052 [2] NCCL INFO P2P plugin IBext
325: hkn0634:1506024:1506024 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
325: hkn0634:1506024:1506024 [1] NCCL INFO P2P plugin IBext
490: hkn0809:922569:922569 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
490: hkn0809:922569:922569 [2] NCCL INFO Using network IBext
327: hkn0634:1506040:1506040 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
327: hkn0634:1506040:1506040 [3] NCCL INFO P2P plugin IBext
319: hkn0632:1743781:1743781 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
324: hkn0634:1506032:1506032 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
324: hkn0634:1506032:1506032 [0] NCCL INFO P2P plugin IBext
316: hkn0632:1743761:1743761 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
316: hkn0632:1743761:1743761 [0] NCCL INFO P2P plugin IBext
327: hkn0634:1506040:1506040 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
327: hkn0634:1506040:1506040 [3] NCCL INFO Using network IBext
324: hkn0634:1506032:1506032 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
324: hkn0634:1506032:1506032 [0] NCCL INFO Using network IBext
319: hkn0632:1743781:1743781 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
319: hkn0632:1743781:1743781 [3] NCCL INFO P2P plugin IBext
317: hkn0632:1743769:1743769 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
316: hkn0632:1743761:1743761 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
316: hkn0632:1743761:1743761 [0] NCCL INFO Using network IBext
318: hkn0632:1743760:1743760 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
318: hkn0632:1743760:1743760 [2] NCCL INFO Using network IBext
325: hkn0634:1506024:1506024 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
326: hkn0634:1506052:1506052 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
325: hkn0634:1506024:1506024 [1] NCCL INFO Using network IBext
326: hkn0634:1506052:1506052 [2] NCCL INFO Using network IBext
319: hkn0632:1743781:1743781 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
319: hkn0632:1743781:1743781 [3] NCCL INFO Using network IBext
317: hkn0632:1743769:1743769 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
317: hkn0632:1743769:1743769 [1] NCCL INFO P2P plugin IBext
317: hkn0632:1743769:1743769 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
317: hkn0632:1743769:1743769 [1] NCCL INFO Using network IBext
324: hkn0634:1506032:1506151 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
381: hkn0715:387096:387223 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
367: hkn0711:569054:569153 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
325: hkn0634:1506024:1506157 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
326: hkn0634:1506052:1506156 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
327: hkn0634:1506040:1506149 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
366: hkn0711:569042:569160 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
380: hkn0715:387124:387215 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
364: hkn0711:569026:569156 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
365: hkn0711:569034:569157 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
345: hkn0705:768401:768516 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
382: hkn0715:387104:387217 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
389: hkn0717:4172715:4172825 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
339: hkn0703:726146:726263 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
383: hkn0715:387112:387222 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
338: hkn0703:726147:726262 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
181: hkn0526:1413569:1413673 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
315: hkn0631:1006960:1007067 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
344: hkn0705:768421:768521 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
321: hkn0633:1511514:1511639 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
160: hkn0520:2697999:2698118 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
328: hkn0635:1210747:1210870 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
346: hkn0705:768409:768518 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
393: hkn0718:3902174:3902293 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
347: hkn0705:768400:768514 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
336: hkn0703:726160:726259 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
337: hkn0703:726148:726258 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
307: hkn0629:1577178:1577305 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
391: hkn0717:4172703:4172819 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
180: hkn0526:1413561:1413674 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
282: hkn0622:2005581:2005688 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
292: hkn0626:1283594:1283703 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
394: hkn0718:3902173:3902289 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
320: hkn0633:1511506:1511630 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
436: hkn0731:1371920:1372018 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
316: hkn0632:1743761:1743906 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
312: hkn0631:1006952:1007073 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
386: hkn0716:93666:93764 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
182: hkn0526:1413581:1413675 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
388: hkn0717:4172687:4172818 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
407: hkn0721:2284151:2284268 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
372: hkn0713:455428:455539 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
161: hkn0520:2698015:2698119 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
390: hkn0717:4172695:4172824 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
183: hkn0526:1413553:1413678 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
378: hkn0714:417196:417322 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
240: hkn0607:889534:889628 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
294: hkn0626:1283606:1283705 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
392: hkn0718:3902194:3902291 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
351: hkn0706:737447:737575 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
323: hkn0633:1511534:1511635 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
361: hkn0710:340632:340748 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
430: hkn0728:1309110:1309210 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
395: hkn0718:3902182:3902290 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
306: hkn0629:1577206:1577307 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
492: hkn0810:924748:924846 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
162: hkn0520:2698027:2698123 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
404: hkn0721:2284143:2284269 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
276: hkn0621:1976635:1976739 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
330: hkn0635:1210755:1210867 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
295: hkn0626:1283583:1283699 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
208: hkn0534:1133577:1133694 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
375: hkn0713:455441:455538 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
360: hkn0710:340644:340742 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
322: hkn0633:1511522:1511638 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
283: hkn0622:2005565:2005687 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
174: hkn0524:1118942:1119055 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
255: hkn0611:694957:695086 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
293: hkn0626:1283586:1283696 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
331: hkn0635:1210773:1210865 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
341: hkn0704:777142:777272 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
313: hkn0631:1006972:1007066 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
438: hkn0731:1371892:1372022 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
163: hkn0520:2698007:2698122 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
314: hkn0631:1006951:1007072 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
304: hkn0629:1577186:1577310 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
440: hkn0732:1196819:1196963 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
207: hkn0532:908790:909100 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
329: hkn0635:1210739:1210866 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
409: hkn0723:192925:193085 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
406: hkn0721:2284171:2284267 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
385: hkn0716:93646:93761 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
281: hkn0622:2005573:2005694 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
445: hkn0733:1374570:1374664 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
305: hkn0629:1577194:1577306 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
243: hkn0607:889506:889630 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
374: hkn0713:455429:455542 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
363: hkn0710:340631:340745 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
193: hkn0529:1526023:1526124 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
358: hkn0708:398424:398526 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
405: hkn0721:2284159:2284270 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
145: hkn0513:2998098:2998200 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
376: hkn0714:417195:417320 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
387: hkn0716:93654:93766 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
167: hkn0521:1182990:1183086 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
280: hkn0622:2005593:2005692 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
373: hkn0713:455427:455540 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
317: hkn0632:1743769:1743914 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
508: hkn0816:360788:360900 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
229: hkn0604:674466:674561 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
303: hkn0628:656987:657106 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
349: hkn0706:737463:737570 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
429: hkn0728:1309098:1309209 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
242: hkn0607:889522:889635 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
384: hkn0716:93645:93760 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
399: hkn0719:1290839:1290961 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
221: hkn0602:3345235:3345487 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
340: hkn0704:777158:777265 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
226: hkn0603:1398315:1398422 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
362: hkn0710:340630:340740 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
215: hkn0535:2384173:2384300 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
154: hkn0515:2881950:2882069 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
277: hkn0621:1976619:1976745 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
247: hkn0608:470914:471033 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
241: hkn0607:889514:889633 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
431: hkn0728:1309090:1309203 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
464: hkn0803:861669:861771 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
439: hkn0731:1371900:1372017 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
210: hkn0534:1133593:1133689 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
175: hkn0524:1118950:1119063 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
357: hkn0708:398436:398520 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
319: hkn0632:1743781:1743911 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
348: hkn0706:737455:737573 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
377: hkn0714:417216:417317 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
189: hkn0528:1286847:1286970 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  8: hkn0405:3191892:3192005 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
164: hkn0521:1182978:1183084 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
201: hkn0531:1215724:1215823 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
254: hkn0611:694965:695087 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
452: hkn0736:1493537:1493642 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
437: hkn0731:1371908:1372021 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
205: hkn0532:908774:909097 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
144: hkn0513:2998090:2998209 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
379: hkn0714:417204:417316 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
343: hkn0704:777170:777274 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
318: hkn0632:1743760:1743909 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
359: hkn0708:398415:398522 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
493: hkn0810:924720:924850 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
428: hkn0728:1309082:1309204 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
350: hkn0706:737475:737567 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
231: hkn0604:674454:674562 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
251: hkn0609:696044:696154 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
262: hkn0613:887824:887976 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
443: hkn0732:1196831:1196956 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
422: hkn0726:1533298:1533416 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
172: hkn0524:1118962:1119061 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
209: hkn0534:1133578:1133691 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
222: hkn0602:3345207:3345482 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
267: hkn0615:399435:399549 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
356: hkn0708:398416:398525 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
278: hkn0621:1976647:1976747 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
146: hkn0513:2998110:2998204 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 47: hkn0415:2481502:2481621 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
354: hkn0707:4005065:4005191 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
411: hkn0723:192909:193084 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
301: hkn0628:657007:657097 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 16: hkn0408:2875836:2875939 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
186: hkn0527:1334041:1334160 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
168: hkn0523:1533186:1533298 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
237: hkn0606:2357183:2357320 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
194: hkn0529:1526011:1526128 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
173: hkn0524:1118934:1119058 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
432: hkn0730:1386910:1387019 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
211: hkn0534:1133581:1133690 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 30: hkn0411:2301012:2301139 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
398: hkn0719:1290848:1290952 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
447: hkn0733:1374550:1374661 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
279: hkn0621:1976627:1976741 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
253: hkn0611:694985:695081 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  0: hkn0403:1738669:1739051 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
416: hkn0725:3097110:3097192 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
454: hkn0736:1493528:1493648 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
342: hkn0704:777150:777271 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
442: hkn0732:1196803:1196961 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
397: hkn0719:1290860:1290956 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
206: hkn0532:908802:909093 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
230: hkn0604:674446:674565 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
368: hkn0712:280251:280359 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
204: hkn0532:908782:909098 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
263: hkn0613:887832:887970 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
302: hkn0628:656986:657104 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
244: hkn0608:470923:471037 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
166: hkn0521:1182970:1183090 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
228: hkn0604:674438:674558 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
147: hkn0513:2998082:2998206 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
250: hkn0609:696036:696151 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 63: hkn0420:3195346:3195463 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
396: hkn0719:1290840:1290959 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 11: hkn0405:3191884:3191996 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
300: hkn0628:656995:657105 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
165: hkn0521:1182962:1183092 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
200: hkn0531:1215696:1215820 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
420: hkn0726:1533318:1533412 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
450: hkn0734:1141720:1141848 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
252: hkn0611:694973:695080 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
203: hkn0531:1215704:1215819 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 37: hkn0413:2351826:2351942 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 33: hkn0412:2247562:2247671 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
441: hkn0732:1196811:1196965 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
236: hkn0606:2357167:2357319 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
455: hkn0736:1493529:1493646 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
311: hkn0630:1583636:1583760 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
408: hkn0723:192917:193087 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
195: hkn0529:1526003:1526130 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
355: hkn0707:4005093:4005183 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
159: hkn0516:2901136:2901292 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
511: hkn0816:360780:360901 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
260: hkn0613:887844:887968 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
225: hkn0603:1398307:1398426 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
179: hkn0525:971983:972104 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
214: hkn0535:2384181:2384305 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
152: hkn0515:2881970:2882070 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
446: hkn0733:1374549:1374669 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
453: hkn0736:1493549:1493641 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 15: hkn0407:1801457:1801568 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
495: hkn0810:924736:924852 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
202: hkn0531:1215712:1215824 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
353: hkn0707:4005073:4005192 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
308: hkn0630:1583656:1583761 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
192: hkn0529:1525995:1526126 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
423: hkn0726:1533306:1533413 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
465: hkn0803:861667:861779 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
153: hkn0515:2881958:2882071 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
502: hkn0814:660989:661111 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
473: hkn0805:1097263:1097382 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
245: hkn0608:470935:471034 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
114: hkn0505:2288957:2289067 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
421: hkn0726:1533295:1533418 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
419: hkn0725:3097098:3097193 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
134: hkn0510:2747248:2747351 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
235: hkn0605:697250:697395 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
352: hkn0707:4005081:4005188 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
494: hkn0810:924728:924849 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 10: hkn0405:3191876:3192004 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
220: hkn0602:3345223:3345484 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
191: hkn0528:1286875:1286972 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
223: hkn0602:3345215:3345483 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
249: hkn0609:696028:696150 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
444: hkn0733:1374558:1374666 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
264: hkn0615:399427:399550 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
261: hkn0613:887816:887974 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
238: hkn0606:2357175:2357324 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
309: hkn0630:1583628:1583756 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
410: hkn0723:192937:193090 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
510: hkn0816:360796:360907 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
369: hkn0712:280243:280361 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
256: hkn0612:902120:902251 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 45: hkn0415:2481516:2481618 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
239: hkn0606:2357195:2357321 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 98: hkn0501:1312966:1313101 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
418: hkn0725:3097089:3097197 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  9: hkn0405:3191904:3192003 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 13: hkn0407:1801441:1801573 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
425: hkn0727:1330936:1331042 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
246: hkn0608:470915:471032 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  6: hkn0404:1324539:1324635 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
248: hkn0609:696056:696155 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 21: hkn0409:2570850:2570977 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
370: hkn0712:280242:280355 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 55: hkn0418:1854333:1854449 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
310: hkn0630:1583644:1583757 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
227: hkn0603:1398303:1398428 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
213: hkn0535:2384189:2384302 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
509: hkn0816:360808:360905 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
190: hkn0528:1286863:1286971 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
417: hkn0725:3097090:3097194 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
233: hkn0605:697262:697393 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
155: hkn0515:2881942:2882062 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 17: hkn0408:2875824:2875937 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
266: hkn0615:399419:399548 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
434: hkn0730:1386902:1387024 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
224: hkn0603:1398327:1398423 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
265: hkn0615:399447:399552 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
466: hkn0803:861668:861780 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
212: hkn0535:2384201:2384301 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
270: hkn0616:389969:390099 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 68: hkn0422:4138173:4138299 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
258: hkn0612:902136:902248 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
335: hkn0636:1639362:1639461 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
451: hkn0734:1141736:1141845 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 23: hkn0409:2570858:2570973 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
111: hkn0504:25981:26087 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
185: hkn0527:1334057:1334167 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 12: hkn0407:1801469:1801564 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 31: hkn0411:2301028:2301136 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
274: hkn0617:2279774:2279896 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
371: hkn0712:280263:280354 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 14: hkn0407:1801449:1801570 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
234: hkn0605:697234:697394 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 44: hkn0415:2481503:2481619 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
112: hkn0505:2288969:2289061 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  3: hkn0403:1738677:1739059 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
461: hkn0802:1185499:1185610 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
184: hkn0527:1334049:1334169 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
467: hkn0803:861681:861778 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
475: hkn0805:1097283:1097377 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
137: hkn0511:3051503:3051608 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
171: hkn0523:1533178:1533297 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
187: hkn0527:1334069:1334163 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 88: hkn0427:1120324:1120446 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
130: hkn0509:3109548:3109677 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
176: hkn0525:971975:972098 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
232: hkn0605:697242:697386 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
259: hkn0612:902148:902244 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 39: hkn0413:2351834:2351947 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
472: hkn0805:1097255:1097378 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
482: hkn0807:1004292:1004392 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 62: hkn0420:3195366:3195465 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
156: hkn0516:2901152:2901289 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
424: hkn0727:1330945:1331038 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
435: hkn0730:1386922:1387017 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 46: hkn0415:2481504:2481617 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 51: hkn0417:2252746:2252861 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
188: hkn0528:1286855:1286975 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  2: hkn0403:1738697:1739060 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
427: hkn0727:1330957:1331044 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
257: hkn0612:902128:902247 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 19: hkn0408:2875816:2875935 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
332: hkn0636:1639342:1639458 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
474: hkn0805:1097271:1097381 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
501: hkn0814:661009:661108 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 29: hkn0411:2301040:2301137 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 32: hkn0412:2247570:2247665 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 56: hkn0419:1529464:1529580 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
271: hkn0616:389985:390100 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
412: hkn0724:1701140:1701248 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 25: hkn0410:1144790:1144895 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
157: hkn0516:2901164:2901294 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 18: hkn0408:2875808:2875934 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
334: hkn0636:1639350:1639453 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
113: hkn0505:2288949:2289068 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
433: hkn0730:1386894:1387025 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
426: hkn0727:1330937:1331047 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
449: hkn0734:1141728:1141851 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 22: hkn0409:2570866:2570968 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 38: hkn0413:2351846:2351938 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
170: hkn0523:1533170:1533292 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
177: hkn0525:971991:972103 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
129: hkn0509:3109564:3109680 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 61: hkn0420:3195354:3195457 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  7: hkn0404:1324519:1324638 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
333: hkn0636:1639334:1639456 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
476: hkn0806:1039501:1039609 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 54: hkn0418:1854325:1854445 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 36: hkn0413:2351818:2351944 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 91: hkn0427:1120333:1120440 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
269: hkn0616:389977:390103 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
135: hkn0510:2747228:2747349 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
448: hkn0734:1141748:1141849 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
158: hkn0516:2901144:2901290 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 60: hkn0420:3195338:3195466 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
115: hkn0505:2288941:2289062 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
287: hkn0623:1857898:1858023 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
169: hkn0523:1533198:1533289 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
275: hkn0617:2279766:2279891 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
178: hkn0525:972003:972097 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  1: hkn0403:1738685:1739058 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 20: hkn0409:2570878:2570976 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 28: hkn0411:2301020:2301135 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
268: hkn0616:389997:390101 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 34: hkn0412:2247554:2247673 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
272: hkn0617:2279782:2279893 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
131: hkn0509:3109556:3109675 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 96: hkn0501:1312974:1313097 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
414: hkn0724:1701124:1701254 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 64: hkn0421:2163508:2163779 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
290: hkn0624:1758086:1758202 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
463: hkn0802:1185491:1185618 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
105: hkn0503:2884817:2884916 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
273: hkn0617:2279794:2279887 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
478: hkn0806:1039513:1039607 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
128: hkn0509:3109576:3109676 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 35: hkn0412:2247582:2247669 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 70: hkn0422:4138165:4138293 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
481: hkn0807:1004271:1004387 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
500: hkn0814:660997:661104 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
136: hkn0511:3051475:3051605 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 90: hkn0427:1120345:1120439 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
480: hkn0807:1004272:1004391 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
110: hkn0504:25993:26089 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 97: hkn0501:1312996:1313099 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 53: hkn0418:1854353:1854450 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
479: hkn0806:1039493:1039614 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
413: hkn0724:1701132:1701247 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
108: hkn0504:25965:26094 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
483: hkn0807:1004280:1004394 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
286: hkn0623:1857878:1858024 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
503: hkn0814:660981:661105 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 26: hkn0410:1144773:1144892 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 69: hkn0422:4138181:4138294 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 73: hkn0423:1689969:1690080 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
460: hkn0802:1185519:1185612 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
151: hkn0514:2935901:2936013 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
477: hkn0806:1039485:1039615 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
138: hkn0511:3051491:3051603 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  4: hkn0404:1324511:1324629 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 52: hkn0418:1854341:1854446 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 71: hkn0422:4138193:4138296 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 89: hkn0427:1120325:1120445 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
104: hkn0503:2884789:2884923 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
415: hkn0724:1701152:1701251 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
133: hkn0510:2747236:2747343 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  5: hkn0404:1324527:1324632 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
132: hkn0510:2747220:2747346 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
462: hkn0802:1185507:1185616 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
109: hkn0504:25973:26092 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 59: hkn0419:1529462:1529576 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
285: hkn0623:1857886:1858018 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 49: hkn0417:2252738:2252863 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 99: hkn0501:1312982:1313098 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 27: hkn0410:1144778:1144896 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 95: hkn0428:652509:652633 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 66: hkn0421:2163516:2163782 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
497: hkn0812:678921:679031 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
139: hkn0511:3051483:3051604 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
106: hkn0503:2884805:2884921 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 43: hkn0414:1966712:1966819 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
291: hkn0624:1758078:1758198 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 24: hkn0410:1144774:1144891 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
289: hkn0624:1758098:1758200 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 65: hkn0421:2163528:2163777 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
107: hkn0503:2884797:2884917 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 57: hkn0419:1529484:1529583 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 50: hkn0417:2252730:2252862 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
284: hkn0623:1857870:1858027 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 81: hkn0425:2069090:2069201 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
127: hkn0508:3124313:3124406 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
103: hkn0502:214196:214352 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
288: hkn0624:1758070:1758195 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 67: hkn0421:2163500:2163778 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
141: hkn0512:3029294:3029422 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 48: hkn0417:2252758:2252860 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 58: hkn0419:1529472:1529584 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
149: hkn0514:2935893:2936011 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
150: hkn0514:2935913:2936009 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 75: hkn0423:1689977:1690087 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
400: hkn0720:4181520:4181819 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
148: hkn0514:2935885:2936010 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 42: hkn0414:1966704:1966820 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
101: hkn0502:214224:214351 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
401: hkn0720:4181528:4181827 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
125: hkn0508:3124305:3124410 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 72: hkn0423:1689989:1690089 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 77: hkn0424:2933097:2933239 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
485: hkn0808:955879:955981 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
140: hkn0512:3029302:3029419 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
488: hkn0809:922553:922675 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
402: hkn0720:4181548:4181824 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
142: hkn0512:3029322:3029415 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
102: hkn0502:214204:214346 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 41: hkn0414:1966724:1966822 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
100: hkn0502:214212:214345 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 92: hkn0428:652537:652628 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 94: hkn0428:652525:652632 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
499: hkn0812:678941:679039 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 93: hkn0428:652517:652634 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
143: hkn0512:3029310:3029418 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
124: hkn0508:3124325:3124404 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 74: hkn0423:1689961:1690083 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
117: hkn0506:823185:823311 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 40: hkn0414:1966696:1966821 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
217: hkn0601:102836:102938 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 79: hkn0424:2933081:2933238 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
403: hkn0720:4181536:4181828 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 78: hkn0424:2933089:2933240 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
126: hkn0508:3124297:3124412 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
496: hkn0812:678913:679036 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 76: hkn0424:2933109:2933241 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
489: hkn0809:922561:922677 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 82: hkn0425:2069118:2069202 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
116: hkn0506:823193:823308 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
498: hkn0812:678929:679040 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 83: hkn0425:2069106:2069204 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 80: hkn0425:2069098:2069207 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
470: hkn0804:1190787:1190892 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
122: hkn0507:3172208:3172331 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
459: hkn0801:2225102:2225219 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
490: hkn0809:922569:922682 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
486: hkn0808:955867:955976 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
491: hkn0809:922581:922679 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
297: hkn0627:1773070:1773181 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
504: hkn0815:380357:380455 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
484: hkn0808:955851:955982 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 85: hkn0426:799266:799362 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
487: hkn0808:955859:955975 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
219: hkn0601:102808:102935 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
118: hkn0506:823201:823314 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
218: hkn0601:102824:102933 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
119: hkn0506:823213:823305 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
199: hkn0530:1243337:1243436 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
456: hkn0801:2225122:2225226 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
299: hkn0627:1773082:1773180 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
198: hkn0530:1243309:1243429 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
457: hkn0801:2225101:2225223 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
120: hkn0507:3172228:3172326 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
197: hkn0530:1243325:1243432 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
458: hkn0801:2225110:2225221 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
506: hkn0815:380337:380459 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
298: hkn0627:1773054:1773175 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
296: hkn0627:1773062:1773179 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
216: hkn0601:102816:102929 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
505: hkn0815:380329:380451 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 84: hkn0426:799238:799364 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
471: hkn0804:1190762:1190887 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 87: hkn0426:799254:799358 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
507: hkn0815:380345:380457 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
468: hkn0804:1190767:1190886 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
121: hkn0507:3172216:3172329 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 86: hkn0426:799246:799367 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
123: hkn0507:3172200:3172323 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
469: hkn0804:1190775:1190890 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
196: hkn0530:1243317:1243433 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
237: hkn0606:2357183:2357320 [1] NCCL INFO Trees [0] 238/-1/-1->237->236 [1] 238/244/-1->237->236
407: hkn0721:2284151:2284268 [3] NCCL INFO Trees [0] -1/-1/-1->407->406 [1] -1/-1/-1->407->406
239: hkn0606:2357195:2357321 [3] NCCL INFO Trees [0] -1/-1/-1->239->238 [1] -1/-1/-1->239->238
237: hkn0606:2357183:2357320 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
407: hkn0721:2284151:2284268 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
239: hkn0606:2357195:2357321 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
238: hkn0606:2357175:2357324 [2] NCCL INFO Trees [0] 239/-1/-1->238->237 [1] 239/-1/-1->238->237
238: hkn0606:2357175:2357324 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
240: hkn0607:889534:889628 [0] NCCL INFO Trees [0] 241/248/-1->240->224 [1] 241/-1/-1->240->244
410: hkn0723:192937:193090 [2] NCCL INFO Trees [0] 411/-1/-1->410->409 [1] 411/-1/-1->410->409
405: hkn0721:2284159:2284270 [1] NCCL INFO Trees [0] 406/-1/-1->405->404 [1] 406/408/-1->405->404
405: hkn0721:2284159:2284270 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
240: hkn0607:889534:889628 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
414: hkn0724:1701124:1701254 [2] NCCL INFO Trees [0] 415/-1/-1->414->413 [1] 415/-1/-1->414->413
406: hkn0721:2284171:2284267 [2] NCCL INFO Trees [0] 407/-1/-1->406->405 [1] 407/-1/-1->406->405
406: hkn0721:2284171:2284267 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
410: hkn0723:192937:193090 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
414: hkn0724:1701124:1701254 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
242: hkn0607:889522:889635 [2] NCCL INFO Trees [0] 243/-1/-1->242->241 [1] 243/-1/-1->242->241
408: hkn0723:192917:193087 [0] NCCL INFO Trees [0] 409/412/-1->408->400 [1] 409/-1/-1->408->405
415: hkn0724:1701152:1701251 [3] NCCL INFO Trees [0] -1/-1/-1->415->414 [1] -1/-1/-1->415->414
416: hkn0725:3097110:3097192 [0] NCCL INFO Trees [0] 417/432/-1->416->449 [1] 417/-1/-1->416->420
241: hkn0607:889514:889633 [1] NCCL INFO Trees [0] 242/232/-1->241->240 [1] 242/-1/-1->241->240
409: hkn0723:192925:193085 [1] NCCL INFO Trees [0] 410/404/-1->409->408 [1] 410/-1/-1->409->408
409: hkn0723:192925:193085 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
416: hkn0725:3097110:3097192 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
404: hkn0721:2284143:2284269 [0] NCCL INFO Trees [0] 405/-1/-1->404->409 [1] 405/400/-1->404->397
246: hkn0608:470915:471032 [2] NCCL INFO Trees [0] 247/-1/-1->246->245 [1] 247/-1/-1->246->245
236: hkn0606:2357167:2357319 [0] NCCL INFO Trees [0] 237/-1/-1->236->232 [1] 237/228/-1->236->221
242: hkn0607:889522:889635 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
411: hkn0723:192909:193084 [3] NCCL INFO Trees [0] -1/-1/-1->411->410 [1] -1/-1/-1->411->410
411: hkn0723:192909:193084 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
422: hkn0726:1533298:1533416 [2] NCCL INFO Trees [0] 423/-1/-1->422->421 [1] 423/-1/-1->422->421
415: hkn0724:1701152:1701251 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
404: hkn0721:2284143:2284269 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
246: hkn0608:470915:471032 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
243: hkn0607:889506:889630 [3] NCCL INFO Trees [0] -1/-1/-1->243->242 [1] -1/-1/-1->243->242
408: hkn0723:192917:193087 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
422: hkn0726:1533298:1533416 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
413: hkn0724:1701132:1701247 [1] NCCL INFO Trees [0] 414/-1/-1->413->412 [1] 414/428/-1->413->412
413: hkn0724:1701132:1701247 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
235: hkn0605:697250:697395 [3] NCCL INFO Trees [0] -1/-1/-1->235->234 [1] -1/-1/-1->235->234
417: hkn0725:3097090:3097194 [1] NCCL INFO Trees [0] 418/400/-1->417->416 [1] 418/-1/-1->417->416
417: hkn0725:3097090:3097194 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
241: hkn0607:889514:889633 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
403: hkn0720:4181536:4181828 [3] NCCL INFO Trees [0] -1/-1/-1->403->402 [1] -1/-1/-1->403->402
412: hkn0724:1701140:1701248 [0] NCCL INFO Trees [0] 413/-1/-1->412->408 [1] 413/396/-1->412->444
235: hkn0605:697250:697395 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
418: hkn0725:3097089:3097197 [2] NCCL INFO Trees [0] 419/-1/-1->418->417 [1] 419/-1/-1->418->417
251: hkn0609:696044:696154 [3] NCCL INFO Trees [0] -1/-1/-1->251->250 [1] -1/-1/-1->251->250
243: hkn0607:889506:889630 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
403: hkn0720:4181536:4181828 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
421: hkn0726:1533295:1533418 [1] NCCL INFO Trees [0] 422/-1/-1->421->420 [1] 422/424/-1->421->420
421: hkn0726:1533295:1533418 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
412: hkn0724:1701140:1701248 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
233: hkn0605:697262:697393 [1] NCCL INFO Trees [0] 234/228/-1->233->232 [1] 234/-1/-1->233->232
418: hkn0725:3097089:3097197 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
248: hkn0609:696056:696155 [0] NCCL INFO Trees [0] 249/252/-1->248->240 [1] 249/-1/-1->248->245
401: hkn0720:4181528:4181827 [1] NCCL INFO Trees [0] 402/392/-1->401->400 [1] 402/-1/-1->401->400
420: hkn0726:1533318:1533412 [0] NCCL INFO Trees [0] 421/-1/-1->420->425 [1] 421/416/-1->420->428
425: hkn0727:1330936:1331042 [1] NCCL INFO Trees [0] 426/420/-1->425->424 [1] 426/-1/-1->425->424
233: hkn0605:697262:697393 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
419: hkn0725:3097098:3097193 [3] NCCL INFO Trees [0] -1/-1/-1->419->418 [1] -1/-1/-1->419->418
236: hkn0606:2357167:2357319 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
251: hkn0609:696044:696154 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
401: hkn0720:4181528:4181827 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
420: hkn0726:1533318:1533412 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
234: hkn0605:697234:697394 [2] NCCL INFO Trees [0] 235/-1/-1->234->233 [1] 235/-1/-1->234->233
419: hkn0725:3097098:3097193 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
244: hkn0608:470923:471037 [0] NCCL INFO Trees [0] 245/-1/-1->244->249 [1] 245/240/-1->244->237
244: hkn0608:470923:471037 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
248: hkn0609:696056:696155 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
234: hkn0605:697234:697394 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
245: hkn0608:470935:471034 [1] NCCL INFO Trees [0] 246/-1/-1->245->244 [1] 246/248/-1->245->244
245: hkn0608:470935:471034 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
249: hkn0609:696028:696150 [1] NCCL INFO Trees [0] 250/244/-1->249->248 [1] 250/-1/-1->249->248
249: hkn0609:696028:696150 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
423: hkn0726:1533306:1533413 [3] NCCL INFO Trees [0] -1/-1/-1->423->422 [1] -1/-1/-1->423->422
423: hkn0726:1533306:1533413 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
247: hkn0608:470914:471033 [3] NCCL INFO Trees [0] -1/-1/-1->247->246 [1] -1/-1/-1->247->246
247: hkn0608:470914:471033 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
250: hkn0609:696036:696151 [2] NCCL INFO Trees [0] 251/-1/-1->250->249 [1] 251/-1/-1->250->249
250: hkn0609:696036:696151 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
231: hkn0604:674454:674562 [3] NCCL INFO Trees [0] -1/-1/-1->231->230 [1] -1/-1/-1->231->230
430: hkn0728:1309110:1309210 [2] NCCL INFO Trees [0] 431/-1/-1->430->429 [1] 431/-1/-1->430->429
425: hkn0727:1330936:1331042 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
231: hkn0604:674454:674562 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
402: hkn0720:4181548:4181824 [2] NCCL INFO Trees [0] 403/-1/-1->402->401 [1] 403/-1/-1->402->401
430: hkn0728:1309110:1309210 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
424: hkn0727:1330945:1331038 [0] NCCL INFO Trees [0] 425/428/-1->424->433 [1] 425/-1/-1->424->421
232: hkn0605:697242:697386 [0] NCCL INFO Trees [0] 233/236/-1->232->241 [1] 233/-1/-1->232->229
402: hkn0720:4181548:4181824 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
432: hkn0730:1386910:1387019 [0] NCCL INFO Trees [0] 433/440/-1->432->416 [1] 433/-1/-1->432->436
426: hkn0727:1330937:1331047 [2] NCCL INFO Trees [0] 427/-1/-1->426->425 [1] 427/-1/-1->426->425
426: hkn0727:1330937:1331047 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
232: hkn0605:697242:697386 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
428: hkn0728:1309082:1309204 [0] NCCL INFO Trees [0] 429/-1/-1->428->424 [1] 429/420/-1->428->413
428: hkn0728:1309082:1309204 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
427: hkn0727:1330957:1331044 [3] NCCL INFO Trees [0] -1/-1/-1->427->426 [1] -1/-1/-1->427->426
427: hkn0727:1330957:1331044 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
429: hkn0728:1309098:1309209 [1] NCCL INFO Trees [0] 430/-1/-1->429->428 [1] 430/436/-1->429->428
429: hkn0728:1309098:1309209 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
437: hkn0731:1371908:1372021 [1] NCCL INFO Trees [0] 438/-1/-1->437->436 [1] 438/440/-1->437->436
424: hkn0727:1330945:1331038 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
455: hkn0736:1493529:1493646 [3] NCCL INFO Trees [0] -1/-1/-1->455->454 [1] -1/-1/-1->455->454
400: hkn0720:4181520:4181819 [0] NCCL INFO Trees [0] 401/408/-1->400->417 [1] 401/-1/-1->400->404
431: hkn0728:1309090:1309203 [3] NCCL INFO Trees [0] -1/-1/-1->431->430 [1] -1/-1/-1->431->430
431: hkn0728:1309090:1309203 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
438: hkn0731:1371892:1372022 [2] NCCL INFO Trees [0] 439/-1/-1->438->437 [1] 439/-1/-1->438->437
438: hkn0731:1371892:1372022 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
432: hkn0730:1386910:1387019 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
445: hkn0733:1374570:1374664 [1] NCCL INFO Trees [0] 446/-1/-1->445->444 [1] 446/476/-1->445->444
482: hkn0807:1004292:1004392 [2] NCCL INFO Trees [0] 483/-1/-1->482->481 [1] 483/-1/-1->482->481
482: hkn0807:1004292:1004392 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
475: hkn0805:1097283:1097377 [3] NCCL INFO Trees [0] -1/-1/-1->475->474 [1] -1/-1/-1->475->474
478: hkn0806:1039513:1039607 [2] NCCL INFO Trees [0] 479/-1/-1->478->477 [1] 479/-1/-1->478->477
400: hkn0720:4181520:4181819 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
437: hkn0731:1371908:1372021 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
434: hkn0730:1386902:1387024 [2] NCCL INFO Trees [0] 435/-1/-1->434->433 [1] 435/-1/-1->434->433
445: hkn0733:1374570:1374664 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
469: hkn0804:1190775:1190890 [1] NCCL INFO Trees [0] 470/-1/-1->469->468 [1] 470/472/-1->469->468
475: hkn0805:1097283:1097377 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
464: hkn0803:861669:861771 [0] NCCL INFO Trees [0] 465/472/-1->464->481 [1] 465/-1/-1->464->468
453: hkn0736:1493549:1493641 [1] NCCL INFO Trees [0] 454/-1/-1->453->452 [1] 454/456/-1->453->452
440: hkn0732:1196819:1196963 [0] NCCL INFO Trees [0] 441/444/-1->440->432 [1] 441/-1/-1->440->437
439: hkn0731:1371900:1372017 [3] NCCL INFO Trees [0] -1/-1/-1->439->438 [1] -1/-1/-1->439->438
434: hkn0730:1386902:1387024 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
447: hkn0733:1374550:1374661 [3] NCCL INFO Trees [0] -1/-1/-1->447->446 [1] -1/-1/-1->447->446
483: hkn0807:1004280:1004394 [3] NCCL INFO Trees [0] -1/-1/-1->483->482 [1] -1/-1/-1->483->482
483: hkn0807:1004280:1004394 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
471: hkn0804:1190762:1190887 [3] NCCL INFO Trees [0] -1/-1/-1->471->470 [1] -1/-1/-1->471->470
473: hkn0805:1097263:1097382 [1] NCCL INFO Trees [0] 474/468/-1->473->472 [1] 474/-1/-1->473->472
448: hkn0734:1141748:1141849 [0] NCCL INFO Trees [0] 449/480/-1->448->384 [1] 449/-1/-1->448->452
464: hkn0803:861669:861771 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
454: hkn0736:1493528:1493648 [2] NCCL INFO Trees [0] 455/-1/-1->454->453 [1] 455/-1/-1->454->453
252: hkn0611:694973:695080 [0] NCCL INFO Trees [0] 253/-1/-1->252->248 [1] 253/124/-1->252->508
458: hkn0801:2225110:2225221 [2] NCCL INFO Trees [0] 459/-1/-1->458->457 [1] 459/-1/-1->458->457
458: hkn0801:2225110:2225221 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
476: hkn0806:1039501:1039609 [0] NCCL INFO Trees [0] 477/-1/-1->476->472 [1] 477/460/-1->476->445
439: hkn0731:1371900:1372017 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
435: hkn0730:1386922:1387017 [3] NCCL INFO Trees [0] -1/-1/-1->435->434 [1] -1/-1/-1->435->434
447: hkn0733:1374550:1374661 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
480: hkn0807:1004272:1004391 [0] NCCL INFO Trees [0] 481/496/-1->480->448 [1] 481/-1/-1->480->484
469: hkn0804:1190775:1190890 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
399: hkn0719:1290839:1290961 [3] NCCL INFO Trees [0] -1/-1/-1->399->398 [1] -1/-1/-1->399->398
461: hkn0802:1185499:1185610 [1] NCCL INFO Trees [0] 462/-1/-1->461->460 [1] 462/468/-1->461->460
485: hkn0808:955879:955981 [1] NCCL INFO Trees [0] 486/-1/-1->485->484 [1] 486/488/-1->485->484
473: hkn0805:1097263:1097382 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
448: hkn0734:1141748:1141849 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
465: hkn0803:861667:861779 [1] NCCL INFO Trees [0] 466/456/-1->465->464 [1] 466/-1/-1->465->464
465: hkn0803:861667:861779 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
455: hkn0736:1493529:1493646 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
256: hkn0612:902120:902251 [0] NCCL INFO Trees [0] 257/384/-1->256->0 [1] 257/-1/-1->256->260
478: hkn0806:1039513:1039607 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
189: hkn0528:1286847:1286970 [1] NCCL INFO Trees [0] 190/-1/-1->189->188 [1] 190/220/-1->189->188
440: hkn0732:1196819:1196963 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
436: hkn0731:1371920:1372018 [0] NCCL INFO Trees [0] 437/-1/-1->436->441 [1] 437/432/-1->436->429
433: hkn0730:1386894:1387025 [1] NCCL INFO Trees [0] 434/424/-1->433->432 [1] 434/-1/-1->433->432
446: hkn0733:1374549:1374669 [2] NCCL INFO Trees [0] 447/-1/-1->446->445 [1] 447/-1/-1->446->445
481: hkn0807:1004271:1004387 [1] NCCL INFO Trees [0] 482/464/-1->481->480 [1] 482/-1/-1->481->480
481: hkn0807:1004271:1004387 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
471: hkn0804:1190762:1190887 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
399: hkn0719:1290839:1290961 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
462: hkn0802:1185507:1185616 [2] NCCL INFO Trees [0] 463/-1/-1->462->461 [1] 463/-1/-1->462->461
485: hkn0808:955879:955981 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
474: hkn0805:1097271:1097381 [2] NCCL INFO Trees [0] 475/-1/-1->474->473 [1] 475/-1/-1->474->473
451: hkn0734:1141736:1141845 [3] NCCL INFO Trees [0] -1/-1/-1->451->450 [1] -1/-1/-1->451->450
466: hkn0803:861668:861780 [2] NCCL INFO Trees [0] 467/-1/-1->466->465 [1] 467/-1/-1->466->465
466: hkn0803:861668:861780 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
453: hkn0736:1493549:1493641 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
261: hkn0613:887816:887974 [1] NCCL INFO Trees [0] 262/-1/-1->261->260 [1] 262/264/-1->261->260
252: hkn0611:694973:695080 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
229: hkn0604:674466:674561 [1] NCCL INFO Trees [0] 230/-1/-1->229->228 [1] 230/232/-1->229->228
459: hkn0801:2225102:2225219 [3] NCCL INFO Trees [0] -1/-1/-1->459->458 [1] -1/-1/-1->459->458
256: hkn0612:902120:902251 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
476: hkn0806:1039501:1039609 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
189: hkn0528:1286847:1286970 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
193: hkn0529:1526023:1526124 [1] NCCL INFO Trees [0] 194/160/-1->193->192 [1] 194/-1/-1->193->192
441: hkn0732:1196811:1196965 [1] NCCL INFO Trees [0] 442/436/-1->441->440 [1] 442/-1/-1->441->440
441: hkn0732:1196811:1196965 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
436: hkn0731:1371920:1372018 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
435: hkn0730:1386922:1387017 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
446: hkn0733:1374549:1374669 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
480: hkn0807:1004272:1004391 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
470: hkn0804:1190787:1190892 [2] NCCL INFO Trees [0] 471/-1/-1->470->469 [1] 471/-1/-1->470->469
461: hkn0802:1185499:1185610 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
486: hkn0808:955867:955976 [2] NCCL INFO Trees [0] 487/-1/-1->486->485 [1] 487/-1/-1->486->485
486: hkn0808:955867:955976 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
472: hkn0805:1097255:1097378 [0] NCCL INFO Trees [0] 473/476/-1->472->464 [1] 473/-1/-1->472->469
451: hkn0734:1141736:1141845 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
467: hkn0803:861681:861778 [3] NCCL INFO Trees [0] -1/-1/-1->467->466 [1] -1/-1/-1->467->466
467: hkn0803:861681:861778 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
454: hkn0736:1493528:1493648 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
488: hkn0809:922553:922675 [0] NCCL INFO Trees [0] 489/492/-1->488->497 [1] 489/-1/-1->488->485
488: hkn0809:922553:922675 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
260: hkn0613:887844:887968 [0] NCCL INFO Trees [0] 261/-1/-1->260->265 [1] 261/256/-1->260->268
253: hkn0611:694985:695081 [1] NCCL INFO Trees [0] 254/-1/-1->253->252 [1] 254/380/-1->253->252
253: hkn0611:694985:695081 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
266: hkn0615:399419:399548 [2] NCCL INFO Trees [0] 267/-1/-1->266->265 [1] 267/-1/-1->266->265
229: hkn0604:674466:674561 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
459: hkn0801:2225102:2225219 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
477: hkn0806:1039485:1039615 [1] NCCL INFO Trees [0] 478/-1/-1->477->476 [1] 478/492/-1->477->476
477: hkn0806:1039485:1039615 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
193: hkn0529:1526023:1526124 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
442: hkn0732:1196803:1196961 [2] NCCL INFO Trees [0] 443/-1/-1->442->441 [1] 443/-1/-1->442->441
442: hkn0732:1196803:1196961 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
433: hkn0730:1386894:1387025 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
444: hkn0733:1374558:1374666 [0] NCCL INFO Trees [0] 445/-1/-1->444->440 [1] 445/412/-1->444->381
470: hkn0804:1190787:1190892 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
462: hkn0802:1185507:1185616 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
487: hkn0808:955859:955975 [3] NCCL INFO Trees [0] -1/-1/-1->487->486 [1] -1/-1/-1->487->486
487: hkn0808:955859:955975 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
474: hkn0805:1097271:1097381 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
449: hkn0734:1141728:1141851 [1] NCCL INFO Trees [0] 450/416/-1->449->448 [1] 450/-1/-1->449->448
452: hkn0736:1493537:1493642 [0] NCCL INFO Trees [0] 453/-1/-1->452->457 [1] 453/448/-1->452->460
489: hkn0809:922561:922677 [1] NCCL INFO Trees [0] 490/484/-1->489->488 [1] 490/-1/-1->489->488
489: hkn0809:922561:922677 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
261: hkn0613:887816:887974 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
254: hkn0611:694965:695087 [2] NCCL INFO Trees [0] 255/-1/-1->254->253 [1] 255/-1/-1->254->253
254: hkn0611:694965:695087 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 37: hkn0413:2351826:2351942 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/40/-1->37->36
230: hkn0604:674446:674565 [2] NCCL INFO Trees [0] 231/-1/-1->230->229 [1] 231/-1/-1->230->229
456: hkn0801:2225122:2225226 [0] NCCL INFO Trees [0] 457/460/-1->456->465 [1] 457/-1/-1->456->453
479: hkn0806:1039493:1039614 [3] NCCL INFO Trees [0] -1/-1/-1->479->478 [1] -1/-1/-1->479->478
479: hkn0806:1039493:1039614 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
194: hkn0529:1526011:1526128 [2] NCCL INFO Trees [0] 195/-1/-1->194->193 [1] 195/-1/-1->194->193
443: hkn0732:1196831:1196956 [3] NCCL INFO Trees [0] -1/-1/-1->443->442 [1] -1/-1/-1->443->442
443: hkn0732:1196831:1196956 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
444: hkn0733:1374558:1374666 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
468: hkn0804:1190767:1190886 [0] NCCL INFO Trees [0] 469/-1/-1->468->473 [1] 469/464/-1->468->461
398: hkn0719:1290848:1290952 [2] NCCL INFO Trees [0] 399/-1/-1->398->397 [1] 399/-1/-1->398->397
205: hkn0532:908774:909097 [1] NCCL INFO Trees [0] 206/-1/-1->205->204 [1] 206/212/-1->205->204
205: hkn0532:908774:909097 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
463: hkn0802:1185491:1185618 [3] NCCL INFO Trees [0] -1/-1/-1->463->462 [1] -1/-1/-1->463->462
463: hkn0802:1185491:1185618 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
484: hkn0808:955851:955982 [0] NCCL INFO Trees [0] 485/-1/-1->484->489 [1] 485/480/-1->484->492
484: hkn0808:955851:955982 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
472: hkn0805:1097255:1097378 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
450: hkn0734:1141720:1141848 [2] NCCL INFO Trees [0] 451/-1/-1->450->449 [1] 451/-1/-1->450->449
452: hkn0736:1493537:1493642 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
490: hkn0809:922569:922682 [2] NCCL INFO Trees [0] 491/-1/-1->490->489 [1] 491/-1/-1->490->489
490: hkn0809:922569:922682 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
262: hkn0613:887824:887976 [2] NCCL INFO Trees [0] 263/-1/-1->262->261 [1] 263/-1/-1->262->261
262: hkn0613:887824:887976 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
255: hkn0611:694957:695086 [3] NCCL INFO Trees [0] -1/-1/-1->255->254 [1] -1/-1/-1->255->254
255: hkn0611:694957:695086 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
266: hkn0615:399419:399548 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
230: hkn0604:674446:674565 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
457: hkn0801:2225101:2225223 [1] NCCL INFO Trees [0] 458/452/-1->457->456 [1] 458/-1/-1->457->456
 40: hkn0414:1966696:1966821 [0] NCCL INFO Trees [0] 41/44/-1->40->49 [1] 41/-1/-1->40->37
257: hkn0612:902128:902247 [1] NCCL INFO Trees [0] 258/128/-1->257->256 [1] 258/-1/-1->257->256
188: hkn0528:1286855:1286975 [0] NCCL INFO Trees [0] 189/-1/-1->188->184 [1] 189/156/-1->188->125
195: hkn0529:1526003:1526130 [3] NCCL INFO Trees [0] -1/-1/-1->195->194 [1] -1/-1/-1->195->194
468: hkn0804:1190767:1190886 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
493: hkn0810:924720:924850 [1] NCCL INFO Trees [0] 494/-1/-1->493->492 [1] 494/500/-1->493->492
398: hkn0719:1290848:1290952 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
206: hkn0532:908802:909093 [2] NCCL INFO Trees [0] 207/-1/-1->206->205 [1] 207/-1/-1->206->205
206: hkn0532:908802:909093 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
460: hkn0802:1185519:1185612 [0] NCCL INFO Trees [0] 461/-1/-1->460->456 [1] 461/452/-1->460->476
208: hkn0534:1133577:1133694 [0] NCCL INFO Trees [0] 209/216/-1->208->225 [1] 209/-1/-1->208->212
449: hkn0734:1141728:1141851 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
227: hkn0603:1398303:1398428 [3] NCCL INFO Trees [0] -1/-1/-1->227->226 [1] -1/-1/-1->227->226
491: hkn0809:922581:922679 [3] NCCL INFO Trees [0] -1/-1/-1->491->490 [1] -1/-1/-1->491->490
491: hkn0809:922581:922679 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
260: hkn0613:887844:887968 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 37: hkn0413:2351826:2351942 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
267: hkn0615:399435:399549 [3] NCCL INFO Trees [0] -1/-1/-1->267->266 [1] -1/-1/-1->267->266
456: hkn0801:2225122:2225226 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
270: hkn0616:389969:390099 [2] NCCL INFO Trees [0] 271/-1/-1->270->269 [1] 271/-1/-1->270->269
258: hkn0612:902136:902248 [2] NCCL INFO Trees [0] 259/-1/-1->258->257 [1] 259/-1/-1->258->257
 32: hkn0412:2247570:2247665 [0] NCCL INFO Trees [0] 33/48/-1->32->65 [1] 33/-1/-1->32->36
 32: hkn0412:2247570:2247665 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
201: hkn0531:1215724:1215823 [1] NCCL INFO Trees [0] 202/196/-1->201->200 [1] 202/-1/-1->201->200
190: hkn0528:1286863:1286971 [2] NCCL INFO Trees [0] 191/-1/-1->190->189 [1] 191/-1/-1->190->189
190: hkn0528:1286863:1286971 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
192: hkn0529:1525995:1526126 [0] NCCL INFO Trees [0] 193/224/-1->192->128 [1] 193/-1/-1->192->196
493: hkn0810:924720:924850 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
397: hkn0719:1290860:1290956 [1] NCCL INFO Trees [0] 398/-1/-1->397->396 [1] 398/404/-1->397->396
397: hkn0719:1290860:1290956 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
207: hkn0532:908790:909100 [3] NCCL INFO Trees [0] -1/-1/-1->207->206 [1] -1/-1/-1->207->206
207: hkn0532:908790:909100 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
460: hkn0802:1185519:1185612 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
208: hkn0534:1133577:1133694 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
450: hkn0734:1141720:1141848 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
227: hkn0603:1398303:1398428 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
129: hkn0509:3109564:3109680 [1] NCCL INFO Trees [0] 130/64/-1->129->128 [1] 130/-1/-1->129->128
129: hkn0509:3109564:3109680 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
263: hkn0613:887832:887970 [3] NCCL INFO Trees [0] -1/-1/-1->263->262 [1] -1/-1/-1->263->262
 39: hkn0413:2351834:2351947 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38
267: hkn0615:399435:399549 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 27: hkn0410:1144778:1144896 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26
457: hkn0801:2225101:2225223 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
270: hkn0616:389969:390099 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 40: hkn0414:1966696:1966821 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
259: hkn0612:902148:902244 [3] NCCL INFO Trees [0] -1/-1/-1->259->258 [1] -1/-1/-1->259->258
259: hkn0612:902148:902244 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 28: hkn0411:2301020:2301135 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/12/-1->28->60
 28: hkn0411:2301020:2301135 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 33: hkn0412:2247562:2247671 [1] NCCL INFO Trees [0] 34/16/-1->33->32 [1] 34/-1/-1->33->32
 33: hkn0412:2247562:2247671 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 46: hkn0415:2481504:2481617 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45
214: hkn0535:2384181:2384305 [2] NCCL INFO Trees [0] 215/-1/-1->214->213 [1] 215/-1/-1->214->213
201: hkn0531:1215724:1215823 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
191: hkn0528:1286875:1286972 [3] NCCL INFO Trees [0] -1/-1/-1->191->190 [1] -1/-1/-1->191->190
191: hkn0528:1286875:1286972 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
194: hkn0529:1526011:1526128 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
197: hkn0530:1243325:1243432 [1] NCCL INFO Trees [0] 198/-1/-1->197->196 [1] 198/200/-1->197->196
494: hkn0810:924728:924849 [2] NCCL INFO Trees [0] 495/-1/-1->494->493 [1] 495/-1/-1->494->493
204: hkn0532:908782:909098 [0] NCCL INFO Trees [0] 205/-1/-1->204->200 [1] 205/196/-1->204->220
204: hkn0532:908782:909098 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
209: hkn0534:1133578:1133691 [1] NCCL INFO Trees [0] 210/200/-1->209->208 [1] 210/-1/-1->209->208
209: hkn0534:1133578:1133691 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
225: hkn0603:1398307:1398426 [1] NCCL INFO Trees [0] 226/208/-1->225->224 [1] 226/-1/-1->225->224
130: hkn0509:3109548:3109677 [2] NCCL INFO Trees [0] 131/-1/-1->130->129 [1] 131/-1/-1->130->129
130: hkn0509:3109548:3109677 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
263: hkn0613:887832:887970 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 39: hkn0413:2351834:2351947 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
265: hkn0615:399447:399552 [1] NCCL INFO Trees [0] 266/260/-1->265->264 [1] 266/-1/-1->265->264
 27: hkn0410:1144778:1144896 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
228: hkn0604:674438:674558 [0] NCCL INFO Trees [0] 229/-1/-1->228->233 [1] 229/224/-1->228->236
268: hkn0616:389997:390101 [0] NCCL INFO Trees [0] 269/-1/-1->268->264 [1] 269/260/-1->268->284
268: hkn0616:389997:390101 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 43: hkn0414:1966712:1966819 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42
257: hkn0612:902128:902247 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
223: hkn0602:3345215:3345483 [3] NCCL INFO Trees [0] -1/-1/-1->223->222 [1] -1/-1/-1->223->222
 34: hkn0412:2247554:2247673 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33
 34: hkn0412:2247554:2247673 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 47: hkn0415:2481502:2481621 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46
273: hkn0617:2279794:2279887 [1] NCCL INFO Trees [0] 274/264/-1->273->272 [1] 274/-1/-1->273->272
215: hkn0535:2384173:2384300 [3] NCCL INFO Trees [0] -1/-1/-1->215->214 [1] -1/-1/-1->215->214
200: hkn0531:1215696:1215820 [0] NCCL INFO Trees [0] 201/204/-1->200->209 [1] 201/-1/-1->200->197
188: hkn0528:1286855:1286975 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
195: hkn0529:1526003:1526130 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
132: hkn0510:2747220:2747346 [0] NCCL INFO Trees [0] 133/-1/-1->132->137 [1] 133/128/-1->132->140
198: hkn0530:1243309:1243429 [2] NCCL INFO Trees [0] 199/-1/-1->198->197 [1] 199/-1/-1->198->197
492: hkn0810:924748:924846 [0] NCCL INFO Trees [0] 493/-1/-1->492->488 [1] 493/484/-1->492->477
492: hkn0810:924748:924846 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
210: hkn0534:1133593:1133689 [2] NCCL INFO Trees [0] 211/-1/-1->210->209 [1] 211/-1/-1->210->209
210: hkn0534:1133593:1133689 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
225: hkn0603:1398307:1398426 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
131: hkn0509:3109556:3109675 [3] NCCL INFO Trees [0] -1/-1/-1->131->130 [1] -1/-1/-1->131->130
131: hkn0509:3109556:3109675 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
217: hkn0601:102836:102938 [1] NCCL INFO Trees [0] 218/212/-1->217->216 [1] 218/-1/-1->217->216
217: hkn0601:102836:102938 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 38: hkn0413:2351846:2351938 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37
264: hkn0615:399427:399550 [0] NCCL INFO Trees [0] 265/268/-1->264->273 [1] 265/-1/-1->264->261
264: hkn0615:399427:399550 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 26: hkn0410:1144773:1144892 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25
228: hkn0604:674438:674558 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
269: hkn0616:389977:390103 [1] NCCL INFO Trees [0] 270/-1/-1->269->268 [1] 270/276/-1->269->268
269: hkn0616:389977:390103 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 43: hkn0414:1966712:1966819 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
258: hkn0612:902136:902248 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 30: hkn0411:2301012:2301139 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29
 30: hkn0411:2301012:2301139 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
223: hkn0602:3345215:3345483 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 35: hkn0412:2247582:2247669 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34
 35: hkn0412:2247582:2247669 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
274: hkn0617:2279774:2279896 [2] NCCL INFO Trees [0] 275/-1/-1->274->273 [1] 275/-1/-1->274->273
215: hkn0535:2384173:2384300 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
202: hkn0531:1215712:1215824 [2] NCCL INFO Trees [0] 203/-1/-1->202->201 [1] 203/-1/-1->202->201
192: hkn0529:1525995:1526126 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
132: hkn0510:2747220:2747346 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 49: hkn0417:2252738:2252863 [1] NCCL INFO Trees [0] 50/40/-1->49->48 [1] 50/-1/-1->49->48
186: hkn0527:1334041:1334160 [2] NCCL INFO Trees [0] 187/-1/-1->186->185 [1] 187/-1/-1->186->185
186: hkn0527:1334041:1334160 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
137: hkn0511:3051503:3051608 [1] NCCL INFO Trees [0] 138/132/-1->137->136 [1] 138/-1/-1->137->136
199: hkn0530:1243337:1243436 [3] NCCL INFO Trees [0] -1/-1/-1->199->198 [1] -1/-1/-1->199->198
494: hkn0810:924728:924849 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
211: hkn0534:1133581:1133690 [3] NCCL INFO Trees [0] -1/-1/-1->211->210 [1] -1/-1/-1->211->210
211: hkn0534:1133581:1133690 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
395: hkn0718:3902182:3902290 [3] NCCL INFO Trees [0] -1/-1/-1->395->394 [1] -1/-1/-1->395->394
226: hkn0603:1398315:1398422 [2] NCCL INFO Trees [0] 227/-1/-1->226->225 [1] 227/-1/-1->226->225
128: hkn0509:3109576:3109676 [0] NCCL INFO Trees [0] 129/192/-1->128->257 [1] 129/-1/-1->128->132
218: hkn0601:102824:102933 [2] NCCL INFO Trees [0] 219/-1/-1->218->217 [1] 219/-1/-1->218->217
218: hkn0601:102824:102933 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 38: hkn0413:2351846:2351938 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
265: hkn0615:399447:399552 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 26: hkn0410:1144773:1144892 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
271: hkn0616:389985:390100 [3] NCCL INFO Trees [0] -1/-1/-1->271->270 [1] -1/-1/-1->271->270
 41: hkn0414:1966724:1966822 [1] NCCL INFO Trees [0] 42/36/-1->41->40 [1] 42/-1/-1->41->40
 41: hkn0414:1966724:1966822 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 31: hkn0411:2301028:2301136 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30
 31: hkn0411:2301028:2301136 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
222: hkn0602:3345207:3345482 [2] NCCL INFO Trees [0] 223/-1/-1->222->221 [1] 223/-1/-1->222->221
 46: hkn0415:2481504:2481617 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
273: hkn0617:2279794:2279887 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
214: hkn0535:2384181:2384305 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
203: hkn0531:1215704:1215819 [3] NCCL INFO Trees [0] -1/-1/-1->203->202 [1] -1/-1/-1->203->202
133: hkn0510:2747236:2747343 [1] NCCL INFO Trees [0] 134/-1/-1->133->132 [1] 134/136/-1->133->132
 49: hkn0417:2252738:2252863 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
187: hkn0527:1334069:1334163 [3] NCCL INFO Trees [0] -1/-1/-1->187->186 [1] -1/-1/-1->187->186
187: hkn0527:1334069:1334163 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
137: hkn0511:3051503:3051608 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
197: hkn0530:1243325:1243432 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
495: hkn0810:924736:924852 [3] NCCL INFO Trees [0] -1/-1/-1->495->494 [1] -1/-1/-1->495->494
396: hkn0719:1290840:1290959 [0] NCCL INFO Trees [0] 397/-1/-1->396->392 [1] 397/388/-1->396->412
396: hkn0719:1290840:1290959 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
395: hkn0718:3902182:3902290 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
226: hkn0603:1398315:1398422 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
128: hkn0509:3109576:3109676 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
219: hkn0601:102808:102935 [3] NCCL INFO Trees [0] -1/-1/-1->219->218 [1] -1/-1/-1->219->218
219: hkn0601:102808:102935 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 36: hkn0413:2351818:2351944 [0] NCCL INFO Trees [0] 37/-1/-1->36->41 [1] 37/32/-1->36->44
144: hkn0513:2998090:2998209 [0] NCCL INFO Trees [0] 145/152/-1->144->161 [1] 145/-1/-1->144->148
271: hkn0616:389985:390100 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 42: hkn0414:1966704:1966820 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41
 29: hkn0411:2301040:2301137 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/44/-1->29->28
 29: hkn0411:2301040:2301137 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
222: hkn0602:3345207:3345482 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 47: hkn0415:2481502:2481621 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
274: hkn0617:2279774:2279896 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
213: hkn0535:2384189:2384302 [1] NCCL INFO Trees [0] 214/-1/-1->213->212 [1] 214/216/-1->213->212
213: hkn0535:2384189:2384302 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
200: hkn0531:1215696:1215820 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
134: hkn0510:2747248:2747351 [2] NCCL INFO Trees [0] 135/-1/-1->134->133 [1] 135/-1/-1->134->133
134: hkn0510:2747248:2747351 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 48: hkn0417:2252758:2252860 [0] NCCL INFO Trees [0] 49/56/-1->48->32 [1] 49/-1/-1->48->52
276: hkn0621:1976635:1976739 [0] NCCL INFO Trees [0] 277/-1/-1->276->281 [1] 277/272/-1->276->269
185: hkn0527:1334057:1334167 [1] NCCL INFO Trees [0] 186/180/-1->185->184 [1] 186/-1/-1->185->184
139: hkn0511:3051483:3051604 [3] NCCL INFO Trees [0] -1/-1/-1->139->138 [1] -1/-1/-1->139->138
198: hkn0530:1243309:1243429 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
495: hkn0810:924736:924852 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
394: hkn0718:3902173:3902289 [2] NCCL INFO Trees [0] 395/-1/-1->394->393 [1] 395/-1/-1->394->393
394: hkn0718:3902173:3902289 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
224: hkn0603:1398327:1398423 [0] NCCL INFO Trees [0] 225/240/-1->224->192 [1] 225/-1/-1->224->228
216: hkn0601:102816:102929 [0] NCCL INFO Trees [0] 217/220/-1->216->208 [1] 217/-1/-1->216->213
 36: hkn0413:2351818:2351944 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
122: hkn0507:3172208:3172331 [2] NCCL INFO Trees [0] 123/-1/-1->122->121 [1] 123/-1/-1->122->121
145: hkn0513:2998098:2998200 [1] NCCL INFO Trees [0] 146/136/-1->145->144 [1] 146/-1/-1->145->144
 42: hkn0414:1966704:1966820 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
220: hkn0602:3345223:3345484 [0] NCCL INFO Trees [0] 221/-1/-1->220->216 [1] 221/204/-1->220->189
 45: hkn0415:2481516:2481618 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/52/-1->45->44
272: hkn0617:2279782:2279893 [0] NCCL INFO Trees [0] 273/280/-1->272->289 [1] 273/-1/-1->272->276
272: hkn0617:2279782:2279893 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
212: hkn0535:2384201:2384301 [0] NCCL INFO Trees [0] 213/-1/-1->212->217 [1] 213/208/-1->212->205
202: hkn0531:1215712:1215824 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
140: hkn0512:3029302:3029419 [0] NCCL INFO Trees [0] 141/-1/-1->140->136 [1] 141/132/-1->140->156
133: hkn0510:2747236:2747343 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 50: hkn0417:2252730:2252862 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49
276: hkn0621:1976635:1976739 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
185: hkn0527:1334057:1334167 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
149: hkn0514:2935893:2936011 [1] NCCL INFO Trees [0] 150/-1/-1->149->148 [1] 150/152/-1->149->148
149: hkn0514:2935893:2936011 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
173: hkn0524:1118934:1119058 [1] NCCL INFO Trees [0] 174/-1/-1->173->172 [1] 174/180/-1->173->172
126: hkn0508:3124297:3124412 [2] NCCL INFO Trees [0] 127/-1/-1->126->125 [1] 127/-1/-1->126->125
139: hkn0511:3051483:3051604 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
199: hkn0530:1243337:1243436 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
496: hkn0812:678913:679036 [0] NCCL INFO Trees [0] 497/504/-1->496->480 [1] 497/-1/-1->496->500
496: hkn0812:678913:679036 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
341: hkn0704:777142:777272 [1] NCCL INFO Trees [0] 342/-1/-1->341->340 [1] 342/344/-1->341->340
391: hkn0717:4172703:4172819 [3] NCCL INFO Trees [0] -1/-1/-1->391->390 [1] -1/-1/-1->391->390
393: hkn0718:3902174:3902293 [1] NCCL INFO Trees [0] 394/388/-1->393->392 [1] 394/-1/-1->393->392
224: hkn0603:1398327:1398423 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
216: hkn0601:102816:102929 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
122: hkn0507:3172208:3172331 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
144: hkn0513:2998090:2998209 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
221: hkn0602:3345235:3345487 [1] NCCL INFO Trees [0] 222/-1/-1->221->220 [1] 222/236/-1->221->220
221: hkn0602:3345235:3345487 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 44: hkn0415:2481503:2481619 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/36/-1->44->29
 44: hkn0415:2481503:2481619 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
154: hkn0515:2881950:2882069 [2] NCCL INFO Trees [0] 155/-1/-1->154->153 [1] 155/-1/-1->154->153
275: hkn0617:2279766:2279891 [3] NCCL INFO Trees [0] -1/-1/-1->275->274 [1] -1/-1/-1->275->274
165: hkn0521:1182962:1183092 [1] NCCL INFO Trees [0] 166/-1/-1->165->164 [1] 166/168/-1->165->164
179: hkn0525:971983:972104 [3] NCCL INFO Trees [0] -1/-1/-1->179->178 [1] -1/-1/-1->179->178
212: hkn0535:2384201:2384301 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
203: hkn0531:1215704:1215819 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
141: hkn0512:3029294:3029422 [1] NCCL INFO Trees [0] 142/-1/-1->141->140 [1] 142/148/-1->141->140
135: hkn0510:2747228:2747349 [3] NCCL INFO Trees [0] -1/-1/-1->135->134 [1] -1/-1/-1->135->134
182: hkn0526:1413581:1413675 [2] NCCL INFO Trees [0] 183/-1/-1->182->181 [1] 183/-1/-1->182->181
 51: hkn0417:2252746:2252861 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50
 51: hkn0417:2252746:2252861 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
277: hkn0621:1976619:1976745 [1] NCCL INFO Trees [0] 278/-1/-1->277->276 [1] 278/280/-1->277->276
184: hkn0527:1334049:1334169 [0] NCCL INFO Trees [0] 185/188/-1->184->176 [1] 185/-1/-1->184->181
151: hkn0514:2935901:2936013 [3] NCCL INFO Trees [0] -1/-1/-1->151->150 [1] -1/-1/-1->151->150
151: hkn0514:2935901:2936013 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
174: hkn0524:1118942:1119055 [2] NCCL INFO Trees [0] 175/-1/-1->174->173 [1] 175/-1/-1->174->173
174: hkn0524:1118942:1119055 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
126: hkn0508:3124297:3124412 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
138: hkn0511:3051491:3051603 [2] NCCL INFO Trees [0] 139/-1/-1->138->137 [1] 139/-1/-1->138->137
138: hkn0511:3051491:3051603 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
196: hkn0530:1243317:1243433 [0] NCCL INFO Trees [0] 197/-1/-1->196->201 [1] 197/192/-1->196->204
499: hkn0812:678941:679039 [3] NCCL INFO Trees [0] -1/-1/-1->499->498 [1] -1/-1/-1->499->498
499: hkn0812:678941:679039 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
351: hkn0706:737447:737575 [3] NCCL INFO Trees [0] -1/-1/-1->351->350 [1] -1/-1/-1->351->350
341: hkn0704:777142:777272 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
391: hkn0717:4172703:4172819 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
393: hkn0718:3902174:3902293 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
121: hkn0507:3172216:3172329 [1] NCCL INFO Trees [0] 122/116/-1->121->120 [1] 122/-1/-1->121->120
145: hkn0513:2998098:2998200 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
159: hkn0516:2901136:2901292 [3] NCCL INFO Trees [0] -1/-1/-1->159->158 [1] -1/-1/-1->159->158
280: hkn0622:2005593:2005692 [0] NCCL INFO Trees [0] 281/284/-1->280->272 [1] 281/-1/-1->280->277
220: hkn0602:3345223:3345484 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 45: hkn0415:2481516:2481618 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
155: hkn0515:2881942:2882062 [3] NCCL INFO Trees [0] -1/-1/-1->155->154 [1] -1/-1/-1->155->154
275: hkn0617:2279766:2279891 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
165: hkn0521:1182962:1183092 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
179: hkn0525:971983:972104 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
142: hkn0512:3029322:3029415 [2] NCCL INFO Trees [0] 143/-1/-1->142->141 [1] 143/-1/-1->142->141
135: hkn0510:2747228:2747349 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
169: hkn0523:1533198:1533289 [1] NCCL INFO Trees [0] 170/164/-1->169->168 [1] 170/-1/-1->169->168
169: hkn0523:1533198:1533289 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
183: hkn0526:1413553:1413678 [3] NCCL INFO Trees [0] -1/-1/-1->183->182 [1] -1/-1/-1->183->182
 48: hkn0417:2252758:2252860 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
278: hkn0621:1976647:1976747 [2] NCCL INFO Trees [0] 279/-1/-1->278->277 [1] 279/-1/-1->278->277
184: hkn0527:1334049:1334169 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
150: hkn0514:2935913:2936009 [2] NCCL INFO Trees [0] 151/-1/-1->150->149 [1] 151/-1/-1->150->149
173: hkn0524:1118934:1119058 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
124: hkn0508:3124325:3124404 [0] NCCL INFO Trees [0] 125/-1/-1->124->120 [1] 125/60/-1->124->252
124: hkn0508:3124325:3124404 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
136: hkn0511:3051475:3051605 [0] NCCL INFO Trees [0] 137/140/-1->136->145 [1] 137/-1/-1->136->133
136: hkn0511:3051475:3051605 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
196: hkn0530:1243317:1243433 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
498: hkn0812:678929:679040 [2] NCCL INFO Trees [0] 499/-1/-1->498->497 [1] 499/-1/-1->498->497
348: hkn0706:737455:737573 [0] NCCL INFO Trees [0] 349/-1/-1->348->344 [1] 349/332/-1->348->317
343: hkn0704:777170:777274 [3] NCCL INFO Trees [0] -1/-1/-1->343->342 [1] -1/-1/-1->343->342
389: hkn0717:4172715:4172825 [1] NCCL INFO Trees [0] 390/-1/-1->389->388 [1] 390/392/-1->389->388
161: hkn0520:2698015:2698119 [1] NCCL INFO Trees [0] 162/144/-1->161->160 [1] 162/-1/-1->161->160
392: hkn0718:3902194:3902291 [0] NCCL INFO Trees [0] 393/396/-1->392->401 [1] 393/-1/-1->392->389
123: hkn0507:3172200:3172323 [3] NCCL INFO Trees [0] -1/-1/-1->123->122 [1] -1/-1/-1->123->122
123: hkn0507:3172200:3172323 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
146: hkn0513:2998110:2998204 [2] NCCL INFO Trees [0] 147/-1/-1->146->145 [1] 147/-1/-1->146->145
146: hkn0513:2998110:2998204 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
159: hkn0516:2901136:2901292 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
280: hkn0622:2005593:2005692 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 52: hkn0418:1854341:1854446 [0] NCCL INFO Trees [0] 53/-1/-1->52->57 [1] 53/48/-1->52->45
154: hkn0515:2881950:2882069 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
166: hkn0521:1182970:1183090 [2] NCCL INFO Trees [0] 167/-1/-1->166->165 [1] 167/-1/-1->166->165
166: hkn0521:1182970:1183090 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
177: hkn0525:971991:972103 [1] NCCL INFO Trees [0] 178/168/-1->177->176 [1] 178/-1/-1->177->176
143: hkn0512:3029310:3029418 [3] NCCL INFO Trees [0] -1/-1/-1->143->142 [1] -1/-1/-1->143->142
170: hkn0523:1533170:1533292 [2] NCCL INFO Trees [0] 171/-1/-1->170->169 [1] 171/-1/-1->170->169
170: hkn0523:1533170:1533292 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
182: hkn0526:1413581:1413675 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 50: hkn0417:2252730:2252862 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
279: hkn0621:1976627:1976741 [3] NCCL INFO Trees [0] -1/-1/-1->279->278 [1] -1/-1/-1->279->278
279: hkn0621:1976627:1976741 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
150: hkn0514:2935913:2936009 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
172: hkn0524:1118962:1119061 [0] NCCL INFO Trees [0] 173/-1/-1->172->168 [1] 173/164/-1->172->157
125: hkn0508:3124305:3124410 [1] NCCL INFO Trees [0] 126/-1/-1->125->124 [1] 126/188/-1->125->124
125: hkn0508:3124305:3124410 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
500: hkn0814:660997:661104 [0] NCCL INFO Trees [0] 501/-1/-1->500->505 [1] 501/496/-1->500->493
498: hkn0812:678929:679040 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
351: hkn0706:737447:737575 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
343: hkn0704:777170:777274 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
353: hkn0707:4005073:4005192 [1] NCCL INFO Trees [0] 354/336/-1->353->352 [1] 354/-1/-1->353->352
389: hkn0717:4172715:4172825 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
162: hkn0520:2698027:2698123 [2] NCCL INFO Trees [0] 163/-1/-1->162->161 [1] 163/-1/-1->162->161
345: hkn0705:768401:768516 [1] NCCL INFO Trees [0] 346/340/-1->345->344 [1] 346/-1/-1->345->344
358: hkn0708:398424:398526 [2] NCCL INFO Trees [0] 359/-1/-1->358->357 [1] 359/-1/-1->358->357
392: hkn0718:3902194:3902291 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
121: hkn0507:3172216:3172329 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
147: hkn0513:2998082:2998206 [3] NCCL INFO Trees [0] -1/-1/-1->147->146 [1] -1/-1/-1->147->146
281: hkn0622:2005573:2005694 [1] NCCL INFO Trees [0] 282/276/-1->281->280 [1] 282/-1/-1->281->280
 52: hkn0418:1854341:1854446 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
155: hkn0515:2881942:2882062 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
167: hkn0521:1182990:1183086 [3] NCCL INFO Trees [0] -1/-1/-1->167->166 [1] -1/-1/-1->167->166
167: hkn0521:1182990:1183086 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
177: hkn0525:971991:972103 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
119: hkn0506:823213:823305 [3] NCCL INFO Trees [0] -1/-1/-1->119->118 [1] -1/-1/-1->119->118
140: hkn0512:3029302:3029419 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
171: hkn0523:1533178:1533297 [3] NCCL INFO Trees [0] -1/-1/-1->171->170 [1] -1/-1/-1->171->170
183: hkn0526:1413553:1413678 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
277: hkn0621:1976619:1976745 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
148: hkn0514:2935885:2936010 [0] NCCL INFO Trees [0] 149/-1/-1->148->153 [1] 149/144/-1->148->141
175: hkn0524:1118950:1119063 [3] NCCL INFO Trees [0] -1/-1/-1->175->174 [1] -1/-1/-1->175->174
175: hkn0524:1118950:1119063 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
500: hkn0814:660997:661104 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
497: hkn0812:678921:679031 [1] NCCL INFO Trees [0] 498/488/-1->497->496 [1] 498/-1/-1->497->496
361: hkn0710:340632:340748 [1] NCCL INFO Trees [0] 362/356/-1->361->360 [1] 362/-1/-1->361->360
348: hkn0706:737455:737573 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
340: hkn0704:777158:777265 [0] NCCL INFO Trees [0] 341/-1/-1->340->345 [1] 341/336/-1->340->333
355: hkn0707:4005093:4005183 [3] NCCL INFO Trees [0] -1/-1/-1->355->354 [1] -1/-1/-1->355->354
390: hkn0717:4172695:4172824 [2] NCCL INFO Trees [0] 391/-1/-1->390->389 [1] 391/-1/-1->390->389
390: hkn0717:4172695:4172824 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
163: hkn0520:2698007:2698122 [3] NCCL INFO Trees [0] -1/-1/-1->163->162 [1] -1/-1/-1->163->162
163: hkn0520:2698007:2698122 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
345: hkn0705:768401:768516 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
358: hkn0708:398424:398526 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
120: hkn0507:3172228:3172326 [0] NCCL INFO Trees [0] 121/124/-1->120->112 [1] 121/-1/-1->120->117
120: hkn0507:3172228:3172326 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
147: hkn0513:2998082:2998206 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
158: hkn0516:2901144:2901290 [2] NCCL INFO Trees [0] 159/-1/-1->158->157 [1] 159/-1/-1->158->157
282: hkn0622:2005581:2005688 [2] NCCL INFO Trees [0] 283/-1/-1->282->281 [1] 283/-1/-1->282->281
282: hkn0622:2005581:2005688 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 53: hkn0418:1854353:1854450 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/56/-1->53->52
152: hkn0515:2881970:2882070 [0] NCCL INFO Trees [0] 153/156/-1->152->144 [1] 153/-1/-1->152->149
164: hkn0521:1182978:1183084 [0] NCCL INFO Trees [0] 165/-1/-1->164->169 [1] 165/160/-1->164->172
178: hkn0525:972003:972097 [2] NCCL INFO Trees [0] 179/-1/-1->178->177 [1] 179/-1/-1->178->177
119: hkn0506:823213:823305 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
141: hkn0512:3029294:3029422 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
171: hkn0523:1533178:1533297 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
181: hkn0526:1413569:1413673 [1] NCCL INFO Trees [0] 182/-1/-1->181->180 [1] 182/184/-1->181->180
278: hkn0621:1976647:1976747 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
148: hkn0514:2935885:2936010 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
172: hkn0524:1118962:1119061 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
501: hkn0814:661009:661108 [1] NCCL INFO Trees [0] 502/-1/-1->501->500 [1] 502/504/-1->501->500
501: hkn0814:661009:661108 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
497: hkn0812:678921:679031 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 00/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
362: hkn0710:340630:340740 [2] NCCL INFO Trees [0] 363/-1/-1->362->361 [1] 363/-1/-1->362->361
349: hkn0706:737463:737570 [1] NCCL INFO Trees [0] 350/-1/-1->349->348 [1] 350/364/-1->349->348
342: hkn0704:777150:777271 [2] NCCL INFO Trees [0] 343/-1/-1->342->341 [1] 343/-1/-1->342->341
353: hkn0707:4005073:4005192 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
364: hkn0711:569026:569156 [0] NCCL INFO Trees [0] 365/-1/-1->364->360 [1] 365/356/-1->364->349
364: hkn0711:569026:569156 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
160: hkn0520:2697999:2698118 [0] NCCL INFO Trees [0] 161/176/-1->160->193 [1] 161/-1/-1->160->164
347: hkn0705:768400:768514 [3] NCCL INFO Trees [0] -1/-1/-1->347->346 [1] -1/-1/-1->347->346
347: hkn0705:768400:768514 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
357: hkn0708:398436:398520 [1] NCCL INFO Trees [0] 358/-1/-1->357->356 [1] 358/360/-1->357->356
357: hkn0708:398436:398520 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
158: hkn0516:2901144:2901290 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
283: hkn0622:2005565:2005687 [3] NCCL INFO Trees [0] -1/-1/-1->283->282 [1] -1/-1/-1->283->282
283: hkn0622:2005565:2005687 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 54: hkn0418:1854325:1854445 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53
 54: hkn0418:1854325:1854445 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
153: hkn0515:2881958:2882071 [1] NCCL INFO Trees [0] 154/148/-1->153->152 [1] 154/-1/-1->153->152
153: hkn0515:2881958:2882071 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
164: hkn0521:1182978:1183084 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
178: hkn0525:972003:972097 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
142: hkn0512:3029322:3029415 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
168: hkn0523:1533186:1533298 [0] NCCL INFO Trees [0] 169/172/-1->168->177 [1] 169/-1/-1->168->165
180: hkn0526:1413561:1413674 [0] NCCL INFO Trees [0] 181/-1/-1->180->185 [1] 181/176/-1->180->173
502: hkn0814:660989:661111 [2] NCCL INFO Trees [0] 503/-1/-1->502->501 [1] 503/-1/-1->502->501
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 01/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
361: hkn0710:340632:340748 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
350: hkn0706:737475:737567 [2] NCCL INFO Trees [0] 351/-1/-1->350->349 [1] 351/-1/-1->350->349
340: hkn0704:777158:777265 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
355: hkn0707:4005093:4005183 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
365: hkn0711:569034:569157 [1] NCCL INFO Trees [0] 366/-1/-1->365->364 [1] 366/372/-1->365->364
365: hkn0711:569034:569157 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
161: hkn0520:2698015:2698119 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
344: hkn0705:768421:768521 [0] NCCL INFO Trees [0] 345/348/-1->344->336 [1] 345/-1/-1->344->341
344: hkn0705:768421:768521 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
359: hkn0708:398415:398522 [3] NCCL INFO Trees [0] -1/-1/-1->359->358 [1] -1/-1/-1->359->358
156: hkn0516:2901152:2901289 [0] NCCL INFO Trees [0] 157/-1/-1->156->152 [1] 157/140/-1->156->188
281: hkn0622:2005573:2005694 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 55: hkn0418:1854333:1854449 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54
 55: hkn0418:1854333:1854449 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
152: hkn0515:2881970:2882070 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
287: hkn0623:1857898:1858023 [3] NCCL INFO Trees [0] -1/-1/-1->287->286 [1] -1/-1/-1->287->286
176: hkn0525:971975:972098 [0] NCCL INFO Trees [0] 177/184/-1->176->160 [1] 177/-1/-1->176->180
143: hkn0512:3029310:3029418 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
168: hkn0523:1533186:1533298 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
181: hkn0526:1413569:1413673 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
127: hkn0508:3124313:3124406 [3] NCCL INFO Trees [0] -1/-1/-1->127->126 [1] -1/-1/-1->127->126
502: hkn0814:660989:661111 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  1: hkn0403:1738685:1739058 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
362: hkn0710:340630:340740 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
349: hkn0706:737463:737570 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
375: hkn0713:455441:455538 [3] NCCL INFO Trees [0] -1/-1/-1->375->374 [1] -1/-1/-1->375->374
342: hkn0704:777150:777271 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
352: hkn0707:4005081:4005188 [0] NCCL INFO Trees [0] 353/368/-1->352->320 [1] 353/-1/-1->352->356
352: hkn0707:4005081:4005188 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
366: hkn0711:569042:569160 [2] NCCL INFO Trees [0] 367/-1/-1->366->365 [1] 367/-1/-1->366->365
366: hkn0711:569042:569160 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
162: hkn0520:2698027:2698123 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
346: hkn0705:768409:768518 [2] NCCL INFO Trees [0] 347/-1/-1->346->345 [1] 347/-1/-1->346->345
346: hkn0705:768409:768518 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
356: hkn0708:398416:398525 [0] NCCL INFO Trees [0] 357/-1/-1->356->361 [1] 357/352/-1->356->364
356: hkn0708:398416:398525 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
371: hkn0712:280263:280354 [3] NCCL INFO Trees [0] -1/-1/-1->371->370 [1] -1/-1/-1->371->370
 25: hkn0410:1144790:1144895 [1] NCCL INFO Trees [0] 26/20/-1->25->24 [1] 26/-1/-1->25->24
157: hkn0516:2901164:2901294 [1] NCCL INFO Trees [0] 158/-1/-1->157->156 [1] 158/172/-1->157->156
292: hkn0626:1283594:1283703 [0] NCCL INFO Trees [0] 293/-1/-1->292->297 [1] 293/288/-1->292->300
292: hkn0626:1283594:1283703 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 53: hkn0418:1854353:1854450 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 56: hkn0419:1529464:1529580 [0] NCCL INFO Trees [0] 57/60/-1->56->48 [1] 57/-1/-1->56->53
287: hkn0623:1857898:1858023 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
176: hkn0525:971975:972098 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
180: hkn0526:1413561:1413674 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
289: hkn0624:1758098:1758200 [1] NCCL INFO Trees [0] 290/272/-1->289->288 [1] 290/-1/-1->289->288
289: hkn0624:1758098:1758200 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
127: hkn0508:3124313:3124406 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
503: hkn0814:660981:661105 [3] NCCL INFO Trees [0] -1/-1/-1->503->502 [1] -1/-1/-1->503->502
503: hkn0814:660981:661105 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  1: hkn0403:1738685:1739058 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
360: hkn0710:340644:340742 [0] NCCL INFO Trees [0] 361/364/-1->360->369 [1] 361/-1/-1->360->357
350: hkn0706:737475:737567 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
375: hkn0713:455441:455538 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
354: hkn0707:4005065:4005191 [2] NCCL INFO Trees [0] 355/-1/-1->354->353 [1] 355/-1/-1->354->353
354: hkn0707:4005065:4005191 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
367: hkn0711:569054:569153 [3] NCCL INFO Trees [0] -1/-1/-1->367->366 [1] -1/-1/-1->367->366
367: hkn0711:569054:569153 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
160: hkn0520:2697999:2698118 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
359: hkn0708:398415:398522 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
371: hkn0712:280263:280354 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 25: hkn0410:1144790:1144895 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
156: hkn0516:2901152:2901289 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
294: hkn0626:1283606:1283705 [2] NCCL INFO Trees [0] 295/-1/-1->294->293 [1] 295/-1/-1->294->293
294: hkn0626:1283606:1283705 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 56: hkn0419:1529464:1529580 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
285: hkn0623:1857886:1858018 [1] NCCL INFO Trees [0] 286/-1/-1->285->284 [1] 286/300/-1->285->284
298: hkn0627:1773054:1773175 [2] NCCL INFO Trees [0] 299/-1/-1->298->297 [1] 299/-1/-1->298->297
288: hkn0624:1758070:1758195 [0] NCCL INFO Trees [0] 289/304/-1->288->321 [1] 289/-1/-1->288->292
506: hkn0815:380337:380459 [2] NCCL INFO Trees [0] 507/-1/-1->506->505 [1] 507/-1/-1->506->505
508: hkn0816:360788:360900 [0] NCCL INFO Trees [0] 509/-1/-1->508->504 [1] 509/252/-1->508->-1
  0: hkn0403:1738669:1739051 [0] NCCL INFO Trees [0] 1/256/-1->0->-1 [1] 1/-1/-1->0->4
360: hkn0710:340644:340742 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
372: hkn0713:455428:455539 [0] NCCL INFO Trees [0] 373/-1/-1->372->377 [1] 373/368/-1->372->365
372: hkn0713:455428:455539 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
368: hkn0712:280251:280359 [0] NCCL INFO Trees [0] 369/376/-1->368->352 [1] 369/-1/-1->368->372
157: hkn0516:2901164:2901294 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
293: hkn0626:1283586:1283696 [1] NCCL INFO Trees [0] 294/-1/-1->293->292 [1] 294/296/-1->293->292
 57: hkn0419:1529484:1529583 [1] NCCL INFO Trees [0] 58/52/-1->57->56 [1] 58/-1/-1->57->56
286: hkn0623:1857878:1858024 [2] NCCL INFO Trees [0] 287/-1/-1->286->285 [1] 287/-1/-1->286->285
286: hkn0623:1857878:1858024 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
299: hkn0627:1773082:1773180 [3] NCCL INFO Trees [0] -1/-1/-1->299->298 [1] -1/-1/-1->299->298
299: hkn0627:1773082:1773180 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
118: hkn0506:823201:823314 [2] NCCL INFO Trees [0] 119/-1/-1->118->117 [1] 119/-1/-1->118->117
288: hkn0624:1758070:1758195 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
507: hkn0815:380345:380457 [3] NCCL INFO Trees [0] -1/-1/-1->507->506 [1] -1/-1/-1->507->506
508: hkn0816:360788:360900 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  0: hkn0403:1738669:1739051 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
338: hkn0703:726147:726262 [2] NCCL INFO Trees [0] 339/-1/-1->338->337 [1] 339/-1/-1->338->337
363: hkn0710:340631:340745 [3] NCCL INFO Trees [0] -1/-1/-1->363->362 [1] -1/-1/-1->363->362
373: hkn0713:455427:455540 [1] NCCL INFO Trees [0] 374/-1/-1->373->372 [1] 374/376/-1->373->372
369: hkn0712:280243:280361 [1] NCCL INFO Trees [0] 370/360/-1->369->368 [1] 370/-1/-1->369->368
369: hkn0712:280243:280361 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
301: hkn0628:657007:657097 [1] NCCL INFO Trees [0] 302/-1/-1->301->300 [1] 302/308/-1->301->300
 24: hkn0410:1144774:1144891 [0] NCCL INFO Trees [0] 25/28/-1->24->16 [1] 25/-1/-1->24->21
295: hkn0626:1283583:1283699 [3] NCCL INFO Trees [0] -1/-1/-1->295->294 [1] -1/-1/-1->295->294
305: hkn0629:1577194:1577306 [1] NCCL INFO Trees [0] 306/296/-1->305->304 [1] 306/-1/-1->305->304
 57: hkn0419:1529484:1529583 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
285: hkn0623:1857886:1858018 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
298: hkn0627:1773054:1773175 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
118: hkn0506:823201:823314 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
290: hkn0624:1758086:1758202 [2] NCCL INFO Trees [0] 291/-1/-1->290->289 [1] 291/-1/-1->290->289
  4: hkn0404:1324511:1324629 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/0/-1->4->12
  4: hkn0404:1324511:1324629 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
506: hkn0815:380337:380459 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
509: hkn0816:360808:360905 [1] NCCL INFO Trees [0] 510/-1/-1->509->508 [1] 510/-1/-1->509->508
  2: hkn0403:1738697:1739060 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
338: hkn0703:726147:726262 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
363: hkn0710:340631:340745 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
373: hkn0713:455427:455540 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
376: hkn0714:417195:417320 [0] NCCL INFO Trees [0] 377/380/-1->376->368 [1] 377/-1/-1->376->373
381: hkn0715:387096:387223 [1] NCCL INFO Trees [0] 382/-1/-1->381->380 [1] 382/444/-1->381->380
370: hkn0712:280242:280355 [2] NCCL INFO Trees [0] 371/-1/-1->370->369 [1] 371/-1/-1->370->369
370: hkn0712:280242:280355 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 20: hkn0409:2570878:2570976 [0] NCCL INFO Trees [0] 21/-1/-1->20->25 [1] 21/16/-1->20->13
 20: hkn0409:2570878:2570976 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
303: hkn0628:656987:657106 [3] NCCL INFO Trees [0] -1/-1/-1->303->302 [1] -1/-1/-1->303->302
 24: hkn0410:1144774:1144891 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
293: hkn0626:1283586:1283696 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
305: hkn0629:1577194:1577306 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 59: hkn0419:1529462:1529576 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58
284: hkn0623:1857870:1858027 [0] NCCL INFO Trees [0] 285/-1/-1->284->280 [1] 285/268/-1->284->316
297: hkn0627:1773070:1773181 [1] NCCL INFO Trees [0] 298/292/-1->297->296 [1] 298/-1/-1->297->296
311: hkn0630:1583636:1583760 [3] NCCL INFO Trees [0] -1/-1/-1->311->310 [1] -1/-1/-1->311->310
290: hkn0624:1758086:1758202 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  5: hkn0404:1324527:1324632 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/8/-1->5->4
507: hkn0815:380345:380457 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
510: hkn0816:360796:360907 [2] NCCL INFO Trees [0] 511/-1/-1->510->509 [1] 511/-1/-1->510->509
510: hkn0816:360796:360907 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  3: hkn0403:1738677:1739059 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
  3: hkn0403:1738677:1739059 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
339: hkn0703:726146:726263 [3] NCCL INFO Trees [0] -1/-1/-1->339->338 [1] -1/-1/-1->339->338
387: hkn0716:93654:93766 [3] NCCL INFO Trees [0] -1/-1/-1->387->386 [1] -1/-1/-1->387->386
374: hkn0713:455429:455542 [2] NCCL INFO Trees [0] 375/-1/-1->374->373 [1] 375/-1/-1->374->373
 14: hkn0407:1801449:1801570 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
376: hkn0714:417195:417320 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
381: hkn0715:387096:387223 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
368: hkn0712:280251:280359 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 21: hkn0409:2570850:2570977 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/24/-1->21->20
  8: hkn0405:3191892:3192005 [0] NCCL INFO Trees [0] 9/12/-1->8->17 [1] 9/-1/-1->8->5
301: hkn0628:657007:657097 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
295: hkn0626:1283583:1283699 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
306: hkn0629:1577206:1577307 [2] NCCL INFO Trees [0] 307/-1/-1->306->305 [1] 307/-1/-1->306->305
306: hkn0629:1577206:1577307 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 59: hkn0419:1529462:1529576 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
284: hkn0623:1857870:1858027 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
297: hkn0627:1773070:1773181 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
311: hkn0630:1583636:1583760 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 63: hkn0420:3195346:3195463 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62
291: hkn0624:1758078:1758198 [3] NCCL INFO Trees [0] -1/-1/-1->291->290 [1] -1/-1/-1->291->290
  5: hkn0404:1324527:1324632 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
505: hkn0815:380329:380451 [1] NCCL INFO Trees [0] 506/500/-1->505->504 [1] 506/-1/-1->505->504
511: hkn0816:360780:360901 [3] NCCL INFO Trees [0] -1/-1/-1->511->510 [1] -1/-1/-1->511->510
511: hkn0816:360780:360901 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  2: hkn0403:1738697:1739060 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
339: hkn0703:726146:726263 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
387: hkn0716:93654:93766 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
374: hkn0713:455429:455542 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 14: hkn0407:1801449:1801570 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
378: hkn0714:417196:417322 [2] NCCL INFO Trees [0] 379/-1/-1->378->377 [1] 379/-1/-1->378->377
383: hkn0715:387112:387222 [3] NCCL INFO Trees [0] -1/-1/-1->383->382 [1] -1/-1/-1->383->382
 22: hkn0409:2570866:2570968 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21
 22: hkn0409:2570866:2570968 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 11: hkn0405:3191884:3191996 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10
303: hkn0628:656987:657106 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
314: hkn0631:1006951:1007072 [2] NCCL INFO Trees [0] 315/-1/-1->314->313 [1] 315/-1/-1->314->313
319: hkn0632:1743781:1743911 [3] NCCL INFO Trees [0] -1/-1/-1->319->318 [1] -1/-1/-1->319->318
 16: hkn0408:2875836:2875939 [0] NCCL INFO Trees [0] 17/24/-1->16->33 [1] 17/-1/-1->16->20
307: hkn0629:1577178:1577305 [3] NCCL INFO Trees [0] -1/-1/-1->307->306 [1] -1/-1/-1->307->306
307: hkn0629:1577178:1577305 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 58: hkn0419:1529472:1529584 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57
320: hkn0633:1511506:1511630 [0] NCCL INFO Trees [0] 321/352/-1->320->385 [1] 321/-1/-1->320->324
320: hkn0633:1511506:1511630 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
296: hkn0627:1773062:1773179 [0] NCCL INFO Trees [0] 297/300/-1->296->305 [1] 297/-1/-1->296->293
296: hkn0627:1773062:1773179 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
308: hkn0630:1583656:1583761 [0] NCCL INFO Trees [0] 309/-1/-1->308->313 [1] 309/304/-1->308->301
 63: hkn0420:3195346:3195463 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
291: hkn0624:1758078:1758198 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  6: hkn0404:1324539:1324635 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
505: hkn0815:380329:380451 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
509: hkn0816:360808:360905 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
337: hkn0703:726148:726258 [1] NCCL INFO Trees [0] 338/328/-1->337->336 [1] 338/-1/-1->337->336
385: hkn0716:93646:93761 [1] NCCL INFO Trees [0] 386/320/-1->385->384 [1] 386/-1/-1->385->384
 15: hkn0407:1801457:1801568 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
378: hkn0714:417196:417322 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
388: hkn0717:4172687:4172818 [0] NCCL INFO Trees [0] 389/-1/-1->388->393 [1] 389/384/-1->388->396
382: hkn0715:387104:387217 [2] NCCL INFO Trees [0] 383/-1/-1->382->381 [1] 383/-1/-1->382->381
 23: hkn0409:2570858:2570973 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22
 23: hkn0409:2570858:2570973 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  8: hkn0405:3191892:3192005 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
300: hkn0628:656995:657105 [0] NCCL INFO Trees [0] 301/-1/-1->300->296 [1] 301/292/-1->300->285
314: hkn0631:1006951:1007072 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
319: hkn0632:1743781:1743911 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 17: hkn0408:2875824:2875937 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] 18/-1/-1->17->16
 17: hkn0408:2875824:2875937 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
304: hkn0629:1577186:1577310 [0] NCCL INFO Trees [0] 305/312/-1->304->288 [1] 305/-1/-1->304->308
 58: hkn0419:1529472:1529584 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
309: hkn0630:1583628:1583756 [1] NCCL INFO Trees [0] 310/-1/-1->309->308 [1] 310/312/-1->309->308
309: hkn0630:1583628:1583756 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 60: hkn0420:3195338:3195466 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/28/-1->60->124
 60: hkn0420:3195338:3195466 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  7: hkn0404:1324519:1324638 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
504: hkn0815:380357:380455 [0] NCCL INFO Trees [0] 505/508/-1->504->496 [1] 505/-1/-1->504->501
336: hkn0703:726160:726259 [0] NCCL INFO Trees [0] 337/344/-1->336->353 [1] 337/-1/-1->336->340
386: hkn0716:93666:93764 [2] NCCL INFO Trees [0] 387/-1/-1->386->385 [1] 387/-1/-1->386->385
 12: hkn0407:1801469:1801564 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/4/-1->12->28
 12: hkn0407:1801469:1801564 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
377: hkn0714:417216:417317 [1] NCCL INFO Trees [0] 378/372/-1->377->376 [1] 378/-1/-1->377->376
377: hkn0714:417216:417317 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
388: hkn0717:4172687:4172818 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
383: hkn0715:387112:387222 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 21: hkn0409:2570850:2570977 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 11: hkn0405:3191884:3191996 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
302: hkn0628:656986:657104 [2] NCCL INFO Trees [0] 303/-1/-1->302->301 [1] 303/-1/-1->302->301
316: hkn0632:1743761:1743906 [0] NCCL INFO Trees [0] 317/-1/-1->316->312 [1] 317/284/-1->316->380
 16: hkn0408:2875836:2875939 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
304: hkn0629:1577186:1577310 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
322: hkn0633:1511522:1511638 [2] NCCL INFO Trees [0] 323/-1/-1->322->321 [1] 323/-1/-1->322->321
322: hkn0633:1511522:1511638 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
310: hkn0630:1583644:1583757 [2] NCCL INFO Trees [0] 311/-1/-1->310->309 [1] 311/-1/-1->310->309
310: hkn0630:1583644:1583757 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 61: hkn0420:3195354:3195457 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/92/-1->61->60
 61: hkn0420:3195354:3195457 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  6: hkn0404:1324539:1324635 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
504: hkn0815:380357:380455 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
337: hkn0703:726148:726258 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
384: hkn0716:93645:93760 [0] NCCL INFO Trees [0] 385/448/-1->384->256 [1] 385/-1/-1->384->388
 13: hkn0407:1801441:1801573 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/20/-1->13->12
 13: hkn0407:1801441:1801573 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
379: hkn0714:417204:417316 [3] NCCL INFO Trees [0] -1/-1/-1->379->378 [1] -1/-1/-1->379->378
380: hkn0715:387124:387215 [0] NCCL INFO Trees [0] 381/-1/-1->380->376 [1] 381/316/-1->380->253
  9: hkn0405:3191904:3192003 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/-1/-1->9->8
300: hkn0628:656995:657105 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
312: hkn0631:1006952:1007073 [0] NCCL INFO Trees [0] 313/316/-1->312->304 [1] 313/-1/-1->312->309
324: hkn0634:1506032:1506151 [0] NCCL INFO Trees [0] 325/-1/-1->324->329 [1] 325/320/-1->324->332
317: hkn0632:1743769:1743914 [1] NCCL INFO Trees [0] 318/-1/-1->317->316 [1] 318/348/-1->317->316
 18: hkn0408:2875808:2875934 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17
 64: hkn0421:2163508:2163779 [0] NCCL INFO Trees [0] 65/96/-1->64->129 [1] 65/-1/-1->64->68
321: hkn0633:1511514:1511639 [1] NCCL INFO Trees [0] 322/288/-1->321->320 [1] 322/-1/-1->321->320
321: hkn0633:1511514:1511639 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
308: hkn0630:1583656:1583761 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 62: hkn0420:3195366:3195465 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61
 62: hkn0420:3195366:3195465 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  7: hkn0404:1324519:1324638 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
336: hkn0703:726160:726259 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
385: hkn0716:93646:93761 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 15: hkn0407:1801457:1801568 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
379: hkn0714:417204:417316 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
382: hkn0715:387104:387217 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 10: hkn0405:3191876:3192004 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
302: hkn0628:656986:657104 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
313: hkn0631:1006972:1007066 [1] NCCL INFO Trees [0] 314/308/-1->313->312 [1] 314/-1/-1->313->312
318: hkn0632:1743760:1743909 [2] NCCL INFO Trees [0] 319/-1/-1->318->317 [1] 319/-1/-1->318->317
 19: hkn0408:2875816:2875935 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18
 64: hkn0421:2163508:2163779 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
334: hkn0636:1639350:1639453 [2] NCCL INFO Trees [0] 335/-1/-1->334->333 [1] 335/-1/-1->334->333
334: hkn0636:1639350:1639453 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
323: hkn0633:1511534:1511635 [3] NCCL INFO Trees [0] -1/-1/-1->323->322 [1] -1/-1/-1->323->322
323: hkn0633:1511534:1511635 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
330: hkn0635:1210755:1210867 [2] NCCL INFO Trees [0] 331/-1/-1->330->329 [1] 331/-1/-1->330->329
386: hkn0716:93666:93764 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
380: hkn0715:387124:387215 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  9: hkn0405:3191904:3192003 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
315: hkn0631:1006960:1007067 [3] NCCL INFO Trees [0] -1/-1/-1->315->314 [1] -1/-1/-1->315->314
325: hkn0634:1506024:1506157 [1] NCCL INFO Trees [0] 326/-1/-1->325->324 [1] 326/328/-1->325->324
325: hkn0634:1506024:1506157 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
316: hkn0632:1743761:1743906 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 18: hkn0408:2875808:2875934 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
335: hkn0636:1639362:1639461 [3] NCCL INFO Trees [0] -1/-1/-1->335->334 [1] -1/-1/-1->335->334
384: hkn0716:93645:93760 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 10: hkn0405:3191876:3192004 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
312: hkn0631:1006952:1007073 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
326: hkn0634:1506052:1506156 [2] NCCL INFO Trees [0] 327/-1/-1->326->325 [1] 327/-1/-1->326->325
326: hkn0634:1506052:1506156 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
317: hkn0632:1743769:1743914 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 19: hkn0408:2875816:2875935 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 65: hkn0421:2163528:2163777 [1] NCCL INFO Trees [0] 66/32/-1->65->64 [1] 66/-1/-1->65->64
335: hkn0636:1639362:1639461 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
330: hkn0635:1210755:1210867 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
313: hkn0631:1006972:1007066 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
327: hkn0634:1506040:1506149 [3] NCCL INFO Trees [0] -1/-1/-1->327->326 [1] -1/-1/-1->327->326
327: hkn0634:1506040:1506149 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
318: hkn0632:1743760:1743909 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 65: hkn0421:2163528:2163777 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 68: hkn0422:4138173:4138299 [0] NCCL INFO Trees [0] 69/-1/-1->68->73 [1] 69/64/-1->68->76
332: hkn0636:1639342:1639458 [0] NCCL INFO Trees [0] 333/-1/-1->332->328 [1] 333/324/-1->332->348
315: hkn0631:1006960:1007067 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
324: hkn0634:1506032:1506151 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 67: hkn0421:2163500:2163778 [3] NCCL INFO Trees [0] -1/-1/-1->67->66 [1] -1/-1/-1->67->66
333: hkn0636:1639334:1639456 [1] NCCL INFO Trees [0] 334/-1/-1->333->332 [1] 334/340/-1->333->332
 67: hkn0421:2163500:2163778 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
332: hkn0636:1639342:1639458 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 66: hkn0421:2163516:2163782 [2] NCCL INFO Trees [0] 67/-1/-1->66->65 [1] 67/-1/-1->66->65
 66: hkn0421:2163516:2163782 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
333: hkn0636:1639334:1639456 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
329: hkn0635:1210739:1210866 [1] NCCL INFO Trees [0] 330/324/-1->329->328 [1] 330/-1/-1->329->328
 70: hkn0422:4138165:4138293 [2] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 71/-1/-1->70->69
 70: hkn0422:4138165:4138293 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
329: hkn0635:1210739:1210866 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 68: hkn0422:4138173:4138299 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
328: hkn0635:1210747:1210870 [0] NCCL INFO Trees [0] 329/332/-1->328->337 [1] 329/-1/-1->328->325
 69: hkn0422:4138181:4138294 [1] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 70/72/-1->69->68
331: hkn0635:1210773:1210865 [3] NCCL INFO Trees [0] -1/-1/-1->331->330 [1] -1/-1/-1->331->330
 69: hkn0422:4138181:4138294 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
328: hkn0635:1210747:1210870 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 71: hkn0422:4138193:4138296 [3] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] -1/-1/-1->71->70
331: hkn0635:1210773:1210865 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 73: hkn0423:1689969:1690080 [1] NCCL INFO Trees [0] 74/68/-1->73->72 [1] 74/-1/-1->73->72
 71: hkn0422:4138193:4138296 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 73: hkn0423:1689969:1690080 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 74: hkn0423:1689961:1690083 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] 75/-1/-1->74->73
 74: hkn0423:1689961:1690083 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 72: hkn0423:1689989:1690089 [0] NCCL INFO Trees [0] 73/76/-1->72->81 [1] 73/-1/-1->72->69
117: hkn0506:823185:823311 [1] NCCL INFO Trees [0] 118/-1/-1->117->116 [1] 118/120/-1->117->116
117: hkn0506:823185:823311 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 77: hkn0424:2933097:2933239 [1] NCCL INFO Trees [0] 78/-1/-1->77->76 [1] 78/84/-1->77->76
 80: hkn0425:2069098:2069207 [0] NCCL INFO Trees [0] 81/88/-1->80->97 [1] 81/-1/-1->80->84
116: hkn0506:823193:823308 [0] NCCL INFO Trees [0] 117/-1/-1->116->121 [1] 117/112/-1->116->109
 77: hkn0424:2933097:2933239 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 72: hkn0423:1689989:1690089 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 80: hkn0425:2069098:2069207 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
116: hkn0506:823193:823308 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 75: hkn0423:1689977:1690087 [3] NCCL INFO Trees [0] -1/-1/-1->75->74 [1] -1/-1/-1->75->74
 81: hkn0425:2069090:2069201 [1] NCCL INFO Trees [0] 82/72/-1->81->80 [1] 82/-1/-1->81->80
 79: hkn0424:2933081:2933238 [3] NCCL INFO Trees [0] -1/-1/-1->79->78 [1] -1/-1/-1->79->78
 75: hkn0423:1689977:1690087 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 81: hkn0425:2069090:2069201 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 79: hkn0424:2933081:2933238 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 83: hkn0425:2069106:2069204 [3] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] -1/-1/-1->83->82
 76: hkn0424:2933109:2933241 [0] NCCL INFO Trees [0] 77/-1/-1->76->72 [1] 77/68/-1->76->92
 83: hkn0425:2069106:2069204 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 78: hkn0424:2933089:2933240 [2] NCCL INFO Trees [0] 79/-1/-1->78->77 [1] 79/-1/-1->78->77
 78: hkn0424:2933089:2933240 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
103: hkn0502:214196:214352 [3] NCCL INFO Trees [0] -1/-1/-1->103->102 [1] -1/-1/-1->103->102
 82: hkn0425:2069118:2069202 [2] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 83/-1/-1->82->81
 85: hkn0426:799266:799362 [1] NCCL INFO Trees [0] 86/-1/-1->85->84 [1] 86/88/-1->85->84
 76: hkn0424:2933109:2933241 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 82: hkn0425:2069118:2069202 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 85: hkn0426:799266:799362 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
101: hkn0502:214224:214351 [1] NCCL INFO Trees [0] 102/-1/-1->101->100 [1] 102/104/-1->101->100
 99: hkn0501:1312982:1313098 [3] NCCL INFO Trees [0] -1/-1/-1->99->98 [1] -1/-1/-1->99->98
 89: hkn0427:1120325:1120445 [1] NCCL INFO Trees [0] 90/84/-1->89->88 [1] 90/-1/-1->89->88
103: hkn0502:214196:214352 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
105: hkn0503:2884817:2884916 [1] NCCL INFO Trees [0] 106/100/-1->105->104 [1] 106/-1/-1->105->104
 99: hkn0501:1312982:1313098 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 87: hkn0426:799254:799358 [3] NCCL INFO Trees [0] -1/-1/-1->87->86 [1] -1/-1/-1->87->86
 89: hkn0427:1120325:1120445 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
101: hkn0502:214224:214351 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 93: hkn0428:652517:652634 [1] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 94/108/-1->93->92
 93: hkn0428:652517:652634 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 98: hkn0501:1312966:1313101 [2] NCCL INFO Trees [0] 99/-1/-1->98->97 [1] 99/-1/-1->98->97
 98: hkn0501:1312966:1313101 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 87: hkn0426:799254:799358 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 90: hkn0427:1120345:1120439 [2] NCCL INFO Trees [0] 91/-1/-1->90->89 [1] 91/-1/-1->90->89
102: hkn0502:214204:214346 [2] NCCL INFO Trees [0] 103/-1/-1->102->101 [1] 103/-1/-1->102->101
 86: hkn0426:799246:799367 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] 87/-1/-1->86->85
 91: hkn0427:1120333:1120440 [3] NCCL INFO Trees [0] -1/-1/-1->91->90 [1] -1/-1/-1->91->90
102: hkn0502:214204:214346 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 94: hkn0428:652525:652632 [2] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 95/-1/-1->94->93
 94: hkn0428:652525:652632 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 86: hkn0426:799246:799367 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 90: hkn0427:1120345:1120439 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
100: hkn0502:214212:214345 [0] NCCL INFO Trees [0] 101/-1/-1->100->105 [1] 101/96/-1->100->108
100: hkn0502:214212:214345 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 95: hkn0428:652509:652633 [3] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] -1/-1/-1->95->94
 95: hkn0428:652509:652633 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 96: hkn0501:1312974:1313097 [0] NCCL INFO Trees [0] 97/112/-1->96->64 [1] 97/-1/-1->96->100
 84: hkn0426:799238:799364 [0] NCCL INFO Trees [0] 85/-1/-1->84->89 [1] 85/80/-1->84->77
 84: hkn0426:799238:799364 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 91: hkn0427:1120333:1120440 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 92: hkn0428:652537:652628 [0] NCCL INFO Trees [0] 93/-1/-1->92->88 [1] 93/76/-1->92->61
105: hkn0503:2884817:2884916 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 97: hkn0501:1312996:1313099 [1] NCCL INFO Trees [0] 98/80/-1->97->96 [1] 98/-1/-1->97->96
 88: hkn0427:1120324:1120446 [0] NCCL INFO Trees [0] 89/92/-1->88->80 [1] 89/-1/-1->88->85
108: hkn0504:25965:26094 [0] NCCL INFO Trees [0] 109/-1/-1->108->104 [1] 109/100/-1->108->93
108: hkn0504:25965:26094 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
112: hkn0505:2288969:2289061 [0] NCCL INFO Trees [0] 113/120/-1->112->96 [1] 113/-1/-1->112->116
 92: hkn0428:652537:652628 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
104: hkn0503:2884789:2884923 [0] NCCL INFO Trees [0] 105/108/-1->104->113 [1] 105/-1/-1->104->101
 96: hkn0501:1312974:1313097 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 88: hkn0427:1120324:1120446 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
111: hkn0504:25981:26087 [3] NCCL INFO Trees [0] -1/-1/-1->111->110 [1] -1/-1/-1->111->110
111: hkn0504:25981:26087 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
114: hkn0505:2288957:2289067 [2] NCCL INFO Trees [0] 115/-1/-1->114->113 [1] 115/-1/-1->114->113
104: hkn0503:2884789:2884923 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 97: hkn0501:1312996:1313099 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
115: hkn0505:2288941:2289062 [3] NCCL INFO Trees [0] -1/-1/-1->115->114 [1] -1/-1/-1->115->114
106: hkn0503:2884805:2884921 [2] NCCL INFO Trees [0] 107/-1/-1->106->105 [1] 107/-1/-1->106->105
109: hkn0504:25973:26092 [1] NCCL INFO Trees [0] 110/-1/-1->109->108 [1] 110/116/-1->109->108
109: hkn0504:25973:26092 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
112: hkn0505:2288969:2289061 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
106: hkn0503:2884805:2884921 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
114: hkn0505:2288957:2289067 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
107: hkn0503:2884797:2884917 [3] NCCL INFO Trees [0] -1/-1/-1->107->106 [1] -1/-1/-1->107->106
110: hkn0504:25993:26089 [2] NCCL INFO Trees [0] 111/-1/-1->110->109 [1] 111/-1/-1->110->109
115: hkn0505:2288941:2289062 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
107: hkn0503:2884797:2884917 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
110: hkn0504:25993:26089 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
113: hkn0505:2288949:2289068 [1] NCCL INFO Trees [0] 114/104/-1->113->112 [1] 114/-1/-1->113->112
113: hkn0505:2288949:2289068 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
242: hkn0607:889522:889635 [2] NCCL INFO Channel 00 : 242[ca000] -> 241[4b000] via P2P/IPC/read
406: hkn0721:2284171:2284267 [2] NCCL INFO Channel 00 : 406[ca000] -> 405[4b000] via P2P/IPC/read
238: hkn0606:2357175:2357324 [2] NCCL INFO Channel 00 : 238[ca000] -> 237[4b000] via P2P/IPC/read
234: hkn0605:697234:697394 [2] NCCL INFO Channel 00 : 234[ca000] -> 233[4b000] via P2P/IPC/read
230: hkn0604:674446:674565 [2] NCCL INFO Channel 00 : 230[ca000] -> 229[4b000] via P2P/IPC/read
418: hkn0725:3097089:3097197 [2] NCCL INFO Channel 00 : 418[ca000] -> 417[4b000] via P2P/IPC/read
410: hkn0723:192937:193090 [2] NCCL INFO Channel 00 : 410[ca000] -> 409[4b000] via P2P/IPC/read
246: hkn0608:470915:471032 [2] NCCL INFO Channel 00 : 246[ca000] -> 245[4b000] via P2P/IPC/read
406: hkn0721:2284171:2284267 [2] NCCL INFO Channel 01 : 406[ca000] -> 405[4b000] via P2P/IPC/read
414: hkn0724:1701124:1701254 [2] NCCL INFO Channel 00 : 414[ca000] -> 413[4b000] via P2P/IPC/read
242: hkn0607:889522:889635 [2] NCCL INFO Channel 01 : 242[ca000] -> 241[4b000] via P2P/IPC/read
422: hkn0726:1533298:1533416 [2] NCCL INFO Channel 00 : 422[ca000] -> 421[4b000] via P2P/IPC/read
194: hkn0529:1526011:1526128 [2] NCCL INFO Channel 00 : 194[ca000] -> 193[4b000] via P2P/IPC/read
486: hkn0808:955867:955976 [2] NCCL INFO Channel 00 : 486[ca000] -> 485[4b000] via P2P/IPC/read
426: hkn0727:1330937:1331047 [2] NCCL INFO Channel 00 : 426[ca000] -> 425[4b000] via P2P/IPC/read
398: hkn0719:1290848:1290952 [2] NCCL INFO Channel 00 : 398[ca000] -> 397[4b000] via P2P/IPC/read
450: hkn0734:1141720:1141848 [2] NCCL INFO Channel 00 : 450[ca000] -> 449[4b000] via P2P/IPC/read
258: hkn0612:902136:902248 [2] NCCL INFO Channel 00 : 258[ca000] -> 257[4b000] via P2P/IPC/read
442: hkn0732:1196803:1196961 [2] NCCL INFO Channel 00 : 442[ca000] -> 441[4b000] via P2P/IPC/read
250: hkn0609:696036:696151 [2] NCCL INFO Channel 00 : 250[ca000] -> 249[4b000] via P2P/IPC/read
434: hkn0730:1386902:1387024 [2] NCCL INFO Channel 00 : 434[ca000] -> 433[4b000] via P2P/IPC/read
430: hkn0728:1309110:1309210 [2] NCCL INFO Channel 00 : 430[ca000] -> 429[4b000] via P2P/IPC/read
190: hkn0528:1286863:1286971 [2] NCCL INFO Channel 00 : 190[ca000] -> 189[4b000] via P2P/IPC/read
478: hkn0806:1039513:1039607 [2] NCCL INFO Channel 00 : 478[ca000] -> 477[4b000] via P2P/IPC/read
446: hkn0733:1374549:1374669 [2] NCCL INFO Channel 00 : 446[ca000] -> 445[4b000] via P2P/IPC/read
482: hkn0807:1004292:1004392 [2] NCCL INFO Channel 00 : 482[ca000] -> 481[4b000] via P2P/IPC/read
230: hkn0604:674446:674565 [2] NCCL INFO Channel 01 : 230[ca000] -> 229[4b000] via P2P/IPC/read
410: hkn0723:192937:193090 [2] NCCL INFO Channel 01 : 410[ca000] -> 409[4b000] via P2P/IPC/read
234: hkn0605:697234:697394 [2] NCCL INFO Channel 01 : 234[ca000] -> 233[4b000] via P2P/IPC/read
466: hkn0803:861668:861780 [2] NCCL INFO Channel 00 : 466[ca000] -> 465[4b000] via P2P/IPC/read
490: hkn0809:922569:922682 [2] NCCL INFO Channel 00 : 490[ca000] -> 489[4b000] via P2P/IPC/read
474: hkn0805:1097271:1097381 [2] NCCL INFO Channel 00 : 474[ca000] -> 473[4b000] via P2P/IPC/read
458: hkn0801:2225110:2225221 [2] NCCL INFO Channel 00 : 458[ca000] -> 457[4b000] via P2P/IPC/read
438: hkn0731:1371892:1372022 [2] NCCL INFO Channel 00 : 438[ca000] -> 437[4b000] via P2P/IPC/read
470: hkn0804:1190787:1190892 [2] NCCL INFO Channel 00 : 470[ca000] -> 469[4b000] via P2P/IPC/read
246: hkn0608:470915:471032 [2] NCCL INFO Channel 01 : 246[ca000] -> 245[4b000] via P2P/IPC/read
 26: hkn0410:1144773:1144892 [2] NCCL INFO Channel 00 : 26[ca000] -> 25[4b000] via P2P/IPC/read
210: hkn0534:1133593:1133689 [2] NCCL INFO Channel 00 : 210[ca000] -> 209[4b000] via P2P/IPC/read
494: hkn0810:924728:924849 [2] NCCL INFO Channel 00 : 494[ca000] -> 493[4b000] via P2P/IPC/read
454: hkn0736:1493528:1493648 [2] NCCL INFO Channel 00 : 454[ca000] -> 453[4b000] via P2P/IPC/read
254: hkn0611:694965:695087 [2] NCCL INFO Channel 00 : 254[ca000] -> 253[4b000] via P2P/IPC/read
202: hkn0531:1215712:1215824 [2] NCCL INFO Channel 00 : 202[ca000] -> 201[4b000] via P2P/IPC/read
418: hkn0725:3097089:3097197 [2] NCCL INFO Channel 01 : 418[ca000] -> 417[4b000] via P2P/IPC/read
 38: hkn0413:2351846:2351938 [2] NCCL INFO Channel 00 : 38[ca000] -> 37[4b000] via P2P/IPC/read
414: hkn0724:1701124:1701254 [2] NCCL INFO Channel 01 : 414[ca000] -> 413[4b000] via P2P/IPC/read
238: hkn0606:2357175:2357324 [2] NCCL INFO Channel 01 : 238[ca000] -> 237[4b000] via P2P/IPC/read
402: hkn0720:4181548:4181824 [2] NCCL INFO Channel 00 : 402[ca000] -> 401[4b000] via P2P/IPC/read
422: hkn0726:1533298:1533416 [2] NCCL INFO Channel 01 : 422[ca000] -> 421[4b000] via P2P/IPC/read
462: hkn0802:1185507:1185616 [2] NCCL INFO Channel 00 : 462[ca000] -> 461[4b000] via P2P/IPC/read
 42: hkn0414:1966704:1966820 [2] NCCL INFO Channel 00 : 42[ca000] -> 41[4b000] via P2P/IPC/read
 50: hkn0417:2252730:2252862 [2] NCCL INFO Channel 00 : 50[ca000] -> 49[4b000] via P2P/IPC/read
398: hkn0719:1290848:1290952 [2] NCCL INFO Channel 01 : 398[ca000] -> 397[4b000] via P2P/IPC/read
266: hkn0615:399419:399548 [2] NCCL INFO Channel 00 : 266[ca000] -> 265[4b000] via P2P/IPC/read
226: hkn0603:1398315:1398422 [2] NCCL INFO Channel 00 : 226[ca000] -> 225[4b000] via P2P/IPC/read
262: hkn0613:887824:887976 [2] NCCL INFO Channel 00 : 262[ca000] -> 261[4b000] via P2P/IPC/read
 34: hkn0412:2247554:2247673 [2] NCCL INFO Channel 00 : 34[ca000] -> 33[4b000] via P2P/IPC/read
426: hkn0727:1330937:1331047 [2] NCCL INFO Channel 01 : 426[ca000] -> 425[4b000] via P2P/IPC/read
130: hkn0509:3109548:3109677 [2] NCCL INFO Channel 00 : 130[ca000] -> 129[4b000] via P2P/IPC/read
270: hkn0616:389969:390099 [2] NCCL INFO Channel 00 : 270[ca000] -> 269[4b000] via P2P/IPC/read
250: hkn0609:696036:696151 [2] NCCL INFO Channel 01 : 250[ca000] -> 249[4b000] via P2P/IPC/read
198: hkn0530:1243309:1243429 [2] NCCL INFO Channel 00 : 198[ca000] -> 197[4b000] via P2P/IPC/read
394: hkn0718:3902173:3902289 [2] NCCL INFO Channel 00 : 394[ca000] -> 393[4b000] via P2P/IPC/read
430: hkn0728:1309110:1309210 [2] NCCL INFO Channel 01 : 430[ca000] -> 429[4b000] via P2P/IPC/read
390: hkn0717:4172695:4172824 [2] NCCL INFO Channel 00 : 390[ca000] -> 389[4b000] via P2P/IPC/read
274: hkn0617:2279774:2279896 [2] NCCL INFO Channel 00 : 274[ca000] -> 273[4b000] via P2P/IPC/read
482: hkn0807:1004292:1004392 [2] NCCL INFO Channel 01 : 482[ca000] -> 481[4b000] via P2P/IPC/read
 30: hkn0411:2301012:2301139 [2] NCCL INFO Channel 00 : 30[ca000] -> 29[4b000] via P2P/IPC/read
194: hkn0529:1526011:1526128 [2] NCCL INFO Channel 01 : 194[ca000] -> 193[4b000] via P2P/IPC/read
486: hkn0808:955867:955976 [2] NCCL INFO Channel 01 : 486[ca000] -> 485[4b000] via P2P/IPC/read
134: hkn0510:2747248:2747351 [2] NCCL INFO Channel 00 : 134[ca000] -> 133[4b000] via P2P/IPC/read
218: hkn0601:102824:102933 [2] NCCL INFO Channel 00 : 218[ca000] -> 217[4b000] via P2P/IPC/read
458: hkn0801:2225110:2225221 [2] NCCL INFO Channel 01 : 458[ca000] -> 457[4b000] via P2P/IPC/read
442: hkn0732:1196803:1196961 [2] NCCL INFO Channel 01 : 442[ca000] -> 441[4b000] via P2P/IPC/read
222: hkn0602:3345207:3345482 [2] NCCL INFO Channel 00 : 222[ca000] -> 221[4b000] via P2P/IPC/read
138: hkn0511:3051491:3051603 [2] NCCL INFO Channel 00 : 138[ca000] -> 137[4b000] via P2P/IPC/read
446: hkn0733:1374549:1374669 [2] NCCL INFO Channel 01 : 446[ca000] -> 445[4b000] via P2P/IPC/read
206: hkn0532:908802:909093 [2] NCCL INFO Channel 00 : 206[ca000] -> 205[4b000] via P2P/IPC/read
254: hkn0611:694965:695087 [2] NCCL INFO Channel 01 : 254[ca000] -> 253[4b000] via P2P/IPC/read
 26: hkn0410:1144773:1144892 [2] NCCL INFO Channel 01 : 26[ca000] -> 25[4b000] via P2P/IPC/read
258: hkn0612:902136:902248 [2] NCCL INFO Channel 01 : 258[ca000] -> 257[4b000] via P2P/IPC/read
150: hkn0514:2935913:2936009 [2] NCCL INFO Channel 00 : 150[ca000] -> 149[4b000] via P2P/IPC/read
 46: hkn0415:2481504:2481617 [2] NCCL INFO Channel 00 : 46[ca000] -> 45[4b000] via P2P/IPC/read
454: hkn0736:1493528:1493648 [2] NCCL INFO Channel 01 : 454[ca000] -> 453[4b000] via P2P/IPC/read
214: hkn0535:2384181:2384305 [2] NCCL INFO Channel 00 : 214[ca000] -> 213[4b000] via P2P/IPC/read
278: hkn0621:1976647:1976747 [2] NCCL INFO Channel 00 : 278[ca000] -> 277[4b000] via P2P/IPC/read
342: hkn0704:777150:777271 [2] NCCL INFO Channel 00 : 342[ca000] -> 341[4b000] via P2P/IPC/read
450: hkn0734:1141720:1141848 [2] NCCL INFO Channel 01 : 450[ca000] -> 449[4b000] via P2P/IPC/read
178: hkn0525:972003:972097 [2] NCCL INFO Channel 00 : 178[ca000] -> 177[4b000] via P2P/IPC/read
142: hkn0512:3029322:3029415 [2] NCCL INFO Channel 00 : 142[ca000] -> 141[4b000] via P2P/IPC/read
170: hkn0523:1533170:1533292 [2] NCCL INFO Channel 00 : 170[ca000] -> 169[4b000] via P2P/IPC/read
186: hkn0527:1334041:1334160 [2] NCCL INFO Channel 00 : 186[ca000] -> 185[4b000] via P2P/IPC/read
434: hkn0730:1386902:1387024 [2] NCCL INFO Channel 01 : 434[ca000] -> 433[4b000] via P2P/IPC/read
462: hkn0802:1185507:1185616 [2] NCCL INFO Channel 01 : 462[ca000] -> 461[4b000] via P2P/IPC/read
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
498: hkn0812:678929:679040 [2] NCCL INFO Channel 00 : 498[ca000] -> 497[4b000] via P2P/IPC/read
478: hkn0806:1039513:1039607 [2] NCCL INFO Channel 01 : 478[ca000] -> 477[4b000] via P2P/IPC/read
190: hkn0528:1286863:1286971 [2] NCCL INFO Channel 01 : 190[ca000] -> 189[4b000] via P2P/IPC/read
466: hkn0803:861668:861780 [2] NCCL INFO Channel 01 : 466[ca000] -> 465[4b000] via P2P/IPC/read
282: hkn0622:2005581:2005688 [2] NCCL INFO Channel 00 : 282[ca000] -> 281[4b000] via P2P/IPC/read
182: hkn0526:1413581:1413675 [2] NCCL INFO Channel 00 : 182[ca000] -> 181[4b000] via P2P/IPC/read
438: hkn0731:1371892:1372022 [2] NCCL INFO Channel 01 : 438[ca000] -> 437[4b000] via P2P/IPC/read
350: hkn0706:737475:737567 [2] NCCL INFO Channel 00 : 350[ca000] -> 349[4b000] via P2P/IPC/read
470: hkn0804:1190787:1190892 [2] NCCL INFO Channel 01 : 470[ca000] -> 469[4b000] via P2P/IPC/read
354: hkn0707:4005065:4005191 [2] NCCL INFO Channel 00 : 354[ca000] -> 353[4b000] via P2P/IPC/read
122: hkn0507:3172208:3172331 [2] NCCL INFO Channel 00 : 122[ca000] -> 121[4b000] via P2P/IPC/read
210: hkn0534:1133593:1133689 [2] NCCL INFO Channel 01 : 210[ca000] -> 209[4b000] via P2P/IPC/read
474: hkn0805:1097271:1097381 [2] NCCL INFO Channel 01 : 474[ca000] -> 473[4b000] via P2P/IPC/read
162: hkn0520:2698027:2698123 [2] NCCL INFO Channel 00 : 162[ca000] -> 161[4b000] via P2P/IPC/read
262: hkn0613:887824:887976 [2] NCCL INFO Channel 01 : 262[ca000] -> 261[4b000] via P2P/IPC/read
266: hkn0615:399419:399548 [2] NCCL INFO Channel 01 : 266[ca000] -> 265[4b000] via P2P/IPC/read
174: hkn0524:1118942:1119055 [2] NCCL INFO Channel 00 : 174[ca000] -> 173[4b000] via P2P/IPC/read
390: hkn0717:4172695:4172824 [2] NCCL INFO Channel 01 : 390[ca000] -> 389[4b000] via P2P/IPC/read
154: hkn0515:2881950:2882069 [2] NCCL INFO Channel 00 : 154[ca000] -> 153[4b000] via P2P/IPC/read
298: hkn0627:1773054:1773175 [2] NCCL INFO Channel 00 : 298[ca000] -> 297[4b000] via P2P/IPC/read
198: hkn0530:1243309:1243429 [2] NCCL INFO Channel 01 : 198[ca000] -> 197[4b000] via P2P/IPC/read
202: hkn0531:1215712:1215824 [2] NCCL INFO Channel 01 : 202[ca000] -> 201[4b000] via P2P/IPC/read
126: hkn0508:3124297:3124412 [2] NCCL INFO Channel 00 : 126[ca000] -> 125[4b000] via P2P/IPC/read
 38: hkn0413:2351846:2351938 [2] NCCL INFO Channel 01 : 38[ca000] -> 37[4b000] via P2P/IPC/read
 42: hkn0414:1966704:1966820 [2] NCCL INFO Channel 01 : 42[ca000] -> 41[4b000] via P2P/IPC/read
 30: hkn0411:2301012:2301139 [2] NCCL INFO Channel 01 : 30[ca000] -> 29[4b000] via P2P/IPC/read
240: hkn0607:889534:889628 [0] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
158: hkn0516:2901144:2901290 [2] NCCL INFO Channel 00 : 158[ca000] -> 157[4b000] via P2P/IPC/read
 34: hkn0412:2247554:2247673 [2] NCCL INFO Channel 01 : 34[ca000] -> 33[4b000] via P2P/IPC/read
270: hkn0616:389969:390099 [2] NCCL INFO Channel 01 : 270[ca000] -> 269[4b000] via P2P/IPC/read
222: hkn0602:3345207:3345482 [2] NCCL INFO Channel 01 : 222[ca000] -> 221[4b000] via P2P/IPC/read
218: hkn0601:102824:102933 [2] NCCL INFO Channel 01 : 218[ca000] -> 217[4b000] via P2P/IPC/read
294: hkn0626:1283606:1283705 [2] NCCL INFO Channel 00 : 294[ca000] -> 293[4b000] via P2P/IPC/read
402: hkn0720:4181548:4181824 [2] NCCL INFO Channel 01 : 402[ca000] -> 401[4b000] via P2P/IPC/read
  2: hkn0403:1738697:1739060 [2] NCCL INFO Channel 00 : 2[ca000] -> 1[4b000] via P2P/IPC/read
362: hkn0710:340630:340740 [2] NCCL INFO Channel 00 : 362[ca000] -> 361[4b000] via P2P/IPC/read
226: hkn0603:1398315:1398422 [2] NCCL INFO Channel 01 : 226[ca000] -> 225[4b000] via P2P/IPC/read
130: hkn0509:3109548:3109677 [2] NCCL INFO Channel 01 : 130[ca000] -> 129[4b000] via P2P/IPC/read
146: hkn0513:2998110:2998204 [2] NCCL INFO Channel 00 : 146[ca000] -> 145[4b000] via P2P/IPC/read
506: hkn0815:380337:380459 [2] NCCL INFO Channel 00 : 506[ca000] -> 505[4b000] via P2P/IPC/read
394: hkn0718:3902173:3902289 [2] NCCL INFO Channel 01 : 394[ca000] -> 393[4b000] via P2P/IPC/read
 50: hkn0417:2252730:2252862 [2] NCCL INFO Channel 01 : 50[ca000] -> 49[4b000] via P2P/IPC/read
278: hkn0621:1976647:1976747 [2] NCCL INFO Channel 01 : 278[ca000] -> 277[4b000] via P2P/IPC/read
150: hkn0514:2935913:2936009 [2] NCCL INFO Channel 01 : 150[ca000] -> 149[4b000] via P2P/IPC/read
302: hkn0628:656986:657104 [2] NCCL INFO Channel 00 : 302[ca000] -> 301[4b000] via P2P/IPC/read
 46: hkn0415:2481504:2481617 [2] NCCL INFO Channel 01 : 46[ca000] -> 45[4b000] via P2P/IPC/read
166: hkn0521:1182970:1183090 [2] NCCL INFO Channel 00 : 166[ca000] -> 165[4b000] via P2P/IPC/read
142: hkn0512:3029322:3029415 [2] NCCL INFO Channel 01 : 142[ca000] -> 141[4b000] via P2P/IPC/read
206: hkn0532:908802:909093 [2] NCCL INFO Channel 01 : 206[ca000] -> 205[4b000] via P2P/IPC/read
346: hkn0705:768409:768518 [2] NCCL INFO Channel 00 : 346[ca000] -> 345[4b000] via P2P/IPC/read
214: hkn0535:2384181:2384305 [2] NCCL INFO Channel 01 : 214[ca000] -> 213[4b000] via P2P/IPC/read
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
286: hkn0623:1857878:1858024 [2] NCCL INFO Channel 00 : 286[ca000] -> 285[4b000] via P2P/IPC/read
170: hkn0523:1533170:1533292 [2] NCCL INFO Channel 01 : 170[ca000] -> 169[4b000] via P2P/IPC/read
186: hkn0527:1334041:1334160 [2] NCCL INFO Channel 01 : 186[ca000] -> 185[4b000] via P2P/IPC/read
502: hkn0814:660989:661111 [2] NCCL INFO Channel 00 : 502[ca000] -> 501[4b000] via P2P/IPC/read
490: hkn0809:922569:922682 [2] NCCL INFO Channel 01 : 490[ca000] -> 489[4b000] via P2P/IPC/read
314: hkn0631:1006951:1007072 [2] NCCL INFO Channel 00 : 314[ca000] -> 313[4b000] via P2P/IPC/read
  6: hkn0404:1324539:1324635 [2] NCCL INFO Channel 00 : 6[ca000] -> 5[4b000] via P2P/IPC/read
498: hkn0812:678929:679040 [2] NCCL INFO Channel 01 : 498[ca000] -> 497[4b000] via P2P/IPC/read
322: hkn0633:1511522:1511638 [2] NCCL INFO Channel 00 : 322[ca000] -> 321[4b000] via P2P/IPC/read
274: hkn0617:2279774:2279896 [2] NCCL INFO Channel 01 : 274[ca000] -> 273[4b000] via P2P/IPC/read
182: hkn0526:1413581:1413675 [2] NCCL INFO Channel 01 : 182[ca000] -> 181[4b000] via P2P/IPC/read
494: hkn0810:924728:924849 [2] NCCL INFO Channel 01 : 494[ca000] -> 493[4b000] via P2P/IPC/read
122: hkn0507:3172208:3172331 [2] NCCL INFO Channel 01 : 122[ca000] -> 121[4b000] via P2P/IPC/read
 54: hkn0418:1854325:1854445 [2] NCCL INFO Channel 00 : 54[ca000] -> 53[4b000] via P2P/IPC/read
374: hkn0713:455429:455542 [2] NCCL INFO Channel 00 : 374[ca000] -> 373[4b000] via P2P/IPC/read
378: hkn0714:417196:417322 [2] NCCL INFO Channel 00 : 378[ca000] -> 377[4b000] via P2P/IPC/read
366: hkn0711:569042:569160 [2] NCCL INFO Channel 00 : 366[ca000] -> 365[4b000] via P2P/IPC/read
 18: hkn0408:2875808:2875934 [2] NCCL INFO Channel 00 : 18[ca000] -> 17[4b000] via P2P/IPC/read
 58: hkn0419:1529472:1529584 [2] NCCL INFO Channel 00 : 58[ca000] -> 57[4b000] via P2P/IPC/read
138: hkn0511:3051491:3051603 [2] NCCL INFO Channel 01 : 138[ca000] -> 137[4b000] via P2P/IPC/read
358: hkn0708:398424:398526 [2] NCCL INFO Channel 00 : 358[ca000] -> 357[4b000] via P2P/IPC/read
 22: hkn0409:2570866:2570968 [2] NCCL INFO Channel 00 : 22[ca000] -> 21[4b000] via P2P/IPC/read
 10: hkn0405:3191876:3192004 [2] NCCL INFO Channel 00 : 10[ca000] -> 9[4b000] via P2P/IPC/read
154: hkn0515:2881950:2882069 [2] NCCL INFO Channel 01 : 154[ca000] -> 153[4b000] via P2P/IPC/read
298: hkn0627:1773054:1773175 [2] NCCL INFO Channel 01 : 298[ca000] -> 297[4b000] via P2P/IPC/read
174: hkn0524:1118942:1119055 [2] NCCL INFO Channel 01 : 174[ca000] -> 173[4b000] via P2P/IPC/read
510: hkn0816:360796:360907 [2] NCCL INFO Channel 00 : 510[ca000] -> 509[4b000] via P2P/IPC/read
338: hkn0703:726147:726262 [2] NCCL INFO Channel 00 : 338[ca000] -> 337[4b000] via P2P/IPC/read
158: hkn0516:2901144:2901290 [2] NCCL INFO Channel 01 : 158[ca000] -> 157[4b000] via P2P/IPC/read
 66: hkn0421:2163516:2163782 [2] NCCL INFO Channel 00 : 66[ca000] -> 65[4b000] via P2P/IPC/read
306: hkn0629:1577206:1577307 [2] NCCL INFO Channel 00 : 306[ca000] -> 305[4b000] via P2P/IPC/read
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
178: hkn0525:972003:972097 [2] NCCL INFO Channel 01 : 178[ca000] -> 177[4b000] via P2P/IPC/read
134: hkn0510:2747248:2747351 [2] NCCL INFO Channel 01 : 134[ca000] -> 133[4b000] via P2P/IPC/read
282: hkn0622:2005581:2005688 [2] NCCL INFO Channel 01 : 282[ca000] -> 281[4b000] via P2P/IPC/read
310: hkn0630:1583644:1583757 [2] NCCL INFO Channel 00 : 310[ca000] -> 309[4b000] via P2P/IPC/read
342: hkn0704:777150:777271 [2] NCCL INFO Channel 01 : 342[ca000] -> 341[4b000] via P2P/IPC/read
233: hkn0605:697262:697393 [1] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
162: hkn0520:2698027:2698123 [2] NCCL INFO Channel 01 : 162[ca000] -> 161[4b000] via P2P/IPC/read
370: hkn0712:280242:280355 [2] NCCL INFO Channel 00 : 370[ca000] -> 369[4b000] via P2P/IPC/read
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
350: hkn0706:737475:737567 [2] NCCL INFO Channel 01 : 350[ca000] -> 349[4b000] via P2P/IPC/read
382: hkn0715:387104:387217 [2] NCCL INFO Channel 00 : 382[ca000] -> 381[4b000] via P2P/IPC/read
318: hkn0632:1743760:1743909 [2] NCCL INFO Channel 00 : 318[ca000] -> 317[4b000] via P2P/IPC/read
 62: hkn0420:3195366:3195465 [2] NCCL INFO Channel 00 : 62[ca000] -> 61[4b000] via P2P/IPC/read
241: hkn0607:889514:889633 [1] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
386: hkn0716:93666:93764 [2] NCCL INFO Channel 00 : 386[ca000] -> 385[4b000] via P2P/IPC/read
506: hkn0815:380337:380459 [2] NCCL INFO Channel 01 : 506[ca000] -> 505[4b000] via P2P/IPC/read
354: hkn0707:4005065:4005191 [2] NCCL INFO Channel 01 : 354[ca000] -> 353[4b000] via P2P/IPC/read
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
256: hkn0612:902120:902251 [0] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
118: hkn0506:823201:823314 [2] NCCL INFO Channel 00 : 118[ca000] -> 117[4b000] via P2P/IPC/read
346: hkn0705:768409:768518 [2] NCCL INFO Channel 01 : 346[ca000] -> 345[4b000] via P2P/IPC/read
326: hkn0634:1506052:1506156 [2] NCCL INFO Channel 00 : 326[ca000] -> 325[4b000] via P2P/IPC/read
166: hkn0521:1182970:1183090 [2] NCCL INFO Channel 01 : 166[ca000] -> 165[4b000] via P2P/IPC/read
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
126: hkn0508:3124297:3124412 [2] NCCL INFO Channel 01 : 126[ca000] -> 125[4b000] via P2P/IPC/read
 14: hkn0407:1801449:1801570 [2] NCCL INFO Channel 00 : 14[ca000] -> 13[4b000] via P2P/IPC/read
314: hkn0631:1006951:1007072 [2] NCCL INFO Channel 01 : 314[ca000] -> 313[4b000] via P2P/IPC/read
286: hkn0623:1857878:1858024 [2] NCCL INFO Channel 01 : 286[ca000] -> 285[4b000] via P2P/IPC/read
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
464: hkn0803:861669:861771 [0] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
  6: hkn0404:1324539:1324635 [2] NCCL INFO Channel 01 : 6[ca000] -> 5[4b000] via P2P/IPC/read
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
294: hkn0626:1283606:1283705 [2] NCCL INFO Channel 01 : 294[ca000] -> 293[4b000] via P2P/IPC/read
 54: hkn0418:1854325:1854445 [2] NCCL INFO Channel 01 : 54[ca000] -> 53[4b000] via P2P/IPC/read
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
  2: hkn0403:1738697:1739060 [2] NCCL INFO Channel 01 : 2[ca000] -> 1[4b000] via P2P/IPC/read
362: hkn0710:340630:340740 [2] NCCL INFO Channel 01 : 362[ca000] -> 361[4b000] via P2P/IPC/read
374: hkn0713:455429:455542 [2] NCCL INFO Channel 01 : 374[ca000] -> 373[4b000] via P2P/IPC/read
366: hkn0711:569042:569160 [2] NCCL INFO Channel 01 : 366[ca000] -> 365[4b000] via P2P/IPC/read
232: hkn0605:697242:697386 [0] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
358: hkn0708:398424:398526 [2] NCCL INFO Channel 01 : 358[ca000] -> 357[4b000] via P2P/IPC/read
302: hkn0628:656986:657104 [2] NCCL INFO Channel 01 : 302[ca000] -> 301[4b000] via P2P/IPC/read
405: hkn0721:2284159:2284270 [1] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
 22: hkn0409:2570866:2570968 [2] NCCL INFO Channel 01 : 22[ca000] -> 21[4b000] via P2P/IPC/read
 70: hkn0422:4138165:4138293 [2] NCCL INFO Channel 00 : 70[ca000] -> 69[4b000] via P2P/IPC/read
290: hkn0624:1758086:1758202 [2] NCCL INFO Channel 00 : 290[ca000] -> 289[4b000] via P2P/IPC/read
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
370: hkn0712:280242:280355 [2] NCCL INFO Channel 01 : 370[ca000] -> 369[4b000] via P2P/IPC/read
 58: hkn0419:1529472:1529584 [2] NCCL INFO Channel 01 : 58[ca000] -> 57[4b000] via P2P/IPC/read
338: hkn0703:726147:726262 [2] NCCL INFO Channel 01 : 338[ca000] -> 337[4b000] via P2P/IPC/read
310: hkn0630:1583644:1583757 [2] NCCL INFO Channel 01 : 310[ca000] -> 309[4b000] via P2P/IPC/read
330: hkn0635:1210755:1210867 [2] NCCL INFO Channel 00 : 330[ca000] -> 329[4b000] via P2P/IPC/read
437: hkn0731:1371908:1372021 [1] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
510: hkn0816:360796:360907 [2] NCCL INFO Channel 01 : 510[ca000] -> 509[4b000] via P2P/IPC/read
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
485: hkn0808:955879:955981 [1] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
 62: hkn0420:3195366:3195465 [2] NCCL INFO Channel 01 : 62[ca000] -> 61[4b000] via P2P/IPC/read
 37: hkn0413:2351826:2351942 [1] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
146: hkn0513:2998110:2998204 [2] NCCL INFO Channel 01 : 146[ca000] -> 145[4b000] via P2P/IPC/read
318: hkn0632:1743760:1743909 [2] NCCL INFO Channel 01 : 318[ca000] -> 317[4b000] via P2P/IPC/read
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
 78: hkn0424:2933089:2933240 [2] NCCL INFO Channel 00 : 78[ca000] -> 77[4b000] via P2P/IPC/read
386: hkn0716:93666:93764 [2] NCCL INFO Channel 01 : 386[ca000] -> 385[4b000] via P2P/IPC/read
382: hkn0715:387104:387217 [2] NCCL INFO Channel 01 : 382[ca000] -> 381[4b000] via P2P/IPC/read
489: hkn0809:922561:922677 [1] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
334: hkn0636:1639350:1639453 [2] NCCL INFO Channel 00 : 334[ca000] -> 333[4b000] via P2P/IPC/read
322: hkn0633:1511522:1511638 [2] NCCL INFO Channel 01 : 322[ca000] -> 321[4b000] via P2P/IPC/read
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
326: hkn0634:1506052:1506156 [2] NCCL INFO Channel 01 : 326[ca000] -> 325[4b000] via P2P/IPC/read
229: hkn0604:674466:674561 [1] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
248: hkn0609:696056:696155 [0] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
488: hkn0809:922553:922675 [0] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
465: hkn0803:861667:861779 [1] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
118: hkn0506:823201:823314 [2] NCCL INFO Channel 01 : 118[ca000] -> 117[4b000] via P2P/IPC/read
502: hkn0814:660989:661111 [2] NCCL INFO Channel 01 : 502[ca000] -> 501[4b000] via P2P/IPC/read
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
469: hkn0804:1190775:1190890 [1] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
484: hkn0808:955851:955982 [0] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
306: hkn0629:1577206:1577307 [2] NCCL INFO Channel 01 : 306[ca000] -> 305[4b000] via P2P/IPC/read
257: hkn0612:902128:902247 [1] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
493: hkn0810:924720:924850 [1] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
409: hkn0723:192925:193085 [1] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
228: hkn0604:674438:674558 [0] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
 82: hkn0425:2069118:2069202 [2] NCCL INFO Channel 00 : 82[ca000] -> 81[4b000] via P2P/IPC/read
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
 86: hkn0426:799246:799367 [2] NCCL INFO Channel 00 : 86[ca000] -> 85[4b000] via P2P/IPC/read
492: hkn0810:924748:924846 [0] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
 10: hkn0405:3191876:3192004 [2] NCCL INFO Channel 01 : 10[ca000] -> 9[4b000] via P2P/IPC/read
 74: hkn0423:1689961:1690083 [2] NCCL INFO Channel 00 : 74[ca000] -> 73[4b000] via P2P/IPC/read
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
 18: hkn0408:2875808:2875934 [2] NCCL INFO Channel 01 : 18[ca000] -> 17[4b000] via P2P/IPC/read
106: hkn0503:2884805:2884921 [2] NCCL INFO Channel 00 : 106[ca000] -> 105[4b000] via P2P/IPC/read
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
 66: hkn0421:2163516:2163782 [2] NCCL INFO Channel 01 : 66[ca000] -> 65[4b000] via P2P/IPC/read
330: hkn0635:1210755:1210867 [2] NCCL INFO Channel 01 : 330[ca000] -> 329[4b000] via P2P/IPC/read
341: hkn0704:777142:777272 [1] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
110: hkn0504:25993:26089 [2] NCCL INFO Channel 00 : 110[ca000] -> 109[4b000] via P2P/IPC/read
102: hkn0502:214204:214346 [2] NCCL INFO Channel 00 : 102[ca000] -> 101[4b000] via P2P/IPC/read
334: hkn0636:1639350:1639453 [2] NCCL INFO Channel 01 : 334[ca000] -> 333[4b000] via P2P/IPC/read
 90: hkn0427:1120345:1120439 [2] NCCL INFO Channel 00 : 90[ca000] -> 89[4b000] via P2P/IPC/read
245: hkn0608:470935:471034 [1] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
453: hkn0736:1493549:1493641 [1] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
269: hkn0616:389977:390103 [1] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
378: hkn0714:417196:417322 [2] NCCL INFO Channel 01 : 378[ca000] -> 377[4b000] via P2P/IPC/read
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
 70: hkn0422:4138165:4138293 [2] NCCL INFO Channel 01 : 70[ca000] -> 69[4b000] via P2P/IPC/read
133: hkn0510:2747236:2747343 [1] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
177: hkn0525:971991:972103 [1] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
500: hkn0814:660997:661104 [0] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
 98: hkn0501:1312966:1313101 [2] NCCL INFO Channel 00 : 98[ca000] -> 97[4b000] via P2P/IPC/read
508: hkn0816:360788:360900 [0] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
348: hkn0706:737455:737573 [0] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
389: hkn0717:4172715:4172825 [1] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
261: hkn0613:887816:887974 [1] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
268: hkn0616:389997:390101 [0] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
 78: hkn0424:2933089:2933240 [2] NCCL INFO Channel 01 : 78[ca000] -> 77[4b000] via P2P/IPC/read
 14: hkn0407:1801449:1801570 [2] NCCL INFO Channel 01 : 14[ca000] -> 13[4b000] via P2P/IPC/read
253: hkn0611:694985:695081 [1] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
290: hkn0624:1758086:1758202 [2] NCCL INFO Channel 01 : 290[ca000] -> 289[4b000] via P2P/IPC/read
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
260: hkn0613:887844:887968 [0] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
501: hkn0814:661009:661108 [1] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
301: hkn0628:657007:657097 [1] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
149: hkn0514:2935893:2936011 [1] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
265: hkn0615:399447:399552 [1] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
114: hkn0505:2288957:2289067 [2] NCCL INFO Channel 00 : 114[ca000] -> 113[4b000] via P2P/IPC/read
205: hkn0532:908774:909097 [1] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
 82: hkn0425:2069118:2069202 [2] NCCL INFO Channel 01 : 82[ca000] -> 81[4b000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
340: hkn0704:777158:777265 [0] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
 90: hkn0427:1120345:1120439 [2] NCCL INFO Channel 01 : 90[ca000] -> 89[4b000] via P2P/IPC/read
264: hkn0615:399427:399550 [0] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
361: hkn0710:340632:340748 [1] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
204: hkn0532:908782:909098 [0] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
217: hkn0601:102836:102938 [1] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
 86: hkn0426:799246:799367 [2] NCCL INFO Channel 01 : 86[ca000] -> 85[4b000] via P2P/IPC/read
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
 74: hkn0423:1689961:1690083 [2] NCCL INFO Channel 01 : 74[ca000] -> 73[4b000] via P2P/IPC/read
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
277: hkn0621:1976619:1976745 [1] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
 98: hkn0501:1312966:1313101 [2] NCCL INFO Channel 01 : 98[ca000] -> 97[4b000] via P2P/IPC/read
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
  1: hkn0403:1738685:1739058 [1] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
360: hkn0710:340644:340742 [0] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
 94: hkn0428:652525:652632 [2] NCCL INFO Channel 00 : 94[ca000] -> 93[4b000] via P2P/IPC/read
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
376: hkn0714:417195:417320 [0] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
102: hkn0502:214204:214346 [2] NCCL INFO Channel 01 : 102[ca000] -> 101[4b000] via P2P/IPC/read
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
110: hkn0504:25993:26089 [2] NCCL INFO Channel 01 : 110[ca000] -> 109[4b000] via P2P/IPC/read
176: hkn0525:971975:972098 [0] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
300: hkn0628:656995:657105 [0] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
106: hkn0503:2884805:2884921 [2] NCCL INFO Channel 01 : 106[ca000] -> 105[4b000] via P2P/IPC/read
197: hkn0530:1243325:1243432 [1] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
293: hkn0626:1283586:1283696 [1] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
365: hkn0711:569034:569157 [1] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
165: hkn0521:1182962:1183092 [1] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
496: hkn0812:678913:679036 [0] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
114: hkn0505:2288957:2289067 [2] NCCL INFO Channel 01 : 114[ca000] -> 113[4b000] via P2P/IPC/read
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
497: hkn0812:678921:679031 [1] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
364: hkn0711:569026:569156 [0] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
213: hkn0535:2384189:2384302 [1] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
381: hkn0715:387096:387223 [1] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
377: hkn0714:417216:417317 [1] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
 53: hkn0418:1854353:1854450 [1] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
421: hkn0726:1533295:1533418 [1] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
249: hkn0609:696028:696150 [1] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
380: hkn0715:387124:387215 [0] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
309: hkn0630:1583628:1583756 [1] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
356: hkn0708:398416:398525 [0] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
181: hkn0526:1413569:1413673 [1] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
 85: hkn0426:799266:799362 [1] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
 94: hkn0428:652525:652632 [2] NCCL INFO Channel 01 : 94[ca000] -> 93[4b000] via P2P/IPC/read
373: hkn0713:455427:455540 [1] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
372: hkn0713:455428:455539 [0] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
345: hkn0705:768401:768516 [1] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
101: hkn0502:214224:214351 [1] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
  5: hkn0404:1324527:1324632 [1] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
344: hkn0705:768421:768521 [0] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
108: hkn0504:25965:26094 [0] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
368: hkn0712:280251:280359 [0] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
337: hkn0703:726148:726258 [1] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
 21: hkn0409:2570850:2570977 [1] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
216: hkn0601:102816:102929 [0] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
336: hkn0703:726160:726259 [0] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
252: hkn0611:694973:695080 [0] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
385: hkn0716:93646:93761 [1] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
116: hkn0506:823193:823308 [0] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
117: hkn0506:823185:823311 [1] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
100: hkn0502:214212:214345 [0] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
349: hkn0706:737463:737570 [1] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
109: hkn0504:25973:26092 [1] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
357: hkn0708:398436:398520 [1] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
509: hkn0816:360808:360905 [1] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
505: hkn0815:380329:380451 [1] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
325: hkn0634:1506024:1506157 [1] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
504: hkn0815:380357:380455 [0] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 00 : 416[31000] -> 419[e3000] via P2P/IPC/read
369: hkn0712:280243:280361 [1] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
241: hkn0607:889514:889633 [1] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
384: hkn0716:93645:93760 [0] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
256: hkn0612:902120:902251 [0] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 00 : 240[31000] -> 243[e3000] via P2P/IPC/read
464: hkn0803:861669:861771 [0] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
 69: hkn0422:4138181:4138294 [1] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
233: hkn0605:697262:697393 [1] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
437: hkn0731:1371908:1372021 [1] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 00 : 236[31000] -> 239[e3000] via P2P/IPC/read
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 01 : 416[31000] -> 419[e3000] via P2P/IPC/read
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
232: hkn0605:697242:697386 [0] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
405: hkn0721:2284159:2284270 [1] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
 37: hkn0413:2351826:2351942 [1] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
485: hkn0808:955879:955981 [1] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 01 : 240[31000] -> 243[e3000] via P2P/IPC/read
465: hkn0803:861667:861779 [1] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 00 : 404[31000] -> 407[e3000] via P2P/IPC/read
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 00 : 400[31000] -> 403[e3000] via P2P/IPC/read
256: hkn0612:902120:902251 [0] NCCL INFO Channel 00 : 256[31000] -> 259[e3000] via P2P/IPC/read
464: hkn0803:861669:861771 [0] NCCL INFO Channel 00 : 464[31000] -> 467[e3000] via P2P/IPC/read
489: hkn0809:922561:922677 [1] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
484: hkn0808:955851:955982 [0] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
257: hkn0612:902128:902247 [1] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 00 : 432[31000] -> 435[e3000] via P2P/IPC/read
488: hkn0809:922553:922675 [0] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
493: hkn0810:924720:924850 [1] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 01 : 236[31000] -> 239[e3000] via P2P/IPC/read
341: hkn0704:777142:777272 [1] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 00 : 440[31000] -> 443[e3000] via P2P/IPC/read
492: hkn0810:924748:924846 [0] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
508: hkn0816:360788:360900 [0] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
248: hkn0609:696056:696155 [0] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
409: hkn0723:192925:193085 [1] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
469: hkn0804:1190775:1190890 [1] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 00 : 40[31000] -> 43[e3000] via P2P/IPC/read
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 00 : 420[31000] -> 423[e3000] via P2P/IPC/read
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
229: hkn0604:674466:674561 [1] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
228: hkn0604:674438:674558 [0] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 00 : 448[31000] -> 451[e3000] via P2P/IPC/read
348: hkn0706:737455:737573 [0] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 00 : 412[31000] -> 415[e3000] via P2P/IPC/read
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
177: hkn0525:971991:972103 [1] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 00 : 208[31000] -> 211[e3000] via P2P/IPC/read
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 01 : 404[31000] -> 407[e3000] via P2P/IPC/read
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
256: hkn0612:902120:902251 [0] NCCL INFO Channel 01 : 256[31000] -> 259[e3000] via P2P/IPC/read
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 01 : 400[31000] -> 403[e3000] via P2P/IPC/read
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
232: hkn0605:697242:697386 [0] NCCL INFO Channel 00 : 232[31000] -> 235[e3000] via P2P/IPC/read
464: hkn0803:861669:861771 [0] NCCL INFO Channel 01 : 464[31000] -> 467[e3000] via P2P/IPC/read
453: hkn0736:1493549:1493641 [1] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
301: hkn0628:657007:657097 [1] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
389: hkn0717:4172715:4172825 [1] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
245: hkn0608:470935:471034 [1] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
269: hkn0616:389977:390103 [1] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 01 : 432[31000] -> 435[e3000] via P2P/IPC/read
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 00 : 444[31000] -> 447[e3000] via P2P/IPC/read
253: hkn0611:694985:695081 [1] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
133: hkn0510:2747236:2747343 [1] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 00 : 188[31000] -> 191[e3000] via P2P/IPC/read
149: hkn0514:2935893:2936011 [1] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
500: hkn0814:660997:661104 [0] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
484: hkn0808:955851:955982 [0] NCCL INFO Channel 00 : 484[31000] -> 487[e3000] via P2P/IPC/read
488: hkn0809:922553:922675 [0] NCCL INFO Channel 00 : 488[31000] -> 491[e3000] via P2P/IPC/read
261: hkn0613:887816:887974 [1] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 01 : 440[31000] -> 443[e3000] via P2P/IPC/read
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 01 : 420[31000] -> 423[e3000] via P2P/IPC/read
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
260: hkn0613:887844:887968 [0] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
268: hkn0616:389997:390101 [0] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 01 : 40[31000] -> 43[e3000] via P2P/IPC/read
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
340: hkn0704:777158:777265 [0] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
217: hkn0601:102836:102938 [1] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO Channel 00 : 492[31000] -> 495[e3000] via P2P/IPC/read
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 00 : 136[31000] -> 139[e3000] via P2P/IPC/read
508: hkn0816:360788:360900 [0] NCCL INFO Channel 00 : 508[31000] -> 511[e3000] via P2P/IPC/read
501: hkn0814:661009:661108 [1] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 00 : 56[31000] -> 59[e3000] via P2P/IPC/read
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 01 : 448[31000] -> 451[e3000] via P2P/IPC/read
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
248: hkn0609:696056:696155 [0] NCCL INFO Channel 00 : 248[31000] -> 251[e3000] via P2P/IPC/read
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 00 : 192[31000] -> 195[e3000] via P2P/IPC/read
361: hkn0710:340632:340748 [1] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 00 : 476[31000] -> 479[e3000] via P2P/IPC/read
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 00 : 200[31000] -> 203[e3000] via P2P/IPC/read
348: hkn0706:737455:737573 [0] NCCL INFO Channel 00 : 348[31000] -> 351[e3000] via P2P/IPC/read
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 01 : 208[31000] -> 211[e3000] via P2P/IPC/read
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 00 : 48[31000] -> 51[e3000] via P2P/IPC/read
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 00 : 468[31000] -> 471[e3000] via P2P/IPC/read
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 00 : 472[31000] -> 475[e3000] via P2P/IPC/read
232: hkn0605:697242:697386 [0] NCCL INFO Channel 01 : 232[31000] -> 235[e3000] via P2P/IPC/read
265: hkn0615:399447:399552 [1] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
228: hkn0604:674438:674558 [0] NCCL INFO Channel 00 : 228[31000] -> 231[e3000] via P2P/IPC/read
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 00 : 408[31000] -> 411[e3000] via P2P/IPC/read
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 00 : 480[31000] -> 483[e3000] via P2P/IPC/read
205: hkn0532:908774:909097 [1] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 00 : 452[31000] -> 455[e3000] via P2P/IPC/read
264: hkn0615:399427:399550 [0] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 00 : 280[31000] -> 283[e3000] via P2P/IPC/read
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
277: hkn0621:1976619:1976745 [1] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 01 : 444[31000] -> 447[e3000] via P2P/IPC/read
360: hkn0710:340644:340742 [0] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
376: hkn0714:417195:417320 [0] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 00 : 292[31000] -> 295[e3000] via P2P/IPC/read
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 01 : 188[31000] -> 191[e3000] via P2P/IPC/read
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 00 : 132[31000] -> 135[e3000] via P2P/IPC/read
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
197: hkn0530:1243325:1243432 [1] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
484: hkn0808:955851:955982 [0] NCCL INFO Channel 01 : 484[31000] -> 487[e3000] via P2P/IPC/read
488: hkn0809:922553:922675 [0] NCCL INFO Channel 01 : 488[31000] -> 491[e3000] via P2P/IPC/read
300: hkn0628:656995:657105 [0] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 00 : 36[31000] -> 39[e3000] via P2P/IPC/read
244: hkn0608:470923:471037 [0] NCCL INFO Channel 00 : 244[31000] -> 247[e3000] via P2P/IPC/read
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 00 : 32[31000] -> 35[e3000] via P2P/IPC/read
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
204: hkn0532:908782:909098 [0] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
176: hkn0525:971975:972098 [0] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
500: hkn0814:660997:661104 [0] NCCL INFO Channel 00 : 500[31000] -> 503[e3000] via P2P/IPC/read
  1: hkn0403:1738685:1739058 [1] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
293: hkn0626:1283586:1283696 [1] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 00 : 436[31000] -> 439[e3000] via P2P/IPC/read
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
508: hkn0816:360788:360900 [0] NCCL INFO Channel 01 : 508[31000] -> 511[e3000] via P2P/IPC/read
492: hkn0810:924748:924846 [0] NCCL INFO Channel 01 : 492[31000] -> 495[e3000] via P2P/IPC/read
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 00 : 8[31000] -> 11[e3000] via P2P/IPC/read
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 01 : 136[31000] -> 139[e3000] via P2P/IPC/read
364: hkn0711:569026:569156 [0] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
260: hkn0613:887844:887968 [0] NCCL INFO Channel 00 : 260[31000] -> 263[e3000] via P2P/IPC/read
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 01 : 56[31000] -> 59[e3000] via P2P/IPC/read
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 00 : 396[31000] -> 399[e3000] via P2P/IPC/read
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 00 : 144[31000] -> 147[e3000] via P2P/IPC/read
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
248: hkn0609:696056:696155 [0] NCCL INFO Channel 01 : 248[31000] -> 251[e3000] via P2P/IPC/read
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 00 : 224[31000] -> 227[e3000] via P2P/IPC/read
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 00 : 320[31000] -> 323[e3000] via P2P/IPC/read
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 01 : 200[31000] -> 203[e3000] via P2P/IPC/read
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 01 : 192[31000] -> 195[e3000] via P2P/IPC/read
348: hkn0706:737455:737573 [0] NCCL INFO Channel 01 : 348[31000] -> 351[e3000] via P2P/IPC/read
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
268: hkn0616:389997:390101 [0] NCCL INFO Channel 00 : 268[31000] -> 271[e3000] via P2P/IPC/read
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 01 : 476[31000] -> 479[e3000] via P2P/IPC/read
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 01 : 48[31000] -> 51[e3000] via P2P/IPC/read
340: hkn0704:777158:777265 [0] NCCL INFO Channel 00 : 340[31000] -> 343[e3000] via P2P/IPC/read
228: hkn0604:674438:674558 [0] NCCL INFO Channel 01 : 228[31000] -> 231[e3000] via P2P/IPC/read
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 00 : 456[31000] -> 459[e3000] via P2P/IPC/read
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 01 : 280[31000] -> 283[e3000] via P2P/IPC/read
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 00 : 28[31000] -> 31[e3000] via P2P/IPC/read
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 01 : 408[31000] -> 411[e3000] via P2P/IPC/read
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 01 : 480[31000] -> 483[e3000] via P2P/IPC/read
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 01 : 468[31000] -> 471[e3000] via P2P/IPC/read
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 01 : 412[31000] -> 415[e3000] via P2P/IPC/read
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 01 : 472[31000] -> 475[e3000] via P2P/IPC/read
165: hkn0521:1182962:1183092 [1] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 01 : 452[31000] -> 455[e3000] via P2P/IPC/read
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 00 : 392[31000] -> 395[e3000] via P2P/IPC/read
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 00 : 128[31000] -> 131[e3000] via P2P/IPC/read
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 01 : 292[31000] -> 295[e3000] via P2P/IPC/read
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 01 : 132[31000] -> 135[e3000] via P2P/IPC/read
 85: hkn0426:799266:799362 [1] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
381: hkn0715:387096:387223 [1] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Channel 01 : 244[31000] -> 247[e3000] via P2P/IPC/read
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
497: hkn0812:678921:679031 [1] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
377: hkn0714:417216:417317 [1] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 00 : 352[31000] -> 355[e3000] via P2P/IPC/read
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 00 : 388[31000] -> 391[e3000] via P2P/IPC/read
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 01 : 36[31000] -> 39[e3000] via P2P/IPC/read
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 01 : 32[31000] -> 35[e3000] via P2P/IPC/read
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 00 : 276[31000] -> 279[e3000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 00 : 428[31000] -> 431[e3000] via P2P/IPC/read
360: hkn0710:340644:340742 [0] NCCL INFO Channel 00 : 360[31000] -> 363[e3000] via P2P/IPC/read
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
376: hkn0714:417195:417320 [0] NCCL INFO Channel 00 : 376[31000] -> 379[e3000] via P2P/IPC/read
264: hkn0615:399427:399550 [0] NCCL INFO Channel 00 : 264[31000] -> 267[e3000] via P2P/IPC/read
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 00 : 120[31000] -> 123[e3000] via P2P/IPC/read
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
213: hkn0535:2384189:2384302 [1] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 00 : 0[31000] -> 3[e3000] via P2P/IPC/read
356: hkn0708:398416:398525 [0] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
500: hkn0814:660997:661104 [0] NCCL INFO Channel 01 : 500[31000] -> 503[e3000] via P2P/IPC/read
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 01 : 436[31000] -> 439[e3000] via P2P/IPC/read
496: hkn0812:678913:679036 [0] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
380: hkn0715:387124:387215 [0] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 01 : 8[31000] -> 11[e3000] via P2P/IPC/read
300: hkn0628:656995:657105 [0] NCCL INFO Channel 00 : 300[31000] -> 303[e3000] via P2P/IPC/read
 53: hkn0418:1854353:1854450 [1] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 00 : 168[31000] -> 171[e3000] via P2P/IPC/read
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
204: hkn0532:908782:909098 [0] NCCL INFO Channel 00 : 204[31000] -> 207[e3000] via P2P/IPC/read
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 00 : 460[31000] -> 463[e3000] via P2P/IPC/read
260: hkn0613:887844:887968 [0] NCCL INFO Channel 01 : 260[31000] -> 263[e3000] via P2P/IPC/read
108: hkn0504:25965:26094 [0] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 01 : 396[31000] -> 399[e3000] via P2P/IPC/read
368: hkn0712:280251:280359 [0] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
101: hkn0502:214224:214351 [1] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 00 : 172[31000] -> 175[e3000] via P2P/IPC/read
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 00 : 160[31000] -> 163[e3000] via P2P/IPC/read
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 01 : 144[31000] -> 147[e3000] via P2P/IPC/read
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 01 : 320[31000] -> 323[e3000] via P2P/IPC/read
176: hkn0525:971975:972098 [0] NCCL INFO Channel 00 : 176[31000] -> 179[e3000] via P2P/IPC/read
365: hkn0711:569034:569157 [1] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
419: hkn0725:3097098:3097193 [3] NCCL INFO Channel 00 : 419[e3000] -> 418[ca000] via P2P/IPC/read
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 01 : 224[31000] -> 227[e3000] via P2P/IPC/read
268: hkn0616:389997:390101 [0] NCCL INFO Channel 01 : 268[31000] -> 271[e3000] via P2P/IPC/read
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
309: hkn0630:1583628:1583756 [1] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
340: hkn0704:777158:777265 [0] NCCL INFO Channel 01 : 340[31000] -> 343[e3000] via P2P/IPC/read
364: hkn0711:569026:569156 [0] NCCL INFO Channel 00 : 364[31000] -> 367[e3000] via P2P/IPC/read
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 01 : 456[31000] -> 459[e3000] via P2P/IPC/read
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 01 : 28[31000] -> 31[e3000] via P2P/IPC/read
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 00 : 220[31000] -> 223[e3000] via P2P/IPC/read
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
372: hkn0713:455428:455539 [0] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
 21: hkn0409:2570850:2570977 [1] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 00 : 24[31000] -> 27[e3000] via P2P/IPC/read
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 00 : 68[31000] -> 71[e3000] via P2P/IPC/read
181: hkn0526:1413569:1413673 [1] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 01 : 392[31000] -> 395[e3000] via P2P/IPC/read
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 01 : 128[31000] -> 131[e3000] via P2P/IPC/read
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 00 : 156[31000] -> 159[e3000] via P2P/IPC/read
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 00 : 148[31000] -> 151[e3000] via P2P/IPC/read
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 01 : 388[31000] -> 391[e3000] via P2P/IPC/read
345: hkn0705:768401:768516 [1] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
373: hkn0713:455427:455540 [1] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 01 : 352[31000] -> 355[e3000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 01 : 428[31000] -> 431[e3000] via P2P/IPC/read
264: hkn0615:399427:399550 [0] NCCL INFO Channel 01 : 264[31000] -> 267[e3000] via P2P/IPC/read
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 01 : 120[31000] -> 123[e3000] via P2P/IPC/read
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 01 : 276[31000] -> 279[e3000] via P2P/IPC/read
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 00 : 184[31000] -> 187[e3000] via P2P/IPC/read
  5: hkn0404:1324527:1324632 [1] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 01 : 0[31000] -> 3[e3000] via P2P/IPC/read
360: hkn0710:340644:340742 [0] NCCL INFO Channel 01 : 360[31000] -> 363[e3000] via P2P/IPC/read
376: hkn0714:417195:417320 [0] NCCL INFO Channel 01 : 376[31000] -> 379[e3000] via P2P/IPC/read
344: hkn0705:768421:768521 [0] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 00 : 164[31000] -> 167[e3000] via P2P/IPC/read
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
385: hkn0716:93646:93761 [1] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
300: hkn0628:656995:657105 [0] NCCL INFO Channel 01 : 300[31000] -> 303[e3000] via P2P/IPC/read
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
204: hkn0532:908782:909098 [0] NCCL INFO Channel 01 : 204[31000] -> 207[e3000] via P2P/IPC/read
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 00 : 12[31000] -> 15[e3000] via P2P/IPC/read
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 00 : 16[31000] -> 19[e3000] via P2P/IPC/read
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 00 : 64[31000] -> 67[e3000] via P2P/IPC/read
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 00 : 152[31000] -> 155[e3000] via P2P/IPC/read
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 00 : 140[31000] -> 143[e3000] via P2P/IPC/read
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 01 : 168[31000] -> 171[e3000] via P2P/IPC/read
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 01 : 460[31000] -> 463[e3000] via P2P/IPC/read
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 01 : 172[31000] -> 175[e3000] via P2P/IPC/read
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 01 : 160[31000] -> 163[e3000] via P2P/IPC/read
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 00 : 212[31000] -> 215[e3000] via P2P/IPC/read
356: hkn0708:398416:398525 [0] NCCL INFO Channel 00 : 356[31000] -> 359[e3000] via P2P/IPC/read
380: hkn0715:387124:387215 [0] NCCL INFO Channel 00 : 380[31000] -> 383[e3000] via P2P/IPC/read
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
176: hkn0525:971975:972098 [0] NCCL INFO Channel 01 : 176[31000] -> 179[e3000] via P2P/IPC/read
419: hkn0725:3097098:3097193 [3] NCCL INFO Channel 01 : 419[e3000] -> 418[ca000] via P2P/IPC/read
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
496: hkn0812:678913:679036 [0] NCCL INFO Channel 00 : 496[31000] -> 499[e3000] via P2P/IPC/read
337: hkn0703:726148:726258 [1] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
108: hkn0504:25965:26094 [0] NCCL INFO Channel 00 : 108[31000] -> 111[e3000] via P2P/IPC/read
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 01 : 24[31000] -> 27[e3000] via P2P/IPC/read
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 01 : 220[31000] -> 223[e3000] via P2P/IPC/read
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 00 : 308[31000] -> 311[e3000] via P2P/IPC/read
336: hkn0703:726160:726259 [0] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
368: hkn0712:280251:280359 [0] NCCL INFO Channel 00 : 368[31000] -> 371[e3000] via P2P/IPC/read
100: hkn0502:214212:214345 [0] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 01 : 68[31000] -> 71[e3000] via P2P/IPC/read
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 00 : 332[31000] -> 335[e3000] via P2P/IPC/read
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 01 : 156[31000] -> 159[e3000] via P2P/IPC/read
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 00 : 44[31000] -> 47[e3000] via P2P/IPC/read
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 00 : 52[31000] -> 55[e3000] via P2P/IPC/read
117: hkn0506:823185:823311 [1] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 01 : 148[31000] -> 151[e3000] via P2P/IPC/read
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 00 : 304[31000] -> 307[e3000] via P2P/IPC/read
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 00 : 272[31000] -> 275[e3000] via P2P/IPC/read
243: hkn0607:889506:889630 [3] NCCL INFO Channel 00 : 243[e3000] -> 242[ca000] via P2P/IPC/read
372: hkn0713:455428:455539 [0] NCCL INFO Channel 00 : 372[31000] -> 375[e3000] via P2P/IPC/read
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 00 : 72[31000] -> 75[e3000] via P2P/IPC/read
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 00 : 112[31000] -> 115[e3000] via P2P/IPC/read
116: hkn0506:823193:823308 [0] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 01 : 184[31000] -> 187[e3000] via P2P/IPC/read
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 01 : 16[31000] -> 19[e3000] via P2P/IPC/read
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 01 : 164[31000] -> 167[e3000] via P2P/IPC/read
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 00 : 288[31000] -> 291[e3000] via P2P/IPC/read
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 01 : 12[31000] -> 15[e3000] via P2P/IPC/read
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 01 : 64[31000] -> 67[e3000] via P2P/IPC/read
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 00 : 180[31000] -> 183[e3000] via P2P/IPC/read
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 01 : 152[31000] -> 155[e3000] via P2P/IPC/read
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 01 : 140[31000] -> 143[e3000] via P2P/IPC/read
344: hkn0705:768421:768521 [0] NCCL INFO Channel 00 : 344[31000] -> 347[e3000] via P2P/IPC/read
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 01 : 212[31000] -> 215[e3000] via P2P/IPC/read
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 00 : 296[31000] -> 299[e3000] via P2P/IPC/read
356: hkn0708:398416:398525 [0] NCCL INFO Channel 01 : 356[31000] -> 359[e3000] via P2P/IPC/read
380: hkn0715:387124:387215 [0] NCCL INFO Channel 01 : 380[31000] -> 383[e3000] via P2P/IPC/read
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 00 : 316[31000] -> 319[e3000] via P2P/IPC/read
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 00 : 4[31000] -> 7[e3000] via P2P/IPC/read
496: hkn0812:678913:679036 [0] NCCL INFO Channel 01 : 496[31000] -> 499[e3000] via P2P/IPC/read
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
108: hkn0504:25965:26094 [0] NCCL INFO Channel 01 : 108[31000] -> 111[e3000] via P2P/IPC/read
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 01 : 308[31000] -> 311[e3000] via P2P/IPC/read
191: hkn0528:1286875:1286972 [3] NCCL INFO Channel 00 : 191[e3000] -> 190[ca000] via P2P/IPC/read
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 00 : 76[31000] -> 79[e3000] via P2P/IPC/read
109: hkn0504:25973:26092 [1] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
368: hkn0712:280251:280359 [0] NCCL INFO Channel 01 : 368[31000] -> 371[e3000] via P2P/IPC/read
239: hkn0606:2357195:2357321 [3] NCCL INFO Channel 00 : 239[e3000] -> 238[ca000] via P2P/IPC/read
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 01 : 332[31000] -> 335[e3000] via P2P/IPC/read
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 01 : 44[31000] -> 47[e3000] via P2P/IPC/read
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 01 : 52[31000] -> 55[e3000] via P2P/IPC/read
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 00 : 80[31000] -> 83[e3000] via P2P/IPC/read
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 01 : 304[31000] -> 307[e3000] via P2P/IPC/read
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 00 : 60[31000] -> 63[e3000] via P2P/IPC/read
336: hkn0703:726160:726259 [0] NCCL INFO Channel 00 : 336[31000] -> 339[e3000] via P2P/IPC/read
243: hkn0607:889506:889630 [3] NCCL INFO Channel 01 : 243[e3000] -> 242[ca000] via P2P/IPC/read
100: hkn0502:214212:214345 [0] NCCL INFO Channel 00 : 100[31000] -> 103[e3000] via P2P/IPC/read
423: hkn0726:1533306:1533413 [3] NCCL INFO Channel 00 : 423[e3000] -> 422[ca000] via P2P/IPC/read
372: hkn0713:455428:455539 [0] NCCL INFO Channel 01 : 372[31000] -> 375[e3000] via P2P/IPC/read
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 00 : 20[31000] -> 23[e3000] via P2P/IPC/read
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 01 : 72[31000] -> 75[e3000] via P2P/IPC/read
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 01 : 112[31000] -> 115[e3000] via P2P/IPC/read
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 01 : 272[31000] -> 275[e3000] via P2P/IPC/read
407: hkn0721:2284151:2284268 [3] NCCL INFO Channel 00 : 407[e3000] -> 406[ca000] via P2P/IPC/read
259: hkn0612:902148:902244 [3] NCCL INFO Channel 00 : 259[e3000] -> 258[ca000] via P2P/IPC/read
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 00 : 92[31000] -> 95[e3000] via P2P/IPC/read
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 00 : 104[31000] -> 107[e3000] via P2P/IPC/read
403: hkn0720:4181536:4181828 [3] NCCL INFO Channel 00 : 403[e3000] -> 402[ca000] via P2P/IPC/read
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 01 : 288[31000] -> 291[e3000] via P2P/IPC/read
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 01 : 180[31000] -> 183[e3000] via P2P/IPC/read
435: hkn0730:1386922:1387017 [3] NCCL INFO Channel 00 : 435[e3000] -> 434[ca000] via P2P/IPC/read
344: hkn0705:768421:768521 [0] NCCL INFO Channel 01 : 344[31000] -> 347[e3000] via P2P/IPC/read
467: hkn0803:861681:861778 [3] NCCL INFO Channel 00 : 467[e3000] -> 466[ca000] via P2P/IPC/read
116: hkn0506:823193:823308 [0] NCCL INFO Channel 00 : 116[31000] -> 119[e3000] via P2P/IPC/read
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 01 : 296[31000] -> 299[e3000] via P2P/IPC/read
421: hkn0726:1533295:1533418 [1] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 00 : 312[31000] -> 315[e3000] via P2P/IPC/read
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 01 : 4[31000] -> 7[e3000] via P2P/IPC/read
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 01 : 316[31000] -> 319[e3000] via P2P/IPC/read
191: hkn0528:1286875:1286972 [3] NCCL INFO Channel 01 : 191[e3000] -> 190[ca000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
239: hkn0606:2357195:2357321 [3] NCCL INFO Channel 01 : 239[e3000] -> 238[ca000] via P2P/IPC/read
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 01 : 76[31000] -> 79[e3000] via P2P/IPC/read
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
249: hkn0609:696028:696150 [1] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
336: hkn0703:726160:726259 [0] NCCL INFO Channel 01 : 336[31000] -> 339[e3000] via P2P/IPC/read
451: hkn0734:1141736:1141845 [3] NCCL INFO Channel 00 : 451[e3000] -> 450[ca000] via P2P/IPC/read
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 01 : 60[31000] -> 63[e3000] via P2P/IPC/read
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
419: hkn0725:3097098:3097193 [3] NCCL INFO Connected all rings
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 01 : 20[31000] -> 23[e3000] via P2P/IPC/read
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
443: hkn0732:1196831:1196956 [3] NCCL INFO Channel 00 : 443[e3000] -> 442[ca000] via P2P/IPC/read
511: hkn0816:360780:360901 [3] NCCL INFO Channel 00 : 511[e3000] -> 510[ca000] via P2P/IPC/read
384: hkn0716:93645:93760 [0] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
211: hkn0534:1133581:1133690 [3] NCCL INFO Channel 00 : 211[e3000] -> 210[ca000] via P2P/IPC/read
100: hkn0502:214212:214345 [0] NCCL INFO Channel 01 : 100[31000] -> 103[e3000] via P2P/IPC/read
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 01 : 92[31000] -> 95[e3000] via P2P/IPC/read
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 01 : 104[31000] -> 107[e3000] via P2P/IPC/read
403: hkn0720:4181536:4181828 [3] NCCL INFO Channel 01 : 403[e3000] -> 402[ca000] via P2P/IPC/read
407: hkn0721:2284151:2284268 [3] NCCL INFO Channel 01 : 407[e3000] -> 406[ca000] via P2P/IPC/read
325: hkn0634:1506024:1506157 [1] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
259: hkn0612:902148:902244 [3] NCCL INFO Channel 01 : 259[e3000] -> 258[ca000] via P2P/IPC/read
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
435: hkn0730:1386922:1387017 [3] NCCL INFO Channel 01 : 435[e3000] -> 434[ca000] via P2P/IPC/read
364: hkn0711:569026:569156 [0] NCCL INFO Channel 01 : 364[31000] -> 367[e3000] via P2P/IPC/read
447: hkn0733:1374550:1374661 [3] NCCL INFO Channel 00 : 447[e3000] -> 446[ca000] via P2P/IPC/read
467: hkn0803:861681:861778 [3] NCCL INFO Channel 01 : 467[e3000] -> 466[ca000] via P2P/IPC/read
116: hkn0506:823193:823308 [0] NCCL INFO Channel 01 : 116[31000] -> 119[e3000] via P2P/IPC/read
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 01 : 312[31000] -> 315[e3000] via P2P/IPC/read
  3: hkn0403:1738677:1739059 [3] NCCL INFO Channel 00 : 3[e3000] -> 2[ca000] via P2P/IPC/read
491: hkn0809:922581:922679 [3] NCCL INFO Channel 00 : 491[e3000] -> 490[ca000] via P2P/IPC/read
235: hkn0605:697250:697395 [3] NCCL INFO Channel 00 : 235[e3000] -> 234[ca000] via P2P/IPC/read
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
363: hkn0710:340631:340745 [3] NCCL INFO Channel 00 : 363[e3000] -> 362[ca000] via P2P/IPC/read
252: hkn0611:694973:695080 [0] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
 43: hkn0414:1966712:1966819 [3] NCCL INFO Channel 00 : 43[e3000] -> 42[ca000] via P2P/IPC/read
355: hkn0707:4005093:4005183 [3] NCCL INFO Channel 00 : 355[e3000] -> 354[ca000] via P2P/IPC/read
139: hkn0511:3051483:3051604 [3] NCCL INFO Channel 00 : 139[e3000] -> 138[ca000] via P2P/IPC/read
495: hkn0810:924736:924852 [3] NCCL INFO Channel 00 : 495[e3000] -> 494[ca000] via P2P/IPC/read
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 01 : 80[31000] -> 83[e3000] via P2P/IPC/read
 59: hkn0419:1529462:1529576 [3] NCCL INFO Channel 00 : 59[e3000] -> 58[ca000] via P2P/IPC/read
487: hkn0808:955859:955975 [3] NCCL INFO Channel 00 : 487[e3000] -> 486[ca000] via P2P/IPC/read
451: hkn0734:1141736:1141845 [3] NCCL INFO Channel 01 : 451[e3000] -> 450[ca000] via P2P/IPC/read
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 00 : 88[31000] -> 91[e3000] via P2P/IPC/read
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
 51: hkn0417:2252746:2252861 [3] NCCL INFO Channel 00 : 51[e3000] -> 50[ca000] via P2P/IPC/read
443: hkn0732:1196831:1196956 [3] NCCL INFO Channel 01 : 443[e3000] -> 442[ca000] via P2P/IPC/read
511: hkn0816:360780:360901 [3] NCCL INFO Channel 01 : 511[e3000] -> 510[ca000] via P2P/IPC/read
211: hkn0534:1133581:1133690 [3] NCCL INFO Channel 01 : 211[e3000] -> 210[ca000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO Channel 00 : 216[31000] -> 219[e3000] via P2P/IPC/read
479: hkn0806:1039493:1039614 [3] NCCL INFO Channel 00 : 479[e3000] -> 478[ca000] via P2P/IPC/read
203: hkn0531:1215704:1215819 [3] NCCL INFO Channel 00 : 203[e3000] -> 202[ca000] via P2P/IPC/read
411: hkn0723:192909:193084 [3] NCCL INFO Channel 00 : 411[e3000] -> 410[ca000] via P2P/IPC/read
283: hkn0622:2005565:2005687 [3] NCCL INFO Channel 00 : 283[e3000] -> 282[ca000] via P2P/IPC/read
195: hkn0529:1526003:1526130 [3] NCCL INFO Channel 00 : 195[e3000] -> 194[ca000] via P2P/IPC/read
243: hkn0607:889506:889630 [3] NCCL INFO Connected all rings
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 00 : 96[31000] -> 99[e3000] via P2P/IPC/read
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 00 : 324[31000] -> 327[e3000] via P2P/IPC/read
471: hkn0804:1190762:1190887 [3] NCCL INFO Channel 00 : 471[e3000] -> 470[ca000] via P2P/IPC/read
247: hkn0608:470914:471033 [3] NCCL INFO Channel 00 : 247[e3000] -> 246[ca000] via P2P/IPC/read
135: hkn0510:2747228:2747349 [3] NCCL INFO Channel 00 : 135[e3000] -> 134[ca000] via P2P/IPC/read
447: hkn0733:1374550:1374661 [3] NCCL INFO Channel 01 : 447[e3000] -> 446[ca000] via P2P/IPC/read
483: hkn0807:1004280:1004394 [3] NCCL INFO Channel 00 : 483[e3000] -> 482[ca000] via P2P/IPC/read
231: hkn0604:674454:674562 [3] NCCL INFO Channel 00 : 231[e3000] -> 230[ca000] via P2P/IPC/read
295: hkn0626:1283583:1283699 [3] NCCL INFO Channel 00 : 295[e3000] -> 294[ca000] via P2P/IPC/read
 35: hkn0412:2247582:2247669 [3] NCCL INFO Channel 00 : 35[e3000] -> 34[ca000] via P2P/IPC/read
384: hkn0716:93645:93760 [0] NCCL INFO Channel 00 : 384[31000] -> 387[e3000] via P2P/IPC/read
455: hkn0736:1493529:1493646 [3] NCCL INFO Channel 00 : 455[e3000] -> 454[ca000] via P2P/IPC/read
  3: hkn0403:1738677:1739059 [3] NCCL INFO Channel 01 : 3[e3000] -> 2[ca000] via P2P/IPC/read
235: hkn0605:697250:697395 [3] NCCL INFO Channel 01 : 235[e3000] -> 234[ca000] via P2P/IPC/read
 39: hkn0413:2351834:2351947 [3] NCCL INFO Channel 00 : 39[e3000] -> 38[ca000] via P2P/IPC/read
423: hkn0726:1533306:1533413 [3] NCCL INFO Channel 01 : 423[e3000] -> 422[ca000] via P2P/IPC/read
491: hkn0809:922581:922679 [3] NCCL INFO Channel 01 : 491[e3000] -> 490[ca000] via P2P/IPC/read
363: hkn0710:340631:340745 [3] NCCL INFO Channel 01 : 363[e3000] -> 362[ca000] via P2P/IPC/read
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 00 : 424[31000] -> 427[e3000] via P2P/IPC/read
475: hkn0805:1097283:1097377 [3] NCCL INFO Channel 00 : 475[e3000] -> 474[ca000] via P2P/IPC/read
 43: hkn0414:1966712:1966819 [3] NCCL INFO Channel 01 : 43[e3000] -> 42[ca000] via P2P/IPC/read
439: hkn0731:1371900:1372017 [3] NCCL INFO Channel 00 : 439[e3000] -> 438[ca000] via P2P/IPC/read
139: hkn0511:3051483:3051604 [3] NCCL INFO Channel 01 : 139[e3000] -> 138[ca000] via P2P/IPC/read
503: hkn0814:660981:661105 [3] NCCL INFO Channel 00 : 503[e3000] -> 502[ca000] via P2P/IPC/read
509: hkn0816:360808:360905 [1] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
355: hkn0707:4005093:4005183 [3] NCCL INFO Channel 01 : 355[e3000] -> 354[ca000] via P2P/IPC/read
 11: hkn0405:3191884:3191996 [3] NCCL INFO Channel 00 : 11[e3000] -> 10[ca000] via P2P/IPC/read
251: hkn0609:696044:696154 [3] NCCL INFO Channel 00 : 251[e3000] -> 250[ca000] via P2P/IPC/read
 59: hkn0419:1529462:1529576 [3] NCCL INFO Channel 01 : 59[e3000] -> 58[ca000] via P2P/IPC/read
191: hkn0528:1286875:1286972 [3] NCCL INFO Connected all rings
495: hkn0810:924736:924852 [3] NCCL INFO Channel 01 : 495[e3000] -> 494[ca000] via P2P/IPC/read
487: hkn0808:955859:955975 [3] NCCL INFO Channel 01 : 487[e3000] -> 486[ca000] via P2P/IPC/read
323: hkn0633:1511534:1511635 [3] NCCL INFO Channel 00 : 323[e3000] -> 322[ca000] via P2P/IPC/read
239: hkn0606:2357195:2357321 [3] NCCL INFO Connected all rings
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
 51: hkn0417:2252746:2252861 [3] NCCL INFO Channel 01 : 51[e3000] -> 50[ca000] via P2P/IPC/read
399: hkn0719:1290839:1290961 [3] NCCL INFO Channel 00 : 399[e3000] -> 398[ca000] via P2P/IPC/read
415: hkn0724:1701152:1701251 [3] NCCL INFO Channel 00 : 415[e3000] -> 414[ca000] via P2P/IPC/read
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 01 : 88[31000] -> 91[e3000] via P2P/IPC/read
147: hkn0513:2998082:2998206 [3] NCCL INFO Channel 00 : 147[e3000] -> 146[ca000] via P2P/IPC/read
203: hkn0531:1215704:1215819 [3] NCCL INFO Channel 01 : 203[e3000] -> 202[ca000] via P2P/IPC/read
227: hkn0603:1398303:1398428 [3] NCCL INFO Channel 00 : 227[e3000] -> 226[ca000] via P2P/IPC/read
263: hkn0613:887832:887970 [3] NCCL INFO Channel 00 : 263[e3000] -> 262[ca000] via P2P/IPC/read
 31: hkn0411:2301028:2301136 [3] NCCL INFO Channel 00 : 31[e3000] -> 30[ca000] via P2P/IPC/read
479: hkn0806:1039493:1039614 [3] NCCL INFO Channel 01 : 479[e3000] -> 478[ca000] via P2P/IPC/read
351: hkn0706:737447:737575 [3] NCCL INFO Channel 00 : 351[e3000] -> 350[ca000] via P2P/IPC/read
271: hkn0616:389985:390100 [3] NCCL INFO Channel 00 : 271[e3000] -> 270[ca000] via P2P/IPC/read
283: hkn0622:2005565:2005687 [3] NCCL INFO Channel 01 : 283[e3000] -> 282[ca000] via P2P/IPC/read
195: hkn0529:1526003:1526130 [3] NCCL INFO Channel 01 : 195[e3000] -> 194[ca000] via P2P/IPC/read
411: hkn0723:192909:193084 [3] NCCL INFO Channel 01 : 411[e3000] -> 410[ca000] via P2P/IPC/read
343: hkn0704:777170:777274 [3] NCCL INFO Channel 00 : 343[e3000] -> 342[ca000] via P2P/IPC/read
459: hkn0801:2225102:2225219 [3] NCCL INFO Channel 00 : 459[e3000] -> 458[ca000] via P2P/IPC/read
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 01 : 96[31000] -> 99[e3000] via P2P/IPC/read
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 00 : 196[31000] -> 199[e3000] via P2P/IPC/read
471: hkn0804:1190762:1190887 [3] NCCL INFO Channel 01 : 471[e3000] -> 470[ca000] via P2P/IPC/read
395: hkn0718:3902182:3902290 [3] NCCL INFO Channel 00 : 395[e3000] -> 394[ca000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO Channel 01 : 216[31000] -> 219[e3000] via P2P/IPC/read
135: hkn0510:2747228:2747349 [3] NCCL INFO Channel 01 : 135[e3000] -> 134[ca000] via P2P/IPC/read
483: hkn0807:1004280:1004394 [3] NCCL INFO Channel 01 : 483[e3000] -> 482[ca000] via P2P/IPC/read
131: hkn0509:3109556:3109675 [3] NCCL INFO Channel 00 : 131[e3000] -> 130[ca000] via P2P/IPC/read
252: hkn0611:694973:695080 [0] NCCL INFO Channel 00 : 252[31000] -> 255[e3000] via P2P/IPC/read
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 01 : 324[31000] -> 327[e3000] via P2P/IPC/read
231: hkn0604:674454:674562 [3] NCCL INFO Channel 01 : 231[e3000] -> 230[ca000] via P2P/IPC/read
247: hkn0608:470914:471033 [3] NCCL INFO Channel 01 : 247[e3000] -> 246[ca000] via P2P/IPC/read
295: hkn0626:1283583:1283699 [3] NCCL INFO Channel 01 : 295[e3000] -> 294[ca000] via P2P/IPC/read
259: hkn0612:902148:902244 [3] NCCL INFO Connected all rings
 35: hkn0412:2247582:2247669 [3] NCCL INFO Channel 01 : 35[e3000] -> 34[ca000] via P2P/IPC/read
403: hkn0720:4181536:4181828 [3] NCCL INFO Connected all rings
384: hkn0716:93645:93760 [0] NCCL INFO Channel 01 : 384[31000] -> 387[e3000] via P2P/IPC/read
349: hkn0706:737463:737570 [1] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
407: hkn0721:2284151:2284268 [3] NCCL INFO Connected all rings
279: hkn0621:1976627:1976741 [3] NCCL INFO Channel 00 : 279[e3000] -> 278[ca000] via P2P/IPC/read
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
357: hkn0708:398436:398520 [1] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
455: hkn0736:1493529:1493646 [3] NCCL INFO Channel 01 : 455[e3000] -> 454[ca000] via P2P/IPC/read
267: hkn0615:399435:399549 [3] NCCL INFO Channel 00 : 267[e3000] -> 266[ca000] via P2P/IPC/read
435: hkn0730:1386922:1387017 [3] NCCL INFO Connected all rings
375: hkn0713:455441:455538 [3] NCCL INFO Channel 00 : 375[e3000] -> 374[ca000] via P2P/IPC/read
475: hkn0805:1097283:1097377 [3] NCCL INFO Channel 01 : 475[e3000] -> 474[ca000] via P2P/IPC/read
 75: hkn0423:1689977:1690087 [3] NCCL INFO Channel 00 : 75[e3000] -> 74[ca000] via P2P/IPC/read
123: hkn0507:3172200:3172323 [3] NCCL INFO Channel 00 : 123[e3000] -> 122[ca000] via P2P/IPC/read
431: hkn0728:1309090:1309203 [3] NCCL INFO Channel 00 : 431[e3000] -> 430[ca000] via P2P/IPC/read
467: hkn0803:861681:861778 [3] NCCL INFO Connected all rings
171: hkn0523:1533178:1533297 [3] NCCL INFO Channel 00 : 171[e3000] -> 170[ca000] via P2P/IPC/read
503: hkn0814:660981:661105 [3] NCCL INFO Channel 01 : 503[e3000] -> 502[ca000] via P2P/IPC/read
439: hkn0731:1371900:1372017 [3] NCCL INFO Channel 01 : 439[e3000] -> 438[ca000] via P2P/IPC/read
207: hkn0532:908790:909100 [3] NCCL INFO Channel 00 : 207[e3000] -> 206[ca000] via P2P/IPC/read
391: hkn0717:4172703:4172819 [3] NCCL INFO Channel 00 : 391[e3000] -> 390[ca000] via P2P/IPC/read
 11: hkn0405:3191884:3191996 [3] NCCL INFO Channel 01 : 11[e3000] -> 10[ca000] via P2P/IPC/read
251: hkn0609:696044:696154 [3] NCCL INFO Channel 01 : 251[e3000] -> 250[ca000] via P2P/IPC/read
463: hkn0802:1185491:1185618 [3] NCCL INFO Channel 00 : 463[e3000] -> 462[ca000] via P2P/IPC/read
379: hkn0714:417204:417316 [3] NCCL INFO Channel 00 : 379[e3000] -> 378[ca000] via P2P/IPC/read
303: hkn0628:656987:657106 [3] NCCL INFO Channel 00 : 303[e3000] -> 302[ca000] via P2P/IPC/read
323: hkn0633:1511534:1511635 [3] NCCL INFO Channel 01 : 323[e3000] -> 322[ca000] via P2P/IPC/read
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 00 : 284[31000] -> 287[e3000] via P2P/IPC/read
175: hkn0524:1118950:1119063 [3] NCCL INFO Channel 00 : 175[e3000] -> 174[ca000] via P2P/IPC/read
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 00 : 124[31000] -> 127[e3000] via P2P/IPC/read
399: hkn0719:1290839:1290961 [3] NCCL INFO Channel 01 : 399[e3000] -> 398[ca000] via P2P/IPC/read
415: hkn0724:1701152:1701251 [3] NCCL INFO Channel 01 : 415[e3000] -> 414[ca000] via P2P/IPC/read
147: hkn0513:2998082:2998206 [3] NCCL INFO Channel 01 : 147[e3000] -> 146[ca000] via P2P/IPC/read
263: hkn0613:887832:887970 [3] NCCL INFO Channel 01 : 263[e3000] -> 262[ca000] via P2P/IPC/read
505: hkn0815:380329:380451 [1] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
227: hkn0603:1398303:1398428 [3] NCCL INFO Channel 01 : 227[e3000] -> 226[ca000] via P2P/IPC/read
 31: hkn0411:2301028:2301136 [3] NCCL INFO Channel 01 : 31[e3000] -> 30[ca000] via P2P/IPC/read
351: hkn0706:737447:737575 [3] NCCL INFO Channel 01 : 351[e3000] -> 350[ca000] via P2P/IPC/read
 27: hkn0410:1144778:1144896 [3] NCCL INFO Channel 00 : 27[e3000] -> 26[ca000] via P2P/IPC/read
271: hkn0616:389985:390100 [3] NCCL INFO Channel 01 : 271[e3000] -> 270[ca000] via P2P/IPC/read
343: hkn0704:777170:777274 [3] NCCL INFO Channel 01 : 343[e3000] -> 342[ca000] via P2P/IPC/read
451: hkn0734:1141736:1141845 [3] NCCL INFO Connected all rings
459: hkn0801:2225102:2225219 [3] NCCL INFO Channel 01 : 459[e3000] -> 458[ca000] via P2P/IPC/read
179: hkn0525:971983:972104 [3] NCCL INFO Channel 00 : 179[e3000] -> 178[ca000] via P2P/IPC/read
443: hkn0732:1196831:1196956 [3] NCCL INFO Connected all rings
395: hkn0718:3902182:3902290 [3] NCCL INFO Channel 01 : 395[e3000] -> 394[ca000] via P2P/IPC/read
223: hkn0602:3345215:3345483 [3] NCCL INFO Channel 00 : 223[e3000] -> 222[ca000] via P2P/IPC/read
504: hkn0815:380357:380455 [0] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
511: hkn0816:360780:360901 [3] NCCL INFO Connected all rings
131: hkn0509:3109556:3109675 [3] NCCL INFO Channel 01 : 131[e3000] -> 130[ca000] via P2P/IPC/read
159: hkn0516:2901136:2901292 [3] NCCL INFO Channel 00 : 159[e3000] -> 158[ca000] via P2P/IPC/read
279: hkn0621:1976627:1976741 [3] NCCL INFO Channel 01 : 279[e3000] -> 278[ca000] via P2P/IPC/read
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
163: hkn0520:2698007:2698122 [3] NCCL INFO Channel 00 : 163[e3000] -> 162[ca000] via P2P/IPC/read
267: hkn0615:399435:399549 [3] NCCL INFO Channel 01 : 267[e3000] -> 266[ca000] via P2P/IPC/read
339: hkn0703:726146:726263 [3] NCCL INFO Channel 00 : 339[e3000] -> 338[ca000] via P2P/IPC/read
211: hkn0534:1133581:1133690 [3] NCCL INFO Connected all rings
375: hkn0713:455441:455538 [3] NCCL INFO Channel 01 : 375[e3000] -> 374[ca000] via P2P/IPC/read
 75: hkn0423:1689977:1690087 [3] NCCL INFO Channel 01 : 75[e3000] -> 74[ca000] via P2P/IPC/read
252: hkn0611:694973:695080 [0] NCCL INFO Channel 01 : 252[31000] -> 255[e3000] via P2P/IPC/read
123: hkn0507:3172200:3172323 [3] NCCL INFO Channel 01 : 123[e3000] -> 122[ca000] via P2P/IPC/read
 19: hkn0408:2875816:2875935 [3] NCCL INFO Channel 00 : 19[e3000] -> 18[ca000] via P2P/IPC/read
171: hkn0523:1533178:1533297 [3] NCCL INFO Channel 01 : 171[e3000] -> 170[ca000] via P2P/IPC/read
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 01 : 196[31000] -> 199[e3000] via P2P/IPC/read
431: hkn0728:1309090:1309203 [3] NCCL INFO Channel 01 : 431[e3000] -> 430[ca000] via P2P/IPC/read
447: hkn0733:1374550:1374661 [3] NCCL INFO Connected all rings
 39: hkn0413:2351834:2351947 [3] NCCL INFO Channel 01 : 39[e3000] -> 38[ca000] via P2P/IPC/read
207: hkn0532:908790:909100 [3] NCCL INFO Channel 01 : 207[e3000] -> 206[ca000] via P2P/IPC/read
 15: hkn0407:1801457:1801568 [3] NCCL INFO Channel 00 : 15[e3000] -> 14[ca000] via P2P/IPC/read
463: hkn0802:1185491:1185618 [3] NCCL INFO Channel 01 : 463[e3000] -> 462[ca000] via P2P/IPC/read
391: hkn0717:4172703:4172819 [3] NCCL INFO Channel 01 : 391[e3000] -> 390[ca000] via P2P/IPC/read
379: hkn0714:417204:417316 [3] NCCL INFO Channel 01 : 379[e3000] -> 378[ca000] via P2P/IPC/read
235: hkn0605:697250:697395 [3] NCCL INFO Connected all rings
303: hkn0628:656987:657106 [3] NCCL INFO Channel 01 : 303[e3000] -> 302[ca000] via P2P/IPC/read
423: hkn0726:1533306:1533413 [3] NCCL INFO Connected all rings
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 01 : 424[31000] -> 427[e3000] via P2P/IPC/read
 67: hkn0421:2163500:2163778 [3] NCCL INFO Channel 00 : 67[e3000] -> 66[ca000] via P2P/IPC/read
175: hkn0524:1118950:1119063 [3] NCCL INFO Channel 01 : 175[e3000] -> 174[ca000] via P2P/IPC/read
 43: hkn0414:1966712:1966819 [3] NCCL INFO Connected all rings
139: hkn0511:3051483:3051604 [3] NCCL INFO Connected all rings
491: hkn0809:922581:922679 [3] NCCL INFO Connected all rings
369: hkn0712:280243:280361 [1] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
167: hkn0521:1182990:1183086 [3] NCCL INFO Channel 00 : 167[e3000] -> 166[ca000] via P2P/IPC/read
151: hkn0514:2935901:2936013 [3] NCCL INFO Channel 00 : 151[e3000] -> 150[ca000] via P2P/IPC/read
383: hkn0715:387112:387222 [3] NCCL INFO Channel 00 : 383[e3000] -> 382[ca000] via P2P/IPC/read
 27: hkn0410:1144778:1144896 [3] NCCL INFO Channel 01 : 27[e3000] -> 26[ca000] via P2P/IPC/read
 59: hkn0419:1529462:1529576 [3] NCCL INFO Connected all rings
215: hkn0535:2384173:2384300 [3] NCCL INFO Channel 00 : 215[e3000] -> 214[ca000] via P2P/IPC/read
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 01 : 124[31000] -> 127[e3000] via P2P/IPC/read
499: hkn0812:678941:679039 [3] NCCL INFO Channel 00 : 499[e3000] -> 498[ca000] via P2P/IPC/read
111: hkn0504:25981:26087 [3] NCCL INFO Channel 00 : 111[e3000] -> 110[ca000] via P2P/IPC/read
155: hkn0515:2881942:2882062 [3] NCCL INFO Channel 00 : 155[e3000] -> 154[ca000] via P2P/IPC/read
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 01 : 284[31000] -> 287[e3000] via P2P/IPC/read
 51: hkn0417:2252746:2252861 [3] NCCL INFO Connected all rings
223: hkn0602:3345215:3345483 [3] NCCL INFO Channel 01 : 223[e3000] -> 222[ca000] via P2P/IPC/read
179: hkn0525:971983:972104 [3] NCCL INFO Channel 01 : 179[e3000] -> 178[ca000] via P2P/IPC/read
203: hkn0531:1215704:1215819 [3] NCCL INFO Connected all rings
143: hkn0512:3029310:3029418 [3] NCCL INFO Channel 00 : 143[e3000] -> 142[ca000] via P2P/IPC/read
495: hkn0810:924736:924852 [3] NCCL INFO Connected all rings
159: hkn0516:2901136:2901292 [3] NCCL INFO Channel 01 : 159[e3000] -> 158[ca000] via P2P/IPC/read
 71: hkn0422:4138193:4138296 [3] NCCL INFO Channel 00 : 71[e3000] -> 70[ca000] via P2P/IPC/read
479: hkn0806:1039493:1039614 [3] NCCL INFO Connected all rings
283: hkn0622:2005565:2005687 [3] NCCL INFO Connected all rings
307: hkn0629:1577178:1577305 [3] NCCL INFO Channel 00 : 307[e3000] -> 306[ca000] via P2P/IPC/read
 55: hkn0418:1854333:1854449 [3] NCCL INFO Channel 00 : 55[e3000] -> 54[ca000] via P2P/IPC/read
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
411: hkn0723:192909:193084 [3] NCCL INFO Connected all rings
339: hkn0703:726146:726263 [3] NCCL INFO Channel 01 : 339[e3000] -> 338[ca000] via P2P/IPC/read
163: hkn0520:2698007:2698122 [3] NCCL INFO Channel 01 : 163[e3000] -> 162[ca000] via P2P/IPC/read
311: hkn0630:1583636:1583760 [3] NCCL INFO Channel 00 : 311[e3000] -> 310[ca000] via P2P/IPC/read
187: hkn0527:1334069:1334163 [3] NCCL INFO Channel 00 : 187[e3000] -> 186[ca000] via P2P/IPC/read
487: hkn0808:955859:955975 [3] NCCL INFO Connected all rings
359: hkn0708:398415:398522 [3] NCCL INFO Channel 00 : 359[e3000] -> 358[ca000] via P2P/IPC/read
247: hkn0608:470914:471033 [3] NCCL INFO Connected all rings
115: hkn0505:2288941:2289062 [3] NCCL INFO Channel 00 : 115[e3000] -> 114[ca000] via P2P/IPC/read
275: hkn0617:2279766:2279891 [3] NCCL INFO Channel 00 : 275[e3000] -> 274[ca000] via P2P/IPC/read
135: hkn0510:2747228:2747349 [3] NCCL INFO Connected all rings
231: hkn0604:674454:674562 [3] NCCL INFO Connected all rings
 19: hkn0408:2875816:2875935 [3] NCCL INFO Channel 01 : 19[e3000] -> 18[ca000] via P2P/IPC/read
295: hkn0626:1283583:1283699 [3] NCCL INFO Connected all rings
 35: hkn0412:2247582:2247669 [3] NCCL INFO Connected all rings
183: hkn0526:1413553:1413678 [3] NCCL INFO Channel 00 : 183[e3000] -> 182[ca000] via P2P/IPC/read
483: hkn0807:1004280:1004394 [3] NCCL INFO Connected all rings
 47: hkn0415:2481502:2481621 [3] NCCL INFO Channel 00 : 47[e3000] -> 46[ca000] via P2P/IPC/read
 69: hkn0422:4138181:4138294 [1] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
504: hkn0815:380357:380455 [0] NCCL INFO Channel 00 : 504[31000] -> 507[e3000] via P2P/IPC/read
 15: hkn0407:1801457:1801568 [3] NCCL INFO Channel 01 : 15[e3000] -> 14[ca000] via P2P/IPC/read
455: hkn0736:1493529:1493646 [3] NCCL INFO Connected all rings
195: hkn0529:1526003:1526130 [3] NCCL INFO Connected all rings
363: hkn0710:340631:340745 [3] NCCL INFO Connected all rings
347: hkn0705:768400:768514 [3] NCCL INFO Channel 00 : 347[e3000] -> 346[ca000] via P2P/IPC/read
 67: hkn0421:2163500:2163778 [3] NCCL INFO Channel 01 : 67[e3000] -> 66[ca000] via P2P/IPC/read
299: hkn0627:1773082:1773180 [3] NCCL INFO Channel 00 : 299[e3000] -> 298[ca000] via P2P/IPC/read
383: hkn0715:387112:387222 [3] NCCL INFO Channel 01 : 383[e3000] -> 382[ca000] via P2P/IPC/read
355: hkn0707:4005093:4005183 [3] NCCL INFO Connected all rings
475: hkn0805:1097283:1097377 [3] NCCL INFO Connected all rings
167: hkn0521:1182990:1183086 [3] NCCL INFO Channel 01 : 167[e3000] -> 166[ca000] via P2P/IPC/read
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 00 : 328[31000] -> 331[e3000] via P2P/IPC/read
503: hkn0814:660981:661105 [3] NCCL INFO Connected all rings
471: hkn0804:1190762:1190887 [3] NCCL INFO Connected all rings
 11: hkn0405:3191884:3191996 [3] NCCL INFO Connected all rings
155: hkn0515:2881942:2882062 [3] NCCL INFO Channel 01 : 155[e3000] -> 154[ca000] via P2P/IPC/read
251: hkn0609:696044:696154 [3] NCCL INFO Connected all rings
323: hkn0633:1511534:1511635 [3] NCCL INFO Connected all rings
215: hkn0535:2384173:2384300 [3] NCCL INFO Channel 01 : 215[e3000] -> 214[ca000] via P2P/IPC/read
151: hkn0514:2935901:2936013 [3] NCCL INFO Channel 01 : 151[e3000] -> 150[ca000] via P2P/IPC/read
499: hkn0812:678941:679039 [3] NCCL INFO Channel 01 : 499[e3000] -> 498[ca000] via P2P/IPC/read
111: hkn0504:25981:26087 [3] NCCL INFO Channel 01 : 111[e3000] -> 110[ca000] via P2P/IPC/read
319: hkn0632:1743781:1743911 [3] NCCL INFO Channel 00 : 319[e3000] -> 318[ca000] via P2P/IPC/read
  7: hkn0404:1324519:1324638 [3] NCCL INFO Channel 00 : 7[e3000] -> 6[ca000] via P2P/IPC/read
 79: hkn0424:2933081:2933238 [3] NCCL INFO Channel 00 : 79[e3000] -> 78[ca000] via P2P/IPC/read
439: hkn0731:1371900:1372017 [3] NCCL INFO Connected all rings
143: hkn0512:3029310:3029418 [3] NCCL INFO Channel 01 : 143[e3000] -> 142[ca000] via P2P/IPC/read
399: hkn0719:1290839:1290961 [3] NCCL INFO Connected all rings
415: hkn0724:1701152:1701251 [3] NCCL INFO Connected all rings
147: hkn0513:2998082:2998206 [3] NCCL INFO Connected all rings
 71: hkn0422:4138193:4138296 [3] NCCL INFO Channel 01 : 71[e3000] -> 70[ca000] via P2P/IPC/read
227: hkn0603:1398303:1398428 [3] NCCL INFO Connected all rings
371: hkn0712:280263:280354 [3] NCCL INFO Channel 00 : 371[e3000] -> 370[ca000] via P2P/IPC/read
263: hkn0613:887832:887970 [3] NCCL INFO Connected all rings
 31: hkn0411:2301028:2301136 [3] NCCL INFO Connected all rings
  3: hkn0403:1738677:1739059 [3] NCCL INFO Connected all rings
271: hkn0616:389985:390100 [3] NCCL INFO Connected all rings
307: hkn0629:1577178:1577305 [3] NCCL INFO Channel 01 : 307[e3000] -> 306[ca000] via P2P/IPC/read
 55: hkn0418:1854333:1854449 [3] NCCL INFO Channel 01 : 55[e3000] -> 54[ca000] via P2P/IPC/read
311: hkn0630:1583636:1583760 [3] NCCL INFO Channel 01 : 311[e3000] -> 310[ca000] via P2P/IPC/read
351: hkn0706:737447:737575 [3] NCCL INFO Connected all rings
343: hkn0704:777170:777274 [3] NCCL INFO Connected all rings
359: hkn0708:398415:398522 [3] NCCL INFO Channel 01 : 359[e3000] -> 358[ca000] via P2P/IPC/read
395: hkn0718:3902182:3902290 [3] NCCL INFO Connected all rings
 23: hkn0409:2570858:2570973 [3] NCCL INFO Channel 00 : 23[e3000] -> 22[ca000] via P2P/IPC/read
459: hkn0801:2225102:2225219 [3] NCCL INFO Connected all rings
115: hkn0505:2288941:2289062 [3] NCCL INFO Channel 01 : 115[e3000] -> 114[ca000] via P2P/IPC/read
187: hkn0527:1334069:1334163 [3] NCCL INFO Channel 01 : 187[e3000] -> 186[ca000] via P2P/IPC/read
 47: hkn0415:2481502:2481621 [3] NCCL INFO Channel 01 : 47[e3000] -> 46[ca000] via P2P/IPC/read
107: hkn0503:2884797:2884917 [3] NCCL INFO Channel 00 : 107[e3000] -> 106[ca000] via P2P/IPC/read
275: hkn0617:2279766:2279891 [3] NCCL INFO Channel 01 : 275[e3000] -> 274[ca000] via P2P/IPC/read
 63: hkn0420:3195346:3195463 [3] NCCL INFO Channel 00 : 63[e3000] -> 62[ca000] via P2P/IPC/read
183: hkn0526:1413553:1413678 [3] NCCL INFO Channel 01 : 183[e3000] -> 182[ca000] via P2P/IPC/read
291: hkn0624:1758078:1758198 [3] NCCL INFO Channel 00 : 291[e3000] -> 290[ca000] via P2P/IPC/read
103: hkn0502:214196:214352 [3] NCCL INFO Channel 00 : 103[e3000] -> 102[ca000] via P2P/IPC/read
335: hkn0636:1639362:1639461 [3] NCCL INFO Channel 00 : 335[e3000] -> 334[ca000] via P2P/IPC/read
279: hkn0621:1976627:1976741 [3] NCCL INFO Connected all rings
131: hkn0509:3109556:3109675 [3] NCCL INFO Connected all rings
504: hkn0815:380357:380455 [0] NCCL INFO Channel 01 : 504[31000] -> 507[e3000] via P2P/IPC/read
267: hkn0615:399435:399549 [3] NCCL INFO Connected all rings
 75: hkn0423:1689977:1690087 [3] NCCL INFO Connected all rings
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
347: hkn0705:768400:768514 [3] NCCL INFO Channel 01 : 347[e3000] -> 346[ca000] via P2P/IPC/read
299: hkn0627:1773082:1773180 [3] NCCL INFO Channel 01 : 299[e3000] -> 298[ca000] via P2P/IPC/read
367: hkn0711:569054:569153 [3] NCCL INFO Channel 00 : 367[e3000] -> 366[ca000] via P2P/IPC/read
123: hkn0507:3172200:3172323 [3] NCCL INFO Connected all rings
 39: hkn0413:2351834:2351947 [3] NCCL INFO Connected all rings
 95: hkn0428:652509:652633 [3] NCCL INFO Channel 00 : 95[e3000] -> 94[ca000] via P2P/IPC/read
431: hkn0728:1309090:1309203 [3] NCCL INFO Connected all rings
207: hkn0532:908790:909100 [3] NCCL INFO Connected all rings
463: hkn0802:1185491:1185618 [3] NCCL INFO Connected all rings
391: hkn0717:4172703:4172819 [3] NCCL INFO Connected all rings
319: hkn0632:1743781:1743911 [3] NCCL INFO Channel 01 : 319[e3000] -> 318[ca000] via P2P/IPC/read
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 00 : 84[31000] -> 87[e3000] via P2P/IPC/read
  7: hkn0404:1324519:1324638 [3] NCCL INFO Channel 01 : 7[e3000] -> 6[ca000] via P2P/IPC/read
379: hkn0714:417204:417316 [3] NCCL INFO Connected all rings
303: hkn0628:656987:657106 [3] NCCL INFO Connected all rings
315: hkn0631:1006960:1007067 [3] NCCL INFO Channel 00 : 315[e3000] -> 314[ca000] via P2P/IPC/read
119: hkn0506:823213:823305 [3] NCCL INFO Channel 00 : 119[e3000] -> 118[ca000] via P2P/IPC/read
171: hkn0523:1533178:1533297 [3] NCCL INFO Connected all rings
 79: hkn0424:2933081:2933238 [3] NCCL INFO Channel 01 : 79[e3000] -> 78[ca000] via P2P/IPC/read
175: hkn0524:1118950:1119063 [3] NCCL INFO Connected all rings
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 01 : 328[31000] -> 331[e3000] via P2P/IPC/read
371: hkn0712:280263:280354 [3] NCCL INFO Channel 01 : 371[e3000] -> 370[ca000] via P2P/IPC/read
 27: hkn0410:1144778:1144896 [3] NCCL INFO Connected all rings
 83: hkn0425:2069106:2069204 [3] NCCL INFO Channel 00 : 83[e3000] -> 82[ca000] via P2P/IPC/read
 23: hkn0409:2570858:2570973 [3] NCCL INFO Channel 01 : 23[e3000] -> 22[ca000] via P2P/IPC/read
223: hkn0602:3345215:3345483 [3] NCCL INFO Connected all rings
107: hkn0503:2884797:2884917 [3] NCCL INFO Channel 01 : 107[e3000] -> 106[ca000] via P2P/IPC/read
179: hkn0525:971983:972104 [3] NCCL INFO Connected all rings
 63: hkn0420:3195346:3195463 [3] NCCL INFO Channel 01 : 63[e3000] -> 62[ca000] via P2P/IPC/read
103: hkn0502:214196:214352 [3] NCCL INFO Channel 01 : 103[e3000] -> 102[ca000] via P2P/IPC/read
159: hkn0516:2901136:2901292 [3] NCCL INFO Connected all rings
335: hkn0636:1639362:1639461 [3] NCCL INFO Channel 01 : 335[e3000] -> 334[ca000] via P2P/IPC/read
339: hkn0703:726146:726263 [3] NCCL INFO Connected all rings
163: hkn0520:2698007:2698122 [3] NCCL INFO Connected all rings
367: hkn0711:569054:569153 [3] NCCL INFO Channel 01 : 367[e3000] -> 366[ca000] via P2P/IPC/read
 19: hkn0408:2875816:2875935 [3] NCCL INFO Connected all rings
291: hkn0624:1758078:1758198 [3] NCCL INFO Channel 01 : 291[e3000] -> 290[ca000] via P2P/IPC/read
 95: hkn0428:652509:652633 [3] NCCL INFO Channel 01 : 95[e3000] -> 94[ca000] via P2P/IPC/read
119: hkn0506:823213:823305 [3] NCCL INFO Channel 01 : 119[e3000] -> 118[ca000] via P2P/IPC/read
315: hkn0631:1006960:1007067 [3] NCCL INFO Channel 01 : 315[e3000] -> 314[ca000] via P2P/IPC/read
 67: hkn0421:2163500:2163778 [3] NCCL INFO Connected all rings
383: hkn0715:387112:387222 [3] NCCL INFO Connected all rings
167: hkn0521:1182990:1183086 [3] NCCL INFO Connected all rings
 15: hkn0407:1801457:1801568 [3] NCCL INFO Connected all rings
 83: hkn0425:2069106:2069204 [3] NCCL INFO Channel 01 : 83[e3000] -> 82[ca000] via P2P/IPC/read
155: hkn0515:2881942:2882062 [3] NCCL INFO Connected all rings
215: hkn0535:2384173:2384300 [3] NCCL INFO Connected all rings
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 01 : 84[31000] -> 87[e3000] via P2P/IPC/read
151: hkn0514:2935901:2936013 [3] NCCL INFO Connected all rings
375: hkn0713:455441:455538 [3] NCCL INFO Connected all rings
143: hkn0512:3029310:3029418 [3] NCCL INFO Connected all rings
499: hkn0812:678941:679039 [3] NCCL INFO Connected all rings
111: hkn0504:25981:26087 [3] NCCL INFO Connected all rings
 91: hkn0427:1120333:1120440 [3] NCCL INFO Channel 00 : 91[e3000] -> 90[ca000] via P2P/IPC/read
307: hkn0629:1577178:1577305 [3] NCCL INFO Connected all rings
 71: hkn0422:4138193:4138296 [3] NCCL INFO Connected all rings
311: hkn0630:1583636:1583760 [3] NCCL INFO Connected all rings
187: hkn0527:1334069:1334163 [3] NCCL INFO Connected all rings
359: hkn0708:398415:398522 [3] NCCL INFO Connected all rings
115: hkn0505:2288941:2289062 [3] NCCL INFO Connected all rings
327: hkn0634:1506040:1506149 [3] NCCL INFO Channel 00 : 327[e3000] -> 326[ca000] via P2P/IPC/read
 55: hkn0418:1854333:1854449 [3] NCCL INFO Connected all rings
183: hkn0526:1413553:1413678 [3] NCCL INFO Connected all rings
 47: hkn0415:2481502:2481621 [3] NCCL INFO Connected all rings
275: hkn0617:2279766:2279891 [3] NCCL INFO Connected all rings
387: hkn0716:93654:93766 [3] NCCL INFO Channel 00 : 387[e3000] -> 386[ca000] via P2P/IPC/read
 99: hkn0501:1312982:1313098 [3] NCCL INFO Channel 00 : 99[e3000] -> 98[ca000] via P2P/IPC/read
299: hkn0627:1773082:1773180 [3] NCCL INFO Connected all rings
347: hkn0705:768400:768514 [3] NCCL INFO Connected all rings
219: hkn0601:102808:102935 [3] NCCL INFO Channel 00 : 219[e3000] -> 218[ca000] via P2P/IPC/read
  7: hkn0404:1324519:1324638 [3] NCCL INFO Connected all rings
319: hkn0632:1743781:1743911 [3] NCCL INFO Connected all rings
 79: hkn0424:2933081:2933238 [3] NCCL INFO Connected all rings
 91: hkn0427:1120333:1120440 [3] NCCL INFO Channel 01 : 91[e3000] -> 90[ca000] via P2P/IPC/read
 23: hkn0409:2570858:2570973 [3] NCCL INFO Connected all rings
107: hkn0503:2884797:2884917 [3] NCCL INFO Connected all rings
371: hkn0712:280263:280354 [3] NCCL INFO Connected all rings
327: hkn0634:1506040:1506149 [3] NCCL INFO Channel 01 : 327[e3000] -> 326[ca000] via P2P/IPC/read
387: hkn0716:93654:93766 [3] NCCL INFO Channel 01 : 387[e3000] -> 386[ca000] via P2P/IPC/read
103: hkn0502:214196:214352 [3] NCCL INFO Connected all rings
 63: hkn0420:3195346:3195463 [3] NCCL INFO Connected all rings
335: hkn0636:1639362:1639461 [3] NCCL INFO Connected all rings
 99: hkn0501:1312982:1313098 [3] NCCL INFO Channel 01 : 99[e3000] -> 98[ca000] via P2P/IPC/read
367: hkn0711:569054:569153 [3] NCCL INFO Connected all rings
219: hkn0601:102808:102935 [3] NCCL INFO Channel 01 : 219[e3000] -> 218[ca000] via P2P/IPC/read
 95: hkn0428:652509:652633 [3] NCCL INFO Connected all rings
199: hkn0530:1243337:1243436 [3] NCCL INFO Channel 00 : 199[e3000] -> 198[ca000] via P2P/IPC/read
315: hkn0631:1006960:1007067 [3] NCCL INFO Connected all rings
119: hkn0506:823213:823305 [3] NCCL INFO Connected all rings
291: hkn0624:1758078:1758198 [3] NCCL INFO Connected all rings
255: hkn0611:694957:695086 [3] NCCL INFO Channel 00 : 255[e3000] -> 254[ca000] via P2P/IPC/read
 83: hkn0425:2069106:2069204 [3] NCCL INFO Connected all rings
427: hkn0727:1330957:1331044 [3] NCCL INFO Channel 00 : 427[e3000] -> 426[ca000] via P2P/IPC/read
127: hkn0508:3124313:3124406 [3] NCCL INFO Channel 00 : 127[e3000] -> 126[ca000] via P2P/IPC/read
287: hkn0623:1857898:1858023 [3] NCCL INFO Channel 00 : 287[e3000] -> 286[ca000] via P2P/IPC/read
199: hkn0530:1243337:1243436 [3] NCCL INFO Channel 01 : 199[e3000] -> 198[ca000] via P2P/IPC/read
255: hkn0611:694957:695086 [3] NCCL INFO Channel 01 : 255[e3000] -> 254[ca000] via P2P/IPC/read
427: hkn0727:1330957:1331044 [3] NCCL INFO Channel 01 : 427[e3000] -> 426[ca000] via P2P/IPC/read
 91: hkn0427:1120333:1120440 [3] NCCL INFO Connected all rings
127: hkn0508:3124313:3124406 [3] NCCL INFO Channel 01 : 127[e3000] -> 126[ca000] via P2P/IPC/read
287: hkn0623:1857898:1858023 [3] NCCL INFO Channel 01 : 287[e3000] -> 286[ca000] via P2P/IPC/read
327: hkn0634:1506040:1506149 [3] NCCL INFO Connected all rings
387: hkn0716:93654:93766 [3] NCCL INFO Connected all rings
 99: hkn0501:1312982:1313098 [3] NCCL INFO Connected all rings
507: hkn0815:380345:380457 [3] NCCL INFO Channel 00 : 507[e3000] -> 506[ca000] via P2P/IPC/read
219: hkn0601:102808:102935 [3] NCCL INFO Connected all rings
331: hkn0635:1210773:1210865 [3] NCCL INFO Channel 00 : 331[e3000] -> 330[ca000] via P2P/IPC/read
507: hkn0815:380345:380457 [3] NCCL INFO Channel 01 : 507[e3000] -> 506[ca000] via P2P/IPC/read
199: hkn0530:1243337:1243436 [3] NCCL INFO Connected all rings
331: hkn0635:1210773:1210865 [3] NCCL INFO Channel 01 : 331[e3000] -> 330[ca000] via P2P/IPC/read
427: hkn0727:1330957:1331044 [3] NCCL INFO Connected all rings
 87: hkn0426:799254:799358 [3] NCCL INFO Channel 00 : 87[e3000] -> 86[ca000] via P2P/IPC/read
127: hkn0508:3124313:3124406 [3] NCCL INFO Connected all rings
287: hkn0623:1857898:1858023 [3] NCCL INFO Connected all rings
255: hkn0611:694957:695086 [3] NCCL INFO Connected all rings
233: hkn0605:697262:697393 [1] NCCL INFO Connected all rings
 87: hkn0426:799254:799358 [3] NCCL INFO Channel 01 : 87[e3000] -> 86[ca000] via P2P/IPC/read
507: hkn0815:380345:380457 [3] NCCL INFO Connected all rings
400: hkn0720:4181520:4181819 [0] NCCL INFO Connected all rings
331: hkn0635:1210773:1210865 [3] NCCL INFO Connected all rings
440: hkn0732:1196819:1196963 [0] NCCL INFO Connected all rings
444: hkn0733:1374558:1374666 [0] NCCL INFO Connected all rings
 37: hkn0413:2351826:2351942 [1] NCCL INFO Connected all rings
484: hkn0808:955851:955982 [0] NCCL INFO Connected all rings
437: hkn0731:1371908:1372021 [1] NCCL INFO Connected all rings
481: hkn0807:1004271:1004387 [1] NCCL INFO Connected all rings
232: hkn0605:697242:697386 [0] NCCL INFO Connected all rings
240: hkn0607:889534:889628 [0] NCCL INFO Connected all rings
401: hkn0720:4181528:4181827 [1] NCCL INFO Connected all rings
 87: hkn0426:799254:799358 [3] NCCL INFO Connected all rings
228: hkn0604:674438:674558 [0] NCCL INFO Connected all rings
277: hkn0621:1976619:1976745 [1] NCCL INFO Connected all rings
429: hkn0728:1309098:1309209 [1] NCCL INFO Connected all rings
445: hkn0733:1374570:1374664 [1] NCCL INFO Connected all rings
404: hkn0721:2284143:2284269 [0] NCCL INFO Connected all rings
189: hkn0528:1286847:1286970 [1] NCCL INFO Connected all rings
472: hkn0805:1097255:1097378 [0] NCCL INFO Connected all rings
448: hkn0734:1141748:1141849 [0] NCCL INFO Connected all rings
234: hkn0605:697234:697394 [2] NCCL INFO Connected all rings
489: hkn0809:922561:922677 [1] NCCL INFO Connected all rings
229: hkn0604:674466:674561 [1] NCCL INFO Connected all rings
 32: hkn0412:2247570:2247665 [0] NCCL INFO Connected all rings
236: hkn0606:2357167:2357319 [0] NCCL INFO Connected all rings
225: hkn0603:1398307:1398426 [1] NCCL INFO Connected all rings
476: hkn0806:1039501:1039609 [0] NCCL INFO Connected all rings
397: hkn0719:1290860:1290956 [1] NCCL INFO Connected all rings
 28: hkn0411:2301020:2301135 [0] NCCL INFO Connected all rings
436: hkn0731:1371920:1372018 [0] NCCL INFO Connected all rings
432: hkn0730:1386910:1387019 [0] NCCL INFO Connected all rings
 36: hkn0413:2351818:2351944 [0] NCCL INFO Connected all rings
488: hkn0809:922553:922675 [0] NCCL INFO Connected all rings
256: hkn0612:902120:902251 [0] NCCL INFO Connected all rings
480: hkn0807:1004272:1004391 [0] NCCL INFO Connected all rings
464: hkn0803:861669:861771 [0] NCCL INFO Connected all rings
469: hkn0804:1190775:1190890 [1] NCCL INFO Connected all rings
473: hkn0805:1097263:1097382 [1] NCCL INFO Connected all rings
244: hkn0608:470923:471037 [0] NCCL INFO Connected all rings
396: hkn0719:1290840:1290959 [0] NCCL INFO Connected all rings
461: hkn0802:1185499:1185610 [1] NCCL INFO Connected all rings
129: hkn0509:3109564:3109680 [1] NCCL INFO Connected all rings
132: hkn0510:2747220:2747346 [0] NCCL INFO Connected all rings
205: hkn0532:908774:909097 [1] NCCL INFO Connected all rings
497: hkn0812:678921:679031 [1] NCCL INFO Connected all rings
449: hkn0734:1141728:1141851 [1] NCCL INFO Connected all rings
392: hkn0718:3902194:3902291 [0] NCCL INFO Connected all rings
 45: hkn0415:2481516:2481618 [1] NCCL INFO Connected all rings
245: hkn0608:470935:471034 [1] NCCL INFO Connected all rings
388: hkn0717:4172687:4172818 [0] NCCL INFO Connected all rings
168: hkn0523:1533186:1533298 [0] NCCL INFO Connected all rings
276: hkn0621:1976635:1976739 [0] NCCL INFO Connected all rings
441: hkn0732:1196811:1196965 [1] NCCL INFO Connected all rings
 25: hkn0410:1144790:1144895 [1] NCCL INFO Connected all rings
460: hkn0802:1185519:1185612 [0] NCCL INFO Connected all rings
485: hkn0808:955879:955981 [1] NCCL INFO Connected all rings
452: hkn0736:1493537:1493642 [0] NCCL INFO Connected all rings
265: hkn0615:399447:399552 [1] NCCL INFO Connected all rings
172: hkn0524:1118962:1119061 [0] NCCL INFO Connected all rings
468: hkn0804:1190767:1190886 [0] NCCL INFO Connected all rings
237: hkn0606:2357183:2357320 [1] NCCL INFO Connected all rings
220: hkn0602:3345223:3345484 [0] NCCL INFO Connected all rings
128: hkn0509:3109576:3109676 [0] NCCL INFO Connected all rings
405: hkn0721:2284159:2284270 [1] NCCL INFO Connected all rings
273: hkn0617:2279794:2279887 [1] NCCL INFO Connected all rings
200: hkn0531:1215696:1215820 [0] NCCL INFO Connected all rings
165: hkn0521:1182962:1183092 [1] NCCL INFO Connected all rings
144: hkn0513:2998090:2998209 [0] NCCL INFO Connected all rings
 29: hkn0411:2301040:2301137 [1] NCCL INFO Connected all rings
204: hkn0532:908782:909098 [0] NCCL INFO Connected all rings
393: hkn0718:3902174:3902293 [1] NCCL INFO Connected all rings
173: hkn0524:1118934:1119058 [1] NCCL INFO Connected all rings
492: hkn0810:924748:924846 [0] NCCL INFO Connected all rings
224: hkn0603:1398327:1398423 [0] NCCL INFO Connected all rings
241: hkn0607:889514:889633 [1] NCCL INFO Connected all rings
456: hkn0801:2225122:2225226 [0] NCCL INFO Connected all rings
152: hkn0515:2881970:2882070 [0] NCCL INFO Connected all rings
133: hkn0510:2747236:2747343 [1] NCCL INFO Connected all rings
433: hkn0730:1386894:1387025 [1] NCCL INFO Connected all rings
317: hkn0632:1743769:1743914 [1] NCCL INFO Connected all rings
221: hkn0602:3345235:3345487 [1] NCCL INFO Connected all rings
141: hkn0512:3029294:3029422 [1] NCCL INFO Connected all rings
 38: hkn0413:2351846:2351938 [2] NCCL INFO Connected all rings
 53: hkn0418:1854353:1854450 [1] NCCL INFO Connected all rings
289: hkn0624:1758098:1758200 [1] NCCL INFO Connected all rings
385: hkn0716:93646:93761 [1] NCCL INFO Connected all rings
268: hkn0616:389997:390101 [0] NCCL INFO Connected all rings
496: hkn0812:678913:679036 [0] NCCL INFO Connected all rings
453: hkn0736:1493549:1493641 [1] NCCL INFO Connected all rings
 33: hkn0412:2247562:2247671 [1] NCCL INFO Connected all rings
477: hkn0806:1039485:1039615 [1] NCCL INFO Connected all rings
408: hkn0723:192917:193087 [0] NCCL INFO Connected all rings
389: hkn0717:4172715:4172825 [1] NCCL INFO Connected all rings
140: hkn0512:3029302:3029419 [0] NCCL INFO Connected all rings
136: hkn0511:3051475:3051605 [0] NCCL INFO Connected all rings
160: hkn0520:2697999:2698118 [0] NCCL INFO Connected all rings
257: hkn0612:902128:902247 [1] NCCL INFO Connected all rings
148: hkn0514:2935885:2936010 [0] NCCL INFO Connected all rings
428: hkn0728:1309082:1309204 [0] NCCL INFO Connected all rings
398: hkn0719:1290848:1290952 [2] NCCL INFO Connected all rings
373: hkn0713:455427:455540 [1] NCCL INFO Connected all rings
108: hkn0504:25965:26094 [0] NCCL INFO Connected all rings
297: hkn0627:1773070:1773181 [1] NCCL INFO Connected all rings
409: hkn0723:192925:193085 [1] NCCL INFO Connected all rings
482: hkn0807:1004292:1004392 [2] NCCL INFO Connected all rings
 24: hkn0410:1144774:1144891 [0] NCCL INFO Connected all rings
164: hkn0521:1182978:1183084 [0] NCCL INFO Connected all rings
438: hkn0731:1371892:1372022 [2] NCCL INFO Connected all rings
208: hkn0534:1133577:1133694 [0] NCCL INFO Connected all rings
232: hkn0605:697242:697386 [0] NCCL INFO Channel 00 : 232[31000] -> 233[4b000] via P2P/IPC/read
  5: hkn0404:1324527:1324632 [1] NCCL INFO Connected all rings
430: hkn0728:1309110:1309210 [2] NCCL INFO Connected all rings
253: hkn0611:694985:695081 [1] NCCL INFO Connected all rings
190: hkn0528:1286863:1286971 [2] NCCL INFO Connected all rings
201: hkn0531:1215724:1215823 [1] NCCL INFO Connected all rings
180: hkn0526:1413561:1413674 [0] NCCL INFO Connected all rings
197: hkn0530:1243325:1243432 [1] NCCL INFO Connected all rings
337: hkn0703:726148:726258 [1] NCCL INFO Connected all rings
305: hkn0629:1577194:1577306 [1] NCCL INFO Connected all rings
272: hkn0617:2279782:2279893 [0] NCCL INFO Connected all rings
 48: hkn0417:2252758:2252860 [0] NCCL INFO Connected all rings
278: hkn0621:1976647:1976747 [2] NCCL INFO Connected all rings
353: hkn0707:4005073:4005192 [1] NCCL INFO Connected all rings
345: hkn0705:768401:768516 [1] NCCL INFO Connected all rings
260: hkn0613:887844:887968 [0] NCCL INFO Connected all rings
462: hkn0802:1185507:1185616 [2] NCCL INFO Connected all rings
344: hkn0705:768421:768521 [0] NCCL INFO Connected all rings
217: hkn0601:102836:102938 [1] NCCL INFO Connected all rings
 61: hkn0420:3195354:3195457 [1] NCCL INFO Connected all rings
340: hkn0704:777158:777265 [0] NCCL INFO Connected all rings
300: hkn0628:656995:657105 [0] NCCL INFO Connected all rings
176: hkn0525:971975:972098 [0] NCCL INFO Connected all rings
117: hkn0506:823185:823311 [1] NCCL INFO Connected all rings
 65: hkn0421:2163528:2163777 [1] NCCL INFO Connected all rings
308: hkn0630:1583656:1583761 [0] NCCL INFO Connected all rings
402: hkn0720:4181548:4181824 [2] NCCL INFO Connected all rings
 21: hkn0409:2570850:2570977 [1] NCCL INFO Connected all rings
145: hkn0513:2998098:2998200 [1] NCCL INFO Connected all rings
 52: hkn0418:1854341:1854446 [0] NCCL INFO Connected all rings
226: hkn0603:1398315:1398422 [2] NCCL INFO Connected all rings
230: hkn0604:674446:674565 [2] NCCL INFO Connected all rings
365: hkn0711:569034:569157 [1] NCCL INFO Connected all rings
446: hkn0733:1374549:1374669 [2] NCCL INFO Connected all rings
 12: hkn0407:1801469:1801564 [0] NCCL INFO Connected all rings
490: hkn0809:922569:922682 [2] NCCL INFO Connected all rings
  8: hkn0405:3191892:3192005 [0] NCCL INFO Connected all rings
442: hkn0732:1196803:1196961 [2] NCCL INFO Connected all rings
177: hkn0525:971991:972103 [1] NCCL INFO Connected all rings
169: hkn0523:1533198:1533289 [1] NCCL INFO Connected all rings
125: hkn0508:3124305:3124410 [1] NCCL INFO Connected all rings
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 00 : 400[31000] -> 401[4b000] via P2P/IPC/read
 64: hkn0421:2163508:2163779 [0] NCCL INFO Connected all rings
153: hkn0515:2881958:2882071 [1] NCCL INFO Connected all rings
105: hkn0503:2884817:2884916 [1] NCCL INFO Connected all rings
296: hkn0627:1773062:1773179 [0] NCCL INFO Connected all rings
  4: hkn0404:1324511:1324629 [0] NCCL INFO Connected all rings
493: hkn0810:924720:924850 [1] NCCL INFO Connected all rings
376: hkn0714:417195:417320 [0] NCCL INFO Connected all rings
364: hkn0711:569026:569156 [0] NCCL INFO Connected all rings
304: hkn0629:1577186:1577310 [0] NCCL INFO Connected all rings
 46: hkn0415:2481504:2481617 [2] NCCL INFO Connected all rings
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 00 : 444[31000] -> 445[4b000] via P2P/IPC/read
470: hkn0804:1190787:1190892 [2] NCCL INFO Connected all rings
486: hkn0808:955867:955976 [2] NCCL INFO Connected all rings
465: hkn0803:861667:861779 [1] NCCL INFO Connected all rings
137: hkn0511:3051503:3051608 [1] NCCL INFO Connected all rings
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 00 : 436[31000] -> 437[4b000] via P2P/IPC/read
 73: hkn0423:1689969:1690080 [1] NCCL INFO Connected all rings
498: hkn0812:678929:679040 [2] NCCL INFO Connected all rings
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 00 : 480[31000] -> 481[4b000] via P2P/IPC/read
 16: hkn0408:2875836:2875939 [0] NCCL INFO Connected all rings
474: hkn0805:1097271:1097381 [2] NCCL INFO Connected all rings
264: hkn0615:399427:399550 [0] NCCL INFO Connected all rings
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 00 : 396[31000] -> 397[4b000] via P2P/IPC/read
416: hkn0725:3097110:3097192 [0] NCCL INFO Connected all rings
248: hkn0609:696056:696155 [0] NCCL INFO Connected all rings
  1: hkn0403:1738685:1739058 [1] NCCL INFO Connected all rings
206: hkn0532:908802:909093 [2] NCCL INFO Connected all rings
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 00 : 36[31000] -> 37[4b000] via P2P/IPC/read
266: hkn0615:399419:399548 [2] NCCL INFO Connected all rings
318: hkn0632:1743760:1743909 [2] NCCL INFO Connected all rings
269: hkn0616:389977:390103 [1] NCCL INFO Connected all rings
478: hkn0806:1039513:1039607 [2] NCCL INFO Connected all rings
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 00 : 440[31000] -> 441[4b000] via P2P/IPC/read
 13: hkn0407:1801441:1801573 [1] NCCL INFO Connected all rings
 26: hkn0410:1144773:1144892 [2] NCCL INFO Connected all rings
457: hkn0801:2225101:2225223 [1] NCCL INFO Connected all rings
112: hkn0505:2288969:2289061 [0] NCCL INFO Connected all rings
181: hkn0526:1413569:1413673 [1] NCCL INFO Connected all rings
130: hkn0509:3109548:3109677 [2] NCCL INFO Connected all rings
 40: hkn0414:1966696:1966821 [0] NCCL INFO Connected all rings
100: hkn0502:214212:214345 [0] NCCL INFO Connected all rings
192: hkn0529:1525995:1526126 [0] NCCL INFO Connected all rings
425: hkn0727:1330936:1331042 [1] NCCL INFO Connected all rings
161: hkn0520:2698015:2698119 [1] NCCL INFO Connected all rings
 20: hkn0409:2570878:2570976 [0] NCCL INFO Connected all rings
228: hkn0604:674438:674558 [0] NCCL INFO Channel 00 : 228[31000] -> 229[4b000] via P2P/IPC/read
246: hkn0608:470915:471032 [2] NCCL INFO Connected all rings
 49: hkn0417:2252738:2252863 [1] NCCL INFO Connected all rings
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 00 : 276[31000] -> 277[4b000] via P2P/IPC/read
209: hkn0534:1133578:1133691 [1] NCCL INFO Connected all rings
157: hkn0516:2901164:2901294 [1] NCCL INFO Connected all rings
149: hkn0514:2935893:2936011 [1] NCCL INFO Connected all rings
484: hkn0808:955851:955982 [0] NCCL INFO Channel 00 : 484[31000] -> 485[4b000] via P2P/IPC/read
261: hkn0613:887816:887974 [1] NCCL INFO Connected all rings
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 00 : 460[31000] -> 461[4b000] via P2P/IPC/read
450: hkn0734:1141720:1141848 [2] NCCL INFO Connected all rings
488: hkn0809:922553:922675 [0] NCCL INFO Channel 00 : 488[31000] -> 489[4b000] via P2P/IPC/read
316: hkn0632:1743761:1743906 [0] NCCL INFO Connected all rings
142: hkn0512:3029322:3029415 [2] NCCL INFO Connected all rings
348: hkn0706:737455:737573 [0] NCCL INFO Connected all rings
156: hkn0516:2901152:2901289 [0] NCCL INFO Connected all rings
341: hkn0704:777142:777272 [1] NCCL INFO Connected all rings
412: hkn0724:1701140:1701248 [0] NCCL INFO Connected all rings
352: hkn0707:4005081:4005188 [0] NCCL INFO Connected all rings
 89: hkn0427:1120325:1120445 [1] NCCL INFO Connected all rings
406: hkn0721:2284171:2284267 [2] NCCL INFO Connected all rings
301: hkn0628:657007:657097 [1] NCCL INFO Connected all rings
238: hkn0606:2357175:2357324 [2] NCCL INFO Connected all rings
274: hkn0617:2279774:2279896 [2] NCCL INFO Connected all rings
109: hkn0504:25973:26092 [1] NCCL INFO Connected all rings
320: hkn0633:1511506:1511630 [0] NCCL INFO Connected all rings
377: hkn0714:417216:417317 [1] NCCL INFO Connected all rings
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 00 : 448[31000] -> 449[4b000] via P2P/IPC/read
166: hkn0521:1182970:1183090 [2] NCCL INFO Connected all rings
 60: hkn0420:3195338:3195466 [0] NCCL INFO Connected all rings
290: hkn0624:1758086:1758202 [2] NCCL INFO Connected all rings
386: hkn0716:93666:93764 [2] NCCL INFO Connected all rings
232: hkn0605:697242:697386 [0] NCCL INFO Channel 01 : 232[31000] -> 233[4b000] via P2P/IPC/read
309: hkn0630:1583628:1583756 [1] NCCL INFO Connected all rings
  9: hkn0405:3191904:3192003 [1] NCCL INFO Connected all rings
244: hkn0608:470923:471037 [0] NCCL INFO Channel 00 : 244[31000] -> 245[4b000] via P2P/IPC/read
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 00 : 476[31000] -> 477[4b000] via P2P/IPC/read
240: hkn0607:889534:889628 [0] NCCL INFO Channel 00 : 240[31000] -> 241[4b000] via P2P/IPC/read
  0: hkn0403:1738669:1739051 [0] NCCL INFO Connected all rings
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 00 : 404[31000] -> 405[4b000] via P2P/IPC/read
 68: hkn0422:4138173:4138299 [0] NCCL INFO Connected all rings
188: hkn0528:1286855:1286975 [0] NCCL INFO Connected all rings
420: hkn0726:1533318:1533412 [0] NCCL INFO Connected all rings
361: hkn0710:340632:340748 [1] NCCL INFO Connected all rings
204: hkn0532:908782:909098 [0] NCCL INFO Channel 00 : 204[31000] -> 205[4b000] via P2P/IPC/read
394: hkn0718:3902173:3902289 [2] NCCL INFO Connected all rings
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 00 : 236[31000] -> 237[4b000] via P2P/IPC/read
116: hkn0506:823193:823308 [0] NCCL INFO Connected all rings
242: hkn0607:889522:889635 [2] NCCL INFO Connected all rings
434: hkn0730:1386902:1387024 [2] NCCL INFO Connected all rings
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 00 : 224[31000] -> 225[4b000] via P2P/IPC/read
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 00 : 128[31000] -> 129[4b000] via P2P/IPC/read
292: hkn0626:1283594:1283703 [0] NCCL INFO Connected all rings
 54: hkn0418:1854325:1854445 [2] NCCL INFO Connected all rings
 34: hkn0412:2247554:2247673 [2] NCCL INFO Connected all rings
174: hkn0524:1118942:1119055 [2] NCCL INFO Connected all rings
233: hkn0605:697262:697393 [1] NCCL INFO Channel 00 : 233[4b000] -> 234[ca000] via P2P/IPC/read
346: hkn0705:768409:768518 [2] NCCL INFO Connected all rings
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 00 : 428[31000] -> 429[4b000] via P2P/IPC/read
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 00 : 468[31000] -> 469[4b000] via P2P/IPC/read
374: hkn0713:455429:455542 [2] NCCL INFO Connected all rings
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 00 : 472[31000] -> 473[4b000] via P2P/IPC/read
218: hkn0601:102824:102933 [2] NCCL INFO Connected all rings
101: hkn0502:214224:214351 [1] NCCL INFO Connected all rings
104: hkn0503:2884789:2884923 [0] NCCL INFO Connected all rings
312: hkn0631:1006952:1007073 [0] NCCL INFO Connected all rings
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 00 : 28[31000] -> 29[4b000] via P2P/IPC/read
222: hkn0602:3345207:3345482 [2] NCCL INFO Connected all rings
 76: hkn0424:2933109:2933241 [0] NCCL INFO Connected all rings
113: hkn0505:2288949:2289068 [1] NCCL INFO Connected all rings
258: hkn0612:902136:902248 [2] NCCL INFO Connected all rings
248: hkn0609:696056:696155 [0] NCCL INFO Channel 00 : 248[31000] -> 249[4b000] via P2P/IPC/read
390: hkn0717:4172695:4172824 [2] NCCL INFO Connected all rings
 30: hkn0411:2301012:2301139 [2] NCCL INFO Connected all rings
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 00 : 32[31000] -> 33[4b000] via P2P/IPC/read
 56: hkn0419:1529464:1529580 [0] NCCL INFO Connected all rings
134: hkn0510:2747248:2747351 [2] NCCL INFO Connected all rings
 88: hkn0427:1120324:1120446 [0] NCCL INFO Connected all rings
298: hkn0627:1773054:1773175 [2] NCCL INFO Connected all rings
288: hkn0624:1758070:1758195 [0] NCCL INFO Connected all rings
254: hkn0611:694965:695087 [2] NCCL INFO Connected all rings
106: hkn0503:2884805:2884921 [2] NCCL INFO Connected all rings
329: hkn0635:1210739:1210866 [1] NCCL INFO Connected all rings
496: hkn0812:678913:679036 [0] NCCL INFO Channel 00 : 496[31000] -> 497[4b000] via P2P/IPC/read
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 00 : 392[31000] -> 393[4b000] via P2P/IPC/read
146: hkn0513:2998110:2998204 [2] NCCL INFO Connected all rings
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 00 : 140[31000] -> 141[4b000] via P2P/IPC/read
198: hkn0530:1243309:1243429 [2] NCCL INFO Connected all rings
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 00 : 432[31000] -> 433[4b000] via P2P/IPC/read
338: hkn0703:726147:726262 [2] NCCL INFO Connected all rings
380: hkn0715:387124:387215 [0] NCCL INFO Connected all rings
454: hkn0736:1493528:1493648 [2] NCCL INFO Connected all rings
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 00 : 40[31000] -> 41[4b000] via P2P/IPC/read
256: hkn0612:902120:902251 [0] NCCL INFO Channel 00 : 256[31000] -> 257[4b000] via P2P/IPC/read
354: hkn0707:4005065:4005191 [2] NCCL INFO Connected all rings
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 00 : 388[31000] -> 389[4b000] via P2P/IPC/read
280: hkn0622:2005593:2005692 [0] NCCL INFO Connected all rings
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 00 : 132[31000] -> 133[4b000] via P2P/IPC/read
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 00 : 172[31000] -> 173[4b000] via P2P/IPC/read
348: hkn0706:737455:737573 [0] NCCL INFO Channel 00 : 348[31000] -> 349[4b000] via P2P/IPC/read
356: hkn0708:398416:398525 [0] NCCL INFO Connected all rings
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 00 : 24[31000] -> 25[4b000] via P2P/IPC/read
120: hkn0507:3172228:3172326 [0] NCCL INFO Connected all rings
 17: hkn0408:2875824:2875937 [1] NCCL INFO Connected all rings
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 00 : 220[31000] -> 221[4b000] via P2P/IPC/read
  6: hkn0404:1324539:1324635 [2] NCCL INFO Connected all rings
500: hkn0814:660997:661104 [0] NCCL INFO Connected all rings
410: hkn0723:192937:193090 [2] NCCL INFO Connected all rings
417: hkn0725:3097090:3097194 [1] NCCL INFO Connected all rings
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 00 : 452[31000] -> 453[4b000] via P2P/IPC/read
 62: hkn0420:3195366:3195465 [2] NCCL INFO Connected all rings
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 01 : 436[31000] -> 437[4b000] via P2P/IPC/read
384: hkn0716:93645:93760 [0] NCCL INFO Connected all rings
306: hkn0629:1577206:1577307 [2] NCCL INFO Connected all rings
 44: hkn0415:2481503:2481619 [0] NCCL INFO Connected all rings
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 00 : 164[31000] -> 165[4b000] via P2P/IPC/read
118: hkn0506:823201:823314 [2] NCCL INFO Connected all rings
 96: hkn0501:1312974:1313097 [0] NCCL INFO Connected all rings
508: hkn0816:360788:360900 [0] NCCL INFO Connected all rings
464: hkn0803:861669:861771 [0] NCCL INFO Channel 00 : 464[31000] -> 465[4b000] via P2P/IPC/read
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 01 : 400[31000] -> 401[4b000] via P2P/IPC/read
360: hkn0710:340644:340742 [0] NCCL INFO Connected all rings
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 00 : 272[31000] -> 273[4b000] via P2P/IPC/read
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 01 : 444[31000] -> 445[4b000] via P2P/IPC/read
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 01 : 480[31000] -> 481[4b000] via P2P/IPC/read
466: hkn0803:861668:861780 [2] NCCL INFO Connected all rings
 92: hkn0428:652537:652628 [0] NCCL INFO Connected all rings
202: hkn0531:1215712:1215824 [2] NCCL INFO Connected all rings
126: hkn0508:3124297:3124412 [2] NCCL INFO Connected all rings
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 01 : 396[31000] -> 397[4b000] via P2P/IPC/read
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 01 : 36[31000] -> 37[4b000] via P2P/IPC/read
 66: hkn0421:2163516:2163782 [2] NCCL INFO Connected all rings
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 01 : 440[31000] -> 441[4b000] via P2P/IPC/read
 22: hkn0409:2570866:2570968 [2] NCCL INFO Connected all rings
 14: hkn0407:1801449:1801570 [2] NCCL INFO Connected all rings
368: hkn0712:280251:280359 [0] NCCL INFO Connected all rings
264: hkn0615:399427:399550 [0] NCCL INFO Channel 00 : 264[31000] -> 265[4b000] via P2P/IPC/read
 74: hkn0423:1689961:1690083 [2] NCCL INFO Connected all rings
458: hkn0801:2225110:2225221 [2] NCCL INFO Connected all rings
293: hkn0626:1283586:1283696 [1] NCCL INFO Connected all rings
 97: hkn0501:1312996:1313099 [1] NCCL INFO Connected all rings
184: hkn0527:1334049:1334169 [0] NCCL INFO Connected all rings
366: hkn0711:569042:569160 [2] NCCL INFO Connected all rings
344: hkn0705:768421:768521 [0] NCCL INFO Channel 00 : 344[31000] -> 345[4b000] via P2P/IPC/read
228: hkn0604:674438:674558 [0] NCCL INFO Channel 01 : 228[31000] -> 229[4b000] via P2P/IPC/read
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 00 : 200[31000] -> 201[4b000] via P2P/IPC/read
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 01 : 276[31000] -> 277[4b000] via P2P/IPC/read
484: hkn0808:955851:955982 [0] NCCL INFO Channel 01 : 484[31000] -> 485[4b000] via P2P/IPC/read
424: hkn0727:1330945:1331038 [0] NCCL INFO Connected all rings
234: hkn0605:697234:697394 [2] NCCL INFO Channel 00 : 234[ca000] -> 235[e3000] via P2P/IPC/read
162: hkn0520:2698027:2698123 [2] NCCL INFO Connected all rings
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 00 : 144[31000] -> 145[4b000] via P2P/IPC/read
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 00 : 52[31000] -> 53[4b000] via P2P/IPC/read
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 00 : 168[31000] -> 169[4b000] via P2P/IPC/read
494: hkn0810:924728:924849 [2] NCCL INFO Connected all rings
 93: hkn0428:652517:652634 [1] NCCL INFO Connected all rings
 57: hkn0419:1529484:1529583 [1] NCCL INFO Connected all rings
 77: hkn0424:2933097:2933239 [1] NCCL INFO Connected all rings
408: hkn0723:192917:193087 [0] NCCL INFO Channel 00 : 408[31000] -> 409[4b000] via P2P/IPC/read
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 01 : 460[31000] -> 461[4b000] via P2P/IPC/read
233: hkn0605:697262:697393 [1] NCCL INFO Channel 01 : 233[4b000] -> 234[ca000] via P2P/IPC/read
313: hkn0631:1006972:1007066 [1] NCCL INFO Connected all rings
170: hkn0523:1533170:1533292 [2] NCCL INFO Connected all rings
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 00 : 420[31000] -> 421[4b000] via P2P/IPC/read
488: hkn0809:922553:922675 [0] NCCL INFO Channel 01 : 488[31000] -> 489[4b000] via P2P/IPC/read
154: hkn0515:2881950:2882069 [2] NCCL INFO Connected all rings
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 00 : 68[31000] -> 69[4b000] via P2P/IPC/read
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 00 : 296[31000] -> 297[4b000] via P2P/IPC/read
178: hkn0525:972003:972097 [2] NCCL INFO Connected all rings
212: hkn0535:2384201:2384301 [0] NCCL INFO Connected all rings
138: hkn0511:3051491:3051603 [2] NCCL INFO Connected all rings
372: hkn0713:455428:455539 [0] NCCL INFO Connected all rings
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 00 : 189[4b000] -> 190[ca000] via P2P/IPC/read
  2: hkn0403:1738697:1739060 [2] NCCL INFO Connected all rings
492: hkn0810:924748:924846 [0] NCCL INFO Channel 00 : 492[31000] -> 493[4b000] via P2P/IPC/read
426: hkn0727:1330937:1331047 [2] NCCL INFO Connected all rings
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 00 : 316[31000] -> 317[4b000] via P2P/IPC/read
248: hkn0609:696056:696155 [0] NCCL INFO Channel 01 : 248[31000] -> 249[4b000] via P2P/IPC/read
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 00 : 4[31000] -> 5[4b000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO Connected all rings
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 01 : 448[31000] -> 449[4b000] via P2P/IPC/read
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 00 : 456[31000] -> 457[4b000] via P2P/IPC/read
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 00 : 64[31000] -> 65[4b000] via P2P/IPC/read
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 00 : 152[31000] -> 153[4b000] via P2P/IPC/read
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 00 : 136[31000] -> 137[4b000] via P2P/IPC/read
210: hkn0534:1133593:1133689 [2] NCCL INFO Connected all rings
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 00 : 160[31000] -> 161[4b000] via P2P/IPC/read
270: hkn0616:389969:390099 [2] NCCL INFO Connected all rings
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 00 : 304[31000] -> 305[4b000] via P2P/IPC/read
285: hkn0623:1857886:1858018 [1] NCCL INFO Connected all rings
182: hkn0526:1413581:1413675 [2] NCCL INFO Connected all rings
240: hkn0607:889534:889628 [0] NCCL INFO Channel 01 : 240[31000] -> 241[4b000] via P2P/IPC/read
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 01 : 472[31000] -> 473[4b000] via P2P/IPC/read
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 01 : 404[31000] -> 405[4b000] via P2P/IPC/read
 37: hkn0413:2351826:2351942 [1] NCCL INFO Channel 00 : 37[4b000] -> 38[ca000] via P2P/IPC/read
244: hkn0608:470923:471037 [0] NCCL INFO Channel 01 : 244[31000] -> 245[4b000] via P2P/IPC/read
268: hkn0616:389997:390101 [0] NCCL INFO Channel 00 : 268[31000] -> 269[4b000] via P2P/IPC/read
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 01 : 236[31000] -> 237[4b000] via P2P/IPC/read
 85: hkn0426:799266:799362 [1] NCCL INFO Connected all rings
500: hkn0814:660997:661104 [0] NCCL INFO Channel 00 : 500[31000] -> 501[4b000] via P2P/IPC/read
204: hkn0532:908782:909098 [0] NCCL INFO Channel 01 : 204[31000] -> 205[4b000] via P2P/IPC/read
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 00 : 12[31000] -> 13[4b000] via P2P/IPC/read
 72: hkn0423:1689989:1690089 [0] NCCL INFO Connected all rings
158: hkn0516:2901144:2901290 [2] NCCL INFO Connected all rings
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 01 : 476[31000] -> 477[4b000] via P2P/IPC/read
 50: hkn0417:2252730:2252862 [2] NCCL INFO Connected all rings
150: hkn0514:2935913:2936009 [2] NCCL INFO Connected all rings
364: hkn0711:569026:569156 [0] NCCL INFO Channel 00 : 364[31000] -> 365[4b000] via P2P/IPC/read
381: hkn0715:387096:387223 [1] NCCL INFO Connected all rings
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 00 : 280[31000] -> 281[4b000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 01 : 428[31000] -> 429[4b000] via P2P/IPC/read
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 00 : 208[31000] -> 209[4b000] via P2P/IPC/read
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 01 : 224[31000] -> 225[4b000] via P2P/IPC/read
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 01 : 128[31000] -> 129[4b000] via P2P/IPC/read
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 00 : 20[31000] -> 21[4b000] via P2P/IPC/read
332: hkn0636:1639342:1639458 [0] NCCL INFO Connected all rings
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 00 : 180[31000] -> 181[4b000] via P2P/IPC/read
196: hkn0530:1243317:1243433 [0] NCCL INFO Connected all rings
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 00 : 481[4b000] -> 482[ca000] via P2P/IPC/read
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 00 : 352[31000] -> 353[4b000] via P2P/IPC/read
262: hkn0613:887824:887976 [2] NCCL INFO Connected all rings
 80: hkn0425:2069098:2069207 [0] NCCL INFO Connected all rings
176: hkn0525:971975:972098 [0] NCCL INFO Channel 00 : 176[31000] -> 177[4b000] via P2P/IPC/read
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 00 : 188[31000] -> 189[4b000] via P2P/IPC/read
277: hkn0621:1976619:1976745 [1] NCCL INFO Channel 00 : 277[4b000] -> 278[ca000] via P2P/IPC/read
413: hkn0724:1701132:1701247 [1] NCCL INFO Connected all rings
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 00 : 148[31000] -> 149[4b000] via P2P/IPC/read
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 01 : 468[31000] -> 469[4b000] via P2P/IPC/read
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 00 : 45[4b000] -> 46[ca000] via P2P/IPC/read
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 00 : 192[31000] -> 193[4b000] via P2P/IPC/read
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 00 : 48[31000] -> 49[4b000] via P2P/IPC/read
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 00 : 445[4b000] -> 446[ca000] via P2P/IPC/read
342: hkn0704:777150:777271 [2] NCCL INFO Connected all rings
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 01 : 28[31000] -> 29[4b000] via P2P/IPC/read
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 00 : 60[31000] -> 61[4b000] via P2P/IPC/read
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 00 : 429[4b000] -> 430[ca000] via P2P/IPC/read
496: hkn0812:678913:679036 [0] NCCL INFO Channel 01 : 496[31000] -> 497[4b000] via P2P/IPC/read
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 00 : 397[4b000] -> 398[ca000] via P2P/IPC/read
 90: hkn0427:1120345:1120439 [2] NCCL INFO Connected all rings
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 01 : 392[31000] -> 393[4b000] via P2P/IPC/read
368: hkn0712:280251:280359 [0] NCCL INFO Channel 00 : 368[31000] -> 369[4b000] via P2P/IPC/read
302: hkn0628:656986:657104 [2] NCCL INFO Connected all rings
108: hkn0504:25965:26094 [0] NCCL INFO Channel 00 : 108[31000] -> 109[4b000] via P2P/IPC/read
229: hkn0604:674466:674561 [1] NCCL INFO Channel 00 : 229[4b000] -> 230[ca000] via P2P/IPC/read
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 01 : 220[31000] -> 221[4b000] via P2P/IPC/read
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 01 : 32[31000] -> 33[4b000] via P2P/IPC/read
260: hkn0613:887844:887968 [0] NCCL INFO Channel 00 : 260[31000] -> 261[4b000] via P2P/IPC/read
256: hkn0612:902120:902251 [0] NCCL INFO Channel 01 : 256[31000] -> 257[4b000] via P2P/IPC/read
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 00 : 104[31000] -> 105[4b000] via P2P/IPC/read
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 01 : 140[31000] -> 141[4b000] via P2P/IPC/read
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 01 : 132[31000] -> 133[4b000] via P2P/IPC/read
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 01 : 172[31000] -> 173[4b000] via P2P/IPC/read
437: hkn0731:1371908:1372021 [1] NCCL INFO Channel 00 : 437[4b000] -> 438[ca000] via P2P/IPC/read
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 01 : 388[31000] -> 389[4b000] via P2P/IPC/read
110: hkn0504:25993:26089 [2] NCCL INFO Connected all rings
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 01 : 40[31000] -> 41[4b000] via P2P/IPC/read
310: hkn0630:1583644:1583757 [2] NCCL INFO Connected all rings
213: hkn0535:2384189:2384302 [1] NCCL INFO Connected all rings
116: hkn0506:823193:823308 [0] NCCL INFO Channel 00 : 116[31000] -> 117[4b000] via P2P/IPC/read
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 00 : 288[31000] -> 289[4b000] via P2P/IPC/read
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 00 : 401[4b000] -> 402[ca000] via P2P/IPC/read
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via P2P/IPC/read
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 01 : 432[31000] -> 433[4b000] via P2P/IPC/read
340: hkn0704:777158:777265 [0] NCCL INFO Channel 00 : 340[31000] -> 341[4b000] via P2P/IPC/read
489: hkn0809:922561:922677 [1] NCCL INFO Channel 00 : 489[4b000] -> 490[ca000] via P2P/IPC/read
 38: hkn0413:2351846:2351938 [2] NCCL INFO Channel 00 : 38[ca000] -> 39[e3000] via P2P/IPC/read
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 01 : 24[31000] -> 25[4b000] via P2P/IPC/read
438: hkn0731:1371892:1372022 [2] NCCL INFO Channel 00 : 438[ca000] -> 439[e3000] via P2P/IPC/read
362: hkn0710:340630:340740 [2] NCCL INFO Connected all rings
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 01 : 452[31000] -> 453[4b000] via P2P/IPC/read
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 00 : 225[4b000] -> 226[ca000] via P2P/IPC/read
 10: hkn0405:3191876:3192004 [2] NCCL INFO Connected all rings
300: hkn0628:656995:657105 [0] NCCL INFO Channel 00 : 300[31000] -> 301[4b000] via P2P/IPC/read
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 00 : 461[4b000] -> 462[ca000] via P2P/IPC/read
418: hkn0725:3097089:3097197 [2] NCCL INFO Connected all rings
252: hkn0611:694973:695080 [0] NCCL INFO Connected all rings
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 00 : 441[4b000] -> 442[ca000] via P2P/IPC/read
376: hkn0714:417195:417320 [0] NCCL INFO Channel 00 : 376[31000] -> 377[4b000] via P2P/IPC/read
464: hkn0803:861669:861771 [0] NCCL INFO Channel 01 : 464[31000] -> 465[4b000] via P2P/IPC/read
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 01 : 68[31000] -> 69[4b000] via P2P/IPC/read
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 00 : 320[31000] -> 321[4b000] via P2P/IPC/read
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 01 : 272[31000] -> 273[4b000] via P2P/IPC/read
193: hkn0529:1526023:1526124 [1] NCCL INFO Connected all rings
482: hkn0807:1004292:1004392 [2] NCCL INFO Channel 00 : 482[ca000] -> 483[e3000] via P2P/IPC/read
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 00 : 156[31000] -> 157[4b000] via P2P/IPC/read
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 00 : 308[31000] -> 309[4b000] via P2P/IPC/read
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 01 : 164[31000] -> 165[4b000] via P2P/IPC/read
384: hkn0716:93645:93760 [0] NCCL INFO Channel 00 : 384[31000] -> 385[4b000] via P2P/IPC/read
378: hkn0714:417196:417322 [2] NCCL INFO Connected all rings
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 00 : 44[31000] -> 45[4b000] via P2P/IPC/read
485: hkn0808:955879:955981 [1] NCCL INFO Channel 00 : 485[4b000] -> 486[ca000] via P2P/IPC/read
102: hkn0502:214204:214346 [2] NCCL INFO Connected all rings
330: hkn0635:1210755:1210867 [2] NCCL INFO Connected all rings
398: hkn0719:1290848:1290952 [2] NCCL INFO Channel 00 : 398[ca000] -> 399[e3000] via P2P/IPC/read
124: hkn0508:3124325:3124404 [0] NCCL INFO Connected all rings
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 00 : 8[31000] -> 9[4b000] via P2P/IPC/read
114: hkn0505:2288957:2289067 [2] NCCL INFO Connected all rings
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 01 : 52[31000] -> 53[4b000] via P2P/IPC/read
190: hkn0528:1286863:1286971 [2] NCCL INFO Channel 00 : 190[ca000] -> 191[e3000] via P2P/IPC/read
469: hkn0804:1190775:1190890 [1] NCCL INFO Channel 00 : 469[4b000] -> 470[ca000] via P2P/IPC/read
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 01 : 200[31000] -> 201[4b000] via P2P/IPC/read
205: hkn0532:908774:909097 [1] NCCL INFO Channel 00 : 205[4b000] -> 206[ca000] via P2P/IPC/read
 37: hkn0413:2351826:2351942 [1] NCCL INFO Channel 01 : 37[4b000] -> 38[ca000] via P2P/IPC/read
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 00 : 25[4b000] -> 26[ca000] via P2P/IPC/read
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 01 : 168[31000] -> 169[4b000] via P2P/IPC/read
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 00 : 473[4b000] -> 474[ca000] via P2P/IPC/read
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 00 : 449[4b000] -> 450[ca000] via P2P/IPC/read
344: hkn0705:768421:768521 [0] NCCL INFO Channel 01 : 344[31000] -> 345[4b000] via P2P/IPC/read
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 00 : 416[31000] -> 417[4b000] via P2P/IPC/read
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 01 : 144[31000] -> 145[4b000] via P2P/IPC/read
100: hkn0502:214212:214345 [0] NCCL INFO Channel 00 : 100[31000] -> 101[4b000] via P2P/IPC/read
278: hkn0621:1976647:1976747 [2] NCCL INFO Channel 00 : 278[ca000] -> 279[e3000] via P2P/IPC/read
 84: hkn0426:799238:799364 [0] NCCL INFO Connected all rings
497: hkn0812:678921:679031 [1] NCCL INFO Channel 00 : 497[4b000] -> 498[ca000] via P2P/IPC/read
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 00 : 88[31000] -> 89[4b000] via P2P/IPC/read
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 00 : 129[4b000] -> 130[ca000] via P2P/IPC/read
264: hkn0615:399427:399550 [0] NCCL INFO Channel 01 : 264[31000] -> 265[4b000] via P2P/IPC/read
408: hkn0723:192917:193087 [0] NCCL INFO Channel 01 : 408[31000] -> 409[4b000] via P2P/IPC/read
462: hkn0802:1185507:1185616 [2] NCCL INFO Channel 00 : 462[ca000] -> 463[e3000] via P2P/IPC/read
245: hkn0608:470935:471034 [1] NCCL INFO Channel 00 : 245[4b000] -> 246[ca000] via P2P/IPC/read
 18: hkn0408:2875808:2875934 [2] NCCL INFO Connected all rings
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 00 : 112[31000] -> 113[4b000] via P2P/IPC/read
442: hkn0732:1196803:1196961 [2] NCCL INFO Channel 00 : 442[ca000] -> 443[e3000] via P2P/IPC/read
265: hkn0615:399447:399552 [1] NCCL INFO Channel 00 : 265[4b000] -> 266[ca000] via P2P/IPC/read
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 01 : 316[31000] -> 317[4b000] via P2P/IPC/read
430: hkn0728:1309110:1309210 [2] NCCL INFO Channel 00 : 430[ca000] -> 431[e3000] via P2P/IPC/read
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 01 : 481[4b000] -> 482[ca000] via P2P/IPC/read
234: hkn0605:697234:697394 [2] NCCL INFO Channel 01 : 234[ca000] -> 235[e3000] via P2P/IPC/read
405: hkn0721:2284159:2284270 [1] NCCL INFO Channel 00 : 405[4b000] -> 406[ca000] via P2P/IPC/read
230: hkn0604:674446:674565 [2] NCCL INFO Channel 00 : 230[ca000] -> 231[e3000] via P2P/IPC/read
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 00 : 237[4b000] -> 238[ca000] via P2P/IPC/read
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 01 : 296[31000] -> 297[4b000] via P2P/IPC/read
277: hkn0621:1976619:1976745 [1] NCCL INFO Channel 01 : 277[4b000] -> 278[ca000] via P2P/IPC/read
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 01 : 420[31000] -> 421[4b000] via P2P/IPC/read
337: hkn0703:726148:726258 [1] NCCL INFO Channel 00 : 337[4b000] -> 338[ca000] via P2P/IPC/read
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 00 : 16[31000] -> 17[4b000] via P2P/IPC/read
321: hkn0633:1511514:1511639 [1] NCCL INFO Connected all rings
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 01 : 189[4b000] -> 190[ca000] via P2P/IPC/read
446: hkn0733:1374549:1374669 [2] NCCL INFO Channel 00 : 446[ca000] -> 447[e3000] via P2P/IPC/read
486: hkn0808:955867:955976 [2] NCCL INFO Channel 00 : 486[ca000] -> 487[e3000] via P2P/IPC/read
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 00 : 332[31000] -> 333[4b000] via P2P/IPC/read
 86: hkn0426:799246:799367 [2] NCCL INFO Connected all rings
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 01 : 4[31000] -> 5[4b000] via P2P/IPC/read
328: hkn0635:1210747:1210870 [0] NCCL INFO Connected all rings
509: hkn0816:360808:360905 [1] NCCL INFO Connected all rings
336: hkn0703:726160:726259 [0] NCCL INFO Connected all rings
360: hkn0710:340644:340742 [0] NCCL INFO Channel 00 : 360[31000] -> 361[4b000] via P2P/IPC/read
492: hkn0810:924748:924846 [0] NCCL INFO Channel 01 : 492[31000] -> 493[4b000] via P2P/IPC/read
490: hkn0809:922569:922682 [2] NCCL INFO Channel 00 : 490[ca000] -> 491[e3000] via P2P/IPC/read
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 01 : 456[31000] -> 457[4b000] via P2P/IPC/read
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 00 : 477[4b000] -> 478[ca000] via P2P/IPC/read
284: hkn0623:1857870:1858027 [0] NCCL INFO Connected all rings
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 01 : 429[4b000] -> 430[ca000] via P2P/IPC/read
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 01 : 445[4b000] -> 446[ca000] via P2P/IPC/read
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 01 : 397[4b000] -> 398[ca000] via P2P/IPC/read
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 00 : 424[31000] -> 425[4b000] via P2P/IPC/read
226: hkn0603:1398315:1398422 [2] NCCL INFO Channel 00 : 226[ca000] -> 227[e3000] via P2P/IPC/read
253: hkn0611:694985:695081 [1] NCCL INFO Channel 00 : 253[4b000] -> 254[ca000] via P2P/IPC/read
229: hkn0604:674466:674561 [1] NCCL INFO Channel 01 : 229[4b000] -> 230[ca000] via P2P/IPC/read
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 00 : 173[4b000] -> 174[ca000] via P2P/IPC/read
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 01 : 136[31000] -> 137[4b000] via P2P/IPC/read
349: hkn0706:737463:737570 [1] NCCL INFO Connected all rings
372: hkn0713:455428:455539 [0] NCCL INFO Channel 00 : 372[31000] -> 373[4b000] via P2P/IPC/read
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 00 : 393[4b000] -> 394[ca000] via P2P/IPC/read
121: hkn0507:3172216:3172329 [1] NCCL INFO Connected all rings
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 00 : 317[4b000] -> 318[ca000] via P2P/IPC/read
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 01 : 64[31000] -> 65[4b000] via P2P/IPC/read
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 01 : 304[31000] -> 305[4b000] via P2P/IPC/read
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 00 : 29[4b000] -> 30[ca000] via P2P/IPC/read
 81: hkn0425:2069090:2069201 [1] NCCL INFO Connected all rings
165: hkn0521:1182962:1183092 [1] NCCL INFO Channel 00 : 165[4b000] -> 166[ca000] via P2P/IPC/read
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 00 : 141[4b000] -> 142[ca000] via P2P/IPC/read
241: hkn0607:889514:889633 [1] NCCL INFO Channel 00 : 241[4b000] -> 242[ca000] via P2P/IPC/read
402: hkn0720:4181548:4181824 [2] NCCL INFO Channel 00 : 402[ca000] -> 403[e3000] via P2P/IPC/read
504: hkn0815:380357:380455 [0] NCCL INFO Connected all rings
385: hkn0716:93646:93761 [1] NCCL INFO Channel 00 : 385[4b000] -> 386[ca000] via P2P/IPC/read
470: hkn0804:1190787:1190892 [2] NCCL INFO Channel 00 : 470[ca000] -> 471[e3000] via P2P/IPC/read
206: hkn0532:908802:909093 [2] NCCL INFO Channel 00 : 206[ca000] -> 207[e3000] via P2P/IPC/read
489: hkn0809:922561:922677 [1] NCCL INFO Channel 01 : 489[4b000] -> 490[ca000] via P2P/IPC/read
 46: hkn0415:2481504:2481617 [2] NCCL INFO Channel 00 : 46[ca000] -> 47[e3000] via P2P/IPC/read
478: hkn0806:1039513:1039607 [2] NCCL INFO Channel 00 : 478[ca000] -> 479[e3000] via P2P/IPC/read
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 00 : 273[4b000] -> 274[ca000] via P2P/IPC/read
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 01 : 188[31000] -> 189[4b000] via P2P/IPC/read
437: hkn0731:1371908:1372021 [1] NCCL INFO Channel 01 : 437[4b000] -> 438[ca000] via P2P/IPC/read
498: hkn0812:678929:679040 [2] NCCL INFO Channel 00 : 498[ca000] -> 499[e3000] via P2P/IPC/read
373: hkn0713:455427:455540 [1] NCCL INFO Channel 00 : 373[4b000] -> 374[ca000] via P2P/IPC/read
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 01 : 12[31000] -> 13[4b000] via P2P/IPC/read
364: hkn0711:569026:569156 [0] NCCL INFO Channel 01 : 364[31000] -> 365[4b000] via P2P/IPC/read
474: hkn0805:1097271:1097381 [2] NCCL INFO Channel 00 : 474[ca000] -> 475[e3000] via P2P/IPC/read
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 01 : 160[31000] -> 161[4b000] via P2P/IPC/read
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 01 : 225[4b000] -> 226[ca000] via P2P/IPC/read
130: hkn0509:3109548:3109677 [2] NCCL INFO Channel 00 : 130[ca000] -> 131[e3000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO Channel 00 : 216[31000] -> 217[4b000] via P2P/IPC/read
324: hkn0634:1506032:1506151 [0] NCCL INFO Connected all rings
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 00 : 72[31000] -> 73[4b000] via P2P/IPC/read
246: hkn0608:470915:471032 [2] NCCL INFO Channel 00 : 246[ca000] -> 247[e3000] via P2P/IPC/read
257: hkn0612:902128:902247 [1] NCCL INFO Channel 00 : 257[4b000] -> 258[ca000] via P2P/IPC/read
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 01 : 152[31000] -> 153[4b000] via P2P/IPC/read
133: hkn0510:2747236:2747343 [1] NCCL INFO Channel 00 : 133[4b000] -> 134[ca000] via P2P/IPC/read
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 00 : 289[4b000] -> 290[ca000] via P2P/IPC/read
197: hkn0530:1243325:1243432 [1] NCCL INFO Channel 00 : 197[4b000] -> 198[ca000] via P2P/IPC/read
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 01 : 401[4b000] -> 402[ca000] via P2P/IPC/read
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 01 : 461[4b000] -> 462[ca000] via P2P/IPC/read
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 01 : 208[31000] -> 209[4b000] via P2P/IPC/read
389: hkn0717:4172715:4172825 [1] NCCL INFO Channel 00 : 389[4b000] -> 390[ca000] via P2P/IPC/read
357: hkn0708:398436:398520 [1] NCCL INFO Connected all rings
268: hkn0616:389997:390101 [0] NCCL INFO Channel 01 : 268[31000] -> 269[4b000] via P2P/IPC/read
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 00 : 292[31000] -> 293[4b000] via P2P/IPC/read
 53: hkn0418:1854353:1854450 [1] NCCL INFO Channel 00 : 53[4b000] -> 54[ca000] via P2P/IPC/read
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 00 : 33[4b000] -> 34[ca000] via P2P/IPC/read
 94: hkn0428:652525:652632 [2] NCCL INFO Connected all rings
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 01 : 180[31000] -> 181[4b000] via P2P/IPC/read
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 01 : 441[4b000] -> 442[ca000] via P2P/IPC/read
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 00 : 433[4b000] -> 434[ca000] via P2P/IPC/read
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 01 : 352[31000] -> 353[4b000] via P2P/IPC/read
453: hkn0736:1493549:1493641 [1] NCCL INFO Channel 00 : 453[4b000] -> 454[ca000] via P2P/IPC/read
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 01 : 20[31000] -> 21[4b000] via P2P/IPC/read
314: hkn0631:1006951:1007072 [2] NCCL INFO Connected all rings
294: hkn0626:1283606:1283705 [2] NCCL INFO Connected all rings
286: hkn0623:1857878:1858024 [2] NCCL INFO Connected all rings
 98: hkn0501:1312966:1313101 [2] NCCL INFO Connected all rings
 78: hkn0424:2933089:2933240 [2] NCCL INFO Connected all rings
485: hkn0808:955879:955981 [1] NCCL INFO Channel 01 : 485[4b000] -> 486[ca000] via P2P/IPC/read
108: hkn0504:25965:26094 [0] NCCL INFO Channel 01 : 108[31000] -> 109[4b000] via P2P/IPC/read
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 01 : 45[4b000] -> 46[ca000] via P2P/IPC/read
 58: hkn0419:1529472:1529584 [2] NCCL INFO Connected all rings
176: hkn0525:971975:972098 [0] NCCL INFO Channel 01 : 176[31000] -> 177[4b000] via P2P/IPC/read
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 01 : 60[31000] -> 61[4b000] via P2P/IPC/read
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 01 : 48[31000] -> 49[4b000] via P2P/IPC/read
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 00 : 196[31000] -> 197[4b000] via P2P/IPC/read
414: hkn0724:1701124:1701254 [2] NCCL INFO Connected all rings
450: hkn0734:1141720:1141848 [2] NCCL INFO Channel 00 : 450[ca000] -> 451[e3000] via P2P/IPC/read
 41: hkn0414:1966724:1966822 [1] NCCL INFO Connected all rings
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 01 : 148[31000] -> 149[4b000] via P2P/IPC/read
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 00 : 125[4b000] -> 126[ca000] via P2P/IPC/read
438: hkn0731:1371892:1372022 [2] NCCL INFO Channel 01 : 438[ca000] -> 439[e3000] via P2P/IPC/read
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 00 : 312[31000] -> 313[4b000] via P2P/IPC/read
 26: hkn0410:1144773:1144892 [2] NCCL INFO Channel 00 : 26[ca000] -> 27[e3000] via P2P/IPC/read
281: hkn0622:2005573:2005694 [1] NCCL INFO Connected all rings
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 01 : 104[31000] -> 105[4b000] via P2P/IPC/read
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 00 : 412[31000] -> 413[4b000] via P2P/IPC/read
260: hkn0613:887844:887968 [0] NCCL INFO Channel 01 : 260[31000] -> 261[4b000] via P2P/IPC/read
266: hkn0615:399419:399548 [2] NCCL INFO Channel 00 : 266[ca000] -> 267[e3000] via P2P/IPC/read
318: hkn0632:1743760:1743909 [2] NCCL INFO Channel 00 : 318[ca000] -> 319[e3000] via P2P/IPC/read
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 00 : 56[31000] -> 57[4b000] via P2P/IPC/read
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 00 : 297[4b000] -> 298[ca000] via P2P/IPC/read
142: hkn0512:3029322:3029415 [2] NCCL INFO Channel 00 : 142[ca000] -> 143[e3000] via P2P/IPC/read
242: hkn0607:889522:889635 [2] NCCL INFO Channel 00 : 242[ca000] -> 243[e3000] via P2P/IPC/read
505: hkn0815:380329:380451 [1] NCCL INFO Connected all rings
469: hkn0804:1190775:1190890 [1] NCCL INFO Channel 01 : 469[4b000] -> 470[ca000] via P2P/IPC/read
205: hkn0532:908774:909097 [1] NCCL INFO Channel 01 : 205[4b000] -> 206[ca000] via P2P/IPC/read
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 01 : 449[4b000] -> 450[ca000] via P2P/IPC/read
217: hkn0601:102836:102938 [1] NCCL INFO Channel 00 : 217[4b000] -> 218[ca000] via P2P/IPC/read
 38: hkn0413:2351846:2351938 [2] NCCL INFO Channel 01 : 38[ca000] -> 39[e3000] via P2P/IPC/read
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 01 : 25[4b000] -> 26[ca000] via P2P/IPC/read
116: hkn0506:823193:823308 [0] NCCL INFO Channel 01 : 116[31000] -> 117[4b000] via P2P/IPC/read
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 00 : 96[31000] -> 97[4b000] via P2P/IPC/read
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 00 : 76[31000] -> 77[4b000] via P2P/IPC/read
409: hkn0723:192925:193085 [1] NCCL INFO Channel 00 : 409[4b000] -> 410[ca000] via P2P/IPC/read
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 01 : 473[4b000] -> 474[ca000] via P2P/IPC/read
345: hkn0705:768401:768516 [1] NCCL INFO Channel 00 : 345[4b000] -> 346[ca000] via P2P/IPC/read
406: hkn0721:2284171:2284267 [2] NCCL INFO Channel 00 : 406[ca000] -> 407[e3000] via P2P/IPC/read
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 01 : 129[4b000] -> 130[ca000] via P2P/IPC/read
245: hkn0608:470935:471034 [1] NCCL INFO Channel 01 : 245[4b000] -> 246[ca000] via P2P/IPC/read
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 00 : 221[4b000] -> 222[ca000] via P2P/IPC/read
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 01 : 44[31000] -> 45[4b000] via P2P/IPC/read
238: hkn0606:2357175:2357324 [2] NCCL INFO Channel 00 : 238[ca000] -> 239[e3000] via P2P/IPC/read
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 01 : 288[31000] -> 289[4b000] via P2P/IPC/read
185: hkn0527:1334057:1334167 [1] NCCL INFO Connected all rings
497: hkn0812:678921:679031 [1] NCCL INFO Channel 01 : 497[4b000] -> 498[ca000] via P2P/IPC/read
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via P2P/IPC/read
340: hkn0704:777158:777265 [0] NCCL INFO Channel 01 : 340[31000] -> 341[4b000] via P2P/IPC/read
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 00 : 353[4b000] -> 354[ca000] via P2P/IPC/read
382: hkn0715:387104:387217 [2] NCCL INFO Connected all rings
300: hkn0628:656995:657105 [0] NCCL INFO Channel 01 : 300[31000] -> 301[4b000] via P2P/IPC/read
265: hkn0615:399447:399552 [1] NCCL INFO Channel 01 : 265[4b000] -> 266[ca000] via P2P/IPC/read
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 00 : 201[4b000] -> 202[ca000] via P2P/IPC/read
434: hkn0730:1386902:1387024 [2] NCCL INFO Channel 00 : 434[ca000] -> 435[e3000] via P2P/IPC/read
482: hkn0807:1004292:1004392 [2] NCCL INFO Channel 01 : 482[ca000] -> 483[e3000] via P2P/IPC/read
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 00 : 145[4b000] -> 146[ca000] via P2P/IPC/read
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 00 : 305[4b000] -> 306[ca000] via P2P/IPC/read
222: hkn0602:3345207:3345482 [2] NCCL INFO Channel 00 : 222[ca000] -> 223[e3000] via P2P/IPC/read
 34: hkn0412:2247554:2247673 [2] NCCL INFO Channel 00 : 34[ca000] -> 35[e3000] via P2P/IPC/read
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 01 : 237[4b000] -> 238[ca000] via P2P/IPC/read
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 00 : 92[31000] -> 93[4b000] via P2P/IPC/read
501: hkn0814:661009:661108 [1] NCCL INFO Connected all rings
376: hkn0714:417195:417320 [0] NCCL INFO Channel 01 : 376[31000] -> 377[4b000] via P2P/IPC/read
465: hkn0803:861667:861779 [1] NCCL INFO Channel 00 : 465[4b000] -> 466[ca000] via P2P/IPC/read
405: hkn0721:2284159:2284270 [1] NCCL INFO Channel 01 : 405[4b000] -> 406[ca000] via P2P/IPC/read
394: hkn0718:3902173:3902289 [2] NCCL INFO Channel 00 : 394[ca000] -> 395[e3000] via P2P/IPC/read
325: hkn0634:1506024:1506157 [1] NCCL INFO Connected all rings
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 01 : 156[31000] -> 157[4b000] via P2P/IPC/read
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 01 : 308[31000] -> 309[4b000] via P2P/IPC/read
384: hkn0716:93645:93760 [0] NCCL INFO Channel 01 : 384[31000] -> 385[4b000] via P2P/IPC/read
380: hkn0715:387124:387215 [0] NCCL INFO Channel 00 : 380[31000] -> 381[4b000] via P2P/IPC/read
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 01 : 8[31000] -> 9[4b000] via P2P/IPC/read
274: hkn0617:2279774:2279896 [2] NCCL INFO Channel 00 : 274[ca000] -> 275[e3000] via P2P/IPC/read
174: hkn0524:1118942:1119055 [2] NCCL INFO Channel 00 : 174[ca000] -> 175[e3000] via P2P/IPC/read
  5: hkn0404:1324527:1324632 [1] NCCL INFO Channel 00 : 5[4b000] -> 6[ca000] via P2P/IPC/read
398: hkn0719:1290848:1290952 [2] NCCL INFO Channel 01 : 398[ca000] -> 399[e3000] via P2P/IPC/read
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 00 : 65[4b000] -> 66[ca000] via P2P/IPC/read
166: hkn0521:1182970:1183090 [2] NCCL INFO Channel 00 : 166[ca000] -> 167[e3000] via P2P/IPC/read
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 00 : 169[4b000] -> 170[ca000] via P2P/IPC/read
 21: hkn0409:2570850:2570977 [1] NCCL INFO Channel 00 : 21[4b000] -> 22[ca000] via P2P/IPC/read
 30: hkn0411:2301012:2301139 [2] NCCL INFO Channel 00 : 30[ca000] -> 31[e3000] via P2P/IPC/read
249: hkn0609:696028:696150 [1] NCCL INFO Connected all rings
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 01 : 477[4b000] -> 478[ca000] via P2P/IPC/read
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 00 : 105[4b000] -> 106[ca000] via P2P/IPC/read
134: hkn0510:2747248:2747351 [2] NCCL INFO Channel 00 : 134[ca000] -> 135[e3000] via P2P/IPC/read
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 01 : 173[4b000] -> 174[ca000] via P2P/IPC/read
338: hkn0703:726147:726262 [2] NCCL INFO Channel 00 : 338[ca000] -> 339[e3000] via P2P/IPC/read
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 01 : 393[4b000] -> 394[ca000] via P2P/IPC/read
252: hkn0611:694973:695080 [0] NCCL INFO Channel 00 : 252[31000] -> 253[4b000] via P2P/IPC/read
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 01 : 317[4b000] -> 318[ca000] via P2P/IPC/read
258: hkn0612:902136:902248 [2] NCCL INFO Channel 00 : 258[ca000] -> 259[e3000] via P2P/IPC/read
165: hkn0521:1182962:1183092 [1] NCCL INFO Channel 01 : 165[4b000] -> 166[ca000] via P2P/IPC/read
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 00 : 61[4b000] -> 62[ca000] via P2P/IPC/read
493: hkn0810:924720:924850 [1] NCCL INFO Channel 00 : 493[4b000] -> 494[ca000] via P2P/IPC/read
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 00 : 73[4b000] -> 74[ca000] via P2P/IPC/read
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 01 : 29[4b000] -> 30[ca000] via P2P/IPC/read
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 01 : 273[4b000] -> 274[ca000] via P2P/IPC/read
190: hkn0528:1286863:1286971 [2] NCCL INFO Channel 01 : 190[ca000] -> 191[e3000] via P2P/IPC/read
117: hkn0506:823185:823311 [1] NCCL INFO Channel 00 : 117[4b000] -> 118[ca000] via P2P/IPC/read
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 01 : 141[4b000] -> 142[ca000] via P2P/IPC/read
241: hkn0607:889514:889633 [1] NCCL INFO Channel 01 : 241[4b000] -> 242[ca000] via P2P/IPC/read
346: hkn0705:768409:768518 [2] NCCL INFO Channel 00 : 346[ca000] -> 347[e3000] via P2P/IPC/read
 54: hkn0418:1854325:1854445 [2] NCCL INFO Channel 00 : 54[ca000] -> 55[e3000] via P2P/IPC/read
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 00 : 153[4b000] -> 154[ca000] via P2P/IPC/read
386: hkn0716:93666:93764 [2] NCCL INFO Channel 00 : 386[ca000] -> 387[e3000] via P2P/IPC/read
365: hkn0711:569034:569157 [1] NCCL INFO Channel 00 : 365[4b000] -> 366[ca000] via P2P/IPC/read
389: hkn0717:4172715:4172825 [1] NCCL INFO Channel 01 : 389[4b000] -> 390[ca000] via P2P/IPC/read
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 00 : 161[4b000] -> 162[ca000] via P2P/IPC/read
356: hkn0708:398416:398525 [0] NCCL INFO Channel 00 : 356[31000] -> 357[4b000] via P2P/IPC/read
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 01 : 112[31000] -> 113[4b000] via P2P/IPC/read
257: hkn0612:902128:902247 [1] NCCL INFO Channel 01 : 257[4b000] -> 258[ca000] via P2P/IPC/read
478: hkn0806:1039513:1039607 [2] NCCL INFO Channel 01 : 478[ca000] -> 479[e3000] via P2P/IPC/read
133: hkn0510:2747236:2747343 [1] NCCL INFO Channel 01 : 133[4b000] -> 134[ca000] via P2P/IPC/read
290: hkn0624:1758086:1758202 [2] NCCL INFO Channel 00 : 290[ca000] -> 291[e3000] via P2P/IPC/read
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 00 : 137[4b000] -> 138[ca000] via P2P/IPC/read
442: hkn0732:1196803:1196961 [2] NCCL INFO Channel 01 : 442[ca000] -> 443[e3000] via P2P/IPC/read
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 00 : 13[4b000] -> 14[ca000] via P2P/IPC/read
462: hkn0802:1185507:1185616 [2] NCCL INFO Channel 01 : 462[ca000] -> 463[e3000] via P2P/IPC/read
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 01 : 88[31000] -> 89[4b000] via P2P/IPC/read
390: hkn0717:4172695:4172824 [2] NCCL INFO Channel 00 : 390[ca000] -> 391[e3000] via P2P/IPC/read
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 01 : 416[31000] -> 417[4b000] via P2P/IPC/read
454: hkn0736:1493528:1493648 [2] NCCL INFO Channel 00 : 454[ca000] -> 455[e3000] via P2P/IPC/read
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 00 : 120[31000] -> 121[4b000] via P2P/IPC/read
146: hkn0513:2998110:2998204 [2] NCCL INFO Channel 00 : 146[ca000] -> 147[e3000] via P2P/IPC/read
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 00 : 457[4b000] -> 458[ca000] via P2P/IPC/read
100: hkn0502:214212:214345 [0] NCCL INFO Channel 01 : 100[31000] -> 101[4b000] via P2P/IPC/read
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 01 : 33[4b000] -> 34[ca000] via P2P/IPC/read
214: hkn0535:2384181:2384305 [2] NCCL INFO Connected all rings
278: hkn0621:1976647:1976747 [2] NCCL INFO Channel 01 : 278[ca000] -> 279[e3000] via P2P/IPC/read
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 00 : 124[31000] -> 125[4b000] via P2P/IPC/read
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 01 : 433[4b000] -> 434[ca000] via P2P/IPC/read
466: hkn0803:861668:861780 [2] NCCL INFO Channel 00 : 466[ca000] -> 467[e3000] via P2P/IPC/read
453: hkn0736:1493549:1493641 [1] NCCL INFO Channel 01 : 453[4b000] -> 454[ca000] via P2P/IPC/read
254: hkn0611:694965:695087 [2] NCCL INFO Channel 00 : 254[ca000] -> 255[e3000] via P2P/IPC/read
 53: hkn0418:1854353:1854450 [1] NCCL INFO Channel 01 : 53[4b000] -> 54[ca000] via P2P/IPC/read
194: hkn0529:1526011:1526128 [2] NCCL INFO Connected all rings
337: hkn0703:726148:726258 [1] NCCL INFO Channel 01 : 337[4b000] -> 338[ca000] via P2P/IPC/read
385: hkn0716:93646:93761 [1] NCCL INFO Channel 01 : 385[4b000] -> 386[ca000] via P2P/IPC/read
486: hkn0808:955867:955976 [2] NCCL INFO Channel 01 : 486[ca000] -> 487[e3000] via P2P/IPC/read
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 01 : 16[31000] -> 17[4b000] via P2P/IPC/read
298: hkn0627:1773054:1773175 [2] NCCL INFO Channel 00 : 298[ca000] -> 299[e3000] via P2P/IPC/read
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 00 : 212[31000] -> 213[4b000] via P2P/IPC/read
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 01 : 289[4b000] -> 290[ca000] via P2P/IPC/read
  6: hkn0404:1324539:1324635 [2] NCCL INFO Channel 00 : 6[ca000] -> 7[e3000] via P2P/IPC/read
336: hkn0703:726160:726259 [0] NCCL INFO Channel 00 : 336[31000] -> 337[4b000] via P2P/IPC/read
374: hkn0713:455429:455542 [2] NCCL INFO Channel 00 : 374[ca000] -> 375[e3000] via P2P/IPC/read
177: hkn0525:971991:972103 [1] NCCL INFO Channel 00 : 177[4b000] -> 178[ca000] via P2P/IPC/read
181: hkn0526:1413569:1413673 [1] NCCL INFO Channel 00 : 181[4b000] -> 182[ca000] via P2P/IPC/read
410: hkn0723:192937:193090 [2] NCCL INFO Channel 00 : 410[ca000] -> 411[e3000] via P2P/IPC/read
430: hkn0728:1309110:1309210 [2] NCCL INFO Channel 01 : 430[ca000] -> 431[e3000] via P2P/IPC/read
  1: hkn0403:1738685:1739058 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[ca000] via P2P/IPC/read
446: hkn0733:1374549:1374669 [2] NCCL INFO Channel 01 : 446[ca000] -> 447[e3000] via P2P/IPC/read
360: hkn0710:340644:340742 [0] NCCL INFO Channel 01 : 360[31000] -> 361[4b000] via P2P/IPC/read
218: hkn0601:102824:102933 [2] NCCL INFO Channel 00 : 218[ca000] -> 219[e3000] via P2P/IPC/read
230: hkn0604:674446:674565 [2] NCCL INFO Channel 01 : 230[ca000] -> 231[e3000] via P2P/IPC/read
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 00 : 49[4b000] -> 50[ca000] via P2P/IPC/read
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 00 : 328[31000] -> 329[4b000] via P2P/IPC/read
198: hkn0530:1243309:1243429 [2] NCCL INFO Channel 00 : 198[ca000] -> 199[e3000] via P2P/IPC/read
421: hkn0726:1533295:1533418 [1] NCCL INFO Connected all rings
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 01 : 424[31000] -> 425[4b000] via P2P/IPC/read
106: hkn0503:2884805:2884921 [2] NCCL INFO Channel 00 : 106[ca000] -> 107[e3000] via P2P/IPC/read
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 01 : 297[4b000] -> 298[ca000] via P2P/IPC/read
508: hkn0816:360788:360900 [0] NCCL INFO Channel 00 : 508[31000] -> 509[4b000] via P2P/IPC/read
372: hkn0713:455428:455539 [0] NCCL INFO Channel 01 : 372[31000] -> 373[4b000] via P2P/IPC/read
206: hkn0532:908802:909093 [2] NCCL INFO Channel 01 : 206[ca000] -> 207[e3000] via P2P/IPC/read
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 00 : 209[4b000] -> 210[ca000] via P2P/IPC/read
253: hkn0611:694985:695081 [1] NCCL INFO Channel 01 : 253[4b000] -> 254[ca000] via P2P/IPC/read
122: hkn0507:3172208:3172331 [2] NCCL INFO Connected all rings
269: hkn0616:389977:390103 [1] NCCL INFO Channel 00 : 269[4b000] -> 270[ca000] via P2P/IPC/read
202: hkn0531:1215712:1215824 [2] NCCL INFO Channel 00 : 202[ca000] -> 203[e3000] via P2P/IPC/read
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 00 : 84[31000] -> 85[4b000] via P2P/IPC/read
149: hkn0514:2935893:2936011 [1] NCCL INFO Channel 00 : 149[4b000] -> 150[ca000] via P2P/IPC/read
409: hkn0723:192925:193085 [1] NCCL INFO Channel 01 : 409[4b000] -> 410[ca000] via P2P/IPC/read
470: hkn0804:1190787:1190892 [2] NCCL INFO Channel 01 : 470[ca000] -> 471[e3000] via P2P/IPC/read
373: hkn0713:455427:455540 [1] NCCL INFO Channel 01 : 373[4b000] -> 374[ca000] via P2P/IPC/read
354: hkn0707:4005065:4005191 [2] NCCL INFO Channel 00 : 354[ca000] -> 355[e3000] via P2P/IPC/read
474: hkn0805:1097271:1097381 [2] NCCL INFO Channel 01 : 474[ca000] -> 475[e3000] via P2P/IPC/read
345: hkn0705:768401:768516 [1] NCCL INFO Channel 01 : 345[4b000] -> 346[ca000] via P2P/IPC/read
226: hkn0603:1398315:1398422 [2] NCCL INFO Channel 01 : 226[ca000] -> 227[e3000] via P2P/IPC/read
490: hkn0809:922569:922682 [2] NCCL INFO Channel 01 : 490[ca000] -> 491[e3000] via P2P/IPC/read
246: hkn0608:470915:471032 [2] NCCL INFO Channel 01 : 246[ca000] -> 247[e3000] via P2P/IPC/read
306: hkn0629:1577206:1577307 [2] NCCL INFO Channel 00 : 306[ca000] -> 307[e3000] via P2P/IPC/read
 46: hkn0415:2481504:2481617 [2] NCCL INFO Channel 01 : 46[ca000] -> 47[e3000] via P2P/IPC/read
118: hkn0506:823201:823314 [2] NCCL INFO Channel 00 : 118[ca000] -> 119[e3000] via P2P/IPC/read
197: hkn0530:1243325:1243432 [1] NCCL INFO Channel 01 : 197[4b000] -> 198[ca000] via P2P/IPC/read
498: hkn0812:678929:679040 [2] NCCL INFO Channel 01 : 498[ca000] -> 499[e3000] via P2P/IPC/read
348: hkn0706:737455:737573 [0] NCCL INFO Channel 01 : 348[31000] -> 349[4b000] via P2P/IPC/read
341: hkn0704:777142:777272 [1] NCCL INFO Channel 00 : 341[4b000] -> 342[ca000] via P2P/IPC/read
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 00 : 425[4b000] -> 426[ca000] via P2P/IPC/read
366: hkn0711:569042:569160 [2] NCCL INFO Channel 00 : 366[ca000] -> 367[e3000] via P2P/IPC/read
369: hkn0712:280243:280361 [1] NCCL INFO Connected all rings
130: hkn0509:3109548:3109677 [2] NCCL INFO Channel 01 : 130[ca000] -> 131[e3000] via P2P/IPC/read
261: hkn0613:887816:887974 [1] NCCL INFO Channel 00 : 261[4b000] -> 262[ca000] via P2P/IPC/read
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 01 : 72[31000] -> 73[4b000] via P2P/IPC/read
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 01 : 145[4b000] -> 146[ca000] via P2P/IPC/read
458: hkn0801:2225110:2225221 [2] NCCL INFO Channel 00 : 458[ca000] -> 459[e3000] via P2P/IPC/read
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 00 : 157[4b000] -> 158[ca000] via P2P/IPC/read
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 01 : 292[31000] -> 293[4b000] via P2P/IPC/read
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 01 : 221[4b000] -> 222[ca000] via P2P/IPC/read
 69: hkn0422:4138181:4138294 [1] NCCL INFO Connected all rings
 62: hkn0420:3195366:3195465 [2] NCCL INFO Channel 00 : 62[ca000] -> 63[e3000] via P2P/IPC/read
 14: hkn0407:1801449:1801570 [2] NCCL INFO Channel 00 : 14[ca000] -> 15[e3000] via P2P/IPC/read
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 01 : 353[4b000] -> 354[ca000] via P2P/IPC/read
301: hkn0628:657007:657097 [1] NCCL INFO Channel 00 : 301[4b000] -> 302[ca000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO Channel 01 : 216[31000] -> 217[4b000] via P2P/IPC/read
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 01 : 305[4b000] -> 306[ca000] via P2P/IPC/read
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 01 : 201[4b000] -> 202[ca000] via P2P/IPC/read
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 01 : 192[31000] -> 193[4b000] via P2P/IPC/read
170: hkn0523:1533170:1533292 [2] NCCL INFO Channel 00 : 170[ca000] -> 171[e3000] via P2P/IPC/read
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 01 : 196[31000] -> 197[4b000] via P2P/IPC/read
402: hkn0720:4181548:4181824 [2] NCCL INFO Channel 01 : 402[ca000] -> 403[e3000] via P2P/IPC/read
465: hkn0803:861667:861779 [1] NCCL INFO Channel 01 : 465[4b000] -> 466[ca000] via P2P/IPC/read
 22: hkn0409:2570866:2570968 [2] NCCL INFO Channel 00 : 22[ca000] -> 23[e3000] via P2P/IPC/read
 66: hkn0421:2163516:2163782 [2] NCCL INFO Channel 00 : 66[ca000] -> 67[e3000] via P2P/IPC/read
222: hkn0602:3345207:3345482 [2] NCCL INFO Channel 01 : 222[ca000] -> 223[e3000] via P2P/IPC/read
  5: hkn0404:1324527:1324632 [1] NCCL INFO Channel 01 : 5[4b000] -> 6[ca000] via P2P/IPC/read
266: hkn0615:399419:399548 [2] NCCL INFO Channel 01 : 266[ca000] -> 267[e3000] via P2P/IPC/read
126: hkn0508:3124297:3124412 [2] NCCL INFO Channel 00 : 126[ca000] -> 127[e3000] via P2P/IPC/read
510: hkn0816:360796:360907 [2] NCCL INFO Connected all rings
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 01 : 65[4b000] -> 66[ca000] via P2P/IPC/read
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 01 : 169[4b000] -> 170[ca000] via P2P/IPC/read
494: hkn0810:924728:924849 [2] NCCL INFO Channel 00 : 494[ca000] -> 495[e3000] via P2P/IPC/read
377: hkn0714:417216:417317 [1] NCCL INFO Channel 00 : 377[4b000] -> 378[ca000] via P2P/IPC/read
 21: hkn0409:2570850:2570977 [1] NCCL INFO Channel 01 : 21[4b000] -> 22[ca000] via P2P/IPC/read
109: hkn0504:25973:26092 [1] NCCL INFO Channel 00 : 109[4b000] -> 110[ca000] via P2P/IPC/read
154: hkn0515:2881950:2882069 [2] NCCL INFO Channel 00 : 154[ca000] -> 155[e3000] via P2P/IPC/read
322: hkn0633:1511522:1511638 [2] NCCL INFO Connected all rings
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 00 : 284[31000] -> 285[4b000] via P2P/IPC/read
309: hkn0630:1583628:1583756 [1] NCCL INFO Channel 00 : 309[4b000] -> 310[ca000] via P2P/IPC/read
162: hkn0520:2698027:2698123 [2] NCCL INFO Channel 00 : 162[ca000] -> 163[e3000] via P2P/IPC/read
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 00 : 9[4b000] -> 10[ca000] via P2P/IPC/read
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 01 : 312[31000] -> 313[4b000] via P2P/IPC/read
318: hkn0632:1743760:1743909 [2] NCCL INFO Channel 01 : 318[ca000] -> 319[e3000] via P2P/IPC/read
270: hkn0616:389969:390099 [2] NCCL INFO Channel 00 : 270[ca000] -> 271[e3000] via P2P/IPC/read
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 01 : 105[4b000] -> 106[ca000] via P2P/IPC/read
178: hkn0525:972003:972097 [2] NCCL INFO Channel 00 : 178[ca000] -> 179[e3000] via P2P/IPC/read
142: hkn0512:3029322:3029415 [2] NCCL INFO Channel 01 : 142[ca000] -> 143[e3000] via P2P/IPC/read
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 01 : 61[4b000] -> 62[ca000] via P2P/IPC/read
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 01 : 125[4b000] -> 126[ca000] via P2P/IPC/read
138: hkn0511:3051491:3051603 [2] NCCL INFO Channel 00 : 138[ca000] -> 139[e3000] via P2P/IPC/read
350: hkn0706:737475:737567 [2] NCCL INFO Connected all rings
493: hkn0810:924720:924850 [1] NCCL INFO Channel 01 : 493[4b000] -> 494[ca000] via P2P/IPC/read
210: hkn0534:1133593:1133689 [2] NCCL INFO Channel 00 : 210[ca000] -> 211[e3000] via P2P/IPC/read
450: hkn0734:1141720:1141848 [2] NCCL INFO Channel 01 : 450[ca000] -> 451[e3000] via P2P/IPC/read
217: hkn0601:102836:102938 [1] NCCL INFO Channel 01 : 217[4b000] -> 218[ca000] via P2P/IPC/read
 26: hkn0410:1144773:1144892 [2] NCCL INFO Channel 01 : 26[ca000] -> 27[e3000] via P2P/IPC/read
 82: hkn0425:2069118:2069202 [2] NCCL INFO Connected all rings
242: hkn0607:889522:889635 [2] NCCL INFO Channel 01 : 242[ca000] -> 243[e3000] via P2P/IPC/read
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 00 : 89[4b000] -> 90[ca000] via P2P/IPC/read
365: hkn0711:569034:569157 [1] NCCL INFO Channel 01 : 365[4b000] -> 366[ca000] via P2P/IPC/read
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 01 : 280[31000] -> 281[4b000] via P2P/IPC/read
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 01 : 153[4b000] -> 154[ca000] via P2P/IPC/read
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 01 : 56[31000] -> 57[4b000] via P2P/IPC/read
117: hkn0506:823185:823311 [1] NCCL INFO Channel 01 : 117[4b000] -> 118[ca000] via P2P/IPC/read
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 01 : 96[31000] -> 97[4b000] via P2P/IPC/read
506: hkn0815:380337:380459 [2] NCCL INFO Connected all rings
338: hkn0703:726147:726262 [2] NCCL INFO Channel 01 : 338[ca000] -> 339[e3000] via P2P/IPC/read
361: hkn0710:340632:340748 [1] NCCL INFO Channel 00 : 361[4b000] -> 362[ca000] via P2P/IPC/read
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 01 : 412[31000] -> 413[4b000] via P2P/IPC/read
235: hkn0605:697250:697395 [3] NCCL INFO Connected all trees
235: hkn0605:697250:697395 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 01 : 161[4b000] -> 162[ca000] via P2P/IPC/read
 74: hkn0423:1689961:1690083 [2] NCCL INFO Channel 00 : 74[ca000] -> 75[e3000] via P2P/IPC/read
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 01 : 332[31000] -> 333[4b000] via P2P/IPC/read
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 01 : 320[31000] -> 321[4b000] via P2P/IPC/read
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 00 : 184[31000] -> 185[4b000] via P2P/IPC/read
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 01 : 137[4b000] -> 138[ca000] via P2P/IPC/read
  2: hkn0403:1738697:1739060 [2] NCCL INFO Channel 00 : 2[ca000] -> 3[e3000] via P2P/IPC/read
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 01 : 13[4b000] -> 14[ca000] via P2P/IPC/read
235: hkn0605:697250:697395 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 01 : 457[4b000] -> 458[ca000] via P2P/IPC/read
101: hkn0502:214224:214351 [1] NCCL INFO Channel 00 : 101[4b000] -> 102[ca000] via P2P/IPC/read
 34: hkn0412:2247554:2247673 [2] NCCL INFO Channel 01 : 34[ca000] -> 35[e3000] via P2P/IPC/read
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 00 : 80[31000] -> 81[4b000] via P2P/IPC/read
238: hkn0606:2357175:2357324 [2] NCCL INFO Channel 01 : 238[ca000] -> 239[e3000] via P2P/IPC/read
182: hkn0526:1413581:1413675 [2] NCCL INFO Channel 00 : 182[ca000] -> 183[e3000] via P2P/IPC/read
434: hkn0730:1386902:1387024 [2] NCCL INFO Channel 01 : 434[ca000] -> 435[e3000] via P2P/IPC/read
336: hkn0703:726160:726259 [0] NCCL INFO Channel 01 : 336[31000] -> 337[4b000] via P2P/IPC/read
358: hkn0708:398424:398526 [2] NCCL INFO Connected all rings
406: hkn0721:2284171:2284267 [2] NCCL INFO Channel 01 : 406[ca000] -> 407[e3000] via P2P/IPC/read
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 01 : 73[4b000] -> 74[ca000] via P2P/IPC/read
 42: hkn0414:1966704:1966820 [2] NCCL INFO Connected all rings
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 01 : 92[31000] -> 93[4b000] via P2P/IPC/read
186: hkn0527:1334041:1334160 [2] NCCL INFO Connected all rings
380: hkn0715:387124:387215 [0] NCCL INFO Channel 01 : 380[31000] -> 381[4b000] via P2P/IPC/read
252: hkn0611:694973:695080 [0] NCCL INFO Channel 01 : 252[31000] -> 253[4b000] via P2P/IPC/read
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 00 : 113[4b000] -> 114[ca000] via P2P/IPC/read
177: hkn0525:971991:972103 [1] NCCL INFO Channel 01 : 177[4b000] -> 178[ca000] via P2P/IPC/read
500: hkn0814:660997:661104 [0] NCCL INFO Channel 01 : 500[31000] -> 501[4b000] via P2P/IPC/read
  1: hkn0403:1738685:1739058 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[ca000] via P2P/IPC/read
110: hkn0504:25993:26089 [2] NCCL INFO Channel 00 : 110[ca000] -> 111[e3000] via P2P/IPC/read
181: hkn0526:1413569:1413673 [1] NCCL INFO Channel 01 : 181[4b000] -> 182[ca000] via P2P/IPC/read
 50: hkn0417:2252730:2252862 [2] NCCL INFO Channel 00 : 50[ca000] -> 51[e3000] via P2P/IPC/read
150: hkn0514:2935913:2936009 [2] NCCL INFO Channel 00 : 150[ca000] -> 151[e3000] via P2P/IPC/read
262: hkn0613:887824:887976 [2] NCCL INFO Channel 00 : 262[ca000] -> 263[e3000] via P2P/IPC/read
254: hkn0611:694965:695087 [2] NCCL INFO Channel 01 : 254[ca000] -> 255[e3000] via P2P/IPC/read
394: hkn0718:3902173:3902289 [2] NCCL INFO Channel 01 : 394[ca000] -> 395[e3000] via P2P/IPC/read
158: hkn0516:2901144:2901290 [2] NCCL INFO Channel 00 : 158[ca000] -> 159[e3000] via P2P/IPC/read
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 01 : 209[4b000] -> 210[ca000] via P2P/IPC/read
426: hkn0727:1330937:1331047 [2] NCCL INFO Channel 00 : 426[ca000] -> 427[e3000] via P2P/IPC/read
346: hkn0705:768409:768518 [2] NCCL INFO Channel 01 : 346[ca000] -> 347[e3000] via P2P/IPC/read
261: hkn0613:887816:887974 [1] NCCL INFO Channel 01 : 261[4b000] -> 262[ca000] via P2P/IPC/read
342: hkn0704:777150:777271 [2] NCCL INFO Channel 00 : 342[ca000] -> 343[e3000] via P2P/IPC/read
 90: hkn0427:1120345:1120439 [2] NCCL INFO Channel 00 : 90[ca000] -> 91[e3000] via P2P/IPC/read
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 00 : 417[4b000] -> 418[ca000] via P2P/IPC/read
302: hkn0628:656986:657104 [2] NCCL INFO Channel 00 : 302[ca000] -> 303[e3000] via P2P/IPC/read
422: hkn0726:1533298:1533416 [2] NCCL INFO Connected all rings
341: hkn0704:777142:777272 [1] NCCL INFO Channel 01 : 341[4b000] -> 342[ca000] via P2P/IPC/read
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 01 : 425[4b000] -> 426[ca000] via P2P/IPC/read
390: hkn0717:4172695:4172824 [2] NCCL INFO Channel 01 : 390[ca000] -> 391[e3000] via P2P/IPC/read
378: hkn0714:417196:417322 [2] NCCL INFO Channel 00 : 378[ca000] -> 379[e3000] via P2P/IPC/read
466: hkn0803:861668:861780 [2] NCCL INFO Channel 01 : 466[ca000] -> 467[e3000] via P2P/IPC/read
454: hkn0736:1493528:1493648 [2] NCCL INFO Channel 01 : 454[ca000] -> 455[e3000] via P2P/IPC/read
368: hkn0712:280251:280359 [0] NCCL INFO Channel 01 : 368[31000] -> 369[4b000] via P2P/IPC/read
 10: hkn0405:3191876:3192004 [2] NCCL INFO Channel 00 : 10[ca000] -> 11[e3000] via P2P/IPC/read
301: hkn0628:657007:657097 [1] NCCL INFO Channel 01 : 301[4b000] -> 302[ca000] via P2P/IPC/read
386: hkn0716:93666:93764 [2] NCCL INFO Channel 01 : 386[ca000] -> 387[e3000] via P2P/IPC/read
377: hkn0714:417216:417317 [1] NCCL INFO Channel 01 : 377[4b000] -> 378[ca000] via P2P/IPC/read
362: hkn0710:340630:340740 [2] NCCL INFO Channel 00 : 362[ca000] -> 363[e3000] via P2P/IPC/read
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 01 : 9[4b000] -> 10[ca000] via P2P/IPC/read
374: hkn0713:455429:455542 [2] NCCL INFO Channel 01 : 374[ca000] -> 375[e3000] via P2P/IPC/read
109: hkn0504:25973:26092 [1] NCCL INFO Channel 01 : 109[4b000] -> 110[ca000] via P2P/IPC/read
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 01 : 89[4b000] -> 90[ca000] via P2P/IPC/read
218: hkn0601:102824:102933 [2] NCCL INFO Channel 01 : 218[ca000] -> 219[e3000] via P2P/IPC/read
361: hkn0710:340632:340748 [1] NCCL INFO Channel 01 : 361[4b000] -> 362[ca000] via P2P/IPC/read
366: hkn0711:569042:569160 [2] NCCL INFO Channel 01 : 366[ca000] -> 367[e3000] via P2P/IPC/read
 14: hkn0407:1801449:1801570 [2] NCCL INFO Channel 01 : 14[ca000] -> 15[e3000] via P2P/IPC/read
354: hkn0707:4005065:4005191 [2] NCCL INFO Channel 01 : 354[ca000] -> 355[e3000] via P2P/IPC/read
356: hkn0708:398416:398525 [0] NCCL INFO Channel 01 : 356[31000] -> 357[4b000] via P2P/IPC/read
418: hkn0725:3097089:3097197 [2] NCCL INFO Channel 00 : 418[ca000] -> 419[e3000] via P2P/IPC/read
370: hkn0712:280242:280355 [2] NCCL INFO Connected all rings
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 00 : 313[4b000] -> 314[ca000] via P2P/IPC/read
483: hkn0807:1004280:1004394 [3] NCCL INFO Connected all trees
 39: hkn0413:2351834:2351947 [3] NCCL INFO Connected all trees
463: hkn0802:1185491:1185618 [3] NCCL INFO Connected all trees
 22: hkn0409:2570866:2570968 [2] NCCL INFO Channel 01 : 22[ca000] -> 23[e3000] via P2P/IPC/read
483: hkn0807:1004280:1004394 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 39: hkn0413:2351834:2351947 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
483: hkn0807:1004280:1004394 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
463: hkn0802:1185491:1185618 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
494: hkn0810:924728:924849 [2] NCCL INFO Channel 01 : 494[ca000] -> 495[e3000] via P2P/IPC/read
463: hkn0802:1185491:1185618 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
210: hkn0534:1133593:1133689 [2] NCCL INFO Channel 01 : 210[ca000] -> 211[e3000] via P2P/IPC/read
381: hkn0715:387096:387223 [1] NCCL INFO Channel 00 : 381[4b000] -> 382[ca000] via P2P/IPC/read
399: hkn0719:1290839:1290961 [3] NCCL INFO Connected all trees
399: hkn0719:1290839:1290961 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 39: hkn0413:2351834:2351947 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
399: hkn0719:1290839:1290961 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
162: hkn0520:2698027:2698123 [2] NCCL INFO Channel 01 : 162[ca000] -> 163[e3000] via P2P/IPC/read
326: hkn0634:1506052:1506156 [2] NCCL INFO Connected all rings
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 01 : 120[31000] -> 121[4b000] via P2P/IPC/read
146: hkn0513:2998110:2998204 [2] NCCL INFO Channel 01 : 146[ca000] -> 147[e3000] via P2P/IPC/read
458: hkn0801:2225110:2225221 [2] NCCL INFO Channel 01 : 458[ca000] -> 459[e3000] via P2P/IPC/read
447: hkn0733:1374550:1374661 [3] NCCL INFO Connected all trees
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 01 : 417[4b000] -> 418[ca000] via P2P/IPC/read
110: hkn0504:25993:26089 [2] NCCL INFO Channel 01 : 110[ca000] -> 111[e3000] via P2P/IPC/read
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 00 : 324[31000] -> 325[4b000] via P2P/IPC/read
  2: hkn0403:1738697:1739060 [2] NCCL INFO Channel 01 : 2[ca000] -> 3[e3000] via P2P/IPC/read
447: hkn0733:1374550:1374661 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
447: hkn0733:1374550:1374661 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
314: hkn0631:1006951:1007072 [2] NCCL INFO Channel 00 : 314[ca000] -> 315[e3000] via P2P/IPC/read
487: hkn0808:955859:955975 [3] NCCL INFO Connected all trees
227: hkn0603:1398303:1398428 [3] NCCL INFO Connected all trees
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 00 : 413[4b000] -> 414[ca000] via P2P/IPC/read
262: hkn0613:887824:887976 [2] NCCL INFO Channel 01 : 262[ca000] -> 263[e3000] via P2P/IPC/read
487: hkn0808:955859:955975 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 90: hkn0427:1120345:1120439 [2] NCCL INFO Channel 01 : 90[ca000] -> 91[e3000] via P2P/IPC/read
207: hkn0532:908790:909100 [3] NCCL INFO Connected all trees
487: hkn0808:955859:955975 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1190762:1190887 [3] NCCL INFO Connected all trees
342: hkn0704:777150:777271 [2] NCCL INFO Channel 01 : 342[ca000] -> 343[e3000] via P2P/IPC/read
207: hkn0532:908790:909100 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1701124:1701254 [2] NCCL INFO Channel 00 : 414[ca000] -> 415[e3000] via P2P/IPC/read
471: hkn0804:1190762:1190887 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
207: hkn0532:908790:909100 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1190762:1190887 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
426: hkn0727:1330937:1331047 [2] NCCL INFO Channel 01 : 426[ca000] -> 427[e3000] via P2P/IPC/read
475: hkn0805:1097283:1097377 [3] NCCL INFO Connected all trees
227: hkn0603:1398303:1398428 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
451: hkn0734:1141736:1141845 [3] NCCL INFO Connected all trees
234: hkn0605:697234:697394 [2] NCCL INFO Connected all trees
378: hkn0714:417196:417322 [2] NCCL INFO Channel 01 : 378[ca000] -> 379[e3000] via P2P/IPC/read
475: hkn0805:1097283:1097377 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
475: hkn0805:1097283:1097377 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
451: hkn0734:1141736:1141845 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
451: hkn0734:1141736:1141845 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
234: hkn0605:697234:697394 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
362: hkn0710:340630:340740 [2] NCCL INFO Channel 01 : 362[ca000] -> 363[e3000] via P2P/IPC/read
234: hkn0605:697234:697394 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
382: hkn0715:387104:387217 [2] NCCL INFO Channel 00 : 382[ca000] -> 383[e3000] via P2P/IPC/read
407: hkn0721:2284151:2284268 [3] NCCL INFO Connected all trees
227: hkn0603:1398303:1398428 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
491: hkn0809:922581:922679 [3] NCCL INFO Connected all trees
381: hkn0715:387096:387223 [1] NCCL INFO Channel 01 : 381[4b000] -> 382[ca000] via P2P/IPC/read
407: hkn0721:2284151:2284268 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
418: hkn0725:3097089:3097197 [2] NCCL INFO Channel 01 : 418[ca000] -> 419[e3000] via P2P/IPC/read
407: hkn0721:2284151:2284268 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
395: hkn0718:3902182:3902290 [3] NCCL INFO Connected all trees
491: hkn0809:922581:922679 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
435: hkn0730:1386922:1387017 [3] NCCL INFO Connected all trees
349: hkn0706:737463:737570 [1] NCCL INFO Channel 00 : 349[4b000] -> 350[ca000] via P2P/IPC/read
395: hkn0718:3902182:3902290 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
491: hkn0809:922581:922679 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
435: hkn0730:1386922:1387017 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
339: hkn0703:726146:726263 [3] NCCL INFO Connected all trees
435: hkn0730:1386922:1387017 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:697242:697386 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [send] via NET/IBext/0
339: hkn0703:726146:726263 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
395: hkn0718:3902182:3902290 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
339: hkn0703:726146:726263 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
347: hkn0705:768400:768514 [3] NCCL INFO Connected all trees
455: hkn0736:1493529:1493646 [3] NCCL INFO Connected all trees
131: hkn0509:3109556:3109675 [3] NCCL INFO Connected all trees
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 01 : 413[4b000] -> 414[ca000] via P2P/IPC/read
391: hkn0717:4172703:4172819 [3] NCCL INFO Connected all trees
347: hkn0705:768400:768514 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
455: hkn0736:1493529:1493646 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1701124:1701254 [2] NCCL INFO Channel 01 : 414[ca000] -> 415[e3000] via P2P/IPC/read
391: hkn0717:4172703:4172819 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
387: hkn0716:93654:93766 [3] NCCL INFO Connected all trees
391: hkn0717:4172703:4172819 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
347: hkn0705:768400:768514 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
467: hkn0803:861681:861778 [3] NCCL INFO Connected all trees
387: hkn0716:93654:93766 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
350: hkn0706:737475:737567 [2] NCCL INFO Channel 00 : 350[ca000] -> 351[e3000] via P2P/IPC/read
387: hkn0716:93654:93766 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
375: hkn0713:455441:455538 [3] NCCL INFO Connected all trees
355: hkn0707:4005093:4005183 [3] NCCL INFO Connected all trees
355: hkn0707:4005093:4005183 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
467: hkn0803:861681:861778 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
375: hkn0713:455441:455538 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
467: hkn0803:861681:861778 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
421: hkn0726:1533295:1533418 [1] NCCL INFO Channel 00 : 421[4b000] -> 422[ca000] via P2P/IPC/read
482: hkn0807:1004292:1004392 [2] NCCL INFO Connected all trees
375: hkn0713:455441:455538 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
462: hkn0802:1185507:1185616 [2] NCCL INFO Connected all trees
482: hkn0807:1004292:1004392 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
355: hkn0707:4005093:4005183 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
482: hkn0807:1004292:1004392 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1801457:1801568 [3] NCCL INFO Connected all trees
 15: hkn0407:1801457:1801568 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
462: hkn0802:1185507:1185616 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
462: hkn0802:1185507:1185616 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
495: hkn0810:924736:924852 [3] NCCL INFO Connected all trees
398: hkn0719:1290848:1290952 [2] NCCL INFO Connected all trees
398: hkn0719:1290848:1290952 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
398: hkn0719:1290848:1290952 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1801457:1801568 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
495: hkn0810:924736:924852 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
367: hkn0711:569054:569153 [3] NCCL INFO Connected all trees
446: hkn0733:1374549:1374669 [2] NCCL INFO Connected all trees
349: hkn0706:737463:737570 [1] NCCL INFO Channel 01 : 349[4b000] -> 350[ca000] via P2P/IPC/read
495: hkn0810:924736:924852 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
367: hkn0711:569054:569153 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
446: hkn0733:1374549:1374669 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
211: hkn0534:1133581:1133690 [3] NCCL INFO Connected all trees
446: hkn0733:1374549:1374669 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
367: hkn0711:569054:569153 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
422: hkn0726:1533298:1533416 [2] NCCL INFO Channel 00 : 422[ca000] -> 423[e3000] via P2P/IPC/read
211: hkn0534:1133581:1133690 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [send] via NET/IBext/0
211: hkn0534:1133581:1133690 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  3: hkn0403:1738677:1739059 [3] NCCL INFO Connected all trees
  3: hkn0403:1738677:1739059 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
486: hkn0808:955867:955976 [2] NCCL INFO Connected all trees
  3: hkn0403:1738677:1739059 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
474: hkn0805:1097271:1097381 [2] NCCL INFO Connected all trees
486: hkn0808:955867:955976 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
163: hkn0520:2698007:2698122 [3] NCCL INFO Connected all trees
206: hkn0532:908802:909093 [2] NCCL INFO Connected all trees
486: hkn0808:955867:955976 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [receive] via NET/IBext/0
474: hkn0805:1097271:1097381 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
470: hkn0804:1190787:1190892 [2] NCCL INFO Connected all trees
206: hkn0532:908802:909093 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
206: hkn0532:908802:909093 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
343: hkn0704:777170:777274 [3] NCCL INFO Connected all trees
470: hkn0804:1190787:1190892 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
427: hkn0727:1330957:1331044 [3] NCCL INFO Connected all trees
470: hkn0804:1190787:1190892 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
343: hkn0704:777170:777274 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
343: hkn0704:777170:777274 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
427: hkn0727:1330957:1331044 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
421: hkn0726:1533295:1533418 [1] NCCL INFO Channel 01 : 421[4b000] -> 422[ca000] via P2P/IPC/read
427: hkn0727:1330957:1331044 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:955851:955982 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [receive] via NET/IBext/0
 91: hkn0427:1120333:1120440 [3] NCCL INFO Connected all trees
474: hkn0805:1097271:1097381 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
163: hkn0520:2698007:2698122 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
379: hkn0714:417204:417316 [3] NCCL INFO Connected all trees
379: hkn0714:417204:417316 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 91: hkn0427:1120333:1120440 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
379: hkn0714:417204:417316 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 91: hkn0427:1120333:1120440 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
163: hkn0520:2698007:2698122 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:398436:398520 [1] NCCL INFO Channel 00 : 357[4b000] -> 358[ca000] via P2P/IPC/read
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [receive] via NET/IBext/0
363: hkn0710:340631:340745 [3] NCCL INFO Connected all trees
350: hkn0706:737475:737567 [2] NCCL INFO Channel 01 : 350[ca000] -> 351[e3000] via P2P/IPC/read
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [receive] via NET/IBext/0
363: hkn0710:340631:340745 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [receive] via NET/IBext/0
434: hkn0730:1386902:1387024 [2] NCCL INFO Connected all trees
363: hkn0710:340631:340745 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1141720:1141848 [2] NCCL INFO Connected all trees
382: hkn0715:387104:387217 [2] NCCL INFO Channel 01 : 382[ca000] -> 383[e3000] via P2P/IPC/read
434: hkn0730:1386902:1387024 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
406: hkn0721:2284171:2284267 [2] NCCL INFO Connected all trees
406: hkn0721:2284171:2284267 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
434: hkn0730:1386902:1387024 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
450: hkn0734:1141720:1141848 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [send] via NET/IBext/0
450: hkn0734:1141720:1141848 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
358: hkn0708:398424:398526 [2] NCCL INFO Channel 00 : 358[ca000] -> 359[e3000] via P2P/IPC/read
406: hkn0721:2284171:2284267 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:908782:909098 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [receive] via NET/IBext/0
455: hkn0736:1493529:1493646 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
338: hkn0703:726147:726262 [2] NCCL INFO Connected all trees
390: hkn0717:4172695:4172824 [2] NCCL INFO Connected all trees
346: hkn0705:768409:768518 [2] NCCL INFO Connected all trees
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [receive] via NET/IBext/0
338: hkn0703:726147:726262 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
390: hkn0717:4172695:4172824 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
338: hkn0703:726147:726262 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:93666:93764 [2] NCCL INFO Connected all trees
422: hkn0726:1533298:1533416 [2] NCCL INFO Channel 01 : 422[ca000] -> 423[e3000] via P2P/IPC/read
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [send] via NET/IBext/0
386: hkn0716:93666:93764 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
354: hkn0707:4005065:4005191 [2] NCCL INFO Connected all trees
354: hkn0707:4005065:4005191 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [send] via NET/IBext/0
386: hkn0716:93666:93764 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
374: hkn0713:455429:455542 [2] NCCL INFO Connected all trees
374: hkn0713:455429:455542 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
354: hkn0707:4005065:4005191 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
374: hkn0713:455429:455542 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 14: hkn0407:1801449:1801570 [2] NCCL INFO Connected all trees
390: hkn0717:4172695:4172824 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
346: hkn0705:768409:768518 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 14: hkn0407:1801449:1801570 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [receive] via NET/IBext/0
 14: hkn0407:1801449:1801570 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
366: hkn0711:569042:569160 [2] NCCL INFO Connected all trees
366: hkn0711:569042:569160 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
494: hkn0810:924728:924849 [2] NCCL INFO Connected all trees
366: hkn0711:569042:569160 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
346: hkn0705:768409:768518 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:398436:398520 [1] NCCL INFO Channel 01 : 357[4b000] -> 358[ca000] via P2P/IPC/read
384: hkn0716:93645:93760 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [send] via NET/IBext/0
344: hkn0705:768421:768521 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [send] via NET/IBext/0
494: hkn0810:924728:924849 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:455428:455539 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [receive] via NET/IBext/0
494: hkn0810:924728:924849 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
466: hkn0803:861668:861780 [2] NCCL INFO Connected all trees
162: hkn0520:2698027:2698123 [2] NCCL INFO Connected all trees
419: hkn0725:3097098:3097193 [3] NCCL INFO Connected all trees
162: hkn0520:2698027:2698123 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
466: hkn0803:861668:861780 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
210: hkn0534:1133593:1133689 [2] NCCL INFO Connected all trees
162: hkn0520:2698027:2698123 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
415: hkn0724:1701152:1701251 [3] NCCL INFO Connected all trees
466: hkn0803:861668:861780 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
210: hkn0534:1133593:1133689 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
464: hkn0803:861669:861771 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [send] via NET/IBext/0
415: hkn0724:1701152:1701251 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
210: hkn0534:1133593:1133689 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
415: hkn0724:1701152:1701251 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
383: hkn0715:387112:387222 [3] NCCL INFO Connected all trees
419: hkn0725:3097098:3097193 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
454: hkn0736:1493528:1493648 [2] NCCL INFO Connected all trees
383: hkn0715:387112:387222 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
419: hkn0725:3097098:3097193 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
383: hkn0715:387112:387222 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
454: hkn0736:1493528:1493648 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
454: hkn0736:1493528:1493648 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
394: hkn0718:3902173:3902289 [2] NCCL INFO Connected all trees
342: hkn0704:777150:777271 [2] NCCL INFO Connected all trees
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [send] via NET/IBext/0
426: hkn0727:1330937:1331047 [2] NCCL INFO Connected all trees
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [send] via NET/IBext/0
342: hkn0704:777150:777271 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
342: hkn0704:777150:777271 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
358: hkn0708:398424:398526 [2] NCCL INFO Channel 01 : 358[ca000] -> 359[e3000] via P2P/IPC/read
  2: hkn0403:1738697:1739060 [2] NCCL INFO Connected all trees
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [send] via NET/IBext/0
  2: hkn0403:1738697:1739060 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  2: hkn0403:1738697:1739060 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
426: hkn0727:1330937:1331047 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
426: hkn0727:1330937:1331047 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 90: hkn0427:1120345:1120439 [2] NCCL INFO Connected all trees
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [send] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [receive] via NET/IBext/0
 90: hkn0427:1120345:1120439 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
364: hkn0711:569026:569156 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [receive] via NET/IBext/0
 90: hkn0427:1120345:1120439 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [receive] via NET/IBext/0
394: hkn0718:3902173:3902289 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
226: hkn0603:1398315:1398422 [2] NCCL INFO Connected all trees
362: hkn0710:340630:340740 [2] NCCL INFO Connected all trees
233: hkn0605:697262:697393 [1] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [receive] via NET/IBext/0
  1: hkn0403:1738685:1739058 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via P2P/IPC/read
394: hkn0718:3902173:3902289 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
362: hkn0710:340630:340740 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [send] via NET/IBext/0
362: hkn0710:340630:340740 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [send] via NET/IBext/0
226: hkn0603:1398315:1398422 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:922553:922675 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [send] via NET/IBext/0
226: hkn0603:1398315:1398422 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
369: hkn0712:280243:280361 [1] NCCL INFO Channel 00 : 369[4b000] -> 370[ca000] via P2P/IPC/read
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [send] via NET/IBext/0
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [send] via NET/IBext/0
378: hkn0714:417196:417322 [2] NCCL INFO Connected all trees
490: hkn0809:922569:922682 [2] NCCL INFO Connected all trees
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [receive] via NET/IBext/0
490: hkn0809:922569:922682 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
378: hkn0714:417196:417322 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
490: hkn0809:922569:922682 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
378: hkn0714:417196:417322 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
370: hkn0712:280242:280355 [2] NCCL INFO Channel 00 : 370[ca000] -> 371[e3000] via P2P/IPC/read
369: hkn0712:280243:280361 [1] NCCL INFO Channel 01 : 369[4b000] -> 370[ca000] via P2P/IPC/read
131: hkn0509:3109556:3109675 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:340644:340742 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [send] via NET/IBext/0
351: hkn0706:737447:737575 [3] NCCL INFO Connected all trees
  1: hkn0403:1738685:1739058 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via P2P/IPC/read
376: hkn0714:417195:417320 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [send] via NET/IBext/0
351: hkn0706:737447:737575 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:777158:777265 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [receive] via NET/IBext/0
351: hkn0706:737447:737575 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
418: hkn0725:3097089:3097197 [2] NCCL INFO Connected all trees
370: hkn0712:280242:280355 [2] NCCL INFO Channel 01 : 370[ca000] -> 371[e3000] via P2P/IPC/read
131: hkn0509:3109556:3109675 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
418: hkn0725:3097089:3097197 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
130: hkn0509:3109548:3109677 [2] NCCL INFO Connected all trees
418: hkn0725:3097089:3097197 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 23: hkn0409:2570858:2570973 [3] NCCL INFO Connected all trees
130: hkn0509:3109548:3109677 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 10: hkn0405:3191876:3192004 [2] NCCL INFO Channel 01 : 10[ca000] -> 11[e3000] via P2P/IPC/read
130: hkn0509:3109548:3109677 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 23: hkn0409:2570858:2570973 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [send] via NET/IBext/0
 23: hkn0409:2570858:2570973 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 22: hkn0409:2570866:2570968 [2] NCCL INFO Connected all trees
 22: hkn0409:2570866:2570968 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 11: hkn0405:3191884:3191996 [3] NCCL INFO Connected all trees
 22: hkn0409:2570866:2570968 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 11: hkn0405:3191884:3191996 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [receive] via NET/IBext/0
 11: hkn0405:3191884:3191996 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 10: hkn0405:3191876:3192004 [2] NCCL INFO Connected all trees
263: hkn0613:887832:887970 [3] NCCL INFO Connected all trees
423: hkn0726:1533306:1533413 [3] NCCL INFO Connected all trees
 10: hkn0405:3191876:3192004 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [send] via NET/IBext/0
263: hkn0613:887832:887970 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
423: hkn0726:1533306:1533413 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [receive] via NET/IBext/0
423: hkn0726:1533306:1533413 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 10: hkn0405:3191876:3192004 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
263: hkn0613:887832:887970 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
302: hkn0628:656986:657104 [2] NCCL INFO Channel 01 : 302[ca000] -> 303[e3000] via P2P/IPC/read
262: hkn0613:887824:887976 [2] NCCL INFO Connected all trees
111: hkn0504:25981:26087 [3] NCCL INFO Connected all trees
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [send] via NET/IBext/0
262: hkn0613:887824:887976 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
262: hkn0613:887824:887976 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
303: hkn0628:656987:657106 [3] NCCL INFO Connected all trees
414: hkn0724:1701124:1701254 [2] NCCL INFO Connected all trees
371: hkn0712:280263:280354 [3] NCCL INFO Connected all trees
260: hkn0613:887844:887968 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [receive] via NET/IBext/0
303: hkn0628:656987:657106 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1701124:1701254 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [send] via NET/IBext/0
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [send] via NET/IBext/0
414: hkn0724:1701124:1701254 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
336: hkn0703:726160:726259 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [send] via NET/IBext/0
382: hkn0715:387104:387217 [2] NCCL INFO Connected all trees
489: hkn0809:922561:922677 [1] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [receive] via NET/IBext/0
371: hkn0712:280263:280354 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [send] via NET/IBext/0
485: hkn0808:955879:955981 [1] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [receive] via NET/IBext/0
382: hkn0715:387104:387217 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [receive] via NET/IBext/0
382: hkn0715:387104:387217 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
371: hkn0712:280263:280354 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [receive] via NET/IBext/0
380: hkn0715:387124:387215 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [receive] via NET/IBext/0
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [receive] via NET/IBext/0
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [receive] via NET/IBext/0
303: hkn0628:656987:657106 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
111: hkn0504:25981:26087 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1190775:1190890 [1] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [receive] via NET/IBext/0
205: hkn0532:908774:909097 [1] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [send] via NET/IBext/0
302: hkn0628:656986:657104 [2] NCCL INFO Connected all trees
302: hkn0628:656986:657104 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
111: hkn0504:25981:26087 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
302: hkn0628:656986:657104 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
110: hkn0504:25993:26089 [2] NCCL INFO Connected all trees
110: hkn0504:25993:26089 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:656995:657105 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [receive] via NET/IBext/0
110: hkn0504:25993:26089 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
108: hkn0504:25965:26094 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [receive] via NET/IBext/0
219: hkn0601:102808:102935 [3] NCCL INFO Connected all trees
255: hkn0611:694957:695086 [3] NCCL INFO Connected all trees
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 01 : 313[4b000] -> 314[ca000] via P2P/IPC/read
405: hkn0721:2284159:2284270 [1] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [receive] via NET/IBext/0
219: hkn0601:102808:102935 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
359: hkn0708:398415:398522 [3] NCCL INFO Connected all trees
219: hkn0601:102808:102935 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
218: hkn0601:102824:102933 [2] NCCL INFO Connected all trees
255: hkn0611:694957:695086 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
359: hkn0708:398415:398522 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
218: hkn0601:102824:102933 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
359: hkn0708:398415:398522 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
218: hkn0601:102824:102933 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
216: hkn0601:102816:102929 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [send] via NET/IBext/0
255: hkn0611:694957:695086 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
254: hkn0611:694965:695087 [2] NCCL INFO Connected all trees
314: hkn0631:1006951:1007072 [2] NCCL INFO Channel 01 : 314[ca000] -> 315[e3000] via P2P/IPC/read
254: hkn0611:694965:695087 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
315: hkn0631:1006960:1007067 [3] NCCL INFO Connected all trees
254: hkn0611:694965:695087 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
315: hkn0631:1006960:1007067 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
315: hkn0631:1006960:1007067 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 38: hkn0413:2351846:2351938 [2] NCCL INFO Connected all trees
 38: hkn0413:2351846:2351938 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
314: hkn0631:1006951:1007072 [2] NCCL INFO Connected all trees
 38: hkn0413:2351846:2351938 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [receive] via NET/IBext/0
314: hkn0631:1006951:1007072 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
350: hkn0706:737475:737567 [2] NCCL INFO Connected all trees
314: hkn0631:1006951:1007072 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
345: hkn0705:768401:768516 [1] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [receive] via NET/IBext/0
453: hkn0736:1493549:1493641 [1] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [receive] via NET/IBext/0
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [receive] via NET/IBext/0
350: hkn0706:737475:737567 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
350: hkn0706:737475:737567 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
389: hkn0717:4172715:4172825 [1] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [receive] via NET/IBext/0
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [send] via NET/IBext/0
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [receive] via NET/IBext/0
 37: hkn0413:2351826:2351942 [1] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [receive] via NET/IBext/0
267: hkn0615:399435:399549 [3] NCCL INFO Connected all trees
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 01 : 324[31000] -> 325[4b000] via P2P/IPC/read
 74: hkn0423:1689961:1690083 [2] NCCL INFO Channel 01 : 74[ca000] -> 75[e3000] via P2P/IPC/read
267: hkn0615:399435:399549 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 27: hkn0410:1144778:1144896 [3] NCCL INFO Connected all trees
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [receive] via NET/IBext/0
267: hkn0615:399435:399549 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:694973:695080 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [receive] via NET/IBext/0
266: hkn0615:399419:399548 [2] NCCL INFO Connected all trees
373: hkn0713:455427:455540 [1] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [receive] via NET/IBext/0
465: hkn0803:861667:861779 [1] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [receive] via NET/IBext/0
217: hkn0601:102836:102938 [1] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [receive] via NET/IBext/0
266: hkn0615:399419:399548 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
337: hkn0703:726148:726258 [1] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [receive] via NET/IBext/0
266: hkn0615:399419:399548 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
264: hkn0615:399427:399550 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [send] via NET/IBext/0
325: hkn0634:1506024:1506157 [1] NCCL INFO Channel 00 : 325[4b000] -> 326[ca000] via P2P/IPC/read
365: hkn0711:569034:569157 [1] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [send] via NET/IBext/0
265: hkn0615:399447:399552 [1] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [receive] via NET/IBext/0
422: hkn0726:1533298:1533416 [2] NCCL INFO Connected all trees
385: hkn0716:93646:93761 [1] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [receive] via NET/IBext/0
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [send] via NET/IBext/0
326: hkn0634:1506052:1506156 [2] NCCL INFO Channel 00 : 326[ca000] -> 327[e3000] via P2P/IPC/read
422: hkn0726:1533298:1533416 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1506024:1506157 [1] NCCL INFO Channel 01 : 325[4b000] -> 326[ca000] via P2P/IPC/read
422: hkn0726:1533298:1533416 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
326: hkn0634:1506052:1506156 [2] NCCL INFO Channel 01 : 326[ca000] -> 327[e3000] via P2P/IPC/read
 21: hkn0409:2570850:2570977 [1] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [receive] via NET/IBext/0
253: hkn0611:694985:695081 [1] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [send] via NET/IBext/0
493: hkn0810:924720:924850 [1] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [send] via NET/IBext/0
327: hkn0634:1506040:1506149 [3] NCCL INFO Connected all trees
261: hkn0613:887816:887974 [1] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [receive] via NET/IBext/0
327: hkn0634:1506040:1506149 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:737455:737573 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [receive] via NET/IBext/0
370: hkn0712:280242:280355 [2] NCCL INFO Connected all trees
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [receive] via NET/IBext/0
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [receive] via NET/IBext/0
370: hkn0712:280242:280355 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
327: hkn0634:1506040:1506149 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
370: hkn0712:280242:280355 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
326: hkn0634:1506052:1506156 [2] NCCL INFO Connected all trees
 75: hkn0423:1689977:1690087 [3] NCCL INFO Connected all trees
 27: hkn0410:1144778:1144896 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [send] via NET/IBext/0
326: hkn0634:1506052:1506156 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
326: hkn0634:1506052:1506156 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [receive] via NET/IBext/0
 75: hkn0423:1689977:1690087 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 75: hkn0423:1689977:1690087 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 27: hkn0410:1144778:1144896 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 74: hkn0423:1689961:1690083 [2] NCCL INFO Connected all trees
 26: hkn0410:1144773:1144892 [2] NCCL INFO Connected all trees
301: hkn0628:657007:657097 [1] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [send] via NET/IBext/0
 74: hkn0423:1689961:1690083 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 74: hkn0423:1689961:1690083 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 26: hkn0410:1144773:1144892 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [receive] via NET/IBext/0
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [send] via NET/IBext/0
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [receive] via NET/IBext/0
109: hkn0504:25973:26092 [1] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [send] via NET/IBext/0
341: hkn0704:777142:777272 [1] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [receive] via NET/IBext/0
 26: hkn0410:1144773:1144892 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [receive] via NET/IBext/0
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [send] via NET/IBext/0
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [receive] via NET/IBext/0
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [receive] via NET/IBext/0
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [receive] via NET/IBext/0
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 00 : 121[4b000] -> 122[ca000] via P2P/IPC/read
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [send] via NET/IBext/0
231: hkn0604:674454:674562 [3] NCCL INFO Connected all trees
377: hkn0714:417216:417317 [1] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [receive] via NET/IBext/0
122: hkn0507:3172208:3172331 [2] NCCL INFO Channel 00 : 122[ca000] -> 123[e3000] via P2P/IPC/read
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 01 : 121[4b000] -> 122[ca000] via P2P/IPC/read
231: hkn0604:674454:674562 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
358: hkn0708:398424:398526 [2] NCCL INFO Connected all trees
122: hkn0507:3172208:3172331 [2] NCCL INFO Channel 01 : 122[ca000] -> 123[e3000] via P2P/IPC/read
361: hkn0710:340632:340748 [1] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [receive] via NET/IBext/0
232: hkn0605:697242:697386 [0] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [send] via NET/IBext/0
358: hkn0708:398424:398526 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:280251:280359 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [send] via NET/IBext/0
358: hkn0708:398424:398526 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
123: hkn0507:3172200:3172323 [3] NCCL INFO Connected all trees
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [receive] via NET/IBext/0
123: hkn0507:3172200:3172323 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
123: hkn0507:3172200:3172323 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
231: hkn0604:674454:674562 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
122: hkn0507:3172208:3172331 [2] NCCL INFO Connected all trees
230: hkn0604:674446:674565 [2] NCCL INFO Connected all trees
122: hkn0507:3172208:3172331 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
230: hkn0604:674446:674565 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
122: hkn0507:3172208:3172331 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
230: hkn0604:674446:674565 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [send] via NET/IBext/0
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [send] via NET/IBext/0
228: hkn0604:674438:674558 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [receive] via NET/IBext/0
147: hkn0513:2998082:2998206 [3] NCCL INFO Connected all trees
229: hkn0604:674466:674561 [1] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [receive] via NET/IBext/0
459: hkn0801:2225102:2225219 [3] NCCL INFO Connected all trees
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [send] via NET/IBext/0
147: hkn0513:2998082:2998206 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [send] via NET/IBext/0
356: hkn0708:398416:398525 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [receive] via NET/IBext/0
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [receive] via NET/IBext/0
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [receive] via NET/IBext/0
147: hkn0513:2998082:2998206 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
459: hkn0801:2225102:2225219 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
384: hkn0716:93645:93760 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [send] via NET/IBext/0
146: hkn0513:2998110:2998204 [2] NCCL INFO Connected all trees
146: hkn0513:2998110:2998204 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
459: hkn0801:2225102:2225219 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
146: hkn0513:2998110:2998204 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
458: hkn0801:2225110:2225221 [2] NCCL INFO Connected all trees
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [send] via NET/IBext/0
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [send] via NET/IBext/0
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [receive] via NET/IBext/0
458: hkn0801:2225110:2225221 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
458: hkn0801:2225110:2225221 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 01 : 157[4b000] -> 158[ca000] via P2P/IPC/read
484: hkn0808:955851:955982 [0] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [send] via NET/IBext/0
464: hkn0803:861669:861771 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [send] via NET/IBext/0
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [send] via NET/IBext/0
158: hkn0516:2901144:2901290 [2] NCCL INFO Channel 01 : 158[ca000] -> 159[e3000] via P2P/IPC/read
381: hkn0715:387096:387223 [1] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [send] via NET/IBext/0
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [receive] via NET/IBext/0
159: hkn0516:2901136:2901292 [3] NCCL INFO Connected all trees
319: hkn0632:1743781:1743911 [3] NCCL INFO Connected all trees
159: hkn0516:2901136:2901292 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
247: hkn0608:470914:471033 [3] NCCL INFO Connected all trees
159: hkn0516:2901136:2901292 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
319: hkn0632:1743781:1743911 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
158: hkn0516:2901144:2901290 [2] NCCL INFO Connected all trees
319: hkn0632:1743781:1743911 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
158: hkn0516:2901144:2901290 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
318: hkn0632:1743760:1743909 [2] NCCL INFO Connected all trees
158: hkn0516:2901144:2901290 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
318: hkn0632:1743760:1743909 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [receive] via NET/IBext/0
318: hkn0632:1743760:1743909 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [receive] via NET/IBext/0
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [send] via NET/IBext/0
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [receive] via NET/IBext/0
247: hkn0608:470914:471033 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
247: hkn0608:470914:471033 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [send] via NET/IBext/0
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [send] via NET/IBext/0
246: hkn0608:470915:471032 [2] NCCL INFO Connected all trees
246: hkn0608:470915:471032 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 00 : 17[4b000] -> 18[ca000] via P2P/IPC/read
264: hkn0615:399427:399550 [0] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [send] via NET/IBext/0
228: hkn0604:674438:674558 [0] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [send] via NET/IBext/0
246: hkn0608:470915:471032 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 18: hkn0408:2875808:2875934 [2] NCCL INFO Channel 00 : 18[ca000] -> 19[e3000] via P2P/IPC/read
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [receive] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [receive] via NET/IBext/0
488: hkn0809:922553:922675 [0] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [send] via NET/IBext/0
245: hkn0608:470935:471034 [1] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [receive] via NET/IBext/0
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [send] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [send] via NET/IBext/0
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [receive] via NET/IBext/0
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [send] via NET/IBext/0
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [send] via NET/IBext/0
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 01 : 17[4b000] -> 18[ca000] via P2P/IPC/read
 18: hkn0408:2875808:2875934 [2] NCCL INFO Channel 01 : 18[ca000] -> 19[e3000] via P2P/IPC/read
269: hkn0616:389977:390103 [1] NCCL INFO Channel 01 : 269[4b000] -> 270[ca000] via P2P/IPC/read
 19: hkn0408:2875816:2875935 [3] NCCL INFO Connected all trees
293: hkn0626:1283586:1283696 [1] NCCL INFO Channel 00 : 293[4b000] -> 294[ca000] via P2P/IPC/read
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [send] via NET/IBext/0
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [receive] via NET/IBext/0
 19: hkn0408:2875816:2875935 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
270: hkn0616:389969:390099 [2] NCCL INFO Channel 01 : 270[ca000] -> 271[e3000] via P2P/IPC/read
 19: hkn0408:2875816:2875935 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
271: hkn0616:389985:390100 [3] NCCL INFO Connected all trees
 18: hkn0408:2875808:2875934 [2] NCCL INFO Connected all trees
 18: hkn0408:2875808:2875934 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
271: hkn0616:389985:390100 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 18: hkn0408:2875808:2875934 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
271: hkn0616:389985:390100 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [send] via NET/IBext/0
270: hkn0616:389969:390099 [2] NCCL INFO Connected all trees
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [send] via NET/IBext/0
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [receive] via NET/IBext/0
270: hkn0616:389969:390099 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
294: hkn0626:1283606:1283705 [2] NCCL INFO Channel 00 : 294[ca000] -> 295[e3000] via P2P/IPC/read
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [send] via NET/IBext/0
270: hkn0616:389969:390099 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [send] via NET/IBext/0
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [receive] via NET/IBext/0
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [receive] via NET/IBext/0
268: hkn0616:389997:390101 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [receive] via NET/IBext/0
360: hkn0710:340644:340742 [0] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [send] via NET/IBext/0
269: hkn0616:389977:390103 [1] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [send] via NET/IBext/0
293: hkn0626:1283586:1283696 [1] NCCL INFO Channel 01 : 293[4b000] -> 294[ca000] via P2P/IPC/read
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 00 : 41[4b000] -> 42[ca000] via P2P/IPC/read
294: hkn0626:1283606:1283705 [2] NCCL INFO Channel 01 : 294[ca000] -> 295[e3000] via P2P/IPC/read
282: hkn0622:2005581:2005688 [2] NCCL INFO Connected all rings
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [send] via NET/IBext/0
295: hkn0626:1283583:1283699 [3] NCCL INFO Connected all trees
295: hkn0626:1283583:1283699 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 42: hkn0414:1966704:1966820 [2] NCCL INFO Channel 00 : 42[ca000] -> 43[e3000] via P2P/IPC/read
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [send] via NET/IBext/0
295: hkn0626:1283583:1283699 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:908782:909098 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [receive] via NET/IBext/0
294: hkn0626:1283606:1283705 [2] NCCL INFO Connected all trees
294: hkn0626:1283606:1283705 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 01 : 41[4b000] -> 42[ca000] via P2P/IPC/read
294: hkn0626:1283606:1283705 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 42: hkn0414:1966704:1966820 [2] NCCL INFO Channel 01 : 42[ca000] -> 43[e3000] via P2P/IPC/read
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [receive] via NET/IBext/0
 43: hkn0414:1966712:1966819 [3] NCCL INFO Connected all trees
293: hkn0626:1283586:1283696 [1] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [receive] via NET/IBext/0
 43: hkn0414:1966712:1966819 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 43: hkn0414:1966712:1966819 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 00 : 281[4b000] -> 282[ca000] via P2P/IPC/read
 42: hkn0414:1966704:1966820 [2] NCCL INFO Connected all trees
282: hkn0622:2005581:2005688 [2] NCCL INFO Channel 00 : 282[ca000] -> 283[e3000] via P2P/IPC/read
 42: hkn0414:1966704:1966820 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 01 : 281[4b000] -> 282[ca000] via P2P/IPC/read
 42: hkn0414:1966704:1966820 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
282: hkn0622:2005581:2005688 [2] NCCL INFO Channel 01 : 282[ca000] -> 283[e3000] via P2P/IPC/read
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [send] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [send] via NET/IBext/0
283: hkn0622:2005565:2005687 [3] NCCL INFO Connected all trees
102: hkn0502:214204:214346 [2] NCCL INFO Channel 00 : 102[ca000] -> 103[e3000] via P2P/IPC/read
283: hkn0622:2005565:2005687 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
114: hkn0505:2288957:2289067 [2] NCCL INFO Channel 00 : 114[ca000] -> 115[e3000] via P2P/IPC/read
283: hkn0622:2005565:2005687 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
101: hkn0502:214224:214351 [1] NCCL INFO Channel 01 : 101[4b000] -> 102[ca000] via P2P/IPC/read
268: hkn0616:389997:390101 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [receive] via NET/IBext/0
282: hkn0622:2005581:2005688 [2] NCCL INFO Connected all trees
282: hkn0622:2005581:2005688 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
102: hkn0502:214204:214346 [2] NCCL INFO Channel 01 : 102[ca000] -> 103[e3000] via P2P/IPC/read
492: hkn0810:924748:924846 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [receive] via NET/IBext/0
282: hkn0622:2005581:2005688 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [send] via NET/IBext/0
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [send] via NET/IBext/0
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [receive] via NET/IBext/0
103: hkn0502:214196:214352 [3] NCCL INFO Connected all trees
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [receive] via NET/IBext/0
103: hkn0502:214196:214352 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
336: hkn0703:726160:726259 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [send] via NET/IBext/0
103: hkn0502:214196:214352 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [receive] via NET/IBext/0
102: hkn0502:214204:214346 [2] NCCL INFO Connected all trees
102: hkn0502:214204:214346 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 01 : 113[4b000] -> 114[ca000] via P2P/IPC/read
260: hkn0613:887844:887968 [0] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [send] via NET/IBext/0
102: hkn0502:214204:214346 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
100: hkn0502:214212:214345 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [receive] via NET/IBext/0
114: hkn0505:2288957:2289067 [2] NCCL INFO Channel 01 : 114[ca000] -> 115[e3000] via P2P/IPC/read
325: hkn0634:1506024:1506157 [1] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [receive] via NET/IBext/0
101: hkn0502:214224:214351 [1] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [receive] via NET/IBext/0
115: hkn0505:2288941:2289062 [3] NCCL INFO Connected all trees
 66: hkn0421:2163516:2163782 [2] NCCL INFO Channel 01 : 66[ca000] -> 67[e3000] via P2P/IPC/read
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [receive] via NET/IBext/0
364: hkn0711:569026:569156 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [receive] via NET/IBext/0
376: hkn0714:417195:417320 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [receive] via NET/IBext/0
115: hkn0505:2288941:2289062 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:25965:26094 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [receive] via NET/IBext/0
115: hkn0505:2288941:2289062 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
114: hkn0505:2288957:2289067 [2] NCCL INFO Connected all trees
 67: hkn0421:2163500:2163778 [3] NCCL INFO Connected all trees
114: hkn0505:2288957:2289067 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 67: hkn0421:2163500:2163778 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
114: hkn0505:2288957:2289067 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 67: hkn0421:2163500:2163778 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [receive] via NET/IBext/0
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [send] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [send] via NET/IBext/0
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [receive] via NET/IBext/0
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [send] via NET/IBext/0
 66: hkn0421:2163516:2163782 [2] NCCL INFO Connected all trees
 66: hkn0421:2163516:2163782 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
306: hkn0629:1577206:1577307 [2] NCCL INFO Channel 01 : 306[ca000] -> 307[e3000] via P2P/IPC/read
300: hkn0628:656995:657105 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [receive] via NET/IBext/0
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [receive] via NET/IBext/0
 66: hkn0421:2163516:2163782 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
307: hkn0629:1577178:1577305 [3] NCCL INFO Connected all trees
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [send] via NET/IBext/0
307: hkn0629:1577178:1577305 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [receive] via NET/IBext/0
307: hkn0629:1577178:1577305 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
306: hkn0629:1577206:1577307 [2] NCCL INFO Connected all trees
258: hkn0612:902136:902248 [2] NCCL INFO Channel 01 : 258[ca000] -> 259[e3000] via P2P/IPC/read
306: hkn0629:1577206:1577307 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 54: hkn0418:1854325:1854445 [2] NCCL INFO Channel 01 : 54[ca000] -> 55[e3000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [receive] via NET/IBext/0
306: hkn0629:1577206:1577307 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
349: hkn0706:737463:737570 [1] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [send] via NET/IBext/0
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [receive] via NET/IBext/0
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [send] via NET/IBext/0
259: hkn0612:902148:902244 [3] NCCL INFO Connected all trees
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [receive] via NET/IBext/0
259: hkn0612:902148:902244 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [send] via NET/IBext/0
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [send] via NET/IBext/0
259: hkn0612:902148:902244 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 55: hkn0418:1854333:1854449 [3] NCCL INFO Connected all trees
258: hkn0612:902136:902248 [2] NCCL INFO Connected all trees
 55: hkn0418:1854333:1854449 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
258: hkn0612:902136:902248 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 55: hkn0418:1854333:1854449 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
258: hkn0612:902136:902248 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 54: hkn0418:1854325:1854445 [2] NCCL INFO Connected all trees
256: hkn0612:902120:902251 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [send] via NET/IBext/0
 54: hkn0418:1854325:1854445 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:902128:902247 [1] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [receive] via NET/IBext/0
 54: hkn0418:1854325:1854445 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:777158:777265 [0] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [send] via NET/IBext/0
256: hkn0612:902120:902251 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [send] via NET/IBext/0
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [receive] via NET/IBext/0
 30: hkn0411:2301012:2301139 [2] NCCL INFO Channel 01 : 30[ca000] -> 31[e3000] via P2P/IPC/read
 53: hkn0418:1854353:1854450 [1] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [receive] via NET/IBext/0
223: hkn0602:3345215:3345483 [3] NCCL INFO Connected all trees
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [send] via NET/IBext/0
 31: hkn0411:2301028:2301136 [3] NCCL INFO Connected all trees
 31: hkn0411:2301028:2301136 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
223: hkn0602:3345215:3345483 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 31: hkn0411:2301028:2301136 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
223: hkn0602:3345215:3345483 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [receive] via NET/IBext/0
 30: hkn0411:2301012:2301139 [2] NCCL INFO Connected all trees
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [send] via NET/IBext/0
100: hkn0502:214212:214345 [0] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [send] via NET/IBext/0
 30: hkn0411:2301012:2301139 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
222: hkn0602:3345207:3345482 [2] NCCL INFO Connected all trees
 30: hkn0411:2301012:2301139 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3345207:3345482 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [receive] via NET/IBext/0
222: hkn0602:3345207:3345482 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [send] via NET/IBext/0
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [receive] via NET/IBext/0
421: hkn0726:1533295:1533418 [1] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [receive] via NET/IBext/0
380: hkn0715:387124:387215 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [receive] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [send] via NET/IBext/0
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [receive] via NET/IBext/0
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [send] via NET/IBext/0
 35: hkn0412:2247582:2247669 [3] NCCL INFO Connected all trees
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [receive] via NET/IBext/0
 47: hkn0415:2481502:2481621 [3] NCCL INFO Connected all trees
 35: hkn0412:2247582:2247669 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 01 : 80[31000] -> 81[4b000] via P2P/IPC/read
344: hkn0705:768421:768521 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [receive] via NET/IBext/0
 35: hkn0412:2247582:2247669 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [receive] via NET/IBext/0
 34: hkn0412:2247554:2247673 [2] NCCL INFO Connected all trees
369: hkn0712:280243:280361 [1] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [receive] via NET/IBext/0
 34: hkn0412:2247554:2247673 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 34: hkn0412:2247554:2247673 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 47: hkn0415:2481502:2481621 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [send] via NET/IBext/0
 47: hkn0415:2481502:2481621 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [receive] via NET/IBext/0
 46: hkn0415:2481504:2481617 [2] NCCL INFO Connected all trees
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [send] via NET/IBext/0
 46: hkn0415:2481504:2481617 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [send] via NET/IBext/0
 46: hkn0415:2481504:2481617 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [send] via NET/IBext/0
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [receive] via NET/IBext/0
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [send] via NET/IBext/0
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 00 : 81[4b000] -> 82[ca000] via P2P/IPC/read
 82: hkn0425:2069118:2069202 [2] NCCL INFO Channel 00 : 82[ca000] -> 83[e3000] via P2P/IPC/read
239: hkn0606:2357195:2357321 [3] NCCL INFO Connected all trees
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 01 : 81[4b000] -> 82[ca000] via P2P/IPC/read
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 00 : 93[4b000] -> 94[ca000] via P2P/IPC/read
 82: hkn0425:2069118:2069202 [2] NCCL INFO Channel 01 : 82[ca000] -> 83[e3000] via P2P/IPC/read
239: hkn0606:2357195:2357321 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 83: hkn0425:2069106:2069204 [3] NCCL INFO Connected all trees
239: hkn0606:2357195:2357321 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 83: hkn0425:2069106:2069204 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
238: hkn0606:2357175:2357324 [2] NCCL INFO Connected all trees
232: hkn0605:697242:697386 [0] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [receive] via NET/IBext/0
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [send] via NET/IBext/0
 83: hkn0425:2069106:2069204 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
238: hkn0606:2357175:2357324 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 82: hkn0425:2069118:2069202 [2] NCCL INFO Connected all trees
238: hkn0606:2357175:2357324 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 82: hkn0425:2069118:2069202 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [receive] via NET/IBext/0
 82: hkn0425:2069118:2069202 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [send] via NET/IBext/0
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [send] via NET/IBext/0
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [receive] via NET/IBext/0
357: hkn0708:398436:398520 [1] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [receive] via NET/IBext/0
368: hkn0712:280251:280359 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [send] via NET/IBext/0
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [receive] via NET/IBext/0
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [receive] via NET/IBext/0
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [send] via NET/IBext/0
 94: hkn0428:652525:652632 [2] NCCL INFO Channel 00 : 94[ca000] -> 95[e3000] via P2P/IPC/read
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 01 : 93[4b000] -> 94[ca000] via P2P/IPC/read
154: hkn0515:2881950:2882069 [2] NCCL INFO Channel 01 : 154[ca000] -> 155[e3000] via P2P/IPC/read
 94: hkn0428:652525:652632 [2] NCCL INFO Channel 01 : 94[ca000] -> 95[e3000] via P2P/IPC/read
 70: hkn0422:4138165:4138293 [2] NCCL INFO Connected all rings
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [send] via NET/IBext/0
 95: hkn0428:652509:652633 [3] NCCL INFO Connected all trees
 95: hkn0428:652509:652633 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
155: hkn0515:2881942:2882062 [3] NCCL INFO Connected all trees
 95: hkn0428:652509:652633 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
155: hkn0515:2881942:2882062 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [send] via NET/IBext/0
 94: hkn0428:652525:652632 [2] NCCL INFO Connected all trees
 94: hkn0428:652525:652632 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
155: hkn0515:2881942:2882062 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 94: hkn0428:652525:652632 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
154: hkn0515:2881950:2882069 [2] NCCL INFO Connected all trees
484: hkn0808:955851:955982 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [send] via NET/IBext/0
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [receive] via NET/IBext/0
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [send] via NET/IBext/0
154: hkn0515:2881950:2882069 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [receive] via NET/IBext/0
154: hkn0515:2881950:2882069 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [send] via NET/IBext/0
 69: hkn0422:4138181:4138294 [1] NCCL INFO Channel 00 : 69[4b000] -> 70[ca000] via P2P/IPC/read
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [receive] via NET/IBext/0
 70: hkn0422:4138165:4138293 [2] NCCL INFO Channel 00 : 70[ca000] -> 71[e3000] via P2P/IPC/read
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [receive] via NET/IBext/0
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [receive] via NET/IBext/0
 69: hkn0422:4138181:4138294 [1] NCCL INFO Channel 01 : 69[4b000] -> 70[ca000] via P2P/IPC/read
250: hkn0609:696036:696151 [2] NCCL INFO Connected all rings
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [receive] via NET/IBext/0
 70: hkn0422:4138165:4138293 [2] NCCL INFO Channel 01 : 70[ca000] -> 71[e3000] via P2P/IPC/read
 71: hkn0422:4138193:4138296 [3] NCCL INFO Connected all trees
249: hkn0609:696028:696150 [1] NCCL INFO Channel 00 : 249[4b000] -> 250[ca000] via P2P/IPC/read
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [receive] via NET/IBext/0
 71: hkn0422:4138193:4138296 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:737455:737573 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [receive] via NET/IBext/0
 71: hkn0422:4138193:4138296 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 70: hkn0422:4138165:4138293 [2] NCCL INFO Connected all trees
250: hkn0609:696036:696151 [2] NCCL INFO Channel 00 : 250[ca000] -> 251[e3000] via P2P/IPC/read
 70: hkn0422:4138165:4138293 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:696028:696150 [1] NCCL INFO Channel 01 : 249[4b000] -> 250[ca000] via P2P/IPC/read
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [send] via NET/IBext/0
 70: hkn0422:4138165:4138293 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [receive] via NET/IBext/0
250: hkn0609:696036:696151 [2] NCCL INFO Channel 01 : 250[ca000] -> 251[e3000] via P2P/IPC/read
 69: hkn0422:4138181:4138294 [1] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [receive] via NET/IBext/0
251: hkn0609:696044:696154 [3] NCCL INFO Connected all trees
264: hkn0615:399427:399550 [0] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [receive] via NET/IBext/0
251: hkn0609:696044:696154 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:674438:674558 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [send] via NET/IBext/0
251: hkn0609:696044:696154 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
250: hkn0609:696036:696151 [2] NCCL INFO Connected all trees
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 00 : 57[4b000] -> 58[ca000] via P2P/IPC/read
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [receive] via NET/IBext/0
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [receive] via NET/IBext/0
250: hkn0609:696036:696151 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 58: hkn0419:1529472:1529584 [2] NCCL INFO Channel 00 : 58[ca000] -> 59[e3000] via P2P/IPC/read
250: hkn0609:696036:696151 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 01 : 57[4b000] -> 58[ca000] via P2P/IPC/read
248: hkn0609:696056:696155 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [send] via NET/IBext/0
 58: hkn0419:1529472:1529584 [2] NCCL INFO Channel 01 : 58[ca000] -> 59[e3000] via P2P/IPC/read
249: hkn0609:696028:696150 [1] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [receive] via NET/IBext/0
 59: hkn0419:1529462:1529576 [3] NCCL INFO Connected all trees
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [receive] via NET/IBext/0
248: hkn0609:696056:696155 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [receive] via NET/IBext/0
488: hkn0809:922553:922675 [0] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [receive] via NET/IBext/0
 59: hkn0419:1529462:1529576 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 59: hkn0419:1529462:1529576 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
333: hkn0636:1639334:1639456 [1] NCCL INFO Connected all rings
372: hkn0713:455428:455539 [0] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [send] via NET/IBext/0
 58: hkn0419:1529472:1529584 [2] NCCL INFO Connected all trees
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [receive] via NET/IBext/0
 58: hkn0419:1529472:1529584 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 58: hkn0419:1529472:1529584 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
334: hkn0636:1639350:1639453 [2] NCCL INFO Connected all rings
464: hkn0803:861669:861771 [0] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [send] via NET/IBext/0
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [send] via NET/IBext/0
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [receive] via NET/IBext/0
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 00 : 333[4b000] -> 334[ca000] via P2P/IPC/read
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [receive] via NET/IBext/0
334: hkn0636:1639350:1639453 [2] NCCL INFO Channel 00 : 334[ca000] -> 335[e3000] via P2P/IPC/read
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 01 : 333[4b000] -> 334[ca000] via P2P/IPC/read
479: hkn0806:1039493:1039614 [3] NCCL INFO Connected all trees
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [send] via NET/IBext/0
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [receive] via NET/IBext/0
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [send] via NET/IBext/0
334: hkn0636:1639350:1639453 [2] NCCL INFO Channel 01 : 334[ca000] -> 335[e3000] via P2P/IPC/read
335: hkn0636:1639362:1639461 [3] NCCL INFO Connected all trees
479: hkn0806:1039493:1039614 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [send] via NET/IBext/0
335: hkn0636:1639362:1639461 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
335: hkn0636:1639362:1639461 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
479: hkn0806:1039493:1039614 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [send] via NET/IBext/0
334: hkn0636:1639350:1639453 [2] NCCL INFO Connected all trees
334: hkn0636:1639350:1639453 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
478: hkn0806:1039513:1039607 [2] NCCL INFO Connected all trees
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [send] via NET/IBext/0
334: hkn0636:1639350:1639453 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [receive] via NET/IBext/0
478: hkn0806:1039513:1039607 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [send] via NET/IBext/0
478: hkn0806:1039513:1039607 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [send] via NET/IBext/0
356: hkn0708:398416:398525 [0] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [send] via NET/IBext/0
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [receive] via NET/IBext/0
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [receive] via NET/IBext/0
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [send] via NET/IBext/0
106: hkn0503:2884805:2884921 [2] NCCL INFO Channel 01 : 106[ca000] -> 107[e3000] via P2P/IPC/read
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [receive] via NET/IBext/0
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 00 : 321[4b000] -> 322[ca000] via P2P/IPC/read
489: hkn0809:922561:922677 [1] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [send] via NET/IBext/0
107: hkn0503:2884797:2884917 [3] NCCL INFO Connected all trees
107: hkn0503:2884797:2884917 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
322: hkn0633:1511522:1511638 [2] NCCL INFO Channel 00 : 322[ca000] -> 323[e3000] via P2P/IPC/read
107: hkn0503:2884797:2884917 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 01 : 321[4b000] -> 322[ca000] via P2P/IPC/read
106: hkn0503:2884805:2884921 [2] NCCL INFO Connected all trees
322: hkn0633:1511522:1511638 [2] NCCL INFO Channel 01 : 322[ca000] -> 323[e3000] via P2P/IPC/read
106: hkn0503:2884805:2884921 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
323: hkn0633:1511534:1511635 [3] NCCL INFO Connected all trees
106: hkn0503:2884805:2884921 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
323: hkn0633:1511534:1511635 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [send] via NET/IBext/0
323: hkn0633:1511534:1511635 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [receive] via NET/IBext/0
322: hkn0633:1511522:1511638 [2] NCCL INFO Connected all trees
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [send] via NET/IBext/0
322: hkn0633:1511522:1511638 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [receive] via NET/IBext/0
322: hkn0633:1511522:1511638 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [send] via NET/IBext/0
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 01 : 284[31000] -> 285[4b000] via P2P/IPC/read
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [receive] via NET/IBext/0
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [receive] via NET/IBext/0
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [send] via NET/IBext/0
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 00 : 285[4b000] -> 286[ca000] via P2P/IPC/read
233: hkn0605:697262:697393 [1] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [send] via NET/IBext/0
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [send] via NET/IBext/0
260: hkn0613:887844:887968 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [send] via NET/IBext/0
286: hkn0623:1857878:1858024 [2] NCCL INFO Channel 00 : 286[ca000] -> 287[e3000] via P2P/IPC/read
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 01 : 285[4b000] -> 286[ca000] via P2P/IPC/read
298: hkn0627:1773054:1773175 [2] NCCL INFO Channel 01 : 298[ca000] -> 299[e3000] via P2P/IPC/read
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [send] via NET/IBext/0
286: hkn0623:1857878:1858024 [2] NCCL INFO Channel 01 : 286[ca000] -> 287[e3000] via P2P/IPC/read
287: hkn0623:1857898:1858023 [3] NCCL INFO Connected all trees
299: hkn0627:1773082:1773180 [3] NCCL INFO Connected all trees
287: hkn0623:1857898:1858023 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
299: hkn0627:1773082:1773180 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
287: hkn0623:1857898:1858023 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
299: hkn0627:1773082:1773180 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [send] via NET/IBext/0
286: hkn0623:1857878:1858024 [2] NCCL INFO Connected all trees
286: hkn0623:1857878:1858024 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
298: hkn0627:1773054:1773175 [2] NCCL INFO Connected all trees
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [receive] via NET/IBext/0
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [receive] via NET/IBext/0
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [send] via NET/IBext/0
286: hkn0623:1857878:1858024 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [receive] via NET/IBext/0
298: hkn0627:1773054:1773175 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [send] via NET/IBext/0
298: hkn0627:1773054:1773175 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [send] via NET/IBext/0
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [receive] via NET/IBext/0
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [send] via NET/IBext/0
274: hkn0617:2279774:2279896 [2] NCCL INFO Channel 01 : 274[ca000] -> 275[e3000] via P2P/IPC/read
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [receive] via NET/IBext/0
310: hkn0630:1583644:1583757 [2] NCCL INFO Channel 00 : 310[ca000] -> 311[e3000] via P2P/IPC/read
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [send] via NET/IBext/0
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [send] via NET/IBext/0
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [receive] via NET/IBext/0
275: hkn0617:2279766:2279891 [3] NCCL INFO Connected all trees
275: hkn0617:2279766:2279891 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1583628:1583756 [1] NCCL INFO Channel 01 : 309[4b000] -> 310[ca000] via P2P/IPC/read
465: hkn0803:861667:861779 [1] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [send] via NET/IBext/0
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [send] via NET/IBext/0
275: hkn0617:2279766:2279891 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
310: hkn0630:1583644:1583757 [2] NCCL INFO Channel 01 : 310[ca000] -> 311[e3000] via P2P/IPC/read
274: hkn0617:2279774:2279896 [2] NCCL INFO Connected all trees
311: hkn0630:1583636:1583760 [3] NCCL INFO Connected all trees
274: hkn0617:2279774:2279896 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
311: hkn0630:1583636:1583760 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [send] via NET/IBext/0
274: hkn0617:2279774:2279896 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [send] via NET/IBext/0
311: hkn0630:1583636:1583760 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [send] via NET/IBext/0
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [receive] via NET/IBext/0
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [send] via NET/IBext/0
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [send] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [send] via NET/IBext/0
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [send] via NET/IBext/0
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [receive] via NET/IBext/0
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [send] via NET/IBext/0
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [send] via NET/IBext/0
310: hkn0630:1583644:1583757 [2] NCCL INFO Connected all trees
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [send] via NET/IBext/0
310: hkn0630:1583644:1583757 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
310: hkn0630:1583644:1583757 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
166: hkn0521:1182970:1183090 [2] NCCL INFO Channel 01 : 166[ca000] -> 167[e3000] via P2P/IPC/read
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [receive] via NET/IBext/0
178: hkn0525:972003:972097 [2] NCCL INFO Channel 01 : 178[ca000] -> 179[e3000] via P2P/IPC/read
340: hkn0704:777158:777265 [0] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [receive] via NET/IBext/0
309: hkn0630:1583628:1583756 [1] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [receive] via NET/IBext/0
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [receive] via NET/IBext/0
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [send] via NET/IBext/0
252: hkn0611:694973:695080 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [receive] via NET/IBext/0
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [receive] via NET/IBext/0
167: hkn0521:1182990:1183086 [3] NCCL INFO Connected all trees
167: hkn0521:1182990:1183086 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
179: hkn0525:971983:972104 [3] NCCL INFO Connected all trees
167: hkn0521:1182990:1183086 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
179: hkn0525:971983:972104 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 00 : 209[4b000] -> 208[31000] via P2P/IPC/read
166: hkn0521:1182970:1183090 [2] NCCL INFO Connected all trees
166: hkn0521:1182970:1183090 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
179: hkn0525:971983:972104 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
166: hkn0521:1182970:1183090 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
178: hkn0525:972003:972097 [2] NCCL INFO Connected all trees
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [receive] via NET/IBext/0
178: hkn0525:972003:972097 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
165: hkn0521:1182962:1183092 [1] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [receive] via NET/IBext/0
178: hkn0525:972003:972097 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
100: hkn0502:214212:214345 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [send] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [send] via NET/IBext/0
265: hkn0615:399447:399552 [1] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [send] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [receive] via NET/IBext/0
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [send] via NET/IBext/0
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [send] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [send] via NET/IBext/0
176: hkn0525:971975:972098 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [send] via NET/IBext/0
177: hkn0525:971991:972103 [1] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [receive] via NET/IBext/0
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 01 : 212[31000] -> 213[4b000] via P2P/IPC/read
176: hkn0525:971975:972098 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [send] via NET/IBext/0
202: hkn0531:1215712:1215824 [2] NCCL INFO Channel 01 : 202[ca000] -> 203[e3000] via P2P/IPC/read
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [send] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [receive] via NET/IBext/0
209: hkn0534:1133578:1133691 [1] NCCL INFO Channel 01 : 209[4b000] -> 208[31000] via P2P/IPC/read
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 00 : 273[4b000] -> 272[31000] via P2P/IPC/read
177: hkn0525:971991:972103 [1] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [send] via NET/IBext/0
213: hkn0535:2384189:2384302 [1] NCCL INFO Channel 00 : 213[4b000] -> 214[ca000] via P2P/IPC/read
177: hkn0525:971991:972103 [1] NCCL INFO Channel 00 : 177[4b000] -> 176[31000] via P2P/IPC/read
214: hkn0535:2384181:2384305 [2] NCCL INFO Channel 00 : 214[ca000] -> 215[e3000] via P2P/IPC/read
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [send] via NET/IBext/0
213: hkn0535:2384189:2384302 [1] NCCL INFO Channel 01 : 213[4b000] -> 214[ca000] via P2P/IPC/read
177: hkn0525:971991:972103 [1] NCCL INFO Channel 01 : 177[4b000] -> 176[31000] via P2P/IPC/read
214: hkn0535:2384181:2384305 [2] NCCL INFO Channel 01 : 214[ca000] -> 215[e3000] via P2P/IPC/read
215: hkn0535:2384173:2384300 [3] NCCL INFO Connected all trees
203: hkn0531:1215704:1215819 [3] NCCL INFO Connected all trees
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 00 : 433[4b000] -> 432[31000] via P2P/IPC/read
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [send] via NET/IBext/0
215: hkn0535:2384173:2384300 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
203: hkn0531:1215704:1215819 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [send] via NET/IBext/0
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [send] via NET/IBext/0
215: hkn0535:2384173:2384300 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
203: hkn0531:1215704:1215819 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [send] via NET/IBext/0
214: hkn0535:2384181:2384305 [2] NCCL INFO Connected all trees
214: hkn0535:2384181:2384305 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
202: hkn0531:1215712:1215824 [2] NCCL INFO Connected all trees
273: hkn0617:2279794:2279887 [1] NCCL INFO Channel 01 : 273[4b000] -> 272[31000] via P2P/IPC/read
214: hkn0535:2384181:2384305 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:340644:340742 [0] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [receive] via NET/IBext/0
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [receive] via NET/IBext/0
213: hkn0535:2384189:2384302 [1] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [receive] via NET/IBext/0
202: hkn0531:1215712:1215824 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [send] via NET/IBext/0
202: hkn0531:1215712:1215824 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 00 : 145[4b000] -> 144[31000] via P2P/IPC/read
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [receive] via NET/IBext/0
336: hkn0703:726160:726259 [0] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [send] via NET/IBext/0
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [send] via NET/IBext/0
433: hkn0730:1386894:1387025 [1] NCCL INFO Channel 01 : 433[4b000] -> 432[31000] via P2P/IPC/read
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [receive] via NET/IBext/0
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [send] via NET/IBext/0
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [receive] via NET/IBext/0
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [send] via NET/IBext/0
191: hkn0528:1286875:1286972 [3] NCCL INFO Connected all trees
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [receive] via NET/IBext/0
118: hkn0506:823201:823314 [2] NCCL INFO Channel 01 : 118[ca000] -> 119[e3000] via P2P/IPC/read
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 00 : 305[4b000] -> 304[31000] via P2P/IPC/read
191: hkn0528:1286875:1286972 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [send] via NET/IBext/0
191: hkn0528:1286875:1286972 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
190: hkn0528:1286863:1286971 [2] NCCL INFO Connected all trees
119: hkn0506:823213:823305 [3] NCCL INFO Connected all trees
190: hkn0528:1286863:1286971 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
119: hkn0506:823213:823305 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:280251:280359 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [receive] via NET/IBext/0
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [send] via NET/IBext/0
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 00 : 17[4b000] -> 16[31000] via P2P/IPC/read
190: hkn0528:1286863:1286971 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
145: hkn0513:2998098:2998200 [1] NCCL INFO Channel 01 : 145[4b000] -> 144[31000] via P2P/IPC/read
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [receive] via NET/IBext/0
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [send] via NET/IBext/0
119: hkn0506:823213:823305 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [send] via NET/IBext/0
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [receive] via NET/IBext/0
465: hkn0803:861667:861779 [1] NCCL INFO Channel 00 : 465[4b000] -> 464[31000] via P2P/IPC/read
118: hkn0506:823201:823314 [2] NCCL INFO Connected all trees
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [send] via NET/IBext/0
118: hkn0506:823201:823314 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:955851:955982 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [receive] via NET/IBext/0
118: hkn0506:823201:823314 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
116: hkn0506:823193:823308 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [receive] via NET/IBext/0
143: hkn0512:3029310:3029418 [3] NCCL INFO Connected all trees
305: hkn0629:1577194:1577306 [1] NCCL INFO Channel 01 : 305[4b000] -> 304[31000] via P2P/IPC/read
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [send] via NET/IBext/0
117: hkn0506:823185:823311 [1] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [receive] via NET/IBext/0
143: hkn0512:3029310:3029418 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:823193:823308 [0] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [send] via NET/IBext/0
143: hkn0512:3029310:3029418 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 17: hkn0408:2875824:2875937 [1] NCCL INFO Channel 01 : 17[4b000] -> 16[31000] via P2P/IPC/read
116: hkn0506:823193:823308 [0] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [receive] via NET/IBext/0
142: hkn0512:3029322:3029415 [2] NCCL INFO Connected all trees
 62: hkn0420:3195366:3195465 [2] NCCL INFO Channel 01 : 62[ca000] -> 63[e3000] via P2P/IPC/read
142: hkn0512:3029322:3029415 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 00 : 97[4b000] -> 98[ca000] via P2P/IPC/read
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [send] via NET/IBext/0
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [send] via NET/IBext/0
142: hkn0512:3029322:3029415 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 63: hkn0420:3195346:3195463 [3] NCCL INFO Connected all trees
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [receive] via NET/IBext/0
 63: hkn0420:3195346:3195463 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [send] via NET/IBext/0
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [send] via NET/IBext/0
345: hkn0705:768401:768516 [1] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [send] via NET/IBext/0
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [send] via NET/IBext/0
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [receive] via NET/IBext/0
 63: hkn0420:3195346:3195463 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 62: hkn0420:3195366:3195465 [2] NCCL INFO Connected all trees
 98: hkn0501:1312966:1313101 [2] NCCL INFO Channel 00 : 98[ca000] -> 99[e3000] via P2P/IPC/read
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [send] via NET/IBext/0
 62: hkn0420:3195366:3195465 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 62: hkn0420:3195366:3195465 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 01 : 97[4b000] -> 98[ca000] via P2P/IPC/read
465: hkn0803:861667:861779 [1] NCCL INFO Channel 01 : 465[4b000] -> 464[31000] via P2P/IPC/read
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [receive] via NET/IBext/0
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [send] via NET/IBext/0
 98: hkn0501:1312966:1313101 [2] NCCL INFO Channel 01 : 98[ca000] -> 99[e3000] via P2P/IPC/read
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [send] via NET/IBext/0
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [receive] via NET/IBext/0
 99: hkn0501:1312982:1313098 [3] NCCL INFO Connected all trees
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 00 : 193[4b000] -> 194[ca000] via P2P/IPC/read
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [send] via NET/IBext/0
 99: hkn0501:1312982:1313098 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:455428:455539 [0] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [receive] via NET/IBext/0
217: hkn0601:102836:102938 [1] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [send] via NET/IBext/0
 99: hkn0501:1312982:1313098 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
194: hkn0529:1526011:1526128 [2] NCCL INFO Channel 00 : 194[ca000] -> 195[e3000] via P2P/IPC/read
 98: hkn0501:1312966:1313101 [2] NCCL INFO Connected all trees
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 01 : 193[4b000] -> 194[ca000] via P2P/IPC/read
 98: hkn0501:1312966:1313101 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
194: hkn0529:1526011:1526128 [2] NCCL INFO Channel 01 : 194[ca000] -> 195[e3000] via P2P/IPC/read
 98: hkn0501:1312966:1313101 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
195: hkn0529:1526003:1526130 [3] NCCL INFO Connected all trees
344: hkn0705:768421:768521 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [send] via NET/IBext/0
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [send] via NET/IBext/0
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [receive] via NET/IBext/0
195: hkn0529:1526003:1526130 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:674438:674558 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [receive] via NET/IBext/0
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [send] via NET/IBext/0
195: hkn0529:1526003:1526130 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
134: hkn0510:2747248:2747351 [2] NCCL INFO Channel 01 : 134[ca000] -> 135[e3000] via P2P/IPC/read
194: hkn0529:1526011:1526128 [2] NCCL INFO Connected all trees
170: hkn0523:1533170:1533292 [2] NCCL INFO Channel 01 : 170[ca000] -> 171[e3000] via P2P/IPC/read
194: hkn0529:1526011:1526128 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
135: hkn0510:2747228:2747349 [3] NCCL INFO Connected all trees
464: hkn0803:861669:861771 [0] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [receive] via NET/IBext/0
194: hkn0529:1526011:1526128 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:417195:417320 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [send] via NET/IBext/0
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [receive] via NET/IBext/0
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [receive] via NET/IBext/0
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [receive] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [receive] via NET/IBext/0
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [send] via NET/IBext/0
216: hkn0601:102816:102929 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [send] via NET/IBext/0
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [send] via NET/IBext/0
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [receive] via NET/IBext/0
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [receive] via NET/IBext/0
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [send] via NET/IBext/0
135: hkn0510:2747228:2747349 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
135: hkn0510:2747228:2747349 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
171: hkn0523:1533178:1533297 [3] NCCL INFO Connected all trees
134: hkn0510:2747248:2747351 [2] NCCL INFO Connected all trees
171: hkn0523:1533178:1533297 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:971975:972098 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [receive] via NET/IBext/0
134: hkn0510:2747248:2747351 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
134: hkn0510:2747248:2747351 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
171: hkn0523:1533178:1533297 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:398416:398525 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [send] via NET/IBext/0
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [receive] via NET/IBext/0
133: hkn0510:2747236:2747343 [1] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [receive] via NET/IBext/0
170: hkn0523:1533170:1533292 [2] NCCL INFO Connected all trees
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [send] via NET/IBext/0
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [send] via NET/IBext/0
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [send] via NET/IBext/0
170: hkn0523:1533170:1533292 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [receive] via NET/IBext/0
170: hkn0523:1533170:1533292 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [send] via NET/IBext/0
182: hkn0526:1413581:1413675 [2] NCCL INFO Channel 01 : 182[ca000] -> 183[e3000] via P2P/IPC/read
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 00 : 113[4b000] -> 112[31000] via P2P/IPC/read
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [receive] via NET/IBext/0
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [send] via NET/IBext/0
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [send] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [receive] via NET/IBext/0
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [receive] via NET/IBext/0
232: hkn0605:697242:697386 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [receive] via NET/IBext/0
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [send] via NET/IBext/0
183: hkn0526:1413553:1413678 [3] NCCL INFO Connected all trees
290: hkn0624:1758086:1758202 [2] NCCL INFO Channel 01 : 290[ca000] -> 291[e3000] via P2P/IPC/read
183: hkn0526:1413553:1413678 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 01 : 49[4b000] -> 50[ca000] via P2P/IPC/read
183: hkn0526:1413553:1413678 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
291: hkn0624:1758078:1758198 [3] NCCL INFO Connected all trees
182: hkn0526:1413581:1413675 [2] NCCL INFO Connected all trees
291: hkn0624:1758078:1758198 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
182: hkn0526:1413581:1413675 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
291: hkn0624:1758078:1758198 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
249: hkn0609:696028:696150 [1] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [send] via NET/IBext/0
182: hkn0526:1413581:1413675 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
337: hkn0703:726148:726258 [1] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [send] via NET/IBext/0
269: hkn0616:389977:390103 [1] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [receive] via NET/IBext/0
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [send] via NET/IBext/0
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [receive] via NET/IBext/0
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [receive] via NET/IBext/0
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [send] via NET/IBext/0
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [send] via NET/IBext/0
113: hkn0505:2288949:2289068 [1] NCCL INFO Channel 01 : 113[4b000] -> 112[31000] via P2P/IPC/read
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [receive] via NET/IBext/0
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [send] via NET/IBext/0
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [receive] via NET/IBext/0
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [receive] via NET/IBext/0
181: hkn0526:1413569:1413673 [1] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [receive] via NET/IBext/0
290: hkn0624:1758086:1758202 [2] NCCL INFO Connected all trees
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [send] via NET/IBext/0
290: hkn0624:1758086:1758202 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [receive] via NET/IBext/0
290: hkn0624:1758086:1758202 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [send] via NET/IBext/0
 50: hkn0417:2252730:2252862 [2] NCCL INFO Channel 01 : 50[ca000] -> 51[e3000] via P2P/IPC/read
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [receive] via NET/IBext/0
 51: hkn0417:2252746:2252861 [3] NCCL INFO Connected all trees
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [send] via NET/IBext/0
 51: hkn0417:2252746:2252861 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 00 : 81[4b000] -> 80[31000] via P2P/IPC/read
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [send] via NET/IBext/0
 51: hkn0417:2252746:2252861 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
279: hkn0621:1976627:1976741 [3] NCCL INFO Connected all trees
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [send] via NET/IBext/0
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [send] via NET/IBext/0
 50: hkn0417:2252730:2252862 [2] NCCL INFO Connected all trees
279: hkn0621:1976627:1976741 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 50: hkn0417:2252730:2252862 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
279: hkn0621:1976627:1976741 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 50: hkn0417:2252730:2252862 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
278: hkn0621:1976647:1976747 [2] NCCL INFO Connected all trees
369: hkn0712:280243:280361 [1] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [send] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [send] via NET/IBext/0
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [receive] via NET/IBext/0
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [receive] via NET/IBext/0
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [receive] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [send] via NET/IBext/0
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [receive] via NET/IBext/0
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [receive] via NET/IBext/0
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [send] via NET/IBext/0
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [send] via NET/IBext/0
377: hkn0714:417216:417317 [1] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [send] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [receive] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [receive] via NET/IBext/0
 81: hkn0425:2069090:2069201 [1] NCCL INFO Channel 01 : 81[4b000] -> 80[31000] via P2P/IPC/read
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [send] via NET/IBext/0
278: hkn0621:1976647:1976747 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 00 : 49[4b000] -> 48[31000] via P2P/IPC/read
278: hkn0621:1976647:1976747 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
301: hkn0628:657007:657097 [1] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [receive] via NET/IBext/0
 49: hkn0417:2252738:2252863 [1] NCCL INFO Channel 01 : 49[4b000] -> 48[31000] via P2P/IPC/read
361: hkn0710:340632:340748 [1] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [send] via NET/IBext/0
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [receive] via NET/IBext/0
248: hkn0609:696056:696155 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [send] via NET/IBext/0
277: hkn0621:1976619:1976745 [1] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [receive] via NET/IBext/0
264: hkn0615:399427:399550 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [receive] via NET/IBext/0
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [send] via NET/IBext/0
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [receive] via NET/IBext/0
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 01 : 84[31000] -> 85[4b000] via P2P/IPC/read
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [send] via NET/IBext/0
243: hkn0607:889506:889630 [3] NCCL INFO Connected all trees
 85: hkn0426:799266:799362 [1] NCCL INFO Channel 00 : 85[4b000] -> 86[ca000] via P2P/IPC/read
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 01 : 184[31000] -> 185[4b000] via P2P/IPC/read
 86: hkn0426:799246:799367 [2] NCCL INFO Channel 00 : 86[ca000] -> 87[e3000] via P2P/IPC/read
243: hkn0607:889506:889630 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [send] via NET/IBext/0
488: hkn0809:922553:922675 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [receive] via NET/IBext/0
 85: hkn0426:799266:799362 [1] NCCL INFO Channel 01 : 85[4b000] -> 86[ca000] via P2P/IPC/read
243: hkn0607:889506:889630 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 86: hkn0426:799246:799367 [2] NCCL INFO Channel 01 : 86[ca000] -> 87[e3000] via P2P/IPC/read
242: hkn0607:889522:889635 [2] NCCL INFO Connected all trees
 87: hkn0426:799254:799358 [3] NCCL INFO Connected all trees
242: hkn0607:889522:889635 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
109: hkn0504:25973:26092 [1] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [receive] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [send] via NET/IBext/0
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [send] via NET/IBext/0
 87: hkn0426:799254:799358 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 87: hkn0426:799254:799358 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
242: hkn0607:889522:889635 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:389997:390101 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [send] via NET/IBext/0
 86: hkn0426:799246:799367 [2] NCCL INFO Connected all trees
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [send] via NET/IBext/0
 86: hkn0426:799246:799367 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 86: hkn0426:799246:799367 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [receive] via NET/IBext/0
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [receive] via NET/IBext/0
 85: hkn0426:799266:799362 [1] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [receive] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [send] via NET/IBext/0
100: hkn0502:214212:214345 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [receive] via NET/IBext/0
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [send] via NET/IBext/0
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [receive] via NET/IBext/0
241: hkn0607:889514:889633 [1] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [receive] via NET/IBext/0
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [receive] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [send] via NET/IBext/0
241: hkn0607:889514:889633 [1] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [send] via NET/IBext/0
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 00 : 185[4b000] -> 186[ca000] via P2P/IPC/read
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [send] via NET/IBext/0
241: hkn0607:889514:889633 [1] NCCL INFO Channel 00 : 241[4b000] -> 240[31000] via P2P/IPC/read
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [receive] via NET/IBext/0
241: hkn0607:889514:889633 [1] NCCL INFO Channel 01 : 241[4b000] -> 240[31000] via P2P/IPC/read
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [receive] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [receive] via NET/IBext/0
186: hkn0527:1334041:1334160 [2] NCCL INFO Channel 00 : 186[ca000] -> 187[e3000] via P2P/IPC/read
149: hkn0514:2935893:2936011 [1] NCCL INFO Channel 01 : 149[4b000] -> 150[ca000] via P2P/IPC/read
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [receive] via NET/IBext/0
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 01 : 185[4b000] -> 186[ca000] via P2P/IPC/read
186: hkn0527:1334041:1334160 [2] NCCL INFO Channel 01 : 186[ca000] -> 187[e3000] via P2P/IPC/read
150: hkn0514:2935913:2936009 [2] NCCL INFO Channel 01 : 150[ca000] -> 151[e3000] via P2P/IPC/read
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [send] via NET/IBext/0
187: hkn0527:1334069:1334163 [3] NCCL INFO Connected all trees
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [receive] via NET/IBext/0
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [send] via NET/IBext/0
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [receive] via NET/IBext/0
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [receive] via NET/IBext/0
337: hkn0703:726148:726258 [1] NCCL INFO Channel 00 : 337[4b000] -> 336[31000] via P2P/IPC/read
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [receive] via NET/IBext/0
187: hkn0527:1334069:1334163 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
151: hkn0514:2935901:2936013 [3] NCCL INFO Connected all trees
187: hkn0527:1334069:1334163 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
151: hkn0514:2935901:2936013 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
186: hkn0527:1334041:1334160 [2] NCCL INFO Connected all trees
151: hkn0514:2935901:2936013 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [receive] via NET/IBext/0
186: hkn0527:1334041:1334160 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
186: hkn0527:1334041:1334160 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
150: hkn0514:2935913:2936009 [2] NCCL INFO Connected all trees
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [send] via NET/IBext/0
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [send] via NET/IBext/0
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [send] via NET/IBext/0
150: hkn0514:2935913:2936009 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [receive] via NET/IBext/0
150: hkn0514:2935913:2936009 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [receive] via NET/IBext/0
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [receive] via NET/IBext/0
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [send] via NET/IBext/0
149: hkn0514:2935893:2936011 [1] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [receive] via NET/IBext/0
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [send] via NET/IBext/0
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [send] via NET/IBext/0
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [receive] via NET/IBext/0
174: hkn0524:1118942:1119055 [2] NCCL INFO Channel 01 : 174[ca000] -> 175[e3000] via P2P/IPC/read
337: hkn0703:726148:726258 [1] NCCL INFO Channel 01 : 337[4b000] -> 336[31000] via P2P/IPC/read
116: hkn0506:823193:823308 [0] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [send] via NET/IBext/0
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 00 : 481[4b000] -> 480[31000] via P2P/IPC/read
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [send] via NET/IBext/0
260: hkn0613:887844:887968 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [receive] via NET/IBext/0
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [send] via NET/IBext/0
336: hkn0703:726160:726259 [0] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [receive] via NET/IBext/0
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [send] via NET/IBext/0
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [send] via NET/IBext/0
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 00 : 161[4b000] -> 160[31000] via P2P/IPC/read
108: hkn0504:25965:26094 [0] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [receive] via NET/IBext/0
175: hkn0524:1118950:1119063 [3] NCCL INFO Connected all trees
205: hkn0532:908774:909097 [1] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [receive] via NET/IBext/0
175: hkn0524:1118950:1119063 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
175: hkn0524:1118950:1119063 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 01 : 124[31000] -> 125[4b000] via P2P/IPC/read
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [send] via NET/IBext/0
174: hkn0524:1118942:1119055 [2] NCCL INFO Connected all trees
174: hkn0524:1118942:1119055 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
174: hkn0524:1118942:1119055 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
126: hkn0508:3124297:3124412 [2] NCCL INFO Channel 01 : 126[ca000] -> 127[e3000] via P2P/IPC/read
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [receive] via NET/IBext/0
127: hkn0508:3124313:3124406 [3] NCCL INFO Connected all trees
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [send] via NET/IBext/0
127: hkn0508:3124313:3124406 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:777158:777265 [0] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [send] via NET/IBext/0
369: hkn0712:280243:280361 [1] NCCL INFO Channel 00 : 369[4b000] -> 368[31000] via P2P/IPC/read
244: hkn0608:470923:471037 [0] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [send] via NET/IBext/0
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [receive] via NET/IBext/0
481: hkn0807:1004271:1004387 [1] NCCL INFO Channel 01 : 481[4b000] -> 480[31000] via P2P/IPC/read
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [receive] via NET/IBext/0
127: hkn0508:3124313:3124406 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1324539:1324635 [2] NCCL INFO Channel 01 : 6[ca000] -> 7[e3000] via P2P/IPC/read
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [receive] via NET/IBext/0
161: hkn0520:2698015:2698119 [1] NCCL INFO Channel 01 : 161[4b000] -> 160[31000] via P2P/IPC/read
126: hkn0508:3124297:3124412 [2] NCCL INFO Connected all trees
  7: hkn0404:1324519:1324638 [3] NCCL INFO Connected all trees
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 00 : 397[4b000] -> 396[31000] via P2P/IPC/read
126: hkn0508:3124297:3124412 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:656995:657105 [0] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [receive] via NET/IBext/0
126: hkn0508:3124297:3124412 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
493: hkn0810:924720:924850 [1] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [receive] via NET/IBext/0
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 00 : 33[4b000] -> 32[31000] via P2P/IPC/read
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [receive] via NET/IBext/0
  7: hkn0404:1324519:1324638 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [send] via NET/IBext/0
  7: hkn0404:1324519:1324638 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [receive] via NET/IBext/0
  6: hkn0404:1324539:1324635 [2] NCCL INFO Connected all trees
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [receive] via NET/IBext/0
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [receive] via NET/IBext/0
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [receive] via NET/IBext/0
  6: hkn0404:1324539:1324635 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  6: hkn0404:1324539:1324635 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 00 : 329[4b000] -> 330[ca000] via P2P/IPC/read
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [receive] via NET/IBext/0
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 01 : 328[31000] -> 329[4b000] via P2P/IPC/read
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [receive] via NET/IBext/0
  5: hkn0404:1324527:1324632 [1] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [receive] via NET/IBext/0
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [receive] via NET/IBext/0
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [receive] via NET/IBext/0
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [receive] via NET/IBext/0
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [send] via NET/IBext/0
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [send] via NET/IBext/0
330: hkn0635:1210755:1210867 [2] NCCL INFO Channel 00 : 330[ca000] -> 331[e3000] via P2P/IPC/read
397: hkn0719:1290860:1290956 [1] NCCL INFO Channel 01 : 397[4b000] -> 396[31000] via P2P/IPC/read
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [send] via NET/IBext/0
 33: hkn0412:2247562:2247671 [1] NCCL INFO Channel 01 : 33[4b000] -> 32[31000] via P2P/IPC/read
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [send] via NET/IBext/0
369: hkn0712:280243:280361 [1] NCCL INFO Channel 01 : 369[4b000] -> 368[31000] via P2P/IPC/read
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [send] via NET/IBext/0
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [receive] via NET/IBext/0
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 01 : 329[4b000] -> 330[ca000] via P2P/IPC/read
330: hkn0635:1210755:1210867 [2] NCCL INFO Channel 01 : 330[ca000] -> 331[e3000] via P2P/IPC/read
138: hkn0511:3051491:3051603 [2] NCCL INFO Channel 01 : 138[ca000] -> 139[e3000] via P2P/IPC/read
331: hkn0635:1210773:1210865 [3] NCCL INFO Connected all trees
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 01 : 76[31000] -> 77[4b000] via P2P/IPC/read
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [send] via NET/IBext/0
331: hkn0635:1210773:1210865 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
331: hkn0635:1210773:1210865 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
139: hkn0511:3051483:3051604 [3] NCCL INFO Connected all trees
330: hkn0635:1210755:1210867 [2] NCCL INFO Connected all trees
139: hkn0511:3051483:3051604 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
269: hkn0616:389977:390103 [1] NCCL INFO Channel 00 : 269[4b000] -> 268[31000] via P2P/IPC/read
330: hkn0635:1210755:1210867 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
365: hkn0711:569034:569157 [1] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [receive] via NET/IBext/0
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [receive] via NET/IBext/0
330: hkn0635:1210755:1210867 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
139: hkn0511:3051483:3051604 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [send] via NET/IBext/0
138: hkn0511:3051491:3051603 [2] NCCL INFO Connected all trees
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [receive] via NET/IBext/0
138: hkn0511:3051491:3051603 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [send] via NET/IBext/0
138: hkn0511:3051491:3051603 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [receive] via NET/IBext/0
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [receive] via NET/IBext/0
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [receive] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [send] via NET/IBext/0
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [send] via NET/IBext/0
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [receive] via NET/IBext/0
368: hkn0712:280251:280359 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [send] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [send] via NET/IBext/0
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 00 : 461[4b000] -> 460[31000] via P2P/IPC/read
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [receive] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [send] via NET/IBext/0
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [send] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [receive] via NET/IBext/0
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 00 : 77[4b000] -> 78[ca000] via P2P/IPC/read
269: hkn0616:389977:390103 [1] NCCL INFO Channel 01 : 269[4b000] -> 268[31000] via P2P/IPC/read
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 01 : 77[4b000] -> 78[ca000] via P2P/IPC/read
 78: hkn0424:2933089:2933240 [2] NCCL INFO Channel 00 : 78[ca000] -> 79[e3000] via P2P/IPC/read
198: hkn0530:1243309:1243429 [2] NCCL INFO Channel 01 : 198[ca000] -> 199[e3000] via P2P/IPC/read
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 00 : 225[4b000] -> 224[31000] via P2P/IPC/read
 78: hkn0424:2933089:2933240 [2] NCCL INFO Channel 01 : 78[ca000] -> 79[e3000] via P2P/IPC/read
 79: hkn0424:2933081:2933238 [3] NCCL INFO Connected all trees
199: hkn0530:1243337:1243436 [3] NCCL INFO Connected all trees
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [receive] via NET/IBext/0
 79: hkn0424:2933081:2933238 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [receive] via NET/IBext/0
 79: hkn0424:2933081:2933238 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 78: hkn0424:2933089:2933240 [2] NCCL INFO Connected all trees
199: hkn0530:1243337:1243436 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [send] via NET/IBext/0
 78: hkn0424:2933089:2933240 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:398416:398525 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [receive] via NET/IBext/0
 78: hkn0424:2933089:2933240 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [receive] via NET/IBext/0
199: hkn0530:1243337:1243436 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
461: hkn0802:1185499:1185610 [1] NCCL INFO Channel 01 : 461[4b000] -> 460[31000] via P2P/IPC/read
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [send] via NET/IBext/0
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 00 : 141[4b000] -> 140[31000] via P2P/IPC/read
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [receive] via NET/IBext/0
198: hkn0530:1243309:1243429 [2] NCCL INFO Connected all trees
502: hkn0814:660989:661111 [2] NCCL INFO Connected all rings
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [send] via NET/IBext/0
198: hkn0530:1243309:1243429 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [receive] via NET/IBext/0
198: hkn0530:1243309:1243429 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:908782:909098 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [send] via NET/IBext/0
225: hkn0603:1398307:1398426 [1] NCCL INFO Channel 01 : 225[4b000] -> 224[31000] via P2P/IPC/read
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [receive] via NET/IBext/0
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [receive] via NET/IBext/0
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [receive] via NET/IBext/0
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [receive] via NET/IBext/0
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [send] via NET/IBext/0
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [receive] via NET/IBext/0
197: hkn0530:1243325:1243432 [1] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [receive] via NET/IBext/0
501: hkn0814:661009:661108 [1] NCCL INFO Channel 00 : 501[4b000] -> 502[ca000] via P2P/IPC/read
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [send] via NET/IBext/0
502: hkn0814:660989:661111 [2] NCCL INFO Channel 00 : 502[ca000] -> 503[e3000] via P2P/IPC/read
372: hkn0713:455428:455539 [0] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [send] via NET/IBext/0
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [send] via NET/IBext/0
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [receive] via NET/IBext/0
501: hkn0814:661009:661108 [1] NCCL INFO Channel 01 : 501[4b000] -> 502[ca000] via P2P/IPC/read
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 00 : 45[4b000] -> 44[31000] via P2P/IPC/read
502: hkn0814:660989:661111 [2] NCCL INFO Channel 01 : 502[ca000] -> 503[e3000] via P2P/IPC/read
141: hkn0512:3029294:3029422 [1] NCCL INFO Channel 01 : 141[4b000] -> 140[31000] via P2P/IPC/read
503: hkn0814:660981:661105 [3] NCCL INFO Connected all trees
503: hkn0814:660981:661105 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
443: hkn0732:1196831:1196956 [3] NCCL INFO Connected all trees
503: hkn0814:660981:661105 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
403: hkn0720:4181536:4181828 [3] NCCL INFO Connected all trees
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [receive] via NET/IBext/0
502: hkn0814:660989:661111 [2] NCCL INFO Connected all trees
301: hkn0628:657007:657097 [1] NCCL INFO Channel 00 : 301[4b000] -> 300[31000] via P2P/IPC/read
502: hkn0814:660989:661111 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
502: hkn0814:660989:661111 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
443: hkn0732:1196831:1196956 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
500: hkn0814:660997:661104 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [receive] via NET/IBext/0
443: hkn0732:1196831:1196956 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [send] via NET/IBext/0
501: hkn0814:661009:661108 [1] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [receive] via NET/IBext/0
500: hkn0814:660997:661104 [0] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [send] via NET/IBext/0
442: hkn0732:1196803:1196961 [2] NCCL INFO Connected all trees
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 00 : 13[4b000] -> 12[31000] via P2P/IPC/read
500: hkn0814:660997:661104 [0] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [receive] via NET/IBext/0
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [receive] via NET/IBext/0
500: hkn0814:660997:661104 [0] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [send] via NET/IBext/0
 45: hkn0415:2481516:2481618 [1] NCCL INFO Channel 01 : 45[4b000] -> 44[31000] via P2P/IPC/read
442: hkn0732:1196803:1196961 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
442: hkn0732:1196803:1196961 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
403: hkn0720:4181536:4181828 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [send] via NET/IBext/0
403: hkn0720:4181536:4181828 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:924748:924846 [0] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [send] via NET/IBext/0
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 00 : 353[4b000] -> 352[31000] via P2P/IPC/read
364: hkn0711:569026:569156 [0] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [receive] via NET/IBext/0
109: hkn0504:25973:26092 [1] NCCL INFO Channel 00 : 109[4b000] -> 108[31000] via P2P/IPC/read
301: hkn0628:657007:657097 [1] NCCL INFO Channel 01 : 301[4b000] -> 300[31000] via P2P/IPC/read
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [receive] via NET/IBext/0
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [send] via NET/IBext/0
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [receive] via NET/IBext/0
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 00 : 289[4b000] -> 288[31000] via P2P/IPC/read
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [receive] via NET/IBext/0
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [send] via NET/IBext/0
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [send] via NET/IBext/0
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [receive] via NET/IBext/0
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [send] via NET/IBext/0
 13: hkn0407:1801441:1801573 [1] NCCL INFO Channel 01 : 13[4b000] -> 12[31000] via P2P/IPC/read
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [send] via NET/IBext/0
402: hkn0720:4181548:4181824 [2] NCCL INFO Connected all trees
410: hkn0723:192937:193090 [2] NCCL INFO Channel 01 : 410[ca000] -> 411[e3000] via P2P/IPC/read
402: hkn0720:4181548:4181824 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:380357:380455 [0] NCCL INFO Channel 00 : 504[31000] -> 505[4b000] via P2P/IPC/read
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 00 : 97[4b000] -> 96[31000] via P2P/IPC/read
402: hkn0720:4181548:4181824 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [receive] via NET/IBext/0
411: hkn0723:192909:193084 [3] NCCL INFO Connected all trees
353: hkn0707:4005073:4005192 [1] NCCL INFO Channel 01 : 353[4b000] -> 352[31000] via P2P/IPC/read
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [receive] via NET/IBext/0
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [send] via NET/IBext/0
411: hkn0723:192909:193084 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
109: hkn0504:25973:26092 [1] NCCL INFO Channel 01 : 109[4b000] -> 108[31000] via P2P/IPC/read
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [send] via NET/IBext/0
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [receive] via NET/IBext/0
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 00 : 237[4b000] -> 236[31000] via P2P/IPC/read
176: hkn0525:971975:972098 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [send] via NET/IBext/0
289: hkn0624:1758098:1758200 [1] NCCL INFO Channel 01 : 289[4b000] -> 288[31000] via P2P/IPC/read
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 00 : 401[4b000] -> 400[31000] via P2P/IPC/read
411: hkn0723:192909:193084 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:4181528:4181827 [1] NCCL INFO Channel 01 : 401[4b000] -> 400[31000] via P2P/IPC/read
410: hkn0723:192937:193090 [2] NCCL INFO Connected all trees
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [send] via NET/IBext/0
410: hkn0723:192937:193090 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [receive] via NET/IBext/0
410: hkn0723:192937:193090 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:192917:193087 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [send] via NET/IBext/0
504: hkn0815:380357:380455 [0] NCCL INFO Channel 01 : 504[31000] -> 505[4b000] via P2P/IPC/read
 97: hkn0501:1312996:1313099 [1] NCCL INFO Channel 01 : 97[4b000] -> 96[31000] via P2P/IPC/read
409: hkn0723:192925:193085 [1] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [receive] via NET/IBext/0
464: hkn0803:861669:861771 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [receive] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [receive] via NET/IBext/0
409: hkn0723:192925:193085 [1] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [send] via NET/IBext/0
505: hkn0815:380329:380451 [1] NCCL INFO Channel 00 : 505[4b000] -> 506[ca000] via P2P/IPC/read
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [send] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [send] via NET/IBext/0
268: hkn0616:389997:390101 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [receive] via NET/IBext/0
506: hkn0815:380337:380459 [2] NCCL INFO Channel 00 : 506[ca000] -> 507[e3000] via P2P/IPC/read
237: hkn0606:2357183:2357320 [1] NCCL INFO Channel 01 : 237[4b000] -> 236[31000] via P2P/IPC/read
505: hkn0815:380329:380451 [1] NCCL INFO Channel 01 : 505[4b000] -> 506[ca000] via P2P/IPC/read
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [receive] via NET/IBext/0
506: hkn0815:380337:380459 [2] NCCL INFO Channel 01 : 506[ca000] -> 507[e3000] via P2P/IPC/read
507: hkn0815:380345:380457 [3] NCCL INFO Connected all trees
507: hkn0815:380345:380457 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
431: hkn0728:1309090:1309203 [3] NCCL INFO Connected all trees
205: hkn0532:908774:909097 [1] NCCL INFO Channel 00 : 205[4b000] -> 204[31000] via P2P/IPC/read
507: hkn0815:380345:380457 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
506: hkn0815:380337:380459 [2] NCCL INFO Connected all trees
431: hkn0728:1309090:1309203 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [send] via NET/IBext/0
506: hkn0815:380337:380459 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:380337:380459 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
431: hkn0728:1309090:1309203 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [receive] via NET/IBext/0
504: hkn0815:380357:380455 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [send] via NET/IBext/0
360: hkn0710:340644:340742 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [receive] via NET/IBext/0
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 00 : 449[4b000] -> 448[31000] via P2P/IPC/read
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [send] via NET/IBext/0
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 00 : 333[4b000] -> 332[31000] via P2P/IPC/read
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [receive] via NET/IBext/0
409: hkn0723:192925:193085 [1] NCCL INFO Channel 00 : 409[4b000] -> 408[31000] via P2P/IPC/read
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [receive] via NET/IBext/0
505: hkn0815:380329:380451 [1] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [receive] via NET/IBext/0
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [send] via NET/IBext/0
504: hkn0815:380357:380455 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [receive] via NET/IBext/0
505: hkn0815:380329:380451 [1] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [send] via NET/IBext/0
430: hkn0728:1309110:1309210 [2] NCCL INFO Connected all trees
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [send] via NET/IBext/0
430: hkn0728:1309110:1309210 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:380357:380455 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [send] via NET/IBext/0
430: hkn0728:1309110:1309210 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
205: hkn0532:908774:909097 [1] NCCL INFO Channel 01 : 205[4b000] -> 204[31000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [receive] via NET/IBext/0
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [send] via NET/IBext/0
439: hkn0731:1371900:1372017 [3] NCCL INFO Connected all trees
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [receive] via NET/IBext/0
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [receive] via NET/IBext/0
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [receive] via NET/IBext/0
439: hkn0731:1371900:1372017 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 00 : 429[4b000] -> 428[31000] via P2P/IPC/read
439: hkn0731:1371900:1372017 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
429: hkn0728:1309098:1309209 [1] NCCL INFO Channel 01 : 429[4b000] -> 428[31000] via P2P/IPC/read
438: hkn0731:1371892:1372022 [2] NCCL INFO Connected all trees
409: hkn0723:192925:193085 [1] NCCL INFO Channel 01 : 409[4b000] -> 408[31000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [receive] via NET/IBext/0
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [receive] via NET/IBext/0
438: hkn0731:1371892:1372022 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
449: hkn0734:1141728:1141851 [1] NCCL INFO Channel 01 : 449[4b000] -> 448[31000] via P2P/IPC/read
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [receive] via NET/IBext/0
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [receive] via NET/IBext/0
333: hkn0636:1639334:1639456 [1] NCCL INFO Channel 01 : 333[4b000] -> 332[31000] via P2P/IPC/read
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [receive] via NET/IBext/0
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 00 : 441[4b000] -> 440[31000] via P2P/IPC/read
438: hkn0731:1371892:1372022 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
499: hkn0812:678941:679039 [3] NCCL INFO Connected all trees
116: hkn0506:823193:823308 [0] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [receive] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [receive] via NET/IBext/0
437: hkn0731:1371908:1372021 [1] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [receive] via NET/IBext/0
499: hkn0812:678941:679039 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [send] via NET/IBext/0
499: hkn0812:678941:679039 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [receive] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [receive] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [send] via NET/IBext/0
498: hkn0812:678929:679040 [2] NCCL INFO Connected all trees
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [send] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [receive] via NET/IBext/0
493: hkn0810:924720:924850 [1] NCCL INFO Channel 00 : 493[4b000] -> 492[31000] via P2P/IPC/read
498: hkn0812:678929:679040 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 00 : 281[4b000] -> 280[31000] via P2P/IPC/read
498: hkn0812:678929:679040 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 00 : 417[4b000] -> 416[31000] via P2P/IPC/read
496: hkn0812:678913:679036 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [send] via NET/IBext/0
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 00 : 173[4b000] -> 172[31000] via P2P/IPC/read
441: hkn0732:1196811:1196965 [1] NCCL INFO Channel 01 : 441[4b000] -> 440[31000] via P2P/IPC/read
244: hkn0608:470923:471037 [0] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [receive] via NET/IBext/0
497: hkn0812:678921:679031 [1] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [receive] via NET/IBext/0
496: hkn0812:678913:679036 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [send] via NET/IBext/0
508: hkn0816:360788:360900 [0] NCCL INFO Channel 01 : 508[31000] -> 509[4b000] via P2P/IPC/read
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [receive] via NET/IBext/0
497: hkn0812:678921:679031 [1] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [send] via NET/IBext/0
497: hkn0812:678921:679031 [1] NCCL INFO Channel 00 : 497[4b000] -> 496[31000] via P2P/IPC/read
509: hkn0816:360808:360905 [1] NCCL INFO Channel 00 : 509[4b000] -> 510[ca000] via P2P/IPC/read
497: hkn0812:678921:679031 [1] NCCL INFO Channel 01 : 497[4b000] -> 496[31000] via P2P/IPC/read
510: hkn0816:360796:360907 [2] NCCL INFO Channel 00 : 510[ca000] -> 511[e3000] via P2P/IPC/read
496: hkn0812:678913:679036 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [receive] via NET/IBext/0
509: hkn0816:360808:360905 [1] NCCL INFO Channel 01 : 509[4b000] -> 510[ca000] via P2P/IPC/read
496: hkn0812:678913:679036 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [send] via NET/IBext/0
510: hkn0816:360796:360907 [2] NCCL INFO Channel 01 : 510[ca000] -> 511[e3000] via P2P/IPC/read
365: hkn0711:569034:569157 [1] NCCL INFO Channel 00 : 365[4b000] -> 364[31000] via P2P/IPC/read
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [send] via NET/IBext/0
511: hkn0816:360780:360901 [3] NCCL INFO Connected all trees
493: hkn0810:924720:924850 [1] NCCL INFO Channel 01 : 493[4b000] -> 492[31000] via P2P/IPC/read
511: hkn0816:360780:360901 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2005573:2005694 [1] NCCL INFO Channel 01 : 281[4b000] -> 280[31000] via P2P/IPC/read
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [send] via NET/IBext/0
511: hkn0816:360780:360901 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 00 : 473[4b000] -> 472[31000] via P2P/IPC/read
510: hkn0816:360796:360907 [2] NCCL INFO Connected all trees
173: hkn0524:1118934:1119058 [1] NCCL INFO Channel 01 : 173[4b000] -> 172[31000] via P2P/IPC/read
510: hkn0816:360796:360907 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
417: hkn0725:3097090:3097194 [1] NCCL INFO Channel 01 : 417[4b000] -> 416[31000] via P2P/IPC/read
510: hkn0816:360796:360907 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:777158:777265 [0] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [receive] via NET/IBext/0
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 00 : 65[4b000] -> 64[31000] via P2P/IPC/read
508: hkn0816:360788:360900 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [receive] via NET/IBext/0
509: hkn0816:360808:360905 [1] NCCL INFO Channel 00 : 509[4b000] -> 508[31000] via P2P/IPC/read
509: hkn0816:360808:360905 [1] NCCL INFO Channel 01 : 509[4b000] -> 508[31000] via P2P/IPC/read
508: hkn0816:360788:360900 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [receive] via NET/IBext/0
508: hkn0816:360788:360900 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [send] via NET/IBext/0
365: hkn0711:569034:569157 [1] NCCL INFO Channel 01 : 365[4b000] -> 364[31000] via P2P/IPC/read
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [receive] via NET/IBext/0
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [receive] via NET/IBext/0
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 00 : 153[4b000] -> 152[31000] via P2P/IPC/read
473: hkn0805:1097263:1097382 [1] NCCL INFO Channel 01 : 473[4b000] -> 472[31000] via P2P/IPC/read
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 00 : 477[4b000] -> 476[31000] via P2P/IPC/read
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [send] via NET/IBext/0
 65: hkn0421:2163528:2163777 [1] NCCL INFO Channel 01 : 65[4b000] -> 64[31000] via P2P/IPC/read
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [receive] via NET/IBext/0
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [receive] via NET/IBext/0
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 00 : 321[4b000] -> 320[31000] via P2P/IPC/read
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [send] via NET/IBext/0
153: hkn0515:2881958:2882071 [1] NCCL INFO Channel 01 : 153[4b000] -> 152[31000] via P2P/IPC/read
108: hkn0504:25965:26094 [0] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [send] via NET/IBext/0
477: hkn0806:1039485:1039615 [1] NCCL INFO Channel 01 : 477[4b000] -> 476[31000] via P2P/IPC/read
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [receive] via NET/IBext/0
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [send] via NET/IBext/0
300: hkn0628:656995:657105 [0] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [send] via NET/IBext/0
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 00 : 313[4b000] -> 312[31000] via P2P/IPC/read
321: hkn0633:1511514:1511639 [1] NCCL INFO Channel 01 : 321[4b000] -> 320[31000] via P2P/IPC/read
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [send] via NET/IBext/0
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 00 : 25[4b000] -> 24[31000] via P2P/IPC/read
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [receive] via NET/IBext/0
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 00 : 57[4b000] -> 56[31000] via P2P/IPC/read
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [receive] via NET/IBext/0
500: hkn0814:660997:661104 [0] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [receive] via NET/IBext/0
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 00 : 221[4b000] -> 220[31000] via P2P/IPC/read
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 00 : 121[4b000] -> 120[31000] via P2P/IPC/read
313: hkn0631:1006972:1007066 [1] NCCL INFO Channel 01 : 313[4b000] -> 312[31000] via P2P/IPC/read
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [send] via NET/IBext/0
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [receive] via NET/IBext/0
372: hkn0713:455428:455539 [0] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [receive] via NET/IBext/0
 25: hkn0410:1144790:1144895 [1] NCCL INFO Channel 01 : 25[4b000] -> 24[31000] via P2P/IPC/read
336: hkn0703:726160:726259 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [receive] via NET/IBext/0
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [send] via NET/IBext/0
 57: hkn0419:1529484:1529583 [1] NCCL INFO Channel 01 : 57[4b000] -> 56[31000] via P2P/IPC/read
204: hkn0532:908782:909098 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [receive] via NET/IBext/0
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [receive] via NET/IBext/0
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [receive] via NET/IBext/0
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [receive] via NET/IBext/0
121: hkn0507:3172216:3172329 [1] NCCL INFO Channel 01 : 121[4b000] -> 120[31000] via P2P/IPC/read
221: hkn0602:3345235:3345487 [1] NCCL INFO Channel 01 : 221[4b000] -> 220[31000] via P2P/IPC/read
249: hkn0609:696028:696150 [1] NCCL INFO Channel 00 : 249[4b000] -> 248[31000] via P2P/IPC/read
492: hkn0810:924748:924846 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [send] via NET/IBext/0
345: hkn0705:768401:768516 [1] NCCL INFO Channel 00 : 345[4b000] -> 344[31000] via P2P/IPC/read
217: hkn0601:102836:102938 [1] NCCL INFO Channel 00 : 217[4b000] -> 216[31000] via P2P/IPC/read
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 00 : 157[4b000] -> 156[31000] via P2P/IPC/read
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [receive] via NET/IBext/0
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [send] via NET/IBext/0
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [send] via NET/IBext/0
249: hkn0609:696028:696150 [1] NCCL INFO Channel 01 : 249[4b000] -> 248[31000] via P2P/IPC/read
345: hkn0705:768401:768516 [1] NCCL INFO Channel 01 : 345[4b000] -> 344[31000] via P2P/IPC/read
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [receive] via NET/IBext/0
404: hkn0721:2284143:2284269 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [send] via NET/IBext/0
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [receive] via NET/IBext/0
217: hkn0601:102836:102938 [1] NCCL INFO Channel 01 : 217[4b000] -> 216[31000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [send] via NET/IBext/0
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [receive] via NET/IBext/0
157: hkn0516:2901164:2901294 [1] NCCL INFO Channel 01 : 157[4b000] -> 156[31000] via P2P/IPC/read
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [send] via NET/IBext/0
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [receive] via NET/IBext/0
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [receive] via NET/IBext/0
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [send] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [send] via NET/IBext/0
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [receive] via NET/IBext/0
505: hkn0815:380329:380451 [1] NCCL INFO Channel 00 : 505[4b000] -> 504[31000] via P2P/IPC/read
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [receive] via NET/IBext/0
364: hkn0711:569026:569156 [0] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [send] via NET/IBext/0
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [receive] via NET/IBext/0
377: hkn0714:417216:417317 [1] NCCL INFO Channel 00 : 377[4b000] -> 376[31000] via P2P/IPC/read
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [receive] via NET/IBext/0
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 00 : 93[4b000] -> 92[31000] via P2P/IPC/read
505: hkn0815:380329:380451 [1] NCCL INFO Channel 01 : 505[4b000] -> 504[31000] via P2P/IPC/read
276: hkn0621:1976635:1976739 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [send] via NET/IBext/0
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [receive] via NET/IBext/0
348: hkn0706:737455:737573 [0] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [receive] via NET/IBext/0
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [receive] via NET/IBext/0
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 00 : 185[4b000] -> 184[31000] via P2P/IPC/read
468: hkn0804:1190767:1190886 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [send] via NET/IBext/0
377: hkn0714:417216:417317 [1] NCCL INFO Channel 01 : 377[4b000] -> 376[31000] via P2P/IPC/read
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [receive] via NET/IBext/0
 93: hkn0428:652517:652634 [1] NCCL INFO Channel 01 : 93[4b000] -> 92[31000] via P2P/IPC/read
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [send] via NET/IBext/0
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 00 : 193[4b000] -> 192[31000] via P2P/IPC/read
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 00 : 285[4b000] -> 284[31000] via P2P/IPC/read
464: hkn0803:861669:861771 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [receive] via NET/IBext/0
349: hkn0706:737463:737570 [1] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [receive] via NET/IBext/0
144: hkn0513:2998090:2998209 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [receive] via NET/IBext/0
148: hkn0514:2935885:2936010 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [send] via NET/IBext/0
185: hkn0527:1334057:1334167 [1] NCCL INFO Channel 01 : 185[4b000] -> 184[31000] via P2P/IPC/read
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [receive] via NET/IBext/0
285: hkn0623:1857886:1858018 [1] NCCL INFO Channel 01 : 285[4b000] -> 284[31000] via P2P/IPC/read
193: hkn0529:1526023:1526124 [1] NCCL INFO Channel 01 : 193[4b000] -> 192[31000] via P2P/IPC/read
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [receive] via NET/IBext/0
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [receive] via NET/IBext/0
308: hkn0630:1583656:1583761 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [send] via NET/IBext/0
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [send] via NET/IBext/0
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [receive] via NET/IBext/0
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [send] via NET/IBext/0
 16: hkn0408:2875836:2875939 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [receive] via NET/IBext/0
 52: hkn0418:1854341:1854446 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [send] via NET/IBext/0
108: hkn0504:25965:26094 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [send] via NET/IBext/0
116: hkn0506:823193:823308 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [send] via NET/IBext/0
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 00 : 77[4b000] -> 76[31000] via P2P/IPC/read
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [receive] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [send] via NET/IBext/0
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [receive] via NET/IBext/0
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [send] via NET/IBext/0
300: hkn0628:656995:657105 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [send] via NET/IBext/0
 77: hkn0424:2933097:2933239 [1] NCCL INFO Channel 01 : 77[4b000] -> 76[31000] via P2P/IPC/read
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 00 : 29[4b000] -> 28[31000] via P2P/IPC/read
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [receive] via NET/IBext/0
340: hkn0704:777158:777265 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [send] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [receive] via NET/IBext/0
212: hkn0535:2384201:2384301 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [send] via NET/IBext/0
344: hkn0705:768421:768521 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [receive] via NET/IBext/0
385: hkn0716:93646:93761 [1] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [send] via NET/IBext/0
 29: hkn0411:2301040:2301137 [1] NCCL INFO Channel 01 : 29[4b000] -> 28[31000] via P2P/IPC/read
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [receive] via NET/IBext/0
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [receive] via NET/IBext/0
216: hkn0601:102816:102929 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [receive] via NET/IBext/0
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [send] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [send] via NET/IBext/0
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 00 : 413[4b000] -> 412[31000] via P2P/IPC/read
384: hkn0716:93645:93760 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [receive] via NET/IBext/0
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 00 : 129[4b000] -> 128[31000] via P2P/IPC/read
 20: hkn0409:2570878:2570976 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [send] via NET/IBext/0
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [send] via NET/IBext/0
413: hkn0724:1701132:1701247 [1] NCCL INFO Channel 01 : 413[4b000] -> 412[31000] via P2P/IPC/read
500: hkn0814:660997:661104 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [send] via NET/IBext/0
272: hkn0617:2279782:2279893 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [receive] via NET/IBext/0
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [receive] via NET/IBext/0
336: hkn0703:726160:726259 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [receive] via NET/IBext/0
129: hkn0509:3109564:3109680 [1] NCCL INFO Channel 01 : 129[4b000] -> 128[31000] via P2P/IPC/read
372: hkn0713:455428:455539 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [send] via NET/IBext/0
 80: hkn0425:2069098:2069207 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [receive] via NET/IBext/0
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [receive] via NET/IBext/0
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [send] via NET/IBext/0
236: hkn0606:2357167:2357319 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [send] via NET/IBext/0
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [send] via NET/IBext/0
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [send] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [receive] via NET/IBext/0
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 00 : 445[4b000] -> 444[31000] via P2P/IPC/read
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [receive] via NET/IBext/0
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [receive] via NET/IBext/0
180: hkn0526:1413561:1413674 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [send] via NET/IBext/0
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [send] via NET/IBext/0
484: hkn0808:955851:955982 [0] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [receive] via NET/IBext/0
445: hkn0733:1374570:1374664 [1] NCCL INFO Channel 01 : 445[4b000] -> 444[31000] via P2P/IPC/read
385: hkn0716:93646:93761 [1] NCCL INFO Channel 00 : 385[4b000] -> 384[31000] via P2P/IPC/read
349: hkn0706:737463:737570 [1] NCCL INFO Channel 00 : 349[4b000] -> 348[31000] via P2P/IPC/read
416: hkn0725:3097110:3097192 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [receive] via NET/IBext/0
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [receive] via NET/IBext/0
172: hkn0524:1118962:1119061 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [send] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [receive] via NET/IBext/0
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [receive] via NET/IBext/0
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [send] via NET/IBext/0
400: hkn0720:4181520:4181819 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [receive] via NET/IBext/0
385: hkn0716:93646:93761 [1] NCCL INFO Channel 01 : 385[4b000] -> 384[31000] via P2P/IPC/read
145: hkn0513:2998098:2998200 [1] NCCL INFO Connected all trees
145: hkn0513:2998098:2998200 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:861667:861779 [1] NCCL INFO Connected all trees
145: hkn0513:2998098:2998200 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:861667:861779 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
465: hkn0803:861667:861779 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:569026:569156 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [send] via NET/IBext/0
144: hkn0513:2998090:2998209 [0] NCCL INFO Connected all trees
464: hkn0803:861669:861771 [0] NCCL INFO Connected all trees
144: hkn0513:2998090:2998209 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
464: hkn0803:861669:861771 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
144: hkn0513:2998090:2998209 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
349: hkn0706:737463:737570 [1] NCCL INFO Channel 01 : 349[4b000] -> 348[31000] via P2P/IPC/read
464: hkn0803:861669:861771 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:674438:674558 [0] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [receive] via NET/IBext/0
145: hkn0513:2998098:2998200 [1] NCCL INFO comm 0x152d04008fb0 rank 145 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
144: hkn0513:2998090:2998209 [0] NCCL INFO comm 0x154738008fb0 rank 144 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
464: hkn0803:861669:861771 [0] NCCL INFO comm 0x14d7cc008fb0 rank 464 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
146: hkn0513:2998110:2998204 [2] NCCL INFO comm 0x154a10008fb0 rank 146 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
465: hkn0803:861667:861779 [1] NCCL INFO comm 0x146ea0008fb0 rank 465 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
147: hkn0513:2998082:2998206 [3] NCCL INFO comm 0x14cd6c008fb0 rank 147 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
466: hkn0803:861668:861780 [2] NCCL INFO comm 0x148ef4008fb0 rank 466 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
467: hkn0803:861681:861778 [3] NCCL INFO comm 0x147044008fb0 rank 467 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [send] via NET/IBext/0
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [receive] via NET/IBext/0
493: hkn0810:924720:924850 [1] NCCL INFO Connected all trees
493: hkn0810:924720:924850 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:924720:924850 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2247570:2247665 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [receive] via NET/IBext/0
108: hkn0504:25965:26094 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [send] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO Connected all trees
489: hkn0809:922561:922677 [1] NCCL INFO Channel 00 : 489[4b000] -> 488[31000] via P2P/IPC/read
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [receive] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [receive] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [receive] via NET/IBext/0
492: hkn0810:924748:924846 [0] NCCL INFO comm 0x149430008fb0 rank 492 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [receive] via NET/IBext/0
300: hkn0628:656995:657105 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [send] via NET/IBext/0
495: hkn0810:924736:924852 [3] NCCL INFO comm 0x1532f4008fb0 rank 495 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
493: hkn0810:924720:924850 [1] NCCL INFO comm 0x14af04008fb0 rank 493 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
494: hkn0810:924728:924849 [2] NCCL INFO comm 0x14cb24008fb0 rank 494 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
489: hkn0809:922561:922677 [1] NCCL INFO Channel 01 : 489[4b000] -> 488[31000] via P2P/IPC/read
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 00 : 89[4b000] -> 88[31000] via P2P/IPC/read
209: hkn0534:1133578:1133691 [1] NCCL INFO Connected all trees
209: hkn0534:1133578:1133691 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
209: hkn0534:1133578:1133691 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
237: hkn0606:2357183:2357320 [1] NCCL INFO Connected all trees
237: hkn0606:2357183:2357320 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
237: hkn0606:2357183:2357320 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
208: hkn0534:1133577:1133694 [0] NCCL INFO Connected all trees
208: hkn0534:1133577:1133694 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1133577:1133694 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [receive] via NET/IBext/0
 89: hkn0427:1120325:1120445 [1] NCCL INFO Channel 01 : 89[4b000] -> 88[31000] via P2P/IPC/read
233: hkn0605:697262:697393 [1] NCCL INFO Channel 00 : 233[4b000] -> 232[31000] via P2P/IPC/read
236: hkn0606:2357167:2357319 [0] NCCL INFO Connected all trees
236: hkn0606:2357167:2357319 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
236: hkn0606:2357167:2357319 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [send] via NET/IBext/0
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [send] via NET/IBext/0
348: hkn0706:737455:737573 [0] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [send] via NET/IBext/0
208: hkn0534:1133577:1133694 [0] NCCL INFO comm 0x14b4a0008fb0 rank 208 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
210: hkn0534:1133593:1133689 [2] NCCL INFO comm 0x149a58008fb0 rank 210 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
211: hkn0534:1133581:1133690 [3] NCCL INFO comm 0x150db4008fb0 rank 211 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
236: hkn0606:2357167:2357319 [0] NCCL INFO comm 0x15129c008fb0 rank 236 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
209: hkn0534:1133578:1133691 [1] NCCL INFO comm 0x14de34008fb0 rank 209 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
288: hkn0624:1758070:1758195 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [receive] via NET/IBext/0
233: hkn0605:697262:697393 [1] NCCL INFO Channel 01 : 233[4b000] -> 232[31000] via P2P/IPC/read
237: hkn0606:2357183:2357320 [1] NCCL INFO comm 0x1548ac008fb0 rank 237 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
238: hkn0606:2357175:2357324 [2] NCCL INFO comm 0x151d9c008fb0 rank 238 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
100: hkn0502:214212:214345 [0] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [receive] via NET/IBext/0
239: hkn0606:2357195:2357321 [3] NCCL INFO comm 0x148a18008fb0 rank 239 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 00 : 189[4b000] -> 188[31000] via P2P/IPC/read
 17: hkn0408:2875824:2875937 [1] NCCL INFO Connected all trees
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [receive] via NET/IBext/0
 17: hkn0408:2875824:2875937 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 17: hkn0408:2875824:2875937 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
381: hkn0715:387096:387223 [1] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [receive] via NET/IBext/0
273: hkn0617:2279794:2279887 [1] NCCL INFO Connected all trees
273: hkn0617:2279794:2279887 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
273: hkn0617:2279794:2279887 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
173: hkn0524:1118934:1119058 [1] NCCL INFO Connected all trees
 16: hkn0408:2875836:2875939 [0] NCCL INFO Connected all trees
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [receive] via NET/IBext/0
173: hkn0524:1118934:1119058 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
337: hkn0703:726148:726258 [1] NCCL INFO Connected all trees
 16: hkn0408:2875836:2875939 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1118934:1119058 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 16: hkn0408:2875836:2875939 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1286847:1286970 [1] NCCL INFO Channel 01 : 189[4b000] -> 188[31000] via P2P/IPC/read
337: hkn0703:726148:726258 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
337: hkn0703:726148:726258 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2279782:2279893 [0] NCCL INFO Connected all trees
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 00 : 169[4b000] -> 168[31000] via P2P/IPC/read
272: hkn0617:2279782:2279893 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
272: hkn0617:2279782:2279893 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
172: hkn0524:1118962:1119061 [0] NCCL INFO Connected all trees
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [receive] via NET/IBext/0
336: hkn0703:726160:726259 [0] NCCL INFO Connected all trees
172: hkn0524:1118962:1119061 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1118962:1119061 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
336: hkn0703:726160:726259 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 16: hkn0408:2875836:2875939 [0] NCCL INFO comm 0x1456c8008fb0 rank 16 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
336: hkn0703:726160:726259 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 17: hkn0408:2875824:2875937 [1] NCCL INFO comm 0x1463c0008fb0 rank 17 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [receive] via NET/IBext/0
 18: hkn0408:2875808:2875934 [2] NCCL INFO comm 0x1546d0008fb0 rank 18 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 19: hkn0408:2875816:2875935 [3] NCCL INFO comm 0x152710008fb0 rank 19 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
272: hkn0617:2279782:2279893 [0] NCCL INFO comm 0x145874008fb0 rank 272 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
257: hkn0612:902128:902247 [1] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [send] via NET/IBext/0
273: hkn0617:2279794:2279887 [1] NCCL INFO comm 0x151410008fb0 rank 273 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
256: hkn0612:902120:902251 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [receive] via NET/IBext/0
274: hkn0617:2279774:2279896 [2] NCCL INFO comm 0x1480dc008fb0 rank 274 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
172: hkn0524:1118962:1119061 [0] NCCL INFO comm 0x14eca8008fb0 rank 172 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
337: hkn0703:726148:726258 [1] NCCL INFO comm 0x14b584008fb0 rank 337 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
275: hkn0617:2279766:2279891 [3] NCCL INFO comm 0x14c54c008fb0 rank 275 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
169: hkn0523:1533198:1533289 [1] NCCL INFO Channel 01 : 169[4b000] -> 168[31000] via P2P/IPC/read
173: hkn0524:1118934:1119058 [1] NCCL INFO comm 0x146dcc008fb0 rank 173 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
339: hkn0703:726146:726263 [3] NCCL INFO comm 0x15021c008fb0 rank 339 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
338: hkn0703:726147:726262 [2] NCCL INFO comm 0x1524b8008fb0 rank 338 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
336: hkn0703:726160:726259 [0] NCCL INFO comm 0x145528008fb0 rank 336 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
174: hkn0524:1118942:1119055 [2] NCCL INFO comm 0x1480ec008fb0 rank 174 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
175: hkn0524:1118950:1119063 [3] NCCL INFO comm 0x1481e8008fb0 rank 175 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [receive] via NET/IBext/0
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [send] via NET/IBext/0
488: hkn0809:922553:922675 [0] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [send] via NET/IBext/0
 44: hkn0415:2481503:2481619 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [send] via NET/IBext/0
428: hkn0728:1309082:1309204 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [send] via NET/IBext/0
176: hkn0525:971975:972098 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [receive] via NET/IBext/0
384: hkn0716:93645:93760 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [send] via NET/IBext/0
109: hkn0504:25973:26092 [1] NCCL INFO Connected all trees
109: hkn0504:25973:26092 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
109: hkn0504:25973:26092 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 00 : 105[4b000] -> 104[31000] via P2P/IPC/read
108: hkn0504:25965:26094 [0] NCCL INFO Connected all trees
108: hkn0504:25965:26094 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [send] via NET/IBext/0
432: hkn0730:1386910:1387019 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [receive] via NET/IBext/0
108: hkn0504:25965:26094 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:4181528:4181827 [1] NCCL INFO Connected all trees
401: hkn0720:4181528:4181827 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
401: hkn0720:4181528:4181827 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:4181520:4181819 [0] NCCL INFO Connected all trees
364: hkn0711:569026:569156 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [send] via NET/IBext/0
110: hkn0504:25993:26089 [2] NCCL INFO comm 0x155200008fb0 rank 110 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
301: hkn0628:657007:657097 [1] NCCL INFO Connected all trees
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [receive] via NET/IBext/0
400: hkn0720:4181520:4181819 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:25965:26094 [0] NCCL INFO comm 0x1521e8008fb0 rank 108 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
105: hkn0503:2884817:2884916 [1] NCCL INFO Channel 01 : 105[4b000] -> 104[31000] via P2P/IPC/read
400: hkn0720:4181520:4181819 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
301: hkn0628:657007:657097 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
301: hkn0628:657007:657097 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:697242:697386 [0] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [send] via NET/IBext/0
111: hkn0504:25981:26087 [3] NCCL INFO comm 0x152f98008fb0 rank 111 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
380: hkn0715:387124:387215 [0] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [receive] via NET/IBext/0
109: hkn0504:25973:26092 [1] NCCL INFO comm 0x14cd90008fb0 rank 109 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
300: hkn0628:656995:657105 [0] NCCL INFO Connected all trees
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 00 : 297[4b000] -> 296[31000] via P2P/IPC/read
401: hkn0720:4181528:4181827 [1] NCCL INFO comm 0x152a0c008fb0 rank 401 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
300: hkn0628:656995:657105 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
300: hkn0628:656995:657105 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:4181520:4181819 [0] NCCL INFO comm 0x14b694008fb0 rank 400 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [receive] via NET/IBext/0
402: hkn0720:4181548:4181824 [2] NCCL INFO comm 0x149be4008fb0 rank 402 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
160: hkn0520:2697999:2698118 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [receive] via NET/IBext/0
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [receive] via NET/IBext/0
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 00 : 61[4b000] -> 60[31000] via P2P/IPC/read
484: hkn0808:955851:955982 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [send] via NET/IBext/0
300: hkn0628:656995:657105 [0] NCCL INFO comm 0x152224008fb0 rank 300 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 00 : 317[4b000] -> 316[31000] via P2P/IPC/read
303: hkn0628:656987:657106 [3] NCCL INFO comm 0x14b808008fb0 rank 303 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
297: hkn0627:1773070:1773181 [1] NCCL INFO Channel 01 : 297[4b000] -> 296[31000] via P2P/IPC/read
403: hkn0720:4181536:4181828 [3] NCCL INFO comm 0x14be00008fb0 rank 403 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
301: hkn0628:657007:657097 [1] NCCL INFO comm 0x14ac60008fb0 rank 301 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
302: hkn0628:656986:657104 [2] NCCL INFO comm 0x147bd4008fb0 rank 302 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 00 : 125[4b000] -> 124[31000] via P2P/IPC/read
 61: hkn0420:3195354:3195457 [1] NCCL INFO Channel 01 : 61[4b000] -> 60[31000] via P2P/IPC/read
476: hkn0806:1039501:1039609 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [send] via NET/IBext/0
168: hkn0523:1533186:1533298 [0] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [send] via NET/IBext/0
 48: hkn0417:2252758:2252860 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [receive] via NET/IBext/0
125: hkn0508:3124305:3124410 [1] NCCL INFO Channel 01 : 125[4b000] -> 124[31000] via P2P/IPC/read
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [receive] via NET/IBext/0
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [send] via NET/IBext/0
228: hkn0604:674438:674558 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [send] via NET/IBext/0
317: hkn0632:1743769:1743914 [1] NCCL INFO Channel 01 : 317[4b000] -> 316[31000] via P2P/IPC/read
356: hkn0708:398416:398525 [0] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [receive] via NET/IBext/0
381: hkn0715:387096:387223 [1] NCCL INFO Channel 00 : 381[4b000] -> 380[31000] via P2P/IPC/read
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [send] via NET/IBext/0
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [send] via NET/IBext/0
256: hkn0612:902120:902251 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [send] via NET/IBext/0
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [send] via NET/IBext/0
485: hkn0808:955879:955981 [1] NCCL INFO Channel 00 : 485[4b000] -> 484[31000] via P2P/IPC/read
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [receive] via NET/IBext/0
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 00 : 425[4b000] -> 424[31000] via P2P/IPC/read
381: hkn0715:387096:387223 [1] NCCL INFO Channel 01 : 381[4b000] -> 380[31000] via P2P/IPC/read
304: hkn0629:1577186:1577310 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [receive] via NET/IBext/0
428: hkn0728:1309082:1309204 [0] NCCL INFO Connected all trees
348: hkn0706:737455:737573 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [send] via NET/IBext/0
428: hkn0728:1309082:1309204 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
104: hkn0503:2884789:2884923 [0] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [send] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [send] via NET/IBext/0
428: hkn0728:1309082:1309204 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
489: hkn0809:922561:922677 [1] NCCL INFO Connected all trees
 84: hkn0426:799238:799364 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [send] via NET/IBext/0
 45: hkn0415:2481516:2481618 [1] NCCL INFO Connected all trees
489: hkn0809:922561:922677 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
489: hkn0809:922561:922677 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 45: hkn0415:2481516:2481618 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
485: hkn0808:955879:955981 [1] NCCL INFO Channel 01 : 485[4b000] -> 484[31000] via P2P/IPC/read
 45: hkn0415:2481516:2481618 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
429: hkn0728:1309098:1309209 [1] NCCL INFO Connected all trees
488: hkn0809:922553:922675 [0] NCCL INFO Connected all trees
257: hkn0612:902128:902247 [1] NCCL INFO Channel 00 : 257[4b000] -> 256[31000] via P2P/IPC/read
 44: hkn0415:2481503:2481619 [0] NCCL INFO Connected all trees
429: hkn0728:1309098:1309209 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:922553:922675 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2481503:2481619 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
429: hkn0728:1309098:1309209 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1330936:1331042 [1] NCCL INFO Channel 01 : 425[4b000] -> 424[31000] via P2P/IPC/read
488: hkn0809:922553:922675 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 44: hkn0415:2481503:2481619 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
296: hkn0627:1773062:1773179 [0] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [send] via NET/IBext/0
491: hkn0809:922581:922679 [3] NCCL INFO comm 0x14dffc008fb0 rank 491 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
229: hkn0604:674466:674561 [1] NCCL INFO Channel 00 : 229[4b000] -> 228[31000] via P2P/IPC/read
428: hkn0728:1309082:1309204 [0] NCCL INFO comm 0x14c18c008fb0 rank 428 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
490: hkn0809:922569:922682 [2] NCCL INFO comm 0x14791c008fb0 rank 490 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 46: hkn0415:2481504:2481617 [2] NCCL INFO comm 0x14cbd0008fb0 rank 46 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
430: hkn0728:1309110:1309210 [2] NCCL INFO comm 0x14a618008fb0 rank 430 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
488: hkn0809:922553:922675 [0] NCCL INFO comm 0x14e8b4008fb0 rank 488 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 47: hkn0415:2481502:2481621 [3] NCCL INFO comm 0x1545fc008fb0 rank 47 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
431: hkn0728:1309090:1309203 [3] NCCL INFO comm 0x151fc4008fb0 rank 431 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
364: hkn0711:569026:569156 [0] NCCL INFO Connected all trees
489: hkn0809:922561:922677 [1] NCCL INFO comm 0x14543c008fb0 rank 489 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 44: hkn0415:2481503:2481619 [0] NCCL INFO comm 0x14cfe8008fb0 rank 44 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
429: hkn0728:1309098:1309209 [1] NCCL INFO comm 0x150d8c008fb0 rank 429 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
257: hkn0612:902128:902247 [1] NCCL INFO Channel 01 : 257[4b000] -> 256[31000] via P2P/IPC/read
364: hkn0711:569026:569156 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
364: hkn0711:569026:569156 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 45: hkn0415:2481516:2481618 [1] NCCL INFO comm 0x147a78008fb0 rank 45 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [receive] via NET/IBext/0
365: hkn0711:569034:569157 [1] NCCL INFO Connected all trees
233: hkn0605:697262:697393 [1] NCCL INFO Connected all trees
365: hkn0711:569034:569157 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
233: hkn0605:697262:697393 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
365: hkn0711:569034:569157 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
233: hkn0605:697262:697393 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:674466:674561 [1] NCCL INFO Channel 01 : 229[4b000] -> 228[31000] via P2P/IPC/read
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 00 : 41[4b000] -> 40[31000] via P2P/IPC/read
361: hkn0710:340632:340748 [1] NCCL INFO Channel 00 : 361[4b000] -> 360[31000] via P2P/IPC/read
 64: hkn0421:2163508:2163779 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [receive] via NET/IBext/0
232: hkn0605:697242:697386 [0] NCCL INFO Connected all trees
232: hkn0605:697242:697386 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
232: hkn0605:697242:697386 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
365: hkn0711:569034:569157 [1] NCCL INFO comm 0x14758c008fb0 rank 365 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
100: hkn0502:214212:214345 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [send] via NET/IBext/0
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [send] via NET/IBext/0
366: hkn0711:569042:569160 [2] NCCL INFO comm 0x14f004008fb0 rank 366 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
364: hkn0711:569026:569156 [0] NCCL INFO comm 0x154a58008fb0 rank 364 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
361: hkn0710:340632:340748 [1] NCCL INFO Channel 01 : 361[4b000] -> 360[31000] via P2P/IPC/read
234: hkn0605:697234:697394 [2] NCCL INFO comm 0x146aec008fb0 rank 234 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
367: hkn0711:569054:569153 [3] NCCL INFO comm 0x1496c0008fb0 rank 367 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
233: hkn0605:697262:697393 [1] NCCL INFO comm 0x152544008fb0 rank 233 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 41: hkn0414:1966724:1966822 [1] NCCL INFO Channel 01 : 41[4b000] -> 40[31000] via P2P/IPC/read
235: hkn0605:697250:697395 [3] NCCL INFO comm 0x153dfc008fb0 rank 235 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
232: hkn0605:697242:697386 [0] NCCL INFO comm 0x148da8008fb0 rank 232 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
476: hkn0806:1039501:1039609 [0] NCCL INFO Connected all trees
476: hkn0806:1039501:1039609 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
476: hkn0806:1039501:1039609 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1039485:1039615 [1] NCCL INFO Connected all trees
165: hkn0521:1182962:1183092 [1] NCCL INFO Channel 00 : 165[4b000] -> 164[31000] via P2P/IPC/read
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [receive] via NET/IBext/0
432: hkn0730:1386910:1387019 [0] NCCL INFO Connected all trees
432: hkn0730:1386910:1387019 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1039485:1039615 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1386910:1387019 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1039485:1039615 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
320: hkn0633:1511506:1511630 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [receive] via NET/IBext/0
169: hkn0523:1533198:1533289 [1] NCCL INFO Connected all trees
220: hkn0602:3345223:3345484 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [send] via NET/IBext/0
169: hkn0523:1533198:1533289 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
169: hkn0523:1533198:1533289 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1386894:1387025 [1] NCCL INFO Connected all trees
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [receive] via NET/IBext/0
476: hkn0806:1039501:1039609 [0] NCCL INFO comm 0x153368008fb0 rank 476 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
433: hkn0730:1386894:1387025 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1283594:1283703 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [send] via NET/IBext/0
433: hkn0730:1386894:1387025 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1533186:1533298 [0] NCCL INFO Connected all trees
168: hkn0523:1533186:1533298 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
168: hkn0523:1533186:1533298 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1039485:1039615 [1] NCCL INFO comm 0x147714008fb0 rank 477 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
479: hkn0806:1039493:1039614 [3] NCCL INFO comm 0x145538008fb0 rank 479 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
478: hkn0806:1039513:1039607 [2] NCCL INFO comm 0x14e0d0008fb0 rank 478 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
432: hkn0730:1386910:1387019 [0] NCCL INFO comm 0x14db34008fb0 rank 432 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
434: hkn0730:1386902:1387024 [2] NCCL INFO comm 0x14f330008fb0 rank 434 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
433: hkn0730:1386894:1387025 [1] NCCL INFO comm 0x145d7c008fb0 rank 433 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
165: hkn0521:1182962:1183092 [1] NCCL INFO Channel 01 : 165[4b000] -> 164[31000] via P2P/IPC/read
169: hkn0523:1533198:1533289 [1] NCCL INFO comm 0x15511c008fb0 rank 169 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
171: hkn0523:1533178:1533297 [3] NCCL INFO comm 0x149d40008fb0 rank 171 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
168: hkn0523:1533186:1533298 [0] NCCL INFO comm 0x145f18008fb0 rank 168 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
170: hkn0523:1533170:1533292 [2] NCCL INFO comm 0x151db8008fb0 rank 170 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
435: hkn0730:1386922:1387017 [3] NCCL INFO comm 0x14e6cc008fb0 rank 435 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
424: hkn0727:1330945:1331038 [0] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [send] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [send] via NET/IBext/0
176: hkn0525:971975:972098 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [receive] via NET/IBext/0
101: hkn0502:214224:214351 [1] NCCL INFO Channel 00 : 101[4b000] -> 100[31000] via P2P/IPC/read
253: hkn0611:694985:695081 [1] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [receive] via NET/IBext/0
204: hkn0532:908782:909098 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [send] via NET/IBext/0
 49: hkn0417:2252738:2252863 [1] NCCL INFO Connected all trees
101: hkn0502:214224:214351 [1] NCCL INFO Channel 01 : 101[4b000] -> 100[31000] via P2P/IPC/read
 49: hkn0417:2252738:2252863 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 49: hkn0417:2252738:2252863 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2884817:2884916 [1] NCCL INFO Connected all trees
105: hkn0503:2884817:2884916 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:340644:340742 [0] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [send] via NET/IBext/0
105: hkn0503:2884817:2884916 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1283586:1283696 [1] NCCL INFO Channel 00 : 293[4b000] -> 292[31000] via P2P/IPC/read
 48: hkn0417:2252758:2252860 [0] NCCL INFO Connected all trees
165: hkn0521:1182962:1183092 [1] NCCL INFO Connected all trees
 48: hkn0417:2252758:2252860 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
104: hkn0503:2884789:2884923 [0] NCCL INFO Connected all trees
165: hkn0521:1182962:1183092 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 48: hkn0417:2252758:2252860 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
165: hkn0521:1182962:1183092 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
104: hkn0503:2884789:2884923 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
104: hkn0503:2884789:2884923 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
297: hkn0627:1773070:1773181 [1] NCCL INFO Connected all trees
297: hkn0627:1773070:1773181 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
297: hkn0627:1773070:1773181 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
420: hkn0726:1533318:1533412 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [send] via NET/IBext/0
164: hkn0521:1182978:1183084 [0] NCCL INFO Connected all trees
164: hkn0521:1182978:1183084 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
164: hkn0521:1182978:1183084 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 51: hkn0417:2252746:2252861 [3] NCCL INFO comm 0x149538008fb0 rank 51 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
296: hkn0627:1773062:1773179 [0] NCCL INFO Connected all trees
105: hkn0503:2884817:2884916 [1] NCCL INFO comm 0x151fe0008fb0 rank 105 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 48: hkn0417:2252758:2252860 [0] NCCL INFO comm 0x155160008fb0 rank 48 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
296: hkn0627:1773062:1773179 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
106: hkn0503:2884805:2884921 [2] NCCL INFO comm 0x14bf14008fb0 rank 106 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
296: hkn0627:1773062:1773179 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 49: hkn0417:2252738:2252863 [1] NCCL INFO comm 0x1493c0008fb0 rank 49 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
107: hkn0503:2884797:2884917 [3] NCCL INFO comm 0x15370c008fb0 rank 107 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 36: hkn0413:2351818:2351944 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [send] via NET/IBext/0
 50: hkn0417:2252730:2252862 [2] NCCL INFO comm 0x150bcc008fb0 rank 50 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
104: hkn0503:2884789:2884923 [0] NCCL INFO comm 0x14580c008fb0 rank 104 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
164: hkn0521:1182978:1183084 [0] NCCL INFO comm 0x14bf74008fb0 rank 164 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
188: hkn0528:1286855:1286975 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [send] via NET/IBext/0
297: hkn0627:1773070:1773181 [1] NCCL INFO comm 0x14e8ac008fb0 rank 297 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
165: hkn0521:1182962:1183092 [1] NCCL INFO comm 0x145e48008fb0 rank 165 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
460: hkn0802:1185519:1185612 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [send] via NET/IBext/0
160: hkn0520:2697999:2698118 [0] NCCL INFO Connected all trees
296: hkn0627:1773062:1773179 [0] NCCL INFO comm 0x14bea8008fb0 rank 296 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
167: hkn0521:1182990:1183086 [3] NCCL INFO comm 0x151304008fb0 rank 167 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
166: hkn0521:1182970:1183090 [2] NCCL INFO comm 0x1495c0008fb0 rank 166 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 92: hkn0428:652537:652628 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [send] via NET/IBext/0
299: hkn0627:1773082:1773180 [3] NCCL INFO comm 0x148948008fb0 rank 299 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
160: hkn0520:2697999:2698118 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
293: hkn0626:1283586:1283696 [1] NCCL INFO Channel 01 : 293[4b000] -> 292[31000] via P2P/IPC/read
298: hkn0627:1773054:1773175 [2] NCCL INFO comm 0x15381c008fb0 rank 298 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
160: hkn0520:2697999:2698118 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:387124:387215 [0] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [send] via NET/IBext/0
472: hkn0805:1097255:1097378 [0] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [send] via NET/IBext/0
161: hkn0520:2698015:2698119 [1] NCCL INFO Connected all trees
305: hkn0629:1577194:1577306 [1] NCCL INFO Connected all trees
161: hkn0520:2698015:2698119 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2698015:2698119 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1577194:1577306 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
305: hkn0629:1577194:1577306 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:737455:737573 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [send] via NET/IBext/0
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [receive] via NET/IBext/0
304: hkn0629:1577186:1577310 [0] NCCL INFO Connected all trees
 81: hkn0425:2069090:2069201 [1] NCCL INFO Connected all trees
304: hkn0629:1577186:1577310 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2069090:2069201 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
304: hkn0629:1577186:1577310 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 81: hkn0425:2069090:2069201 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2697999:2698118 [0] NCCL INFO comm 0x153e5c008fb0 rank 160 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
163: hkn0520:2698007:2698122 [3] NCCL INFO comm 0x153f70008fb0 rank 163 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 80: hkn0425:2069098:2069207 [0] NCCL INFO Connected all trees
161: hkn0520:2698015:2698119 [1] NCCL INFO comm 0x152a68008fb0 rank 161 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 80: hkn0425:2069098:2069207 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:398416:398525 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [send] via NET/IBext/0
 80: hkn0425:2069098:2069207 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
162: hkn0520:2698027:2698123 [2] NCCL INFO comm 0x146cdc008fb0 rank 162 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
307: hkn0629:1577178:1577305 [3] NCCL INFO comm 0x14cc30008fb0 rank 307 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
304: hkn0629:1577186:1577310 [0] NCCL INFO comm 0x153480008fb0 rank 304 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
306: hkn0629:1577206:1577307 [2] NCCL INFO comm 0x1479d4008fb0 rank 306 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
221: hkn0602:3345235:3345487 [1] NCCL INFO Connected all trees
305: hkn0629:1577194:1577306 [1] NCCL INFO comm 0x152384008fb0 rank 305 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
221: hkn0602:3345235:3345487 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
221: hkn0602:3345235:3345487 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 80: hkn0425:2069098:2069207 [0] NCCL INFO comm 0x14f6f0008fb0 rank 80 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 81: hkn0425:2069090:2069201 [1] NCCL INFO comm 0x145efc008fb0 rank 81 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [send] via NET/IBext/0
 83: hkn0425:2069106:2069204 [3] NCCL INFO comm 0x146e48008fb0 rank 83 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 82: hkn0425:2069118:2069202 [2] NCCL INFO comm 0x153fec008fb0 rank 82 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
368: hkn0712:280251:280359 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [receive] via NET/IBext/0
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [receive] via NET/IBext/0
293: hkn0626:1283586:1283696 [1] NCCL INFO Connected all trees
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [send] via NET/IBext/0
293: hkn0626:1283586:1283696 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
256: hkn0612:902120:902251 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [receive] via NET/IBext/0
220: hkn0602:3345223:3345484 [0] NCCL INFO Connected all trees
444: hkn0733:1374558:1374666 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [send] via NET/IBext/0
293: hkn0626:1283586:1283696 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3345223:3345484 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [receive] via NET/IBext/0
220: hkn0602:3345223:3345484 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [send] via NET/IBext/0
425: hkn0727:1330936:1331042 [1] NCCL INFO Connected all trees
292: hkn0626:1283594:1283703 [0] NCCL INFO Connected all trees
292: hkn0626:1283594:1283703 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
425: hkn0727:1330936:1331042 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1283594:1283703 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1330936:1331042 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3345207:3345482 [2] NCCL INFO comm 0x151ff0008fb0 rank 222 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 37: hkn0413:2351826:2351942 [1] NCCL INFO Channel 00 : 37[4b000] -> 36[31000] via P2P/IPC/read
220: hkn0602:3345223:3345484 [0] NCCL INFO comm 0x14c6f4008fb0 rank 220 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
221: hkn0602:3345235:3345487 [1] NCCL INFO comm 0x14771c008fb0 rank 221 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
424: hkn0727:1330945:1331038 [0] NCCL INFO Connected all trees
 41: hkn0414:1966724:1966822 [1] NCCL INFO Connected all trees
424: hkn0727:1330945:1331038 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 96: hkn0501:1312974:1313097 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [receive] via NET/IBext/0
424: hkn0727:1330945:1331038 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1283594:1283703 [0] NCCL INFO comm 0x150288008fb0 rank 292 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 41: hkn0414:1966724:1966822 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 41: hkn0414:1966724:1966822 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1283586:1283696 [1] NCCL INFO comm 0x14daa4008fb0 rank 293 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
223: hkn0602:3345215:3345483 [3] NCCL INFO comm 0x146598008fb0 rank 223 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
295: hkn0626:1283583:1283699 [3] NCCL INFO comm 0x1503d4008fb0 rank 295 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
288: hkn0624:1758070:1758195 [0] NCCL INFO Connected all trees
294: hkn0626:1283606:1283705 [2] NCCL INFO comm 0x148584008fb0 rank 294 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
288: hkn0624:1758070:1758195 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1738669:1739051 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [receive] via NET/IBext/0
288: hkn0624:1758070:1758195 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:694973:695080 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [receive] via NET/IBext/0
 40: hkn0414:1966696:1966821 [0] NCCL INFO Connected all trees
421: hkn0726:1533295:1533418 [1] NCCL INFO Channel 00 : 421[4b000] -> 420[31000] via P2P/IPC/read
 40: hkn0414:1966696:1966821 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 40: hkn0414:1966696:1966821 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
425: hkn0727:1330936:1331042 [1] NCCL INFO comm 0x14e4b8008fb0 rank 425 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
426: hkn0727:1330937:1331047 [2] NCCL INFO comm 0x152424008fb0 rank 426 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
424: hkn0727:1330945:1331038 [0] NCCL INFO comm 0x14861c008fb0 rank 424 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 40: hkn0414:1966696:1966821 [0] NCCL INFO comm 0x1454b4008fb0 rank 40 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
427: hkn0727:1330957:1331044 [3] NCCL INFO comm 0x14b46c008fb0 rank 427 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 41: hkn0414:1966724:1966822 [1] NCCL INFO comm 0x14fb7c008fb0 rank 41 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
361: hkn0710:340632:340748 [1] NCCL INFO Connected all trees
 37: hkn0413:2351826:2351942 [1] NCCL INFO Channel 01 : 37[4b000] -> 36[31000] via P2P/IPC/read
 42: hkn0414:1966704:1966820 [2] NCCL INFO comm 0x150878008fb0 rank 42 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 43: hkn0414:1966712:1966819 [3] NCCL INFO comm 0x15483c008fb0 rank 43 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
361: hkn0710:340632:340748 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [receive] via NET/IBext/0
361: hkn0710:340632:340748 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:398436:398520 [1] NCCL INFO Channel 00 : 357[4b000] -> 356[31000] via P2P/IPC/read
352: hkn0707:4005081:4005188 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [receive] via NET/IBext/0
421: hkn0726:1533295:1533418 [1] NCCL INFO Channel 01 : 421[4b000] -> 420[31000] via P2P/IPC/read
360: hkn0710:340644:340742 [0] NCCL INFO Connected all trees
360: hkn0710:340644:340742 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:340644:340742 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
289: hkn0624:1758098:1758200 [1] NCCL INFO Connected all trees
289: hkn0624:1758098:1758200 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
289: hkn0624:1758098:1758200 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:340644:340742 [0] NCCL INFO comm 0x148524008fb0 rank 360 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [send] via NET/IBext/0
189: hkn0528:1286847:1286970 [1] NCCL INFO Connected all trees
361: hkn0710:340632:340748 [1] NCCL INFO comm 0x1536c0008fb0 rank 361 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
357: hkn0708:398436:398520 [1] NCCL INFO Channel 01 : 357[4b000] -> 356[31000] via P2P/IPC/read
362: hkn0710:340630:340740 [2] NCCL INFO comm 0x150220008fb0 rank 362 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
189: hkn0528:1286847:1286970 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
363: hkn0710:340631:340745 [3] NCCL INFO comm 0x14b9ac008fb0 rank 363 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
189: hkn0528:1286847:1286970 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:694985:695081 [1] NCCL INFO Channel 00 : 253[4b000] -> 252[31000] via P2P/IPC/read
461: hkn0802:1185499:1185610 [1] NCCL INFO Connected all trees
288: hkn0624:1758070:1758195 [0] NCCL INFO comm 0x14ac80008fb0 rank 288 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
461: hkn0802:1185499:1185610 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 93: hkn0428:652517:652634 [1] NCCL INFO Connected all trees
461: hkn0802:1185499:1185610 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1286855:1286975 [0] NCCL INFO Connected all trees
289: hkn0624:1758098:1758200 [1] NCCL INFO comm 0x15018c008fb0 rank 289 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 93: hkn0428:652517:652634 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
291: hkn0624:1758078:1758198 [3] NCCL INFO comm 0x150188008fb0 rank 291 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 93: hkn0428:652517:652634 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1286855:1286975 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
290: hkn0624:1758086:1758202 [2] NCCL INFO comm 0x146ae8008fb0 rank 290 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
469: hkn0804:1190775:1190890 [1] NCCL INFO Channel 00 : 469[4b000] -> 468[31000] via P2P/IPC/read
177: hkn0525:971991:972103 [1] NCCL INFO Connected all trees
188: hkn0528:1286855:1286975 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
177: hkn0525:971991:972103 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:971991:972103 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
460: hkn0802:1185519:1185612 [0] NCCL INFO Connected all trees
 92: hkn0428:652537:652628 [0] NCCL INFO Connected all trees
460: hkn0802:1185519:1185612 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
460: hkn0802:1185519:1185612 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 92: hkn0428:652537:652628 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 36: hkn0413:2351818:2351944 [0] NCCL INFO Connected all trees
 92: hkn0428:652537:652628 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:694985:695081 [1] NCCL INFO Channel 01 : 253[4b000] -> 252[31000] via P2P/IPC/read
 36: hkn0413:2351818:2351944 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:971975:972098 [0] NCCL INFO Connected all trees
 36: hkn0413:2351818:2351944 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
191: hkn0528:1286875:1286972 [3] NCCL INFO comm 0x153bb8008fb0 rank 191 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
349: hkn0706:737463:737570 [1] NCCL INFO Connected all trees
176: hkn0525:971975:972098 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:971975:972098 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
190: hkn0528:1286863:1286971 [2] NCCL INFO comm 0x15027c008fb0 rank 190 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 00 : 457[4b000] -> 456[31000] via P2P/IPC/read
189: hkn0528:1286847:1286970 [1] NCCL INFO comm 0x153484008fb0 rank 189 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
349: hkn0706:737463:737570 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
188: hkn0528:1286855:1286975 [0] NCCL INFO comm 0x152b6c008fb0 rank 188 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
349: hkn0706:737463:737570 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
463: hkn0802:1185491:1185618 [3] NCCL INFO comm 0x14b060008fb0 rank 463 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
128: hkn0509:3109576:3109676 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [receive] via NET/IBext/0
420: hkn0726:1533318:1533412 [0] NCCL INFO Connected all trees
469: hkn0804:1190775:1190890 [1] NCCL INFO Channel 01 : 469[4b000] -> 468[31000] via P2P/IPC/read
460: hkn0802:1185519:1185612 [0] NCCL INFO comm 0x145a84008fb0 rank 460 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 93: hkn0428:652517:652634 [1] NCCL INFO comm 0x14b8e0008fb0 rank 93 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
348: hkn0706:737455:737573 [0] NCCL INFO Connected all trees
348: hkn0706:737455:737573 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
204: hkn0532:908782:909098 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [send] via NET/IBext/0
 37: hkn0413:2351826:2351942 [1] NCCL INFO Connected all trees
420: hkn0726:1533318:1533412 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:737455:737573 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
462: hkn0802:1185507:1185616 [2] NCCL INFO comm 0x14ec50008fb0 rank 462 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 95: hkn0428:652509:652633 [3] NCCL INFO comm 0x1459cc008fb0 rank 95 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
420: hkn0726:1533318:1533412 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 37: hkn0413:2351826:2351942 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 92: hkn0428:652537:652628 [0] NCCL INFO comm 0x1506e0008fb0 rank 92 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
177: hkn0525:971991:972103 [1] NCCL INFO comm 0x153a34008fb0 rank 177 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
461: hkn0802:1185499:1185610 [1] NCCL INFO comm 0x14b85c008fb0 rank 461 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 37: hkn0413:2351826:2351942 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 94: hkn0428:652525:652632 [2] NCCL INFO comm 0x151d64008fb0 rank 94 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
178: hkn0525:972003:972097 [2] NCCL INFO comm 0x15026c008fb0 rank 178 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
416: hkn0725:3097110:3097192 [0] NCCL INFO Connected all trees
176: hkn0525:971975:972098 [0] NCCL INFO comm 0x14ace4008fb0 rank 176 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
421: hkn0726:1533295:1533418 [1] NCCL INFO Connected all trees
416: hkn0725:3097110:3097192 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
416: hkn0725:3097110:3097192 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
457: hkn0801:2225101:2225223 [1] NCCL INFO Channel 01 : 457[4b000] -> 456[31000] via P2P/IPC/read
179: hkn0525:971983:972104 [3] NCCL INFO comm 0x14d984008fb0 rank 179 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
421: hkn0726:1533295:1533418 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 37: hkn0413:2351826:2351942 [1] NCCL INFO comm 0x152868008fb0 rank 37 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
421: hkn0726:1533295:1533418 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:737455:737573 [0] NCCL INFO comm 0x153220008fb0 rank 348 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 36: hkn0413:2351818:2351944 [0] NCCL INFO comm 0x1487dc008fb0 rank 36 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 38: hkn0413:2351846:2351938 [2] NCCL INFO comm 0x146644008fb0 rank 38 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
351: hkn0706:737447:737575 [3] NCCL INFO comm 0x14f250008fb0 rank 351 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 33: hkn0412:2247562:2247671 [1] NCCL INFO Connected all trees
 33: hkn0412:2247562:2247671 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 39: hkn0413:2351834:2351947 [3] NCCL INFO comm 0x14720c008fb0 rank 39 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
349: hkn0706:737463:737570 [1] NCCL INFO comm 0x1534c0008fb0 rank 349 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 33: hkn0412:2247562:2247671 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3097090:3097194 [1] NCCL INFO Connected all trees
417: hkn0725:3097090:3097194 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
417: hkn0725:3097090:3097194 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
350: hkn0706:737475:737567 [2] NCCL INFO comm 0x14c0e8008fb0 rank 350 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 32: hkn0412:2247570:2247665 [0] NCCL INFO Connected all trees
 32: hkn0412:2247570:2247665 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
420: hkn0726:1533318:1533412 [0] NCCL INFO comm 0x15092c008fb0 rank 420 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 32: hkn0412:2247570:2247665 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
423: hkn0726:1533306:1533413 [3] NCCL INFO comm 0x149410008fb0 rank 423 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
421: hkn0726:1533295:1533418 [1] NCCL INFO comm 0x14632c008fb0 rank 421 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
422: hkn0726:1533298:1533416 [2] NCCL INFO comm 0x14ae50008fb0 rank 422 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
445: hkn0733:1374570:1374664 [1] NCCL INFO Connected all trees
418: hkn0725:3097089:3097197 [2] NCCL INFO comm 0x14db04008fb0 rank 418 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 33: hkn0412:2247562:2247671 [1] NCCL INFO comm 0x14c684008fb0 rank 33 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
216: hkn0601:102816:102929 [0] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [send] via NET/IBext/0
445: hkn0733:1374570:1374664 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
417: hkn0725:3097090:3097194 [1] NCCL INFO comm 0x14f814008fb0 rank 417 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
445: hkn0733:1374570:1374664 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2247570:2247665 [0] NCCL INFO comm 0x151754008fb0 rank 32 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 34: hkn0412:2247554:2247673 [2] NCCL INFO comm 0x14ac84008fb0 rank 34 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
380: hkn0715:387124:387215 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [send] via NET/IBext/0
416: hkn0725:3097110:3097192 [0] NCCL INFO comm 0x148edc008fb0 rank 416 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
468: hkn0804:1190767:1190886 [0] NCCL INFO Connected all trees
444: hkn0733:1374558:1374666 [0] NCCL INFO Connected all trees
419: hkn0725:3097098:3097193 [3] NCCL INFO comm 0x14ac7c008fb0 rank 419 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 35: hkn0412:2247582:2247669 [3] NCCL INFO comm 0x148188008fb0 rank 35 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
468: hkn0804:1190767:1190886 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1374558:1374666 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
468: hkn0804:1190767:1190886 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1374558:1374666 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
469: hkn0804:1190775:1190890 [1] NCCL INFO Connected all trees
445: hkn0733:1374570:1374664 [1] NCCL INFO comm 0x14c6fc008fb0 rank 445 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
469: hkn0804:1190775:1190890 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1190775:1190890 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
446: hkn0733:1374549:1374669 [2] NCCL INFO comm 0x14f96c008fb0 rank 446 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
101: hkn0502:214224:214351 [1] NCCL INFO Connected all trees
447: hkn0733:1374550:1374661 [3] NCCL INFO comm 0x145670008fb0 rank 447 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
101: hkn0502:214224:214351 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:214224:214351 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [receive] via NET/IBext/0
444: hkn0733:1374558:1374666 [0] NCCL INFO comm 0x1488e0008fb0 rank 444 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
100: hkn0502:214212:214345 [0] NCCL INFO Connected all trees
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [receive] via NET/IBext/0
100: hkn0502:214212:214345 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
468: hkn0804:1190767:1190886 [0] NCCL INFO comm 0x14efc4008fb0 rank 468 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
100: hkn0502:214212:214345 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
469: hkn0804:1190775:1190890 [1] NCCL INFO comm 0x153f64008fb0 rank 469 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
470: hkn0804:1190787:1190892 [2] NCCL INFO comm 0x151d38008fb0 rank 470 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
471: hkn0804:1190762:1190887 [3] NCCL INFO comm 0x146290008fb0 rank 471 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
100: hkn0502:214212:214345 [0] NCCL INFO comm 0x1465f4008fb0 rank 100 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
101: hkn0502:214224:214351 [1] NCCL INFO comm 0x14feb8008fb0 rank 101 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
103: hkn0502:214196:214352 [3] NCCL INFO comm 0x1545e8008fb0 rank 103 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
102: hkn0502:214204:214346 [2] NCCL INFO comm 0x14c684008fb0 rank 102 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
184: hkn0527:1334049:1334169 [0] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [send] via NET/IBext/0
156: hkn0516:2901152:2901289 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [send] via NET/IBext/0
472: hkn0805:1097255:1097378 [0] NCCL INFO Connected all trees
357: hkn0708:398436:398520 [1] NCCL INFO Connected all trees
 88: hkn0427:1120324:1120446 [0] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [send] via NET/IBext/0
472: hkn0805:1097255:1097378 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
357: hkn0708:398436:398520 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1097255:1097378 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:398436:398520 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1639342:1639458 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [send] via NET/IBext/0
344: hkn0705:768421:768521 [0] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [send] via NET/IBext/0
384: hkn0716:93645:93760 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [receive] via NET/IBext/0
356: hkn0708:398416:398525 [0] NCCL INFO Connected all trees
456: hkn0801:2225122:2225226 [0] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [send] via NET/IBext/0
356: hkn0708:398416:398525 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:398416:398525 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2933109:2933241 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [send] via NET/IBext/0
376: hkn0714:417195:417320 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [receive] via NET/IBext/0
 97: hkn0501:1312996:1313099 [1] NCCL INFO Connected all trees
112: hkn0505:2288969:2289061 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [receive] via NET/IBext/0
 97: hkn0501:1312996:1313099 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:398416:398525 [0] NCCL INFO comm 0x150ba0008fb0 rank 356 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 97: hkn0501:1312996:1313099 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
358: hkn0708:398424:398526 [2] NCCL INFO comm 0x15347c008fb0 rank 358 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
359: hkn0708:398415:398522 [3] NCCL INFO comm 0x146654008fb0 rank 359 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
357: hkn0708:398436:398520 [1] NCCL INFO comm 0x145f1c008fb0 rank 357 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 96: hkn0501:1312974:1313097 [0] NCCL INFO Connected all trees
252: hkn0611:694973:695080 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [send] via NET/IBext/0
 96: hkn0501:1312974:1313097 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 96: hkn0501:1312974:1313097 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 97: hkn0501:1312996:1313099 [1] NCCL INFO comm 0x14dd18008fb0 rank 97 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 96: hkn0501:1312974:1313097 [0] NCCL INFO comm 0x14aea8008fb0 rank 96 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
205: hkn0532:908774:909097 [1] NCCL INFO Connected all trees
353: hkn0707:4005073:4005192 [1] NCCL INFO Connected all trees
205: hkn0532:908774:909097 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 99: hkn0501:1312982:1313098 [3] NCCL INFO comm 0x14582c008fb0 rank 99 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
205: hkn0532:908774:909097 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
353: hkn0707:4005073:4005192 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 98: hkn0501:1312966:1313101 [2] NCCL INFO comm 0x153b3c008fb0 rank 98 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
353: hkn0707:4005073:4005192 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:908782:909098 [0] NCCL INFO Connected all trees
256: hkn0612:902120:902251 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [receive] via NET/IBext/0
352: hkn0707:4005081:4005188 [0] NCCL INFO Connected all trees
204: hkn0532:908782:909098 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
204: hkn0532:908782:909098 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
352: hkn0707:4005081:4005188 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4005081:4005188 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [receive] via NET/IBext/0
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [send] via NET/IBext/0
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 00 : 201[4b000] -> 200[31000] via P2P/IPC/read
368: hkn0712:280251:280359 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [receive] via NET/IBext/0
205: hkn0532:908774:909097 [1] NCCL INFO comm 0x151104008fb0 rank 205 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
354: hkn0707:4005065:4005191 [2] NCCL INFO comm 0x1492ac008fb0 rank 354 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
452: hkn0736:1493537:1493642 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [send] via NET/IBext/0
206: hkn0532:908802:909093 [2] NCCL INFO comm 0x148ca0008fb0 rank 206 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
440: hkn0732:1196819:1196963 [0] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [send] via NET/IBext/0
204: hkn0532:908782:909098 [0] NCCL INFO comm 0x150bd4008fb0 rank 204 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
352: hkn0707:4005081:4005188 [0] NCCL INFO comm 0x146c1c008fb0 rank 352 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
207: hkn0532:908790:909100 [3] NCCL INFO comm 0x152874008fb0 rank 207 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
353: hkn0707:4005073:4005192 [1] NCCL INFO comm 0x14b8ec008fb0 rank 353 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
412: hkn0724:1701140:1701248 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [send] via NET/IBext/0
355: hkn0707:4005093:4005183 [3] NCCL INFO comm 0x14f834008fb0 rank 355 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
473: hkn0805:1097263:1097382 [1] NCCL INFO Connected all trees
473: hkn0805:1097263:1097382 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
473: hkn0805:1097263:1097382 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [receive] via NET/IBext/0
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [receive] via NET/IBext/0
201: hkn0531:1215724:1215823 [1] NCCL INFO Channel 01 : 201[4b000] -> 200[31000] via P2P/IPC/read
472: hkn0805:1097255:1097378 [0] NCCL INFO comm 0x147070008fb0 rank 472 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
474: hkn0805:1097271:1097381 [2] NCCL INFO comm 0x14ec78008fb0 rank 474 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
213: hkn0535:2384189:2384302 [1] NCCL INFO Channel 00 : 213[4b000] -> 212[31000] via P2P/IPC/read
473: hkn0805:1097263:1097382 [1] NCCL INFO comm 0x145d20008fb0 rank 473 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
475: hkn0805:1097283:1097377 [3] NCCL INFO comm 0x14f7f4008fb0 rank 475 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
213: hkn0535:2384189:2384302 [1] NCCL INFO Channel 01 : 213[4b000] -> 212[31000] via P2P/IPC/read
192: hkn0529:1525995:1526126 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [receive] via NET/IBext/0
216: hkn0601:102816:102929 [0] NCCL INFO Connected all trees
216: hkn0601:102816:102929 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
216: hkn0601:102816:102929 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1413569:1413673 [1] NCCL INFO Channel 00 : 181[4b000] -> 180[31000] via P2P/IPC/read
217: hkn0601:102836:102938 [1] NCCL INFO Connected all trees
 85: hkn0426:799266:799362 [1] NCCL INFO Channel 00 : 85[4b000] -> 84[31000] via P2P/IPC/read
217: hkn0601:102836:102938 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
217: hkn0601:102836:102938 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [send] via NET/IBext/0
184: hkn0527:1334049:1334169 [0] NCCL INFO Connected all trees
184: hkn0527:1334049:1334169 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
184: hkn0527:1334049:1334169 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
157: hkn0516:2901164:2901294 [1] NCCL INFO Connected all trees
157: hkn0516:2901164:2901294 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
157: hkn0516:2901164:2901294 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:777142:777272 [1] NCCL INFO Channel 00 : 341[4b000] -> 340[31000] via P2P/IPC/read
216: hkn0601:102816:102929 [0] NCCL INFO comm 0x146c50008fb0 rank 216 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
332: hkn0636:1639342:1639458 [0] NCCL INFO Connected all trees
181: hkn0526:1413569:1413673 [1] NCCL INFO Channel 01 : 181[4b000] -> 180[31000] via P2P/IPC/read
219: hkn0601:102808:102935 [3] NCCL INFO comm 0x14b74c008fb0 rank 219 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
332: hkn0636:1639342:1639458 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 89: hkn0427:1120325:1120445 [1] NCCL INFO Connected all trees
218: hkn0601:102824:102933 [2] NCCL INFO comm 0x152fd4008fb0 rank 218 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
332: hkn0636:1639342:1639458 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 85: hkn0426:799266:799362 [1] NCCL INFO Channel 01 : 85[4b000] -> 84[31000] via P2P/IPC/read
 89: hkn0427:1120325:1120445 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
453: hkn0736:1493549:1493641 [1] NCCL INFO Channel 00 : 453[4b000] -> 452[31000] via P2P/IPC/read
 89: hkn0427:1120325:1120445 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:387124:387215 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [send] via NET/IBext/0
217: hkn0601:102836:102938 [1] NCCL INFO comm 0x14ee58008fb0 rank 217 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
345: hkn0705:768401:768516 [1] NCCL INFO Connected all trees
185: hkn0527:1334057:1334167 [1] NCCL INFO Connected all trees
345: hkn0705:768401:768516 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2901152:2901289 [0] NCCL INFO Connected all trees
345: hkn0705:768401:768516 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
212: hkn0535:2384201:2384301 [0] NCCL INFO Connected all trees
185: hkn0527:1334057:1334167 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2901152:2901289 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
185: hkn0527:1334057:1334167 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
156: hkn0516:2901152:2901289 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
212: hkn0535:2384201:2384301 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 88: hkn0427:1120324:1120446 [0] NCCL INFO Connected all trees
212: hkn0535:2384201:2384301 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
333: hkn0636:1639334:1639456 [1] NCCL INFO Connected all trees
 88: hkn0427:1120324:1120446 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 88: hkn0427:1120324:1120446 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
344: hkn0705:768421:768521 [0] NCCL INFO Connected all trees
333: hkn0636:1639334:1639456 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2225101:2225223 [1] NCCL INFO Connected all trees
333: hkn0636:1639334:1639456 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:777142:777272 [1] NCCL INFO Channel 01 : 341[4b000] -> 340[31000] via P2P/IPC/read
344: hkn0705:768421:768521 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
344: hkn0705:768421:768521 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
457: hkn0801:2225101:2225223 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2225101:2225223 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
213: hkn0535:2384189:2384302 [1] NCCL INFO Connected all trees
 77: hkn0424:2933097:2933239 [1] NCCL INFO Connected all trees
213: hkn0535:2384189:2384302 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 00 : 329[4b000] -> 328[31000] via P2P/IPC/read
453: hkn0736:1493549:1493641 [1] NCCL INFO Channel 01 : 453[4b000] -> 452[31000] via P2P/IPC/read
213: hkn0535:2384189:2384302 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 77: hkn0424:2933097:2933239 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
158: hkn0516:2901144:2901290 [2] NCCL INFO comm 0x146f88008fb0 rank 158 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 77: hkn0424:2933097:2933239 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 90: hkn0427:1120345:1120439 [2] NCCL INFO comm 0x14d574008fb0 rank 90 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
456: hkn0801:2225122:2225226 [0] NCCL INFO Connected all trees
156: hkn0516:2901152:2901289 [0] NCCL INFO comm 0x146730008fb0 rank 156 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 89: hkn0427:1120325:1120445 [1] NCCL INFO comm 0x14d55c008fb0 rank 89 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
456: hkn0801:2225122:2225226 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
157: hkn0516:2901164:2901294 [1] NCCL INFO comm 0x1456b8008fb0 rank 157 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
184: hkn0527:1334049:1334169 [0] NCCL INFO comm 0x146fc8008fb0 rank 184 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 91: hkn0427:1120333:1120440 [3] NCCL INFO comm 0x150150008fb0 rank 91 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
456: hkn0801:2225122:2225226 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
159: hkn0516:2901136:2901292 [3] NCCL INFO comm 0x153b48008fb0 rank 159 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 88: hkn0427:1120324:1120446 [0] NCCL INFO comm 0x14e11c008fb0 rank 88 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
186: hkn0527:1334041:1334160 [2] NCCL INFO comm 0x146724008fb0 rank 186 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
344: hkn0705:768421:768521 [0] NCCL INFO comm 0x14efc8008fb0 rank 344 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 00 : 73[4b000] -> 72[31000] via P2P/IPC/read
185: hkn0527:1334057:1334167 [1] NCCL INFO comm 0x14c1fc008fb0 rank 185 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
332: hkn0636:1639342:1639458 [0] NCCL INFO comm 0x14afc8008fb0 rank 332 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
345: hkn0705:768401:768516 [1] NCCL INFO comm 0x153558008fb0 rank 345 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 76: hkn0424:2933109:2933241 [0] NCCL INFO Connected all trees
335: hkn0636:1639362:1639461 [3] NCCL INFO comm 0x14ec68008fb0 rank 335 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 76: hkn0424:2933109:2933241 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
346: hkn0705:768409:768518 [2] NCCL INFO comm 0x14de10008fb0 rank 346 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
213: hkn0535:2384189:2384302 [1] NCCL INFO comm 0x148474008fb0 rank 213 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
200: hkn0531:1215696:1215820 [0] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [send] via NET/IBext/0
 76: hkn0424:2933109:2933241 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
347: hkn0705:768400:768514 [3] NCCL INFO comm 0x14e1e4008fb0 rank 347 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
215: hkn0535:2384173:2384300 [3] NCCL INFO comm 0x14835c008fb0 rank 215 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
333: hkn0636:1639334:1639456 [1] NCCL INFO comm 0x145800008fb0 rank 333 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
212: hkn0535:2384201:2384301 [0] NCCL INFO comm 0x152784008fb0 rank 212 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
187: hkn0527:1334069:1334163 [3] NCCL INFO comm 0x14dda8008fb0 rank 187 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
214: hkn0535:2384181:2384305 [2] NCCL INFO comm 0x14f6d4008fb0 rank 214 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
329: hkn0635:1210739:1210866 [1] NCCL INFO Channel 01 : 329[4b000] -> 328[31000] via P2P/IPC/read
456: hkn0801:2225122:2225226 [0] NCCL INFO comm 0x14cd6c008fb0 rank 456 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
459: hkn0801:2225102:2225219 [3] NCCL INFO comm 0x154120008fb0 rank 459 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 77: hkn0424:2933097:2933239 [1] NCCL INFO comm 0x1507c4008fb0 rank 77 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
457: hkn0801:2225101:2225223 [1] NCCL INFO comm 0x1533f0008fb0 rank 457 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
458: hkn0801:2225110:2225221 [2] NCCL INFO comm 0x14a170008fb0 rank 458 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 78: hkn0424:2933089:2933240 [2] NCCL INFO comm 0x150dd8008fb0 rank 78 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 76: hkn0424:2933109:2933241 [0] NCCL INFO comm 0x146a3c008fb0 rank 76 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 73: hkn0423:1689969:1690080 [1] NCCL INFO Channel 01 : 73[4b000] -> 72[31000] via P2P/IPC/read
180: hkn0526:1413561:1413674 [0] NCCL INFO Connected all trees
 79: hkn0424:2933081:2933238 [3] NCCL INFO comm 0x14e144008fb0 rank 79 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
180: hkn0526:1413561:1413674 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
180: hkn0526:1413561:1413674 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
334: hkn0636:1639350:1639453 [2] NCCL INFO comm 0x14a5f0008fb0 rank 334 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 85: hkn0426:799266:799362 [1] NCCL INFO Connected all trees
 85: hkn0426:799266:799362 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:799266:799362 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1413569:1413673 [1] NCCL INFO Connected all trees
181: hkn0526:1413569:1413673 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [send] via NET/IBext/0
181: hkn0526:1413569:1413673 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
437: hkn0731:1371908:1372021 [1] NCCL INFO Channel 00 : 437[4b000] -> 436[31000] via P2P/IPC/read
340: hkn0704:777158:777265 [0] NCCL INFO Connected all trees
 84: hkn0426:799238:799364 [0] NCCL INFO Connected all trees
340: hkn0704:777158:777265 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 84: hkn0426:799238:799364 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:777158:777265 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 84: hkn0426:799238:799364 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
441: hkn0732:1196811:1196965 [1] NCCL INFO Connected all trees
441: hkn0732:1196811:1196965 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
441: hkn0732:1196811:1196965 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
183: hkn0526:1413553:1413678 [3] NCCL INFO comm 0x14e6a4008fb0 rank 183 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
341: hkn0704:777142:777272 [1] NCCL INFO Connected all trees
440: hkn0732:1196819:1196963 [0] NCCL INFO Connected all trees
341: hkn0704:777142:777272 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
412: hkn0724:1701140:1701248 [0] NCCL INFO Connected all trees
341: hkn0704:777142:777272 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [receive] via NET/IBext/0
440: hkn0732:1196819:1196963 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1196819:1196963 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
412: hkn0724:1701140:1701248 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
180: hkn0526:1413561:1413674 [0] NCCL INFO comm 0x151f64008fb0 rank 180 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
412: hkn0724:1701140:1701248 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
437: hkn0731:1371908:1372021 [1] NCCL INFO Channel 01 : 437[4b000] -> 436[31000] via P2P/IPC/read
112: hkn0505:2288969:2289061 [0] NCCL INFO Connected all trees
181: hkn0526:1413569:1413673 [1] NCCL INFO comm 0x150a7c008fb0 rank 181 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
182: hkn0526:1413581:1413675 [2] NCCL INFO comm 0x14cdac008fb0 rank 182 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 85: hkn0426:799266:799362 [1] NCCL INFO comm 0x1478c4008fb0 rank 85 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
112: hkn0505:2288969:2289061 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2288969:2289061 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 87: hkn0426:799254:799358 [3] NCCL INFO comm 0x14891c008fb0 rank 87 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 86: hkn0426:799246:799367 [2] NCCL INFO comm 0x1495e4008fb0 rank 86 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 84: hkn0426:799238:799364 [0] NCCL INFO comm 0x14fbec008fb0 rank 84 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
341: hkn0704:777142:777272 [1] NCCL INFO comm 0x152f40008fb0 rank 341 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
413: hkn0724:1701132:1701247 [1] NCCL INFO Connected all trees
440: hkn0732:1196819:1196963 [0] NCCL INFO comm 0x148504008fb0 rank 440 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
413: hkn0724:1701132:1701247 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
342: hkn0704:777150:777271 [2] NCCL INFO comm 0x1540f8008fb0 rank 342 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
413: hkn0724:1701132:1701247 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
113: hkn0505:2288949:2289068 [1] NCCL INFO Connected all trees
441: hkn0732:1196811:1196965 [1] NCCL INFO comm 0x1485f0008fb0 rank 441 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
343: hkn0704:777170:777274 [3] NCCL INFO comm 0x153c4c008fb0 rank 343 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
442: hkn0732:1196803:1196961 [2] NCCL INFO comm 0x154e08008fb0 rank 442 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
340: hkn0704:777158:777265 [0] NCCL INFO comm 0x151448008fb0 rank 340 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
113: hkn0505:2288949:2289068 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2288949:2289068 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
443: hkn0732:1196831:1196956 [3] NCCL INFO comm 0x1488e4008fb0 rank 443 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
196: hkn0530:1243317:1243433 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [send] via NET/IBext/0
112: hkn0505:2288969:2289061 [0] NCCL INFO comm 0x14ea08008fb0 rank 112 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
412: hkn0724:1701140:1701248 [0] NCCL INFO comm 0x147a54008fb0 rank 412 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
113: hkn0505:2288949:2289068 [1] NCCL INFO comm 0x154518008fb0 rank 113 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
414: hkn0724:1701124:1701254 [2] NCCL INFO comm 0x14f348008fb0 rank 414 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
114: hkn0505:2288957:2289067 [2] NCCL INFO comm 0x146000008fb0 rank 114 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
115: hkn0505:2288941:2289062 [3] NCCL INFO comm 0x148cd4008fb0 rank 115 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
413: hkn0724:1701132:1701247 [1] NCCL INFO comm 0x14fd74008fb0 rank 413 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
415: hkn0724:1701152:1701251 [3] NCCL INFO comm 0x148490008fb0 rank 415 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
140: hkn0512:3029302:3029419 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [send] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO Connected all trees
368: hkn0712:280251:280359 [0] NCCL INFO Connected all trees
152: hkn0515:2881970:2882070 [0] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [send] via NET/IBext/0
436: hkn0731:1371920:1372018 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:280251:280359 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1371920:1372018 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:280251:280359 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:93645:93760 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [receive] via NET/IBext/0
240: hkn0607:889534:889628 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [receive] via NET/IBext/0
437: hkn0731:1371908:1372021 [1] NCCL INFO Connected all trees
437: hkn0731:1371908:1372021 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:280243:280361 [1] NCCL INFO Connected all trees
437: hkn0731:1371908:1372021 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
369: hkn0712:280243:280361 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:280243:280361 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1210747:1210870 [0] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [send] via NET/IBext/0
381: hkn0715:387096:387223 [1] NCCL INFO Connected all trees
381: hkn0715:387096:387223 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
439: hkn0731:1371900:1372017 [3] NCCL INFO comm 0x14f6f8008fb0 rank 439 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
381: hkn0715:387096:387223 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 72: hkn0423:1689989:1690089 [0] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [send] via NET/IBext/0
438: hkn0731:1371892:1372022 [2] NCCL INFO comm 0x1517fc008fb0 rank 438 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
436: hkn0731:1371920:1372018 [0] NCCL INFO comm 0x1496d8008fb0 rank 436 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
380: hkn0715:387124:387215 [0] NCCL INFO Connected all trees
368: hkn0712:280251:280359 [0] NCCL INFO comm 0x14b47c008fb0 rank 368 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
437: hkn0731:1371908:1372021 [1] NCCL INFO comm 0x153e64008fb0 rank 437 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
380: hkn0715:387124:387215 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:387124:387215 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
371: hkn0712:280263:280354 [3] NCCL INFO comm 0x14791c008fb0 rank 371 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
370: hkn0712:280242:280355 [2] NCCL INFO comm 0x146244008fb0 rank 370 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
369: hkn0712:280243:280361 [1] NCCL INFO comm 0x152198008fb0 rank 369 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
380: hkn0715:387124:387215 [0] NCCL INFO comm 0x1482d4008fb0 rank 380 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
381: hkn0715:387096:387223 [1] NCCL INFO comm 0x149700008fb0 rank 381 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
382: hkn0715:387104:387217 [2] NCCL INFO comm 0x145540008fb0 rank 382 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
383: hkn0715:387112:387222 [3] NCCL INFO comm 0x14d1dc008fb0 rank 383 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
197: hkn0530:1243325:1243432 [1] NCCL INFO Channel 00 : 197[4b000] -> 196[31000] via P2P/IPC/read
508: hkn0816:360788:360900 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [send] via NET/IBext/0
201: hkn0531:1215724:1215823 [1] NCCL INFO Connected all trees
201: hkn0531:1215724:1215823 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
201: hkn0531:1215724:1215823 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1398327:1398423 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [receive] via NET/IBext/0
200: hkn0531:1215696:1215820 [0] NCCL INFO Connected all trees
200: hkn0531:1215696:1215820 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
200: hkn0531:1215696:1215820 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1290840:1290959 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [send] via NET/IBext/0
201: hkn0531:1215724:1215823 [1] NCCL INFO comm 0x149b14008fb0 rank 201 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 68: hkn0422:4138173:4138299 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [send] via NET/IBext/0
408: hkn0723:192917:193087 [0] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [send] via NET/IBext/0
200: hkn0531:1215696:1215820 [0] NCCL INFO comm 0x146278008fb0 rank 200 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
197: hkn0530:1243325:1243432 [1] NCCL INFO Channel 01 : 197[4b000] -> 196[31000] via P2P/IPC/read
324: hkn0634:1506032:1506151 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [send] via NET/IBext/0
202: hkn0531:1215712:1215824 [2] NCCL INFO comm 0x14eb48008fb0 rank 202 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
203: hkn0531:1215704:1215819 [3] NCCL INFO comm 0x149fe8008fb0 rank 203 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [receive] via NET/IBext/0
252: hkn0611:694973:695080 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [send] via NET/IBext/0
197: hkn0530:1243325:1243432 [1] NCCL INFO Connected all trees
197: hkn0530:1243325:1243432 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
197: hkn0530:1243325:1243432 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
140: hkn0512:3029302:3029419 [0] NCCL INFO Connected all trees
140: hkn0512:3029302:3029419 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
140: hkn0512:3029302:3029419 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1743761:1743906 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [send] via NET/IBext/0
149: hkn0514:2935893:2936011 [1] NCCL INFO Channel 00 : 149[4b000] -> 148[31000] via P2P/IPC/read
376: hkn0714:417195:417320 [0] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [send] via NET/IBext/0
196: hkn0530:1243317:1243433 [0] NCCL INFO Connected all trees
196: hkn0530:1243317:1243433 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
153: hkn0515:2881958:2882071 [1] NCCL INFO Connected all trees
196: hkn0530:1243317:1243433 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [receive] via NET/IBext/0
153: hkn0515:2881958:2882071 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
153: hkn0515:2881958:2882071 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
141: hkn0512:3029294:3029422 [1] NCCL INFO Connected all trees
141: hkn0512:3029294:3029422 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
141: hkn0512:3029294:3029422 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
152: hkn0515:2881970:2882070 [0] NCCL INFO Connected all trees
152: hkn0515:2881970:2882070 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
197: hkn0530:1243325:1243432 [1] NCCL INFO comm 0x14fa28008fb0 rank 197 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
152: hkn0515:2881970:2882070 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
149: hkn0514:2935893:2936011 [1] NCCL INFO Channel 01 : 149[4b000] -> 148[31000] via P2P/IPC/read
198: hkn0530:1243309:1243429 [2] NCCL INFO comm 0x14fb48008fb0 rank 198 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
329: hkn0635:1210739:1210866 [1] NCCL INFO Connected all trees
199: hkn0530:1243337:1243436 [3] NCCL INFO comm 0x152684008fb0 rank 199 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
196: hkn0530:1243317:1243433 [0] NCCL INFO comm 0x154498008fb0 rank 196 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
140: hkn0512:3029302:3029419 [0] NCCL INFO comm 0x154f4c008fb0 rank 140 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
325: hkn0634:1506024:1506157 [1] NCCL INFO Channel 00 : 325[4b000] -> 324[31000] via P2P/IPC/read
142: hkn0512:3029322:3029415 [2] NCCL INFO comm 0x1476a8008fb0 rank 142 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [receive] via NET/IBext/0
143: hkn0512:3029310:3029418 [3] NCCL INFO comm 0x153020008fb0 rank 143 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
329: hkn0635:1210739:1210866 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
141: hkn0512:3029294:3029422 [1] NCCL INFO comm 0x1543d8008fb0 rank 141 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
329: hkn0635:1210739:1210866 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 73: hkn0423:1689969:1690080 [1] NCCL INFO Connected all trees
 73: hkn0423:1689969:1690080 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1689969:1690080 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
155: hkn0515:2881942:2882062 [3] NCCL INFO comm 0x145ca4008fb0 rank 155 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
152: hkn0515:2881970:2882070 [0] NCCL INFO comm 0x14f29c008fb0 rank 152 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
328: hkn0635:1210747:1210870 [0] NCCL INFO Connected all trees
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 00 : 137[4b000] -> 136[31000] via P2P/IPC/read
153: hkn0515:2881958:2882071 [1] NCCL INFO comm 0x154e84008fb0 rank 153 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
154: hkn0515:2881950:2882069 [2] NCCL INFO comm 0x153d84008fb0 rank 154 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 72: hkn0423:1689989:1690089 [0] NCCL INFO Connected all trees
 72: hkn0423:1689989:1690089 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1210747:1210870 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 72: hkn0423:1689989:1690089 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1210747:1210870 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
193: hkn0529:1526023:1526124 [1] NCCL INFO Connected all trees
193: hkn0529:1526023:1526124 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
193: hkn0529:1526023:1526124 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1210747:1210870 [0] NCCL INFO comm 0x14d418008fb0 rank 328 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 69: hkn0422:4138181:4138294 [1] NCCL INFO Channel 00 : 69[4b000] -> 68[31000] via P2P/IPC/read
192: hkn0529:1525995:1526126 [0] NCCL INFO Connected all trees
192: hkn0529:1525995:1526126 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1525995:1526126 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3051503:3051608 [1] NCCL INFO Channel 01 : 137[4b000] -> 136[31000] via P2P/IPC/read
 72: hkn0423:1689989:1690089 [0] NCCL INFO comm 0x1453cc008fb0 rank 72 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
330: hkn0635:1210755:1210867 [2] NCCL INFO comm 0x14b1b4008fb0 rank 330 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 73: hkn0423:1689969:1690080 [1] NCCL INFO comm 0x14f5b0008fb0 rank 73 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
331: hkn0635:1210773:1210865 [3] NCCL INFO comm 0x14a170008fb0 rank 331 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 75: hkn0423:1689977:1690087 [3] NCCL INFO comm 0x14a354008fb0 rank 75 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
329: hkn0635:1210739:1210866 [1] NCCL INFO comm 0x152590008fb0 rank 329 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 74: hkn0423:1689961:1690083 [2] NCCL INFO comm 0x153d14008fb0 rank 74 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
325: hkn0634:1506024:1506157 [1] NCCL INFO Channel 01 : 325[4b000] -> 324[31000] via P2P/IPC/read
192: hkn0529:1525995:1526126 [0] NCCL INFO comm 0x148a2c008fb0 rank 192 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
193: hkn0529:1526023:1526124 [1] NCCL INFO comm 0x146dbc008fb0 rank 193 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
194: hkn0529:1526011:1526128 [2] NCCL INFO comm 0x151144008fb0 rank 194 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
148: hkn0514:2935885:2936010 [0] NCCL INFO Connected all trees
195: hkn0529:1526003:1526130 [3] NCCL INFO comm 0x14bf1c008fb0 rank 195 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
148: hkn0514:2935885:2936010 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2935885:2936010 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4138181:4138294 [1] NCCL INFO Channel 01 : 69[4b000] -> 68[31000] via P2P/IPC/read
149: hkn0514:2935893:2936011 [1] NCCL INFO Connected all trees
149: hkn0514:2935893:2936011 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
149: hkn0514:2935893:2936011 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:674466:674561 [1] NCCL INFO Connected all trees
396: hkn0719:1290840:1290959 [0] NCCL INFO Connected all trees
396: hkn0719:1290840:1290959 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1141748:1141849 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [receive] via NET/IBext/0
396: hkn0719:1290840:1290959 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:674466:674561 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
229: hkn0604:674466:674561 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2284159:2284270 [1] NCCL INFO Channel 00 : 405[4b000] -> 404[31000] via P2P/IPC/read
228: hkn0604:674438:674558 [0] NCCL INFO Connected all trees
409: hkn0723:192925:193085 [1] NCCL INFO Connected all trees
228: hkn0604:674438:674558 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
149: hkn0514:2935893:2936011 [1] NCCL INFO comm 0x154ab4008fb0 rank 149 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
397: hkn0719:1290860:1290956 [1] NCCL INFO Connected all trees
228: hkn0604:674438:674558 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
409: hkn0723:192925:193085 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
409: hkn0723:192925:193085 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
397: hkn0719:1290860:1290956 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
397: hkn0719:1290860:1290956 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
148: hkn0514:2935885:2936010 [0] NCCL INFO comm 0x153a88008fb0 rank 148 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
248: hkn0609:696056:696155 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [receive] via NET/IBext/0
150: hkn0514:2935913:2936009 [2] NCCL INFO comm 0x14be68008fb0 rank 150 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
151: hkn0514:2935901:2936013 [3] NCCL INFO comm 0x148b08008fb0 rank 151 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
408: hkn0723:192917:193087 [0] NCCL INFO Connected all trees
408: hkn0723:192917:193087 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:192917:193087 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:674466:674561 [1] NCCL INFO comm 0x147a6c008fb0 rank 229 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
228: hkn0604:674438:674558 [0] NCCL INFO comm 0x1503a8008fb0 rank 228 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 00 : 393[4b000] -> 392[31000] via P2P/IPC/read
325: hkn0634:1506024:1506157 [1] NCCL INFO Connected all trees
405: hkn0721:2284159:2284270 [1] NCCL INFO Channel 01 : 405[4b000] -> 404[31000] via P2P/IPC/read
230: hkn0604:674446:674565 [2] NCCL INFO comm 0x146518008fb0 rank 230 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
396: hkn0719:1290840:1290959 [0] NCCL INFO comm 0x152c68008fb0 rank 396 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
325: hkn0634:1506024:1506157 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1506024:1506157 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
399: hkn0719:1290839:1290961 [3] NCCL INFO comm 0x145d4c008fb0 rank 399 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
231: hkn0604:674454:674562 [3] NCCL INFO comm 0x14f400008fb0 rank 231 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
408: hkn0723:192917:193087 [0] NCCL INFO comm 0x14f984008fb0 rank 408 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
397: hkn0719:1290860:1290956 [1] NCCL INFO comm 0x148498008fb0 rank 397 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
324: hkn0634:1506032:1506151 [0] NCCL INFO Connected all trees
398: hkn0719:1290848:1290952 [2] NCCL INFO comm 0x150eec008fb0 rank 398 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
411: hkn0723:192909:193084 [3] NCCL INFO comm 0x150178008fb0 rank 411 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
324: hkn0634:1506032:1506151 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1506032:1506151 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
409: hkn0723:192925:193085 [1] NCCL INFO comm 0x1544e0008fb0 rank 409 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
410: hkn0723:192937:193090 [2] NCCL INFO comm 0x151b64008fb0 rank 410 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
393: hkn0718:3902174:3902293 [1] NCCL INFO Channel 01 : 393[4b000] -> 392[31000] via P2P/IPC/read
 68: hkn0422:4138173:4138299 [0] NCCL INFO Connected all trees
324: hkn0634:1506032:1506151 [0] NCCL INFO comm 0x15392c008fb0 rank 324 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
225: hkn0603:1398307:1398426 [1] NCCL INFO Connected all trees
 68: hkn0422:4138173:4138299 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1506024:1506157 [1] NCCL INFO comm 0x14c5a0008fb0 rank 325 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 68: hkn0422:4138173:4138299 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
225: hkn0603:1398307:1398426 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
225: hkn0603:1398307:1398426 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
326: hkn0634:1506052:1506156 [2] NCCL INFO comm 0x154b18008fb0 rank 326 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
327: hkn0634:1506040:1506149 [3] NCCL INFO comm 0x14c364008fb0 rank 327 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
224: hkn0603:1398327:1398423 [0] NCCL INFO Connected all trees
 69: hkn0422:4138181:4138294 [1] NCCL INFO Connected all trees
224: hkn0603:1398327:1398423 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1398327:1398423 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4138181:4138294 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
320: hkn0633:1511506:1511630 [0] NCCL INFO Connected all trees
373: hkn0713:455427:455540 [1] NCCL INFO Channel 00 : 373[4b000] -> 372[31000] via P2P/IPC/read
 69: hkn0422:4138181:4138294 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [send] via NET/IBext/0
136: hkn0511:3051475:3051605 [0] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [send] via NET/IBext/0
320: hkn0633:1511506:1511630 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1743761:1743906 [0] NCCL INFO Connected all trees
320: hkn0633:1511506:1511630 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1743761:1743906 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1743761:1743906 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:417195:417320 [0] NCCL INFO Connected all trees
225: hkn0603:1398307:1398426 [1] NCCL INFO comm 0x14abc4008fb0 rank 225 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 65: hkn0421:2163528:2163777 [1] NCCL INFO Connected all trees
376: hkn0714:417195:417320 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
376: hkn0714:417195:417320 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
226: hkn0603:1398315:1398422 [2] NCCL INFO comm 0x152664008fb0 rank 226 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 65: hkn0421:2163528:2163777 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
321: hkn0633:1511514:1511639 [1] NCCL INFO Connected all trees
404: hkn0721:2284143:2284269 [0] NCCL INFO Connected all trees
 65: hkn0421:2163528:2163777 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:889534:889628 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [receive] via NET/IBext/0
227: hkn0603:1398303:1398428 [3] NCCL INFO comm 0x14a2b0008fb0 rank 227 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
404: hkn0721:2284143:2284269 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2284143:2284269 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4138173:4138299 [0] NCCL INFO comm 0x154e78008fb0 rank 68 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
224: hkn0603:1398327:1398423 [0] NCCL INFO comm 0x1488c0008fb0 rank 224 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
317: hkn0632:1743769:1743914 [1] NCCL INFO Connected all trees
321: hkn0633:1511514:1511639 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 70: hkn0422:4138165:4138293 [2] NCCL INFO comm 0x15425c008fb0 rank 70 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
321: hkn0633:1511514:1511639 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:455427:455540 [1] NCCL INFO Channel 01 : 373[4b000] -> 372[31000] via P2P/IPC/read
317: hkn0632:1743769:1743914 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 64: hkn0421:2163508:2163779 [0] NCCL INFO Connected all trees
 71: hkn0422:4138193:4138296 [3] NCCL INFO comm 0x14ee64008fb0 rank 71 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
377: hkn0714:417216:417317 [1] NCCL INFO Connected all trees
317: hkn0632:1743769:1743914 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4138181:4138294 [1] NCCL INFO comm 0x150560008fb0 rank 69 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 64: hkn0421:2163508:2163779 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
377: hkn0714:417216:417317 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 64: hkn0421:2163508:2163779 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
377: hkn0714:417216:417317 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
405: hkn0721:2284159:2284270 [1] NCCL INFO Connected all trees
320: hkn0633:1511506:1511630 [0] NCCL INFO comm 0x14f114008fb0 rank 320 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
405: hkn0721:2284159:2284270 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
405: hkn0721:2284159:2284270 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1743761:1743906 [0] NCCL INFO comm 0x1525c8008fb0 rank 316 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
318: hkn0632:1743760:1743909 [2] NCCL INFO comm 0x150fe0008fb0 rank 318 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 65: hkn0421:2163528:2163777 [1] NCCL INFO comm 0x14778c008fb0 rank 65 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
322: hkn0633:1511522:1511638 [2] NCCL INFO comm 0x154020008fb0 rank 322 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
321: hkn0633:1511514:1511639 [1] NCCL INFO comm 0x14e2d0008fb0 rank 321 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
319: hkn0632:1743781:1743911 [3] NCCL INFO comm 0x145fdc008fb0 rank 319 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 64: hkn0421:2163508:2163779 [0] NCCL INFO comm 0x1466a4008fb0 rank 64 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
323: hkn0633:1511534:1511635 [3] NCCL INFO comm 0x150ccc008fb0 rank 323 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
379: hkn0714:417204:417316 [3] NCCL INFO comm 0x14a5d4008fb0 rank 379 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 66: hkn0421:2163516:2163782 [2] NCCL INFO comm 0x14d620008fb0 rank 66 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
317: hkn0632:1743769:1743914 [1] NCCL INFO comm 0x146bc0008fb0 rank 317 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 67: hkn0421:2163500:2163778 [3] NCCL INFO comm 0x14f370008fb0 rank 67 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
404: hkn0721:2284143:2284269 [0] NCCL INFO comm 0x1532ac008fb0 rank 404 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
376: hkn0714:417195:417320 [0] NCCL INFO comm 0x14f538008fb0 rank 376 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
406: hkn0721:2284171:2284267 [2] NCCL INFO comm 0x147ea0008fb0 rank 406 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
377: hkn0714:417216:417317 [1] NCCL INFO comm 0x14c06c008fb0 rank 377 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
405: hkn0721:2284159:2284270 [1] NCCL INFO comm 0x14e59c008fb0 rank 405 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
378: hkn0714:417196:417322 [2] NCCL INFO comm 0x1546d0008fb0 rank 378 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
407: hkn0721:2284151:2284268 [3] NCCL INFO comm 0x14cf60008fb0 rank 407 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
373: hkn0713:455427:455540 [1] NCCL INFO Connected all trees
132: hkn0510:2747220:2747346 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [send] via NET/IBext/0
373: hkn0713:455427:455540 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
373: hkn0713:455427:455540 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
372: hkn0713:455428:455539 [0] NCCL INFO Connected all trees
372: hkn0713:455428:455539 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:455428:455539 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3902194:3902291 [0] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [send] via NET/IBext/0
453: hkn0736:1493549:1493641 [1] NCCL INFO Connected all trees
372: hkn0713:455428:455539 [0] NCCL INFO comm 0x147050008fb0 rank 372 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
453: hkn0736:1493549:1493641 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
373: hkn0713:455427:455540 [1] NCCL INFO comm 0x152a80008fb0 rank 373 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
453: hkn0736:1493549:1493641 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
374: hkn0713:455429:455542 [2] NCCL INFO comm 0x14afec008fb0 rank 374 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
375: hkn0713:455441:455538 [3] NCCL INFO comm 0x14f8f4008fb0 rank 375 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
452: hkn0736:1493537:1493642 [0] NCCL INFO Connected all trees
452: hkn0736:1493537:1493642 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1493537:1493642 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:694973:695080 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [send] via NET/IBext/0
453: hkn0736:1493549:1493641 [1] NCCL INFO comm 0x14bbf8008fb0 rank 453 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
455: hkn0736:1493529:1493646 [3] NCCL INFO comm 0x15091c008fb0 rank 455 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
496: hkn0812:678913:679036 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [receive] via NET/IBext/0
452: hkn0736:1493537:1493642 [0] NCCL INFO comm 0x150974008fb0 rank 452 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
454: hkn0736:1493528:1493648 [2] NCCL INFO comm 0x154854008fb0 rank 454 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
388: hkn0717:4172687:4172818 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [send] via NET/IBext/0
312: hkn0631:1006952:1007073 [0] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [send] via NET/IBext/0
137: hkn0511:3051503:3051608 [1] NCCL INFO Connected all trees
137: hkn0511:3051503:3051608 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
133: hkn0510:2747236:2747343 [1] NCCL INFO Channel 00 : 133[4b000] -> 132[31000] via P2P/IPC/read
137: hkn0511:3051503:3051608 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
449: hkn0734:1141728:1141851 [1] NCCL INFO Connected all trees
449: hkn0734:1141728:1141851 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
449: hkn0734:1141728:1141851 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
136: hkn0511:3051475:3051605 [0] NCCL INFO Connected all trees
136: hkn0511:3051475:3051605 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3051475:3051605 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
448: hkn0734:1141748:1141849 [0] NCCL INFO Connected all trees
448: hkn0734:1141748:1141849 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1141748:1141849 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
480: hkn0807:1004272:1004391 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [receive] via NET/IBext/0
137: hkn0511:3051503:3051608 [1] NCCL INFO comm 0x149938008fb0 rank 137 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
138: hkn0511:3051491:3051603 [2] NCCL INFO comm 0x1531fc008fb0 rank 138 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
139: hkn0511:3051483:3051604 [3] NCCL INFO comm 0x1490d0008fb0 rank 139 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
136: hkn0511:3051475:3051605 [0] NCCL INFO comm 0x14fda4008fb0 rank 136 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
448: hkn0734:1141748:1141849 [0] NCCL INFO comm 0x151df0008fb0 rank 448 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
451: hkn0734:1141736:1141845 [3] NCCL INFO comm 0x14b690008fb0 rank 451 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
133: hkn0510:2747236:2747343 [1] NCCL INFO Channel 01 : 133[4b000] -> 132[31000] via P2P/IPC/read
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [send] via NET/IBext/0
449: hkn0734:1141728:1141851 [1] NCCL INFO comm 0x1459d4008fb0 rank 449 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
450: hkn0734:1141720:1141848 [2] NCCL INFO comm 0x15455c008fb0 rank 450 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
241: hkn0607:889514:889633 [1] NCCL INFO Connected all trees
241: hkn0607:889514:889633 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
241: hkn0607:889514:889633 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
133: hkn0510:2747236:2747343 [1] NCCL INFO Connected all trees
133: hkn0510:2747236:2747343 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
133: hkn0510:2747236:2747343 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:889534:889628 [0] NCCL INFO Connected all trees
240: hkn0607:889534:889628 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
240: hkn0607:889534:889628 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2747220:2747346 [0] NCCL INFO Connected all trees
132: hkn0510:2747220:2747346 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
132: hkn0510:2747220:2747346 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
243: hkn0607:889506:889630 [3] NCCL INFO comm 0x15305c008fb0 rank 243 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
240: hkn0607:889534:889628 [0] NCCL INFO comm 0x151714008fb0 rank 240 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
241: hkn0607:889514:889633 [1] NCCL INFO comm 0x149af0008fb0 rank 241 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
389: hkn0717:4172715:4172825 [1] NCCL INFO Channel 00 : 389[4b000] -> 388[31000] via P2P/IPC/read
242: hkn0607:889522:889635 [2] NCCL INFO comm 0x151270008fb0 rank 242 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
132: hkn0510:2747220:2747346 [0] NCCL INFO comm 0x14ab78008fb0 rank 132 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
392: hkn0718:3902194:3902291 [0] NCCL INFO Connected all trees
392: hkn0718:3902194:3902291 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3902194:3902291 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
134: hkn0510:2747248:2747351 [2] NCCL INFO comm 0x1494a4008fb0 rank 134 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
393: hkn0718:3902174:3902293 [1] NCCL INFO Connected all trees
393: hkn0718:3902174:3902293 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:4172715:4172825 [1] NCCL INFO Channel 01 : 389[4b000] -> 388[31000] via P2P/IPC/read
393: hkn0718:3902174:3902293 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
129: hkn0509:3109564:3109680 [1] NCCL INFO Connected all trees
129: hkn0509:3109564:3109680 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
253: hkn0611:694985:695081 [1] NCCL INFO Connected all trees
393: hkn0718:3902174:3902293 [1] NCCL INFO comm 0x146924008fb0 rank 393 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
129: hkn0509:3109564:3109680 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:694985:695081 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
253: hkn0611:694985:695081 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3902194:3902291 [0] NCCL INFO comm 0x14aab8008fb0 rank 392 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
395: hkn0718:3902182:3902290 [3] NCCL INFO comm 0x147b90008fb0 rank 395 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
284: hkn0623:1857870:1858027 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [send] via NET/IBext/0
394: hkn0718:3902173:3902289 [2] NCCL INFO comm 0x153f84008fb0 rank 394 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
128: hkn0509:3109576:3109676 [0] NCCL INFO Connected all trees
128: hkn0509:3109576:3109676 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
128: hkn0509:3109576:3109676 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:694973:695080 [0] NCCL INFO Connected all trees
252: hkn0611:694973:695080 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:694973:695080 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:389997:390101 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [send] via NET/IBext/0
313: hkn0631:1006972:1007066 [1] NCCL INFO Connected all trees
313: hkn0631:1006972:1007066 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
313: hkn0631:1006972:1007066 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
129: hkn0509:3109564:3109680 [1] NCCL INFO comm 0x145944008fb0 rank 129 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
128: hkn0509:3109576:3109676 [0] NCCL INFO comm 0x14bb70008fb0 rank 128 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
312: hkn0631:1006952:1007073 [0] NCCL INFO Connected all trees
312: hkn0631:1006952:1007073 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
130: hkn0509:3109548:3109677 [2] NCCL INFO comm 0x14d154008fb0 rank 130 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
312: hkn0631:1006952:1007073 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:694985:695081 [1] NCCL INFO comm 0x151510008fb0 rank 253 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
309: hkn0630:1583628:1583756 [1] NCCL INFO Channel 00 : 309[4b000] -> 308[31000] via P2P/IPC/read
131: hkn0509:3109556:3109675 [3] NCCL INFO comm 0x14e09c008fb0 rank 131 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
252: hkn0611:694973:695080 [0] NCCL INFO comm 0x1503c4008fb0 rank 252 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
254: hkn0611:694965:695087 [2] NCCL INFO comm 0x148b08008fb0 rank 254 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
388: hkn0717:4172687:4172818 [0] NCCL INFO Connected all trees
255: hkn0611:694957:695086 [3] NCCL INFO comm 0x146864008fb0 rank 255 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
388: hkn0717:4172687:4172818 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
315: hkn0631:1006960:1007067 [3] NCCL INFO comm 0x14f750008fb0 rank 315 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
388: hkn0717:4172687:4172818 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1006952:1007073 [0] NCCL INFO comm 0x14dd68008fb0 rank 312 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
313: hkn0631:1006972:1007066 [1] NCCL INFO comm 0x152dac008fb0 rank 313 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
314: hkn0631:1006951:1007072 [2] NCCL INFO comm 0x14bde0008fb0 rank 314 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
389: hkn0717:4172715:4172825 [1] NCCL INFO Connected all trees
485: hkn0808:955879:955981 [1] NCCL INFO Connected all trees
389: hkn0717:4172715:4172825 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1583628:1583756 [1] NCCL INFO Channel 01 : 309[4b000] -> 308[31000] via P2P/IPC/read
485: hkn0808:955879:955981 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:4172715:4172825 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:955879:955981 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:955851:955982 [0] NCCL INFO Connected all trees
384: hkn0716:93645:93760 [0] NCCL INFO Connected all trees
484: hkn0808:955851:955982 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:955851:955982 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:93645:93760 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
388: hkn0717:4172687:4172818 [0] NCCL INFO comm 0x154d6c008fb0 rank 388 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
384: hkn0716:93645:93760 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
389: hkn0717:4172715:4172825 [1] NCCL INFO comm 0x14c9d0008fb0 rank 389 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
391: hkn0717:4172703:4172819 [3] NCCL INFO comm 0x14b918008fb0 rank 391 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
390: hkn0717:4172695:4172824 [2] NCCL INFO comm 0x153c04008fb0 rank 390 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
385: hkn0716:93646:93761 [1] NCCL INFO Connected all trees
385: hkn0716:93646:93761 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
485: hkn0808:955879:955981 [1] NCCL INFO comm 0x1534a8008fb0 rank 485 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
385: hkn0716:93646:93761 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
486: hkn0808:955867:955976 [2] NCCL INFO comm 0x1514f4008fb0 rank 486 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
484: hkn0808:955851:955982 [0] NCCL INFO comm 0x1485a4008fb0 rank 484 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
487: hkn0808:955859:955975 [3] NCCL INFO comm 0x1470e0008fb0 rank 487 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
504: hkn0815:380357:380455 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [receive] via NET/IBext/0
384: hkn0716:93645:93760 [0] NCCL INFO comm 0x14579c008fb0 rank 384 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
135: hkn0510:2747228:2747349 [3] NCCL INFO comm 0x1524ec008fb0 rank 135 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
386: hkn0716:93666:93764 [2] NCCL INFO comm 0x148390008fb0 rank 386 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
387: hkn0716:93654:93766 [3] NCCL INFO comm 0x14d768008fb0 rank 387 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
385: hkn0716:93646:93761 [1] NCCL INFO comm 0x1507ac008fb0 rank 385 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
133: hkn0510:2747236:2747343 [1] NCCL INFO comm 0x151f4c008fb0 rank 133 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
308: hkn0630:1583656:1583761 [0] NCCL INFO Connected all trees
308: hkn0630:1583656:1583761 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
308: hkn0630:1583656:1583761 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:696056:696155 [0] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [send] via NET/IBext/0
481: hkn0807:1004271:1004387 [1] NCCL INFO Connected all trees
309: hkn0630:1583628:1583756 [1] NCCL INFO Connected all trees
481: hkn0807:1004271:1004387 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
481: hkn0807:1004271:1004387 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
309: hkn0630:1583628:1583756 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1583628:1583756 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
480: hkn0807:1004272:1004391 [0] NCCL INFO Connected all trees
480: hkn0807:1004272:1004391 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1004272:1004391 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
310: hkn0630:1583644:1583757 [2] NCCL INFO comm 0x1506e8008fb0 rank 310 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
308: hkn0630:1583656:1583761 [0] NCCL INFO comm 0x1478b8008fb0 rank 308 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
311: hkn0630:1583636:1583760 [3] NCCL INFO comm 0x14a058008fb0 rank 311 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
309: hkn0630:1583628:1583756 [1] NCCL INFO comm 0x14d21c008fb0 rank 309 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
481: hkn0807:1004271:1004387 [1] NCCL INFO comm 0x1499b0008fb0 rank 481 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
480: hkn0807:1004272:1004391 [0] NCCL INFO comm 0x14ec3c008fb0 rank 480 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
482: hkn0807:1004292:1004392 [2] NCCL INFO comm 0x1482fc008fb0 rank 482 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
483: hkn0807:1004280:1004394 [3] NCCL INFO comm 0x14c4c0008fb0 rank 483 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
496: hkn0812:678913:679036 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [receive] via NET/IBext/0
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [send] via NET/IBext/0
124: hkn0508:3124325:3124404 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [send] via NET/IBext/0
284: hkn0623:1857870:1858027 [0] NCCL INFO Connected all trees
284: hkn0623:1857870:1858027 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1857870:1858027 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
285: hkn0623:1857886:1858018 [1] NCCL INFO Connected all trees
285: hkn0623:1857886:1858018 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
285: hkn0623:1857886:1858018 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:389997:390101 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [send] via NET/IBext/0
508: hkn0816:360788:360900 [0] NCCL INFO Connected all trees
287: hkn0623:1857898:1858023 [3] NCCL INFO comm 0x147cc8008fb0 rank 287 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
508: hkn0816:360788:360900 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
285: hkn0623:1857886:1858018 [1] NCCL INFO comm 0x1496b8008fb0 rank 285 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
508: hkn0816:360788:360900 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
286: hkn0623:1857878:1858024 [2] NCCL INFO comm 0x14faac008fb0 rank 286 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
284: hkn0623:1857870:1858027 [0] NCCL INFO comm 0x14d950008fb0 rank 284 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
509: hkn0816:360808:360905 [1] NCCL INFO Connected all trees
248: hkn0609:696056:696155 [0] NCCL INFO Connected all trees
509: hkn0816:360808:360905 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:696056:696155 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
509: hkn0816:360808:360905 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:696056:696155 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
249: hkn0609:696028:696150 [1] NCCL INFO Connected all trees
249: hkn0609:696028:696150 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:696028:696150 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:470935:471034 [1] NCCL INFO Channel 00 : 245[4b000] -> 244[31000] via P2P/IPC/read
508: hkn0816:360788:360900 [0] NCCL INFO comm 0x153788008fb0 rank 508 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
509: hkn0816:360808:360905 [1] NCCL INFO comm 0x14fdc4008fb0 rank 509 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
510: hkn0816:360796:360907 [2] NCCL INFO comm 0x145d74008fb0 rank 510 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
511: hkn0816:360780:360901 [3] NCCL INFO comm 0x1470ec008fb0 rank 511 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
248: hkn0609:696056:696155 [0] NCCL INFO comm 0x14a90c008fb0 rank 248 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
245: hkn0608:470935:471034 [1] NCCL INFO Channel 01 : 245[4b000] -> 244[31000] via P2P/IPC/read
250: hkn0609:696036:696151 [2] NCCL INFO comm 0x14c63c008fb0 rank 250 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
251: hkn0609:696044:696154 [3] NCCL INFO comm 0x14cbd4008fb0 rank 251 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
249: hkn0609:696028:696150 [1] NCCL INFO comm 0x1531ac008fb0 rank 249 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
280: hkn0622:2005593:2005692 [0] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [send] via NET/IBext/0
260: hkn0613:887844:887968 [0] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [receive] via NET/IBext/0
244: hkn0608:470923:471037 [0] NCCL INFO Connected all trees
244: hkn0608:470923:471037 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
244: hkn0608:470923:471037 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
245: hkn0608:470935:471034 [1] NCCL INFO Connected all trees
245: hkn0608:470935:471034 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:470935:471034 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
244: hkn0608:470923:471037 [0] NCCL INFO comm 0x154fd8008fb0 rank 244 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
247: hkn0608:470914:471033 [3] NCCL INFO comm 0x14f654008fb0 rank 247 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
245: hkn0608:470935:471034 [1] NCCL INFO comm 0x145c7c008fb0 rank 245 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
246: hkn0608:470915:471032 [2] NCCL INFO comm 0x14a798008fb0 rank 246 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
125: hkn0508:3124305:3124410 [1] NCCL INFO Connected all trees
497: hkn0812:678921:679031 [1] NCCL INFO Connected all trees
125: hkn0508:3124305:3124410 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
125: hkn0508:3124305:3124410 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
497: hkn0812:678921:679031 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:678921:679031 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
269: hkn0616:389977:390103 [1] NCCL INFO Connected all trees
124: hkn0508:3124325:3124404 [0] NCCL INFO Connected all trees
496: hkn0812:678913:679036 [0] NCCL INFO Connected all trees
269: hkn0616:389977:390103 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
269: hkn0616:389977:390103 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3124325:3124404 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:678913:679036 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
496: hkn0812:678913:679036 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3124325:3124404 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:380357:380455 [0] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [send] via NET/IBext/0
268: hkn0616:389997:390101 [0] NCCL INFO Connected all trees
268: hkn0616:389997:390101 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
268: hkn0616:389997:390101 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
497: hkn0812:678921:679031 [1] NCCL INFO comm 0x147cc4008fb0 rank 497 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
496: hkn0812:678913:679036 [0] NCCL INFO comm 0x154920008fb0 rank 496 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
498: hkn0812:678929:679040 [2] NCCL INFO comm 0x153568008fb0 rank 498 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
499: hkn0812:678941:679039 [3] NCCL INFO comm 0x1531cc008fb0 rank 499 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
269: hkn0616:389977:390103 [1] NCCL INFO comm 0x145940008fb0 rank 269 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
125: hkn0508:3124305:3124410 [1] NCCL INFO comm 0x1537e4008fb0 rank 125 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
268: hkn0616:389997:390101 [0] NCCL INFO comm 0x155178008fb0 rank 268 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
126: hkn0508:3124297:3124412 [2] NCCL INFO comm 0x14f8b8008fb0 rank 126 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
127: hkn0508:3124313:3124406 [3] NCCL INFO comm 0x149f2c008fb0 rank 127 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
265: hkn0615:399447:399552 [1] NCCL INFO Channel 00 : 265[4b000] -> 264[31000] via P2P/IPC/read
271: hkn0616:389985:390100 [3] NCCL INFO comm 0x14b928008fb0 rank 271 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 60: hkn0420:3195338:3195466 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [send] via NET/IBext/0
270: hkn0616:389969:390099 [2] NCCL INFO comm 0x14a284008fb0 rank 270 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
124: hkn0508:3124325:3124404 [0] NCCL INFO comm 0x1531b4008fb0 rank 124 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
265: hkn0615:399447:399552 [1] NCCL INFO Channel 01 : 265[4b000] -> 264[31000] via P2P/IPC/read
281: hkn0622:2005573:2005694 [1] NCCL INFO Connected all trees
281: hkn0622:2005573:2005694 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2005573:2005694 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
280: hkn0622:2005593:2005692 [0] NCCL INFO Connected all trees
280: hkn0622:2005593:2005692 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
280: hkn0622:2005593:2005692 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:1976619:1976745 [1] NCCL INFO Channel 00 : 277[4b000] -> 276[31000] via P2P/IPC/read
280: hkn0622:2005593:2005692 [0] NCCL INFO comm 0x15346c008fb0 rank 280 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
282: hkn0622:2005581:2005688 [2] NCCL INFO comm 0x147cd8008fb0 rank 282 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
281: hkn0622:2005573:2005694 [1] NCCL INFO comm 0x14859c008fb0 rank 281 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
283: hkn0622:2005565:2005687 [3] NCCL INFO comm 0x149db8008fb0 rank 283 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
120: hkn0507:3172228:3172326 [0] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [send] via NET/IBext/0
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [send] via NET/IBext/0
277: hkn0621:1976619:1976745 [1] NCCL INFO Channel 01 : 277[4b000] -> 276[31000] via P2P/IPC/read
276: hkn0621:1976635:1976739 [0] NCCL INFO Connected all trees
276: hkn0621:1976635:1976739 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
276: hkn0621:1976635:1976739 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
264: hkn0615:399427:399550 [0] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [send] via NET/IBext/0
277: hkn0621:1976619:1976745 [1] NCCL INFO Connected all trees
277: hkn0621:1976619:1976745 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:380357:380455 [0] NCCL INFO Connected all trees
277: hkn0621:1976619:1976745 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:661009:661108 [1] NCCL INFO Channel 00 : 501[4b000] -> 500[31000] via P2P/IPC/read
504: hkn0815:380357:380455 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:380357:380455 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:1976619:1976745 [1] NCCL INFO comm 0x154320008fb0 rank 277 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
278: hkn0621:1976647:1976747 [2] NCCL INFO comm 0x149ee0008fb0 rank 278 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
505: hkn0815:380329:380451 [1] NCCL INFO Connected all trees
505: hkn0815:380329:380451 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
505: hkn0815:380329:380451 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:661009:661108 [1] NCCL INFO Channel 01 : 501[4b000] -> 500[31000] via P2P/IPC/read
276: hkn0621:1976635:1976739 [0] NCCL INFO comm 0x14a500008fb0 rank 276 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
279: hkn0621:1976627:1976741 [3] NCCL INFO comm 0x14e50c008fb0 rank 279 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 61: hkn0420:3195354:3195457 [1] NCCL INFO Connected all trees
 61: hkn0420:3195354:3195457 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 61: hkn0420:3195354:3195457 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:380357:380455 [0] NCCL INFO comm 0x14ba30008fb0 rank 504 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
505: hkn0815:380329:380451 [1] NCCL INFO comm 0x154b50008fb0 rank 505 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 60: hkn0420:3195338:3195466 [0] NCCL INFO Connected all trees
506: hkn0815:380337:380459 [2] NCCL INFO comm 0x154b68008fb0 rank 506 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 60: hkn0420:3195338:3195466 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
507: hkn0815:380345:380457 [3] NCCL INFO comm 0x1549dc008fb0 rank 507 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 60: hkn0420:3195338:3195466 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 62: hkn0420:3195366:3195465 [2] NCCL INFO comm 0x147f10008fb0 rank 62 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 60: hkn0420:3195338:3195466 [0] NCCL INFO comm 0x14b6b8008fb0 rank 60 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
260: hkn0613:887844:887968 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [send] via NET/IBext/0
 61: hkn0420:3195354:3195457 [1] NCCL INFO comm 0x14bc94008fb0 rank 61 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 63: hkn0420:3195346:3195463 [3] NCCL INFO comm 0x151450008fb0 rank 63 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
500: hkn0814:660997:661104 [0] NCCL INFO Connected all trees
500: hkn0814:660997:661104 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
500: hkn0814:660997:661104 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:661009:661108 [1] NCCL INFO Connected all trees
501: hkn0814:661009:661108 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
501: hkn0814:661009:661108 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
120: hkn0507:3172228:3172326 [0] NCCL INFO Connected all trees
500: hkn0814:660997:661104 [0] NCCL INFO comm 0x14dc4c008fb0 rank 500 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
120: hkn0507:3172228:3172326 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3172228:3172326 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
502: hkn0814:660989:661111 [2] NCCL INFO comm 0x15170c008fb0 rank 502 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
501: hkn0814:661009:661108 [1] NCCL INFO comm 0x150268008fb0 rank 501 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
503: hkn0814:660981:661105 [3] NCCL INFO comm 0x152f6c008fb0 rank 503 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
117: hkn0506:823185:823311 [1] NCCL INFO Channel 00 : 117[4b000] -> 116[31000] via P2P/IPC/read
121: hkn0507:3172216:3172329 [1] NCCL INFO Connected all trees
121: hkn0507:3172216:3172329 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
121: hkn0507:3172216:3172329 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
120: hkn0507:3172228:3172326 [0] NCCL INFO comm 0x1466cc008fb0 rank 120 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
117: hkn0506:823185:823311 [1] NCCL INFO Channel 01 : 117[4b000] -> 116[31000] via P2P/IPC/read
123: hkn0507:3172200:3172323 [3] NCCL INFO comm 0x1529c4008fb0 rank 123 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
121: hkn0507:3172216:3172329 [1] NCCL INFO comm 0x1469fc008fb0 rank 121 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
122: hkn0507:3172208:3172331 [2] NCCL INFO comm 0x14abe0008fb0 rank 122 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 28: hkn0411:2301020:2301135 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [send] via NET/IBext/0
261: hkn0613:887816:887974 [1] NCCL INFO Channel 00 : 261[4b000] -> 260[31000] via P2P/IPC/read
265: hkn0615:399447:399552 [1] NCCL INFO Connected all trees
265: hkn0615:399447:399552 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 56: hkn0419:1529464:1529580 [0] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [send] via NET/IBext/0
265: hkn0615:399447:399552 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
116: hkn0506:823193:823308 [0] NCCL INFO Connected all trees
264: hkn0615:399427:399550 [0] NCCL INFO Connected all trees
116: hkn0506:823193:823308 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:823193:823308 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
264: hkn0615:399427:399550 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
264: hkn0615:399427:399550 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
117: hkn0506:823185:823311 [1] NCCL INFO Connected all trees
117: hkn0506:823185:823311 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
267: hkn0615:399435:399549 [3] NCCL INFO comm 0x154df4008fb0 rank 267 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
117: hkn0506:823185:823311 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
261: hkn0613:887816:887974 [1] NCCL INFO Channel 01 : 261[4b000] -> 260[31000] via P2P/IPC/read
266: hkn0615:399419:399548 [2] NCCL INFO comm 0x145fb0008fb0 rank 266 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
264: hkn0615:399427:399550 [0] NCCL INFO comm 0x148ecc008fb0 rank 264 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
265: hkn0615:399447:399552 [1] NCCL INFO comm 0x149378008fb0 rank 265 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
117: hkn0506:823185:823311 [1] NCCL INFO comm 0x148700008fb0 rank 117 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
116: hkn0506:823193:823308 [0] NCCL INFO comm 0x14726c008fb0 rank 116 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
118: hkn0506:823201:823314 [2] NCCL INFO comm 0x147994008fb0 rank 118 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
119: hkn0506:823213:823305 [3] NCCL INFO comm 0x147d50008fb0 rank 119 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
261: hkn0613:887816:887974 [1] NCCL INFO Connected all trees
261: hkn0613:887816:887974 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [send] via NET/IBext/0
261: hkn0613:887816:887974 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:887844:887968 [0] NCCL INFO Connected all trees
260: hkn0613:887844:887968 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
260: hkn0613:887844:887968 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
261: hkn0613:887816:887974 [1] NCCL INFO comm 0x146b6c008fb0 rank 261 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
262: hkn0613:887824:887976 [2] NCCL INFO comm 0x14840c008fb0 rank 262 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
260: hkn0613:887844:887968 [0] NCCL INFO comm 0x149044008fb0 rank 260 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
263: hkn0613:887832:887970 [3] NCCL INFO comm 0x14548c008fb0 rank 263 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
256: hkn0612:902120:902251 [0] NCCL INFO Connected all trees
256: hkn0612:902120:902251 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
256: hkn0612:902120:902251 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
257: hkn0612:902128:902247 [1] NCCL INFO Connected all trees
257: hkn0612:902128:902247 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:902128:902247 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2301040:2301137 [1] NCCL INFO Connected all trees
 29: hkn0411:2301040:2301137 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 29: hkn0411:2301040:2301137 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:902120:902251 [0] NCCL INFO comm 0x14b694008fb0 rank 256 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
259: hkn0612:902148:902244 [3] NCCL INFO comm 0x14f928008fb0 rank 259 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 28: hkn0411:2301020:2301135 [0] NCCL INFO Connected all trees
257: hkn0612:902128:902247 [1] NCCL INFO comm 0x15327c008fb0 rank 257 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
258: hkn0612:902136:902248 [2] NCCL INFO comm 0x14b450008fb0 rank 258 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 28: hkn0411:2301020:2301135 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 28: hkn0411:2301020:2301135 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2301040:2301137 [1] NCCL INFO comm 0x151030008fb0 rank 29 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 28: hkn0411:2301020:2301135 [0] NCCL INFO comm 0x14d14c008fb0 rank 28 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 31: hkn0411:2301028:2301136 [3] NCCL INFO comm 0x151e04008fb0 rank 31 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 30: hkn0411:2301012:2301139 [2] NCCL INFO comm 0x145a8c008fb0 rank 30 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 57: hkn0419:1529484:1529583 [1] NCCL INFO Connected all trees
 57: hkn0419:1529484:1529583 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 57: hkn0419:1529484:1529583 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 56: hkn0419:1529464:1529580 [0] NCCL INFO Connected all trees
 56: hkn0419:1529464:1529580 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 56: hkn0419:1529464:1529580 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 56: hkn0419:1529464:1529580 [0] NCCL INFO comm 0x150e2c008fb0 rank 56 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 57: hkn0419:1529484:1529583 [1] NCCL INFO comm 0x14e1bc008fb0 rank 57 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 58: hkn0419:1529472:1529584 [2] NCCL INFO comm 0x14ce54008fb0 rank 58 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 59: hkn0419:1529462:1529576 [3] NCCL INFO comm 0x146d9c008fb0 rank 59 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 53: hkn0418:1854353:1854450 [1] NCCL INFO Channel 00 : 53[4b000] -> 52[31000] via P2P/IPC/read
 53: hkn0418:1854353:1854450 [1] NCCL INFO Channel 01 : 53[4b000] -> 52[31000] via P2P/IPC/read
 52: hkn0418:1854341:1854446 [0] NCCL INFO Connected all trees
 52: hkn0418:1854341:1854446 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1854341:1854446 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1144774:1144891 [0] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [send] via NET/IBext/0
 53: hkn0418:1854353:1854450 [1] NCCL INFO Connected all trees
 53: hkn0418:1854353:1854450 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 53: hkn0418:1854353:1854450 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1801469:1801564 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [send] via NET/IBext/0
 53: hkn0418:1854353:1854450 [1] NCCL INFO comm 0x14c518008fb0 rank 53 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 52: hkn0418:1854341:1854446 [0] NCCL INFO comm 0x14f7a0008fb0 rank 52 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 54: hkn0418:1854325:1854445 [2] NCCL INFO comm 0x154098008fb0 rank 54 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 55: hkn0418:1854333:1854449 [3] NCCL INFO comm 0x15175c008fb0 rank 55 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [receive] via NET/IBext/0
 24: hkn0410:1144774:1144891 [0] NCCL INFO Connected all trees
 24: hkn0410:1144774:1144891 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 24: hkn0410:1144774:1144891 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1801469:1801564 [0] NCCL INFO Connected all trees
 12: hkn0407:1801469:1801564 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 12: hkn0407:1801469:1801564 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 25: hkn0410:1144790:1144895 [1] NCCL INFO Connected all trees
 25: hkn0410:1144790:1144895 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 25: hkn0410:1144790:1144895 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1144774:1144891 [0] NCCL INFO comm 0x152af0008fb0 rank 24 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 27: hkn0410:1144778:1144896 [3] NCCL INFO comm 0x14d7d4008fb0 rank 27 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 25: hkn0410:1144790:1144895 [1] NCCL INFO comm 0x148be0008fb0 rank 25 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 21: hkn0409:2570850:2570977 [1] NCCL INFO Channel 00 : 21[4b000] -> 20[31000] via P2P/IPC/read
 26: hkn0410:1144773:1144892 [2] NCCL INFO comm 0x148e90008fb0 rank 26 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 13: hkn0407:1801441:1801573 [1] NCCL INFO Connected all trees
 13: hkn0407:1801441:1801573 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 13: hkn0407:1801441:1801573 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2570850:2570977 [1] NCCL INFO Channel 01 : 21[4b000] -> 20[31000] via P2P/IPC/read
 12: hkn0407:1801469:1801564 [0] NCCL INFO comm 0x14c994008fb0 rank 12 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 14: hkn0407:1801449:1801570 [2] NCCL INFO comm 0x14572c008fb0 rank 14 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 13: hkn0407:1801441:1801573 [1] NCCL INFO comm 0x146420008fb0 rank 13 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 15: hkn0407:1801457:1801568 [3] NCCL INFO comm 0x14bc98008fb0 rank 15 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 20: hkn0409:2570878:2570976 [0] NCCL INFO Connected all trees
 20: hkn0409:2570878:2570976 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 20: hkn0409:2570878:2570976 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2570850:2570977 [1] NCCL INFO Connected all trees
 21: hkn0409:2570850:2570977 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 21: hkn0409:2570850:2570977 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2570850:2570977 [1] NCCL INFO comm 0x14a220008fb0 rank 21 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 20: hkn0409:2570878:2570976 [0] NCCL INFO comm 0x14c5b4008fb0 rank 20 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 22: hkn0409:2570866:2570968 [2] NCCL INFO comm 0x146578008fb0 rank 22 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 23: hkn0409:2570858:2570973 [3] NCCL INFO comm 0x145e50008fb0 rank 23 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  8: hkn0405:3191892:3192005 [0] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [send] via NET/IBext/0
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 00 : 9[4b000] -> 8[31000] via P2P/IPC/read
  9: hkn0405:3191904:3192003 [1] NCCL INFO Channel 01 : 9[4b000] -> 8[31000] via P2P/IPC/read
  4: hkn0404:1324511:1324629 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [send] via NET/IBext/0
  9: hkn0405:3191904:3192003 [1] NCCL INFO Connected all trees
  9: hkn0405:3191904:3192003 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  9: hkn0405:3191904:3192003 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  8: hkn0405:3191892:3192005 [0] NCCL INFO Connected all trees
  5: hkn0404:1324527:1324632 [1] NCCL INFO Channel 00 : 5[4b000] -> 4[31000] via P2P/IPC/read
  8: hkn0405:3191892:3192005 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  8: hkn0405:3191892:3192005 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  8: hkn0405:3191892:3192005 [0] NCCL INFO comm 0x14f4f4008fb0 rank 8 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 11: hkn0405:3191884:3191996 [3] NCCL INFO comm 0x14d498008fb0 rank 11 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  9: hkn0405:3191904:3192003 [1] NCCL INFO comm 0x149200008fb0 rank 9 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  5: hkn0404:1324527:1324632 [1] NCCL INFO Channel 01 : 5[4b000] -> 4[31000] via P2P/IPC/read
 10: hkn0405:3191876:3192004 [2] NCCL INFO comm 0x154c98008fb0 rank 10 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  4: hkn0404:1324511:1324629 [0] NCCL INFO Connected all trees
  4: hkn0404:1324511:1324629 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1324511:1324629 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1738669:1739051 [0] NCCL INFO Connected all trees
  0: hkn0403:1738669:1739051 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1738669:1739051 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  1: hkn0403:1738685:1739058 [1] NCCL INFO Connected all trees
  1: hkn0403:1738685:1739058 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  1: hkn0403:1738685:1739058 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1738669:1739051 [0] NCCL INFO comm 0x14aac0008fb0 rank 0 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  1: hkn0403:1738685:1739058 [1] NCCL INFO comm 0x14744c008fb0 rank 1 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  2: hkn0403:1738697:1739060 [2] NCCL INFO comm 0x14f260008fb0 rank 2 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  5: hkn0404:1324527:1324632 [1] NCCL INFO Connected all trees
  5: hkn0404:1324527:1324632 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  5: hkn0404:1324527:1324632 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  3: hkn0403:1738677:1739059 [3] NCCL INFO comm 0x150a68008fb0 rank 3 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  7: hkn0404:1324519:1324638 [3] NCCL INFO comm 0x15379c008fb0 rank 7 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  5: hkn0404:1324527:1324632 [1] NCCL INFO comm 0x147ff8008fb0 rank 5 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  4: hkn0404:1324511:1324629 [0] NCCL INFO comm 0x14c448008fb0 rank 4 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  6: hkn0404:1324539:1324635 [2] NCCL INFO comm 0x15286c008fb0 rank 6 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  0: hkn0403:1738669:1738669 [0] NCCL INFO Launch mode Parallel
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989441, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "deepcam", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 55}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989515, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HelmholtzAI", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 58}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989515, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 61}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989515, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 64}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989515, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "HoreKa", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 67}}
 67: hdf5!!
 66: hdf5!!
272: hdf5!!
  2: hdf5!!
386: hdf5!!
376: hdf5!!
353: hdf5!!
416: hdf5!!
404: hdf5!!
  8: hdf5!!
 16: hdf5!!
 54: hdf5!!
 45: hdf5!!
 81: hdf5!!
 99: hdf5!!
 50: hdf5!!
508: hdf5!!
  3: hdf5!!
433: hdf5!!
445: hdf5!!
481: hdf5!!
398: hdf5!!
378: hdf5!!
341: hdf5!!
355: hdf5!!
472: hdf5!!
359: hdf5!!
464: hdf5!!
383: hdf5!!
407: hdf5!!
454: hdf5!!
394: hdf5!!
371: hdf5!!
130: hdf5!!
 10: hdf5!!
 27: hdf5!!
120: hdf5!!
 17: hdf5!!
268: hdf5!!
 43: hdf5!!
281: hdf5!!
100: hdf5!!
 64: hdf5!!
259: hdf5!!
 53: hdf5!!
 28: hdf5!!
 35: hdf5!!
 46: hdf5!!
105: hdf5!!
321: hdf5!!
274: hdf5!!
 63: hdf5!!
 97: hdf5!!
 49: hdf5!!
442: hdf5!!
439: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989516, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 98}}
421: hdf5!!
435: hdf5!!
336: hdf5!!
447: hdf5!!
360: hdf5!!
482: hdf5!!
387: hdf5!!
351: hdf5!!
492: hdf5!!
397: hdf5!!
373: hdf5!!
462: hdf5!!
379: hdf5!!
208: hdf5!!
486: hdf5!!
342: hdf5!!
352: hdf5!!
365: hdf5!!
473: hdf5!!
450: hdf5!!
389: hdf5!!
235: hdf5!!
163: hdf5!!
347: hdf5!!
357: hdf5!!
380: hdf5!!
418: hdf5!!
405: hdf5!!
453: hdf5!!
393: hdf5!!
226: hdf5!!
489: hdf5!!
370: hdf5!!
131: hdf5!!
 21: hdf5!!
 11: hdf5!!
263: hdf5!!
313: hdf5!!
 37: hdf5!!
265: hdf5!!
 73: hdf5!!
 24: hdf5!!
122: hdf5!!
229: hdf5!!
147: hdf5!!
458: hdf5!!
 18: hdf5!!
270: hdf5!!
 42: hdf5!!
101: hdf5!!
 65: hdf5!!
258: hdf5!!
 55: hdf5!!
 29: hdf5!!
 32: hdf5!!
 47: hdf5!!
 83: hdf5!!
236: hdf5!!
250: hdf5!!
 58: hdf5!!
334: hdf5!!
477: hdf5!!
104: hdf5!!
320: hdf5!!
296: hdf5!!
273: hdf5!!
177: hdf5!!
191: hdf5!!
 62: hdf5!!
 98: hdf5!!
193: hdf5!!
169: hdf5!!
290: hdf5!!
 51: hdf5!!
278: hdf5!!
 85: hdf5!!
149: hdf5!!
125: hdf5!!
  7: hdf5!!
328: hdf5!!
139: hdf5!!
 76: hdf5!!
502: hdf5!!
441: hdf5!!
400: hdf5!!
507: hdf5!!
430: hdf5!!
438: hdf5!!
497: hdf5!!
511: hdf5!!
  1: hdf5!!
422: hdf5!!
432: hdf5!!
337: hdf5!!
446: hdf5!!
361: hdf5!!
480: hdf5!!
385: hdf5!!
349: hdf5!!
468: hdf5!!
495: hdf5!!
396: hdf5!!
374: hdf5!!
205: hdf5!!
 13: hdf5!!
461: hdf5!!
412: hdf5!!
377: hdf5!!
209: hdf5!!
487: hdf5!!
343: hdf5!!
354: hdf5!!
427: hdf5!!
366: hdf5!!
475: hdf5!!
448: hdf5!!
390: hdf5!!
232: hdf5!!
160: hdf5!!
346: hdf5!!
358: hdf5!!
381: hdf5!!
419: hdf5!!
406: hdf5!!
455: hdf5!!
395: hdf5!!
227: hdf5!!
490: hdf5!!
368: hdf5!!
129: hdf5!!
 23: hdf5!!
  9: hdf5!!
260: hdf5!!
301: hdf5!!
111: hdf5!!
216: hdf5!!
252: hdf5!!
312: hdf5!!
 39: hdf5!!
266: hdf5!!
 74: hdf5!!
 25: hdf5!!
123: hdf5!!
230: hdf5!!
144: hdf5!!
459: hdf5!!
157: hdf5!!
319: hdf5!!
244: hdf5!!
 19: hdf5!!
271: hdf5!!
294: hdf5!!
 41: hdf5!!
282: hdf5!!
103: hdf5!!
112: hdf5!!
305: hdf5!!
257: hdf5!!
 52: hdf5!!
 31: hdf5!!
 33: hdf5!!
 44: hdf5!!
 80: hdf5!!
238: hdf5!!
 92: hdf5!!
152: hdf5!!
 71: hdf5!!
248: hdf5!!
 59: hdf5!!
335: hdf5!!
478: hdf5!!
106: hdf5!!
323: hdf5!!
285: hdf5!!
297: hdf5!!
275: hdf5!!
311: hdf5!!
167: hdf5!!
179: hdf5!!
212: hdf5!!
201: hdf5!!
189: hdf5!!
143: hdf5!!
 61: hdf5!!
 96: hdf5!!
192: hdf5!!
133: hdf5!!
170: hdf5!!
181: hdf5!!
288: hdf5!!
 48: hdf5!!
279: hdf5!!
 87: hdf5!!
240: hdf5!!
187: hdf5!!
150: hdf5!!
173: hdf5!!
126: hdf5!!
  4: hdf5!!
330: hdf5!!
137: hdf5!!
 78: hdf5!!
197: hdf5!!
503: hdf5!!
440: hdf5!!
403: hdf5!!
410: hdf5!!
504: hdf5!!
431: hdf5!!
437: hdf5!!
496: hdf5!!
510: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989516, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 99}}
420: hdf5!!
434: hdf5!!
338: hdf5!!
444: hdf5!!
362: hdf5!!
483: hdf5!!
384: hdf5!!
348: hdf5!!
469: hdf5!!
493: hdf5!!
399: hdf5!!
375: hdf5!!
207: hdf5!!
 14: hdf5!!
463: hdf5!!
413: hdf5!!
211: hdf5!!
484: hdf5!!
340: hdf5!!
425: hdf5!!
 90: hdf5!!
367: hdf5!!
474: hdf5!!
451: hdf5!!
391: hdf5!!
233: hdf5!!
162: hdf5!!
344: hdf5!!
356: hdf5!!
465: hdf5!!
382: hdf5!!
417: hdf5!!
452: hdf5!!
392: hdf5!!
224: hdf5!!
488: hdf5!!
369: hdf5!!
128: hdf5!!
 20: hdf5!!
261: hdf5!!
303: hdf5!!
108: hdf5!!
217: hdf5!!
253: hdf5!!
315: hdf5!!
 38: hdf5!!
264: hdf5!!
326: hdf5!!
 75: hdf5!!
 26: hdf5!!
121: hdf5!!
231: hdf5!!
145: hdf5!!
456: hdf5!!
159: hdf5!!
316: hdf5!!
245: hdf5!!
269: hdf5!!
292: hdf5!!
 40: hdf5!!
280: hdf5!!
102: hdf5!!
113: hdf5!!
306: hdf5!!
256: hdf5!!
 30: hdf5!!
221: hdf5!!
 34: hdf5!!
 82: hdf5!!
239: hdf5!!
 93: hdf5!!
153: hdf5!!
 69: hdf5!!
251: hdf5!!
 57: hdf5!!
332: hdf5!!
479: hdf5!!
107: hdf5!!
322: hdf5!!
287: hdf5!!
298: hdf5!!
309: hdf5!!
165: hdf5!!
178: hdf5!!
213: hdf5!!
202: hdf5!!
188: hdf5!!
118: hdf5!!
140: hdf5!!
 60: hdf5!!
194: hdf5!!
134: hdf5!!
171: hdf5!!
182: hdf5!!
289: hdf5!!
277: hdf5!!
 86: hdf5!!
242: hdf5!!
184: hdf5!!
151: hdf5!!
175: hdf5!!
127: hdf5!!
  5: hdf5!!
331: hdf5!!
138: hdf5!!
 77: hdf5!!
198: hdf5!!
501: hdf5!!
443: hdf5!!
401: hdf5!!
408: hdf5!!
506: hdf5!!
429: hdf5!!
436: hdf5!!
499: hdf5!!
509: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633412989516, "event_type": "POINT_IN_TIME", "key": "seed", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 103}}
423: hdf5!!
339: hdf5!!
363: hdf5!!
350: hdf5!!
470: hdf5!!
494: hdf5!!
372: hdf5!!
206: hdf5!!
 15: hdf5!!
460: hdf5!!
415: hdf5!!
210: hdf5!!
485: hdf5!!
424: hdf5!!
 91: hdf5!!
364: hdf5!!
449: hdf5!!
388: hdf5!!
234: hdf5!!
161: hdf5!!
345: hdf5!!
466: hdf5!!
225: hdf5!!
491: hdf5!!
 22: hdf5!!
262: hdf5!!
300: hdf5!!
109: hdf5!!
219: hdf5!!
255: hdf5!!
314: hdf5!!
 36: hdf5!!
267: hdf5!!
327: hdf5!!
 72: hdf5!!
228: hdf5!!
146: hdf5!!
457: hdf5!!
158: hdf5!!
318: hdf5!!
246: hdf5!!
293: hdf5!!
283: hdf5!!
114: hdf5!!
307: hdf5!!
222: hdf5!!
237: hdf5!!
 95: hdf5!!
154: hdf5!!
 68: hdf5!!
249: hdf5!!
 56: hdf5!!
333: hdf5!!
476: hdf5!!
284: hdf5!!
299: hdf5!!
308: hdf5!!
166: hdf5!!
176: hdf5!!
214: hdf5!!
203: hdf5!!
190: hdf5!!
119: hdf5!!
141: hdf5!!
195: hdf5!!
132: hdf5!!
168: hdf5!!
183: hdf5!!
291: hdf5!!
 84: hdf5!!
243: hdf5!!
185: hdf5!!
148: hdf5!!
174: hdf5!!
124: hdf5!!
  6: hdf5!!
329: hdf5!!
136: hdf5!!
 79: hdf5!!
199: hdf5!!
500: hdf5!!
402: hdf5!!
411: hdf5!!
505: hdf5!!
428: hdf5!!
498: hdf5!!
  0: hdf5!!
204: hdf5!!
 12: hdf5!!
414: hdf5!!
 89: hdf5!!
467: hdf5!!
302: hdf5!!
110: hdf5!!
218: hdf5!!
254: hdf5!!
156: hdf5!!
317: hdf5!!
247: hdf5!!
295: hdf5!!
115: hdf5!!
304: hdf5!!
220: hdf5!!
 94: hdf5!!
155: hdf5!!
 70: hdf5!!
286: hdf5!!
310: hdf5!!
164: hdf5!!
215: hdf5!!
200: hdf5!!
117: hdf5!!
142: hdf5!!
180: hdf5!!
186: hdf5!!
172: hdf5!!
196: hdf5!!
409: hdf5!!
 88: hdf5!!
116: hdf5!!
324: hdf5!!
135: hdf5!!
471: hdf5!!
426: hdf5!!
325: hdf5!!
223: hdf5!!
241: hdf5!!
276: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
275: root_dir: /tmp/deepcam/instance0
277: root_dir: /tmp/deepcam/instance0
  4: root_dir: /tmp/deepcam/instance0
329: root_dir: /tmp/deepcam/instance0
228: root_dir: /tmp/deepcam/instance0
 44: root_dir: /tmp/deepcam/instance0
491: root_dir: /tmp/deepcam/instance0
116: root_dir: /tmp/deepcam/instance0
107: root_dir: /tmp/deepcam/instance0
320: root_dir: /tmp/deepcam/instance0
399: root_dir: /tmp/deepcam/instance0
416: root_dir: /tmp/deepcam/instance0
490: root_dir: /tmp/deepcam/instance0
 33: root_dir: /tmp/deepcam/instance0
321: root_dir: /tmp/deepcam/instance0
417: root_dir: /tmp/deepcam/instance0
421: root_dir: /tmp/deepcam/instance0
396: root_dir: /tmp/deepcam/instance0
446: root_dir: /tmp/deepcam/instance0
473: root_dir: /tmp/deepcam/instance0
324: root_dir: /tmp/deepcam/instance0
510: root_dir: /tmp/deepcam/instance0
 23: root_dir: /tmp/deepcam/instance0
 81: root_dir: /tmp/deepcam/instance0
 18: root_dir: /tmp/deepcam/instance0
 64: root_dir: /tmp/deepcam/instance0
468: root_dir: /tmp/deepcam/instance0
347: root_dir: /tmp/deepcam/instance0
143: root_dir: /tmp/deepcam/instance0
 65: root_dir: /tmp/deepcam/instance0
422: root_dir: /tmp/deepcam/instance0
113: root_dir: /tmp/deepcam/instance0
 97: root_dir: /tmp/deepcam/instance0
248: root_dir: /tmp/deepcam/instance0
312: root_dir: /tmp/deepcam/instance0
487: root_dir: /tmp/deepcam/instance0
168: root_dir: /tmp/deepcam/instance0
340: root_dir: /tmp/deepcam/instance0
182: root_dir: /tmp/deepcam/instance0
164: root_dir: /tmp/deepcam/instance0
 74: root_dir: /tmp/deepcam/instance0
262: root_dir: /tmp/deepcam/instance0
332: root_dir: /tmp/deepcam/instance0
438: root_dir: /tmp/deepcam/instance0
436: root_dir: /tmp/deepcam/instance0
423: root_dir: /tmp/deepcam/instance0
306: root_dir: /tmp/deepcam/instance0
213: root_dir: /tmp/deepcam/instance0
389: root_dir: /tmp/deepcam/instance0
424: root_dir: /tmp/deepcam/instance0
465: root_dir: /tmp/deepcam/instance0
511: root_dir: /tmp/deepcam/instance0
240: root_dir: /tmp/deepcam/instance0
442: root_dir: /tmp/deepcam/instance0
464: root_dir: /tmp/deepcam/instance0
400: root_dir: /tmp/deepcam/instance0
302: root_dir: /tmp/deepcam/instance0
345: root_dir: /tmp/deepcam/instance0
440: root_dir: /tmp/deepcam/instance0
449: root_dir: /tmp/deepcam/instance0
425: root_dir: /tmp/deepcam/instance0
341: root_dir: /tmp/deepcam/instance0
144: root_dir: /tmp/deepcam/instance0
282: root_dir: /tmp/deepcam/instance0
138: root_dir: /tmp/deepcam/instance0
216: root_dir: /tmp/deepcam/instance0
154: root_dir: /tmp/deepcam/instance0
303: root_dir: /tmp/deepcam/instance0
448: root_dir: /tmp/deepcam/instance0
169: root_dir: /tmp/deepcam/instance0
263: root_dir: /tmp/deepcam/instance0
191: root_dir: /tmp/deepcam/instance0
370: root_dir: /tmp/deepcam/instance0
372: root_dir: /tmp/deepcam/instance0
404: root_dir: /tmp/deepcam/instance0
392: root_dir: /tmp/deepcam/instance0
 27: root_dir: /tmp/deepcam/instance0
304: root_dir: /tmp/deepcam/instance0
258: root_dir: /tmp/deepcam/instance0
215: root_dir: /tmp/deepcam/instance0
483: root_dir: /tmp/deepcam/instance0
373: root_dir: /tmp/deepcam/instance0
426: root_dir: /tmp/deepcam/instance0
356: root_dir: /tmp/deepcam/instance0
466: root_dir: /tmp/deepcam/instance0
369: root_dir: /tmp/deepcam/instance0
 37: root_dir: /tmp/deepcam/instance0
122: root_dir: /tmp/deepcam/instance0
456: root_dir: /tmp/deepcam/instance0
295: root_dir: /tmp/deepcam/instance0
 43: root_dir: /tmp/deepcam/instance0
256: root_dir: /tmp/deepcam/instance0
 50: root_dir: /tmp/deepcam/instance0
 84: root_dir: /tmp/deepcam/instance0
148: root_dir: /tmp/deepcam/instance0
174: root_dir: /tmp/deepcam/instance0
127: root_dir: /tmp/deepcam/instance0
137: root_dir: /tmp/deepcam/instance0
401: root_dir: /tmp/deepcam/instance0
457: root_dir: /tmp/deepcam/instance0
  1: root_dir: /tmp/deepcam/instance0
352: root_dir: /tmp/deepcam/instance0
255: root_dir: /tmp/deepcam/instance0
239: root_dir: /tmp/deepcam/instance0
285: root_dir: /tmp/deepcam/instance0
296: root_dir: /tmp/deepcam/instance0
505: root_dir: /tmp/deepcam/instance0
497: root_dir: /tmp/deepcam/instance0
355: root_dir: /tmp/deepcam/instance0
161: root_dir: /tmp/deepcam/instance0
 94: root_dir: /tmp/deepcam/instance0
503: root_dir: /tmp/deepcam/instance0
237: root_dir: /tmp/deepcam/instance0
495: root_dir: /tmp/deepcam/instance0
 79: root_dir: /tmp/deepcam/instance0
  3: root_dir: /tmp/deepcam/instance0
160: root_dir: /tmp/deepcam/instance0
193: root_dir: /tmp/deepcam/instance0
348: root_dir: /tmp/deepcam/instance0
225: root_dir: /tmp/deepcam/instance0
350: root_dir: /tmp/deepcam/instance0
181: root_dir: /tmp/deepcam/instance0
291: root_dir: /tmp/deepcam/instance0
153: root_dir: /tmp/deepcam/instance0
238: root_dir: /tmp/deepcam/instance0
342: root_dir: /tmp/deepcam/instance0
 51: root_dir: /tmp/deepcam/instance0
391: root_dir: /tmp/deepcam/instance0
162: root_dir: /tmp/deepcam/instance0
299: root_dir: /tmp/deepcam/instance0
454: root_dir: /tmp/deepcam/instance0
147: root_dir: /tmp/deepcam/instance0
158: root_dir: /tmp/deepcam/instance0
316: root_dir: /tmp/deepcam/instance0
 60: root_dir: /tmp/deepcam/instance0
507: root_dir: /tmp/deepcam/instance0
463: root_dir: /tmp/deepcam/instance0
409: root_dir: /tmp/deepcam/instance0
384: root_dir: /tmp/deepcam/instance0
175: root_dir: /tmp/deepcam/instance0
 57: root_dir: /tmp/deepcam/instance0
351: root_dir: /tmp/deepcam/instance0
349: root_dir: /tmp/deepcam/instance0
 56: root_dir: /tmp/deepcam/instance0
 95: root_dir: /tmp/deepcam/instance0
135: root_dir: /tmp/deepcam/instance0
247: root_dir: /tmp/deepcam/instance0
197: root_dir: /tmp/deepcam/instance0
100: root_dir: /tmp/deepcam/instance0
378: root_dir: /tmp/deepcam/instance0
377: root_dir: /tmp/deepcam/instance0
166: root_dir: /tmp/deepcam/instance0
194: root_dir: /tmp/deepcam/instance0
292: root_dir: /tmp/deepcam/instance0
286: root_dir: /tmp/deepcam/instance0
185: root_dir: /tmp/deepcam/instance0
498: root_dir: /tmp/deepcam/instance0
380: root_dir: /tmp/deepcam/instance0
 41: root_dir: /tmp/deepcam/instance0
307: root_dir: /tmp/deepcam/instance0
366: root_dir: /tmp/deepcam/instance0
208: root_dir: /tmp/deepcam/instance0
 53: root_dir: /tmp/deepcam/instance0
246: root_dir: /tmp/deepcam/instance0
129: root_dir: /tmp/deepcam/instance0
 12: root_dir: /tmp/deepcam/instance0
203: root_dir: /tmp/deepcam/instance0
339: root_dir: /tmp/deepcam/instance0
 39: root_dir: /tmp/deepcam/instance0
145: root_dir: /tmp/deepcam/instance0
293: root_dir: /tmp/deepcam/instance0
390: root_dir: /tmp/deepcam/instance0
387: root_dir: /tmp/deepcam/instance0
120: root_dir: /tmp/deepcam/instance0
310: root_dir: /tmp/deepcam/instance0
 88: root_dir: /tmp/deepcam/instance0
335: root_dir: /tmp/deepcam/instance0
204: root_dir: /tmp/deepcam/instance0
364: root_dir: /tmp/deepcam/instance0
206: root_dir: /tmp/deepcam/instance0
178: root_dir: /tmp/deepcam/instance0
241: root_dir: /tmp/deepcam/instance0
430: root_dir: /tmp/deepcam/instance0
297: root_dir: /tmp/deepcam/instance0
382: root_dir: /tmp/deepcam/instance0
 86: root_dir: /tmp/deepcam/instance0
381: root_dir: /tmp/deepcam/instance0
338: root_dir: /tmp/deepcam/instance0
319: root_dir: /tmp/deepcam/instance0
102: root_dir: /tmp/deepcam/instance0
186: root_dir: /tmp/deepcam/instance0
146: root_dir: /tmp/deepcam/instance0
265: root_dir: /tmp/deepcam/instance0
232: root_dir: /tmp/deepcam/instance0
136: root_dir: /tmp/deepcam/instance0
156: root_dir: /tmp/deepcam/instance0
268: root_dir: /tmp/deepcam/instance0
 63: root_dir: /tmp/deepcam/instance0
431: root_dir: /tmp/deepcam/instance0
 77: root_dir: /tmp/deepcam/instance0
179: root_dir: /tmp/deepcam/instance0
266: root_dir: /tmp/deepcam/instance0
199: root_dir: /tmp/deepcam/instance0
220: root_dir: /tmp/deepcam/instance0
445: root_dir: /tmp/deepcam/instance0
476: root_dir: /tmp/deepcam/instance0
187: root_dir: /tmp/deepcam/instance0
189: root_dir: /tmp/deepcam/instance0
157: root_dir: /tmp/deepcam/instance0
101: root_dir: /tmp/deepcam/instance0
207: root_dir: /tmp/deepcam/instance0
264: root_dir: /tmp/deepcam/instance0
480: root_dir: /tmp/deepcam/instance0
394: root_dir: /tmp/deepcam/instance0
383: root_dir: /tmp/deepcam/instance0
411: root_dir: /tmp/deepcam/instance0
195: root_dir: /tmp/deepcam/instance0
470: root_dir: /tmp/deepcam/instance0
176: root_dir: /tmp/deepcam/instance0
386: root_dir: /tmp/deepcam/instance0
363: root_dir: /tmp/deepcam/instance0
 58: root_dir: /tmp/deepcam/instance0
 10: root_dir: /tmp/deepcam/instance0
433: root_dir: /tmp/deepcam/instance0
 14: root_dir: /tmp/deepcam/instance0
133: root_dir: /tmp/deepcam/instance0
233: root_dir: /tmp/deepcam/instance0
434: root_dir: /tmp/deepcam/instance0
290: root_dir: /tmp/deepcam/instance0
479: root_dir: /tmp/deepcam/instance0
234: root_dir: /tmp/deepcam/instance0
 61: root_dir: /tmp/deepcam/instance0
478: root_dir: /tmp/deepcam/instance0
336: root_dir: /tmp/deepcam/instance0
414: root_dir: /tmp/deepcam/instance0
131: root_dir: /tmp/deepcam/instance0
 15: root_dir: /tmp/deepcam/instance0
209: root_dir: /tmp/deepcam/instance0
134: root_dir: /tmp/deepcam/instance0
461: root_dir: /tmp/deepcam/instance0
235: root_dir: /tmp/deepcam/instance0
270: root_dir: /tmp/deepcam/instance0
121: root_dir: /tmp/deepcam/instance0
504: root_dir: /tmp/deepcam/instance0
 25: root_dir: /tmp/deepcam/instance0
315: root_dir: /tmp/deepcam/instance0
223: root_dir: /tmp/deepcam/instance0
210: root_dir: /tmp/deepcam/instance0
222: root_dir: /tmp/deepcam/instance0
 80: root_dir: /tmp/deepcam/instance0
494: root_dir: /tmp/deepcam/instance0
267: root_dir: /tmp/deepcam/instance0
114: root_dir: /tmp/deepcam/instance0
353: root_dir: /tmp/deepcam/instance0
125: root_dir: /tmp/deepcam/instance0
123: root_dir: /tmp/deepcam/instance0
 26: root_dir: /tmp/deepcam/instance0
202: root_dir: /tmp/deepcam/instance0
211: root_dir: /tmp/deepcam/instance0
360: root_dir: /tmp/deepcam/instance0
460: root_dir: /tmp/deepcam/instance0
200: root_dir: /tmp/deepcam/instance0
201: root_dir: /tmp/deepcam/instance0
109: root_dir: /tmp/deepcam/instance0
408: root_dir: /tmp/deepcam/instance0
236: root_dir: /tmp/deepcam/instance0
 35: root_dir: /tmp/deepcam/instance0
170: root_dir: /tmp/deepcam/instance0
365: root_dir: /tmp/deepcam/instance0
 71: root_dir: /tmp/deepcam/instance0
361: root_dir: /tmp/deepcam/instance0
287: root_dir: /tmp/deepcam/instance0
108: root_dir: /tmp/deepcam/instance0
 13: root_dir: /tmp/deepcam/instance0
362: root_dir: /tmp/deepcam/instance0
455: root_dir: /tmp/deepcam/instance0
477: root_dir: /tmp/deepcam/instance0
 78: root_dir: /tmp/deepcam/instance0
294: root_dir: /tmp/deepcam/instance0
 19: root_dir: /tmp/deepcam/instance0
167: root_dir: /tmp/deepcam/instance0
379: root_dir: /tmp/deepcam/instance0
482: root_dir: /tmp/deepcam/instance0
508: root_dir: /tmp/deepcam/instance0
288: root_dir: /tmp/deepcam/instance0
249: root_dir: /tmp/deepcam/instance0
115: root_dir: /tmp/deepcam/instance0
429: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
393: root_dir: /tmp/deepcam/instance0
371: root_dir: /tmp/deepcam/instance0
484: root_dir: /tmp/deepcam/instance0
278: root_dir: /tmp/deepcam/instance0
500: root_dir: /tmp/deepcam/instance0
 70: root_dir: /tmp/deepcam/instance0
188: root_dir: /tmp/deepcam/instance0
177: root_dir: /tmp/deepcam/instance0
359: root_dir: /tmp/deepcam/instance0
327: root_dir: /tmp/deepcam/instance0
486: root_dir: /tmp/deepcam/instance0
435: root_dir: /tmp/deepcam/instance0
309: root_dir: /tmp/deepcam/instance0
 29: root_dir: /tmp/deepcam/instance0
502: root_dir: /tmp/deepcam/instance0
376: root_dir: /tmp/deepcam/instance0
 28: root_dir: /tmp/deepcam/instance0
260: root_dir: /tmp/deepcam/instance0
 21: root_dir: /tmp/deepcam/instance0
 42: root_dir: /tmp/deepcam/instance0
328: root_dir: /tmp/deepcam/instance0
254: root_dir: /tmp/deepcam/instance0
301: root_dir: /tmp/deepcam/instance0
183: root_dir: /tmp/deepcam/instance0
140: root_dir: /tmp/deepcam/instance0
226: root_dir: /tmp/deepcam/instance0
 62: root_dir: /tmp/deepcam/instance0
192: root_dir: /tmp/deepcam/instance0
110: root_dir: /tmp/deepcam/instance0
227: root_dir: /tmp/deepcam/instance0
 91: root_dir: /tmp/deepcam/instance0
499: root_dir: /tmp/deepcam/instance0
184: root_dir: /tmp/deepcam/instance0
410: root_dir: /tmp/deepcam/instance0
402: root_dir: /tmp/deepcam/instance0
 87: root_dir: /tmp/deepcam/instance0
354: root_dir: /tmp/deepcam/instance0
471: root_dir: /tmp/deepcam/instance0
221: root_dir: /tmp/deepcam/instance0
280: root_dir: /tmp/deepcam/instance0
105: root_dir: /tmp/deepcam/instance0
375: root_dir: /tmp/deepcam/instance0
106: root_dir: /tmp/deepcam/instance0
501: root_dir: /tmp/deepcam/instance0
462: root_dir: /tmp/deepcam/instance0
 47: root_dir: /tmp/deepcam/instance0
171: root_dir: /tmp/deepcam/instance0
305: root_dir: /tmp/deepcam/instance0
496: root_dir: /tmp/deepcam/instance0
330: root_dir: /tmp/deepcam/instance0
 24: root_dir: /tmp/deepcam/instance0
 54: root_dir: /tmp/deepcam/instance0
253: root_dir: /tmp/deepcam/instance0
472: root_dir: /tmp/deepcam/instance0
368: root_dir: /tmp/deepcam/instance0
229: root_dir: /tmp/deepcam/instance0
397: root_dir: /tmp/deepcam/instance0
357: root_dir: /tmp/deepcam/instance0
  6: root_dir: /tmp/deepcam/instance0
432: root_dir: /tmp/deepcam/instance0
 55: root_dir: /tmp/deepcam/instance0
 31: root_dir: /tmp/deepcam/instance0
230: root_dir: /tmp/deepcam/instance0
159: root_dir: /tmp/deepcam/instance0
 82: root_dir: /tmp/deepcam/instance0
488: root_dir: /tmp/deepcam/instance0
 90: root_dir: /tmp/deepcam/instance0
257: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
459: root_dir: /tmp/deepcam/instance0
251: root_dir: /tmp/deepcam/instance0
450: root_dir: /tmp/deepcam/instance0
406: root_dir: /tmp/deepcam/instance0
205: root_dir: /tmp/deepcam/instance0
 40: root_dir: /tmp/deepcam/instance0
374: root_dir: /tmp/deepcam/instance0
492: root_dir: /tmp/deepcam/instance0
243: root_dir: /tmp/deepcam/instance0
124: root_dir: /tmp/deepcam/instance0
 96: root_dir: /tmp/deepcam/instance0
 48: root_dir: /tmp/deepcam/instance0
 92: root_dir: /tmp/deepcam/instance0
283: root_dir: /tmp/deepcam/instance0
412: root_dir: /tmp/deepcam/instance0
 89: root_dir: /tmp/deepcam/instance0
 52: root_dir: /tmp/deepcam/instance0
276: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
180: root_dir: /tmp/deepcam/instance0
212: root_dir: /tmp/deepcam/instance0
325: root_dir: /tmp/deepcam/instance0
217: root_dir: /tmp/deepcam/instance0
474: root_dir: /tmp/deepcam/instance0
407: root_dir: /tmp/deepcam/instance0
 68: root_dir: /tmp/deepcam/instance0
439: root_dir: /tmp/deepcam/instance0
259: root_dir: /tmp/deepcam/instance0
198: root_dir: /tmp/deepcam/instance0
  0: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086212, "event_type": "POINT_IN_TIME", "key": "number_of_ranks", "value": 512, "metadata": {"file": "./train_instance.py", "lineno": 211}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "number_of_nodes", "value": 128, "metadata": {"file": "./train_instance.py", "lineno": 212}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "accelerators_per_node", "value": 4, "metadata": {"file": "./train_instance.py", "lineno": 213}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "instance_id", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 215}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "checkpoint", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 217}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "./train_instance.py", "lineno": 218}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "batchnorm_group_size", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 219}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_frequency", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "data_format", "value": "dali-numpy/hdf5", "metadata": {"file": "./train_instance.py", "lineno": 222}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "shuffle_mode", "value": "global", "metadata": {"file": "./train_instance.py", "lineno": 223}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086213, "event_type": "POINT_IN_TIME", "key": "data_oversampling_factor", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 224}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "stage_dir_prefix", "value": "/tmp/deepcam", "metadata": {"file": "./train_instance.py", "lineno": 226}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "stage_mode", "value": "node", "metadata": {"file": "./train_instance.py", "lineno": 227}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "stage_batch_size", "value": -1, "metadata": {"file": "./train_instance.py", "lineno": 228}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "stage_verify", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 229}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "stage_full_data_per_node", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "stage_use_direct_io", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 231}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "precision_mode", "value": "amp", "metadata": {"file": "./train_instance.py", "lineno": 233}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086220, "event_type": "POINT_IN_TIME", "key": "enable_nhwc", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 234}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086221, "event_type": "POINT_IN_TIME", "key": "enable_graph", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 235}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086221, "event_type": "POINT_IN_TIME", "key": "enable_jit", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086221, "event_type": "POINT_IN_TIME", "key": "disable_comm_overlap", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 237}}
  0: Constructing DeepLabv3+ model...
  0: Number of output channels: 3
  0: Output stride: 16
  0: Number of Input Channels: 16
395: root_dir: /tmp/deepcam/instance0
453: root_dir: /tmp/deepcam/instance0
415: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413086982, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "LAMB", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 144}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087024, "event_type": "POINT_IN_TIME", "key": "opt_lr", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087024, "event_type": "POINT_IN_TIME", "key": "opt_bias_correction", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087024, "event_type": "POINT_IN_TIME", "key": "opt_betas", "value": [0.9, 0.999], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087024, "event_type": "POINT_IN_TIME", "key": "opt_eps", "value": 1e-06, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087024, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.01, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087024, "event_type": "POINT_IN_TIME", "key": "opt_grad_averaging", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087024, "event_type": "POINT_IN_TIME", "key": "opt_max_grad_norm", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087025, "event_type": "POINT_IN_TIME", "key": "scheduler_type", "value": "multistep", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087025, "event_type": "POINT_IN_TIME", "key": "scheduler_milestones", "value": [1100, 4096], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087025, "event_type": "POINT_IN_TIME", "key": "scheduler_decay_rate", "value": 0.1, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087025, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_steps", "value": 200, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413087026, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_factor", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: DeepLabv3_plus(
  0:   (xception_features): Xception(
  0:     (relu): ReLU()
  0:     (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  0:     (bn1): Sequential(
  0:       (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:     (bn2): Sequential(
  0:       (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (block1): Block(
  0:       (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
  0:           (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Seque
  0: ntial(
  0:           (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block2): Block(
  0:       (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1):
  0:  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block3): Block(
  0:       (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), 
  0: bias=False)
  0:       (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (2): ReLU()
  0:         (3): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (5): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d
  0: (728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block4): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=
  0: (3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block5): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2
  0: d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block6): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), p
  0: adding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block7): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momen
  0: tum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block8): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7
  0: 28, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block9
  0: ): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(
  0: 728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block10): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU(
  0: )
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block11): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size
  0: =(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block12): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2
  0: ): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block13): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1)
  0: , bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block14): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_sa
  0: me(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNo
  0: rm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block15): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kerne
  0: l_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block16): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): Ba
  0: tchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block17): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride
  0: =(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block18): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e
  0: -05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block19): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1
  0: ), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block20): Block(
  0:       (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:         
  0:   (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
  0:           (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (conv3): SeparableConv2d_same(
  0:       (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1024, bias=False)
  0:       (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn3): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv4): SeparableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn4): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv5): Separa
  0: bleConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn5): Sequential(
  0:       (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (bottleneck): Bottleneck(
  0:     (aspp1): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp2): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp3): ASPP_module(
  0:       (atrous_con
  0: volution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp4): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (global_avg_pool): GlobalAveragePool(
  0:       (global_average_pool): Sequential(
  0:         (0): AdaptiveAvgPool2d(output_size=(1, 1))
  0:         (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         (2): TrainableAffine()
  0:         (3): ReLU(inplace=True)
  0:       )
  0:     )
  0:     (tiling): Tiling()
  0:     (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     (bn): Sequential(
  0:       (0): BatchNorm2d(256, eps=1e-05, m
  0: omentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (conv2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:   (bn2): Sequential(
  0:     (0): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:     (1): ReLU()
  0:   )
  0:   (upsample): DeconvUpsampler(
  0:     (deconv1): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (conv1): Sequential(
  0:       (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  0:     )
  0:     (deconv2): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (last_deconv): Sequential(
  0:       (0): ConvTranspose2d(256, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:     )
  0:   )
  0: )
  0: Number of trainable parameters: 56454720
  0: Creating Dataloaders
 22: root_dir: /tmp/deepcam/instance0
279: root_dir: /tmp/deepcam/instance0
333: root_dir: /tmp/deepcam/instance0
119: root_dir: /tmp/deepcam/instance0
467: root_dir: /tmp/deepcam/instance0
111: root_dir: /tmp/deepcam/instance0
 34: root_dir: /tmp/deepcam/instance0
413: root_dir: /tmp/deepcam/instance0
344: root_dir: /tmp/deepcam/instance0
489: root_dir: /tmp/deepcam/instance0
155: root_dir: /tmp/deepcam/instance0
343: root_dir: /tmp/deepcam/instance0
139: root_dir: /tmp/deepcam/instance0
152: root_dir: /tmp/deepcam/instance0
214: root_dir: /tmp/deepcam/instance0
451: root_dir: /tmp/deepcam/instance0
 85: root_dir: /tmp/deepcam/instance0
452: root_dir: /tmp/deepcam/instance0
  8: root_dir: /tmp/deepcam/instance0
419: root_dir: /tmp/deepcam/instance0
250: root_dir: /tmp/deepcam/instance0
300: root_dir: /tmp/deepcam/instance0
 99: root_dir: /tmp/deepcam/instance0
308: root_dir: /tmp/deepcam/instance0
132: root_dir: /tmp/deepcam/instance0
218: root_dir: /tmp/deepcam/instance0
405: root_dir: /tmp/deepcam/instance0
458: root_dir: /tmp/deepcam/instance0
231: root_dir: /tmp/deepcam/instance0
388: root_dir: /tmp/deepcam/instance0
 49: root_dir: /tmp/deepcam/instance0
  7: root_dir: /tmp/deepcam/instance0
196: root_dir: /tmp/deepcam/instance0
317: root_dir: /tmp/deepcam/instance0
447: root_dir: /tmp/deepcam/instance0
 16: root_dir: /tmp/deepcam/instance0
269: root_dir: /tmp/deepcam/instance0
 93: root_dir: /tmp/deepcam/instance0
298: root_dir: /tmp/deepcam/instance0
 30: root_dir: /tmp/deepcam/instance0
 17: root_dir: /tmp/deepcam/instance0
118: root_dir: /tmp/deepcam/instance0
481: root_dir: /tmp/deepcam/instance0
 83: root_dir: /tmp/deepcam/instance0
 67: root_dir: /tmp/deepcam/instance0
337: root_dir: /tmp/deepcam/instance0
313: root_dir: /tmp/deepcam/instance0
 32: root_dir: /tmp/deepcam/instance0
289: root_dir: /tmp/deepcam/instance0
112: root_dir: /tmp/deepcam/instance0
 45: root_dir: /tmp/deepcam/instance0
271: root_dir: /tmp/deepcam/instance0
 69: root_dir: /tmp/deepcam/instance0
261: root_dir: /tmp/deepcam/instance0
311: root_dir: /tmp/deepcam/instance0
 75: root_dir: /tmp/deepcam/instance0
469: root_dir: /tmp/deepcam/instance0
 11: root_dir: /tmp/deepcam/instance0
367: root_dir: /tmp/deepcam/instance0
 98: root_dir: /tmp/deepcam/instance0
 73: root_dir: /tmp/deepcam/instance0
  9: root_dir: /tmp/deepcam/instance0
273: root_dir: /tmp/deepcam/instance0
485: root_dir: /tmp/deepcam/instance0
 76: root_dir: /tmp/deepcam/instance0
224: root_dir: /tmp/deepcam/instance0
284: root_dir: /tmp/deepcam/instance0
 72: root_dir: /tmp/deepcam/instance0
 20: root_dir: /tmp/deepcam/instance0
334: root_dir: /tmp/deepcam/instance0
242: root_dir: /tmp/deepcam/instance0
219: root_dir: /tmp/deepcam/instance0
117: root_dir: /tmp/deepcam/instance0
165: root_dir: /tmp/deepcam/instance0
149: root_dir: /tmp/deepcam/instance0
281: root_dir: /tmp/deepcam/instance0
420: root_dir: /tmp/deepcam/instance0
272: root_dir: /tmp/deepcam/instance0
173: root_dir: /tmp/deepcam/instance0
274: root_dir: /tmp/deepcam/instance0
428: root_dir: /tmp/deepcam/instance0
244: root_dir: /tmp/deepcam/instance0
245: root_dir: /tmp/deepcam/instance0
141: root_dir: /tmp/deepcam/instance0
126: root_dir: /tmp/deepcam/instance0
252: root_dir: /tmp/deepcam/instance0
318: root_dir: /tmp/deepcam/instance0
  2: root_dir: /tmp/deepcam/instance0
163: root_dir: /tmp/deepcam/instance0
444: root_dir: /tmp/deepcam/instance0
326: root_dir: /tmp/deepcam/instance0
190: root_dir: /tmp/deepcam/instance0
427: root_dir: /tmp/deepcam/instance0
403: root_dir: /tmp/deepcam/instance0
128: root_dir: /tmp/deepcam/instance0
331: root_dir: /tmp/deepcam/instance0
130: root_dir: /tmp/deepcam/instance0
509: root_dir: /tmp/deepcam/instance0
103: root_dir: /tmp/deepcam/instance0
314: root_dir: /tmp/deepcam/instance0
 38: root_dir: /tmp/deepcam/instance0
 46: root_dir: /tmp/deepcam/instance0
506: root_dir: /tmp/deepcam/instance0
475: root_dir: /tmp/deepcam/instance0
172: root_dir: /tmp/deepcam/instance0
322: root_dir: /tmp/deepcam/instance0
150: root_dir: /tmp/deepcam/instance0
443: root_dir: /tmp/deepcam/instance0
437: root_dir: /tmp/deepcam/instance0
385: root_dir: /tmp/deepcam/instance0
323: root_dir: /tmp/deepcam/instance0
441: root_dir: /tmp/deepcam/instance0
 66: root_dir: /tmp/deepcam/instance0
358: root_dir: /tmp/deepcam/instance0
 59: root_dir: /tmp/deepcam/instance0
  5: root_dir: /tmp/deepcam/instance0
346: root_dir: /tmp/deepcam/instance0
151: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413105829, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 121266, "metadata": {"file": "./train_instance.py", "lineno": 353}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413105829, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 15158, "metadata": {"file": "./train_instance.py", "lineno": 354}}
  0: Number of steps per epoch 118
  0: Creating Trainer
  0: Creating Validator
398: root_dir: /tmp/deepcam/instance0
418: root_dir: /tmp/deepcam/instance0
104: root_dir: /tmp/deepcam/instance0
493: root_dir: /tmp/deepcam/instance0
 36: root_dir: /tmp/deepcam/instance0
142: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413146420, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 398}}
  1: hdf5!!
420: hdf5!!
432: hdf5!!
336: hdf5!!
444: hdf5!!
361: hdf5!!
480: hdf5!!
384: hdf5!!
348: hdf5!!
468: hdf5!!
492: hdf5!!
396: hdf5!!
372: hdf5!!
204: hdf5!!
 12: hdf5!!
460: hdf5!!
413: hdf5!!
376: hdf5!!
208: hdf5!!
484: hdf5!!
340: hdf5!!
352: hdf5!!
424: hdf5!!
 88: hdf5!!
364: hdf5!!
472: hdf5!!
448: hdf5!!
388: hdf5!!
232: hdf5!!
160: hdf5!!
344: hdf5!!
356: hdf5!!
464: hdf5!!
380: hdf5!!
417: hdf5!!
404: hdf5!!
453: hdf5!!
392: hdf5!!
224: hdf5!!
488: hdf5!!
368: hdf5!!
128: hdf5!!
 20: hdf5!!
  8: hdf5!!
260: hdf5!!
300: hdf5!!
108: hdf5!!
216: hdf5!!
252: hdf5!!
312: hdf5!!
 36: hdf5!!
264: hdf5!!
325: hdf5!!
 72: hdf5!!
 24: hdf5!!
120: hdf5!!
228: hdf5!!
144: hdf5!!
457: hdf5!!
156: hdf5!!
316: hdf5!!
244: hdf5!!
 16: hdf5!!
268: hdf5!!
292: hdf5!!
 40: hdf5!!
280: hdf5!!
100: hdf5!!
112: hdf5!!
 64: hdf5!!
304: hdf5!!
256: hdf5!!
 52: hdf5!!
 28: hdf5!!
220: hdf5!!
 32: hdf5!!
 44: hdf5!!
 80: hdf5!!
236: hdf5!!
 92: hdf5!!
152: hdf5!!
 68: hdf5!!
248: hdf5!!
 56: hdf5!!
332: hdf5!!
476: hdf5!!
104: hdf5!!
320: hdf5!!
284: hdf5!!
296: hdf5!!
272: hdf5!!
308: hdf5!!
164: hdf5!!
176: hdf5!!
212: hdf5!!
200: hdf5!!
188: hdf5!!
116: hdf5!!
140: hdf5!!
 60: hdf5!!
 96: hdf5!!
192: hdf5!!
132: hdf5!!
168: hdf5!!
180: hdf5!!
288: hdf5!!
 49: hdf5!!
276: hdf5!!
 84: hdf5!!
240: hdf5!!
184: hdf5!!
148: hdf5!!
172: hdf5!!
124: hdf5!!
  4: hdf5!!
328: hdf5!!
136: hdf5!!
 77: hdf5!!
196: hdf5!!
500: hdf5!!
440: hdf5!!
400: hdf5!!
408: hdf5!!
504: hdf5!!
428: hdf5!!
436: hdf5!!
496: hdf5!!
508: hdf5!!
  2: hdf5!!
423: hdf5!!
433: hdf5!!
337: hdf5!!
445: hdf5!!
362: hdf5!!
481: hdf5!!
385: hdf5!!
349: hdf5!!
469: hdf5!!
494: hdf5!!
397: hdf5!!
373: hdf5!!
205: hdf5!!
 13: hdf5!!
461: hdf5!!
414: hdf5!!
377: hdf5!!
209: hdf5!!
485: hdf5!!
341: hdf5!!
353: hdf5!!
425: hdf5!!
 89: hdf5!!
365: hdf5!!
473: hdf5!!
450: hdf5!!
389: hdf5!!
233: hdf5!!
161: hdf5!!
345: hdf5!!
357: hdf5!!
465: hdf5!!
381: hdf5!!
418: hdf5!!
405: hdf5!!
454: hdf5!!
393: hdf5!!
225: hdf5!!
489: hdf5!!
370: hdf5!!
129: hdf5!!
 21: hdf5!!
  9: hdf5!!
261: hdf5!!
301: hdf5!!
109: hdf5!!
217: hdf5!!
253: hdf5!!
313: hdf5!!
 37: hdf5!!
266: hdf5!!
326: hdf5!!
 73: hdf5!!
 25: hdf5!!
121: hdf5!!
229: hdf5!!
145: hdf5!!
459: hdf5!!
157: hdf5!!
317: hdf5!!
245: hdf5!!
 17: hdf5!!
269: hdf5!!
293: hdf5!!
 41: hdf5!!
281: hdf5!!
101: hdf5!!
113: hdf5!!
 65: hdf5!!
305: hdf5!!
257: hdf5!!
 53: hdf5!!
 29: hdf5!!
221: hdf5!!
 33: hdf5!!
 45: hdf5!!
 81: hdf5!!
237: hdf5!!
 93: hdf5!!
153: hdf5!!
 69: hdf5!!
249: hdf5!!
 57: hdf5!!
333: hdf5!!
477: hdf5!!
105: hdf5!!
321: hdf5!!
285: hdf5!!
297: hdf5!!
273: hdf5!!
309: hdf5!!
165: hdf5!!
177: hdf5!!
213: hdf5!!
201: hdf5!!
189: hdf5!!
117: hdf5!!
141: hdf5!!
 61: hdf5!!
 98: hdf5!!
193: hdf5!!
133: hdf5!!
169: hdf5!!
181: hdf5!!
289: hdf5!!
 50: hdf5!!
277: hdf5!!
 85: hdf5!!
241: hdf5!!
185: hdf5!!
149: hdf5!!
173: hdf5!!
125: hdf5!!
  5: hdf5!!
329: hdf5!!
137: hdf5!!
 78: hdf5!!
197: hdf5!!
501: hdf5!!
441: hdf5!!
401: hdf5!!
409: hdf5!!
505: hdf5!!
429: hdf5!!
437: hdf5!!
497: hdf5!!
509: hdf5!!
  3: hdf5!!
421: hdf5!!
434: hdf5!!
338: hdf5!!
446: hdf5!!
363: hdf5!!
482: hdf5!!
386: hdf5!!
350: hdf5!!
470: hdf5!!
495: hdf5!!
398: hdf5!!
374: hdf5!!
206: hdf5!!
 14: hdf5!!
462: hdf5!!
415: hdf5!!
378: hdf5!!
210: hdf5!!
486: hdf5!!
342: hdf5!!
354: hdf5!!
426: hdf5!!
 90: hdf5!!
366: hdf5!!
474: hdf5!!
451: hdf5!!
390: hdf5!!
234: hdf5!!
162: hdf5!!
346: hdf5!!
358: hdf5!!
466: hdf5!!
382: hdf5!!
419: hdf5!!
406: hdf5!!
455: hdf5!!
394: hdf5!!
226: hdf5!!
490: hdf5!!
371: hdf5!!
130: hdf5!!
 22: hdf5!!
 10: hdf5!!
262: hdf5!!
302: hdf5!!
110: hdf5!!
218: hdf5!!
254: hdf5!!
314: hdf5!!
 38: hdf5!!
267: hdf5!!
327: hdf5!!
 74: hdf5!!
 26: hdf5!!
122: hdf5!!
230: hdf5!!
146: hdf5!!
456: hdf5!!
158: hdf5!!
318: hdf5!!
246: hdf5!!
 18: hdf5!!
270: hdf5!!
294: hdf5!!
 42: hdf5!!
282: hdf5!!
102: hdf5!!
114: hdf5!!
 66: hdf5!!
306: hdf5!!
258: hdf5!!
 54: hdf5!!
 30: hdf5!!
222: hdf5!!
 34: hdf5!!
 46: hdf5!!
 82: hdf5!!
238: hdf5!!
 94: hdf5!!
154: hdf5!!
 70: hdf5!!
250: hdf5!!
 58: hdf5!!
334: hdf5!!
478: hdf5!!
106: hdf5!!
322: hdf5!!
286: hdf5!!
298: hdf5!!
274: hdf5!!
310: hdf5!!
166: hdf5!!
178: hdf5!!
214: hdf5!!
202: hdf5!!
190: hdf5!!
119: hdf5!!
142: hdf5!!
 62: hdf5!!
 99: hdf5!!
194: hdf5!!
134: hdf5!!
170: hdf5!!
182: hdf5!!
290: hdf5!!
 51: hdf5!!
278: hdf5!!
 86: hdf5!!
242: hdf5!!
186: hdf5!!
150: hdf5!!
174: hdf5!!
126: hdf5!!
  6: hdf5!!
330: hdf5!!
138: hdf5!!
 79: hdf5!!
198: hdf5!!
502: hdf5!!
442: hdf5!!
402: hdf5!!
410: hdf5!!
506: hdf5!!
430: hdf5!!
438: hdf5!!
498: hdf5!!
510: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633413146422, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 401}}
422: hdf5!!
435: hdf5!!
339: hdf5!!
447: hdf5!!
360: hdf5!!
483: hdf5!!
387: hdf5!!
351: hdf5!!
471: hdf5!!
493: hdf5!!
399: hdf5!!
375: hdf5!!
207: hdf5!!
 15: hdf5!!
463: hdf5!!
412: hdf5!!
379: hdf5!!
211: hdf5!!
487: hdf5!!
343: hdf5!!
355: hdf5!!
427: hdf5!!
 91: hdf5!!
367: hdf5!!
475: hdf5!!
449: hdf5!!
391: hdf5!!
235: hdf5!!
163: hdf5!!
347: hdf5!!
359: hdf5!!
467: hdf5!!
383: hdf5!!
416: hdf5!!
407: hdf5!!
452: hdf5!!
395: hdf5!!
227: hdf5!!
491: hdf5!!
369: hdf5!!
131: hdf5!!
 23: hdf5!!
 11: hdf5!!
263: hdf5!!
303: hdf5!!
111: hdf5!!
219: hdf5!!
255: hdf5!!
315: hdf5!!
 39: hdf5!!
265: hdf5!!
324: hdf5!!
 75: hdf5!!
 27: hdf5!!
123: hdf5!!
231: hdf5!!
147: hdf5!!
458: hdf5!!
159: hdf5!!
319: hdf5!!
247: hdf5!!
 19: hdf5!!
271: hdf5!!
295: hdf5!!
 43: hdf5!!
283: hdf5!!
103: hdf5!!
115: hdf5!!
 67: hdf5!!
307: hdf5!!
259: hdf5!!
 55: hdf5!!
 31: hdf5!!
223: hdf5!!
 35: hdf5!!
 47: hdf5!!
 83: hdf5!!
239: hdf5!!
 95: hdf5!!
155: hdf5!!
 71: hdf5!!
251: hdf5!!
 59: hdf5!!
335: hdf5!!
479: hdf5!!
107: hdf5!!
323: hdf5!!
287: hdf5!!
299: hdf5!!
275: hdf5!!
311: hdf5!!
167: hdf5!!
179: hdf5!!
215: hdf5!!
203: hdf5!!
191: hdf5!!
118: hdf5!!
143: hdf5!!
 63: hdf5!!
 97: hdf5!!
195: hdf5!!
135: hdf5!!
171: hdf5!!
183: hdf5!!
291: hdf5!!
 48: hdf5!!
279: hdf5!!
 87: hdf5!!
243: hdf5!!
187: hdf5!!
151: hdf5!!
175: hdf5!!
127: hdf5!!
  7: hdf5!!
331: hdf5!!
139: hdf5!!
 76: hdf5!!
199: hdf5!!
503: hdf5!!
443: hdf5!!
403: hdf5!!
411: hdf5!!
507: hdf5!!
431: hdf5!!
439: hdf5!!
499: hdf5!!
511: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633413146422, "event_type": "INTERVAL_START", "key": "staging_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 405}}
  0: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
  0: :::MLLOG {"namespace": "", "time_ms": 1633413256784, "event_type": "INTERVAL_END", "key": "staging_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 425}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413256787, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 1, "step_num": 0}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413262642, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00017999999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413262671, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.1618446558713913, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413262671, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.4767321348190308, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413264648, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00038, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413264677, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.19543544948101044, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413264677, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.1297982931137085, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413265610, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00058, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413265610, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.26677432656288147, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413265611, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.7706053256988525, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413266540, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0007800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413266540, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.31902724504470825, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413266541, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.44530850648880005, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413267485, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00098, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413267486, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3283997178077698, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413267486, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.22622305154800415, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413268423, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00118, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413268424, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.331765353679657, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413268424, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.12482762336730957, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413269360, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00138, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413269360, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3618071973323822, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413269361, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.08047865331172943, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413270294, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00158, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413270295, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.4475604295730591, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413270295, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.061046212911605835, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413271233, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0017800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413271233, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5011544227600098, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413271234, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.04807669669389725, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413272161, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00198, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413272162, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5055880546569824, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413272162, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.04258454963564873, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413273097, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00218, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413273098, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5047659277915955, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413273098, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03888515755534172, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413273847, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 1}}
  0: EVAL: first data load time: 0.3319353275001049
  0: EVAL: step 1 time -> 0.05292532034218311
  0: EVAL: step 2 time -> 0.12444940954446793
  0: EVAL: step 3 time -> 0.011928927153348923
  0: EVAL: step 4 time -> 0.011134447529911995
  0: EVAL: full eval time -> 1.0000724028795958
  0: :::MLLOG {"namespace": "", "time_ms": 1633413274890, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.48896280790259267, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413274890, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.06485164937785534, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413274891, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413274910, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413274929, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 2, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413275129, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0023799999999999997, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413275129, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5357819199562073, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413275129, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03804541006684303, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413276061, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0025800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413276061, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5390508770942688, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413276061, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03864935785531998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413276996, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00278, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413276997, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5411322116851807, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413276997, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03577227517962456, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413277936, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00298, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413277936, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5609796047210693, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413277936, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03389071673154831, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413278862, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00318, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413278863, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5454225540161133, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413278863, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03389555215835571, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413279801, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0033799999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413279802, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.564274787902832, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413279802, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.032951679080724716, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413280743, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0035800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413280743, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5710173845291138, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413280743, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03316779434680939, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413281679, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00378, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413281679, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5752870440483093, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413281679, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03141185641288757, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413282620, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00398, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413282620, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5993924140930176, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413282620, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.029430802911520004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413283560, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413283560, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5855680704116821, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413283560, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03127532824873924, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413284493, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413284493, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5966654419898987, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413284494, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.028133049607276917, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413285430, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413285430, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6109541654586792, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413285430, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.027452502399683, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413285997, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 2}}
  0: EVAL: first data load time: 0.0030983993783593178
  0: EVAL: step 1 time -> 0.012130280956625938
  0: EVAL: step 2 time -> 0.01110014133155346
  0: EVAL: step 3 time -> 0.010987546294927597
  0: EVAL: step 4 time -> 0.12410636432468891
  0: EVAL: full eval time -> 0.7834089864045382
  0: :::MLLOG {"namespace": "", "time_ms": 1633413286783, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6078189296699763, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413286783, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.024569539473921567, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413286784, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 2}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413286784, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413286804, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 3, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413288040, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413288041, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.617061197757721, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413288041, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0252304058521986, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413289987, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413289988, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6009559035301208, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413289988, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.028357762843370438, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413291205, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413291206, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6110261678695679, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413291206, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02529841661453247, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413292150, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413292150, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6282996535301208, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413292150, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02500292845070362, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413293089, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413293089, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6285337209701538, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413293090, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.025277694687247276, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413294018, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413294018, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6169827580451965, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413294018, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02663922682404518, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413294946, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413294946, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6245143413543701, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413294946, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.025192296132445335, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413295884, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413295885, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6394896507263184, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413295885, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02412787452340126, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413296820, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413296821, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6380279064178467, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413296821, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02282753959298134, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413297757, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413297758, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6412764191627502, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413297758, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02254362404346466, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413298688, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413298689, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6312834620475769, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413298689, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.025479717180132866, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413299619, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413299620, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6519350409507751, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413299620, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02233586087822914, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413299998, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 3}}
  0: EVAL: first data load time: 0.00223635695874691
  0: EVAL: step 1 time -> 0.012610825709998608
  0: EVAL: step 2 time -> 0.01116141676902771
  0: EVAL: step 3 time -> 0.0109657421708107
  0: EVAL: step 4 time -> 0.010865391232073307
  0: EVAL: full eval time -> 0.5358432494103909
  0: :::MLLOG {"namespace": "", "time_ms": 1633413300537, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5974902253554228, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413300537, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.02580549736138714, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413300537, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 3}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413300557, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413300580, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 4, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413302380, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413302380, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6430317759513855, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413302380, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02124507911503315, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413303967, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413303968, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6462217569351196, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413303968, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021135130897164345, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413305063, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413305064, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6464850902557373, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413305064, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021020526066422462, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413306001, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413306001, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6606058478355408, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413306001, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01970922388136387, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413306939, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413306939, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6525939106941223, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413306940, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020074741914868355, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413307875, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413307875, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6688658595085144, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413307876, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02003658004105091, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413308799, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413308800, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6648312211036682, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413308800, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019005991518497467, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413309732, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413309732, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6702201962471008, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413309732, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01894245110452175, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413310656, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413310656, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6698211431503296, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413310657, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018466921523213387, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413311588, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413311588, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6775822639465332, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413311589, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01877695322036743, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413312529, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413312530, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6601048707962036, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413312530, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01892298460006714, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413313457, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413313457, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6822640299797058, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413313457, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017349209636449814, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413313644, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 4}}
  0: EVAL: first data load time: 0.0014626672491431236
  0: EVAL: step 1 time -> 0.012334218248724937
  0: EVAL: step 2 time -> 0.011285606771707535
  0: EVAL: step 3 time -> 0.011020469479262829
  0: EVAL: step 4 time -> 0.010924562811851501
  0: EVAL: full eval time -> 0.3530111573636532
  0: :::MLLOG {"namespace": "", "time_ms": 1633413314000, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6301874165044861, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413314000, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.019917863704139317, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413314000, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 4}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413314020, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413314040, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 5, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413316425, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413316425, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6738945245742798, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413316426, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017404353246092796, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413317759, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413317759, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6856346130371094, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413317759, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017349569126963615, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413318774, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413318774, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6901934742927551, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413318774, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01716133952140808, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413319727, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413319727, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6989046335220337, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413319728, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01718529500067234, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413320738, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413320739, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6850024461746216, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413320739, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01728590950369835, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413321668, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413321668, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6879477500915527, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413321668, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01633600890636444, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413322605, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413322606, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6926130652427673, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413322606, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016564680263400078, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413323542, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413323543, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6856157779693604, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413323543, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.018454020842909813, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413324468, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413324469, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7028746008872986, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413324469, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016343699768185616, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413325407, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413325407, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6873713731765747, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413325407, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01688004657626152, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413326338, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413326338, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.698298990726471, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413326338, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017157595604658127, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327285, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327285, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7146899104118347, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327286, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01709488406777382, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327288, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 5}}
  0: EVAL: first data load time: 0.004616210237145424
  0: EVAL: step 1 time -> 0.012454664334654808
  0: EVAL: step 2 time -> 0.01118699461221695
  0: EVAL: step 3 time -> 0.011066190898418427
  0: EVAL: step 4 time -> 0.010861631482839584
  0: EVAL: full eval time -> 0.3191649653017521
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327610, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6809451511784206, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327610, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.017769670215913216, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327611, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 5}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327630, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413327634, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 6, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413328561, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413328561, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7026710510253906, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413328561, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015293813310563564, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413329490, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413329491, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7035300731658936, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413329491, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015303202904760838, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413330419, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413330420, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7188858389854431, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413330420, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014834786765277386, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413331350, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413331351, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7262545228004456, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413331351, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015354613773524761, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413332273, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413332274, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7208775281906128, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413332274, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015242362394928932, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413333208, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413333208, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7261272668838501, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413333208, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01515580527484417, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413334139, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413334139, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7170422673225403, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413334139, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015278361737728119, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413335073, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413335074, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.728002667427063, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413335074, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01375557016581297, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413336009, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413336009, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.727981448173523, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413336009, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01458242442458868, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413336942, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413336942, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7117900252342224, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413336943, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015135289169847965, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413337876, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413337877, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7140122652053833, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413337877, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0165350753813982, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413338616, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 6}}
  0: EVAL: first data load time: 0.003860175609588623
  0: EVAL: step 1 time -> 0.012287992984056473
  0: EVAL: step 2 time -> 0.011142977513372898
  0: EVAL: step 3 time -> 0.01102099847048521
  0: EVAL: step 4 time -> 0.01085071824491024
  0: EVAL: full eval time -> 0.7545121824368834
  0: :::MLLOG {"namespace": "", "time_ms": 1633413339374, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.715449736731429, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413339374, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.014480995493303866, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413339374, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 6}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413339393, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413339415, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 7, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413340040, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413340040, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7438874840736389, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413340040, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014705273322761059, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413342175, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413342176, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7406502366065979, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413342176, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014224361628293991, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413343381, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413343381, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7381485104560852, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413343381, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01434160303324461, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413344345, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413344345, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7517662048339844, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413344345, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013531932607293129, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413345279, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413345279, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7622196078300476, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413345279, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013296342454850674, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413346205, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413346205, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.749212920665741, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413346205, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013437929563224316, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413347140, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413347140, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7495517134666443, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413347141, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01420101523399353, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413348072, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413348072, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7451583743095398, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413348072, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013451410457491875, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413349005, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413349005, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7580181956291199, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413349005, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01355966366827488, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413349944, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413349944, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7487422823905945, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413349945, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013387901708483696, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413350880, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413350881, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7433885335922241, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413350881, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014833222143352032, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413351811, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413351812, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7646526098251343, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413351812, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014050806872546673, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413352372, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 7}}
  0: EVAL: first data load time: 0.005088255740702152
  0: EVAL: step 1 time -> 0.012086193077266216
  0: EVAL: step 2 time -> 0.011201217770576477
  0: EVAL: step 3 time -> 0.011066596023738384
  0: EVAL: step 4 time -> 0.010878476314246655
  0: EVAL: full eval time -> 0.5255703777074814
  0: :::MLLOG {"namespace": "", "time_ms": 1633413352901, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7423515918780512, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413352901, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.012040654278191591, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413352901, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 7}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413352921, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413352945, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 8, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413354177, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413354177, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7728350758552551, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413354177, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012774895876646042, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413356158, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413356158, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7570700645446777, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413356158, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01361019629985094, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413357386, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413357386, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7512513399124146, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413357387, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012891157530248165, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413358325, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413358326, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7324861288070679, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413358326, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012552101165056229, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413359257, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413359258, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7741640210151672, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413359258, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012838196009397507, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413360191, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413360191, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7704640626907349, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413360191, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01344314031302929, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413361119, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413361119, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7475587129592896, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413361119, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013355104252696037, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413362045, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413362045, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7679051756858826, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413362045, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012799211777746677, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413362976, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413362977, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7764266729354858, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413362977, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012438450939953327, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413363916, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413363916, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7685126662254333, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413363916, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01301034726202488, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413364847, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413364848, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7601031064987183, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413364848, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013483336195349693, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413365788, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413365788, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7717273831367493, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413365788, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013531611301004887, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413366165, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 8}}
  0: EVAL: first data load time: 0.001729484647512436
  0: EVAL: step 1 time -> 0.0122307687997818
  0: EVAL: step 2 time -> 0.011194862425327301
  0: EVAL: step 3 time -> 0.01105449814349413
  0: EVAL: step 4 time -> 0.010923447087407112
  0: EVAL: full eval time -> 0.7416328126564622
  0: :::MLLOG {"namespace": "", "time_ms": 1633413366909, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7057690890330188, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413366909, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.018522577402789574, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413366909, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 8}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413366929, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413366953, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 9, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413368802, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413368802, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7789222598075867, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413368802, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011667709797620773, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413370229, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413370229, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7552867531776428, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413370229, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011824163608253002, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413371199, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413371199, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7844537496566772, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413371199, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011529061011970043, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413372133, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413372133, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7759249210357666, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413372133, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0121108153834939, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413373067, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413373067, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7653822898864746, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413373068, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011728698387742043, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413374015, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413374015, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.773510217666626, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413374015, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011705400422215462, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413374971, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413374971, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7719631195068359, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413374971, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011679677292704582, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413375907, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413375908, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7908850908279419, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413375908, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012524428777396679, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413376837, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413376837, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7930702567100525, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413376838, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011952877044677734, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413377771, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413377772, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7851959466934204, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413377772, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01172239612787962, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413378706, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413378707, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7793344259262085, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413378707, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011450185440480709, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413379645, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413379645, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7847530245780945, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413379645, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012855153530836105, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413379831, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 9}}
  0: EVAL: first data load time: 0.003350375220179558
  0: EVAL: step 1 time -> 0.012712215073406696
  0: EVAL: step 2 time -> 0.011225062422454357
  0: EVAL: step 3 time -> 0.011056998744606972
  0: EVAL: step 4 time -> 0.010995501652359962
  0: EVAL: full eval time -> 0.7393370838835835
  0: :::MLLOG {"namespace": "", "time_ms": 1633413380573, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7248382789822206, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413380573, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.02174518573628612, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413380573, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 9}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413380593, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413380617, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 10, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413382895, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413382895, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7740375399589539, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413382895, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01193828321993351, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413384111, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413384111, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7788301706314087, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413384111, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011175819672644138, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413385152, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413385153, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7831286787986755, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413385153, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011501745320856571, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413386094, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413386094, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8078369498252869, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413386094, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010856200009584427, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413387020, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413387021, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7878377437591553, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413387021, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01266529317945242, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413387954, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413387955, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7892528176307678, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413387955, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012064843438565731, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413388881, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413388882, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7553902268409729, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413388882, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012503238394856453, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413389824, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413389824, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7811452150344849, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413389824, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011605040170252323, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413390744, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413390744, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7919102311134338, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413390744, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011288034729659557, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413391681, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413391681, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.790123462677002, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413391681, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011612514033913612, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413392611, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413392612, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8015478849411011, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413392612, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011897304095327854, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393540, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393541, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7910485863685608, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393541, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011918921954929829, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393543, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 10}}
  0: EVAL: first data load time: 0.0011651553213596344
  0: EVAL: step 1 time -> 0.012314105406403542
  0: EVAL: step 2 time -> 0.011239089071750641
  0: EVAL: step 3 time -> 0.011116473004221916
  0: EVAL: step 4 time -> 0.01091241929680109
  0: EVAL: full eval time -> 0.32533755525946617
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393872, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7637466730645533, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393872, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.013834662260646193, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393872, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393892, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413393895, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 11, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413394824, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413394825, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8114380240440369, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413394825, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010693497024476528, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413395753, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413395754, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8058158755302429, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413395754, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01045569684356451, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413396695, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413396696, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8119248151779175, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413396696, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010677197948098183, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413397621, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413397622, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8065620064735413, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413397622, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010102388449013233, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413398555, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413398556, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8050116896629333, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413398556, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010572506114840508, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413399488, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413399489, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8006791472434998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413399489, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010790692642331123, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413400427, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413400427, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7797530889511108, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413400427, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011347523890435696, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413401364, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413401364, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7921775579452515, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413401364, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011385328136384487, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413402300, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413402300, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7678576707839966, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413402301, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010503160767257214, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413403222, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413403222, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7917923331260681, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413403223, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010683584026992321, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413404148, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413404149, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7985623478889465, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413404149, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011290227063000202, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413404902, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 11}}
  0: EVAL: first data load time: 0.0016063237562775612
  0: EVAL: step 1 time -> 0.012730550952255726
  0: EVAL: step 2 time -> 0.011239152401685715
  0: EVAL: step 3 time -> 0.011094312183558941
  0: EVAL: step 4 time -> 0.010898659937083721
  0: EVAL: full eval time -> 0.3246595310047269
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405230, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7378514671501847, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405230, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.015616491800688992, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405231, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 11}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405250, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405254, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 12, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405450, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405450, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8113997578620911, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413405450, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010201607830822468, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413406381, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413406381, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.830062210559845, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413406382, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008650694042444229, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413407307, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413407308, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8360263705253601, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413407308, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008641340769827366, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413408248, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413408248, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8417065739631653, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413408249, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008385337889194489, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413409176, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413409177, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8454340696334839, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413409177, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008215092122554779, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413410106, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413410107, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8400474786758423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413410107, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00799885205924511, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413411038, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413411039, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8441818356513977, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413411039, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00807752925902605, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413411963, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413411963, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8450464010238647, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413411964, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007932094857096672, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413412894, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413412894, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8465086817741394, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413412894, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008263038471341133, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413413831, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413413832, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8507360816001892, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413413832, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007971979677677155, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413414764, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413414765, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8524205684661865, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413414765, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007550226990133524, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413415710, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413415711, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8455737829208374, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413415711, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007527933921664953, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413416288, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 12}}
  0: EVAL: first data load time: 0.0012118136510252953
  0: EVAL: step 1 time -> 0.012267100624740124
  0: EVAL: step 2 time -> 0.011270547285676003
  0: EVAL: step 3 time -> 0.01108337938785553
  0: EVAL: step 4 time -> 0.0109563572332263
  0: EVAL: full eval time -> 0.7953597651794553
  0: :::MLLOG {"namespace": "", "time_ms": 1633413417086, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8204698271952104, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413417087, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01030450648030846, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413417087, "event_type": "POINT_IN_TIME", "key": "target_accuracy_reached", "value": 0.82, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 374, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413417087, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 12}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413417106, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413417130, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 507, "status": "success"}}
216: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
216: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
255: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
255: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
464: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
464: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
154: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
154: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
208: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
208: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
440: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
280: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
485: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
280: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
440: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
485: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
251: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
251: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
389: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
229: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
229: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
389: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
240: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
240: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 70: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
125: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 70: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
125: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
358: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
358: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
508: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
508: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  0: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  0: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
233: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
233: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
120: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
120: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
290: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
290: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
341: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
341: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
456: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
456: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
300: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
300: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
492: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
492: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
238: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
238: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
256: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
256: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
497: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
497: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
137: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
137: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
422: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
422: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
215: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
215: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 92: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 92: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
430: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
430: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
159: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
159: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
225: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
225: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 49: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 49: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 25: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 25: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
438: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
438: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
164: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
164: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
435: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
435: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
270: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
270: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
380: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
380: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
294: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
294: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 81: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 81: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 63: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 63: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
425: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
425: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 56: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 56: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
279: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
279: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
418: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
418: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 98: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 98: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
348: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
348: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
145: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
145: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
444: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
444: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  8: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  8: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
302: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
302: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
488: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
488: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 77: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 77: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
297: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
297: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
323: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
323: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
324: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
324: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
267: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
267: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 85: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 85: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
221: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
221: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
272: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
272: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
470: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
470: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
465: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
465: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
500: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
500: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
218: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
218: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
263: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
263: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
455: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
455: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
245: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
245: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
152: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
152: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
388: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
288: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
388: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
288: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 54: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 54: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
460: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
460: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
228: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
228: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
400: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
400: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
504: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
504: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 73: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 73: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
160: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
160: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
484: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
484: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
232: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
232: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
209: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
209: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
311: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
311: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 76: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 76: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
292: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
292: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
353: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
353: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
252: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
252: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
189: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
189: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
414: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
414: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
319: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
319: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
375: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
375: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
410: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
410: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  1: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
156: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  1: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
156: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
104: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
104: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
446: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
446: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
404: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
404: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 37: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 37: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
304: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
304: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
340: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
340: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
212: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
212: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
451: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
451: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
356: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
356: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
144: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
144: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
236: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
236: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 16: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 16: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
351: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
351: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
510: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
510: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
201: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
201: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 88: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 88: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
136: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
136: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
151: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
151: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
126: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
126: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
429: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
429: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
502: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
502: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
134: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
134: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
441: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
441: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
249: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
457: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
249: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
457: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 43: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 43: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 32: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 32: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
122: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
122: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
398: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
398: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
493: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
493: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
434: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
434: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
275: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
275: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
420: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
420: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
283: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
283: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 12: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 12: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
483: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
483: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
101: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
101: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 36: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 36: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 30: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 30: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 24: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 24: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 68: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 68: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
108: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
108: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
269: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
269: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
365: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
105: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
365: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
105: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
193: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
193: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
259: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
259: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  5: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  5: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 95: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 95: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
163: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
163: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
436: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
436: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
227: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
227: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 66: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 66: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
368: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
368: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
128: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
128: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
242: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
242: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
416: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
416: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
204: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
204: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
262: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
262: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
217: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
217: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 80: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 80: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
276: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
276: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 44: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 44: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
467: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
467: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
452: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
452: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
155: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
155: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
391: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
391: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 20: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 20: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 96: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 96: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
333: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
333: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
187: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
187: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
352: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
352: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
486: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
486: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
313: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
313: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
291: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
291: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
412: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
412: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
230: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
230: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
286: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
286: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
211: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
211: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
406: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
406: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 78: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 78: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
177: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
177: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
264: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
264: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
166: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
166: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
336: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
336: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
248: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
248: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
362: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
362: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
254: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
254: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
382: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
382: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
344: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
344: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
147: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
147: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
445: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
445: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 48: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 48: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
392: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
392: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
432: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
432: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 72: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 72: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
138: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
138: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
301: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
301: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
296: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
296: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
234: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
234: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
124: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
124: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
431: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
431: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
113: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
113: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
424: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
424: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
316: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
316: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
268: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
268: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
468: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
468: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
129: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
129: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 59: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 59: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
349: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
349: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
220: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
509: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
220: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
509: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
343: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
343: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
224: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
322: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
322: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
224: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 41: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 41: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
239: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
239: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
308: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
308: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
359: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
378: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
378: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
359: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
117: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
117: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
403: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
403: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
458: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
458: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
244: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
244: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 84: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 84: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
325: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
325: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
408: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
408: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  2: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  2: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
491: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
491: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
387: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
387: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
505: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
505: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
214: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
214: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
158: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
158: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
121: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
121: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
306: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
306: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 71: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 71: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
423: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
423: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
257: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
257: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
281: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
281: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
472: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
472: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
188: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
188: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 38: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 38: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
260: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
260: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
442: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
442: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  9: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  9: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
206: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
206: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
372: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
372: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
461: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
461: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 67: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 67: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
499: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
499: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 52: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 52: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
495: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
495: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 26: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
200: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 26: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
200: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
295: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
295: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
476: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
476: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  6: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  6: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 93: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 93: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 17: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 17: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
132: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
132: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
106: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
106: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
171: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
171: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
439: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
439: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
243: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
243: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
330: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
330: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 83: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 83: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 28: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 28: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
148: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
148: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
174: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
174: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
112: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
112: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
277: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
277: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
337: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
337: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
345: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
345: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
419: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
419: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
383: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
383: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
354: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
354: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
480: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
480: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
284: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
284: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 99: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 99: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 34: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 34: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 60: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 60: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
298: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
298: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
111: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
111: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
167: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
384: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
167: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
384: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
407: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 91: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 91: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
407: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
364: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
364: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
266: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
266: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
184: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
184: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
192: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
192: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
273: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
273: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
454: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
454: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
396: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
396: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
179: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
179: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
320: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
320: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
131: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
131: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
394: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
394: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 58: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 58: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
449: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
449: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
415: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
415: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
332: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
332: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
222: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
222: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
198: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
198: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
328: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
328: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
506: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
506: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
471: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
471: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
246: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
246: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
326: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
326: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 75: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 75: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
490: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
490: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 55: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 55: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
103: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
103: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
180: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
180: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 22: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 22: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
309: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
309: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
207: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
207: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 15: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 15: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
140: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
140: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
462: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
462: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
479: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
479: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
360: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
360: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
318: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
318: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
474: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
474: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
  4: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
  4: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
370: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
370: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
312: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
312: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
373: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
373: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 86: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 86: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
401: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 50: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 50: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
401: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 10: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
496: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 10: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
496: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
190: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
190: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
427: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 65: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
427: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 65: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
203: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
203: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 18: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 18: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
135: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
135: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
305: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
305: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 35: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 35: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
339: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
339: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
409: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
409: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
176: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
176: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
150: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
150: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
376: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
376: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 40: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 40: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
196: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
287: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
287: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
196: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
162: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
162: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 61: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 61: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 46: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 46: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
397: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
397: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
114: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
114: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
482: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
482: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
385: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
385: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
116: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
116: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
346: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
346: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
194: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
194: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
110: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
110: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
100: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
100: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 90: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 90: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
395: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
395: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
168: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
168: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
 29: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
 29: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
334: ENDING TIMING RUN AT 2021-10-05 07:57:02 AM
334: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
367: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
367: RESULT,DEEPCAM_HPC,,468,qv2382,2021-10-05 07:49:14 AM
329: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
329: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
450: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
450: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 14: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 14: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
186: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
186: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
181: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
181: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
172: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
172: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
369: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
369: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
314: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
314: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
473: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
473: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
363: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
363: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 23: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 23: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
478: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
478: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
143: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
143: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
199: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
199: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 45: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 45: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
379: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
379: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
119: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
119: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
183: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
183: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
503: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
503: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
170: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
170: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
173: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
173: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
141: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
141: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
466: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
466: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
250: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
250: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
153: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
153: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
219: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
219: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
231: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
231: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
511: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
511: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
342: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
342: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
235: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
235: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
123: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
123: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
487: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
487: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
258: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
258: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
127: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
127: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
  3: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
  3: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
282: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
282: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
237: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
237: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
210: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
210: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
213: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
213: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 94: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 94: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
157: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
157: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
459: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
459: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
443: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
443: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
271: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
271: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 27: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 27: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
241: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
241: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 69: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 69: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
433: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
433: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
146: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
146: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
274: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
274: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
299: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
299: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
165: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
165: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
321: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
321: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 97: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 97: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 57: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 57: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
463: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
463: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
327: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
327: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
390: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
390: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
265: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
265: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
247: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
247: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
289: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
289: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
357: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
357: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
494: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
494: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 87: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 87: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
355: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
355: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
453: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
453: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 53: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 53: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 51: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 51: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
317: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
317: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
374: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
374: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 19: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 19: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
411: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
411: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
498: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
498: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
310: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
310: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
421: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
421: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
133: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
133: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
293: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
293: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
413: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
413: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
437: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
437: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
307: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
307: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
202: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
202: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
417: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
417: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
149: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
149: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
399: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
399: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 89: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 89: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
253: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
381: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
381: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
253: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
371: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
371: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
448: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
448: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
278: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
278: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
481: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
481: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
191: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
191: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
447: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
447: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 31: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 31: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
335: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
335: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
195: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
195: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
102: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
102: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 62: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 62: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
366: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
366: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
223: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
223: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 64: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 64: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
428: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
428: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
489: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
489: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 13: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 13: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
507: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
507: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
  7: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
  7: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
185: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
185: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 74: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 74: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 79: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 79: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
139: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
139: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
469: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
469: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
285: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
285: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 21: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 21: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 47: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 47: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
393: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
393: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
315: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
315: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
361: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
361: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
130: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
130: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
402: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
402: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
161: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
161: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
303: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
303: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
226: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
226: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
377: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
377: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 11: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 11: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 42: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 42: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
347: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
347: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
386: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
386: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
107: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
107: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
426: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
426: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 82: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 82: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
475: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
475: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
109: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
109: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
338: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 39: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
338: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 39: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
477: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
477: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
261: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
261: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
175: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
175: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
350: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
350: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
501: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
501: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
 33: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
 33: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
405: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
405: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
182: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
182: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
115: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
115: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
118: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
118: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
178: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
178: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
169: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
169: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
331: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
331: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
197: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
197: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
205: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
205: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
142: ENDING TIMING RUN AT 2021-10-05 07:57:03 AM
142: RESULT,DEEPCAM_HPC,,469,qv2382,2021-10-05 07:49:14 AM
