/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/docker/deepcam_optimized-21.09_2.sif
configs/best_configs/config_DGXA100_512GPU_BS1024_graph.sh
#!/bin/bash

# hyperparameters
export LOCAL_BATCH_SIZE=2
export START_LR=0.004
export OPTIMIZER="LAMB"
export LR_SCHEDULE_TYPE="multistep"
export LR_MILESTONES="1100 4096"
export LR_DECAY_RATE="0.1"
export LR_WARMUP_STEPS=200
export LR_WARMUP_FACTOR=1.
export WEIGHT_DECAY=0.01
export BATCHNORM_GROUP_SIZE=1

# data parameters
export SHUFFLE_MODE="global"
export DATA_FORMAT="dali-es/hdf5"
export PRECISION_MODE="amp"
export LOCAL_VALIDATION_BATCH_SIZE=8

# output parameters
#export OUTPUT_ROOT=/results/best

export TRAINING_INSTANCE_SIZE=$((128*4))

# auxiliary parameters
export LOGGING_FREQUENCY=10

# misc args
export ADDITIONAL_ARGS="--enable_jit --enable_graph"
#--disable_comm_overlap
# system parameters
#export DGXNGPU=8
#export DGXNNODES=64
#export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
#export WALLTIME=00:30:00
export DGXNGPU=4
export DGXNNODES=128
export DGXSYSTEM=$(basename $(readlink -f ${BASH_SOURCE[0]}) | sed 's/^config_//' | sed 's/\.sh$//' )
export WALLTIME=01:00:00
 25: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 58: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
508: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
160: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
461: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  0: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
436: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 37: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
102: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 68: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
463: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
463: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 27: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
453: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
402: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 30: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 59: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 36: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 36: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 88: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
161: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
101: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
387: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  2: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  2: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
113: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
443: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  6: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  6: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
202: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
410: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 24: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 25: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 27: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 24: Running Multi Instance Training
 25: Running Multi Instance Training
 27: Running Multi Instance Training
 24: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 27: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 25: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 29: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
471: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
462: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 91: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 56: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 56: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
456: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
504: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
504: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
183: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 62: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 58: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 59: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 58: Running Multi Instance Training
 59: Running Multi Instance Training
 88: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: Running Multi Instance Training
 58: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 91: Running Multi Instance Training
 59: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 56: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 88: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 56: Running Multi Instance Training
 36: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 37: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 91: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 36: Running Multi Instance Training
 37: Running Multi Instance Training
 56: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
436: Running Multi Instance Training
 36: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 37: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
436: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 29: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 30: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 29: Running Multi Instance Training
 30: Running Multi Instance Training
202: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: Running Multi Instance Training
 29: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 30: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: Using bindings from SLURM: mask_cpu:
439: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
202: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  0: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
439: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  2: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  0: Running Multi Instance Training
  2: Running Multi Instance Training
 68: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 68: Running Multi Instance Training
  0: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  2: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 68: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
508: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
508: Running Multi Instance Training
453: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
453: Running Multi Instance Training
508: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
101: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
101: Running Multi Instance Training
102: Running Multi Instance Training
453: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
101: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
402: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
102: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
402: Running Multi Instance Training
387: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
402: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
387: Running Multi Instance Training
432: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  6: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
387: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  6: Running Multi Instance Training
113: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
119: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
113: Running Multi Instance Training
  6: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
461: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
113: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
463: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: Running Multi Instance Training
160: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: Running Multi Instance Training
463: Running Multi Instance Training
161: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
160: Running Multi Instance Training
  1: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
461: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
509: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: Running Multi Instance Training
410: Running Multi Instance Training
439: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
462: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
463: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
160: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
439: Running Multi Instance Training
264: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
264: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
161: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
443: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
410: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
471: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
443: Running Multi Instance Training
471: Running Multi Instance Training
439: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
456: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
456: Running Multi Instance Training
443: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
504: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
471: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
504: Running Multi Instance Training
456: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
183: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
183: Running Multi Instance Training
504: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 62: Running Multi Instance Training
183: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 62: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 23: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
385: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
452: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
114: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
114: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
400: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
509: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  1: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
509: Running Multi Instance Training
  1: Running Multi Instance Training
509: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  1: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 78: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 78: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
432: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: Running Multi Instance Training
119: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
432: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
442: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
119: Running Multi Instance Training
119: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
131: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
385: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
131: Running Multi Instance Training
385: Running Multi Instance Training
264: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: Running Multi Instance Training
264: Running Multi Instance Training
131: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
385: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
114: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
452: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
264: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
114: Running Multi Instance Training
114: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
400: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
400: Running Multi Instance Training
400: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 23: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
442: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 23: Running Multi Instance Training
442: Running Multi Instance Training
 23: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
442: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
409: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 78: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 78: Running Multi Instance Training
 78: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 14: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
109: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
409: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
409: Running Multi Instance Training
163: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
409: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 53: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
506: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
506: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
140: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: Running Multi Instance Training
 14: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
140: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 14: Running Multi Instance Training
163: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
163: Running Multi Instance Training
 14: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
109: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
109: Running Multi Instance Training
163: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
109: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
469: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
506: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
469: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
506: Running Multi Instance Training
506: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 53: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 53: Running Multi Instance Training
 53: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
158: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
469: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
469: Running Multi Instance Training
469: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 70: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  7: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 19: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
148: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
148: Running Multi Instance Training
148: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
200: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 43: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 38: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  7: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 70: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  7: Running Multi Instance Training
 70: Running Multi Instance Training
  7: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 70: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
270: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
406: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
406: Running Multi Instance Training
158: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
158: Running Multi Instance Training
406: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
158: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
200: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
200: Running Multi Instance Training
200: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
510: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 19: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 19: Running Multi Instance Training
 19: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 38: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 38: Running Multi Instance Training
 38: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 43: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 43: Running Multi Instance Training
 43: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
510: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
510: Running Multi Instance Training
103: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
510: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
270: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
270: Running Multi Instance Training
270: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 60: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
457: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
239: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
103: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
103: Running Multi Instance Training
103: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
108: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 60: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 60: Running Multi Instance Training
457: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
457: Running Multi Instance Training
 60: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
457: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
150: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
150: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
438: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
108: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
108: Running Multi Instance Training
108: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
266: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
239: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
239: Running Multi Instance Training
239: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
117: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
117: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 79: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
150: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
150: Running Multi Instance Training
193: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
193: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 47: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
438: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
438: Running Multi Instance Training
150: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
438: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
186: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
266: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: Running Multi Instance Training
455: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
295: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
266: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
401: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
455: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
295: Running Multi Instance Training
117: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
117: Running Multi Instance Training
295: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 28: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 28: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 79: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
129: Running Multi Instance Training
117: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 12: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 79: Running Multi Instance Training
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 12: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
129: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 79: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
201: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
201: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
181: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 90: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 90: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
401: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
455: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 47: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: Running Multi Instance Training
455: Running Multi Instance Training
 47: Running Multi Instance Training
193: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
401: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
193: Running Multi Instance Training
455: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 47: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 28: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 20: Running Multi Instance Training
 28: Running Multi Instance Training
193: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 20: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 28: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 12: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 12: Running Multi Instance Training
142: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
186: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
186: Running Multi Instance Training
 12: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
186: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 69: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 69: Running Multi Instance Training
 69: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
201: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
411: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
201: Running Multi Instance Training
181: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
384: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: Running Multi Instance Training
441: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
384: Running Multi Instance Training
201: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
181: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: Running Multi Instance Training
384: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 90: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
142: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
142: Running Multi Instance Training
142: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
441: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
441: Running Multi Instance Training
411: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: Running Multi Instance Training
411: Running Multi Instance Training
441: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
115: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
173: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
115: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
411: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
236: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
458: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
458: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
107: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 42: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 54: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
115: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: Running Multi Instance Training
236: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
115: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
236: Running Multi Instance Training
458: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
236: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
458: Running Multi Instance Training
458: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
427: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
427: Running Multi Instance Training
159: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
427: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 54: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 54: Running Multi Instance Training
 42: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 42: Running Multi Instance Training
 54: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 42: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
107: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
107: Running Multi Instance Training
107: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
292: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
159: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: Running Multi Instance Training
 18: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
267: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
159: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
267: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
434: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
268: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
268: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
  5: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
292: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
292: Running Multi Instance Training
292: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
197: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
479: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 18: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 18: Running Multi Instance Training
267: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
267: Running Multi Instance Training
 18: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
267: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
434: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: Running Multi Instance Training
268: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
434: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
268: Running Multi Instance Training
  5: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  5: Running Multi Instance Training
268: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  5: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
141: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
507: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
187: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
197: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
197: Running Multi Instance Training
479: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
479: Running Multi Instance Training
197: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
479: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
141: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
141: Running Multi Instance Training
141: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
124: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
470: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
507: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
507: Running Multi Instance Training
187: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
187: Running Multi Instance Training
507: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
187: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 63: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 63: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
470: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
470: Running Multi Instance Training
470: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 63: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 63: Running Multi Instance Training
 63: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
124: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
124: Running Multi Instance Training
124: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
116: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
116: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
180: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
180: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
192: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
208: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
111: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 92: Running Multi Instance Training
116: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 92: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
116: Running Multi Instance Training
116: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
180: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
180: Running Multi Instance Training
404: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
180: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
192: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
192: Running Multi Instance Training
192: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
111: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
111: Running Multi Instance Training
433: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
111: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
254: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
208: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
208: Running Multi Instance Training
208: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 77: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 77: Running Multi Instance Training
271: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 77: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 21: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 21: Running Multi Instance Training
404: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
404: Running Multi Instance Training
 21: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
404: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
476: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
157: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
433: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
433: Running Multi Instance Training
277: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
433: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
175: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
175: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 15: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
130: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
130: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
271: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
271: Running Multi Instance Training
271: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
254: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
254: Running Multi Instance Training
318: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 46: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 46: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
254: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
476: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
157: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
476: Running Multi Instance Training
157: Running Multi Instance Training
476: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
157: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
175: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
175: Running Multi Instance Training
175: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 15: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 15: Running Multi Instance Training
 15: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
130: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
127: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
130: Running Multi Instance Training
130: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
277: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
277: Running Multi Instance Training
277: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
105: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 46: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 46: Running Multi Instance Training
 46: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 55: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
149: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
149: Running Multi Instance Training
149: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 67: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
318: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
227: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
318: Running Multi Instance Training
127: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
318: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
127: Running Multi Instance Training
127: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
198: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
105: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
105: Running Multi Instance Training
105: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 55: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 55: Running Multi Instance Training
 55: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 93: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
198: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
198: Running Multi Instance Training
 99: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
426: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: Running Multi Instance Training
198: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
227: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
426: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
227: Running Multi Instance Training
 67: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 67: Running Multi Instance Training
227: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
195: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 67: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 16: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 93: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 93: Running Multi Instance Training
 93: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
195: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: Running Multi Instance Training
407: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
195: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
407: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 16: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 16: Running Multi Instance Training
 16: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 99: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 99: Running Multi Instance Training
 99: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
332: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
237: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 85: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
407: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
407: Running Multi Instance Training
407: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 41: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 41: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
237: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
237: Running Multi Instance Training
237: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
332: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
332: Running Multi Instance Training
332: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 85: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: Running Multi Instance Training
 41: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 85: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 41: Running Multi Instance Training
 41: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
293: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 65: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
252: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
211: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
211: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
293: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
293: Running Multi Instance Training
293: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 65: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 65: Running Multi Instance Training
 65: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
283: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
252: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
252: Running Multi Instance Training
146: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
252: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
211: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
211: Running Multi Instance Training
211: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
290: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
290: Running Multi Instance Training
 95: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
290: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
184: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
283: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
283: Running Multi Instance Training
283: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
339: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
146: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
146: Running Multi Instance Training
146: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
464: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
310: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
285: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
285: Running Multi Instance Training
279: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 95: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
285: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 95: Running Multi Instance Training
 95: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
184: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
184: Running Multi Instance Training
184: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
174: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
317: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
171: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
171: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 97: STARTING TIMING RUN AT 2021-10-05 07:58:15 AM
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
199: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
279: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 44: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
279: Running Multi Instance Training
279: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
339: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
339: Running Multi Instance Training
249: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
249: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
339: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
174: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
174: Running Multi Instance Training
317: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
317: Running Multi Instance Training
174: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
464: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
464: Running Multi Instance Training
317: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
310: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
310: Running Multi Instance Training
464: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 26: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
310: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 97: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 97: Running Multi Instance Training
164: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 97: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
199: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: Running Multi Instance Training
104: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 44: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
199: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 44: Running Multi Instance Training
  9: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
171: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 44: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
171: Running Multi Instance Training
369: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
369: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
360: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
171: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
225: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 26: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: Running Multi Instance Training
249: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 26: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
249: Running Multi Instance Training
425: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
478: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
249: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
104: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
104: Running Multi Instance Training
 39: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
104: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
164: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
164: Running Multi Instance Training
164: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
225: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
225: Running Multi Instance Training
225: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
425: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
478: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  9: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
425: Running Multi Instance Training
  9: Running Multi Instance Training
478: Running Multi Instance Training
360: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: Running Multi Instance Training
425: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
478: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  9: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
321: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
369: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
360: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
369: Running Multi Instance Training
 57: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
369: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 39: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 39: Running Multi Instance Training
 39: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
135: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 57: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 57: Running Multi Instance Training
 57: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
335: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
321: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
321: Running Multi Instance Training
321: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
465: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 84: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
125: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
125: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
308: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
308: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
154: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
154: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
135: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
135: Running Multi Instance Training
135: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
335: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
335: Running Multi Instance Training
335: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
454: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
454: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
168: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
465: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: Running Multi Instance Training
 84: Running Multi Instance Training
125: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
465: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
308: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 84: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
125: Running Multi Instance Training
308: Running Multi Instance Training
125: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
308: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
251: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
251: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
298: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
319: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
232: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
232: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
454: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
454: Running Multi Instance Training
454: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
418: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
168: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
154: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
168: Running Multi Instance Training
154: Running Multi Instance Training
168: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
154: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
251: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
251: Running Multi Instance Training
251: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
319: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
319: Running Multi Instance Training
319: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
145: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
145: Running Multi Instance Training
145: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
298: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: Running Multi Instance Training
232: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
298: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
232: Running Multi Instance Training
232: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 49: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
289: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 11: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
281: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
209: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
209: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
383: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: Running Multi Instance Training
418: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
383: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
418: Running Multi Instance Training
460: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
418: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
460: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
207: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
287: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
289: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 11: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
287: Running Multi Instance Training
289: Running Multi Instance Training
 11: Running Multi Instance Training
209: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
281: Running Multi Instance Training
209: Running Multi Instance Training
287: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 11: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
289: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
281: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
209: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  3: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
460: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
460: Running Multi Instance Training
460: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 98: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 49: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 49: Running Multi Instance Training
 49: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
100: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
218: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
178: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
207: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: Running Multi Instance Training
  3: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
207: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  3: Running Multi Instance Training
  3: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 98: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 98: Running Multi Instance Training
 98: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
100: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
100: Running Multi Instance Training
100: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
278: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
361: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 66: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 66: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
218: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
218: Running Multi Instance Training
437: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
178: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
178: Running Multi Instance Training
218: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
178: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
162: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
162: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
368: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
368: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
278: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
278: Running Multi Instance Training
511: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
278: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
361: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
361: Running Multi Instance Training
361: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 66: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 66: Running Multi Instance Training
212: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 66: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
382: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
382: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
166: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
437: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: Running Multi Instance Training
334: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
162: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
437: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
162: Running Multi Instance Training
403: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
162: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
368: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
368: Running Multi Instance Training
368: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
511: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
511: Running Multi Instance Training
 31: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
511: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 71: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 71: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
255: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: Running Multi Instance Training
382: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
255: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
382: Running Multi Instance Training
166: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
166: Running Multi Instance Training
382: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
417: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
243: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
166: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
334: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
403: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
334: Running Multi Instance Training
403: Running Multi Instance Training
334: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
403: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 48: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 48: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
212: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
212: Running Multi Instance Training
 31: Running Multi Instance Training
212: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 71: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 31: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 71: Running Multi Instance Training
288: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 71: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
220: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
273: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
273: Running Multi Instance Training
286: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
273: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
417: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
417: Running Multi Instance Training
417: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 48: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 48: Running Multi Instance Training
 48: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
243: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
288: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
243: Running Multi Instance Training
288: Running Multi Instance Training
243: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
288: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
286: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
286: Running Multi Instance Training
286: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
133: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
386: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
112: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
226: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
226: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
112: Running Multi Instance Training
112: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
220: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
220: Running Multi Instance Training
153: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
153: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
220: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
408: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 86: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
179: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
337: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
337: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
282: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
133: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
133: Running Multi Instance Training
386: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
226: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
386: Running Multi Instance Training
133: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: Running Multi Instance Training
386: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
226: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
153: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
296: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
296: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
153: Running Multi Instance Training
219: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
219: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
153: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 73: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
440: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
408: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
440: Running Multi Instance Training
408: Running Multi Instance Training
440: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
408: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 86: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 86: Running Multi Instance Training
179: Running Multi Instance Training
 86: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
337: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
282: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
179: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
337: Running Multi Instance Training
228: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
282: Running Multi Instance Training
337: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
282: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 89: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 89: Running Multi Instance Training
 89: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
296: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: Running Multi Instance Training
219: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
370: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
296: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
219: Running Multi Instance Training
213: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
213: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
219: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  4: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 33: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 73: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 73: Running Multi Instance Training
 73: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
235: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
370: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: Running Multi Instance Training
370: Running Multi Instance Training
228: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
228: Running Multi Instance Training
213: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
235: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
370: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
213: Running Multi Instance Training
228: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
213: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  4: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
328: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  4: Running Multi Instance Training
328: Running Multi Instance Training
  4: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
328: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 33: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 33: Running Multi Instance Training
 33: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
466: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
223: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
223: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
309: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
309: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
343: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
343: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
459: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
307: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
322: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
205: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
147: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 10: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
170: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
466: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: Running Multi Instance Training
223: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
466: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
223: Running Multi Instance Training
309: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
223: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
309: Running Multi Instance Training
309: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
250: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
250: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
459: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
459: Running Multi Instance Training
182: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
459: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
322: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
322: Running Multi Instance Training
205: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
205: Running Multi Instance Training
322: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 10: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
147: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
205: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 10: Running Multi Instance Training
147: Running Multi Instance Training
343: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
170: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 10: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
343: Running Multi Instance Training
147: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
170: Running Multi Instance Training
307: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
307: Running Multi Instance Training
343: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
170: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
307: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
152: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
396: Running Multi Instance Training
250: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
396: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
250: Running Multi Instance Training
336: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
250: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
182: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
182: Running Multi Instance Training
265: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
265: Running Multi Instance Training
182: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
265: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 61: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
324: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
152: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
203: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
152: Running Multi Instance Training
203: Running Multi Instance Training
152: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
203: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
336: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
336: Running Multi Instance Training
165: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
336: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
468: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 61: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 61: Running Multi Instance Training
363: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
363: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 61: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
412: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
412: Running Multi Instance Training
412: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
165: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
165: Running Multi Instance Training
165: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
468: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
468: Running Multi Instance Training
324: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
324: Running Multi Instance Training
177: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
468: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
324: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
363: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
363: Running Multi Instance Training
363: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
405: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
274: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
177: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
177: Running Multi Instance Training
 76: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
177: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
329: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
329: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
405: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
405: Running Multi Instance Training
405: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 83: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
274: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
274: Running Multi Instance Training
274: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
416: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 76: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
435: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 76: Running Multi Instance Training
435: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 76: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
134: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 22: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 22: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
329: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
329: Running Multi Instance Training
329: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 34: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 34: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
416: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: Running Multi Instance Training
143: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
416: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
380: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
380: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
118: Running Multi Instance Training
435: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
118: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
435: Running Multi Instance Training
435: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
505: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: Running Multi Instance Training
 13: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 13: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 74: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
134: Running Multi Instance Training
 74: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 83: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
505: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 22: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 83: Running Multi Instance Training
134: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 22: Running Multi Instance Training
 83: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 22: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
323: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: Running Multi Instance Training
 34: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
323: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 34: Running Multi Instance Training
110: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 34: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
143: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: Running Multi Instance Training
299: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
380: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
143: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
380: Running Multi Instance Training
380: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
450: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 13: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 74: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 13: Running Multi Instance Training
 74: Running Multi Instance Training
 74: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 13: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
128: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
233: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
233: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
110: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
110: Running Multi Instance Training
110: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
299: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
299: Running Multi Instance Training
216: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
216: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
299: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 51: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 51: Running Multi Instance Training
 51: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
491: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
364: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
364: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
128: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: Running Multi Instance Training
151: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
233: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
450: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
128: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
233: Running Multi Instance Training
450: Running Multi Instance Training
156: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
450: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
233: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
372: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
372: Running Multi Instance Training
372: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
216: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
216: Running Multi Instance Training
216: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
138: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
151: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
138: Running Multi Instance Training
151: Running Multi Instance Training
138: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
151: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
491: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
491: Running Multi Instance Training
156: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
156: Running Multi Instance Training
491: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
364: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
156: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
364: Running Multi Instance Training
399: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
364: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
294: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
294: Running Multi Instance Training
294: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
204: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
242: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
242: Running Multi Instance Training
242: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
399: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
399: Running Multi Instance Training
399: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
413: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
215: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
215: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
341: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
257: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
204: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
204: Running Multi Instance Training
204: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 52: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
229: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
221: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 17: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 17: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
413: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: Running Multi Instance Training
215: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
341: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
413: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
215: Running Multi Instance Training
269: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
341: Running Multi Instance Training
215: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
341: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 52: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 52: Running Multi Instance Training
 52: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
229: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
229: Running Multi Instance Training
229: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
221: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
221: Running Multi Instance Training
 17: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
257: Running Multi Instance Training
 17: Running Multi Instance Training
221: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
257: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 17: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
393: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
269: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
269: Running Multi Instance Training
269: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
330: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 40: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 40: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
304: Running Multi Instance Training
312: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
304: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
422: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
194: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
330: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: Running Multi Instance Training
393: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
330: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
393: Running Multi Instance Training
482: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
482: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 40: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
393: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 40: Running Multi Instance Training
272: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
123: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 40: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
194: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
272: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
312: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
194: Running Multi Instance Training
447: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
312: Running Multi Instance Training
272: Running Multi Instance Training
194: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
244: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
312: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
272: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
241: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
422: Running Multi Instance Training
378: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
482: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
422: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
482: Running Multi Instance Training
482: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
123: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
123: Running Multi Instance Training
123: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
241: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
241: Running Multi Instance Training
241: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
326: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
414: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
244: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
244: Running Multi Instance Training
447: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
447: Running Multi Instance Training
244: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
447: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 75: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
378: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
378: Running Multi Instance Training
185: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
451: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
378: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
172: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
106: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
326: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
326: Running Multi Instance Training
414: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
414: Running Multi Instance Training
326: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
414: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 45: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 45: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 75: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 75: Running Multi Instance Training
 75: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
185: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
451: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
185: Running Multi Instance Training
451: Running Multi Instance Training
185: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
451: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
172: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
172: Running Multi Instance Training
172: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
139: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
106: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
106: Running Multi Instance Training
106: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
356: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: Running Multi Instance Training
 45: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
356: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
230: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 45: Running Multi Instance Training
230: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 45: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
139: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
421: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
139: Running Multi Instance Training
421: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
139: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 94: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
230: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
230: Running Multi Instance Training
230: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 32: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 32: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
352: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
352: Running Multi Instance Training
392: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
421: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
392: Running Multi Instance Training
352: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
421: Running Multi Instance Training
392: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
421: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
126: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 94: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 94: Running Multi Instance Training
446: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 94: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
480: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
480: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
397: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 32: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 32: Running Multi Instance Training
 32: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
126: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
126: Running Multi Instance Training
126: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
340: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
446: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: Running Multi Instance Training
480: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
397: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
446: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
480: Running Multi Instance Training
397: Running Multi Instance Training
480: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
397: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 80: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
340: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
340: Running Multi Instance Training
379: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
340: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
302: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
302: Running Multi Instance Training
302: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 80: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 80: Running Multi Instance Training
358: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
358: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 80: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
448: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
188: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
379: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
379: Running Multi Instance Training
306: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
379: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
224: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: Running Multi Instance Training
424: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
358: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
345: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 87: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
373: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 87: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
448: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
448: Running Multi Instance Training
448: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
477: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
313: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
306: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
306: Running Multi Instance Training
137: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
224: Running Multi Instance Training
306: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
224: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
238: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
238: Running Multi Instance Training
238: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
327: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: Running Multi Instance Training
256: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
188: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
327: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
188: Running Multi Instance Training
 87: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
424: Running Multi Instance Training
373: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 87: Running Multi Instance Training
263: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
366: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
188: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
373: Running Multi Instance Training
424: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
366: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
316: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 87: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
373: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
489: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
489: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
348: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
477: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
313: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
345: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
477: Running Multi Instance Training
313: Running Multi Instance Training
345: Running Multi Instance Training
137: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
477: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
137: Running Multi Instance Training
313: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
345: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
137: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
210: Running Multi Instance Training
210: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
256: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
256: Running Multi Instance Training
256: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
316: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
366: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
316: Running Multi Instance Training
366: Running Multi Instance Training
489: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
316: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
366: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
489: Running Multi Instance Training
276: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
246: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
489: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
355: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
355: Running Multi Instance Training
355: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
263: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
263: Running Multi Instance Training
263: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
348: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
348: Running Multi Instance Training
348: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
246: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
276: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
246: Running Multi Instance Training
276: Running Multi Instance Training
246: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
276: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
472: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
487: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
487: Running Multi Instance Training
487: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 81: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
333: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
333: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
122: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
253: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 64: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
472: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
472: Running Multi Instance Training
 81: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: Running Multi Instance Training
472: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 81: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
333: Running Multi Instance Training
291: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
122: Running Multi Instance Training
291: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
333: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
122: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
253: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
253: Running Multi Instance Training
 64: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 64: Running Multi Instance Training
253: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 64: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
144: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
374: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
374: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
431: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
431: Running Multi Instance Training
431: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
428: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
344: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
428: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
291: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
291: Running Multi Instance Training
291: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
196: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
196: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
144: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: Running Multi Instance Training
374: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
144: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
374: Running Multi Instance Training
374: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
367: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
367: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
344: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
344: Running Multi Instance Training
488: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
344: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
196: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
196: Running Multi Instance Training
190: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
190: Running Multi Instance Training
196: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
481: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
190: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
486: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
350: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
350: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
395: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
488: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: Running Multi Instance Training
367: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
488: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
367: Running Multi Instance Training
367: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
481: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
481: Running Multi Instance Training
486: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
486: Running Multi Instance Training
481: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
486: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
350: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
350: Running Multi Instance Training
350: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
395: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
395: Running Multi Instance Training
395: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
301: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
467: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 96: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
420: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
420: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
501: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
284: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
377: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
467: Running Multi Instance Training
301: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
467: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 96: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
301: Running Multi Instance Training
420: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 96: Running Multi Instance Training
420: Running Multi Instance Training
301: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 96: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
420: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
445: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
315: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
315: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
284: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
284: Running Multi Instance Training
501: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
501: Running Multi Instance Training
284: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
501: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
346: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
259: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
377: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
377: Running Multi Instance Training
377: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
371: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
445: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: Running Multi Instance Training
315: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
445: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
315: Running Multi Instance Training
315: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
311: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
346: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
353: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
346: Running Multi Instance Training
353: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
259: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
259: Running Multi Instance Training
346: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
259: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
234: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
371: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
371: Running Multi Instance Training
371: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
245: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
245: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
311: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: Running Multi Instance Training
353: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
311: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
353: Running Multi Instance Training
  8: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
353: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
234: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
234: Running Multi Instance Training
362: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
234: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
169: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
245: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
245: Running Multi Instance Training
357: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
357: Running Multi Instance Training
245: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
280: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
357: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
  8: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
  8: Running Multi Instance Training
  8: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
169: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
169: Running Multi Instance Training
362: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
362: Running Multi Instance Training
169: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
362: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
280: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
280: Running Multi Instance Training
280: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
167: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
320: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
120: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
120: Running Multi Instance Training
120: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
167: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
167: Running Multi Instance Training
167: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
381: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
320: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
320: Running Multi Instance Training
206: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
320: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
248: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
388: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
388: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
381: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
381: Running Multi Instance Training
381: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
206: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
206: Running Multi Instance Training
206: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
248: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
248: Running Multi Instance Training
261: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
248: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
189: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
297: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
155: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
155: Running Multi Instance Training
428: Running Multi Instance Training
428: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
388: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
429: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
429: Running Multi Instance Training
388: Running Multi Instance Training
429: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
155: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
338: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
388: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
473: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
351: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
261: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
261: Running Multi Instance Training
297: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
189: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
297: Running Multi Instance Training
189: Running Multi Instance Training
261: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
297: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
189: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
338: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: Running Multi Instance Training
473: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
338: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
473: Running Multi Instance Training
351: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
351: Running Multi Instance Training
473: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
351: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
500: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
419: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
500: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
500: Running Multi Instance Training
500: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
419: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
419: Running Multi Instance Training
419: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
132: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
303: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
484: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
132: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
132: Running Multi Instance Training
303: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
303: Running Multi Instance Training
132: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
303: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
222: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
484: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
484: Running Multi Instance Training
484: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
262: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 50: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 50: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
275: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
222: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
222: Running Multi Instance Training
495: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
222: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
217: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
262: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
262: Running Multi Instance Training
262: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
275: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: Running Multi Instance Training
 50: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
275: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 50: Running Multi Instance Training
 50: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
217: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
217: Running Multi Instance Training
217: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
495: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
495: Running Multi Instance Training
495: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
475: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
176: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
502: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
389: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
214: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
475: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
475: Running Multi Instance Training
475: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
176: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
176: Running Multi Instance Training
176: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
502: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
502: Running Multi Instance Training
389: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
389: Running Multi Instance Training
502: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
389: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
214: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
214: Running Multi Instance Training
214: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
240: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
240: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
240: Running Multi Instance Training
240: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
325: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
325: Running Multi Instance Training
231: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
325: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
231: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
231: Running Multi Instance Training
231: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
492: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
492: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 35: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 72: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
492: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
492: Running Multi Instance Training
492: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 35: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 35: Running Multi Instance Training
 35: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
331: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 72: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 72: Running Multi Instance Training
 72: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
331: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
331: Running Multi Instance Training
331: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
498: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
498: Running Multi Instance Training
498: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
415: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
398: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
483: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
415: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
415: Running Multi Instance Training
415: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
398: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
398: Running Multi Instance Training
398: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
483: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
483: Running Multi Instance Training
483: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
490: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
490: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
490: Running Multi Instance Training
490: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
391: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
391: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
391: Running Multi Instance Training
391: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
376: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
376: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
376: Running Multi Instance Training
376: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
499: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
499: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
499: Running Multi Instance Training
499: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
305: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 82: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
493: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
305: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
305: Running Multi Instance Training
375: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
305: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
 82: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
 82: Running Multi Instance Training
 82: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
493: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
493: Running Multi Instance Training
493: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
375: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
375: Running Multi Instance Training
375: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
342: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
342: Running Multi Instance Training
342: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
394: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
394: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
394: Running Multi Instance Training
394: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
449: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
449: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
449: Running Multi Instance Training
449: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
347: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
423: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
347: Running Multi Instance Training
354: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
347: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
423: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
423: Running Multi Instance Training
423: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
354: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
354: Running Multi Instance Training
354: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
247: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
247: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
247: Running Multi Instance Training
247: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
496: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
444: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
136: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
496: Running Multi Instance Training
444: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: Running Multi Instance Training
349: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
496: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
365: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
444: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
365: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
136: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
136: Running Multi Instance Training
136: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
349: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
365: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
349: Running Multi Instance Training
365: Running Multi Instance Training
349: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
365: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
258: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
430: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
121: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
359: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
258: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
258: Running Multi Instance Training
430: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
430: Running Multi Instance Training
258: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
430: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
121: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: Running Multi Instance Training
191: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
121: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
191: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
314: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
359: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
359: Running Multi Instance Training
359: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
191: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
191: Running Multi Instance Training
191: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
314: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
314: Running Multi Instance Training
314: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
485: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
485: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
485: Running Multi Instance Training
485: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
300: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
300: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
300: Running Multi Instance Training
300: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
260: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
260: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
260: Running Multi Instance Training
260: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
474: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
474: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
474: Running Multi Instance Training
474: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
503: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
503: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
503: Running Multi Instance Training
503: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
390: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
390: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
390: Running Multi Instance Training
390: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
494: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
494: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
494: Running Multi Instance Training
494: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
497: STARTING TIMING RUN AT 2021-10-05 07:58:16 AM
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: CUDA_VISIBLE_DEVICES (start): 0,1,2,3
497: /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/run_scripts
497: Running Multi Instance Training
497: running   python ./train_instance.py --wireup_method nccl-slurm-pmi --run_tag deepcam_ngpu512_1482999 --data_dir_prefix /hkfs/work/workspace/scratch/qv2382-mlperf_data/hdf5s/ --output_dir /hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/results/deepcam//deepcam_ngpu512_1482999 --model_prefix segmentation --optimizer LAMB --start_lr 0.004 --lr_schedule type=multistep,milestones=1100 4096,decay_rate=0.1 --lr_warmup_steps 200 --lr_warmup_factor 1. --weight_decay 0.01 --logging_frequency 10 --save_frequency 100000 --max_epochs 200 --max_inter_threads 4 --seed 0 --batchnorm_group_size 1 --shuffle_mode global --data_format dali-es/hdf5 --data_oversampling_factor 1 --precision_mode amp --enable_nhwc --local_batch_size 2 --local_batch_size_validation 8 --enable_jit --enable_graph --training_instance_size 512 --stage_dir_prefix /tmp/deepcam --stage_num_workers 1 --stage_batch_size -1 --stage_mode node --data_staging_method instance
 85: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
180: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
140: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
172: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
287: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
356: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
328: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
393: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 32: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
416: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  0: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
408: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
432: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 12: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 36: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
384: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
108: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 96: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 24: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
157: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
182: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 90: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
148: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 28: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
100: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 40: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  5: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
184: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 16: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
402: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
424: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
440: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 44: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 20: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
128: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
404: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 92: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 68: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
176: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
152: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
264: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
288: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
144: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
144: creating process group
132: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
120: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
277: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
169: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
337: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
361: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
325: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
160: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
268: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 64: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
124: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
136: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
292: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
280: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
256: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
365: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
189: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  8: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
333: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
368: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
296: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
320: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
381: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
261: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
164: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 72: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
372: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
348: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
312: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
301: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
376: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
352: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
388: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
341: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
273: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
344: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
396: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
413: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
420: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
429: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  1: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
409: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 13: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 37: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 37: creating process group
 60: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
385: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
108: creating process group
 25: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 25: creating process group
158: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 86: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
180: creating process group
192: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
462: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 52: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 91: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 76: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
149: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 30: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
101: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 41: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  7: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
185: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
185: creating process group
 17: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
403: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
442: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 21: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
129: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
405: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 93: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 56: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
141: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
153: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
200: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
265: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
204: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
133: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
133: creating process group
121: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
170: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
338: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
338: creating process group
216: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 48: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
362: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
161: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
112: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
208: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 65: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
196: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
174: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
125: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
221: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
137: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
316: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
287: creating process group
105: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
236: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
190: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
369: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
309: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
382: creating process group
262: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
165: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
165: creating process group
357: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 73: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
229: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
349: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
349: creating process group
302: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
232: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
304: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
329: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
353: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
389: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
342: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
224: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
394: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 81: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 33: creating process group
212: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
398: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
444: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
421: creating process group
430: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  2: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
410: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
433: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
468: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
456: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 14: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 38: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 38: creating process group
 61: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
386: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
109: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 97: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 97: creating process group
 26: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 26: creating process group
159: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 84: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
182: creating process group
193: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
508: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 90: creating process group
437: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 77: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
150: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 31: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
102: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 43: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  5: creating process group
186: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
186: creating process group
 18: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
402: creating process group
425: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
443: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
452: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 45: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 22: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
130: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
406: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 94: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 69: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
142: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
177: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
177: creating process group
477: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
155: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
202: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
266: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
480: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
289: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
145: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
134: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
122: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
278: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
171: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
337: creating process group
217: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 49: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 49: creating process group
361: creating process group
326: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
162: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
162: creating process group
269: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 66: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
197: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
175: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
126: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
126: creating process group
138: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
138: creating process group
293: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
281: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
259: creating process group
366: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
284: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
106: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
191: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
334: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
370: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
370: creating process group
297: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
321: creating process group
383: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
383: creating process group
263: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
166: creating process group
359: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 74: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
373: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
350: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
350: creating process group
315: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
303: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
303: creating process group
377: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
306: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
330: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
390: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
343: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
450: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
274: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
274: creating process group
393: creating process group
 82: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
345: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 34: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
464: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
418: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
399: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
484: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
422: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
422: creating process group
492: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
488: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
431: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  3: creating process group
411: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
434: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
469: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
458: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
505: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 15: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 39: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 39: creating process group
 62: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
387: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
110: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 98: creating process group
 27: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
157: creating process group
 86: creating process group
181: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
194: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
194: creating process group
463: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
508: creating process group
 53: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 53: creating process group
 91: creating process group
438: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 78: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
151: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
151: creating process group
 28: creating process group
103: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
103: creating process group
 40: creating process group
  7: creating process group
187: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
187: creating process group
 19: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 19: creating process group
403: creating process group
426: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
426: creating process group
441: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
453: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 46: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 23: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 23: creating process group
131: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
131: creating process group
407: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 95: creating process group
 57: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 57: creating process group
 70: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
143: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
178: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
178: creating process group
116: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
478: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
152: creating process group
203: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
267: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
481: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
205: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
290: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
146: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
146: creating process group
135: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
123: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
123: creating process group
253: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
279: creating process group
169: creating process group
339: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
218: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
218: creating process group
 50: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 50: creating process group
362: creating process group
327: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
163: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
163: creating process group
113: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
209: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
270: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 67: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
198: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
198: creating process group
172: creating process group
127: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
127: creating process group
222: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
139: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
139: creating process group
317: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
317: creating process group
294: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
282: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
256: creating process group
367: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
285: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
107: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
107: creating process group
248: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
237: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
189: creating process group
 10: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
335: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
371: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
371: creating process group
309: creating process group
298: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
322: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
322: creating process group
381: creating process group
261: creating process group
167: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
167: creating process group
357: creating process group
 75: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 75: creating process group
231: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
240: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
374: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
351: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
351: creating process group
312: creating process group
301: creating process group
233: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
378: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
378: creating process group
307: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
244: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
328: creating process group
355: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
355: creating process group
391: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
341: creating process group
450: creating process group
225: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
275: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
394: creating process group
 83: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 83: creating process group
346: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
346: creating process group
 35: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 35: creating process group
213: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
465: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
465: creating process group
416: creating process group
396: creating process group
445: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
415: creating process group
423: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
493: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
490: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
472: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
496: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
501: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
429: creating process group
  0: creating process group
408: creating process group
435: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
470: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
456: creating process group
506: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 12: creating process group
 36: creating process group
 63: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
384: creating process group
111: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 99: creating process group
 24: creating process group
158: creating process group
 84: creating process group
183: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
195: creating process group
462: creating process group
509: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 54: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 88: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
439: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 79: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
148: creating process group
 30: creating process group
100: creating process group
 42: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  4: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
184: creating process group
 16: creating process group
400: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
427: creating process group
443: creating process group
454: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 47: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 20: creating process group
128: creating process group
404: creating process group
 92: creating process group
 58: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 58: creating process group
 71: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
140: creating process group
179: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
179: creating process group
117: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
477: creating process group
153: creating process group
200: creating process group
264: creating process group
482: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
206: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
291: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
147: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
132: creating process group
120: creating process group
254: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
277: creating process group
170: creating process group
336: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
219: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
219: creating process group
 51: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 51: creating process group
363: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
325: creating process group
160: creating process group
114: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
210: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
210: creating process group
268: creating process group
 64: creating process group
199: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
199: creating process group
175: creating process group
124: creating process group
223: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
136: creating process group
319: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
319: creating process group
295: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
295: creating process group
283: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
258: creating process group
365: creating process group
286: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
104: creating process group
249: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
238: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
190: creating process group
 11: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 11: creating process group
333: creating process group
368: creating process group
311: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
299: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
299: creating process group
323: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
323: creating process group
380: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
262: creating process group
164: creating process group
359: creating process group
 72: creating process group
229: creating process group
241: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
375: creating process group
348: creating process group
315: creating process group
302: creating process group
234: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
379: creating process group
306: creating process group
245: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
329: creating process group
352: creating process group
388: creating process group
342: creating process group
449: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
226: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
273: creating process group
392: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 80: creating process group
347: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
347: creating process group
 32: creating process group
214: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
466: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
417: creating process group
398: creating process group
447: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
485: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
413: creating process group
420: creating process group
494: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
494: creating process group
491: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
473: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
497: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
502: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
502: creating process group
430: creating process group
  1: creating process group
409: creating process group
432: creating process group
471: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
458: creating process group
507: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
507: creating process group
 13: creating process group
 60: creating process group
385: creating process group
109: creating process group
 96: creating process group
 27: creating process group
159: creating process group
 85: creating process group
181: creating process group
192: creating process group
463: creating process group
510: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 55: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 89: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
436: creating process group
 76: creating process group
149: creating process group
 31: creating process group
101: creating process group
 43: creating process group
  6: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 17: creating process group
401: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
424: creating process group
440: creating process group
455: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 44: creating process group
 21: creating process group
129: creating process group
405: creating process group
 93: creating process group
 59: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 59: creating process group
 68: creating process group
141: creating process group
176: creating process group
118: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
478: creating process group
155: creating process group
202: creating process group
265: creating process group
483: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
483: creating process group
207: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
288: creating process group
145: creating process group
134: creating process group
121: creating process group
255: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
255: creating process group
278: creating process group
171: creating process group
336: creating process group
216: creating process group
 48: creating process group
360: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
326: creating process group
161: creating process group
115: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
115: creating process group
211: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
211: creating process group
269: creating process group
 65: creating process group
196: creating process group
174: creating process group
125: creating process group
221: creating process group
137: creating process group
316: creating process group
292: creating process group
280: creating process group
257: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
366: creating process group
284: creating process group
105: creating process group
250: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
239: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
191: creating process group
  8: creating process group
334: creating process group
369: creating process group
308: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
296: creating process group
320: creating process group
380: creating process group
263: creating process group
356: creating process group
 73: creating process group
231: creating process group
242: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
372: creating process group
313: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
235: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
235: creating process group
376: creating process group
304: creating process group
246: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
246: creating process group
330: creating process group
353: creating process group
389: creating process group
343: creating process group
451: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
227: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
227: creating process group
275: creating process group
395: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 81: creating process group
344: creating process group
 34: creating process group
215: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
467: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
467: creating process group
418: creating process group
399: creating process group
444: creating process group
486: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
414: creating process group
423: creating process group
495: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
495: creating process group
488: creating process group
474: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
498: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
503: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
503: creating process group
431: creating process group
  2: creating process group
410: creating process group
433: creating process group
468: creating process group
457: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
505: creating process group
 14: creating process group
 61: creating process group
386: creating process group
110: creating process group
156: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 87: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
183: creating process group
193: creating process group
460: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
511: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 52: creating process group
 89: creating process group
437: creating process group
 77: creating process group
150: creating process group
 29: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
102: creating process group
 41: creating process group
  4: creating process group
 18: creating process group
400: creating process group
425: creating process group
442: creating process group
452: creating process group
 45: creating process group
 22: creating process group
130: creating process group
406: creating process group
 94: creating process group
 56: creating process group
 69: creating process group
142: creating process group
119: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
479: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
154: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
203: creating process group
266: creating process group
480: creating process group
205: creating process group
289: creating process group
147: creating process group
135: creating process group
122: creating process group
253: creating process group
276: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
168: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
339: creating process group
217: creating process group
363: creating process group
327: creating process group
112: creating process group
208: creating process group
270: creating process group
 66: creating process group
197: creating process group
173: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
222: creating process group
318: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
293: creating process group
281: creating process group
257: creating process group
367: creating process group
285: creating process group
106: creating process group
251: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
251: creating process group
236: creating process group
188: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
  9: creating process group
335: creating process group
310: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
297: creating process group
260: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
358: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 74: creating process group
228: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
243: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
243: creating process group
373: creating process group
314: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
300: creating process group
232: creating process group
377: creating process group
307: creating process group
247: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
331: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
354: creating process group
390: creating process group
340: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
448: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
224: creating process group
272: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
392: creating process group
 82: creating process group
345: creating process group
212: creating process group
464: creating process group
419: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
397: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
445: creating process group
487: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
487: creating process group
412: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
492: creating process group
490: creating process group
475: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
499: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
501: creating process group
428: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
411: creating process group
434: creating process group
469: creating process group
459: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
506: creating process group
 15: creating process group
 62: creating process group
387: creating process group
111: creating process group
156: creating process group
 87: creating process group
460: creating process group
509: creating process group
 54: creating process group
 88: creating process group
438: creating process group
 78: creating process group
 29: creating process group
 42: creating process group
  6: creating process group
401: creating process group
441: creating process group
453: creating process group
 46: creating process group
407: creating process group
 70: creating process group
143: creating process group
117: creating process group
476: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
154: creating process group
201: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
267: creating process group
481: creating process group
206: creating process group
290: creating process group
254: creating process group
276: creating process group
168: creating process group
360: creating process group
324: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
113: creating process group
209: creating process group
271: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 67: creating process group
173: creating process group
223: creating process group
318: creating process group
294: creating process group
282: creating process group
364: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
286: creating process group
248: creating process group
237: creating process group
188: creating process group
 10: creating process group
332: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
311: creating process group
298: creating process group
260: creating process group
358: creating process group
230: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
240: creating process group
374: creating process group
313: creating process group
233: creating process group
305: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
245: creating process group
331: creating process group
391: creating process group
340: creating process group
449: creating process group
225: creating process group
272: creating process group
395: creating process group
213: creating process group
466: creating process group
419: creating process group
397: creating process group
446: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
484: creating process group
412: creating process group
493: creating process group
491: creating process group
472: creating process group
496: creating process group
500: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
428: creating process group
435: creating process group
470: creating process group
457: creating process group
504: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
 63: creating process group
461: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
510: creating process group
 55: creating process group
439: creating process group
 79: creating process group
454: creating process group
 47: creating process group
 71: creating process group
116: creating process group
479: creating process group
201: creating process group
482: creating process group
204: creating process group
291: creating process group
252: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
324: creating process group
114: creating process group
271: creating process group
220: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
283: creating process group
364: creating process group
249: creating process group
238: creating process group
332: creating process group
308: creating process group
228: creating process group
241: creating process group
314: creating process group
234: creating process group
305: creating process group
244: creating process group
451: creating process group
226: creating process group
214: creating process group
447: creating process group
485: creating process group
489: MASTER_ADDR is set to  hkn0403.localdomain instance: 0
473: creating process group
497: creating process group
500: creating process group
471: creating process group
459: creating process group
504: creating process group
461: creating process group
511: creating process group
455: creating process group
118: creating process group
476: creating process group
207: creating process group
252: creating process group
220: creating process group
250: creating process group
239: creating process group
310: creating process group
230: creating process group
242: creating process group
247: creating process group
448: creating process group
215: creating process group
446: creating process group
486: creating process group
489: creating process group
474: creating process group
498: creating process group
119: creating process group
475: creating process group
499: creating process group
  0: Process group successfully created for rank 0 . Now a global mpi barrier...
127: Process group successfully created for rank 127 . Now a global mpi barrier...
132: Process group successfully created for rank 132 . Now a global mpi barrier...
113: Process group successfully created for rank 113 . Now a global mpi barrier...
136: Process group successfully created for rank 136 . Now a global mpi barrier...
133: Process group successfully created for rank 133 . Now a global mpi barrier...
148: Process group successfully created for rank 148 . Now a global mpi barrier...
144: Process group successfully created for rank 144 . Now a global mpi barrier...
137: Process group successfully created for rank 137 . Now a global mpi barrier...
156: Process group successfully created for rank 156 . Now a global mpi barrier...
149: Process group successfully created for rank 149 . Now a global mpi barrier...
140: Process group successfully created for rank 140 . Now a global mpi barrier...
152: Process group successfully created for rank 152 . Now a global mpi barrier...
147: Process group successfully created for rank 147 . Now a global mpi barrier...
160: Process group successfully created for rank 160 . Now a global mpi barrier...
159: Process group successfully created for rank 159 . Now a global mpi barrier...
 91: Process group successfully created for rank 91 . Now a global mpi barrier...
150: Process group successfully created for rank 150 . Now a global mpi barrier...
153: Process group successfully created for rank 153 . Now a global mpi barrier...
145: Process group successfully created for rank 145 . Now a global mpi barrier...
170: Process group successfully created for rank 170 . Now a global mpi barrier...
161: Process group successfully created for rank 161 . Now a global mpi barrier...
164: Process group successfully created for rank 164 . Now a global mpi barrier...
141: Process group successfully created for rank 141 . Now a global mpi barrier...
154: Process group successfully created for rank 154 . Now a global mpi barrier...
162: Process group successfully created for rank 162 . Now a global mpi barrier...
166: Process group successfully created for rank 166 . Now a global mpi barrier...
228: Process group successfully created for rank 228 . Now a global mpi barrier...
226: Process group successfully created for rank 226 . Now a global mpi barrier...
142: Process group successfully created for rank 142 . Now a global mpi barrier...
155: Process group successfully created for rank 155 . Now a global mpi barrier...
218: Process group successfully created for rank 218 . Now a global mpi barrier...
163: Process group successfully created for rank 163 . Now a global mpi barrier...
236: Process group successfully created for rank 236 . Now a global mpi barrier...
167: Process group successfully created for rank 167 . Now a global mpi barrier...
229: Process group successfully created for rank 229 . Now a global mpi barrier...
240: Process group successfully created for rank 240 . Now a global mpi barrier...
232: Process group successfully created for rank 232 . Now a global mpi barrier...
246: Process group successfully created for rank 246 . Now a global mpi barrier...
143: Process group successfully created for rank 143 . Now a global mpi barrier...
252: Process group successfully created for rank 252 . Now a global mpi barrier...
248: Process group successfully created for rank 248 . Now a global mpi barrier...
237: Process group successfully created for rank 237 . Now a global mpi barrier...
231: Process group successfully created for rank 231 . Now a global mpi barrier...
242: Process group successfully created for rank 242 . Now a global mpi barrier...
225: Process group successfully created for rank 225 . Now a global mpi barrier...
238: Process group successfully created for rank 238 . Now a global mpi barrier...
230: Process group successfully created for rank 230 . Now a global mpi barrier...
241: Process group successfully created for rank 241 . Now a global mpi barrier...
247: Process group successfully created for rank 247 . Now a global mpi barrier...
239: Process group successfully created for rank 239 . Now a global mpi barrier...
243: Process group successfully created for rank 243 . Now a global mpi barrier...
244: Process group successfully created for rank 244 . Now a global mpi barrier...
264: Process group successfully created for rank 264 . Now a global mpi barrier...
255: Process group successfully created for rank 255 . Now a global mpi barrier...
268: Process group successfully created for rank 268 . Now a global mpi barrier...
256: Process group successfully created for rank 256 . Now a global mpi barrier...
233: Process group successfully created for rank 233 . Now a global mpi barrier...
245: Process group successfully created for rank 245 . Now a global mpi barrier...
270: Process group successfully created for rank 270 . Now a global mpi barrier...
257: Process group successfully created for rank 257 . Now a global mpi barrier...
261: Process group successfully created for rank 261 . Now a global mpi barrier...
234: Process group successfully created for rank 234 . Now a global mpi barrier...
265: Process group successfully created for rank 265 . Now a global mpi barrier...
254: Process group successfully created for rank 254 . Now a global mpi barrier...
276: Process group successfully created for rank 276 . Now a global mpi barrier...
269: Process group successfully created for rank 269 . Now a global mpi barrier...
280: Process group successfully created for rank 280 . Now a global mpi barrier...
258: Process group successfully created for rank 258 . Now a global mpi barrier...
262: Process group successfully created for rank 262 . Now a global mpi barrier...
235: Process group successfully created for rank 235 . Now a global mpi barrier...
266: Process group successfully created for rank 266 . Now a global mpi barrier...
288: Process group successfully created for rank 288 . Now a global mpi barrier...
253: Process group successfully created for rank 253 . Now a global mpi barrier...
259: Process group successfully created for rank 259 . Now a global mpi barrier...
284: Process group successfully created for rank 284 . Now a global mpi barrier...
260: Process group successfully created for rank 260 . Now a global mpi barrier...
272: Process group successfully created for rank 272 . Now a global mpi barrier...
267: Process group successfully created for rank 267 . Now a global mpi barrier...
289: Process group successfully created for rank 289 . Now a global mpi barrier...
278: Process group successfully created for rank 278 . Now a global mpi barrier...
281: Process group successfully created for rank 281 . Now a global mpi barrier...
285: Process group successfully created for rank 285 . Now a global mpi barrier...
263: Process group successfully created for rank 263 . Now a global mpi barrier...
301: Process group successfully created for rank 301 . Now a global mpi barrier...
275: Process group successfully created for rank 275 . Now a global mpi barrier...
291: Process group successfully created for rank 291 . Now a global mpi barrier...
279: Process group successfully created for rank 279 . Now a global mpi barrier...
292: Process group successfully created for rank 292 . Now a global mpi barrier...
283: Process group successfully created for rank 283 . Now a global mpi barrier...
286: Process group successfully created for rank 286 . Now a global mpi barrier...
298: Process group successfully created for rank 298 . Now a global mpi barrier...
302: Process group successfully created for rank 302 . Now a global mpi barrier...
304: Process group successfully created for rank 304 . Now a global mpi barrier...
273: Process group successfully created for rank 273 . Now a global mpi barrier...
290: Process group successfully created for rank 290 . Now a global mpi barrier...
277: Process group successfully created for rank 277 . Now a global mpi barrier...
316: Process group successfully created for rank 316 . Now a global mpi barrier...
293: Process group successfully created for rank 293 . Now a global mpi barrier...
282: Process group successfully created for rank 282 . Now a global mpi barrier...
287: Process group successfully created for rank 287 . Now a global mpi barrier...
296: Process group successfully created for rank 296 . Now a global mpi barrier...
312: Process group successfully created for rank 312 . Now a global mpi barrier...
303: Process group successfully created for rank 303 . Now a global mpi barrier...
305: Process group successfully created for rank 305 . Now a global mpi barrier...
274: Process group successfully created for rank 274 . Now a global mpi barrier...
317: Process group successfully created for rank 317 . Now a global mpi barrier...
294: Process group successfully created for rank 294 . Now a global mpi barrier...
297: Process group successfully created for rank 297 . Now a global mpi barrier...
313: Process group successfully created for rank 313 . Now a global mpi barrier...
300: Process group successfully created for rank 300 . Now a global mpi barrier...
306: Process group successfully created for rank 306 . Now a global mpi barrier...
328: Process group successfully created for rank 328 . Now a global mpi barrier...
324: Process group successfully created for rank 324 . Now a global mpi barrier...
318: Process group successfully created for rank 318 . Now a global mpi barrier...
295: Process group successfully created for rank 295 . Now a global mpi barrier...
332: Process group successfully created for rank 332 . Now a global mpi barrier...
308: Process group successfully created for rank 308 . Now a global mpi barrier...
299: Process group successfully created for rank 299 . Now a global mpi barrier...
314: Process group successfully created for rank 314 . Now a global mpi barrier...
307: Process group successfully created for rank 307 . Now a global mpi barrier...
336: Process group successfully created for rank 336 . Now a global mpi barrier...
325: Process group successfully created for rank 325 . Now a global mpi barrier...
319: Process group successfully created for rank 319 . Now a global mpi barrier...
334: Process group successfully created for rank 334 . Now a global mpi barrier...
309: Process group successfully created for rank 309 . Now a global mpi barrier...
315: Process group successfully created for rank 315 . Now a global mpi barrier...
330: Process group successfully created for rank 330 . Now a global mpi barrier...
340: Process group successfully created for rank 340 . Now a global mpi barrier...
337: Process group successfully created for rank 337 . Now a global mpi barrier...
326: Process group successfully created for rank 326 . Now a global mpi barrier...
249: Process group successfully created for rank 249 . Now a global mpi barrier...
335: Process group successfully created for rank 335 . Now a global mpi barrier...
320: Process group successfully created for rank 320 . Now a global mpi barrier...
329: Process group successfully created for rank 329 . Now a global mpi barrier...
341: Process group successfully created for rank 341 . Now a global mpi barrier...
338: Process group successfully created for rank 338 . Now a global mpi barrier...
327: Process group successfully created for rank 327 . Now a global mpi barrier...
251: Process group successfully created for rank 251 . Now a global mpi barrier...
333: Process group successfully created for rank 333 . Now a global mpi barrier...
321: Process group successfully created for rank 321 . Now a global mpi barrier...
350: Process group successfully created for rank 350 . Now a global mpi barrier...
331: Process group successfully created for rank 331 . Now a global mpi barrier...
343: Process group successfully created for rank 343 . Now a global mpi barrier...
339: Process group successfully created for rank 339 . Now a global mpi barrier...
362: Process group successfully created for rank 362 . Now a global mpi barrier...
250: Process group successfully created for rank 250 . Now a global mpi barrier...
322: Process group successfully created for rank 322 . Now a global mpi barrier...
356: Process group successfully created for rank 356 . Now a global mpi barrier...
352: Process group successfully created for rank 352 . Now a global mpi barrier...
342: Process group successfully created for rank 342 . Now a global mpi barrier...
364: Process group successfully created for rank 364 . Now a global mpi barrier...
359: Process group successfully created for rank 359 . Now a global mpi barrier...
351: Process group successfully created for rank 351 . Now a global mpi barrier...
353: Process group successfully created for rank 353 . Now a global mpi barrier...
363: Process group successfully created for rank 363 . Now a global mpi barrier...
349: Process group successfully created for rank 349 . Now a global mpi barrier...
355: Process group successfully created for rank 355 . Now a global mpi barrier...
361: Process group successfully created for rank 361 . Now a global mpi barrier...
354: Process group successfully created for rank 354 . Now a global mpi barrier...
346: Process group successfully created for rank 346 . Now a global mpi barrier...
344: Process group successfully created for rank 344 . Now a global mpi barrier...
488: Process group successfully created for rank 488 . Now a global mpi barrier...
497: Process group successfully created for rank 497 . Now a global mpi barrier...
506: Process group successfully created for rank 506 . Now a global mpi barrier...
499: Process group successfully created for rank 499 . Now a global mpi barrier...
507: Process group successfully created for rank 507 . Now a global mpi barrier...
500: Process group successfully created for rank 500 . Now a global mpi barrier...
490: Process group successfully created for rank 490 . Now a global mpi barrier...
157: Process group successfully created for rank 157 . Now a global mpi barrier...
311: Process group successfully created for rank 311 . Now a global mpi barrier...
357: Process group successfully created for rank 357 . Now a global mpi barrier...
169: Process group successfully created for rank 169 . Now a global mpi barrier...
365: Process group successfully created for rank 365 . Now a global mpi barrier...
323: Process group successfully created for rank 323 . Now a global mpi barrier...
358: Process group successfully created for rank 358 . Now a global mpi barrier...
366: Process group successfully created for rank 366 . Now a global mpi barrier...
368: Process group successfully created for rank 368 . Now a global mpi barrier...
310: Process group successfully created for rank 310 . Now a global mpi barrier...
371: Process group successfully created for rank 371 . Now a global mpi barrier...
372: Process group successfully created for rank 372 . Now a global mpi barrier...
370: Process group successfully created for rank 370 . Now a global mpi barrier...
379: Process group successfully created for rank 379 . Now a global mpi barrier...
380: Process group successfully created for rank 380 . Now a global mpi barrier...
373: Process group successfully created for rank 373 . Now a global mpi barrier...
348: Process group successfully created for rank 348 . Now a global mpi barrier...
376: Process group successfully created for rank 376 . Now a global mpi barrier...
392: Process group successfully created for rank 392 . Now a global mpi barrier...
369: Process group successfully created for rank 369 . Now a global mpi barrier...
383: Process group successfully created for rank 383 . Now a global mpi barrier...
375: Process group successfully created for rank 375 . Now a global mpi barrier...
378: Process group successfully created for rank 378 . Now a global mpi barrier...
393: Process group successfully created for rank 393 . Now a global mpi barrier...
382: Process group successfully created for rank 382 . Now a global mpi barrier...
374: Process group successfully created for rank 374 . Now a global mpi barrier...
377: Process group successfully created for rank 377 . Now a global mpi barrier...
384: Process group successfully created for rank 384 . Now a global mpi barrier...
345: Process group successfully created for rank 345 . Now a global mpi barrier...
389: Process group successfully created for rank 389 . Now a global mpi barrier...
347: Process group successfully created for rank 347 . Now a global mpi barrier...
385: Process group successfully created for rank 385 . Now a global mpi barrier...
386: Process group successfully created for rank 386 . Now a global mpi barrier...
387: Process group successfully created for rank 387 . Now a global mpi barrier...
391: Process group successfully created for rank 391 . Now a global mpi barrier...
360: Process group successfully created for rank 360 . Now a global mpi barrier...
388: Process group successfully created for rank 388 . Now a global mpi barrier...
395: Process group successfully created for rank 395 . Now a global mpi barrier...
406: Process group successfully created for rank 406 . Now a global mpi barrier...
381: Process group successfully created for rank 381 . Now a global mpi barrier...
409: Process group successfully created for rank 409 . Now a global mpi barrier...
400: Process group successfully created for rank 400 . Now a global mpi barrier...
367: Process group successfully created for rank 367 . Now a global mpi barrier...
394: Process group successfully created for rank 394 . Now a global mpi barrier...
398: Process group successfully created for rank 398 . Now a global mpi barrier...
407: Process group successfully created for rank 407 . Now a global mpi barrier...
417: Process group successfully created for rank 417 . Now a global mpi barrier...
396: Process group successfully created for rank 396 . Now a global mpi barrier...
412: Process group successfully created for rank 412 . Now a global mpi barrier...
410: Process group successfully created for rank 410 . Now a global mpi barrier...
403: Process group successfully created for rank 403 . Now a global mpi barrier...
405: Process group successfully created for rank 405 . Now a global mpi barrier...
418: Process group successfully created for rank 418 . Now a global mpi barrier...
397: Process group successfully created for rank 397 . Now a global mpi barrier...
413: Process group successfully created for rank 413 . Now a global mpi barrier...
421: Process group successfully created for rank 421 . Now a global mpi barrier...
408: Process group successfully created for rank 408 . Now a global mpi barrier...
401: Process group successfully created for rank 401 . Now a global mpi barrier...
390: Process group successfully created for rank 390 . Now a global mpi barrier...
419: Process group successfully created for rank 419 . Now a global mpi barrier...
399: Process group successfully created for rank 399 . Now a global mpi barrier...
414: Process group successfully created for rank 414 . Now a global mpi barrier...
422: Process group successfully created for rank 422 . Now a global mpi barrier...
411: Process group successfully created for rank 411 . Now a global mpi barrier...
402: Process group successfully created for rank 402 . Now a global mpi barrier...
496: Process group successfully created for rank 496 . Now a global mpi barrier...
489: Process group successfully created for rank 489 . Now a global mpi barrier...
498: Process group successfully created for rank 498 . Now a global mpi barrier...
420: Process group successfully created for rank 420 . Now a global mpi barrier...
416: Process group successfully created for rank 416 . Now a global mpi barrier...
423: Process group successfully created for rank 423 . Now a global mpi barrier...
428: Process group successfully created for rank 428 . Now a global mpi barrier...
271: Process group successfully created for rank 271 . Now a global mpi barrier...
434: Process group successfully created for rank 434 . Now a global mpi barrier...
426: Process group successfully created for rank 426 . Now a global mpi barrier...
415: Process group successfully created for rank 415 . Now a global mpi barrier...
435: Process group successfully created for rank 435 . Now a global mpi barrier...
436: Process group successfully created for rank 436 . Now a global mpi barrier...
452: Process group successfully created for rank 452 . Now a global mpi barrier...
444: Process group successfully created for rank 444 . Now a global mpi barrier...
433: Process group successfully created for rank 433 . Now a global mpi barrier...
457: Process group successfully created for rank 457 . Now a global mpi barrier...
437: Process group successfully created for rank 437 . Now a global mpi barrier...
454: Process group successfully created for rank 454 . Now a global mpi barrier...
449: Process group successfully created for rank 449 . Now a global mpi barrier...
446: Process group successfully created for rank 446 . Now a global mpi barrier...
432: Process group successfully created for rank 432 . Now a global mpi barrier...
460: Process group successfully created for rank 460 . Now a global mpi barrier...
439: Process group successfully created for rank 439 . Now a global mpi barrier...
427: Process group successfully created for rank 427 . Now a global mpi barrier...
445: Process group successfully created for rank 445 . Now a global mpi barrier...
471: Process group successfully created for rank 471 . Now a global mpi barrier...
458: Process group successfully created for rank 458 . Now a global mpi barrier...
462: Process group successfully created for rank 462 . Now a global mpi barrier...
438: Process group successfully created for rank 438 . Now a global mpi barrier...
425: Process group successfully created for rank 425 . Now a global mpi barrier...
453: Process group successfully created for rank 453 . Now a global mpi barrier...
451: Process group successfully created for rank 451 . Now a global mpi barrier...
465: Process group successfully created for rank 465 . Now a global mpi barrier...
447: Process group successfully created for rank 447 . Now a global mpi barrier...
469: Process group successfully created for rank 469 . Now a global mpi barrier...
463: Process group successfully created for rank 463 . Now a global mpi barrier...
424: Process group successfully created for rank 424 . Now a global mpi barrier...
440: Process group successfully created for rank 440 . Now a global mpi barrier...
448: Process group successfully created for rank 448 . Now a global mpi barrier...
467: Process group successfully created for rank 467 . Now a global mpi barrier...
472: Process group successfully created for rank 472 . Now a global mpi barrier...
429: Process group successfully created for rank 429 . Now a global mpi barrier...
442: Process group successfully created for rank 442 . Now a global mpi barrier...
450: Process group successfully created for rank 450 . Now a global mpi barrier...
430: Process group successfully created for rank 430 . Now a global mpi barrier...
505: Process group successfully created for rank 505 . Now a global mpi barrier...
443: Process group successfully created for rank 443 . Now a global mpi barrier...
431: Process group successfully created for rank 431 . Now a global mpi barrier...
441: Process group successfully created for rank 441 . Now a global mpi barrier...
  1: Process group successfully created for rank 1 . Now a global mpi barrier...
  2: Process group successfully created for rank 2 . Now a global mpi barrier...
 12: Process group successfully created for rank 12 . Now a global mpi barrier...
  4: Process group successfully created for rank 4 . Now a global mpi barrier...
  8: Process group successfully created for rank 8 . Now a global mpi barrier...
 13: Process group successfully created for rank 13 . Now a global mpi barrier...
 16: Process group successfully created for rank 16 . Now a global mpi barrier...
 14: Process group successfully created for rank 14 . Now a global mpi barrier...
 20: Process group successfully created for rank 20 . Now a global mpi barrier...
 11: Process group successfully created for rank 11 . Now a global mpi barrier...
  3: Process group successfully created for rank 3 . Now a global mpi barrier...
 15: Process group successfully created for rank 15 . Now a global mpi barrier...
 24: Process group successfully created for rank 24 . Now a global mpi barrier...
 28: Process group successfully created for rank 28 . Now a global mpi barrier...
 21: Process group successfully created for rank 21 . Now a global mpi barrier...
  9: Process group successfully created for rank 9 . Now a global mpi barrier...
 37: Process group successfully created for rank 37 . Now a global mpi barrier...
 27: Process group successfully created for rank 27 . Now a global mpi barrier...
  6: Process group successfully created for rank 6 . Now a global mpi barrier...
 10: Process group successfully created for rank 10 . Now a global mpi barrier...
 32: Process group successfully created for rank 32 . Now a global mpi barrier...
 25: Process group successfully created for rank 25 . Now a global mpi barrier...
 31: Process group successfully created for rank 31 . Now a global mpi barrier...
  5: Process group successfully created for rank 5 . Now a global mpi barrier...
 44: Process group successfully created for rank 44 . Now a global mpi barrier...
 22: Process group successfully created for rank 22 . Now a global mpi barrier...
 33: Process group successfully created for rank 33 . Now a global mpi barrier...
 39: Process group successfully created for rank 39 . Now a global mpi barrier...
 26: Process group successfully created for rank 26 . Now a global mpi barrier...
 29: Process group successfully created for rank 29 . Now a global mpi barrier...
 41: Process group successfully created for rank 41 . Now a global mpi barrier...
  7: Process group successfully created for rank 7 . Now a global mpi barrier...
 19: Process group successfully created for rank 19 . Now a global mpi barrier...
 34: Process group successfully created for rank 34 . Now a global mpi barrier...
 36: Process group successfully created for rank 36 . Now a global mpi barrier...
 52: Process group successfully created for rank 52 . Now a global mpi barrier...
 30: Process group successfully created for rank 30 . Now a global mpi barrier...
 43: Process group successfully created for rank 43 . Now a global mpi barrier...
 18: Process group successfully created for rank 18 . Now a global mpi barrier...
 45: Process group successfully created for rank 45 . Now a global mpi barrier...
 49: Process group successfully created for rank 49 . Now a global mpi barrier...
 35: Process group successfully created for rank 35 . Now a global mpi barrier...
 38: Process group successfully created for rank 38 . Now a global mpi barrier...
 53: Process group successfully created for rank 53 . Now a global mpi barrier...
 40: Process group successfully created for rank 40 . Now a global mpi barrier...
 17: Process group successfully created for rank 17 . Now a global mpi barrier...
 46: Process group successfully created for rank 46 . Now a global mpi barrier...
 56: Process group successfully created for rank 56 . Now a global mpi barrier...
 50: Process group successfully created for rank 50 . Now a global mpi barrier...
 57: Process group successfully created for rank 57 . Now a global mpi barrier...
 71: Process group successfully created for rank 71 . Now a global mpi barrier...
 48: Process group successfully created for rank 48 . Now a global mpi barrier...
 55: Process group successfully created for rank 55 . Now a global mpi barrier...
 59: Process group successfully created for rank 59 . Now a global mpi barrier...
 64: Process group successfully created for rank 64 . Now a global mpi barrier...
 72: Process group successfully created for rank 72 . Now a global mpi barrier...
 60: Process group successfully created for rank 60 . Now a global mpi barrier...
 58: Process group successfully created for rank 58 . Now a global mpi barrier...
 51: Process group successfully created for rank 51 . Now a global mpi barrier...
 65: Process group successfully created for rank 65 . Now a global mpi barrier...
 74: Process group successfully created for rank 74 . Now a global mpi barrier...
 63: Process group successfully created for rank 63 . Now a global mpi barrier...
 67: Process group successfully created for rank 67 . Now a global mpi barrier...
 61: Process group successfully created for rank 61 . Now a global mpi barrier...
 62: Process group successfully created for rank 62 . Now a global mpi barrier...
455: Process group successfully created for rank 455 . Now a global mpi barrier...
404: Process group successfully created for rank 404 . Now a global mpi barrier...
461: Process group successfully created for rank 461 . Now a global mpi barrier...
459: Process group successfully created for rank 459 . Now a global mpi barrier...
475: Process group successfully created for rank 475 . Now a global mpi barrier...
468: Process group successfully created for rank 468 . Now a global mpi barrier...
470: Process group successfully created for rank 470 . Now a global mpi barrier...
456: Process group successfully created for rank 456 . Now a global mpi barrier...
480: Process group successfully created for rank 480 . Now a global mpi barrier...
464: Process group successfully created for rank 464 . Now a global mpi barrier...
485: Process group successfully created for rank 485 . Now a global mpi barrier...
491: Process group successfully created for rank 491 . Now a global mpi barrier...
476: Process group successfully created for rank 476 . Now a global mpi barrier...
466: Process group successfully created for rank 466 . Now a global mpi barrier...
473: Process group successfully created for rank 473 . Now a global mpi barrier...
477: Process group successfully created for rank 477 . Now a global mpi barrier...
482: Process group successfully created for rank 482 . Now a global mpi barrier...
484: Process group successfully created for rank 484 . Now a global mpi barrier...
492: Process group successfully created for rank 492 . Now a global mpi barrier...
479: Process group successfully created for rank 479 . Now a global mpi barrier...
483: Process group successfully created for rank 483 . Now a global mpi barrier...
478: Process group successfully created for rank 478 . Now a global mpi barrier...
481: Process group successfully created for rank 481 . Now a global mpi barrier...
 68: Process group successfully created for rank 68 . Now a global mpi barrier...
493: Process group successfully created for rank 493 . Now a global mpi barrier...
 69: Process group successfully created for rank 69 . Now a global mpi barrier...
 73: Process group successfully created for rank 73 . Now a global mpi barrier...
494: Process group successfully created for rank 494 . Now a global mpi barrier...
 70: Process group successfully created for rank 70 . Now a global mpi barrier...
495: Process group successfully created for rank 495 . Now a global mpi barrier...
 80: Process group successfully created for rank 80 . Now a global mpi barrier...
 84: Process group successfully created for rank 84 . Now a global mpi barrier...
 88: Process group successfully created for rank 88 . Now a global mpi barrier...
 76: Process group successfully created for rank 76 . Now a global mpi barrier...
 92: Process group successfully created for rank 92 . Now a global mpi barrier...
 75: Process group successfully created for rank 75 . Now a global mpi barrier...
 82: Process group successfully created for rank 82 . Now a global mpi barrier...
 89: Process group successfully created for rank 89 . Now a global mpi barrier...
 77: Process group successfully created for rank 77 . Now a global mpi barrier...
 83: Process group successfully created for rank 83 . Now a global mpi barrier...
 85: Process group successfully created for rank 85 . Now a global mpi barrier...
 90: Process group successfully created for rank 90 . Now a global mpi barrier...
 78: Process group successfully created for rank 78 . Now a global mpi barrier...
 94: Process group successfully created for rank 94 . Now a global mpi barrier...
 81: Process group successfully created for rank 81 . Now a global mpi barrier...
108: Process group successfully created for rank 108 . Now a global mpi barrier...
 86: Process group successfully created for rank 86 . Now a global mpi barrier...
 79: Process group successfully created for rank 79 . Now a global mpi barrier...
100: Process group successfully created for rank 100 . Now a global mpi barrier...
 93: Process group successfully created for rank 93 . Now a global mpi barrier...
 96: Process group successfully created for rank 96 . Now a global mpi barrier...
 87: Process group successfully created for rank 87 . Now a global mpi barrier...
 95: Process group successfully created for rank 95 . Now a global mpi barrier...
109: Process group successfully created for rank 109 . Now a global mpi barrier...
 98: Process group successfully created for rank 98 . Now a global mpi barrier...
116: Process group successfully created for rank 116 . Now a global mpi barrier...
114: Process group successfully created for rank 114 . Now a global mpi barrier...
124: Process group successfully created for rank 124 . Now a global mpi barrier...
104: Process group successfully created for rank 104 . Now a global mpi barrier...
 99: Process group successfully created for rank 99 . Now a global mpi barrier...
121: Process group successfully created for rank 121 . Now a global mpi barrier...
 97: Process group successfully created for rank 97 . Now a global mpi barrier...
103: Process group successfully created for rank 103 . Now a global mpi barrier...
117: Process group successfully created for rank 117 . Now a global mpi barrier...
115: Process group successfully created for rank 115 . Now a global mpi barrier...
125: Process group successfully created for rank 125 . Now a global mpi barrier...
105: Process group successfully created for rank 105 . Now a global mpi barrier...
110: Process group successfully created for rank 110 . Now a global mpi barrier...
102: Process group successfully created for rank 102 . Now a global mpi barrier...
129: Process group successfully created for rank 129 . Now a global mpi barrier...
118: Process group successfully created for rank 118 . Now a global mpi barrier...
146: Process group successfully created for rank 146 . Now a global mpi barrier...
122: Process group successfully created for rank 122 . Now a global mpi barrier...
126: Process group successfully created for rank 126 . Now a global mpi barrier...
139: Process group successfully created for rank 139 . Now a global mpi barrier...
106: Process group successfully created for rank 106 . Now a global mpi barrier...
111: Process group successfully created for rank 111 . Now a global mpi barrier...
101: Process group successfully created for rank 101 . Now a global mpi barrier...
130: Process group successfully created for rank 130 . Now a global mpi barrier...
119: Process group successfully created for rank 119 . Now a global mpi barrier...
123: Process group successfully created for rank 123 . Now a global mpi barrier...
138: Process group successfully created for rank 138 . Now a global mpi barrier...
107: Process group successfully created for rank 107 . Now a global mpi barrier...
128: Process group successfully created for rank 128 . Now a global mpi barrier...
120: Process group successfully created for rank 120 . Now a global mpi barrier...
502: Process group successfully created for rank 502 . Now a global mpi barrier...
486: Process group successfully created for rank 486 . Now a global mpi barrier...
503: Process group successfully created for rank 503 . Now a global mpi barrier...
487: Process group successfully created for rank 487 . Now a global mpi barrier...
474: Process group successfully created for rank 474 . Now a global mpi barrier...
134: Process group successfully created for rank 134 . Now a global mpi barrier...
 42: Process group successfully created for rank 42 . Now a global mpi barrier...
131: Process group successfully created for rank 131 . Now a global mpi barrier...
112: Process group successfully created for rank 112 . Now a global mpi barrier...
180: Process group successfully created for rank 180 . Now a global mpi barrier...
 54: Process group successfully created for rank 54 . Now a global mpi barrier...
151: Process group successfully created for rank 151 . Now a global mpi barrier...
 47: Process group successfully created for rank 47 . Now a global mpi barrier...
176: Process group successfully created for rank 176 . Now a global mpi barrier...
165: Process group successfully created for rank 165 . Now a global mpi barrier...
177: Process group successfully created for rank 177 . Now a global mpi barrier...
168: Process group successfully created for rank 168 . Now a global mpi barrier...
158: Process group successfully created for rank 158 . Now a global mpi barrier...
182: Process group successfully created for rank 182 . Now a global mpi barrier...
178: Process group successfully created for rank 178 . Now a global mpi barrier...
171: Process group successfully created for rank 171 . Now a global mpi barrier...
172: Process group successfully created for rank 172 . Now a global mpi barrier...
183: Process group successfully created for rank 183 . Now a global mpi barrier...
 23: Process group successfully created for rank 23 . Now a global mpi barrier...
179: Process group successfully created for rank 179 . Now a global mpi barrier...
173: Process group successfully created for rank 173 . Now a global mpi barrier...
188: Process group successfully created for rank 188 . Now a global mpi barrier...
181: Process group successfully created for rank 181 . Now a global mpi barrier...
184: Process group successfully created for rank 184 . Now a global mpi barrier...
174: Process group successfully created for rank 174 . Now a global mpi barrier...
175: Process group successfully created for rank 175 . Now a global mpi barrier...
186: Process group successfully created for rank 186 . Now a global mpi barrier...
501: Process group successfully created for rank 501 . Now a global mpi barrier...
187: Process group successfully created for rank 187 . Now a global mpi barrier...
504: Process group successfully created for rank 504 . Now a global mpi barrier...
 66: Process group successfully created for rank 66 . Now a global mpi barrier...
190: Process group successfully created for rank 190 . Now a global mpi barrier...
511: Process group successfully created for rank 511 . Now a global mpi barrier...
508: Process group successfully created for rank 508 . Now a global mpi barrier...
185: Process group successfully created for rank 185 . Now a global mpi barrier...
193: Process group successfully created for rank 193 . Now a global mpi barrier...
197: Process group successfully created for rank 197 . Now a global mpi barrier...
200: Process group successfully created for rank 200 . Now a global mpi barrier...
205: Process group successfully created for rank 205 . Now a global mpi barrier...
189: Process group successfully created for rank 189 . Now a global mpi barrier...
204: Process group successfully created for rank 204 . Now a global mpi barrier...
206: Process group successfully created for rank 206 . Now a global mpi barrier...
510: Process group successfully created for rank 510 . Now a global mpi barrier...
201: Process group successfully created for rank 201 . Now a global mpi barrier...
135: Process group successfully created for rank 135 . Now a global mpi barrier...
196: Process group successfully created for rank 196 . Now a global mpi barrier...
192: Process group successfully created for rank 192 . Now a global mpi barrier...
202: Process group successfully created for rank 202 . Now a global mpi barrier...
207: Process group successfully created for rank 207 . Now a global mpi barrier...
191: Process group successfully created for rank 191 . Now a global mpi barrier...
194: Process group successfully created for rank 194 . Now a global mpi barrier...
203: Process group successfully created for rank 203 . Now a global mpi barrier...
209: Process group successfully created for rank 209 . Now a global mpi barrier...
212: Process group successfully created for rank 212 . Now a global mpi barrier...
210: Process group successfully created for rank 210 . Now a global mpi barrier...
199: Process group successfully created for rank 199 . Now a global mpi barrier...
195: Process group successfully created for rank 195 . Now a global mpi barrier...
211: Process group successfully created for rank 211 . Now a global mpi barrier...
208: Process group successfully created for rank 208 . Now a global mpi barrier...
213: Process group successfully created for rank 213 . Now a global mpi barrier...
214: Process group successfully created for rank 214 . Now a global mpi barrier...
215: Process group successfully created for rank 215 . Now a global mpi barrier...
216: Process group successfully created for rank 216 . Now a global mpi barrier...
198: Process group successfully created for rank 198 . Now a global mpi barrier...
509: Process group successfully created for rank 509 . Now a global mpi barrier...
220: Process group successfully created for rank 220 . Now a global mpi barrier...
227: Process group successfully created for rank 227 . Now a global mpi barrier...
217: Process group successfully created for rank 217 . Now a global mpi barrier...
222: Process group successfully created for rank 222 . Now a global mpi barrier...
219: Process group successfully created for rank 219 . Now a global mpi barrier...
223: Process group successfully created for rank 223 . Now a global mpi barrier...
221: Process group successfully created for rank 221 . Now a global mpi barrier...
224: Process group successfully created for rank 224 . Now a global mpi barrier...
282: ... barrier passed on rank  282 .
410: ... barrier passed on rank  410 .
 26: ... barrier passed on rank  26 .
154: ... barrier passed on rank  154 .
266: ... barrier passed on rank  266 .
 10: ... barrier passed on rank  10 .
394: ... barrier passed on rank  394 .
138: ... barrier passed on rank  138 .
184: ... barrier passed on rank  184 .
442: ... barrier passed on rank  442 .
 58: ... barrier passed on rank  58 .
264: ... barrier passed on rank  264 .
136: ... barrier passed on rank  136 .
  8: ... barrier passed on rank  8 .
392: ... barrier passed on rank  392 .
 86: ... barrier passed on rank  86 .
150: ... barrier passed on rank  150 .
186: ... barrier passed on rank  186 .
406: ... barrier passed on rank  406 .
 56: ... barrier passed on rank  56 .
202: ... barrier passed on rank  202 .
278: ... barrier passed on rank  278 .
 74: ... barrier passed on rank  74 .
312: ... barrier passed on rank  312 .
330: ... barrier passed on rank  330 .
342: ... barrier passed on rank  342 .
214: ... barrier passed on rank  214 .
408: ... barrier passed on rank  408 .
468: ... barrier passed on rank  468 .
458: ... barrier passed on rank  458 .
 24: ... barrier passed on rank  24 .
 84: ... barrier passed on rank  84 .
148: ... barrier passed on rank  148 .
 40: ... barrier passed on rank  40 .
  4: ... barrier passed on rank  4 .
 18: ... barrier passed on rank  18 .
402: ... barrier passed on rank  402 .
424: ... barrier passed on rank  424 .
454: ... barrier passed on rank  454 .
 22: ... barrier passed on rank  22 .
404: ... barrier passed on rank  404 .
 70: ... barrier passed on rank  70 .
152: ... barrier passed on rank  152 .
146: ... barrier passed on rank  146 .
132: ... barrier passed on rank  132 .
276: ... barrier passed on rank  276 .
168: ... barrier passed on rank  168 .
326: ... barrier passed on rank  326 .
198: ... barrier passed on rank  198 .
280: ... barrier passed on rank  280 .
260: ... barrier passed on rank  260 .
314: ... barrier passed on rank  314 .
434: ... barrier passed on rank  434 .
470: ... barrier passed on rank  470 .
 90: ... barrier passed on rank  90 .
 42: ... barrier passed on rank  42 .
  6: ... barrier passed on rank  6 .
426: ... barrier passed on rank  426 .
440: ... barrier passed on rank  440 .
452: ... barrier passed on rank  452 .
 20: ... barrier passed on rank  20 .
 68: ... barrier passed on rank  68 .
178: ... barrier passed on rank  178 .
134: ... barrier passed on rank  134 .
170: ... barrier passed on rank  170 .
218: ... barrier passed on rank  218 .
 50: ... barrier passed on rank  50 .
324: ... barrier passed on rank  324 .
196: ... barrier passed on rank  196 .
296: ... barrier passed on rank  296 .
262: ... barrier passed on rank  262 .
306: ... barrier passed on rank  306 .
388: ... barrier passed on rank  388 .
340: ... barrier passed on rank  340 .
274: ... barrier passed on rank  274 .
474: ... barrier passed on rank  474 .
  2: ... barrier passed on rank  2 .
194: ... barrier passed on rank  194 .
130: ... barrier passed on rank  130 .
 66: ... barrier passed on rank  66 .
258: ... barrier passed on rank  258 .
298: ... barrier passed on rank  298 .
322: ... barrier passed on rank  322 .
390: ... barrier passed on rank  390 .
450: ... barrier passed on rank  450 .
386: ... barrier passed on rank  386 .
346: ... barrier passed on rank  346 .
212: ... barrier passed on rank  212 .
 62: ... barrier passed on rank  62 .
 54: ... barrier passed on rank  54 .
270: ... barrier passed on rank  270 .
318: ... barrier passed on rank  318 .
190: ... barrier passed on rank  190 .
310: ... barrier passed on rank  310 .
446: ... barrier passed on rank  446 .
 14: ... barrier passed on rank  14 .
 60: ... barrier passed on rank  60 .
182: ... barrier passed on rank  182 .
462: ... barrier passed on rank  462 .
 52: ... barrier passed on rank  52 .
436: ... barrier passed on rank  436 .
 78: ... barrier passed on rank  78 .
142: ... barrier passed on rank  142 .
200: ... barrier passed on rank  200 .
206: ... barrier passed on rank  206 .
120: ... barrier passed on rank  120 .
316: ... barrier passed on rank  316 .
292: ... barrier passed on rank  292 .
248: ... barrier passed on rank  248 .
188: ... barrier passed on rank  188 .
334: ... barrier passed on rank  334 .
308: ... barrier passed on rank  308 .
164: ... barrier passed on rank  164 .
 72: ... barrier passed on rank  72 .
376: ... barrier passed on rank  376 .
328: ... barrier passed on rank  328 .
398: ... barrier passed on rank  398 .
420: ... barrier passed on rank  420 .
456: ... barrier passed on rank  456 .
504: ... barrier passed on rank  504 .
 12: ... barrier passed on rank  12 .
 36: ... barrier passed on rank  36 .
180: ... barrier passed on rank  180 .
460: ... barrier passed on rank  460 .
 88: ... barrier passed on rank  88 .
438: ... barrier passed on rank  438 .
 76: ... barrier passed on rank  76 .
 30: ... barrier passed on rank  30 .
 16: ... barrier passed on rank  16 .
400: ... barrier passed on rank  400 .
140: ... barrier passed on rank  140 .
204: ... barrier passed on rank  204 .
122: ... barrier passed on rank  122 .
338: ... barrier passed on rank  338 .
216: ... barrier passed on rank  216 .
360: ... barrier passed on rank  360 .
210: ... barrier passed on rank  210 .
268: ... barrier passed on rank  268 .
294: ... barrier passed on rank  294 .
286: ... barrier passed on rank  286 .
104: ... barrier passed on rank  104 .
332: ... barrier passed on rank  332 .
166: ... barrier passed on rank  166 .
232: ... barrier passed on rank  232 .
378: ... barrier passed on rank  378 .
 82: ... barrier passed on rank  82 .
344: ... barrier passed on rank  344 .
466: ... barrier passed on rank  466 .
396: ... barrier passed on rank  396 .
444: ... barrier passed on rank  444 .
414: ... barrier passed on rank  414 .
422: ... barrier passed on rank  422 .
488: ... barrier passed on rank  488 .
472: ... barrier passed on rank  472 .
432: ... barrier passed on rank  432 .
506: ... barrier passed on rank  506 .
158: ... barrier passed on rank  158 .
 28: ... barrier passed on rank  28 .
176: ... barrier passed on rank  176 .
144: ... barrier passed on rank  144 .
 48: ... barrier passed on rank  48 .
362: ... barrier passed on rank  362 .
114: ... barrier passed on rank  114 .
284: ... barrier passed on rank  284 .
106: ... barrier passed on rank  106 .
370: ... barrier passed on rank  370 .
242: ... barrier passed on rank  242 .
234: ... barrier passed on rank  234 .
304: ... barrier passed on rank  304 .
272: ... barrier passed on rank  272 .
412: ... barrier passed on rank  412 .
490: ... barrier passed on rank  490 .
498: ... barrier passed on rank  498 .
156: ... barrier passed on rank  156 .
418: ... barrier passed on rank  418 .
 46: ... barrier passed on rank  46 .
290: ... barrier passed on rank  290 .
162: ... barrier passed on rank  162 .
382: ... barrier passed on rank  382 .
244: ... barrier passed on rank  244 .
 34: ... barrier passed on rank  34 .
510: ... barrier passed on rank  510 .
116: ... barrier passed on rank  116 .
254: ... barrier passed on rank  254 .
174: ... barrier passed on rank  174 .
126: ... barrier passed on rank  126 .
380: ... barrier passed on rank  380 .
372: ... barrier passed on rank  372 .
302: ... barrier passed on rank  302 .
246: ... barrier passed on rank  246 .
500: ... barrier passed on rank  500 .
430: ... barrier passed on rank  430 .
508: ... barrier passed on rank  508 .
100: ... barrier passed on rank  100 .
 44: ... barrier passed on rank  44 .
118: ... barrier passed on rank  118 .
252: ... barrier passed on rank  252 .
172: ... barrier passed on rank  172 .
124: ... barrier passed on rank  124 .
356: ... barrier passed on rank  356 .
374: ... barrier passed on rank  374 .
300: ... barrier passed on rank  300 .
502: ... barrier passed on rank  502 .
358: ... barrier passed on rank  358 .
228: ... barrier passed on rank  228 .
484: ... barrier passed on rank  484 .
 59: ... barrier passed on rank  59 .
336: ... barrier passed on rank  336 .
112: ... barrier passed on rank  112 .
208: ... barrier passed on rank  208 .
283: ... barrier passed on rank  283 .
368: ... barrier passed on rank  368 .
230: ... barrier passed on rank  230 .
240: ... barrier passed on rank  240 .
315: ... barrier passed on rank  315 .
 80: ... barrier passed on rank  80 .
464: ... barrier passed on rank  464 .
486: ... barrier passed on rank  486 .
496: ... barrier passed on rank  496 .
428: ... barrier passed on rank  428 .
  0: ... barrier passed on rank  0 .
411: ... barrier passed on rank  411 .
471: ... barrier passed on rank  471 .
 27: ... barrier passed on rank  27 .
 43: ... barrier passed on rank  43 .
  7: ... barrier passed on rank  7 .
187: ... barrier passed on rank  187 .
443: ... barrier passed on rank  443 .
128: ... barrier passed on rank  128 .
405: ... barrier passed on rank  405 .
155: ... barrier passed on rank  155 .
171: ... barrier passed on rank  171 .
 64: ... barrier passed on rank  64 .
256: ... barrier passed on rank  256 .
320: ... barrier passed on rank  320 .
263: ... barrier passed on rank  263 .
343: ... barrier passed on rank  343 .
448: ... barrier passed on rank  448 .
409: ... barrier passed on rank  409 .
 25: ... barrier passed on rank  25 .
 87: ... barrier passed on rank  87 .
192: ... barrier passed on rank  192 .
149: ... barrier passed on rank  149 .
 41: ... barrier passed on rank  41 .
  5: ... barrier passed on rank  5 .
185: ... barrier passed on rank  185 .
427: ... barrier passed on rank  427 .
 21: ... barrier passed on rank  21 .
407: ... barrier passed on rank  407 .
 92: ... barrier passed on rank  92 .
 57: ... barrier passed on rank  57 .
 69: ... barrier passed on rank  69 .
476: ... barrier passed on rank  476 .
153: ... barrier passed on rank  153 .
267: ... barrier passed on rank  267 .
135: ... barrier passed on rank  135 .
277: ... barrier passed on rank  277 .
169: ... barrier passed on rank  169 .
325: ... barrier passed on rank  325 .
197: ... barrier passed on rank  197 .
220: ... barrier passed on rank  220 .
139: ... barrier passed on rank  139 .
281: ... barrier passed on rank  281 .
 11: ... barrier passed on rank  11 .
297: ... barrier passed on rank  297 .
261: ... barrier passed on rank  261 .
313: ... barrier passed on rank  313 .
395: ... barrier passed on rank  395 .
469: ... barrier passed on rank  469 .
384: ... barrier passed on rank  384 .
110: ... barrier passed on rank  110 .
 98: ... barrier passed on rank  98 .
 85: ... barrier passed on rank  85 .
151: ... barrier passed on rank  151 .
102: ... barrier passed on rank  102 .
425: ... barrier passed on rank  425 .
441: ... barrier passed on rank  441 .
453: ... barrier passed on rank  453 .
 23: ... barrier passed on rank  23 .
 94: ... barrier passed on rank  94 .
 71: ... barrier passed on rank  71 .
478: ... barrier passed on rank  478 .
265: ... barrier passed on rank  265 .
482: ... barrier passed on rank  482 .
133: ... barrier passed on rank  133 .
279: ... barrier passed on rank  279 .
327: ... barrier passed on rank  327 .
222: ... barrier passed on rank  222 .
137: ... barrier passed on rank  137 .
366: ... barrier passed on rank  366 .
238: ... barrier passed on rank  238 .
  9: ... barrier passed on rank  9 .
299: ... barrier passed on rank  299 .
348: ... barrier passed on rank  348 .
354: ... barrier passed on rank  354 .
391: ... barrier passed on rank  391 .
341: ... barrier passed on rank  341 .
226: ... barrier passed on rank  226 .
393: ... barrier passed on rank  393 .
215: ... barrier passed on rank  215 .
494: ... barrier passed on rank  494 .
108: ... barrier passed on rank  108 .
455: ... barrier passed on rank  455 .
199: ... barrier passed on rank  199 .
364: ... barrier passed on rank  364 .
236: ... barrier passed on rank  236 .
350: ... barrier passed on rank  350 .
389: ... barrier passed on rank  389 .
213: ... barrier passed on rank  213 .
475: ... barrier passed on rank  475 .
507: ... barrier passed on rank  507 .
 53: ... barrier passed on rank  53 .
 91: ... barrier passed on rank  91 .
123: ... barrier passed on rank  123 .
219: ... barrier passed on rank  219 .
363: ... barrier passed on rank  363 .
107: ... barrier passed on rank  107 .
309: ... barrier passed on rank  309 .
235: ... barrier passed on rank  235 .
379: ... barrier passed on rank  379 .
347: ... barrier passed on rank  347 .
492: ... barrier passed on rank  492 .
491: ... barrier passed on rank  491 .
459: ... barrier passed on rank  459 .
505: ... barrier passed on rank  505 .
157: ... barrier passed on rank  157 .
181: ... barrier passed on rank  181 .
 55: ... barrier passed on rank  55 .
437: ... barrier passed on rank  437 .
 29: ... barrier passed on rank  29 .
203: ... barrier passed on rank  203 .
288: ... barrier passed on rank  288 .
121: ... barrier passed on rank  121 .
361: ... barrier passed on rank  361 .
160: ... barrier passed on rank  160 .
317: ... barrier passed on rank  317 .
285: ... barrier passed on rank  285 .
105: ... barrier passed on rank  105 .
311: ... barrier passed on rank  311 .
 32: ... barrier passed on rank  32 .
416: ... barrier passed on rank  416 .
413: ... barrier passed on rank  413 .
489: ... barrier passed on rank  489 .
435: ... barrier passed on rank  435 .
457: ... barrier passed on rank  457 .
 13: ... barrier passed on rank  13 .
 61: ... barrier passed on rank  61 .
183: ... barrier passed on rank  183 .
461: ... barrier passed on rank  461 .
 89: ... barrier passed on rank  89 .
439: ... barrier passed on rank  439 .
 77: ... barrier passed on rank  77 .
141: ... barrier passed on rank  141 .
179: ... barrier passed on rank  179 .
201: ... barrier passed on rank  201 .
205: ... barrier passed on rank  205 .
217: ... barrier passed on rank  217 .
 51: ... barrier passed on rank  51 .
269: ... barrier passed on rank  269 .
295: ... barrier passed on rank  295 .
189: ... barrier passed on rank  189 .
333: ... barrier passed on rank  333 .
167: ... barrier passed on rank  167 .
 73: ... barrier passed on rank  73 .
233: ... barrier passed on rank  233 .
377: ... barrier passed on rank  377 .
307: ... barrier passed on rank  307 .
331: ... barrier passed on rank  331 .
397: ... barrier passed on rank  397 .
445: ... barrier passed on rank  445 .
423: ... barrier passed on rank  423 .
473: ... barrier passed on rank  473 .
  3: ... barrier passed on rank  3 .
433: ... barrier passed on rank  433 .
 15: ... barrier passed on rank  15 .
 38: ... barrier passed on rank  38 .
 63: ... barrier passed on rank  63 .
387: ... barrier passed on rank  387 .
159: ... barrier passed on rank  159 .
195: ... barrier passed on rank  195 .
463: ... barrier passed on rank  463 .
 79: ... barrier passed on rank  79 .
 31: ... barrier passed on rank  31 .
 19: ... barrier passed on rank  19 .
403: ... barrier passed on rank  403 .
131: ... barrier passed on rank  131 .
143: ... barrier passed on rank  143 .
177: ... barrier passed on rank  177 .
207: ... barrier passed on rank  207 .
147: ... barrier passed on rank  147 .
 49: ... barrier passed on rank  49 .
271: ... barrier passed on rank  271 .
 67: ... barrier passed on rank  67 .
319: ... barrier passed on rank  319 .
293: ... barrier passed on rank  293 .
259: ... barrier passed on rank  259 .
287: ... barrier passed on rank  287 .
250: ... barrier passed on rank  250 .
191: ... barrier passed on rank  191 .
335: ... barrier passed on rank  335 .
323: ... barrier passed on rank  323 .
165: ... barrier passed on rank  165 .
 75: ... barrier passed on rank  75 .
305: ... barrier passed on rank  305 .
329: ... barrier passed on rank  329 .
451: ... barrier passed on rank  451 .
275: ... barrier passed on rank  275 .
345: ... barrier passed on rank  345 .
399: ... barrier passed on rank  399 .
447: ... barrier passed on rank  447 .
415: ... barrier passed on rank  415 .
421: ... barrier passed on rank  421 .
 39: ... barrier passed on rank  39 .
401: ... barrier passed on rank  401 .
145: ... barrier passed on rank  145 .
251: ... barrier passed on rank  251 .
373: ... barrier passed on rank  373 .
245: ... barrier passed on rank  245 .
273: ... barrier passed on rank  273 .
501: ... barrier passed on rank  501 .
 37: ... barrier passed on rank  37 .
117: ... barrier passed on rank  117 .
477: ... barrier passed on rank  477 .
249: ... barrier passed on rank  249 .
375: ... barrier passed on rank  375 .
349: ... barrier passed on rank  349 .
247: ... barrier passed on rank  247 .
503: ... barrier passed on rank  503 .
 96: ... barrier passed on rank  96 .
509: ... barrier passed on rank  509 .
 17: ... barrier passed on rank  17 .
 45: ... barrier passed on rank  45 .
 93: ... barrier passed on rank  93 .
119: ... barrier passed on rank  119 .
480: ... barrier passed on rank  480 .
253: ... barrier passed on rank  253 .
125: ... barrier passed on rank  125 .
221: ... barrier passed on rank  221 .
371: ... barrier passed on rank  371 .
381: ... barrier passed on rank  381 .
231: ... barrier passed on rank  231 .
243: ... barrier passed on rank  243 .
352: ... barrier passed on rank  352 .
224: ... barrier passed on rank  224 .
499: ... barrier passed on rank  499 .
429: ... barrier passed on rank  429 .
103: ... barrier passed on rank  103 .
115: ... barrier passed on rank  115 .
173: ... barrier passed on rank  173 .
359: ... barrier passed on rank  359 .
229: ... barrier passed on rank  229 .
301: ... barrier passed on rank  301 .
485: ... barrier passed on rank  485 .
511: ... barrier passed on rank  511 .
 47: ... barrier passed on rank  47 .
 95: ... barrier passed on rank  95 .
255: ... barrier passed on rank  255 .
175: ... barrier passed on rank  175 .
127: ... barrier passed on rank  127 .
223: ... barrier passed on rank  223 .
383: ... barrier passed on rank  383 .
357: ... barrier passed on rank  357 .
351: ... barrier passed on rank  351 .
303: ... barrier passed on rank  303 .
487: ... barrier passed on rank  487 .
479: ... barrier passed on rank  479 .
339: ... barrier passed on rank  339 .
113: ... barrier passed on rank  113 .
211: ... barrier passed on rank  211 .
369: ... barrier passed on rank  369 .
241: ... barrier passed on rank  241 .
 83: ... barrier passed on rank  83 .
467: ... barrier passed on rank  467 .
497: ... barrier passed on rank  497 .
  1: ... barrier passed on rank  1 .
385: ... barrier passed on rank  385 .
193: ... barrier passed on rank  193 .
101: ... barrier passed on rank  101 .
129: ... barrier passed on rank  129 .
337: ... barrier passed on rank  337 .
209: ... barrier passed on rank  209 .
257: ... barrier passed on rank  257 .
321: ... barrier passed on rank  321 .
449: ... barrier passed on rank  449 .
 81: ... barrier passed on rank  81 .
465: ... barrier passed on rank  465 .
431: ... barrier passed on rank  431 .
291: ... barrier passed on rank  291 .
163: ... barrier passed on rank  163 .
 65: ... barrier passed on rank  65 .
 35: ... barrier passed on rank  35 .
419: ... barrier passed on rank  419 .
109: ... barrier passed on rank  109 .
365: ... barrier passed on rank  365 .
237: ... barrier passed on rank  237 .
493: ... barrier passed on rank  493 .
239: ... barrier passed on rank  239 .
111: ... barrier passed on rank  111 .
367: ... barrier passed on rank  367 .
289: ... barrier passed on rank  289 .
161: ... barrier passed on rank  161 .
 33: ... barrier passed on rank  33 .
417: ... barrier passed on rank  417 .
495: ... barrier passed on rank  495 .
 99: ... barrier passed on rank  99 .
483: ... barrier passed on rank  483 .
355: ... barrier passed on rank  355 .
227: ... barrier passed on rank  227 .
 97: ... barrier passed on rank  97 .
481: ... barrier passed on rank  481 .
353: ... barrier passed on rank  353 .
225: ... barrier passed on rank  225 .
  0: hkn0403:1751320:1751320 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  0: hkn0403:1751320:1751320 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  0: hkn0403:1751320:1751320 [0] NCCL INFO P2P plugin IBext
  0: hkn0403:1751320:1751320 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  0: hkn0403:1751320:1751320 [0] NCCL INFO Using network IBext
  0: NCCL version 2.11.4+cuda11.4
  3: hkn0403:1751336:1751336 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  1: hkn0403:1751324:1751324 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  2: hkn0403:1751321:1751321 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.35<0>
  3: hkn0403:1751336:1751336 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  3: hkn0403:1751336:1751336 [3] NCCL INFO P2P plugin IBext
  1: hkn0403:1751324:1751324 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  1: hkn0403:1751324:1751324 [1] NCCL INFO P2P plugin IBext
  2: hkn0403:1751321:1751321 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  2: hkn0403:1751321:1751321 [2] NCCL INFO P2P plugin IBext
  3: hkn0403:1751336:1751336 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  1: hkn0403:1751324:1751324 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  3: hkn0403:1751336:1751336 [3] NCCL INFO Using network IBext
  1: hkn0403:1751324:1751324 [1] NCCL INFO Using network IBext
  2: hkn0403:1751321:1751321 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.35<0>
  2: hkn0403:1751321:1751321 [2] NCCL INFO Using network IBext
254: hkn0611:702301:702301 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
142: hkn0512:3036655:3036655 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
141: hkn0512:3036663:3036663 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
140: hkn0512:3036647:3036647 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
149: hkn0514:2943234:2943234 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
143: hkn0512:3036675:3036675 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.80<0>
255: hkn0611:702317:702317 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
148: hkn0514:2943218:2943218 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
151: hkn0514:2943246:2943246 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
142: hkn0512:3036655:3036655 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
142: hkn0512:3036655:3036655 [2] NCCL INFO P2P plugin IBext
141: hkn0512:3036663:3036663 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
141: hkn0512:3036663:3036663 [1] NCCL INFO P2P plugin IBext
254: hkn0611:702301:702301 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
254: hkn0611:702301:702301 [2] NCCL INFO P2P plugin IBext
149: hkn0514:2943234:2943234 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
149: hkn0514:2943234:2943234 [1] NCCL INFO P2P plugin IBext
140: hkn0512:3036647:3036647 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
140: hkn0512:3036647:3036647 [0] NCCL INFO P2P plugin IBext
143: hkn0512:3036675:3036675 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
143: hkn0512:3036675:3036675 [3] NCCL INFO P2P plugin IBext
413: hkn0724:1708483:1708483 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
180: hkn0526:1420918:1420918 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
255: hkn0611:702317:702317 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
255: hkn0611:702317:702317 [3] NCCL INFO P2P plugin IBext
148: hkn0514:2943218:2943218 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
148: hkn0514:2943218:2943218 [0] NCCL INFO P2P plugin IBext
183: hkn0526:1420898:1420898 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
151: hkn0514:2943246:2943246 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
151: hkn0514:2943246:2943246 [3] NCCL INFO P2P plugin IBext
182: hkn0526:1420936:1420936 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
181: hkn0526:1420907:1420907 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.94<0>
150: hkn0514:2943226:2943226 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.82<0>
140: hkn0512:3036647:3036647 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
140: hkn0512:3036647:3036647 [0] NCCL INFO Using network IBext
143: hkn0512:3036675:3036675 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
143: hkn0512:3036675:3036675 [3] NCCL INFO Using network IBext
413: hkn0724:1708483:1708483 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
413: hkn0724:1708483:1708483 [1] NCCL INFO P2P plugin IBext
180: hkn0526:1420918:1420918 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
180: hkn0526:1420918:1420918 [0] NCCL INFO P2P plugin IBext
255: hkn0611:702317:702317 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
255: hkn0611:702317:702317 [3] NCCL INFO Using network IBext
148: hkn0514:2943218:2943218 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
148: hkn0514:2943218:2943218 [0] NCCL INFO Using network IBext
151: hkn0514:2943246:2943246 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
151: hkn0514:2943246:2943246 [3] NCCL INFO Using network IBext
183: hkn0526:1420898:1420898 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
183: hkn0526:1420898:1420898 [3] NCCL INFO P2P plugin IBext
182: hkn0526:1420936:1420936 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
182: hkn0526:1420936:1420936 [2] NCCL INFO P2P plugin IBext
181: hkn0526:1420907:1420907 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
181: hkn0526:1420907:1420907 [1] NCCL INFO P2P plugin IBext
150: hkn0514:2943226:2943226 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
150: hkn0514:2943226:2943226 [2] NCCL INFO P2P plugin IBext
254: hkn0611:702301:702301 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
254: hkn0611:702301:702301 [2] NCCL INFO Using network IBext
141: hkn0512:3036663:3036663 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
141: hkn0512:3036663:3036663 [1] NCCL INFO Using network IBext
142: hkn0512:3036655:3036655 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.80<0>
142: hkn0512:3036655:3036655 [2] NCCL INFO Using network IBext
149: hkn0514:2943234:2943234 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
149: hkn0514:2943234:2943234 [1] NCCL INFO Using network IBext
355: hkn0707:4012431:4012431 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
354: hkn0707:4012451:4012451 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
150: hkn0514:2943226:2943226 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.82<0>
150: hkn0514:2943226:2943226 [2] NCCL INFO Using network IBext
181: hkn0526:1420907:1420907 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
182: hkn0526:1420936:1420936 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
183: hkn0526:1420898:1420898 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
181: hkn0526:1420907:1420907 [1] NCCL INFO Using network IBext
182: hkn0526:1420936:1420936 [2] NCCL INFO Using network IBext
183: hkn0526:1420898:1420898 [3] NCCL INFO Using network IBext
179: hkn0525:979318:979318 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
352: hkn0707:4012423:4012423 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
353: hkn0707:4012439:4012439 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.147<0>
178: hkn0525:979310:979310 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
355: hkn0707:4012431:4012431 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
355: hkn0707:4012431:4012431 [3] NCCL INFO P2P plugin IBext
180: hkn0526:1420918:1420918 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.94<0>
180: hkn0526:1420918:1420918 [0] NCCL INFO Using network IBext
354: hkn0707:4012451:4012451 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
354: hkn0707:4012451:4012451 [2] NCCL INFO P2P plugin IBext
413: hkn0724:1708483:1708483 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
413: hkn0724:1708483:1708483 [1] NCCL INFO Using network IBext
176: hkn0525:979338:979338 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
179: hkn0525:979318:979318 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
179: hkn0525:979318:979318 [3] NCCL INFO P2P plugin IBext
352: hkn0707:4012423:4012423 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
352: hkn0707:4012423:4012423 [0] NCCL INFO P2P plugin IBext
353: hkn0707:4012439:4012439 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
353: hkn0707:4012439:4012439 [1] NCCL INFO P2P plugin IBext
177: hkn0525:979326:979326 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.93<0>
493: hkn0810:932050:932050 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
178: hkn0525:979310:979310 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
178: hkn0525:979310:979310 [2] NCCL INFO P2P plugin IBext
492: hkn0810:932042:932042 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
176: hkn0525:979338:979338 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
176: hkn0525:979338:979338 [0] NCCL INFO P2P plugin IBext
495: hkn0810:932034:932034 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
353: hkn0707:4012439:4012439 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
353: hkn0707:4012439:4012439 [1] NCCL INFO Using network IBext
352: hkn0707:4012423:4012423 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
352: hkn0707:4012423:4012423 [0] NCCL INFO Using network IBext
290: hkn0624:1765428:1765428 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
288: hkn0624:1765444:1765444 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
177: hkn0525:979326:979326 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
177: hkn0525:979326:979326 [1] NCCL INFO P2P plugin IBext
493: hkn0810:932050:932050 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
493: hkn0810:932050:932050 [1] NCCL INFO P2P plugin IBext
176: hkn0525:979338:979338 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
176: hkn0525:979338:979338 [0] NCCL INFO Using network IBext
178: hkn0525:979310:979310 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
178: hkn0525:979310:979310 [2] NCCL INFO Using network IBext
289: hkn0624:1765436:1765436 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
354: hkn0707:4012451:4012451 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
354: hkn0707:4012451:4012451 [2] NCCL INFO Using network IBext
355: hkn0707:4012431:4012431 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.147<0>
355: hkn0707:4012431:4012431 [3] NCCL INFO Using network IBext
492: hkn0810:932042:932042 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
492: hkn0810:932042:932042 [0] NCCL INFO P2P plugin IBext
 31: hkn0411:2308387:2308387 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
417: hkn0725:3104434:3104434 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
291: hkn0624:1765456:1765456 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.128<0>
495: hkn0810:932034:932034 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
495: hkn0810:932034:932034 [3] NCCL INFO P2P plugin IBext
177: hkn0525:979326:979326 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
177: hkn0525:979326:979326 [1] NCCL INFO Using network IBext
 39: hkn0413:2359214:2359214 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
404: hkn0721:2291503:2291503 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
290: hkn0624:1765428:1765428 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
290: hkn0624:1765428:1765428 [2] NCCL INFO P2P plugin IBext
288: hkn0624:1765444:1765444 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
288: hkn0624:1765444:1765444 [0] NCCL INFO P2P plugin IBext
494: hkn0810:932062:932062 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.186<0>
412: hkn0724:1708475:1708475 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
418: hkn0725:3104426:3104426 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
179: hkn0525:979318:979318 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.93<0>
179: hkn0525:979318:979318 [3] NCCL INFO Using network IBext
 38: hkn0413:2359203:2359203 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
405: hkn0721:2291522:2291522 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
 61: hkn0420:3202729:3202729 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
  9: hkn0405:3199291:3199291 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 28: hkn0411:2308375:2308375 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
 63: hkn0420:3202717:3202717 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
419: hkn0725:3104454:3104454 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
 29: hkn0411:2308366:2308366 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
289: hkn0624:1765436:1765436 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
289: hkn0624:1765436:1765436 [1] NCCL INFO P2P plugin IBext
  8: hkn0405:3199319:3199319 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
416: hkn0725:3104442:3104442 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.165<0>
492: hkn0810:932042:932042 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
492: hkn0810:932042:932042 [0] NCCL INFO Using network IBext
495: hkn0810:932034:932034 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
495: hkn0810:932034:932034 [3] NCCL INFO Using network IBext
 31: hkn0411:2308387:2308387 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 31: hkn0411:2308387:2308387 [3] NCCL INFO P2P plugin IBext
406: hkn0721:2291495:2291495 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
291: hkn0624:1765456:1765456 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
291: hkn0624:1765456:1765456 [3] NCCL INFO P2P plugin IBext
407: hkn0721:2291511:2291511 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.161<0>
417: hkn0725:3104434:3104434 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
417: hkn0725:3104434:3104434 [1] NCCL INFO P2P plugin IBext
 30: hkn0411:2308367:2308367 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.43<0>
 37: hkn0413:2359194:2359194 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
 10: hkn0405:3199307:3199307 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 39: hkn0413:2359214:2359214 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 39: hkn0413:2359214:2359214 [3] NCCL INFO P2P plugin IBext
396: hkn0719:1298187:1298187 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
404: hkn0721:2291503:2291503 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
404: hkn0721:2291503:2291503 [0] NCCL INFO P2P plugin IBext
412: hkn0724:1708475:1708475 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
412: hkn0724:1708475:1708475 [0] NCCL INFO P2P plugin IBext
494: hkn0810:932062:932062 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
494: hkn0810:932062:932062 [2] NCCL INFO P2P plugin IBext
418: hkn0725:3104426:3104426 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
418: hkn0725:3104426:3104426 [2] NCCL INFO P2P plugin IBext
 60: hkn0420:3202709:3202709 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
 62: hkn0420:3202701:3202701 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.52<0>
 38: hkn0413:2359203:2359203 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 38: hkn0413:2359203:2359203 [2] NCCL INFO P2P plugin IBext
405: hkn0721:2291522:2291522 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
405: hkn0721:2291522:2291522 [1] NCCL INFO P2P plugin IBext
  9: hkn0405:3199291:3199291 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  9: hkn0405:3199291:3199291 [1] NCCL INFO P2P plugin IBext
 28: hkn0411:2308375:2308375 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 28: hkn0411:2308375:2308375 [0] NCCL INFO P2P plugin IBext
 63: hkn0420:3202717:3202717 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 63: hkn0420:3202717:3202717 [3] NCCL INFO P2P plugin IBext
289: hkn0624:1765436:1765436 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
291: hkn0624:1765456:1765456 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
289: hkn0624:1765436:1765436 [1] NCCL INFO Using network IBext
291: hkn0624:1765456:1765456 [3] NCCL INFO Using network IBext
419: hkn0725:3104454:3104454 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
419: hkn0725:3104454:3104454 [3] NCCL INFO P2P plugin IBext
 29: hkn0411:2308366:2308366 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 29: hkn0411:2308366:2308366 [1] NCCL INFO P2P plugin IBext
  8: hkn0405:3199319:3199319 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  8: hkn0405:3199319:3199319 [0] NCCL INFO P2P plugin IBext
 61: hkn0420:3202729:3202729 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 61: hkn0420:3202729:3202729 [1] NCCL INFO P2P plugin IBext
416: hkn0725:3104442:3104442 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
416: hkn0725:3104442:3104442 [0] NCCL INFO P2P plugin IBext
406: hkn0721:2291495:2291495 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
406: hkn0721:2291495:2291495 [2] NCCL INFO P2P plugin IBext
493: hkn0810:932050:932050 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
493: hkn0810:932050:932050 [1] NCCL INFO Using network IBext
414: hkn0724:1708491:1708491 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
398: hkn0719:1298217:1298217 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
 36: hkn0413:2359195:2359195 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.45<0>
494: hkn0810:932062:932062 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.186<0>
494: hkn0810:932062:932062 [2] NCCL INFO Using network IBext
 30: hkn0411:2308367:2308367 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 30: hkn0411:2308367:2308367 [2] NCCL INFO P2P plugin IBext
 37: hkn0413:2359194:2359194 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 37: hkn0413:2359194:2359194 [1] NCCL INFO P2P plugin IBext
412: hkn0724:1708475:1708475 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
412: hkn0724:1708475:1708475 [0] NCCL INFO Using network IBext
 10: hkn0405:3199307:3199307 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 10: hkn0405:3199307:3199307 [2] NCCL INFO P2P plugin IBext
397: hkn0719:1298203:1298203 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
396: hkn0719:1298187:1298187 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
396: hkn0719:1298187:1298187 [0] NCCL INFO P2P plugin IBext
415: hkn0724:1708503:1708503 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.164<0>
407: hkn0721:2291511:2291511 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
407: hkn0721:2291511:2291511 [3] NCCL INFO P2P plugin IBext
 38: hkn0413:2359203:2359203 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 38: hkn0413:2359203:2359203 [2] NCCL INFO Using network IBext
290: hkn0624:1765428:1765428 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
288: hkn0624:1765444:1765444 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.128<0>
290: hkn0624:1765428:1765428 [2] NCCL INFO Using network IBext
288: hkn0624:1765444:1765444 [0] NCCL INFO Using network IBext
418: hkn0725:3104426:3104426 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
419: hkn0725:3104454:3104454 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
418: hkn0725:3104426:3104426 [2] NCCL INFO Using network IBext
419: hkn0725:3104454:3104454 [3] NCCL INFO Using network IBext
416: hkn0725:3104442:3104442 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
416: hkn0725:3104442:3104442 [0] NCCL INFO Using network IBext
 62: hkn0420:3202701:3202701 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 62: hkn0420:3202701:3202701 [2] NCCL INFO P2P plugin IBext
406: hkn0721:2291495:2291495 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
406: hkn0721:2291495:2291495 [2] NCCL INFO Using network IBext
405: hkn0721:2291522:2291522 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
405: hkn0721:2291522:2291522 [1] NCCL INFO Using network IBext
 60: hkn0420:3202709:3202709 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 60: hkn0420:3202709:3202709 [0] NCCL INFO P2P plugin IBext
 37: hkn0413:2359194:2359194 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 37: hkn0413:2359194:2359194 [1] NCCL INFO Using network IBext
 30: hkn0411:2308367:2308367 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 30: hkn0411:2308367:2308367 [2] NCCL INFO Using network IBext
 28: hkn0411:2308375:2308375 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 29: hkn0411:2308366:2308366 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 28: hkn0411:2308375:2308375 [0] NCCL INFO Using network IBext
 29: hkn0411:2308366:2308366 [1] NCCL INFO Using network IBext
 11: hkn0405:3199299:3199299 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.37<0>
 36: hkn0413:2359195:2359195 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 36: hkn0413:2359195:2359195 [0] NCCL INFO P2P plugin IBext
398: hkn0719:1298217:1298217 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
398: hkn0719:1298217:1298217 [2] NCCL INFO P2P plugin IBext
414: hkn0724:1708491:1708491 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
414: hkn0724:1708491:1708491 [2] NCCL INFO P2P plugin IBext
407: hkn0721:2291511:2291511 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
407: hkn0721:2291511:2291511 [3] NCCL INFO Using network IBext
 10: hkn0405:3199307:3199307 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 10: hkn0405:3199307:3199307 [2] NCCL INFO Using network IBext
 31: hkn0411:2308387:2308387 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.43<0>
 31: hkn0411:2308387:2308387 [3] NCCL INFO Using network IBext
417: hkn0725:3104434:3104434 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.165<0>
417: hkn0725:3104434:3104434 [1] NCCL INFO Using network IBext
 39: hkn0413:2359214:2359214 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 39: hkn0413:2359214:2359214 [3] NCCL INFO Using network IBext
397: hkn0719:1298203:1298203 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
397: hkn0719:1298203:1298203 [1] NCCL INFO P2P plugin IBext
415: hkn0724:1708503:1708503 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
415: hkn0724:1708503:1708503 [3] NCCL INFO P2P plugin IBext
404: hkn0721:2291503:2291503 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.161<0>
404: hkn0721:2291503:2291503 [0] NCCL INFO Using network IBext
 62: hkn0420:3202701:3202701 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 60: hkn0420:3202709:3202709 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 62: hkn0420:3202701:3202701 [2] NCCL INFO Using network IBext
 60: hkn0420:3202709:3202709 [0] NCCL INFO Using network IBext
136: hkn0511:3058878:3058878 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
 36: hkn0413:2359195:2359195 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.45<0>
 36: hkn0413:2359195:2359195 [0] NCCL INFO Using network IBext
414: hkn0724:1708491:1708491 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
414: hkn0724:1708491:1708491 [2] NCCL INFO Using network IBext
 63: hkn0420:3202717:3202717 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 63: hkn0420:3202717:3202717 [3] NCCL INFO Using network IBext
139: hkn0511:3058858:3058858 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
  8: hkn0405:3199319:3199319 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  8: hkn0405:3199319:3199319 [0] NCCL INFO Using network IBext
  9: hkn0405:3199291:3199291 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
  9: hkn0405:3199291:3199291 [1] NCCL INFO Using network IBext
415: hkn0724:1708503:1708503 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.164<0>
415: hkn0724:1708503:1708503 [3] NCCL INFO Using network IBext
 61: hkn0420:3202729:3202729 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.52<0>
 61: hkn0420:3202729:3202729 [1] NCCL INFO Using network IBext
397: hkn0719:1298203:1298203 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
398: hkn0719:1298217:1298217 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
397: hkn0719:1298203:1298203 [1] NCCL INFO Using network IBext
398: hkn0719:1298217:1298217 [2] NCCL INFO Using network IBext
 11: hkn0405:3199299:3199299 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 11: hkn0405:3199299:3199299 [3] NCCL INFO P2P plugin IBext
138: hkn0511:3058850:3058850 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
396: hkn0719:1298187:1298187 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
396: hkn0719:1298187:1298187 [0] NCCL INFO Using network IBext
137: hkn0511:3058866:3058866 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.79<0>
136: hkn0511:3058878:3058878 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
136: hkn0511:3058878:3058878 [0] NCCL INFO P2P plugin IBext
172: hkn0524:1126300:1126300 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
 11: hkn0405:3199299:3199299 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.37<0>
 11: hkn0405:3199299:3199299 [3] NCCL INFO Using network IBext
139: hkn0511:3058858:3058858 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
139: hkn0511:3058858:3058858 [3] NCCL INFO P2P plugin IBext
174: hkn0524:1126288:1126288 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
138: hkn0511:3058850:3058850 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
138: hkn0511:3058850:3058850 [2] NCCL INFO P2P plugin IBext
175: hkn0524:1126280:1126280 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
137: hkn0511:3058866:3058866 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
137: hkn0511:3058866:3058866 [1] NCCL INFO P2P plugin IBext
248: hkn0609:703361:703361 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
172: hkn0524:1126300:1126300 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
172: hkn0524:1126300:1126300 [0] NCCL INFO P2P plugin IBext
251: hkn0609:703341:703341 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
173: hkn0524:1126272:1126272 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.92<0>
138: hkn0511:3058850:3058850 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
139: hkn0511:3058858:3058858 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
138: hkn0511:3058850:3058850 [2] NCCL INFO Using network IBext
139: hkn0511:3058858:3058858 [3] NCCL INFO Using network IBext
174: hkn0524:1126288:1126288 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
174: hkn0524:1126288:1126288 [2] NCCL INFO P2P plugin IBext
250: hkn0609:703349:703349 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
249: hkn0609:703333:703333 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.113<0>
137: hkn0511:3058866:3058866 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
 21: hkn0409:2578197:2578197 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
137: hkn0511:3058866:3058866 [1] NCCL INFO Using network IBext
308: hkn0630:1590950:1590950 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
123: hkn0507:3179565:3179565 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
248: hkn0609:703361:703361 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
248: hkn0609:703361:703361 [0] NCCL INFO P2P plugin IBext
 34: hkn0412:2254908:2254908 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
175: hkn0524:1126280:1126280 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
175: hkn0524:1126280:1126280 [3] NCCL INFO P2P plugin IBext
 33: hkn0412:2254900:2254900 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
424: hkn0727:1338299:1338299 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
237: hkn0606:2364558:2364558 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
238: hkn0606:2364570:2364570 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
 23: hkn0409:2578181:2578181 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
122: hkn0507:3179573:3179573 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
251: hkn0609:703341:703341 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
251: hkn0609:703341:703341 [3] NCCL INFO P2P plugin IBext
136: hkn0511:3058878:3058878 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.79<0>
136: hkn0511:3058878:3058878 [0] NCCL INFO Using network IBext
 32: hkn0412:2254916:2254916 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
426: hkn0727:1338279:1338279 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
236: hkn0606:2364550:2364550 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
239: hkn0606:2364542:2364542 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.110<0>
173: hkn0524:1126272:1126272 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
173: hkn0524:1126272:1126272 [1] NCCL INFO P2P plugin IBext
174: hkn0524:1126288:1126288 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
174: hkn0524:1126288:1126288 [2] NCCL INFO Using network IBext
166: hkn0521:1190294:1190294 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
399: hkn0719:1298195:1298195 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.159<0>
121: hkn0507:3179593:3179593 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
 21: hkn0409:2578197:2578197 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 21: hkn0409:2578197:2578197 [1] NCCL INFO P2P plugin IBext
 22: hkn0409:2578209:2578209 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
249: hkn0609:703333:703333 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
249: hkn0609:703333:703333 [1] NCCL INFO P2P plugin IBext
310: hkn0630:1590942:1590942 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
175: hkn0524:1126280:1126280 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
175: hkn0524:1126280:1126280 [3] NCCL INFO Using network IBext
250: hkn0609:703349:703349 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
250: hkn0609:703349:703349 [2] NCCL INFO P2P plugin IBext
309: hkn0630:1590958:1590958 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
123: hkn0507:3179565:3179565 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
123: hkn0507:3179565:3179565 [3] NCCL INFO P2P plugin IBext
308: hkn0630:1590950:1590950 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
308: hkn0630:1590950:1590950 [0] NCCL INFO P2P plugin IBext
311: hkn0630:1590970:1590970 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.134<0>
 35: hkn0412:2254928:2254928 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.44<0>
 20: hkn0409:2578189:2578189 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.41<0>
 33: hkn0412:2254900:2254900 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 33: hkn0412:2254900:2254900 [1] NCCL INFO P2P plugin IBext
424: hkn0727:1338299:1338299 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
424: hkn0727:1338299:1338299 [0] NCCL INFO P2P plugin IBext
173: hkn0524:1126272:1126272 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
173: hkn0524:1126272:1126272 [1] NCCL INFO Using network IBext
 34: hkn0412:2254908:2254908 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 34: hkn0412:2254908:2254908 [2] NCCL INFO P2P plugin IBext
 23: hkn0409:2578181:2578181 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 23: hkn0409:2578181:2578181 [3] NCCL INFO P2P plugin IBext
122: hkn0507:3179573:3179573 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
122: hkn0507:3179573:3179573 [2] NCCL INFO P2P plugin IBext
238: hkn0606:2364570:2364570 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
238: hkn0606:2364570:2364570 [2] NCCL INFO P2P plugin IBext
251: hkn0609:703341:703341 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
120: hkn0507:3179581:3179581 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.75<0>
251: hkn0609:703341:703341 [3] NCCL INFO Using network IBext
237: hkn0606:2364558:2364558 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
237: hkn0606:2364558:2364558 [1] NCCL INFO P2P plugin IBext
426: hkn0727:1338279:1338279 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
426: hkn0727:1338279:1338279 [2] NCCL INFO P2P plugin IBext
 32: hkn0412:2254916:2254916 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 32: hkn0412:2254916:2254916 [0] NCCL INFO P2P plugin IBext
165: hkn0521:1190302:1190302 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
249: hkn0609:703333:703333 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
249: hkn0609:703333:703333 [1] NCCL INFO Using network IBext
236: hkn0606:2364550:2364550 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
236: hkn0606:2364550:2364550 [0] NCCL INFO P2P plugin IBext
250: hkn0609:703349:703349 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
250: hkn0609:703349:703349 [2] NCCL INFO Using network IBext
172: hkn0524:1126300:1126300 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.92<0>
172: hkn0524:1126300:1126300 [0] NCCL INFO Using network IBext
239: hkn0606:2364542:2364542 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
239: hkn0606:2364542:2364542 [3] NCCL INFO P2P plugin IBext
129: hkn0509:3116896:3116896 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
164: hkn0521:1190286:1190286 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
166: hkn0521:1190294:1190294 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
166: hkn0521:1190294:1190294 [2] NCCL INFO P2P plugin IBext
399: hkn0719:1298195:1298195 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
399: hkn0719:1298195:1298195 [3] NCCL INFO P2P plugin IBext
121: hkn0507:3179593:3179593 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
121: hkn0507:3179593:3179593 [1] NCCL INFO P2P plugin IBext
 14: hkn0407:1808755:1808755 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 22: hkn0409:2578209:2578209 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 22: hkn0409:2578209:2578209 [2] NCCL INFO P2P plugin IBext
 15: hkn0407:1808771:1808771 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
167: hkn0521:1190314:1190314 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.89<0>
349: hkn0706:744786:744786 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
 35: hkn0412:2254928:2254928 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 35: hkn0412:2254928:2254928 [3] NCCL INFO P2P plugin IBext
309: hkn0630:1590958:1590958 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
309: hkn0630:1590958:1590958 [1] NCCL INFO P2P plugin IBext
311: hkn0630:1590970:1590970 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
311: hkn0630:1590970:1590970 [3] NCCL INFO P2P plugin IBext
248: hkn0609:703361:703361 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.113<0>
310: hkn0630:1590942:1590942 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
310: hkn0630:1590942:1590942 [2] NCCL INFO P2P plugin IBext
248: hkn0609:703361:703361 [0] NCCL INFO Using network IBext
 20: hkn0409:2578189:2578189 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 20: hkn0409:2578189:2578189 [0] NCCL INFO P2P plugin IBext
122: hkn0507:3179573:3179573 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
122: hkn0507:3179573:3179573 [2] NCCL INFO Using network IBext
 23: hkn0409:2578181:2578181 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 23: hkn0409:2578181:2578181 [3] NCCL INFO Using network IBext
131: hkn0509:3116888:3116888 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
426: hkn0727:1338279:1338279 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
120: hkn0507:3179581:3179581 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
120: hkn0507:3179581:3179581 [0] NCCL INFO P2P plugin IBext
426: hkn0727:1338279:1338279 [2] NCCL INFO Using network IBext
130: hkn0509:3116904:3116904 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
 32: hkn0412:2254916:2254916 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 32: hkn0412:2254916:2254916 [0] NCCL INFO Using network IBext
 12: hkn0407:1808763:1808763 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 86: hkn0426:806587:806587 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
236: hkn0606:2364550:2364550 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
239: hkn0606:2364542:2364542 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
236: hkn0606:2364550:2364550 [0] NCCL INFO Using network IBext
239: hkn0606:2364542:2364542 [3] NCCL INFO Using network IBext
399: hkn0719:1298195:1298195 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.159<0>
399: hkn0719:1298195:1298195 [3] NCCL INFO Using network IBext
165: hkn0521:1190302:1190302 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
165: hkn0521:1190302:1190302 [1] NCCL INFO P2P plugin IBext
121: hkn0507:3179593:3179593 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
121: hkn0507:3179593:3179593 [1] NCCL INFO Using network IBext
 13: hkn0407:1808783:1808783 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.39<0>
 22: hkn0409:2578209:2578209 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 22: hkn0409:2578209:2578209 [2] NCCL INFO Using network IBext
129: hkn0509:3116896:3116896 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
129: hkn0509:3116896:3116896 [1] NCCL INFO P2P plugin IBext
229: hkn0604:681744:681744 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
 35: hkn0412:2254928:2254928 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 35: hkn0412:2254928:2254928 [3] NCCL INFO Using network IBext
164: hkn0521:1190286:1190286 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
164: hkn0521:1190286:1190286 [0] NCCL INFO P2P plugin IBext
 85: hkn0426:806571:806571 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
 87: hkn0426:806598:806598 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
128: hkn0509:3116916:3116916 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.77<0>
 84: hkn0426:806579:806579 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.58<0>
 21: hkn0409:2578197:2578197 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 21: hkn0409:2578197:2578197 [1] NCCL INFO Using network IBext
 14: hkn0407:1808755:1808755 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 14: hkn0407:1808755:1808755 [2] NCCL INFO P2P plugin IBext
 20: hkn0409:2578189:2578189 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.41<0>
 20: hkn0409:2578189:2578189 [0] NCCL INFO Using network IBext
348: hkn0706:744758:744758 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
167: hkn0521:1190314:1190314 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
167: hkn0521:1190314:1190314 [3] NCCL INFO P2P plugin IBext
123: hkn0507:3179565:3179565 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
123: hkn0507:3179565:3179565 [3] NCCL INFO Using network IBext
120: hkn0507:3179581:3179581 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.75<0>
120: hkn0507:3179581:3179581 [0] NCCL INFO Using network IBext
349: hkn0706:744786:744786 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
349: hkn0706:744786:744786 [1] NCCL INFO P2P plugin IBext
228: hkn0604:681736:681736 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
310: hkn0630:1590942:1590942 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
310: hkn0630:1590942:1590942 [2] NCCL INFO Using network IBext
311: hkn0630:1590970:1590970 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
311: hkn0630:1590970:1590970 [3] NCCL INFO Using network IBext
 15: hkn0407:1808771:1808771 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 15: hkn0407:1808771:1808771 [3] NCCL INFO P2P plugin IBext
309: hkn0630:1590958:1590958 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
309: hkn0630:1590958:1590958 [1] NCCL INFO Using network IBext
308: hkn0630:1590950:1590950 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.134<0>
308: hkn0630:1590950:1590950 [0] NCCL INFO Using network IBext
 34: hkn0412:2254908:2254908 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 34: hkn0412:2254908:2254908 [2] NCCL INFO Using network IBext
 33: hkn0412:2254900:2254900 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.44<0>
 33: hkn0412:2254900:2254900 [1] NCCL INFO Using network IBext
131: hkn0509:3116888:3116888 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
131: hkn0509:3116888:3116888 [3] NCCL INFO P2P plugin IBext
424: hkn0727:1338299:1338299 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
424: hkn0727:1338299:1338299 [0] NCCL INFO Using network IBext
351: hkn0706:744774:744774 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
130: hkn0509:3116904:3116904 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
130: hkn0509:3116904:3116904 [2] NCCL INFO P2P plugin IBext
 12: hkn0407:1808763:1808763 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 12: hkn0407:1808763:1808763 [0] NCCL INFO P2P plugin IBext
230: hkn0604:681752:681752 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
237: hkn0606:2364558:2364558 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
237: hkn0606:2364558:2364558 [1] NCCL INFO Using network IBext
238: hkn0606:2364570:2364570 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.110<0>
238: hkn0606:2364570:2364570 [2] NCCL INFO Using network IBext
165: hkn0521:1190302:1190302 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
165: hkn0521:1190302:1190302 [1] NCCL INFO Using network IBext
164: hkn0521:1190286:1190286 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
164: hkn0521:1190286:1190286 [0] NCCL INFO Using network IBext
 86: hkn0426:806587:806587 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 86: hkn0426:806587:806587 [2] NCCL INFO P2P plugin IBext
 13: hkn0407:1808783:1808783 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 13: hkn0407:1808783:1808783 [1] NCCL INFO P2P plugin IBext
231: hkn0604:681764:681764 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.108<0>
167: hkn0521:1190314:1190314 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
167: hkn0521:1190314:1190314 [3] NCCL INFO Using network IBext
229: hkn0604:681744:681744 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
229: hkn0604:681744:681744 [1] NCCL INFO P2P plugin IBext
166: hkn0521:1190294:1190294 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.89<0>
166: hkn0521:1190294:1190294 [2] NCCL INFO Using network IBext
 85: hkn0426:806571:806571 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 85: hkn0426:806571:806571 [1] NCCL INFO P2P plugin IBext
 84: hkn0426:806579:806579 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 87: hkn0426:806598:806598 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 87: hkn0426:806598:806598 [3] NCCL INFO P2P plugin IBext
 84: hkn0426:806579:806579 [0] NCCL INFO P2P plugin IBext
128: hkn0509:3116916:3116916 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
128: hkn0509:3116916:3116916 [0] NCCL INFO P2P plugin IBext
348: hkn0706:744758:744758 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
348: hkn0706:744758:744758 [0] NCCL INFO P2P plugin IBext
420: hkn0726:1540622:1540622 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
425: hkn0727:1338287:1338287 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
 15: hkn0407:1808771:1808771 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 15: hkn0407:1808771:1808771 [3] NCCL INFO Using network IBext
228: hkn0604:681736:681736 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
228: hkn0604:681736:681736 [0] NCCL INFO P2P plugin IBext
 43: hkn0414:1974063:1974063 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
 12: hkn0407:1808763:1808763 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 12: hkn0407:1808763:1808763 [0] NCCL INFO Using network IBext
 13: hkn0407:1808783:1808783 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 13: hkn0407:1808783:1808783 [1] NCCL INFO Using network IBext
422: hkn0726:1540606:1540606 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
131: hkn0509:3116888:3116888 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
131: hkn0509:3116888:3116888 [3] NCCL INFO Using network IBext
130: hkn0509:3116904:3116904 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
130: hkn0509:3116904:3116904 [2] NCCL INFO Using network IBext
 40: hkn0414:1974091:1974091 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
421: hkn0726:1540614:1540614 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
351: hkn0706:744774:744774 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
351: hkn0706:744774:744774 [3] NCCL INFO P2P plugin IBext
423: hkn0726:1540634:1540634 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.166<0>
427: hkn0727:1338271:1338271 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.167<0>
230: hkn0604:681752:681752 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
230: hkn0604:681752:681752 [2] NCCL INFO P2P plugin IBext
 41: hkn0414:1974079:1974079 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
128: hkn0509:3116916:3116916 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
128: hkn0509:3116916:3116916 [0] NCCL INFO Using network IBext
129: hkn0509:3116896:3116896 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.77<0>
129: hkn0509:3116896:3116896 [1] NCCL INFO Using network IBext
245: hkn0608:478274:478274 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
 42: hkn0414:1974071:1974071 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.46<0>
 84: hkn0426:806579:806579 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 84: hkn0426:806579:806579 [0] NCCL INFO Using network IBext
 87: hkn0426:806598:806598 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
 87: hkn0426:806598:806598 [3] NCCL INFO Using network IBext
368: hkn0712:287551:287551 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
231: hkn0604:681764:681764 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
231: hkn0604:681764:681764 [3] NCCL INFO P2P plugin IBext
348: hkn0706:744758:744758 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
348: hkn0706:744758:744758 [0] NCCL INFO Using network IBext
 14: hkn0407:1808755:1808755 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.39<0>
 14: hkn0407:1808755:1808755 [2] NCCL INFO Using network IBext
369: hkn0712:287543:287543 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
 85: hkn0426:806571:806571 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
420: hkn0726:1540622:1540622 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
420: hkn0726:1540622:1540622 [0] NCCL INFO P2P plugin IBext
 85: hkn0426:806571:806571 [1] NCCL INFO Using network IBext
425: hkn0727:1338287:1338287 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
425: hkn0727:1338287:1338287 [1] NCCL INFO P2P plugin IBext
228: hkn0604:681736:681736 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
228: hkn0604:681736:681736 [0] NCCL INFO Using network IBext
351: hkn0706:744774:744774 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
351: hkn0706:744774:744774 [3] NCCL INFO Using network IBext
 43: hkn0414:1974063:1974063 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 43: hkn0414:1974063:1974063 [3] NCCL INFO P2P plugin IBext
230: hkn0604:681752:681752 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
230: hkn0604:681752:681752 [2] NCCL INFO Using network IBext
349: hkn0706:744786:744786 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
349: hkn0706:744786:744786 [1] NCCL INFO Using network IBext
422: hkn0726:1540606:1540606 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
422: hkn0726:1540606:1540606 [2] NCCL INFO P2P plugin IBext
 40: hkn0414:1974091:1974091 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 40: hkn0414:1974091:1974091 [0] NCCL INFO P2P plugin IBext
244: hkn0608:478258:478258 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
421: hkn0726:1540614:1540614 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
421: hkn0726:1540614:1540614 [1] NCCL INFO P2P plugin IBext
427: hkn0727:1338271:1338271 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
427: hkn0727:1338271:1338271 [3] NCCL INFO P2P plugin IBext
247: hkn0608:478286:478286 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
370: hkn0712:287559:287559 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
423: hkn0726:1540634:1540634 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
423: hkn0726:1540634:1540634 [3] NCCL INFO P2P plugin IBext
 41: hkn0414:1974079:1974079 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 41: hkn0414:1974079:1974079 [1] NCCL INFO P2P plugin IBext
371: hkn0712:287571:287571 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.152<0>
231: hkn0604:681764:681764 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
 86: hkn0426:806587:806587 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.58<0>
231: hkn0604:681764:681764 [3] NCCL INFO Using network IBext
 86: hkn0426:806587:806587 [2] NCCL INFO Using network IBext
246: hkn0608:478266:478266 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.112<0>
245: hkn0608:478274:478274 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
245: hkn0608:478274:478274 [1] NCCL INFO P2P plugin IBext
425: hkn0727:1338287:1338287 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
425: hkn0727:1338287:1338287 [1] NCCL INFO Using network IBext
229: hkn0604:681744:681744 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.108<0>
229: hkn0604:681744:681744 [1] NCCL INFO Using network IBext
368: hkn0712:287551:287551 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
368: hkn0712:287551:287551 [0] NCCL INFO P2P plugin IBext
 42: hkn0414:1974071:1974071 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 42: hkn0414:1974071:1974071 [2] NCCL INFO P2P plugin IBext
369: hkn0712:287543:287543 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
369: hkn0712:287543:287543 [1] NCCL INFO P2P plugin IBext
292: hkn0626:1290939:1290939 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
127: hkn0508:3131628:3131628 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
295: hkn0626:1290931:1290931 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
294: hkn0626:1290959:1290959 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
427: hkn0727:1338271:1338271 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.167<0>
427: hkn0727:1338271:1338271 [3] NCCL INFO Using network IBext
241: hkn0607:896873:896873 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
422: hkn0726:1540606:1540606 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
422: hkn0726:1540606:1540606 [2] NCCL INFO Using network IBext
421: hkn0726:1540614:1540614 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
421: hkn0726:1540614:1540614 [1] NCCL INFO Using network IBext
423: hkn0726:1540634:1540634 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
423: hkn0726:1540634:1540634 [3] NCCL INFO Using network IBext
 40: hkn0414:1974091:1974091 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 41: hkn0414:1974079:1974079 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 41: hkn0414:1974079:1974079 [1] NCCL INFO Using network IBext
 40: hkn0414:1974091:1974091 [0] NCCL INFO Using network IBext
244: hkn0608:478258:478258 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
244: hkn0608:478258:478258 [0] NCCL INFO P2P plugin IBext
125: hkn0508:3131636:3131636 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
370: hkn0712:287559:287559 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
370: hkn0712:287559:287559 [2] NCCL INFO P2P plugin IBext
350: hkn0706:744766:744766 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.146<0>
 42: hkn0414:1974071:1974071 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
247: hkn0608:478286:478286 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
247: hkn0608:478286:478286 [3] NCCL INFO P2P plugin IBext
 42: hkn0414:1974071:1974071 [2] NCCL INFO Using network IBext
371: hkn0712:287571:287571 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
371: hkn0712:287571:287571 [3] NCCL INFO P2P plugin IBext
126: hkn0508:3131648:3131648 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
293: hkn0626:1290947:1290947 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.130<0>
246: hkn0608:478266:478266 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
246: hkn0608:478266:478266 [2] NCCL INFO P2P plugin IBext
457: hkn0801:2232468:2232468 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
292: hkn0626:1290939:1290939 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
292: hkn0626:1290939:1290939 [0] NCCL INFO P2P plugin IBext
127: hkn0508:3131628:3131628 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
127: hkn0508:3131628:3131628 [3] NCCL INFO P2P plugin IBext
243: hkn0607:896857:896857 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
124: hkn0508:3131620:3131620 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.76<0>
295: hkn0626:1290931:1290931 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
295: hkn0626:1290931:1290931 [3] NCCL INFO P2P plugin IBext
420: hkn0726:1540622:1540622 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.166<0>
420: hkn0726:1540622:1540622 [0] NCCL INFO Using network IBext
294: hkn0626:1290959:1290959 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
294: hkn0626:1290959:1290959 [2] NCCL INFO P2P plugin IBext
 43: hkn0414:1974063:1974063 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.46<0>
 43: hkn0414:1974063:1974063 [3] NCCL INFO Using network IBext
241: hkn0607:896873:896873 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
241: hkn0607:896873:896873 [1] NCCL INFO P2P plugin IBext
253: hkn0611:702329:702329 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
242: hkn0607:896865:896865 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
244: hkn0608:478258:478258 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
246: hkn0608:478266:478266 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
247: hkn0608:478286:478286 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
244: hkn0608:478258:478258 [0] NCCL INFO Using network IBext
246: hkn0608:478266:478266 [2] NCCL INFO Using network IBext
247: hkn0608:478286:478286 [3] NCCL INFO Using network IBext
125: hkn0508:3131636:3131636 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
125: hkn0508:3131636:3131636 [1] NCCL INFO P2P plugin IBext
371: hkn0712:287571:287571 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
371: hkn0712:287571:287571 [3] NCCL INFO Using network IBext
370: hkn0712:287559:287559 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
370: hkn0712:287559:287559 [2] NCCL INFO Using network IBext
350: hkn0706:744766:744766 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
350: hkn0706:744766:744766 [2] NCCL INFO P2P plugin IBext
192: hkn0529:1533356:1533356 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
126: hkn0508:3131648:3131648 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
126: hkn0508:3131648:3131648 [2] NCCL INFO P2P plugin IBext
293: hkn0626:1290947:1290947 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
293: hkn0626:1290947:1290947 [1] NCCL INFO P2P plugin IBext
456: hkn0801:2232460:2232460 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
457: hkn0801:2232468:2232468 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
457: hkn0801:2232468:2232468 [1] NCCL INFO P2P plugin IBext
245: hkn0608:478274:478274 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.112<0>
245: hkn0608:478274:478274 [1] NCCL INFO Using network IBext
369: hkn0712:287543:287543 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
369: hkn0712:287543:287543 [1] NCCL INFO Using network IBext
368: hkn0712:287551:287551 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.152<0>
368: hkn0712:287551:287551 [0] NCCL INFO Using network IBext
243: hkn0607:896857:896857 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
243: hkn0607:896857:896857 [3] NCCL INFO P2P plugin IBext
124: hkn0508:3131620:3131620 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
124: hkn0508:3131620:3131620 [0] NCCL INFO P2P plugin IBext
294: hkn0626:1290959:1290959 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
294: hkn0626:1290959:1290959 [2] NCCL INFO Using network IBext
459: hkn0801:2232488:2232488 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
240: hkn0607:896885:896885 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.111<0>
253: hkn0611:702329:702329 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
253: hkn0611:702329:702329 [1] NCCL INFO P2P plugin IBext
350: hkn0706:744766:744766 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.146<0>
350: hkn0706:744766:744766 [2] NCCL INFO Using network IBext
434: hkn0730:1394229:1394229 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
293: hkn0626:1290947:1290947 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
242: hkn0607:896865:896865 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
242: hkn0607:896865:896865 [2] NCCL INFO P2P plugin IBext
293: hkn0626:1290947:1290947 [1] NCCL INFO Using network IBext
125: hkn0508:3131636:3131636 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
126: hkn0508:3131648:3131648 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
125: hkn0508:3131636:3131636 [1] NCCL INFO Using network IBext
126: hkn0508:3131648:3131648 [2] NCCL INFO Using network IBext
458: hkn0801:2232476:2232476 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.177<0>
192: hkn0529:1533356:1533356 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
192: hkn0529:1533356:1533356 [0] NCCL INFO P2P plugin IBext
456: hkn0801:2232460:2232460 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
456: hkn0801:2232460:2232460 [0] NCCL INFO P2P plugin IBext
124: hkn0508:3131620:3131620 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
124: hkn0508:3131620:3131620 [0] NCCL INFO Using network IBext
193: hkn0529:1533348:1533348 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
243: hkn0607:896857:896857 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
243: hkn0607:896857:896857 [3] NCCL INFO Using network IBext
253: hkn0611:702329:702329 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
253: hkn0611:702329:702329 [1] NCCL INFO Using network IBext
242: hkn0607:896865:896865 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
242: hkn0607:896865:896865 [2] NCCL INFO Using network IBext
195: hkn0529:1533364:1533364 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
127: hkn0508:3131628:3131628 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.76<0>
127: hkn0508:3131628:3131628 [3] NCCL INFO Using network IBext
459: hkn0801:2232488:2232488 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
459: hkn0801:2232488:2232488 [3] NCCL INFO P2P plugin IBext
240: hkn0607:896885:896885 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
240: hkn0607:896885:896885 [0] NCCL INFO P2P plugin IBext
281: hkn0622:2012970:2012970 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
292: hkn0626:1290939:1290939 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
241: hkn0607:896873:896873 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
295: hkn0626:1290931:1290931 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.130<0>
241: hkn0607:896873:896873 [1] NCCL INFO Using network IBext
292: hkn0626:1290939:1290939 [0] NCCL INFO Using network IBext
295: hkn0626:1290931:1290931 [3] NCCL INFO Using network IBext
434: hkn0730:1394229:1394229 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
434: hkn0730:1394229:1394229 [2] NCCL INFO P2P plugin IBext
252: hkn0611:702309:702309 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.115<0>
471: hkn0804:1198115:1198115 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
280: hkn0622:2012990:2012990 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
283: hkn0622:2012962:2012962 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
194: hkn0529:1533376:1533376 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.97<0>
458: hkn0801:2232476:2232476 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
458: hkn0801:2232476:2232476 [2] NCCL INFO P2P plugin IBext
435: hkn0730:1394249:1394249 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
456: hkn0801:2232460:2232460 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
456: hkn0801:2232460:2232460 [0] NCCL INFO Using network IBext
282: hkn0622:2012978:2012978 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.126<0>
111: hkn0504:33333:33333 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
432: hkn0730:1394221:1394221 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
381: hkn0715:394422:394422 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
459: hkn0801:2232488:2232488 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
459: hkn0801:2232488:2232488 [3] NCCL INFO Using network IBext
193: hkn0529:1533348:1533348 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
193: hkn0529:1533348:1533348 [1] NCCL INFO P2P plugin IBext
457: hkn0801:2232468:2232468 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
240: hkn0607:896885:896885 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.111<0>
457: hkn0801:2232468:2232468 [1] NCCL INFO Using network IBext
240: hkn0607:896885:896885 [0] NCCL INFO Using network IBext
109: hkn0504:33317:33317 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
433: hkn0730:1394237:1394237 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.170<0>
195: hkn0529:1533364:1533364 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
195: hkn0529:1533364:1533364 [3] NCCL INFO P2P plugin IBext
108: hkn0504:33325:33325 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
458: hkn0801:2232476:2232476 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.177<0>
458: hkn0801:2232476:2232476 [2] NCCL INFO Using network IBext
382: hkn0715:394402:394402 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
383: hkn0715:394394:394394 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
471: hkn0804:1198115:1198115 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
471: hkn0804:1198115:1198115 [3] NCCL INFO P2P plugin IBext
252: hkn0611:702309:702309 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
252: hkn0611:702309:702309 [0] NCCL INFO P2P plugin IBext
281: hkn0622:2012970:2012970 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
281: hkn0622:2012970:2012970 [1] NCCL INFO P2P plugin IBext
380: hkn0715:394410:394410 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.155<0>
469: hkn0804:1198123:1198123 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
194: hkn0529:1533376:1533376 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
194: hkn0529:1533376:1533376 [2] NCCL INFO P2P plugin IBext
283: hkn0622:2012962:2012962 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
283: hkn0622:2012962:2012962 [3] NCCL INFO P2P plugin IBext
280: hkn0622:2012990:2012990 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
280: hkn0622:2012990:2012990 [0] NCCL INFO P2P plugin IBext
110: hkn0504:33345:33345 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.72<0>
435: hkn0730:1394249:1394249 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
435: hkn0730:1394249:1394249 [3] NCCL INFO P2P plugin IBext
282: hkn0622:2012978:2012978 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
282: hkn0622:2012978:2012978 [2] NCCL INFO P2P plugin IBext
111: hkn0504:33333:33333 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
111: hkn0504:33333:33333 [3] NCCL INFO P2P plugin IBext
381: hkn0715:394422:394422 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
381: hkn0715:394422:394422 [1] NCCL INFO P2P plugin IBext
192: hkn0529:1533356:1533356 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
192: hkn0529:1533356:1533356 [0] NCCL INFO Using network IBext
195: hkn0529:1533364:1533364 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
195: hkn0529:1533364:1533364 [3] NCCL INFO Using network IBext
432: hkn0730:1394221:1394221 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
432: hkn0730:1394221:1394221 [0] NCCL INFO P2P plugin IBext
193: hkn0529:1533348:1533348 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
193: hkn0529:1533348:1533348 [1] NCCL INFO Using network IBext
109: hkn0504:33317:33317 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
109: hkn0504:33317:33317 [1] NCCL INFO P2P plugin IBext
468: hkn0804:1198143:1198143 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
252: hkn0611:702309:702309 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.115<0>
252: hkn0611:702309:702309 [0] NCCL INFO Using network IBext
470: hkn0804:1198131:1198131 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.180<0>
194: hkn0529:1533376:1533376 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.97<0>
194: hkn0529:1533376:1533376 [2] NCCL INFO Using network IBext
433: hkn0730:1394237:1394237 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
433: hkn0730:1394237:1394237 [1] NCCL INFO P2P plugin IBext
108: hkn0504:33325:33325 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
108: hkn0504:33325:33325 [0] NCCL INFO P2P plugin IBext
382: hkn0715:394402:394402 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
382: hkn0715:394402:394402 [2] NCCL INFO P2P plugin IBext
383: hkn0715:394394:394394 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
383: hkn0715:394394:394394 [3] NCCL INFO P2P plugin IBext
469: hkn0804:1198123:1198123 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
469: hkn0804:1198123:1198123 [1] NCCL INFO P2P plugin IBext
380: hkn0715:394410:394410 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
380: hkn0715:394410:394410 [0] NCCL INFO P2P plugin IBext
283: hkn0622:2012962:2012962 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
283: hkn0622:2012962:2012962 [3] NCCL INFO Using network IBext
280: hkn0622:2012990:2012990 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
282: hkn0622:2012978:2012978 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
280: hkn0622:2012990:2012990 [0] NCCL INFO Using network IBext
282: hkn0622:2012978:2012978 [2] NCCL INFO Using network IBext
435: hkn0730:1394249:1394249 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
435: hkn0730:1394249:1394249 [3] NCCL INFO Using network IBext
434: hkn0730:1394229:1394229 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
434: hkn0730:1394229:1394229 [2] NCCL INFO Using network IBext
110: hkn0504:33345:33345 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
110: hkn0504:33345:33345 [2] NCCL INFO P2P plugin IBext
433: hkn0730:1394237:1394237 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
433: hkn0730:1394237:1394237 [1] NCCL INFO Using network IBext
432: hkn0730:1394221:1394221 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.170<0>
432: hkn0730:1394221:1394221 [0] NCCL INFO Using network IBext
108: hkn0504:33325:33325 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
108: hkn0504:33325:33325 [0] NCCL INFO Using network IBext
109: hkn0504:33317:33317 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
109: hkn0504:33317:33317 [1] NCCL INFO Using network IBext
468: hkn0804:1198143:1198143 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
468: hkn0804:1198143:1198143 [0] NCCL INFO P2P plugin IBext
470: hkn0804:1198131:1198131 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
470: hkn0804:1198131:1198131 [2] NCCL INFO P2P plugin IBext
297: hkn0627:1780434:1780434 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
382: hkn0715:394402:394402 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
382: hkn0715:394402:394402 [2] NCCL INFO Using network IBext
383: hkn0715:394394:394394 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
380: hkn0715:394410:394410 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
380: hkn0715:394410:394410 [0] NCCL INFO Using network IBext
383: hkn0715:394394:394394 [3] NCCL INFO Using network IBext
469: hkn0804:1198123:1198123 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
469: hkn0804:1198123:1198123 [1] NCCL INFO Using network IBext
471: hkn0804:1198115:1198115 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
471: hkn0804:1198115:1198115 [3] NCCL INFO Using network IBext
281: hkn0622:2012970:2012970 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.126<0>
110: hkn0504:33345:33345 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
281: hkn0622:2012970:2012970 [1] NCCL INFO Using network IBext
110: hkn0504:33345:33345 [2] NCCL INFO Using network IBext
468: hkn0804:1198143:1198143 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
468: hkn0804:1198143:1198143 [0] NCCL INFO Using network IBext
470: hkn0804:1198131:1198131 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.180<0>
470: hkn0804:1198131:1198131 [2] NCCL INFO Using network IBext
111: hkn0504:33333:33333 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.72<0>
111: hkn0504:33333:33333 [3] NCCL INFO Using network IBext
381: hkn0715:394422:394422 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.155<0>
381: hkn0715:394422:394422 [1] NCCL INFO Using network IBext
297: hkn0627:1780434:1780434 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
297: hkn0627:1780434:1780434 [1] NCCL INFO P2P plugin IBext
480: hkn0807:1011577:1011577 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
363: hkn0710:348029:348029 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
327: hkn0634:1513369:1513369 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
362: hkn0710:348041:348041 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
299: hkn0627:1780422:1780422 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
361: hkn0710:348021:348021 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
342: hkn0704:784530:784530 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
341: hkn0704:784510:784510 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
326: hkn0634:1513361:1513361 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
482: hkn0807:1011569:1011569 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
480: hkn0807:1011577:1011577 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
480: hkn0807:1011577:1011577 [0] NCCL INFO P2P plugin IBext
363: hkn0710:348029:348029 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
363: hkn0710:348029:348029 [3] NCCL INFO P2P plugin IBext
298: hkn0627:1780406:1780406 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
327: hkn0634:1513369:1513369 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
327: hkn0634:1513369:1513369 [3] NCCL INFO P2P plugin IBext
362: hkn0710:348041:348041 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
362: hkn0710:348041:348041 [2] NCCL INFO P2P plugin IBext
481: hkn0807:1011585:1011585 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
483: hkn0807:1011596:1011596 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.183<0>
360: hkn0710:348013:348013 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.150<0>
340: hkn0704:784518:784518 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
299: hkn0627:1780422:1780422 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
299: hkn0627:1780422:1780422 [3] NCCL INFO P2P plugin IBext
343: hkn0704:784502:784502 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.144<0>
361: hkn0710:348021:348021 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
361: hkn0710:348021:348021 [1] NCCL INFO P2P plugin IBext
342: hkn0704:784530:784530 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
342: hkn0704:784530:784530 [2] NCCL INFO P2P plugin IBext
341: hkn0704:784510:784510 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
341: hkn0704:784510:784510 [1] NCCL INFO P2P plugin IBext
326: hkn0634:1513361:1513361 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
326: hkn0634:1513361:1513361 [2] NCCL INFO P2P plugin IBext
482: hkn0807:1011569:1011569 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
482: hkn0807:1011569:1011569 [2] NCCL INFO P2P plugin IBext
324: hkn0634:1513353:1513353 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
325: hkn0634:1513380:1513380 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.138<0>
297: hkn0627:1780434:1780434 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
297: hkn0627:1780434:1780434 [1] NCCL INFO Using network IBext
298: hkn0627:1780406:1780406 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
298: hkn0627:1780406:1780406 [2] NCCL INFO P2P plugin IBext
299: hkn0627:1780422:1780422 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
299: hkn0627:1780422:1780422 [3] NCCL INFO Using network IBext
361: hkn0710:348021:348021 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
361: hkn0710:348021:348021 [1] NCCL INFO Using network IBext
362: hkn0710:348041:348041 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
362: hkn0710:348041:348041 [2] NCCL INFO Using network IBext
296: hkn0627:1780414:1780414 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.131<0>
481: hkn0807:1011585:1011585 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
481: hkn0807:1011585:1011585 [1] NCCL INFO P2P plugin IBext
340: hkn0704:784518:784518 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
340: hkn0704:784518:784518 [0] NCCL INFO P2P plugin IBext
343: hkn0704:784502:784502 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
343: hkn0704:784502:784502 [3] NCCL INFO P2P plugin IBext
483: hkn0807:1011596:1011596 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
483: hkn0807:1011596:1011596 [3] NCCL INFO P2P plugin IBext
360: hkn0710:348013:348013 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
360: hkn0710:348013:348013 [0] NCCL INFO P2P plugin IBext
326: hkn0634:1513361:1513361 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
326: hkn0634:1513361:1513361 [2] NCCL INFO Using network IBext
482: hkn0807:1011569:1011569 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
482: hkn0807:1011569:1011569 [2] NCCL INFO Using network IBext
298: hkn0627:1780406:1780406 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
298: hkn0627:1780406:1780406 [2] NCCL INFO Using network IBext
443: hkn0732:1204148:1204148 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
442: hkn0732:1204151:1204151 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
153: hkn0515:2889289:2889289 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
480: hkn0807:1011577:1011577 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
480: hkn0807:1011577:1011577 [0] NCCL INFO Using network IBext
 16: hkn0408:2883211:2883211 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
441: hkn0732:1204159:1204159 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
363: hkn0710:348029:348029 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
363: hkn0710:348029:348029 [3] NCCL INFO Using network IBext
440: hkn0732:1204171:1204171 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.172<0>
324: hkn0634:1513353:1513353 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
324: hkn0634:1513353:1513353 [0] NCCL INFO P2P plugin IBext
325: hkn0634:1513380:1513380 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
325: hkn0634:1513380:1513380 [1] NCCL INFO P2P plugin IBext
483: hkn0807:1011596:1011596 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
483: hkn0807:1011596:1011596 [3] NCCL INFO Using network IBext
481: hkn0807:1011585:1011585 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.183<0>
481: hkn0807:1011585:1011585 [1] NCCL INFO Using network IBext
327: hkn0634:1513369:1513369 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
327: hkn0634:1513369:1513369 [3] NCCL INFO Using network IBext
154: hkn0515:2889281:2889281 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
360: hkn0710:348013:348013 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.150<0>
360: hkn0710:348013:348013 [0] NCCL INFO Using network IBext
152: hkn0515:2889297:2889297 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
155: hkn0515:2889309:2889309 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.83<0>
296: hkn0627:1780414:1780414 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
296: hkn0627:1780414:1780414 [0] NCCL INFO P2P plugin IBext
 17: hkn0408:2883223:2883223 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
340: hkn0704:784518:784518 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
343: hkn0704:784502:784502 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
340: hkn0704:784518:784518 [0] NCCL INFO Using network IBext
343: hkn0704:784502:784502 [3] NCCL INFO Using network IBext
341: hkn0704:784510:784510 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
341: hkn0704:784510:784510 [1] NCCL INFO Using network IBext
105: hkn0503:2892162:2892162 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
342: hkn0704:784530:784530 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.144<0>
342: hkn0704:784530:784530 [2] NCCL INFO Using network IBext
 18: hkn0408:2883203:2883203 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
324: hkn0634:1513353:1513353 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
324: hkn0634:1513353:1513353 [0] NCCL INFO Using network IBext
 19: hkn0408:2883195:2883195 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.40<0>
325: hkn0634:1513380:1513380 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.138<0>
325: hkn0634:1513380:1513380 [1] NCCL INFO Using network IBext
443: hkn0732:1204148:1204148 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
443: hkn0732:1204148:1204148 [3] NCCL INFO P2P plugin IBext
153: hkn0515:2889289:2889289 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
153: hkn0515:2889289:2889289 [1] NCCL INFO P2P plugin IBext
442: hkn0732:1204151:1204151 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
442: hkn0732:1204151:1204151 [2] NCCL INFO P2P plugin IBext
 16: hkn0408:2883211:2883211 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 16: hkn0408:2883211:2883211 [0] NCCL INFO P2P plugin IBext
106: hkn0503:2892182:2892182 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
104: hkn0503:2892170:2892170 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
440: hkn0732:1204171:1204171 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
440: hkn0732:1204171:1204171 [0] NCCL INFO P2P plugin IBext
441: hkn0732:1204159:1204159 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
441: hkn0732:1204159:1204159 [1] NCCL INFO P2P plugin IBext
296: hkn0627:1780414:1780414 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.131<0>
296: hkn0627:1780414:1780414 [0] NCCL INFO Using network IBext
107: hkn0503:2892154:2892154 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.71<0>
154: hkn0515:2889281:2889281 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
154: hkn0515:2889281:2889281 [2] NCCL INFO P2P plugin IBext
155: hkn0515:2889309:2889309 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
155: hkn0515:2889309:2889309 [3] NCCL INFO P2P plugin IBext
152: hkn0515:2889297:2889297 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
152: hkn0515:2889297:2889297 [0] NCCL INFO P2P plugin IBext
 17: hkn0408:2883223:2883223 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 17: hkn0408:2883223:2883223 [1] NCCL INFO P2P plugin IBext
 18: hkn0408:2883203:2883203 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 18: hkn0408:2883203:2883203 [2] NCCL INFO P2P plugin IBext
 19: hkn0408:2883195:2883195 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 19: hkn0408:2883195:2883195 [3] NCCL INFO P2P plugin IBext
132: hkn0510:2754595:2754595 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
440: hkn0732:1204171:1204171 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
440: hkn0732:1204171:1204171 [0] NCCL INFO Using network IBext
441: hkn0732:1204159:1204159 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
441: hkn0732:1204159:1204159 [1] NCCL INFO Using network IBext
105: hkn0503:2892162:2892162 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
105: hkn0503:2892162:2892162 [1] NCCL INFO P2P plugin IBext
 65: hkn0421:2172257:2172257 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
106: hkn0503:2892182:2892182 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
106: hkn0503:2892182:2892182 [2] NCCL INFO P2P plugin IBext
190: hkn0528:1294206:1294206 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
191: hkn0528:1294226:1294226 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
104: hkn0503:2892170:2892170 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
104: hkn0503:2892170:2892170 [0] NCCL INFO P2P plugin IBext
107: hkn0503:2892154:2892154 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
107: hkn0503:2892154:2892154 [3] NCCL INFO P2P plugin IBext
155: hkn0515:2889309:2889309 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
152: hkn0515:2889297:2889297 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
155: hkn0515:2889309:2889309 [3] NCCL INFO Using network IBext
152: hkn0515:2889297:2889297 [0] NCCL INFO Using network IBext
154: hkn0515:2889281:2889281 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
154: hkn0515:2889281:2889281 [2] NCCL INFO Using network IBext
 17: hkn0408:2883223:2883223 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 18: hkn0408:2883203:2883203 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 19: hkn0408:2883195:2883195 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 17: hkn0408:2883223:2883223 [1] NCCL INFO Using network IBext
 18: hkn0408:2883203:2883203 [2] NCCL INFO Using network IBext
 19: hkn0408:2883195:2883195 [3] NCCL INFO Using network IBext
189: hkn0528:1294214:1294214 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
147: hkn0513:3005453:3005453 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
188: hkn0528:1294198:1294198 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.96<0>
207: hkn0532:916642:916642 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
 67: hkn0421:2172249:2172249 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
132: hkn0510:2754595:2754595 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
132: hkn0510:2754595:2754595 [0] NCCL INFO P2P plugin IBext
153: hkn0515:2889289:2889289 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.83<0>
153: hkn0515:2889289:2889289 [1] NCCL INFO Using network IBext
 69: hkn0422:4145507:4145507 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 66: hkn0421:2172265:2172265 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
 59: hkn0419:1536808:1536808 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
 65: hkn0421:2172257:2172257 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 65: hkn0421:2172257:2172257 [1] NCCL INFO P2P plugin IBext
 71: hkn0422:4145519:4145519 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
442: hkn0732:1204151:1204151 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
442: hkn0732:1204151:1204151 [2] NCCL INFO Using network IBext
443: hkn0732:1204148:1204148 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.172<0>
443: hkn0732:1204148:1204148 [3] NCCL INFO Using network IBext
 16: hkn0408:2883211:2883211 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.40<0>
 16: hkn0408:2883211:2883211 [0] NCCL INFO Using network IBext
191: hkn0528:1294226:1294226 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
191: hkn0528:1294226:1294226 [3] NCCL INFO P2P plugin IBext
 57: hkn0419:1536822:1536822 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
 58: hkn0419:1536809:1536809 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
190: hkn0528:1294206:1294206 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
190: hkn0528:1294206:1294206 [2] NCCL INFO P2P plugin IBext
 64: hkn0421:2172277:2172277 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.53<0>
204: hkn0532:916658:916658 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
107: hkn0503:2892154:2892154 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
107: hkn0503:2892154:2892154 [3] NCCL INFO Using network IBext
 70: hkn0422:4145499:4145499 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
 56: hkn0419:1536810:1536810 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.51<0>
 68: hkn0422:4145491:4145491 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.54<0>
135: hkn0510:2754567:2754567 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
206: hkn0532:916669:916669 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
147: hkn0513:3005453:3005453 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
147: hkn0513:3005453:3005453 [3] NCCL INFO P2P plugin IBext
189: hkn0528:1294214:1294214 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
189: hkn0528:1294214:1294214 [1] NCCL INFO P2P plugin IBext
207: hkn0532:916642:916642 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
207: hkn0532:916642:916642 [3] NCCL INFO P2P plugin IBext
188: hkn0528:1294198:1294198 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
188: hkn0528:1294198:1294198 [0] NCCL INFO P2P plugin IBext
205: hkn0532:916650:916650 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.100<0>
 24: hkn0410:1152208:1152208 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 69: hkn0422:4145507:4145507 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 69: hkn0422:4145507:4145507 [1] NCCL INFO P2P plugin IBext
 67: hkn0421:2172249:2172249 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 67: hkn0421:2172249:2172249 [3] NCCL INFO P2P plugin IBext
 27: hkn0410:1152209:1152209 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 93: hkn0428:659873:659873 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
 59: hkn0419:1536808:1536808 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 59: hkn0419:1536808:1536808 [3] NCCL INFO P2P plugin IBext
 71: hkn0422:4145519:4145519 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 71: hkn0422:4145519:4145519 [3] NCCL INFO P2P plugin IBext
 66: hkn0421:2172265:2172265 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 66: hkn0421:2172265:2172265 [2] NCCL INFO P2P plugin IBext
134: hkn0510:2754583:2754583 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
104: hkn0503:2892170:2892170 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
104: hkn0503:2892170:2892170 [0] NCCL INFO Using network IBext
105: hkn0503:2892162:2892162 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
105: hkn0503:2892162:2892162 [1] NCCL INFO Using network IBext
 58: hkn0419:1536809:1536809 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 58: hkn0419:1536809:1536809 [2] NCCL INFO P2P plugin IBext
106: hkn0503:2892182:2892182 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.71<0>
106: hkn0503:2892182:2892182 [2] NCCL INFO Using network IBext
 57: hkn0419:1536822:1536822 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 57: hkn0419:1536822:1536822 [1] NCCL INFO P2P plugin IBext
 64: hkn0421:2172277:2172277 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 64: hkn0421:2172277:2172277 [0] NCCL INFO P2P plugin IBext
133: hkn0510:2754575:2754575 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.78<0>
204: hkn0532:916658:916658 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
204: hkn0532:916658:916658 [0] NCCL INFO P2P plugin IBext
 70: hkn0422:4145499:4145499 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 70: hkn0422:4145499:4145499 [2] NCCL INFO P2P plugin IBext
 95: hkn0428:659881:659881 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
 68: hkn0422:4145491:4145491 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 68: hkn0422:4145491:4145491 [0] NCCL INFO P2P plugin IBext
 56: hkn0419:1536810:1536810 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 56: hkn0419:1536810:1536810 [0] NCCL INFO P2P plugin IBext
135: hkn0510:2754567:2754567 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
135: hkn0510:2754567:2754567 [3] NCCL INFO P2P plugin IBext
206: hkn0532:916669:916669 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
206: hkn0532:916669:916669 [2] NCCL INFO P2P plugin IBext
188: hkn0528:1294198:1294198 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
189: hkn0528:1294214:1294214 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
188: hkn0528:1294198:1294198 [0] NCCL INFO Using network IBext
189: hkn0528:1294214:1294214 [1] NCCL INFO Using network IBext
205: hkn0532:916650:916650 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
205: hkn0532:916650:916650 [1] NCCL INFO P2P plugin IBext
144: hkn0513:3005464:3005464 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
 24: hkn0410:1152208:1152208 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 24: hkn0410:1152208:1152208 [0] NCCL INFO P2P plugin IBext
 66: hkn0421:2172265:2172265 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 67: hkn0421:2172249:2172249 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 66: hkn0421:2172265:2172265 [2] NCCL INFO Using network IBext
 67: hkn0421:2172249:2172249 [3] NCCL INFO Using network IBext
 26: hkn0410:1152222:1152222 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
 27: hkn0410:1152209:1152209 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 27: hkn0410:1152209:1152209 [3] NCCL INFO P2P plugin IBext
 64: hkn0421:2172277:2172277 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 64: hkn0421:2172277:2172277 [0] NCCL INFO Using network IBext
 93: hkn0428:659873:659873 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 93: hkn0428:659873:659873 [1] NCCL INFO P2P plugin IBext
116: hkn0506:830570:830570 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
134: hkn0510:2754583:2754583 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
134: hkn0510:2754583:2754583 [2] NCCL INFO P2P plugin IBext
118: hkn0506:830582:830582 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 58: hkn0419:1536809:1536809 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 58: hkn0419:1536809:1536809 [2] NCCL INFO Using network IBext
145: hkn0513:3005445:3005445 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
 57: hkn0419:1536822:1536822 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 57: hkn0419:1536822:1536822 [1] NCCL INFO Using network IBext
132: hkn0510:2754595:2754595 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
132: hkn0510:2754595:2754595 [0] NCCL INFO Using network IBext
 65: hkn0421:2172257:2172257 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.53<0>
 65: hkn0421:2172257:2172257 [1] NCCL INFO Using network IBext
191: hkn0528:1294226:1294226 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
191: hkn0528:1294226:1294226 [3] NCCL INFO Using network IBext
 56: hkn0419:1536810:1536810 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 56: hkn0419:1536810:1536810 [0] NCCL INFO Using network IBext
135: hkn0510:2754567:2754567 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
135: hkn0510:2754567:2754567 [3] NCCL INFO Using network IBext
190: hkn0528:1294206:1294206 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.96<0>
190: hkn0528:1294206:1294206 [2] NCCL INFO Using network IBext
206: hkn0532:916669:916669 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
206: hkn0532:916669:916669 [2] NCCL INFO Using network IBext
133: hkn0510:2754575:2754575 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
133: hkn0510:2754575:2754575 [1] NCCL INFO P2P plugin IBext
 92: hkn0428:659865:659865 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
 68: hkn0422:4145491:4145491 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 70: hkn0422:4145499:4145499 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 68: hkn0422:4145491:4145491 [0] NCCL INFO Using network IBext
 70: hkn0422:4145499:4145499 [2] NCCL INFO Using network IBext
 25: hkn0410:1152210:1152210 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.42<0>
204: hkn0532:916658:916658 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
204: hkn0532:916658:916658 [0] NCCL INFO Using network IBext
205: hkn0532:916650:916650 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
205: hkn0532:916650:916650 [1] NCCL INFO Using network IBext
146: hkn0513:3005437:3005437 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.81<0>
 95: hkn0428:659881:659881 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 95: hkn0428:659881:659881 [3] NCCL INFO P2P plugin IBext
  5: hkn0404:1331860:1331860 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
222: hkn0602:3353974:3353974 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
134: hkn0510:2754583:2754583 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
134: hkn0510:2754583:2754583 [2] NCCL INFO Using network IBext
207: hkn0532:916642:916642 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.100<0>
  7: hkn0404:1331852:1331852 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
207: hkn0532:916642:916642 [3] NCCL INFO Using network IBext
144: hkn0513:3005464:3005464 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
144: hkn0513:3005464:3005464 [0] NCCL INFO P2P plugin IBext
147: hkn0513:3005453:3005453 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
147: hkn0513:3005453:3005453 [3] NCCL INFO Using network IBext
 26: hkn0410:1152222:1152222 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 26: hkn0410:1152222:1152222 [2] NCCL INFO P2P plugin IBext
  4: hkn0404:1331872:1331872 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
133: hkn0510:2754575:2754575 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.78<0>
133: hkn0510:2754575:2754575 [1] NCCL INFO Using network IBext
 69: hkn0422:4145507:4145507 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 69: hkn0422:4145507:4145507 [1] NCCL INFO Using network IBext
119: hkn0506:830554:830554 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 59: hkn0419:1536808:1536808 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.51<0>
 59: hkn0419:1536808:1536808 [3] NCCL INFO Using network IBext
 71: hkn0422:4145519:4145519 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.54<0>
 71: hkn0422:4145519:4145519 [3] NCCL INFO Using network IBext
145: hkn0513:3005445:3005445 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
145: hkn0513:3005445:3005445 [1] NCCL INFO P2P plugin IBext
118: hkn0506:830582:830582 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
118: hkn0506:830582:830582 [2] NCCL INFO P2P plugin IBext
 94: hkn0428:659895:659895 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.60<0>
223: hkn0602:3353954:3353954 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
 92: hkn0428:659865:659865 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 92: hkn0428:659865:659865 [0] NCCL INFO P2P plugin IBext
116: hkn0506:830570:830570 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
116: hkn0506:830570:830570 [0] NCCL INFO P2P plugin IBext
 25: hkn0410:1152210:1152210 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 25: hkn0410:1152210:1152210 [1] NCCL INFO P2P plugin IBext
 95: hkn0428:659881:659881 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 95: hkn0428:659881:659881 [3] NCCL INFO Using network IBext
146: hkn0513:3005437:3005437 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
146: hkn0513:3005437:3005437 [2] NCCL INFO P2P plugin IBext
144: hkn0513:3005464:3005464 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
144: hkn0513:3005464:3005464 [0] NCCL INFO Using network IBext
  6: hkn0404:1331844:1331844 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.36<0>
221: hkn0602:3353962:3353962 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
  5: hkn0404:1331860:1331860 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  5: hkn0404:1331860:1331860 [1] NCCL INFO P2P plugin IBext
220: hkn0602:3353946:3353946 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.106<0>
222: hkn0602:3353974:3353974 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
222: hkn0602:3353974:3353974 [2] NCCL INFO P2P plugin IBext
145: hkn0513:3005445:3005445 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
145: hkn0513:3005445:3005445 [1] NCCL INFO Using network IBext
  7: hkn0404:1331852:1331852 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  7: hkn0404:1331852:1331852 [3] NCCL INFO P2P plugin IBext
 26: hkn0410:1152222:1152222 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 26: hkn0410:1152222:1152222 [2] NCCL INFO Using network IBext
 24: hkn0410:1152208:1152208 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 24: hkn0410:1152208:1152208 [0] NCCL INFO Using network IBext
117: hkn0506:830562:830562 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.74<0>
 27: hkn0410:1152209:1152209 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 27: hkn0410:1152209:1152209 [3] NCCL INFO Using network IBext
119: hkn0506:830554:830554 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
119: hkn0506:830554:830554 [3] NCCL INFO P2P plugin IBext
 92: hkn0428:659865:659865 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 92: hkn0428:659865:659865 [0] NCCL INFO Using network IBext
 93: hkn0428:659873:659873 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 93: hkn0428:659873:659873 [1] NCCL INFO Using network IBext
 25: hkn0410:1152210:1152210 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.42<0>
 25: hkn0410:1152210:1152210 [1] NCCL INFO Using network IBext
 94: hkn0428:659895:659895 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 94: hkn0428:659895:659895 [2] NCCL INFO P2P plugin IBext
146: hkn0513:3005437:3005437 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.81<0>
146: hkn0513:3005437:3005437 [2] NCCL INFO Using network IBext
  4: hkn0404:1331872:1331872 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  4: hkn0404:1331872:1331872 [0] NCCL INFO P2P plugin IBext
478: hkn0806:1046839:1046839 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
223: hkn0602:3353954:3353954 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
223: hkn0602:3353954:3353954 [3] NCCL INFO P2P plugin IBext
116: hkn0506:830570:830570 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
116: hkn0506:830570:830570 [0] NCCL INFO Using network IBext
  6: hkn0404:1331844:1331844 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
  6: hkn0404:1331844:1331844 [2] NCCL INFO P2P plugin IBext
221: hkn0602:3353962:3353962 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
221: hkn0602:3353962:3353962 [1] NCCL INFO P2P plugin IBext
119: hkn0506:830554:830554 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
119: hkn0506:830554:830554 [3] NCCL INFO Using network IBext
220: hkn0602:3353946:3353946 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
220: hkn0602:3353946:3353946 [0] NCCL INFO P2P plugin IBext
 94: hkn0428:659895:659895 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.60<0>
 94: hkn0428:659895:659895 [2] NCCL INFO Using network IBext
117: hkn0506:830562:830562 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
117: hkn0506:830562:830562 [1] NCCL INFO P2P plugin IBext
118: hkn0506:830582:830582 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
118: hkn0506:830582:830582 [2] NCCL INFO Using network IBext
  4: hkn0404:1331872:1331872 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  4: hkn0404:1331872:1331872 [0] NCCL INFO Using network IBext
478: hkn0806:1046839:1046839 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
478: hkn0806:1046839:1046839 [2] NCCL INFO P2P plugin IBext
223: hkn0602:3353954:3353954 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
223: hkn0602:3353954:3353954 [3] NCCL INFO Using network IBext
477: hkn0806:1046851:1046851 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
  6: hkn0404:1331844:1331844 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  6: hkn0404:1331844:1331844 [2] NCCL INFO Using network IBext
221: hkn0602:3353962:3353962 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
221: hkn0602:3353962:3353962 [1] NCCL INFO Using network IBext
479: hkn0806:1046823:1046823 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
220: hkn0602:3353946:3353946 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
220: hkn0602:3353946:3353946 [0] NCCL INFO Using network IBext
234: hkn0605:704621:704621 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
476: hkn0806:1046831:1046831 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.182<0>
117: hkn0506:830562:830562 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.74<0>
117: hkn0506:830562:830562 [1] NCCL INFO Using network IBext
312: hkn0631:1014294:1014294 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
222: hkn0602:3353974:3353974 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.106<0>
222: hkn0602:3353974:3353974 [2] NCCL INFO Using network IBext
  7: hkn0404:1331852:1331852 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  7: hkn0404:1331852:1331852 [3] NCCL INFO Using network IBext
  5: hkn0404:1331860:1331860 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.36<0>
  5: hkn0404:1331860:1331860 [1] NCCL INFO Using network IBext
270: hkn0616:397349:397349 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
268: hkn0616:397357:397357 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
477: hkn0806:1046851:1046851 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
477: hkn0806:1046851:1046851 [1] NCCL INFO P2P plugin IBext
202: hkn0531:1223078:1223078 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
271: hkn0616:397365:397365 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
479: hkn0806:1046823:1046823 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
479: hkn0806:1046823:1046823 [3] NCCL INFO P2P plugin IBext
315: hkn0631:1014310:1014310 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
234: hkn0605:704621:704621 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
234: hkn0605:704621:704621 [2] NCCL INFO P2P plugin IBext
476: hkn0806:1046831:1046831 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
476: hkn0806:1046831:1046831 [0] NCCL INFO P2P plugin IBext
233: hkn0605:704610:704610 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
312: hkn0631:1014294:1014294 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
312: hkn0631:1014294:1014294 [0] NCCL INFO P2P plugin IBext
201: hkn0531:1223094:1223094 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
270: hkn0616:397349:397349 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
270: hkn0616:397349:397349 [2] NCCL INFO P2P plugin IBext
232: hkn0605:704594:704594 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
268: hkn0616:397357:397357 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
268: hkn0616:397357:397357 [0] NCCL INFO P2P plugin IBext
269: hkn0616:397377:397377 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.120<0>
235: hkn0605:704602:704602 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.109<0>
479: hkn0806:1046823:1046823 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
477: hkn0806:1046851:1046851 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
479: hkn0806:1046823:1046823 [3] NCCL INFO Using network IBext
477: hkn0806:1046851:1046851 [1] NCCL INFO Using network IBext
478: hkn0806:1046839:1046839 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
478: hkn0806:1046839:1046839 [2] NCCL INFO Using network IBext
214: hkn0535:2391519:2391519 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
476: hkn0806:1046831:1046831 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.182<0>
476: hkn0806:1046831:1046831 [0] NCCL INFO Using network IBext
314: hkn0631:1014322:1014322 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
271: hkn0616:397365:397365 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
271: hkn0616:397365:397365 [3] NCCL INFO P2P plugin IBext
202: hkn0531:1223078:1223078 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
202: hkn0531:1223078:1223078 [2] NCCL INFO P2P plugin IBext
315: hkn0631:1014310:1014310 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
315: hkn0631:1014310:1014310 [3] NCCL INFO P2P plugin IBext
313: hkn0631:1014302:1014302 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.135<0>
233: hkn0605:704610:704610 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
233: hkn0605:704610:704610 [1] NCCL INFO P2P plugin IBext
201: hkn0531:1223094:1223094 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
201: hkn0531:1223094:1223094 [1] NCCL INFO P2P plugin IBext
215: hkn0535:2391507:2391507 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
203: hkn0531:1223106:1223106 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
232: hkn0605:704594:704594 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
232: hkn0605:704594:704594 [0] NCCL INFO P2P plugin IBext
 90: hkn0427:1127651:1127651 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
269: hkn0616:397377:397377 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
269: hkn0616:397377:397377 [1] NCCL INFO P2P plugin IBext
213: hkn0535:2391499:2391499 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
235: hkn0605:704602:704602 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
235: hkn0605:704602:704602 [3] NCCL INFO P2P plugin IBext
214: hkn0535:2391519:2391519 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
214: hkn0535:2391519:2391519 [2] NCCL INFO P2P plugin IBext
212: hkn0535:2391491:2391491 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.103<0>
200: hkn0531:1223086:1223086 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.99<0>
314: hkn0631:1014322:1014322 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
314: hkn0631:1014322:1014322 [2] NCCL INFO P2P plugin IBext
315: hkn0631:1014310:1014310 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
315: hkn0631:1014310:1014310 [3] NCCL INFO Using network IBext
271: hkn0616:397365:397365 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
271: hkn0616:397365:397365 [3] NCCL INFO Using network IBext
233: hkn0605:704610:704610 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
233: hkn0605:704610:704610 [1] NCCL INFO Using network IBext
313: hkn0631:1014302:1014302 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
313: hkn0631:1014302:1014302 [1] NCCL INFO P2P plugin IBext
232: hkn0605:704594:704594 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
232: hkn0605:704594:704594 [0] NCCL INFO Using network IBext
234: hkn0605:704621:704621 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
234: hkn0605:704621:704621 [2] NCCL INFO Using network IBext
312: hkn0631:1014294:1014294 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
312: hkn0631:1014294:1014294 [0] NCCL INFO Using network IBext
201: hkn0531:1223094:1223094 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
201: hkn0531:1223094:1223094 [1] NCCL INFO Using network IBext
263: hkn0613:895167:895167 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
331: hkn0635:1218123:1218123 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
269: hkn0616:397377:397377 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
269: hkn0616:397377:397377 [1] NCCL INFO Using network IBext
235: hkn0605:704602:704602 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.109<0>
235: hkn0605:704602:704602 [3] NCCL INFO Using network IBext
330: hkn0635:1218111:1218111 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
215: hkn0535:2391507:2391507 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
215: hkn0535:2391507:2391507 [3] NCCL INFO P2P plugin IBext
268: hkn0616:397357:397357 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
268: hkn0616:397357:397357 [0] NCCL INFO Using network IBext
314: hkn0631:1014322:1014322 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
314: hkn0631:1014322:1014322 [2] NCCL INFO Using network IBext
203: hkn0531:1223106:1223106 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
203: hkn0531:1223106:1223106 [3] NCCL INFO P2P plugin IBext
261: hkn0613:895175:895175 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
 90: hkn0427:1127651:1127651 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
270: hkn0616:397349:397349 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.120<0>
 90: hkn0427:1127651:1127651 [2] NCCL INFO P2P plugin IBext
270: hkn0616:397349:397349 [2] NCCL INFO Using network IBext
213: hkn0535:2391499:2391499 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
213: hkn0535:2391499:2391499 [1] NCCL INFO P2P plugin IBext
212: hkn0535:2391491:2391491 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
212: hkn0535:2391491:2391491 [0] NCCL INFO P2P plugin IBext
313: hkn0631:1014302:1014302 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.135<0>
313: hkn0631:1014302:1014302 [1] NCCL INFO Using network IBext
260: hkn0613:895195:895195 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
200: hkn0531:1223086:1223086 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
200: hkn0531:1223086:1223086 [0] NCCL INFO P2P plugin IBext
262: hkn0613:895183:895183 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.117<0>
 88: hkn0427:1127643:1127643 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
202: hkn0531:1223078:1223078 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
202: hkn0531:1223078:1223078 [2] NCCL INFO Using network IBext
203: hkn0531:1223106:1223106 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
203: hkn0531:1223106:1223106 [3] NCCL INFO Using network IBext
263: hkn0613:895167:895167 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
263: hkn0613:895167:895167 [3] NCCL INFO P2P plugin IBext
445: hkn0733:1381907:1381907 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
331: hkn0635:1218123:1218123 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
331: hkn0635:1218123:1218123 [3] NCCL INFO P2P plugin IBext
213: hkn0535:2391499:2391499 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
213: hkn0535:2391499:2391499 [1] NCCL INFO Using network IBext
215: hkn0535:2391507:2391507 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
215: hkn0535:2391507:2391507 [3] NCCL INFO Using network IBext
330: hkn0635:1218111:1218111 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
330: hkn0635:1218111:1218111 [2] NCCL INFO P2P plugin IBext
212: hkn0535:2391491:2391491 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
212: hkn0535:2391491:2391491 [0] NCCL INFO Using network IBext
200: hkn0531:1223086:1223086 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.99<0>
200: hkn0531:1223086:1223086 [0] NCCL INFO Using network IBext
261: hkn0613:895175:895175 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
261: hkn0613:895175:895175 [1] NCCL INFO P2P plugin IBext
103: hkn0502:221563:221563 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
402: hkn0720:4190312:4190312 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
400: hkn0720:4190315:4190315 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
214: hkn0535:2391519:2391519 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.103<0>
214: hkn0535:2391519:2391519 [2] NCCL INFO Using network IBext
336: hkn0703:733512:733512 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
260: hkn0613:895195:895195 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
260: hkn0613:895195:895195 [0] NCCL INFO P2P plugin IBext
102: hkn0502:221554:221554 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
 88: hkn0427:1127643:1127643 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 88: hkn0427:1127643:1127643 [0] NCCL INFO P2P plugin IBext
344: hkn0705:775713:775713 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
262: hkn0613:895183:895183 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
262: hkn0613:895183:895183 [2] NCCL INFO P2P plugin IBext
403: hkn0720:4190335:4190335 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
345: hkn0705:775705:775705 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
347: hkn0705:775733:775733 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
346: hkn0705:775721:775721 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.145<0>
401: hkn0720:4190323:4190323 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.160<0>
445: hkn0733:1381907:1381907 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
445: hkn0733:1381907:1381907 [1] NCCL INFO P2P plugin IBext
101: hkn0502:221555:221555 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
444: hkn0733:1381919:1381919 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
447: hkn0733:1381891:1381891 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
446: hkn0733:1381899:1381899 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.173<0>
338: hkn0703:733524:733524 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
100: hkn0502:221575:221575 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.70<0>
261: hkn0613:895175:895175 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
261: hkn0613:895175:895175 [1] NCCL INFO Using network IBext
260: hkn0613:895195:895195 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
260: hkn0613:895195:895195 [0] NCCL INFO Using network IBext
103: hkn0502:221563:221563 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
103: hkn0502:221563:221563 [3] NCCL INFO P2P plugin IBext
439: hkn0731:1379236:1379236 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
262: hkn0613:895183:895183 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
262: hkn0613:895183:895183 [2] NCCL INFO Using network IBext
402: hkn0720:4190312:4190312 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
402: hkn0720:4190312:4190312 [2] NCCL INFO P2P plugin IBext
 91: hkn0427:1127642:1127642 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
400: hkn0720:4190315:4190315 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
400: hkn0720:4190315:4190315 [0] NCCL INFO P2P plugin IBext
168: hkn0523:1540548:1540548 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
 90: hkn0427:1127651:1127651 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 90: hkn0427:1127651:1127651 [2] NCCL INFO Using network IBext
 88: hkn0427:1127643:1127643 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 88: hkn0427:1127643:1127643 [0] NCCL INFO Using network IBext
336: hkn0703:733512:733512 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
336: hkn0703:733512:733512 [0] NCCL INFO P2P plugin IBext
 89: hkn0427:1127663:1127663 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.59<0>
344: hkn0705:775713:775713 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
344: hkn0705:775713:775713 [0] NCCL INFO P2P plugin IBext
403: hkn0720:4190335:4190335 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
403: hkn0720:4190335:4190335 [3] NCCL INFO P2P plugin IBext
345: hkn0705:775705:775705 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
345: hkn0705:775705:775705 [1] NCCL INFO P2P plugin IBext
346: hkn0705:775721:775721 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
346: hkn0705:775721:775721 [2] NCCL INFO P2P plugin IBext
401: hkn0720:4190323:4190323 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
401: hkn0720:4190323:4190323 [1] NCCL INFO P2P plugin IBext
102: hkn0502:221554:221554 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
102: hkn0502:221554:221554 [2] NCCL INFO P2P plugin IBext
436: hkn0731:1379234:1379234 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
347: hkn0705:775733:775733 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
347: hkn0705:775733:775733 [3] NCCL INFO P2P plugin IBext
444: hkn0733:1381919:1381919 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
444: hkn0733:1381919:1381919 [0] NCCL INFO P2P plugin IBext
447: hkn0733:1381891:1381891 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
447: hkn0733:1381891:1381891 [3] NCCL INFO P2P plugin IBext
171: hkn0523:1540540:1540540 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
446: hkn0733:1381899:1381899 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
446: hkn0733:1381899:1381899 [2] NCCL INFO P2P plugin IBext
101: hkn0502:221555:221555 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
101: hkn0502:221555:221555 [1] NCCL INFO P2P plugin IBext
263: hkn0613:895167:895167 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.117<0>
263: hkn0613:895167:895167 [3] NCCL INFO Using network IBext
338: hkn0703:733524:733524 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
338: hkn0703:733524:733524 [2] NCCL INFO P2P plugin IBext
100: hkn0502:221575:221575 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
100: hkn0502:221575:221575 [0] NCCL INFO P2P plugin IBext
337: hkn0703:733504:733504 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
170: hkn0523:1540556:1540556 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
439: hkn0731:1379236:1379236 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
439: hkn0731:1379236:1379236 [3] NCCL INFO P2P plugin IBext
473: hkn0805:1104610:1104610 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
 91: hkn0427:1127642:1127642 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 91: hkn0427:1127642:1127642 [3] NCCL INFO P2P plugin IBext
330: hkn0635:1218111:1218111 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
330: hkn0635:1218111:1218111 [2] NCCL INFO Using network IBext
331: hkn0635:1218123:1218123 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
331: hkn0635:1218123:1218123 [3] NCCL INFO Using network IBext
437: hkn0731:1379256:1379256 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
339: hkn0703:733496:733496 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.143<0>
168: hkn0523:1540548:1540548 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
168: hkn0523:1540548:1540548 [0] NCCL INFO P2P plugin IBext
 44: hkn0415:2488950:2488950 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
169: hkn0523:1540568:1540568 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.91<0>
403: hkn0720:4190335:4190335 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
401: hkn0720:4190323:4190323 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
403: hkn0720:4190335:4190335 [3] NCCL INFO Using network IBext
401: hkn0720:4190323:4190323 [1] NCCL INFO Using network IBext
 89: hkn0427:1127663:1127663 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 89: hkn0427:1127663:1127663 [1] NCCL INFO P2P plugin IBext
328: hkn0635:1218095:1218095 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
 47: hkn0415:2488934:2488934 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
317: hkn0632:1751107:1751107 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
101: hkn0502:221555:221555 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
438: hkn0731:1379244:1379244 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.171<0>
102: hkn0502:221554:221554 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
101: hkn0502:221555:221555 [1] NCCL INFO Using network IBext
347: hkn0705:775733:775733 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
102: hkn0502:221554:221554 [2] NCCL INFO Using network IBext
436: hkn0731:1379234:1379234 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
436: hkn0731:1379234:1379234 [0] NCCL INFO P2P plugin IBext
100: hkn0502:221575:221575 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
347: hkn0705:775733:775733 [3] NCCL INFO Using network IBext
100: hkn0502:221575:221575 [0] NCCL INFO Using network IBext
472: hkn0805:1104602:1104602 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
447: hkn0733:1381891:1381891 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
447: hkn0733:1381891:1381891 [3] NCCL INFO Using network IBext
338: hkn0703:733524:733524 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
446: hkn0733:1381899:1381899 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
446: hkn0733:1381899:1381899 [2] NCCL INFO Using network IBext
338: hkn0703:733524:733524 [2] NCCL INFO Using network IBext
444: hkn0733:1381919:1381919 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
444: hkn0733:1381919:1381919 [0] NCCL INFO Using network IBext
171: hkn0523:1540540:1540540 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
171: hkn0523:1540540:1540540 [3] NCCL INFO P2P plugin IBext
319: hkn0632:1751115:1751115 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
445: hkn0733:1381907:1381907 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.173<0>
277: hkn0621:1984016:1984016 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
445: hkn0733:1381907:1381907 [1] NCCL INFO Using network IBext
316: hkn0632:1751127:1751127 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
279: hkn0621:1984024:1984024 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
 91: hkn0427:1127642:1127642 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 91: hkn0427:1127642:1127642 [3] NCCL INFO Using network IBext
337: hkn0703:733504:733504 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
337: hkn0703:733504:733504 [1] NCCL INFO P2P plugin IBext
329: hkn0635:1218103:1218103 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.139<0>
 46: hkn0415:2488942:2488942 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
276: hkn0621:1984044:1984044 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
 45: hkn0415:2488962:2488962 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.47<0>
473: hkn0805:1104610:1104610 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
473: hkn0805:1104610:1104610 [1] NCCL INFO P2P plugin IBext
 89: hkn0427:1127663:1127663 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.59<0>
 89: hkn0427:1127663:1127663 [1] NCCL INFO Using network IBext
170: hkn0523:1540556:1540556 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
170: hkn0523:1540556:1540556 [2] NCCL INFO P2P plugin IBext
318: hkn0632:1751099:1751099 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.136<0>
402: hkn0720:4190312:4190312 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
402: hkn0720:4190312:4190312 [2] NCCL INFO Using network IBext
400: hkn0720:4190315:4190315 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.160<0>
400: hkn0720:4190315:4190315 [0] NCCL INFO Using network IBext
 73: hkn0423:1697346:1697346 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
103: hkn0502:221563:221563 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.70<0>
103: hkn0502:221563:221563 [3] NCCL INFO Using network IBext
437: hkn0731:1379256:1379256 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
437: hkn0731:1379256:1379256 [1] NCCL INFO P2P plugin IBext
 44: hkn0415:2488950:2488950 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 44: hkn0415:2488950:2488950 [0] NCCL INFO P2P plugin IBext
339: hkn0703:733496:733496 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
339: hkn0703:733496:733496 [3] NCCL INFO P2P plugin IBext
336: hkn0703:733512:733512 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
336: hkn0703:733512:733512 [0] NCCL INFO Using network IBext
169: hkn0523:1540568:1540568 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
169: hkn0523:1540568:1540568 [1] NCCL INFO P2P plugin IBext
337: hkn0703:733504:733504 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
337: hkn0703:733504:733504 [1] NCCL INFO Using network IBext
 47: hkn0415:2488934:2488934 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 47: hkn0415:2488934:2488934 [3] NCCL INFO P2P plugin IBext
438: hkn0731:1379244:1379244 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
438: hkn0731:1379244:1379244 [2] NCCL INFO P2P plugin IBext
317: hkn0632:1751107:1751107 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
317: hkn0632:1751107:1751107 [1] NCCL INFO P2P plugin IBext
436: hkn0731:1379234:1379234 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
436: hkn0731:1379234:1379234 [0] NCCL INFO Using network IBext
472: hkn0805:1104602:1104602 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
472: hkn0805:1104602:1104602 [0] NCCL INFO P2P plugin IBext
344: hkn0705:775713:775713 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
344: hkn0705:775713:775713 [0] NCCL INFO Using network IBext
346: hkn0705:775721:775721 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
346: hkn0705:775721:775721 [2] NCCL INFO Using network IBext
345: hkn0705:775705:775705 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.145<0>
345: hkn0705:775705:775705 [1] NCCL INFO Using network IBext
171: hkn0523:1540540:1540540 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
171: hkn0523:1540540:1540540 [3] NCCL INFO Using network IBext
277: hkn0621:1984016:1984016 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
277: hkn0621:1984016:1984016 [1] NCCL INFO P2P plugin IBext
278: hkn0621:1984032:1984032 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.125<0>
328: hkn0635:1218095:1218095 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
170: hkn0523:1540556:1540556 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
328: hkn0635:1218095:1218095 [0] NCCL INFO P2P plugin IBext
170: hkn0523:1540556:1540556 [2] NCCL INFO Using network IBext
475: hkn0805:1104618:1104618 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
319: hkn0632:1751115:1751115 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
319: hkn0632:1751115:1751115 [3] NCCL INFO P2P plugin IBext
316: hkn0632:1751127:1751127 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
316: hkn0632:1751127:1751127 [0] NCCL INFO P2P plugin IBext
279: hkn0621:1984024:1984024 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
279: hkn0621:1984024:1984024 [3] NCCL INFO P2P plugin IBext
390: hkn0717:4180120:4180120 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
437: hkn0731:1379256:1379256 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
437: hkn0731:1379256:1379256 [1] NCCL INFO Using network IBext
391: hkn0717:4180108:4180108 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
339: hkn0703:733496:733496 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.143<0>
339: hkn0703:733496:733496 [3] NCCL INFO Using network IBext
276: hkn0621:1984044:1984044 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
276: hkn0621:1984044:1984044 [0] NCCL INFO P2P plugin IBext
169: hkn0523:1540568:1540568 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
169: hkn0523:1540568:1540568 [1] NCCL INFO Using network IBext
389: hkn0717:4180100:4180100 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
 45: hkn0415:2488962:2488962 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 45: hkn0415:2488962:2488962 [1] NCCL INFO P2P plugin IBext
 46: hkn0415:2488942:2488942 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 46: hkn0415:2488942:2488942 [2] NCCL INFO P2P plugin IBext
439: hkn0731:1379236:1379236 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
439: hkn0731:1379236:1379236 [3] NCCL INFO Using network IBext
318: hkn0632:1751099:1751099 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
318: hkn0632:1751099:1751099 [2] NCCL INFO P2P plugin IBext
329: hkn0635:1218103:1218103 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
329: hkn0635:1218103:1218103 [1] NCCL INFO P2P plugin IBext
438: hkn0731:1379244:1379244 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.171<0>
438: hkn0731:1379244:1379244 [2] NCCL INFO Using network IBext
168: hkn0523:1540548:1540548 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.91<0>
168: hkn0523:1540548:1540548 [0] NCCL INFO Using network IBext
303: hkn0628:664365:664365 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
474: hkn0805:1104630:1104630 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.181<0>
 73: hkn0423:1697346:1697346 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 73: hkn0423:1697346:1697346 [1] NCCL INFO P2P plugin IBext
 47: hkn0415:2488934:2488934 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 47: hkn0415:2488934:2488934 [3] NCCL INFO Using network IBext
472: hkn0805:1104602:1104602 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
472: hkn0805:1104602:1104602 [0] NCCL INFO Using network IBext
301: hkn0628:664357:664357 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
328: hkn0635:1218095:1218095 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
328: hkn0635:1218095:1218095 [0] NCCL INFO Using network IBext
475: hkn0805:1104618:1104618 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
475: hkn0805:1104618:1104618 [3] NCCL INFO P2P plugin IBext
 45: hkn0415:2488962:2488962 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
278: hkn0621:1984032:1984032 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
278: hkn0621:1984032:1984032 [2] NCCL INFO P2P plugin IBext
 45: hkn0415:2488962:2488962 [1] NCCL INFO Using network IBext
 46: hkn0415:2488942:2488942 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 46: hkn0415:2488942:2488942 [2] NCCL INFO Using network IBext
316: hkn0632:1751127:1751127 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
316: hkn0632:1751127:1751127 [0] NCCL INFO Using network IBext
319: hkn0632:1751115:1751115 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
319: hkn0632:1751115:1751115 [3] NCCL INFO Using network IBext
318: hkn0632:1751099:1751099 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
318: hkn0632:1751099:1751099 [2] NCCL INFO Using network IBext
390: hkn0717:4180120:4180120 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
390: hkn0717:4180120:4180120 [2] NCCL INFO P2P plugin IBext
 72: hkn0423:1697374:1697374 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
329: hkn0635:1218103:1218103 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.139<0>
329: hkn0635:1218103:1218103 [1] NCCL INFO Using network IBext
276: hkn0621:1984044:1984044 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
276: hkn0621:1984044:1984044 [0] NCCL INFO Using network IBext
391: hkn0717:4180108:4180108 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
391: hkn0717:4180108:4180108 [3] NCCL INFO P2P plugin IBext
389: hkn0717:4180100:4180100 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
389: hkn0717:4180100:4180100 [1] NCCL INFO P2P plugin IBext
 74: hkn0423:1697354:1697354 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
473: hkn0805:1104610:1104610 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
473: hkn0805:1104610:1104610 [1] NCCL INFO Using network IBext
388: hkn0717:4180092:4180092 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.157<0>
307: hkn0629:1584544:1584544 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
474: hkn0805:1104630:1104630 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
474: hkn0805:1104630:1104630 [2] NCCL INFO P2P plugin IBext
303: hkn0628:664365:664365 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
303: hkn0628:664365:664365 [3] NCCL INFO P2P plugin IBext
 44: hkn0415:2488950:2488950 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.47<0>
 44: hkn0415:2488950:2488950 [0] NCCL INFO Using network IBext
475: hkn0805:1104618:1104618 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
475: hkn0805:1104618:1104618 [3] NCCL INFO Using network IBext
278: hkn0621:1984032:1984032 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
278: hkn0621:1984032:1984032 [2] NCCL INFO Using network IBext
302: hkn0628:664349:664349 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
317: hkn0632:1751107:1751107 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.136<0>
317: hkn0632:1751107:1751107 [1] NCCL INFO Using network IBext
301: hkn0628:664357:664357 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
301: hkn0628:664357:664357 [1] NCCL INFO P2P plugin IBext
279: hkn0621:1984024:1984024 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
279: hkn0621:1984024:1984024 [3] NCCL INFO Using network IBext
306: hkn0629:1584560:1584560 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
277: hkn0621:1984016:1984016 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.125<0>
277: hkn0621:1984016:1984016 [1] NCCL INFO Using network IBext
474: hkn0805:1104630:1104630 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.181<0>
474: hkn0805:1104630:1104630 [2] NCCL INFO Using network IBext
300: hkn0628:664377:664377 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.132<0>
389: hkn0717:4180100:4180100 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
391: hkn0717:4180108:4180108 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
389: hkn0717:4180100:4180100 [1] NCCL INFO Using network IBext
305: hkn0629:1584572:1584572 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
391: hkn0717:4180108:4180108 [3] NCCL INFO Using network IBext
 72: hkn0423:1697374:1697374 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 72: hkn0423:1697374:1697374 [0] NCCL INFO P2P plugin IBext
 75: hkn0423:1697362:1697362 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.55<0>
510: hkn0816:368135:368135 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
503: hkn0814:668359:668359 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
511: hkn0816:368147:368147 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
 74: hkn0423:1697354:1697354 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 74: hkn0423:1697354:1697354 [2] NCCL INFO P2P plugin IBext
388: hkn0717:4180092:4180092 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
388: hkn0717:4180092:4180092 [0] NCCL INFO P2P plugin IBext
307: hkn0629:1584544:1584544 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
307: hkn0629:1584544:1584544 [3] NCCL INFO P2P plugin IBext
508: hkn0816:368125:368125 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
509: hkn0816:368127:368127 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.192<0>
 78: hkn0424:2940433:2940433 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
304: hkn0629:1584552:1584552 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.133<0>
301: hkn0628:664357:664357 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
301: hkn0628:664357:664357 [1] NCCL INFO Using network IBext
302: hkn0628:664349:664349 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
302: hkn0628:664349:664349 [2] NCCL INFO P2P plugin IBext
 77: hkn0424:2940449:2940449 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
 72: hkn0423:1697374:1697374 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 73: hkn0423:1697346:1697346 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 72: hkn0423:1697374:1697374 [0] NCCL INFO Using network IBext
 73: hkn0423:1697346:1697346 [1] NCCL INFO Using network IBext
227: hkn0603:1405656:1405656 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
 79: hkn0424:2940441:2940441 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
 74: hkn0423:1697354:1697354 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 74: hkn0423:1697354:1697354 [2] NCCL INFO Using network IBext
390: hkn0717:4180120:4180120 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
306: hkn0629:1584560:1584560 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
306: hkn0629:1584560:1584560 [2] NCCL INFO P2P plugin IBext
390: hkn0717:4180120:4180120 [2] NCCL INFO Using network IBext
 76: hkn0424:2940461:2940461 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.56<0>
388: hkn0717:4180092:4180092 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.157<0>
388: hkn0717:4180092:4180092 [0] NCCL INFO Using network IBext
300: hkn0628:664377:664377 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
300: hkn0628:664377:664377 [0] NCCL INFO P2P plugin IBext
305: hkn0629:1584572:1584572 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
305: hkn0629:1584572:1584572 [1] NCCL INFO P2P plugin IBext
 75: hkn0423:1697362:1697362 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 75: hkn0423:1697362:1697362 [3] NCCL INFO P2P plugin IBext
501: hkn0814:668331:668331 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
503: hkn0814:668359:668359 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
503: hkn0814:668359:668359 [3] NCCL INFO P2P plugin IBext
500: hkn0814:668339:668339 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
510: hkn0816:368135:368135 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
510: hkn0816:368135:368135 [2] NCCL INFO P2P plugin IBext
302: hkn0628:664349:664349 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
302: hkn0628:664349:664349 [2] NCCL INFO Using network IBext
225: hkn0603:1405664:1405664 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
511: hkn0816:368147:368147 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
511: hkn0816:368147:368147 [3] NCCL INFO P2P plugin IBext
303: hkn0628:664365:664365 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
303: hkn0628:664365:664365 [3] NCCL INFO Using network IBext
508: hkn0816:368125:368125 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
508: hkn0816:368125:368125 [0] NCCL INFO P2P plugin IBext
304: hkn0629:1584552:1584552 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
304: hkn0629:1584552:1584552 [0] NCCL INFO P2P plugin IBext
300: hkn0628:664377:664377 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.132<0>
300: hkn0628:664377:664377 [0] NCCL INFO Using network IBext
 78: hkn0424:2940433:2940433 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 78: hkn0424:2940433:2940433 [2] NCCL INFO P2P plugin IBext
509: hkn0816:368127:368127 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
509: hkn0816:368127:368127 [1] NCCL INFO P2P plugin IBext
 75: hkn0423:1697362:1697362 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.55<0>
 75: hkn0423:1697362:1697362 [3] NCCL INFO Using network IBext
 77: hkn0424:2940449:2940449 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 77: hkn0424:2940449:2940449 [1] NCCL INFO P2P plugin IBext
227: hkn0603:1405656:1405656 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
227: hkn0603:1405656:1405656 [3] NCCL INFO P2P plugin IBext
305: hkn0629:1584572:1584572 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
306: hkn0629:1584560:1584560 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
305: hkn0629:1584572:1584572 [1] NCCL INFO Using network IBext
306: hkn0629:1584560:1584560 [2] NCCL INFO Using network IBext
502: hkn0814:668347:668347 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.190<0>
226: hkn0603:1405672:1405672 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
 79: hkn0424:2940441:2940441 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 79: hkn0424:2940441:2940441 [3] NCCL INFO P2P plugin IBext
224: hkn0603:1405683:1405683 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.107<0>
501: hkn0814:668331:668331 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
501: hkn0814:668331:668331 [1] NCCL INFO P2P plugin IBext
 76: hkn0424:2940461:2940461 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 76: hkn0424:2940461:2940461 [0] NCCL INFO P2P plugin IBext
500: hkn0814:668339:668339 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
500: hkn0814:668339:668339 [0] NCCL INFO P2P plugin IBext
304: hkn0629:1584552:1584552 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
304: hkn0629:1584552:1584552 [0] NCCL INFO Using network IBext
394: hkn0718:3909522:3909522 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
307: hkn0629:1584544:1584544 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.133<0>
307: hkn0629:1584544:1584544 [3] NCCL INFO Using network IBext
225: hkn0603:1405664:1405664 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
225: hkn0603:1405664:1405664 [1] NCCL INFO P2P plugin IBext
508: hkn0816:368125:368125 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
508: hkn0816:368125:368125 [0] NCCL INFO Using network IBext
509: hkn0816:368127:368127 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
509: hkn0816:368127:368127 [1] NCCL INFO Using network IBext
 98: hkn0501:1320364:1320364 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
502: hkn0814:668347:668347 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
502: hkn0814:668347:668347 [2] NCCL INFO P2P plugin IBext
226: hkn0603:1405672:1405672 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
226: hkn0603:1405672:1405672 [2] NCCL INFO P2P plugin IBext
 76: hkn0424:2940461:2940461 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 79: hkn0424:2940441:2940441 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 79: hkn0424:2940441:2940441 [3] NCCL INFO Using network IBext
 76: hkn0424:2940461:2940461 [0] NCCL INFO Using network IBext
224: hkn0603:1405683:1405683 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
224: hkn0603:1405683:1405683 [0] NCCL INFO P2P plugin IBext
486: hkn0808:963183:963183 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
501: hkn0814:668331:668331 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
 97: hkn0501:1320356:1320356 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
500: hkn0814:668339:668339 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
501: hkn0814:668331:668331 [1] NCCL INFO Using network IBext
500: hkn0814:668339:668339 [0] NCCL INFO Using network IBext
 96: hkn0501:1320376:1320376 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
503: hkn0814:668359:668359 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
503: hkn0814:668359:668359 [3] NCCL INFO Using network IBext
394: hkn0718:3909522:3909522 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
394: hkn0718:3909522:3909522 [2] NCCL INFO P2P plugin IBext
225: hkn0603:1405664:1405664 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
225: hkn0603:1405664:1405664 [1] NCCL INFO Using network IBext
510: hkn0816:368135:368135 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
510: hkn0816:368135:368135 [2] NCCL INFO Using network IBext
511: hkn0816:368147:368147 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.192<0>
511: hkn0816:368147:368147 [3] NCCL INFO Using network IBext
395: hkn0718:3909510:3909510 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
502: hkn0814:668347:668347 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.190<0>
502: hkn0814:668347:668347 [2] NCCL INFO Using network IBext
226: hkn0603:1405672:1405672 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
226: hkn0603:1405672:1405672 [2] NCCL INFO Using network IBext
 98: hkn0501:1320364:1320364 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 98: hkn0501:1320364:1320364 [2] NCCL INFO P2P plugin IBext
224: hkn0603:1405683:1405683 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
224: hkn0603:1405683:1405683 [0] NCCL INFO Using network IBext
 99: hkn0501:1320348:1320348 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.69<0>
 77: hkn0424:2940449:2940449 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 77: hkn0424:2940449:2940449 [1] NCCL INFO Using network IBext
 78: hkn0424:2940433:2940433 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.56<0>
 78: hkn0424:2940433:2940433 [2] NCCL INFO Using network IBext
227: hkn0603:1405656:1405656 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.107<0>
227: hkn0603:1405656:1405656 [3] NCCL INFO Using network IBext
486: hkn0808:963183:963183 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
486: hkn0808:963183:963183 [2] NCCL INFO P2P plugin IBext
 97: hkn0501:1320356:1320356 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 97: hkn0501:1320356:1320356 [1] NCCL INFO P2P plugin IBext
 96: hkn0501:1320376:1320376 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 96: hkn0501:1320376:1320376 [0] NCCL INFO P2P plugin IBext
392: hkn0718:3909502:3909502 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
393: hkn0718:3909494:3909494 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.158<0>
395: hkn0718:3909510:3909510 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
395: hkn0718:3909510:3909510 [3] NCCL INFO P2P plugin IBext
487: hkn0808:963175:963175 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
 99: hkn0501:1320348:1320348 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 99: hkn0501:1320348:1320348 [3] NCCL INFO P2P plugin IBext
484: hkn0808:963191:963191 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
485: hkn0808:963203:963203 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.184<0>
 96: hkn0501:1320376:1320376 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 97: hkn0501:1320356:1320356 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 96: hkn0501:1320376:1320376 [0] NCCL INFO Using network IBext
 97: hkn0501:1320356:1320356 [1] NCCL INFO Using network IBext
392: hkn0718:3909502:3909502 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
392: hkn0718:3909502:3909502 [0] NCCL INFO P2P plugin IBext
357: hkn0708:405731:405731 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
 99: hkn0501:1320348:1320348 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 99: hkn0501:1320348:1320348 [3] NCCL INFO Using network IBext
394: hkn0718:3909522:3909522 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
394: hkn0718:3909522:3909522 [2] NCCL INFO Using network IBext
395: hkn0718:3909510:3909510 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
395: hkn0718:3909510:3909510 [3] NCCL INFO Using network IBext
393: hkn0718:3909494:3909494 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
393: hkn0718:3909494:3909494 [1] NCCL INFO P2P plugin IBext
487: hkn0808:963175:963175 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
487: hkn0808:963175:963175 [3] NCCL INFO P2P plugin IBext
162: hkn0520:2705389:2705389 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
 98: hkn0501:1320364:1320364 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.69<0>
 98: hkn0501:1320364:1320364 [2] NCCL INFO Using network IBext
359: hkn0708:405743:405743 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
161: hkn0520:2705368:2705368 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
392: hkn0718:3909502:3909502 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
392: hkn0718:3909502:3909502 [0] NCCL INFO Using network IBext
485: hkn0808:963203:963203 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
485: hkn0808:963203:963203 [1] NCCL INFO P2P plugin IBext
356: hkn0708:405715:405715 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
484: hkn0808:963191:963191 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
484: hkn0808:963191:963191 [0] NCCL INFO P2P plugin IBext
358: hkn0708:405723:405723 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.148<0>
332: hkn0636:1646720:1646720 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
393: hkn0718:3909494:3909494 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.158<0>
393: hkn0718:3909494:3909494 [1] NCCL INFO Using network IBext
357: hkn0708:405731:405731 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
357: hkn0708:405731:405731 [1] NCCL INFO P2P plugin IBext
487: hkn0808:963175:963175 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
487: hkn0808:963175:963175 [3] NCCL INFO Using network IBext
486: hkn0808:963183:963183 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
486: hkn0808:963183:963183 [2] NCCL INFO Using network IBext
162: hkn0520:2705389:2705389 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
162: hkn0520:2705389:2705389 [2] NCCL INFO P2P plugin IBext
485: hkn0808:963203:963203 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
485: hkn0808:963203:963203 [1] NCCL INFO Using network IBext
484: hkn0808:963191:963191 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.184<0>
484: hkn0808:963191:963191 [0] NCCL INFO Using network IBext
359: hkn0708:405743:405743 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
359: hkn0708:405743:405743 [3] NCCL INFO P2P plugin IBext
 53: hkn0418:1861667:1861667 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
161: hkn0520:2705368:2705368 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
161: hkn0520:2705368:2705368 [1] NCCL INFO P2P plugin IBext
163: hkn0520:2705377:2705377 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
356: hkn0708:405715:405715 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
356: hkn0708:405715:405715 [0] NCCL INFO P2P plugin IBext
358: hkn0708:405723:405723 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
358: hkn0708:405723:405723 [2] NCCL INFO P2P plugin IBext
332: hkn0636:1646720:1646720 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
332: hkn0636:1646720:1646720 [0] NCCL INFO P2P plugin IBext
160: hkn0520:2705369:2705369 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.88<0>
 55: hkn0418:1861683:1861683 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
467: hkn0803:869056:869056 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
359: hkn0708:405743:405743 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
359: hkn0708:405743:405743 [3] NCCL INFO Using network IBext
356: hkn0708:405715:405715 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
356: hkn0708:405715:405715 [0] NCCL INFO Using network IBext
 54: hkn0418:1861675:1861675 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
428: hkn0728:1316465:1316465 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
161: hkn0520:2705368:2705368 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
358: hkn0708:405723:405723 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
 53: hkn0418:1861667:1861667 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 53: hkn0418:1861667:1861667 [1] NCCL INFO P2P plugin IBext
161: hkn0520:2705368:2705368 [1] NCCL INFO Using network IBext
358: hkn0708:405723:405723 [2] NCCL INFO Using network IBext
163: hkn0520:2705377:2705377 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
163: hkn0520:2705377:2705377 [3] NCCL INFO P2P plugin IBext
333: hkn0636:1646748:1646748 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
465: hkn0803:869036:869036 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
448: hkn0734:1149085:1149085 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
466: hkn0803:869044:869044 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
160: hkn0520:2705369:2705369 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
160: hkn0520:2705369:2705369 [0] NCCL INFO P2P plugin IBext
450: hkn0734:1149069:1149069 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
 55: hkn0418:1861683:1861683 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 55: hkn0418:1861683:1861683 [3] NCCL INFO P2P plugin IBext
464: hkn0803:869028:869028 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.179<0>
431: hkn0728:1316457:1316457 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
259: hkn0612:909467:909467 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
334: hkn0636:1646736:1646736 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
357: hkn0708:405731:405731 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.148<0>
357: hkn0708:405731:405731 [1] NCCL INFO Using network IBext
467: hkn0803:869056:869056 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
467: hkn0803:869056:869056 [3] NCCL INFO P2P plugin IBext
429: hkn0728:1316473:1316473 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
163: hkn0520:2705377:2705377 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
163: hkn0520:2705377:2705377 [3] NCCL INFO Using network IBext
162: hkn0520:2705389:2705389 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
162: hkn0520:2705389:2705389 [2] NCCL INFO Using network IBext
 54: hkn0418:1861675:1861675 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 54: hkn0418:1861675:1861675 [2] NCCL INFO P2P plugin IBext
160: hkn0520:2705369:2705369 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.88<0>
160: hkn0520:2705369:2705369 [0] NCCL INFO Using network IBext
428: hkn0728:1316465:1316465 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
428: hkn0728:1316465:1316465 [0] NCCL INFO P2P plugin IBext
333: hkn0636:1646748:1646748 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
333: hkn0636:1646748:1646748 [1] NCCL INFO P2P plugin IBext
 52: hkn0418:1861695:1861695 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.50<0>
465: hkn0803:869036:869036 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
465: hkn0803:869036:869036 [1] NCCL INFO P2P plugin IBext
451: hkn0734:1149077:1149077 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
 55: hkn0418:1861683:1861683 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 55: hkn0418:1861683:1861683 [3] NCCL INFO Using network IBext
448: hkn0734:1149085:1149085 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
448: hkn0734:1149085:1149085 [0] NCCL INFO P2P plugin IBext
449: hkn0734:1149097:1149097 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.174<0>
450: hkn0734:1149069:1149069 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
450: hkn0734:1149069:1149069 [2] NCCL INFO P2P plugin IBext
466: hkn0803:869044:869044 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
466: hkn0803:869044:869044 [2] NCCL INFO P2P plugin IBext
464: hkn0803:869028:869028 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
464: hkn0803:869028:869028 [0] NCCL INFO P2P plugin IBext
259: hkn0612:909467:909467 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
259: hkn0612:909467:909467 [3] NCCL INFO P2P plugin IBext
258: hkn0612:909479:909479 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
430: hkn0728:1316485:1316485 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.168<0>
431: hkn0728:1316457:1316457 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
431: hkn0728:1316457:1316457 [3] NCCL INFO P2P plugin IBext
334: hkn0636:1646736:1646736 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
334: hkn0636:1646736:1646736 [2] NCCL INFO P2P plugin IBext
 54: hkn0418:1861675:1861675 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 54: hkn0418:1861675:1861675 [2] NCCL INFO Using network IBext
335: hkn0636:1646728:1646728 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.140<0>
159: hkn0516:2908480:2908480 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
332: hkn0636:1646720:1646720 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
332: hkn0636:1646720:1646720 [0] NCCL INFO Using network IBext
333: hkn0636:1646748:1646748 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
333: hkn0636:1646748:1646748 [1] NCCL INFO Using network IBext
429: hkn0728:1316473:1316473 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
429: hkn0728:1316473:1316473 [1] NCCL INFO P2P plugin IBext
 53: hkn0418:1861667:1861667 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 53: hkn0418:1861667:1861667 [1] NCCL INFO Using network IBext
156: hkn0516:2908500:2908500 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
 52: hkn0418:1861695:1861695 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 52: hkn0418:1861695:1861695 [0] NCCL INFO P2P plugin IBext
334: hkn0636:1646736:1646736 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
334: hkn0636:1646736:1646736 [2] NCCL INFO Using network IBext
451: hkn0734:1149077:1149077 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
451: hkn0734:1149077:1149077 [3] NCCL INFO P2P plugin IBext
466: hkn0803:869044:869044 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
466: hkn0803:869044:869044 [2] NCCL INFO Using network IBext
464: hkn0803:869028:869028 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
465: hkn0803:869036:869036 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
465: hkn0803:869036:869036 [1] NCCL INFO Using network IBext
464: hkn0803:869028:869028 [0] NCCL INFO Using network IBext
449: hkn0734:1149097:1149097 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
449: hkn0734:1149097:1149097 [1] NCCL INFO P2P plugin IBext
258: hkn0612:909479:909479 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
258: hkn0612:909479:909479 [2] NCCL INFO P2P plugin IBext
431: hkn0728:1316457:1316457 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
430: hkn0728:1316485:1316485 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
430: hkn0728:1316485:1316485 [2] NCCL INFO P2P plugin IBext
431: hkn0728:1316457:1316457 [3] NCCL INFO Using network IBext
429: hkn0728:1316473:1316473 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
429: hkn0728:1316473:1316473 [1] NCCL INFO Using network IBext
335: hkn0636:1646728:1646728 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
335: hkn0636:1646728:1646728 [3] NCCL INFO P2P plugin IBext
159: hkn0516:2908480:2908480 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
159: hkn0516:2908480:2908480 [3] NCCL INFO P2P plugin IBext
257: hkn0612:909451:909451 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
218: hkn0601:110156:110156 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
 52: hkn0418:1861695:1861695 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.50<0>
 52: hkn0418:1861695:1861695 [0] NCCL INFO Using network IBext
467: hkn0803:869056:869056 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.179<0>
467: hkn0803:869056:869056 [3] NCCL INFO Using network IBext
211: hkn0534:1140916:1140916 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
428: hkn0728:1316465:1316465 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
428: hkn0728:1316465:1316465 [0] NCCL INFO Using network IBext
216: hkn0601:110172:110172 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
430: hkn0728:1316485:1316485 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.168<0>
156: hkn0516:2908500:2908500 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
156: hkn0516:2908500:2908500 [0] NCCL INFO P2P plugin IBext
430: hkn0728:1316485:1316485 [2] NCCL INFO Using network IBext
256: hkn0612:909459:909459 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.116<0>
157: hkn0516:2908488:2908488 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
209: hkn0534:1140924:1140924 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
335: hkn0636:1646728:1646728 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.140<0>
335: hkn0636:1646728:1646728 [3] NCCL INFO Using network IBext
219: hkn0601:110164:110164 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
449: hkn0734:1149097:1149097 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
451: hkn0734:1149077:1149077 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
451: hkn0734:1149077:1149077 [3] NCCL INFO Using network IBext
449: hkn0734:1149097:1149097 [1] NCCL INFO Using network IBext
258: hkn0612:909479:909479 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
258: hkn0612:909479:909479 [2] NCCL INFO Using network IBext
210: hkn0534:1140936:1140936 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
259: hkn0612:909467:909467 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
259: hkn0612:909467:909467 [3] NCCL INFO Using network IBext
450: hkn0734:1149069:1149069 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
450: hkn0734:1149069:1149069 [2] NCCL INFO Using network IBext
448: hkn0734:1149085:1149085 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.174<0>
448: hkn0734:1149085:1149085 [0] NCCL INFO Using network IBext
208: hkn0534:1140908:1140908 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.102<0>
257: hkn0612:909451:909451 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
257: hkn0612:909451:909451 [1] NCCL INFO P2P plugin IBext
218: hkn0601:110156:110156 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
218: hkn0601:110156:110156 [2] NCCL INFO P2P plugin IBext
211: hkn0534:1140916:1140916 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
211: hkn0534:1140916:1140916 [3] NCCL INFO P2P plugin IBext
158: hkn0516:2908472:2908472 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.84<0>
216: hkn0601:110172:110172 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
216: hkn0601:110172:110172 [0] NCCL INFO P2P plugin IBext
156: hkn0516:2908500:2908500 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
256: hkn0612:909459:909459 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
256: hkn0612:909459:909459 [0] NCCL INFO P2P plugin IBext
156: hkn0516:2908500:2908500 [0] NCCL INFO Using network IBext
157: hkn0516:2908488:2908488 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
157: hkn0516:2908488:2908488 [1] NCCL INFO P2P plugin IBext
219: hkn0601:110164:110164 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
219: hkn0601:110164:110164 [3] NCCL INFO P2P plugin IBext
209: hkn0534:1140924:1140924 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
209: hkn0534:1140924:1140924 [1] NCCL INFO P2P plugin IBext
217: hkn0601:110184:110184 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.105<0>
257: hkn0612:909451:909451 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
257: hkn0612:909451:909451 [1] NCCL INFO Using network IBext
210: hkn0534:1140936:1140936 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
210: hkn0534:1140936:1140936 [2] NCCL INFO P2P plugin IBext
208: hkn0534:1140908:1140908 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
208: hkn0534:1140908:1140908 [0] NCCL INFO P2P plugin IBext
461: hkn0802:1192842:1192842 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
159: hkn0516:2908480:2908480 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
159: hkn0516:2908480:2908480 [3] NCCL INFO Using network IBext
256: hkn0612:909459:909459 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.116<0>
256: hkn0612:909459:909459 [0] NCCL INFO Using network IBext
157: hkn0516:2908488:2908488 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
157: hkn0516:2908488:2908488 [1] NCCL INFO Using network IBext
455: hkn0736:1500858:1500858 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
158: hkn0516:2908472:2908472 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
158: hkn0516:2908472:2908472 [2] NCCL INFO P2P plugin IBext
216: hkn0601:110172:110172 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
219: hkn0601:110164:110164 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
219: hkn0601:110164:110164 [3] NCCL INFO Using network IBext
216: hkn0601:110172:110172 [0] NCCL INFO Using network IBext
209: hkn0534:1140924:1140924 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
499: hkn0812:686277:686277 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
210: hkn0534:1140936:1140936 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
209: hkn0534:1140924:1140924 [1] NCCL INFO Using network IBext
210: hkn0534:1140936:1140936 [2] NCCL INFO Using network IBext
208: hkn0534:1140908:1140908 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
208: hkn0534:1140908:1140908 [0] NCCL INFO Using network IBext
453: hkn0736:1500847:1500847 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
217: hkn0601:110184:110184 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
217: hkn0601:110184:110184 [1] NCCL INFO P2P plugin IBext
158: hkn0516:2908472:2908472 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.84<0>
158: hkn0516:2908472:2908472 [2] NCCL INFO Using network IBext
 82: hkn0425:2076510:2076510 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
461: hkn0802:1192842:1192842 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
461: hkn0802:1192842:1192842 [1] NCCL INFO P2P plugin IBext
463: hkn0802:1192840:1192840 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
218: hkn0601:110156:110156 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
218: hkn0601:110156:110156 [2] NCCL INFO Using network IBext
455: hkn0736:1500858:1500858 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
455: hkn0736:1500858:1500858 [3] NCCL INFO P2P plugin IBext
454: hkn0736:1500869:1500869 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
460: hkn0802:1192854:1192854 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
211: hkn0534:1140916:1140916 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.102<0>
211: hkn0534:1140916:1140916 [3] NCCL INFO Using network IBext
217: hkn0601:110184:110184 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.105<0>
217: hkn0601:110184:110184 [1] NCCL INFO Using network IBext
266: hkn0615:406787:406787 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
462: hkn0802:1192841:1192841 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.178<0>
410: hkn0723:200364:200364 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 80: hkn0425:2076490:2076490 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
499: hkn0812:686277:686277 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
499: hkn0812:686277:686277 [3] NCCL INFO P2P plugin IBext
453: hkn0736:1500847:1500847 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
453: hkn0736:1500847:1500847 [1] NCCL INFO P2P plugin IBext
411: hkn0723:200377:200377 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 83: hkn0425:2076482:2076482 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
496: hkn0812:686285:686285 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
409: hkn0723:200369:200369 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
 81: hkn0425:2076498:2076498 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.57<0>
372: hkn0713:462723:462723 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
497: hkn0812:686297:686297 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
498: hkn0812:686269:686269 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.188<0>
265: hkn0615:406807:406807 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
452: hkn0736:1500850:1500850 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.176<0>
375: hkn0713:462751:462751 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
373: hkn0713:462731:462731 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
 82: hkn0425:2076510:2076510 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 82: hkn0425:2076510:2076510 [2] NCCL INFO P2P plugin IBext
264: hkn0615:406779:406779 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
463: hkn0802:1192840:1192840 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
463: hkn0802:1192840:1192840 [3] NCCL INFO P2P plugin IBext
454: hkn0736:1500869:1500869 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
454: hkn0736:1500869:1500869 [2] NCCL INFO P2P plugin IBext
267: hkn0615:406795:406795 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.119<0>
374: hkn0713:462739:462739 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.153<0>
460: hkn0802:1192854:1192854 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
460: hkn0802:1192854:1192854 [0] NCCL INFO P2P plugin IBext
408: hkn0723:200389:200389 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.163<0>
266: hkn0615:406787:406787 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
266: hkn0615:406787:406787 [2] NCCL INFO P2P plugin IBext
462: hkn0802:1192841:1192841 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
462: hkn0802:1192841:1192841 [2] NCCL INFO P2P plugin IBext
410: hkn0723:200364:200364 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
410: hkn0723:200364:200364 [2] NCCL INFO P2P plugin IBext
453: hkn0736:1500847:1500847 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
453: hkn0736:1500847:1500847 [1] NCCL INFO Using network IBext
 80: hkn0425:2076490:2076490 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 80: hkn0425:2076490:2076490 [0] NCCL INFO P2P plugin IBext
411: hkn0723:200377:200377 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
411: hkn0723:200377:200377 [3] NCCL INFO P2P plugin IBext
409: hkn0723:200369:200369 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
409: hkn0723:200369:200369 [1] NCCL INFO P2P plugin IBext
 83: hkn0425:2076482:2076482 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 83: hkn0425:2076482:2076482 [3] NCCL INFO P2P plugin IBext
496: hkn0812:686285:686285 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
496: hkn0812:686285:686285 [0] NCCL INFO P2P plugin IBext
 81: hkn0425:2076498:2076498 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 81: hkn0425:2076498:2076498 [1] NCCL INFO P2P plugin IBext
265: hkn0615:406807:406807 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
265: hkn0615:406807:406807 [1] NCCL INFO P2P plugin IBext
372: hkn0713:462723:462723 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
372: hkn0713:462723:462723 [0] NCCL INFO P2P plugin IBext
454: hkn0736:1500869:1500869 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
497: hkn0812:686297:686297 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
497: hkn0812:686297:686297 [1] NCCL INFO P2P plugin IBext
454: hkn0736:1500869:1500869 [2] NCCL INFO Using network IBext
452: hkn0736:1500850:1500850 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
452: hkn0736:1500850:1500850 [0] NCCL INFO P2P plugin IBext
498: hkn0812:686269:686269 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
498: hkn0812:686269:686269 [2] NCCL INFO P2P plugin IBext
264: hkn0615:406779:406779 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
264: hkn0615:406779:406779 [0] NCCL INFO P2P plugin IBext
460: hkn0802:1192854:1192854 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
460: hkn0802:1192854:1192854 [0] NCCL INFO Using network IBext
375: hkn0713:462751:462751 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
375: hkn0713:462751:462751 [3] NCCL INFO P2P plugin IBext
463: hkn0802:1192840:1192840 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
463: hkn0802:1192840:1192840 [3] NCCL INFO Using network IBext
373: hkn0713:462731:462731 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
373: hkn0713:462731:462731 [1] NCCL INFO P2P plugin IBext
376: hkn0714:424562:424562 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
462: hkn0802:1192841:1192841 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
462: hkn0802:1192841:1192841 [2] NCCL INFO Using network IBext
455: hkn0736:1500858:1500858 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
455: hkn0736:1500858:1500858 [3] NCCL INFO Using network IBext
267: hkn0615:406795:406795 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
267: hkn0615:406795:406795 [3] NCCL INFO P2P plugin IBext
461: hkn0802:1192842:1192842 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.178<0>
461: hkn0802:1192842:1192842 [1] NCCL INFO Using network IBext
273: hkn0617:2287153:2287153 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
378: hkn0714:424535:424535 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
408: hkn0723:200389:200389 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
408: hkn0723:200389:200389 [0] NCCL INFO P2P plugin IBext
374: hkn0713:462739:462739 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
374: hkn0713:462739:462739 [2] NCCL INFO P2P plugin IBext
377: hkn0714:424551:424551 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
 80: hkn0425:2076490:2076490 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 80: hkn0425:2076490:2076490 [0] NCCL INFO Using network IBext
 81: hkn0425:2076498:2076498 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 81: hkn0425:2076498:2076498 [1] NCCL INFO Using network IBext
 83: hkn0425:2076482:2076482 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 83: hkn0425:2076482:2076482 [3] NCCL INFO Using network IBext
452: hkn0736:1500850:1500850 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.176<0>
452: hkn0736:1500850:1500850 [0] NCCL INFO Using network IBext
409: hkn0723:200369:200369 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
409: hkn0723:200369:200369 [1] NCCL INFO Using network IBext
379: hkn0714:424543:424543 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.154<0>
499: hkn0812:686277:686277 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
496: hkn0812:686285:686285 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
499: hkn0812:686277:686277 [3] NCCL INFO Using network IBext
496: hkn0812:686285:686285 [0] NCCL INFO Using network IBext
497: hkn0812:686297:686297 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
497: hkn0812:686297:686297 [1] NCCL INFO Using network IBext
498: hkn0812:686269:686269 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.188<0>
498: hkn0812:686269:686269 [2] NCCL INFO Using network IBext
264: hkn0615:406779:406779 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
264: hkn0615:406779:406779 [0] NCCL INFO Using network IBext
265: hkn0615:406807:406807 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
265: hkn0615:406807:406807 [1] NCCL INFO Using network IBext
267: hkn0615:406795:406795 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
267: hkn0615:406795:406795 [3] NCCL INFO Using network IBext
375: hkn0713:462751:462751 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
375: hkn0713:462751:462751 [3] NCCL INFO Using network IBext
373: hkn0713:462731:462731 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
373: hkn0713:462731:462731 [1] NCCL INFO Using network IBext
408: hkn0723:200389:200389 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
408: hkn0723:200389:200389 [0] NCCL INFO Using network IBext
374: hkn0713:462739:462739 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
374: hkn0713:462739:462739 [2] NCCL INFO Using network IBext
376: hkn0714:424562:424562 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
376: hkn0714:424562:424562 [0] NCCL INFO P2P plugin IBext
 82: hkn0425:2076510:2076510 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.57<0>
 82: hkn0425:2076510:2076510 [2] NCCL INFO Using network IBext
274: hkn0617:2287161:2287161 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
273: hkn0617:2287153:2287153 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
490: hkn0809:929907:929907 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
273: hkn0617:2287153:2287153 [1] NCCL INFO P2P plugin IBext
378: hkn0714:424535:424535 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
378: hkn0714:424535:424535 [2] NCCL INFO P2P plugin IBext
489: hkn0809:929888:929888 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
377: hkn0714:424551:424551 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
377: hkn0714:424551:424551 [1] NCCL INFO P2P plugin IBext
411: hkn0723:200377:200377 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
411: hkn0723:200377:200377 [3] NCCL INFO Using network IBext
266: hkn0615:406787:406787 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.119<0>
266: hkn0615:406787:406787 [2] NCCL INFO Using network IBext
410: hkn0723:200364:200364 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.163<0>
410: hkn0723:200364:200364 [2] NCCL INFO Using network IBext
275: hkn0617:2287181:2287181 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
379: hkn0714:424543:424543 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
379: hkn0714:424543:424543 [3] NCCL INFO P2P plugin IBext
196: hkn0530:1250671:1250671 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
272: hkn0617:2287169:2287169 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.121<0>
372: hkn0713:462723:462723 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.153<0>
372: hkn0713:462723:462723 [0] NCCL INFO Using network IBext
491: hkn0809:929880:929880 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
198: hkn0530:1250651:1250651 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
274: hkn0617:2287161:2287161 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
274: hkn0617:2287161:2287161 [2] NCCL INFO P2P plugin IBext
490: hkn0809:929907:929907 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
490: hkn0809:929907:929907 [2] NCCL INFO P2P plugin IBext
489: hkn0809:929888:929888 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
489: hkn0809:929888:929888 [1] NCCL INFO P2P plugin IBext
367: hkn0711:576403:576403 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
366: hkn0711:576395:576395 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
377: hkn0714:424551:424551 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
379: hkn0714:424543:424543 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
377: hkn0714:424551:424551 [1] NCCL INFO Using network IBext
379: hkn0714:424543:424543 [3] NCCL INFO Using network IBext
197: hkn0530:1250643:1250643 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
196: hkn0530:1250671:1250671 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
196: hkn0530:1250671:1250671 [0] NCCL INFO P2P plugin IBext
275: hkn0617:2287181:2287181 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
275: hkn0617:2287181:2287181 [3] NCCL INFO P2P plugin IBext
184: hkn0527:1341449:1341449 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
186: hkn0527:1341433:1341433 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
199: hkn0530:1250659:1250659 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.98<0>
272: hkn0617:2287169:2287169 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
272: hkn0617:2287169:2287169 [0] NCCL INFO P2P plugin IBext
491: hkn0809:929880:929880 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
491: hkn0809:929880:929880 [3] NCCL INFO P2P plugin IBext
488: hkn0809:929896:929896 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.185<0>
274: hkn0617:2287161:2287161 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
274: hkn0617:2287161:2287161 [2] NCCL INFO Using network IBext
198: hkn0530:1250651:1250651 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
198: hkn0530:1250651:1250651 [2] NCCL INFO P2P plugin IBext
187: hkn0527:1341441:1341441 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
378: hkn0714:424535:424535 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
378: hkn0714:424535:424535 [2] NCCL INFO Using network IBext
376: hkn0714:424562:424562 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.154<0>
376: hkn0714:424562:424562 [0] NCCL INFO Using network IBext
273: hkn0617:2287153:2287153 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
273: hkn0617:2287153:2287153 [1] NCCL INFO Using network IBext
367: hkn0711:576403:576403 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
367: hkn0711:576403:576403 [3] NCCL INFO P2P plugin IBext
365: hkn0711:576415:576415 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
275: hkn0617:2287181:2287181 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
275: hkn0617:2287181:2287181 [3] NCCL INFO Using network IBext
366: hkn0711:576395:576395 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
366: hkn0711:576395:576395 [2] NCCL INFO P2P plugin IBext
197: hkn0530:1250643:1250643 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
197: hkn0530:1250643:1250643 [1] NCCL INFO P2P plugin IBext
272: hkn0617:2287169:2287169 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.121<0>
272: hkn0617:2287169:2287169 [0] NCCL INFO Using network IBext
184: hkn0527:1341449:1341449 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
184: hkn0527:1341449:1341449 [0] NCCL INFO P2P plugin IBext
491: hkn0809:929880:929880 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
491: hkn0809:929880:929880 [3] NCCL INFO Using network IBext
199: hkn0530:1250659:1250659 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
199: hkn0530:1250659:1250659 [3] NCCL INFO P2P plugin IBext
488: hkn0809:929896:929896 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
488: hkn0809:929896:929896 [0] NCCL INFO P2P plugin IBext
198: hkn0530:1250651:1250651 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
198: hkn0530:1250651:1250651 [2] NCCL INFO Using network IBext
186: hkn0527:1341433:1341433 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
186: hkn0527:1341433:1341433 [2] NCCL INFO P2P plugin IBext
187: hkn0527:1341441:1341441 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
187: hkn0527:1341441:1341441 [3] NCCL INFO P2P plugin IBext
197: hkn0530:1250643:1250643 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
197: hkn0530:1250643:1250643 [1] NCCL INFO Using network IBext
490: hkn0809:929907:929907 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
490: hkn0809:929907:929907 [2] NCCL INFO Using network IBext
489: hkn0809:929888:929888 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
489: hkn0809:929888:929888 [1] NCCL INFO Using network IBext
365: hkn0711:576415:576415 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
365: hkn0711:576415:576415 [1] NCCL INFO P2P plugin IBext
185: hkn0527:1341461:1341461 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.95<0>
364: hkn0711:576387:576387 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.151<0>
196: hkn0530:1250671:1250671 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
196: hkn0530:1250671:1250671 [0] NCCL INFO Using network IBext
199: hkn0530:1250659:1250659 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.98<0>
199: hkn0530:1250659:1250659 [3] NCCL INFO Using network IBext
488: hkn0809:929896:929896 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.185<0>
488: hkn0809:929896:929896 [0] NCCL INFO Using network IBext
187: hkn0527:1341441:1341441 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
187: hkn0527:1341441:1341441 [3] NCCL INFO Using network IBext
186: hkn0527:1341433:1341433 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
186: hkn0527:1341433:1341433 [2] NCCL INFO Using network IBext
365: hkn0711:576415:576415 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
365: hkn0711:576415:576415 [1] NCCL INFO Using network IBext
185: hkn0527:1341461:1341461 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
185: hkn0527:1341461:1341461 [1] NCCL INFO P2P plugin IBext
364: hkn0711:576387:576387 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
364: hkn0711:576387:576387 [0] NCCL INFO P2P plugin IBext
367: hkn0711:576403:576403 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
367: hkn0711:576403:576403 [3] NCCL INFO Using network IBext
366: hkn0711:576395:576395 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
366: hkn0711:576395:576395 [2] NCCL INFO Using network IBext
387: hkn0716:100997:100997 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
184: hkn0527:1341449:1341449 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
184: hkn0527:1341449:1341449 [0] NCCL INFO Using network IBext
185: hkn0527:1341461:1341461 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.95<0>
185: hkn0527:1341461:1341461 [1] NCCL INFO Using network IBext
364: hkn0711:576387:576387 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.151<0>
364: hkn0711:576387:576387 [0] NCCL INFO Using network IBext
384: hkn0716:101008:101008 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
386: hkn0716:101020:101020 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
387: hkn0716:100997:100997 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
387: hkn0716:100997:100997 [3] NCCL INFO P2P plugin IBext
385: hkn0716:101000:101000 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.156<0>
287: hkn0623:1865238:1865238 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
384: hkn0716:101008:101008 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
384: hkn0716:101008:101008 [0] NCCL INFO P2P plugin IBext
286: hkn0623:1865246:1865246 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
504: hkn0815:387632:387632 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
285: hkn0623:1865230:1865230 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
386: hkn0716:101020:101020 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
386: hkn0716:101020:101020 [2] NCCL INFO P2P plugin IBext
385: hkn0716:101000:101000 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
385: hkn0716:101000:101000 [1] NCCL INFO P2P plugin IBext
287: hkn0623:1865238:1865238 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
287: hkn0623:1865238:1865238 [3] NCCL INFO P2P plugin IBext
284: hkn0623:1865258:1865258 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.127<0>
384: hkn0716:101008:101008 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
384: hkn0716:101008:101008 [0] NCCL INFO Using network IBext
386: hkn0716:101020:101020 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
386: hkn0716:101020:101020 [2] NCCL INFO Using network IBext
385: hkn0716:101000:101000 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
385: hkn0716:101000:101000 [1] NCCL INFO Using network IBext
286: hkn0623:1865246:1865246 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
286: hkn0623:1865246:1865246 [2] NCCL INFO P2P plugin IBext
504: hkn0815:387632:387632 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
504: hkn0815:387632:387632 [0] NCCL INFO P2P plugin IBext
285: hkn0623:1865230:1865230 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
285: hkn0623:1865230:1865230 [1] NCCL INFO P2P plugin IBext
387: hkn0716:100997:100997 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.156<0>
387: hkn0716:100997:100997 [3] NCCL INFO Using network IBext
507: hkn0815:387648:387648 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
 50: hkn0417:2260187:2260187 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
284: hkn0623:1865258:1865258 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
284: hkn0623:1865258:1865258 [0] NCCL INFO P2P plugin IBext
 51: hkn0417:2260175:2260175 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
505: hkn0815:387660:387660 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
285: hkn0623:1865230:1865230 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
286: hkn0623:1865246:1865246 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
285: hkn0623:1865230:1865230 [1] NCCL INFO Using network IBext
286: hkn0623:1865246:1865246 [2] NCCL INFO Using network IBext
115: hkn0505:2296296:2296296 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
 48: hkn0417:2260167:2260167 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
 49: hkn0417:2260159:2260159 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.49<0>
284: hkn0623:1865258:1865258 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
284: hkn0623:1865258:1865258 [0] NCCL INFO Using network IBext
507: hkn0815:387648:387648 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
507: hkn0815:387648:387648 [3] NCCL INFO P2P plugin IBext
 50: hkn0417:2260187:2260187 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 50: hkn0417:2260187:2260187 [2] NCCL INFO P2P plugin IBext
287: hkn0623:1865238:1865238 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.127<0>
287: hkn0623:1865238:1865238 [3] NCCL INFO Using network IBext
506: hkn0815:387640:387640 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.191<0>
 51: hkn0417:2260175:2260175 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 51: hkn0417:2260175:2260175 [3] NCCL INFO P2P plugin IBext
114: hkn0505:2296288:2296288 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
505: hkn0815:387660:387660 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
505: hkn0815:387660:387660 [1] NCCL INFO P2P plugin IBext
115: hkn0505:2296296:2296296 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 48: hkn0417:2260167:2260167 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 48: hkn0417:2260167:2260167 [0] NCCL INFO P2P plugin IBext
115: hkn0505:2296296:2296296 [3] NCCL INFO P2P plugin IBext
113: hkn0505:2296285:2296285 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
 49: hkn0417:2260159:2260159 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
 49: hkn0417:2260159:2260159 [1] NCCL INFO P2P plugin IBext
323: hkn0633:1518851:1518851 [3] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
505: hkn0815:387660:387660 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
505: hkn0815:387660:387660 [1] NCCL INFO Using network IBext
504: hkn0815:387632:387632 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
504: hkn0815:387632:387632 [0] NCCL INFO Using network IBext
507: hkn0815:387648:387648 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
507: hkn0815:387648:387648 [3] NCCL INFO Using network IBext
506: hkn0815:387640:387640 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
506: hkn0815:387640:387640 [2] NCCL INFO P2P plugin IBext
 51: hkn0417:2260175:2260175 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 51: hkn0417:2260175:2260175 [3] NCCL INFO Using network IBext
 48: hkn0417:2260167:2260167 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 48: hkn0417:2260167:2260167 [0] NCCL INFO Using network IBext
322: hkn0633:1518843:1518843 [2] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
114: hkn0505:2296288:2296288 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
114: hkn0505:2296288:2296288 [2] NCCL INFO P2P plugin IBext
 49: hkn0417:2260159:2260159 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 49: hkn0417:2260159:2260159 [1] NCCL INFO Using network IBext
113: hkn0505:2296285:2296285 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
113: hkn0505:2296285:2296285 [1] NCCL INFO P2P plugin IBext
112: hkn0505:2296308:2296308 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.73<0>
506: hkn0815:387640:387640 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.191<0>
506: hkn0815:387640:387640 [2] NCCL INFO Using network IBext
323: hkn0633:1518851:1518851 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
323: hkn0633:1518851:1518851 [3] NCCL INFO P2P plugin IBext
 50: hkn0417:2260187:2260187 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.49<0>
 50: hkn0417:2260187:2260187 [2] NCCL INFO Using network IBext
320: hkn0633:1518863:1518863 [0] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
322: hkn0633:1518843:1518843 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
322: hkn0633:1518843:1518843 [2] NCCL INFO P2P plugin IBext
113: hkn0505:2296285:2296285 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
114: hkn0505:2296288:2296288 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
113: hkn0505:2296285:2296285 [1] NCCL INFO Using network IBext
114: hkn0505:2296288:2296288 [2] NCCL INFO Using network IBext
115: hkn0505:2296296:2296296 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
115: hkn0505:2296296:2296296 [3] NCCL INFO Using network IBext
321: hkn0633:1518835:1518835 [1] NCCL INFO Bootstrap : Using ib0:172.26.13.137<0>
112: hkn0505:2296308:2296308 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
112: hkn0505:2296308:2296308 [0] NCCL INFO P2P plugin IBext
322: hkn0633:1518843:1518843 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
322: hkn0633:1518843:1518843 [2] NCCL INFO Using network IBext
320: hkn0633:1518863:1518863 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
320: hkn0633:1518863:1518863 [0] NCCL INFO P2P plugin IBext
112: hkn0505:2296308:2296308 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.73<0>
112: hkn0505:2296308:2296308 [0] NCCL INFO Using network IBext
321: hkn0633:1518835:1518835 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
321: hkn0633:1518835:1518835 [1] NCCL INFO P2P plugin IBext
320: hkn0633:1518863:1518863 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
320: hkn0633:1518863:1518863 [0] NCCL INFO Using network IBext
323: hkn0633:1518851:1518851 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
323: hkn0633:1518851:1518851 [3] NCCL INFO Using network IBext
321: hkn0633:1518835:1518835 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_2:1/RoCE ; OOB ib0:172.26.13.137<0>
321: hkn0633:1518835:1518835 [1] NCCL INFO Using network IBext
356: hkn0708:405715:405864 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
358: hkn0708:405723:405866 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
333: hkn0636:1646748:1646841 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
478: hkn0806:1046839:1046949 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
357: hkn0708:405731:405869 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
410: hkn0723:200364:200541 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
359: hkn0708:405743:405863 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
316: hkn0632:1751127:1751225 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
453: hkn0736:1500847:1500961 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
332: hkn0636:1646720:1646839 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
476: hkn0806:1046831:1046950 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
409: hkn0723:200369:200533 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 92: hkn0428:659865:659978 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 53: hkn0418:1861667:1861790 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
319: hkn0632:1751115:1751226 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
335: hkn0636:1646728:1646847 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 94: hkn0428:659895:659982 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
334: hkn0636:1646736:1646844 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
308: hkn0630:1590950:1591102 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
479: hkn0806:1046823:1046948 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
318: hkn0632:1751099:1751227 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
477: hkn0806:1046851:1046947 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
411: hkn0723:200377:200540 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
452: hkn0736:1500850:1500969 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
408: hkn0723:200389:200535 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 95: hkn0428:659881:659973 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
317: hkn0632:1751107:1751230 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 93: hkn0428:659873:659979 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
363: hkn0710:348029:348129 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
353: hkn0707:4012439:4012533 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
311: hkn0630:1590970:1591099 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
435: hkn0730:1394249:1394347 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
327: hkn0634:1513369:1513478 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
266: hkn0615:406787:406911 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
473: hkn0805:1104610:1104724 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
102: hkn0502:221554:221671 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
309: hkn0630:1590958:1591101 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
132: hkn0510:2754595:2754687 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 52: hkn0418:1861695:1861793 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 21: hkn0409:2578197:2578308 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
509: hkn0816:368127:368238 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
399: hkn0719:1298195:1298344 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
454: hkn0736:1500869:1500964 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
395: hkn0718:3909510:3909645 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
310: hkn0630:1590942:1591100 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
440: hkn0732:1204171:1204267 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
420: hkn0726:1540622:1540733 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 14: hkn0407:1808755:1808914 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
372: hkn0713:462723:462881 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
467: hkn0803:869056:869160 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 55: hkn0418:1861683:1861785 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
455: hkn0736:1500858:1500966 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
361: hkn0710:348021:348124 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 31: hkn0411:2308387:2308486 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
402: hkn0720:4190312:4190585 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
483: hkn0807:1011596:1011696 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
101: hkn0502:221555:221670 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
439: hkn0731:1379236:1379354 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 54: hkn0418:1861675:1861787 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
431: hkn0728:1316457:1316577 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
346: hkn0705:775721:775863 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
387: hkn0716:100997:101122 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
368: hkn0712:287551:287669 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
360: hkn0710:348013:348131 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
343: hkn0704:784502:784626 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
100: hkn0502:221575:221672 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
419: hkn0725:3104454:3104536 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
362: hkn0710:348041:348125 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
189: hkn0528:1294214:1294319 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
437: hkn0731:1379256:1379351 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
472: hkn0805:1104602:1104720 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
324: hkn0634:1513353:1513483 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
433: hkn0730:1394237:1394350 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
354: hkn0707:4012451:4012539 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
265: hkn0615:406807:406907 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 49: hkn0417:2260159:2260288 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
451: hkn0734:1149077:1149192 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 61: hkn0420:3202729:3202829 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
370: hkn0712:287559:287664 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
480: hkn0807:1011577:1011693 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 68: hkn0422:4145491:4145646 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
307: hkn0629:1584544:1584671 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
396: hkn0719:1298187:1298341 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
432: hkn0730:1394221:1394352 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
326: hkn0634:1513361:1513475 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
445: hkn0733:1381907:1382020 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
369: hkn0712:287543:287667 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
103: hkn0502:221563:221675 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
236: hkn0606:2364550:2364664 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
390: hkn0717:4180120:4180224 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 22: hkn0409:2578209:2578305 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
267: hkn0615:406795:406908 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
340: hkn0704:784518:784625 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
443: hkn0732:1204148:1204274 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
422: hkn0726:1540606:1540728 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 12: hkn0407:1808763:1808908 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
401: hkn0720:4190323:4190580 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
355: hkn0707:4012431:4012540 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
436: hkn0731:1379234:1379347 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
133: hkn0510:2754575:2754694 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
403: hkn0720:4190335:4190579 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
325: hkn0634:1513380:1513484 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
510: hkn0816:368135:368243 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
438: hkn0731:1379244:1379355 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
400: hkn0720:4190315:4190586 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
371: hkn0712:287571:287663 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
115: hkn0505:2296296:2296404 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
450: hkn0734:1149069:1149195 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
264: hkn0615:406779:406906 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
448: hkn0734:1149085:1149196 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
104: hkn0503:2892170:2892284 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 30: hkn0411:2308367:2308482 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
481: hkn0807:1011585:1011697 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
352: hkn0707:4012423:4012534 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
329: hkn0635:1218103:1218214 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
386: hkn0716:101020:101119 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
338: hkn0703:733524:733645 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
375: hkn0713:462751:462876 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
342: hkn0704:784530:784630 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 15: hkn0407:1808771:1808909 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 58: hkn0419:1536809:1536916 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
153: hkn0515:2889289:2889409 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
393: hkn0718:3909494:3909650 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
341: hkn0704:784510:784629 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
474: hkn0805:1104630:1104729 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
482: hkn0807:1011569:1011689 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
344: hkn0705:775713:775862 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
466: hkn0803:869044:869156 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
475: hkn0805:1104618:1104726 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
398: hkn0719:1298217:1298339 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 13: hkn0407:1808783:1808911 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
447: hkn0733:1381891:1382017 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  7: hkn0404:1331852:1331996 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 20: hkn0409:2578189:2578309 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 48: hkn0417:2260167:2260286 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
397: hkn0719:1298203:1298338 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
385: hkn0716:101000:101120 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
423: hkn0726:1540634:1540730 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
428: hkn0728:1316465:1316582 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
394: hkn0718:3909522:3909643 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
434: hkn0730:1394229:1394348 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 23: hkn0409:2578181:2578301 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
508: hkn0816:368125:368237 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
303: hkn0628:664365:664474 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 28: hkn0411:2308375:2308484 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
441: hkn0732:1204159:1204268 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
190: hkn0528:1294206:1294325 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
511: hkn0816:368147:368244 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
449: hkn0734:1149097:1149191 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
430: hkn0728:1316485:1316584 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
384: hkn0716:101008:101117 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
464: hkn0803:869028:869155 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
429: hkn0728:1316473:1316578 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
134: hkn0510:2754583:2754692 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
138: hkn0511:3058850:3058979 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
421: hkn0726:1540614:1540729 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
188: hkn0528:1294198:1294318 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 75: hkn0423:1697362:1697475 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
373: hkn0713:462731:462877 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
180: hkn0526:1420918:1421023 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
418: hkn0725:3104426:3104537 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
442: hkn0732:1204151:1204273 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
281: hkn0622:2012970:2013094 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 60: hkn0420:3202709:3202825 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
392: hkn0718:3909502:3909648 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 35: hkn0412:2254928:2255011 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
135: hkn0510:2754567:2754688 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
347: hkn0705:775733:775855 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 51: hkn0417:2260175:2260285 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
444: hkn0733:1381919:1382019 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
381: hkn0715:394422:394551 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
465: hkn0803:869036:869157 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
173: hkn0524:1126272:1126399 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
416: hkn0725:3104442:3104538 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 78: hkn0424:2940433:2940564 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 29: hkn0411:2308366:2308483 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
374: hkn0713:462739:462878 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
191: hkn0528:1294226:1294323 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 90: hkn0427:1127651:1127785 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
389: hkn0717:4180100:4180219 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 24: hkn0410:1152208:1152319 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 47: hkn0415:2488934:2489087 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
306: hkn0629:1584560:1584666 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
406: hkn0721:2291495:2291615 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
446: hkn0733:1381899:1382018 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
345: hkn0705:775705:775864 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
417: hkn0725:3104434:3104541 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 63: hkn0420:3202717:3202827 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 50: hkn0417:2260187:2260291 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
167: hkn0521:1190314:1190440 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
351: hkn0706:744774:744912 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
337: hkn0703:733504:733651 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
286: hkn0623:1865246:1865351 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
237: hkn0606:2364558:2364669 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 70: hkn0422:4145499:4145645 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
339: hkn0703:733496:733654 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 33: hkn0412:2254900:2255017 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 62: hkn0420:3202701:3202824 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
233: hkn0605:704610:704720 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
391: hkn0717:4180108:4180218 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  0: hkn0403:1751320:1751689 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
112: hkn0505:2296308:2296407 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
227: hkn0603:1405656:1405782 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 42: hkn0414:1974071:1974185 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
201: hkn0531:1223094:1223197 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
304: hkn0629:1584552:1584670 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 56: hkn0419:1536810:1536918 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
245: hkn0608:478274:478386 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
388: hkn0717:4180092:4180225 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
263: hkn0613:895167:895298 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
152: hkn0515:2889297:2889406 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
160: hkn0520:2705369:2705482 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
336: hkn0703:733512:733649 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
131: hkn0509:3116888:3117013 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
106: hkn0503:2892182:2892286 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
331: hkn0635:1218123:1218208 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 38: hkn0413:2359203:2359295 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
140: hkn0512:3036647:3036768 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
305: hkn0629:1584572:1584665 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
206: hkn0532:916669:916966 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
348: hkn0706:744758:744910 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 41: hkn0414:1974079:1974183 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
248: hkn0609:703361:703450 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
114: hkn0505:2296288:2296402 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
382: hkn0715:394402:394547 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
312: hkn0631:1014294:1014414 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
154: hkn0515:2889281:2889407 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 71: hkn0422:4145519:4145652 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
300: hkn0628:664377:664476 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  5: hkn0404:1331860:1331998 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
405: hkn0721:2291522:2291616 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
175: hkn0524:1126280:1126395 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 74: hkn0423:1697354:1697472 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 34: hkn0412:2254908:2255016 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
113: hkn0505:2296285:2296401 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
105: hkn0503:2892162:2892285 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 32: hkn0412:2254916:2255009 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
238: hkn0606:2364570:2364670 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 77: hkn0424:2940449:2940563 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 57: hkn0419:1536822:1536917 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
172: hkn0524:1126300:1126401 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
380: hkn0715:394410:394546 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
137: hkn0511:3058866:3058981 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 69: hkn0422:4145507:4145651 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
350: hkn0706:744766:744917 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
182: hkn0526:1420936:1421020 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
260: hkn0613:895195:895293 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
220: hkn0602:3353946:3354226 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
295: hkn0626:1290931:1291060 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
107: hkn0503:2892154:2892277 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
349: hkn0706:744786:744914 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
155: hkn0515:2889309:2889405 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
174: hkn0524:1126288:1126393 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
383: hkn0715:394394:394548 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 88: hkn0427:1127643:1127786 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
239: hkn0606:2364542:2364663 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 97: hkn0501:1320356:1320474 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
328: hkn0635:1218095:1218212 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 59: hkn0419:1536808:1536921 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
165: hkn0521:1190302:1190437 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 36: hkn0413:2359195:2359304 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
404: hkn0721:2291503:2291621 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 72: hkn0423:1697374:1697469 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
127: hkn0508:3131628:3131736 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
164: hkn0521:1190286:1190438 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
187: hkn0527:1341441:1341554 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
367: hkn0711:576403:576515 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
297: hkn0627:1780434:1780527 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
315: hkn0631:1014310:1014411 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
149: hkn0514:2943234:2943343 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
415: hkn0724:1708503:1708602 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
268: hkn0616:397357:397478 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
461: hkn0802:1192842:1192951 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  4: hkn0404:1331872:1331990 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
169: hkn0523:1540568:1540663 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 80: hkn0425:2076490:2076594 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 40: hkn0414:1974091:1974182 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 73: hkn0423:1697346:1697471 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
330: hkn0635:1218111:1218207 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
232: hkn0605:704594:704721 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
166: hkn0521:1190294:1190442 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
302: hkn0628:664349:664472 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 25: hkn0410:1152210:1152322 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 76: hkn0424:2940461:2940557 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
407: hkn0721:2291511:2291619 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
322: hkn0633:1518843:1518959 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
247: hkn0608:478286:478382 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 79: hkn0424:2940441:2940558 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 46: hkn0415:2488942:2489091 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
159: hkn0516:2908480:2908594 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 43: hkn0414:1974063:1974188 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  6: hkn0404:1331844:1331992 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
262: hkn0613:895183:895295 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
203: hkn0531:1223106:1223204 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
240: hkn0607:896885:896985 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  1: hkn0403:1751324:1751696 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
364: hkn0711:576387:576519 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
301: hkn0628:664357:664467 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
462: hkn0802:1192841:1192950 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
136: hkn0511:3058878:3058984 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
284: hkn0623:1865258:1865355 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
287: hkn0623:1865238:1865357 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
261: hkn0613:895175:895292 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
226: hkn0603:1405672:1405779 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
412: hkn0724:1708475:1708596 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
294: hkn0626:1290959:1291053 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 39: hkn0413:2359214:2359301 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
314: hkn0631:1014322:1014417 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
213: hkn0535:2391499:2391618 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 91: hkn0427:1127642:1127790 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
210: hkn0534:1140936:1141031 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
244: hkn0608:478258:478384 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 26: hkn0410:1152222:1152317 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
285: hkn0623:1865230:1865352 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
143: hkn0512:3036675:3036769 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
313: hkn0631:1014302:1014419 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
200: hkn0531:1223086:1223206 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 17: hkn0408:2883223:2883320 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 89: hkn0427:1127663:1127792 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
459: hkn0801:2232488:2232616 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 37: hkn0413:2359194:2359299 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 84: hkn0426:806579:806691 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
250: hkn0609:703349:703447 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
224: hkn0603:1405683:1405780 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
460: hkn0802:1192854:1192947 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 44: hkn0415:2488950:2489094 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
299: hkn0627:1780422:1780529 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
246: hkn0608:478266:478383 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
128: hkn0509:3116916:3117017 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
202: hkn0531:1223078:1223201 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
289: hkn0624:1765436:1765548 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
234: hkn0605:704621:704722 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
183: hkn0526:1420898:1421019 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
139: hkn0511:3058858:3058978 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 27: hkn0410:1152209:1152320 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
489: hkn0809:929888:930005 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
282: hkn0622:2012978:2013091 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
181: hkn0526:1420907:1421018 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
258: hkn0612:909479:909575 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
298: hkn0627:1780406:1780532 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 45: hkn0415:2488962:2489090 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
293: hkn0626:1290947:1291055 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
414: hkn0724:1708491:1708600 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
235: hkn0605:704602:704724 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
225: hkn0603:1405664:1405775 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
494: hkn0810:932062:932167 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
292: hkn0626:1290939:1291061 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
463: hkn0802:1192840:1192948 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
365: hkn0711:576415:576512 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
323: hkn0633:1518851:1518965 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
205: hkn0532:916650:916971 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
276: hkn0621:1984044:1984134 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
163: hkn0520:2705377:2705478 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
296: hkn0627:1780414:1780535 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
243: hkn0607:896857:896978 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
413: hkn0724:1708483:1708593 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
291: hkn0624:1765456:1765549 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
241: hkn0607:896873:896982 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
366: hkn0711:576395:576516 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
186: hkn0527:1341433:1341555 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 18: hkn0408:2883203:2883321 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
270: hkn0616:397349:397480 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
141: hkn0512:3036663:3036774 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
223: hkn0602:3353954:3354221 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
321: hkn0633:1518835:1518968 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 99: hkn0501:1320348:1320478 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
320: hkn0633:1518863:1518964 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 19: hkn0408:2883195:2883322 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 98: hkn0501:1320364:1320480 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
129: hkn0509:3116896:3117018 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
283: hkn0622:2012962:2013089 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
125: hkn0508:3131636:3131730 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
150: hkn0514:2943226:2943345 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
251: hkn0609:703341:703443 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 82: hkn0425:2076510:2076599 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  3: hkn0403:1751336:1751695 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 96: hkn0501:1320376:1320475 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  2: hkn0403:1751321:1751698 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
199: hkn0530:1250659:1250771 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
242: hkn0607:896865:896980 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
142: hkn0512:3036655:3036775 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
290: hkn0624:1765428:1765554 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 16: hkn0408:2883211:2883325 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
249: hkn0609:703333:703446 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
492: hkn0810:932042:932160 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
207: hkn0532:916642:916973 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
288: hkn0624:1765444:1765555 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
162: hkn0520:2705389:2705480 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
425: hkn0727:1338287:1338387 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
176: hkn0525:979338:979432 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
156: hkn0516:2908500:2908590 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
269: hkn0616:397377:397476 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
490: hkn0809:929907:930004 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 10: hkn0405:3199307:3199411 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 83: hkn0425:2076482:2076596 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
204: hkn0532:916658:916970 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
221: hkn0602:3353962:3354225 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
488: hkn0809:929896:930007 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
124: hkn0508:3131620:3131734 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
161: hkn0520:2705368:2705469 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
208: hkn0534:1140908:1141032 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
130: hkn0509:3116904:3117014 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
280: hkn0622:2012990:2013090 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
493: hkn0810:932050:932165 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
222: hkn0602:3353974:3354228 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 86: hkn0426:806587:806697 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
491: hkn0809:929880:930000 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
271: hkn0616:397365:397472 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
212: hkn0535:2391491:2391620 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 81: hkn0425:2076498:2076595 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
495: hkn0810:932034:932161 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
185: hkn0527:1341461:1341561 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
485: hkn0808:963203:963306 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
170: hkn0523:1540556:1540660 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
157: hkn0516:2908488:2908596 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
126: hkn0508:3131648:3131731 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
458: hkn0801:2232476:2232619 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
211: hkn0534:1140916:1141035 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 11: hkn0405:3199299:3199420 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
148: hkn0514:2943218:2943338 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
178: hkn0525:979310:979433 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
215: hkn0535:2391507:2391619 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
151: hkn0514:2943246:2943339 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
277: hkn0621:1984016:1984143 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
377: hkn0714:424551:424658 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
427: hkn0727:1338271:1338389 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
218: hkn0601:110156:110284 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
158: hkn0516:2908472:2908599 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
171: hkn0523:1540540:1540658 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
279: hkn0621:1984024:1984141 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  8: hkn0405:3199319:3199416 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
184: hkn0527:1341449:1341560 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
209: hkn0534:1140924:1141030 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
214: hkn0535:2391519:2391622 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
426: hkn0727:1338279:1338380 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 87: hkn0426:806598:806692 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
168: hkn0523:1540548:1540665 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
278: hkn0621:1984032:1984138 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
  9: hkn0405:3199291:3199417 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
195: hkn0529:1533364:1533476 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
177: hkn0525:979326:979436 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 65: hkn0421:2172257:2172526 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
424: hkn0727:1338299:1338383 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
257: hkn0612:909451:909581 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
179: hkn0525:979318:979438 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 85: hkn0426:806571:806694 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
198: hkn0530:1250651:1250763 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
196: hkn0530:1250671:1250770 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
503: hkn0814:668359:668454 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
122: hkn0507:3179573:3179686 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
259: hkn0612:909467:909577 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
456: hkn0801:2232460:2232615 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
274: hkn0617:2287161:2287275 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
217: hkn0601:110184:110286 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
256: hkn0612:909459:909583 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
194: hkn0529:1533376:1533479 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
192: hkn0529:1533356:1533475 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
219: hkn0601:110164:110279 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
457: hkn0801:2232468:2232617 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
111: hkn0504:33333:33445 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
487: hkn0808:963175:963302 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
197: hkn0530:1250643:1250765 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
216: hkn0601:110172:110280 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
378: hkn0714:424535:424664 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
193: hkn0529:1533348:1533477 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
484: hkn0808:963191:963307 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 64: hkn0421:2172277:2172524 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 67: hkn0421:2172249:2172523 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
379: hkn0714:424543:424659 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 66: hkn0421:2172265:2172522 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
273: hkn0617:2287153:2287277 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
275: hkn0617:2287181:2287280 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
486: hkn0808:963183:963303 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
272: hkn0617:2287169:2287282 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
229: hkn0604:681744:681864 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
108: hkn0504:33325:33439 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
500: hkn0814:668339:668453 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
123: hkn0507:3179565:3179693 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
110: hkn0504:33345:33443 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
501: hkn0814:668331:668452 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
120: hkn0507:3179581:3179694 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
376: hkn0714:424562:424665 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
502: hkn0814:668347:668457 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
109: hkn0504:33317:33440 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
231: hkn0604:681764:681862 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
121: hkn0507:3179593:3179688 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
228: hkn0604:681736:681856 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
147: hkn0513:3005453:3005555 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
230: hkn0604:681752:681859 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
254: hkn0611:702301:702422 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
145: hkn0513:3005445:3005561 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
504: hkn0815:387632:387784 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
253: hkn0611:702329:702425 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
144: hkn0513:3005464:3005559 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
471: hkn0804:1198115:1198243 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
507: hkn0815:387648:387785 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
255: hkn0611:702317:702419 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
505: hkn0815:387660:387783 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
146: hkn0513:3005437:3005564 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
506: hkn0815:387640:387788 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
468: hkn0804:1198143:1198246 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
119: hkn0506:830554:830666 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
469: hkn0804:1198123:1198240 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
252: hkn0611:702309:702428 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
470: hkn0804:1198131:1198247 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
498: hkn0812:686269:686396 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
118: hkn0506:830582:830669 [2] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
497: hkn0812:686297:686395 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
499: hkn0812:686277:686393 [3] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
117: hkn0506:830562:830672 [1] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
116: hkn0506:830570:830664 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
496: hkn0812:686285:686394 [0] NCCL INFO NCCL_COLLNET_ENABLE set by environment to 0.
 58: hkn0419:1536809:1536916 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57
 58: hkn0419:1536809:1536916 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 61: hkn0420:3202729:3202829 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/92/-1->61->60
 57: hkn0419:1536822:1536917 [1] NCCL INFO Trees [0] 58/52/-1->57->56 [1] 58/-1/-1->57->56
 57: hkn0419:1536822:1536917 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 59: hkn0419:1536808:1536921 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58
 59: hkn0419:1536808:1536921 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 65: hkn0421:2172257:2172526 [1] NCCL INFO Trees [0] 66/32/-1->65->64 [1] 66/-1/-1->65->64
 61: hkn0420:3202729:3202829 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 65: hkn0421:2172257:2172526 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 60: hkn0420:3202709:3202825 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/28/-1->60->124
 60: hkn0420:3202709:3202825 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 56: hkn0419:1536810:1536918 [0] NCCL INFO Trees [0] 57/60/-1->56->48 [1] 57/-1/-1->56->53
 64: hkn0421:2172277:2172524 [0] NCCL INFO Trees [0] 65/96/-1->64->129 [1] 65/-1/-1->64->68
 64: hkn0421:2172277:2172524 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 63: hkn0420:3202717:3202827 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62
 56: hkn0419:1536810:1536918 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 68: hkn0422:4145491:4145646 [0] NCCL INFO Trees [0] 69/-1/-1->68->73 [1] 69/64/-1->68->76
 66: hkn0421:2172265:2172522 [2] NCCL INFO Trees [0] 67/-1/-1->66->65 [1] 67/-1/-1->66->65
 66: hkn0421:2172265:2172522 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 62: hkn0420:3202701:3202824 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61
 70: hkn0422:4145499:4145645 [2] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 71/-1/-1->70->69
 67: hkn0421:2172249:2172523 [3] NCCL INFO Trees [0] -1/-1/-1->67->66 [1] -1/-1/-1->67->66
 63: hkn0420:3202717:3202827 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 68: hkn0422:4145491:4145646 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 67: hkn0421:2172249:2172523 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 62: hkn0420:3202701:3202824 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 70: hkn0422:4145499:4145645 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 55: hkn0418:1861683:1861785 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54
 69: hkn0422:4145507:4145651 [1] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 70/72/-1->69->68
 69: hkn0422:4145507:4145651 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 55: hkn0418:1861683:1861785 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
130: hkn0509:3116904:3117014 [2] NCCL INFO Trees [0] 131/-1/-1->130->129 [1] 131/-1/-1->130->129
 71: hkn0422:4145519:4145652 [3] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] -1/-1/-1->71->70
 71: hkn0422:4145519:4145652 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
131: hkn0509:3116888:3117013 [3] NCCL INFO Trees [0] -1/-1/-1->131->130 [1] -1/-1/-1->131->130
133: hkn0510:2754575:2754694 [1] NCCL INFO Trees [0] 134/-1/-1->133->132 [1] 134/136/-1->133->132
130: hkn0509:3116904:3117014 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 74: hkn0423:1697354:1697472 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] 75/-1/-1->74->73
131: hkn0509:3116888:3117013 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
134: hkn0510:2754583:2754692 [2] NCCL INFO Trees [0] 135/-1/-1->134->133 [1] 135/-1/-1->134->133
138: hkn0511:3058850:3058979 [2] NCCL INFO Trees [0] 139/-1/-1->138->137 [1] 139/-1/-1->138->137
 75: hkn0423:1697362:1697475 [3] NCCL INFO Trees [0] -1/-1/-1->75->74 [1] -1/-1/-1->75->74
 75: hkn0423:1697362:1697475 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
140: hkn0512:3036647:3036768 [0] NCCL INFO Trees [0] 141/-1/-1->140->136 [1] 141/132/-1->140->156
133: hkn0510:2754575:2754694 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
138: hkn0511:3058850:3058979 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 74: hkn0423:1697354:1697472 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
129: hkn0509:3116896:3117018 [1] NCCL INFO Trees [0] 130/64/-1->129->128 [1] 130/-1/-1->129->128
134: hkn0510:2754583:2754692 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
129: hkn0509:3116896:3117018 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
140: hkn0512:3036647:3036768 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
144: hkn0513:3005464:3005559 [0] NCCL INFO Trees [0] 145/152/-1->144->161 [1] 145/-1/-1->144->148
144: hkn0513:3005464:3005559 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
135: hkn0510:2754567:2754688 [3] NCCL INFO Trees [0] -1/-1/-1->135->134 [1] -1/-1/-1->135->134
139: hkn0511:3058858:3058978 [3] NCCL INFO Trees [0] -1/-1/-1->139->138 [1] -1/-1/-1->139->138
 72: hkn0423:1697374:1697469 [0] NCCL INFO Trees [0] 73/76/-1->72->81 [1] 73/-1/-1->72->69
 72: hkn0423:1697374:1697469 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
141: hkn0512:3036663:3036774 [1] NCCL INFO Trees [0] 142/-1/-1->141->140 [1] 142/148/-1->141->140
135: hkn0510:2754567:2754688 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
137: hkn0511:3058866:3058981 [1] NCCL INFO Trees [0] 138/132/-1->137->136 [1] 138/-1/-1->137->136
137: hkn0511:3058866:3058981 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 73: hkn0423:1697346:1697471 [1] NCCL INFO Trees [0] 74/68/-1->73->72 [1] 74/-1/-1->73->72
 73: hkn0423:1697346:1697471 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
148: hkn0514:2943218:2943338 [0] NCCL INFO Trees [0] 149/-1/-1->148->153 [1] 149/144/-1->148->141
153: hkn0515:2889289:2889409 [1] NCCL INFO Trees [0] 154/148/-1->153->152 [1] 154/-1/-1->153->152
139: hkn0511:3058858:3058978 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
128: hkn0509:3116916:3117017 [0] NCCL INFO Trees [0] 129/192/-1->128->257 [1] 129/-1/-1->128->132
142: hkn0512:3036655:3036775 [2] NCCL INFO Trees [0] 143/-1/-1->142->141 [1] 143/-1/-1->142->141
153: hkn0515:2889289:2889409 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
145: hkn0513:3005445:3005561 [1] NCCL INFO Trees [0] 146/136/-1->145->144 [1] 146/-1/-1->145->144
132: hkn0510:2754595:2754687 [0] NCCL INFO Trees [0] 133/-1/-1->132->137 [1] 133/128/-1->132->140
136: hkn0511:3058878:3058984 [0] NCCL INFO Trees [0] 137/140/-1->136->145 [1] 137/-1/-1->136->133
136: hkn0511:3058878:3058984 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
158: hkn0516:2908472:2908599 [2] NCCL INFO Trees [0] 159/-1/-1->158->157 [1] 159/-1/-1->158->157
149: hkn0514:2943234:2943343 [1] NCCL INFO Trees [0] 150/-1/-1->149->148 [1] 150/152/-1->149->148
128: hkn0509:3116916:3117017 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
143: hkn0512:3036675:3036769 [3] NCCL INFO Trees [0] -1/-1/-1->143->142 [1] -1/-1/-1->143->142
155: hkn0515:2889309:2889405 [3] NCCL INFO Trees [0] -1/-1/-1->155->154 [1] -1/-1/-1->155->154
145: hkn0513:3005445:3005561 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
132: hkn0510:2754595:2754687 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
159: hkn0516:2908480:2908594 [3] NCCL INFO Trees [0] -1/-1/-1->159->158 [1] -1/-1/-1->159->158
 77: hkn0424:2940449:2940563 [1] NCCL INFO Trees [0] 78/-1/-1->77->76 [1] 78/84/-1->77->76
148: hkn0514:2943218:2943338 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
141: hkn0512:3036663:3036774 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
155: hkn0515:2889309:2889405 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
147: hkn0513:3005453:3005555 [3] NCCL INFO Trees [0] -1/-1/-1->147->146 [1] -1/-1/-1->147->146
160: hkn0520:2705369:2705482 [0] NCCL INFO Trees [0] 161/176/-1->160->193 [1] 161/-1/-1->160->164
158: hkn0516:2908472:2908599 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 77: hkn0424:2940449:2940563 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
149: hkn0514:2943234:2943343 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
142: hkn0512:3036655:3036775 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
154: hkn0515:2889281:2889407 [2] NCCL INFO Trees [0] 155/-1/-1->154->153 [1] 155/-1/-1->154->153
163: hkn0520:2705377:2705478 [3] NCCL INFO Trees [0] -1/-1/-1->163->162 [1] -1/-1/-1->163->162
159: hkn0516:2908480:2908594 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 78: hkn0424:2940433:2940564 [2] NCCL INFO Trees [0] 79/-1/-1->78->77 [1] 79/-1/-1->78->77
150: hkn0514:2943226:2943345 [2] NCCL INFO Trees [0] 151/-1/-1->150->149 [1] 151/-1/-1->150->149
143: hkn0512:3036675:3036769 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
154: hkn0515:2889281:2889407 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
147: hkn0513:3005453:3005555 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
160: hkn0520:2705369:2705482 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
156: hkn0516:2908500:2908590 [0] NCCL INFO Trees [0] 157/-1/-1->156->152 [1] 157/140/-1->156->188
 78: hkn0424:2940433:2940564 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
151: hkn0514:2943246:2943339 [3] NCCL INFO Trees [0] -1/-1/-1->151->150 [1] -1/-1/-1->151->150
152: hkn0515:2889297:2889406 [0] NCCL INFO Trees [0] 153/156/-1->152->144 [1] 153/-1/-1->152->149
146: hkn0513:3005437:3005564 [2] NCCL INFO Trees [0] 147/-1/-1->146->145 [1] 147/-1/-1->146->145
163: hkn0520:2705377:2705478 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
157: hkn0516:2908488:2908596 [1] NCCL INFO Trees [0] 158/-1/-1->157->156 [1] 158/172/-1->157->156
157: hkn0516:2908488:2908596 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 76: hkn0424:2940461:2940557 [0] NCCL INFO Trees [0] 77/-1/-1->76->72 [1] 77/68/-1->76->92
 76: hkn0424:2940461:2940557 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
150: hkn0514:2943226:2943345 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
101: hkn0502:221555:221670 [1] NCCL INFO Trees [0] 102/-1/-1->101->100 [1] 102/104/-1->101->100
152: hkn0515:2889297:2889406 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
146: hkn0513:3005437:3005564 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
161: hkn0520:2705368:2705469 [1] NCCL INFO Trees [0] 162/144/-1->161->160 [1] 162/-1/-1->161->160
127: hkn0508:3131628:3131736 [3] NCCL INFO Trees [0] -1/-1/-1->127->126 [1] -1/-1/-1->127->126
156: hkn0516:2908500:2908590 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 53: hkn0418:1861667:1861790 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/56/-1->53->52
 79: hkn0424:2940441:2940558 [3] NCCL INFO Trees [0] -1/-1/-1->79->78 [1] -1/-1/-1->79->78
 79: hkn0424:2940441:2940558 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
151: hkn0514:2943246:2943339 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
161: hkn0520:2705368:2705469 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
127: hkn0508:3131628:3131736 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 80: hkn0425:2076490:2076594 [0] NCCL INFO Trees [0] 81/88/-1->80->97 [1] 81/-1/-1->80->84
 54: hkn0418:1861675:1861787 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53
162: hkn0520:2705389:2705480 [2] NCCL INFO Trees [0] 163/-1/-1->162->161 [1] 163/-1/-1->162->161
 80: hkn0425:2076490:2076594 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 99: hkn0501:1320348:1320478 [3] NCCL INFO Trees [0] -1/-1/-1->99->98 [1] -1/-1/-1->99->98
 84: hkn0426:806579:806691 [0] NCCL INFO Trees [0] 85/-1/-1->84->89 [1] 85/80/-1->84->77
 53: hkn0418:1861667:1861790 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 94: hkn0428:659895:659982 [2] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 95/-1/-1->94->93
 94: hkn0428:659895:659982 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
122: hkn0507:3179573:3179686 [2] NCCL INFO Trees [0] 123/-1/-1->122->121 [1] 123/-1/-1->122->121
162: hkn0520:2705389:2705480 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 82: hkn0425:2076510:2076599 [2] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 83/-1/-1->82->81
108: hkn0504:33325:33439 [0] NCCL INFO Trees [0] 109/-1/-1->108->104 [1] 109/100/-1->108->93
 99: hkn0501:1320348:1320478 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 26: hkn0410:1152222:1152317 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25
 86: hkn0426:806587:806697 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] 87/-1/-1->86->85
 54: hkn0418:1861675:1861787 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 90: hkn0427:1127651:1127785 [2] NCCL INFO Trees [0] 91/-1/-1->90->89 [1] 91/-1/-1->90->89
102: hkn0502:221554:221671 [2] NCCL INFO Trees [0] 103/-1/-1->102->101 [1] 103/-1/-1->102->101
 95: hkn0428:659881:659973 [3] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] -1/-1/-1->95->94
123: hkn0507:3179565:3179693 [3] NCCL INFO Trees [0] -1/-1/-1->123->122 [1] -1/-1/-1->123->122
123: hkn0507:3179565:3179693 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
125: hkn0508:3131636:3131730 [1] NCCL INFO Trees [0] 126/-1/-1->125->124 [1] 126/188/-1->125->124
104: hkn0503:2892170:2892284 [0] NCCL INFO Trees [0] 105/108/-1->104->113 [1] 105/-1/-1->104->101
 82: hkn0425:2076510:2076599 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 97: hkn0501:1320356:1320474 [1] NCCL INFO Trees [0] 98/80/-1->97->96 [1] 98/-1/-1->97->96
 26: hkn0410:1152222:1152317 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 84: hkn0426:806579:806691 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 90: hkn0427:1127651:1127785 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
100: hkn0502:221575:221672 [0] NCCL INFO Trees [0] 101/-1/-1->100->105 [1] 101/96/-1->100->108
 95: hkn0428:659881:659973 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
122: hkn0507:3179573:3179686 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 51: hkn0417:2260175:2260285 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50
115: hkn0505:2296296:2296404 [3] NCCL INFO Trees [0] -1/-1/-1->115->114 [1] -1/-1/-1->115->114
125: hkn0508:3131636:3131730 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
104: hkn0503:2892170:2892284 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 83: hkn0425:2076482:2076596 [3] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] -1/-1/-1->83->82
 83: hkn0425:2076482:2076596 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
109: hkn0504:33317:33440 [1] NCCL INFO Trees [0] 110/-1/-1->109->108 [1] 110/116/-1->109->108
 97: hkn0501:1320356:1320474 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 27: hkn0410:1152209:1152320 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26
 86: hkn0426:806587:806697 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 52: hkn0418:1861695:1861793 [0] NCCL INFO Trees [0] 53/-1/-1->52->57 [1] 53/48/-1->52->45
 89: hkn0427:1127663:1127792 [1] NCCL INFO Trees [0] 90/84/-1->89->88 [1] 90/-1/-1->89->88
101: hkn0502:221555:221670 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 47: hkn0415:2488934:2489087 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46
 47: hkn0415:2488934:2489087 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 92: hkn0428:659865:659978 [0] NCCL INFO Trees [0] 93/-1/-1->92->88 [1] 93/76/-1->92->61
 92: hkn0428:659865:659978 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
170: hkn0523:1540556:1540660 [2] NCCL INFO Trees [0] 171/-1/-1->170->169 [1] 171/-1/-1->170->169
 51: hkn0417:2260175:2260285 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
115: hkn0505:2296296:2296404 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
124: hkn0508:3131620:3131734 [0] NCCL INFO Trees [0] 125/-1/-1->124->120 [1] 125/60/-1->124->252
124: hkn0508:3131620:3131734 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
106: hkn0503:2892182:2892286 [2] NCCL INFO Trees [0] 107/-1/-1->106->105 [1] 107/-1/-1->106->105
106: hkn0503:2892182:2892286 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
164: hkn0521:1190286:1190438 [0] NCCL INFO Trees [0] 165/-1/-1->164->169 [1] 165/160/-1->164->172
 81: hkn0425:2076498:2076595 [1] NCCL INFO Trees [0] 82/72/-1->81->80 [1] 82/-1/-1->81->80
108: hkn0504:33325:33439 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 98: hkn0501:1320364:1320480 [2] NCCL INFO Trees [0] 99/-1/-1->98->97 [1] 99/-1/-1->98->97
 25: hkn0410:1152210:1152322 [1] NCCL INFO Trees [0] 26/20/-1->25->24 [1] 26/-1/-1->25->24
 85: hkn0426:806571:806694 [1] NCCL INFO Trees [0] 86/-1/-1->85->84 [1] 86/88/-1->85->84
 85: hkn0426:806571:806694 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 52: hkn0418:1861695:1861793 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 89: hkn0427:1127663:1127792 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 31: hkn0411:2308387:2308486 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30
102: hkn0502:221554:221671 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 46: hkn0415:2488942:2489091 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45
 93: hkn0428:659873:659979 [1] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 94/108/-1->93->92
 93: hkn0428:659873:659979 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
116: hkn0506:830570:830664 [0] NCCL INFO Trees [0] 117/-1/-1->116->121 [1] 117/112/-1->116->109
170: hkn0523:1540556:1540660 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 48: hkn0417:2260167:2260286 [0] NCCL INFO Trees [0] 49/56/-1->48->32 [1] 49/-1/-1->48->52
112: hkn0505:2296308:2296407 [0] NCCL INFO Trees [0] 113/120/-1->112->96 [1] 113/-1/-1->112->116
173: hkn0524:1126272:1126399 [1] NCCL INFO Trees [0] 174/-1/-1->173->172 [1] 174/180/-1->173->172
126: hkn0508:3131648:3131731 [2] NCCL INFO Trees [0] 127/-1/-1->126->125 [1] 127/-1/-1->126->125
105: hkn0503:2892162:2892285 [1] NCCL INFO Trees [0] 106/100/-1->105->104 [1] 106/-1/-1->105->104
164: hkn0521:1190286:1190438 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 81: hkn0425:2076498:2076595 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
109: hkn0504:33317:33440 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 96: hkn0501:1320376:1320475 [0] NCCL INFO Trees [0] 97/112/-1->96->64 [1] 97/-1/-1->96->100
 27: hkn0410:1152209:1152320 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 87: hkn0426:806598:806692 [3] NCCL INFO Trees [0] -1/-1/-1->87->86 [1] -1/-1/-1->87->86
 91: hkn0427:1127642:1127790 [3] NCCL INFO Trees [0] -1/-1/-1->91->90 [1] -1/-1/-1->91->90
 91: hkn0427:1127642:1127790 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
439: hkn0731:1379236:1379354 [3] NCCL INFO Trees [0] -1/-1/-1->439->438 [1] -1/-1/-1->439->438
 31: hkn0411:2308387:2308486 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
100: hkn0502:221575:221672 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 46: hkn0415:2488942:2489091 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 21: hkn0409:2578197:2578308 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/24/-1->21->20
117: hkn0506:830562:830672 [1] NCCL INFO Trees [0] 118/-1/-1->117->116 [1] 118/120/-1->117->116
121: hkn0507:3179593:3179688 [1] NCCL INFO Trees [0] 122/116/-1->121->120 [1] 122/-1/-1->121->120
169: hkn0523:1540568:1540663 [1] NCCL INFO Trees [0] 170/164/-1->169->168 [1] 170/-1/-1->169->168
169: hkn0523:1540568:1540663 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 48: hkn0417:2260167:2260286 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
113: hkn0505:2296285:2296401 [1] NCCL INFO Trees [0] 114/104/-1->113->112 [1] 114/-1/-1->113->112
173: hkn0524:1126272:1126399 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
126: hkn0508:3131648:3131731 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
105: hkn0503:2892162:2892285 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
165: hkn0521:1190302:1190437 [1] NCCL INFO Trees [0] 166/-1/-1->165->164 [1] 166/168/-1->165->164
 33: hkn0412:2254900:2255017 [1] NCCL INFO Trees [0] 34/16/-1->33->32 [1] 34/-1/-1->33->32
 36: hkn0413:2359195:2359304 [0] NCCL INFO Trees [0] 37/-1/-1->36->41 [1] 37/32/-1->36->44
110: hkn0504:33345:33443 [2] NCCL INFO Trees [0] 111/-1/-1->110->109 [1] 111/-1/-1->110->109
 98: hkn0501:1320364:1320480 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 25: hkn0410:1152210:1152322 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 87: hkn0426:806598:806692 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
183: hkn0526:1420898:1421019 [3] NCCL INFO Trees [0] -1/-1/-1->183->182 [1] -1/-1/-1->183->182
 88: hkn0427:1127643:1127786 [0] NCCL INFO Trees [0] 89/92/-1->88->80 [1] 89/-1/-1->88->85
 88: hkn0427:1127643:1127786 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
439: hkn0731:1379236:1379354 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
103: hkn0502:221563:221675 [3] NCCL INFO Trees [0] -1/-1/-1->103->102 [1] -1/-1/-1->103->102
 43: hkn0414:1974063:1974188 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42
440: hkn0732:1204171:1204267 [0] NCCL INFO Trees [0] 441/444/-1->440->432 [1] 441/-1/-1->440->437
 45: hkn0415:2488962:2489090 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/52/-1->45->44
 21: hkn0409:2578197:2578308 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
179: hkn0525:979318:979438 [3] NCCL INFO Trees [0] -1/-1/-1->179->178 [1] -1/-1/-1->179->178
179: hkn0525:979318:979438 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
116: hkn0506:830570:830664 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
121: hkn0507:3179593:3179688 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
171: hkn0523:1540540:1540658 [3] NCCL INFO Trees [0] -1/-1/-1->171->170 [1] -1/-1/-1->171->170
171: hkn0523:1540540:1540658 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 49: hkn0417:2260159:2260288 [1] NCCL INFO Trees [0] 50/40/-1->49->48 [1] 50/-1/-1->49->48
114: hkn0505:2296288:2296402 [2] NCCL INFO Trees [0] 115/-1/-1->114->113 [1] 115/-1/-1->114->113
114: hkn0505:2296288:2296402 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
172: hkn0524:1126300:1126401 [0] NCCL INFO Trees [0] 173/-1/-1->172->168 [1] 173/164/-1->172->157
107: hkn0503:2892154:2892277 [3] NCCL INFO Trees [0] -1/-1/-1->107->106 [1] -1/-1/-1->107->106
165: hkn0521:1190302:1190437 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
448: hkn0734:1149085:1149196 [0] NCCL INFO Trees [0] 449/480/-1->448->384 [1] 449/-1/-1->448->452
 35: hkn0412:2254928:2255011 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34
447: hkn0733:1381891:1382017 [3] NCCL INFO Trees [0] -1/-1/-1->447->446 [1] -1/-1/-1->447->446
 38: hkn0413:2359203:2359295 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37
111: hkn0504:33333:33445 [3] NCCL INFO Trees [0] -1/-1/-1->111->110 [1] -1/-1/-1->111->110
 96: hkn0501:1320376:1320475 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 24: hkn0410:1152208:1152319 [0] NCCL INFO Trees [0] 25/28/-1->24->16 [1] 25/-1/-1->24->21
 24: hkn0410:1152208:1152319 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
183: hkn0526:1420898:1421019 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
438: hkn0731:1379244:1379355 [2] NCCL INFO Trees [0] 439/-1/-1->438->437 [1] 439/-1/-1->438->437
 28: hkn0411:2308375:2308484 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/12/-1->28->60
103: hkn0502:221563:221675 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 43: hkn0414:1974063:1974188 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
186: hkn0527:1341433:1341555 [2] NCCL INFO Trees [0] 187/-1/-1->186->185 [1] 187/-1/-1->186->185
186: hkn0527:1341433:1341555 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 19: hkn0408:2883195:2883322 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18
440: hkn0732:1204171:1204267 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
453: hkn0736:1500847:1500961 [1] NCCL INFO Trees [0] 454/-1/-1->453->452 [1] 454/456/-1->453->452
453: hkn0736:1500847:1500961 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 45: hkn0415:2488962:2489090 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 22: hkn0409:2578209:2578305 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21
117: hkn0506:830562:830672 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
120: hkn0507:3179581:3179694 [0] NCCL INFO Trees [0] 121/124/-1->120->112 [1] 121/-1/-1->120->117
168: hkn0523:1540548:1540665 [0] NCCL INFO Trees [0] 169/172/-1->168->177 [1] 169/-1/-1->168->165
 49: hkn0417:2260159:2260288 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
112: hkn0505:2296308:2296407 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
174: hkn0524:1126288:1126393 [2] NCCL INFO Trees [0] 175/-1/-1->174->173 [1] 175/-1/-1->174->173
107: hkn0503:2892154:2892277 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
166: hkn0521:1190294:1190442 [2] NCCL INFO Trees [0] 167/-1/-1->166->165 [1] 167/-1/-1->166->165
166: hkn0521:1190294:1190442 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
448: hkn0734:1149085:1149196 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 33: hkn0412:2254900:2255017 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
447: hkn0733:1381891:1382017 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
457: hkn0801:2232468:2232617 [1] NCCL INFO Trees [0] 458/452/-1->457->456 [1] 458/-1/-1->457->456
 36: hkn0413:2359195:2359304 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
110: hkn0504:33345:33443 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
180: hkn0526:1420918:1421023 [0] NCCL INFO Trees [0] 181/-1/-1->180->185 [1] 181/176/-1->180->173
461: hkn0802:1192842:1192951 [1] NCCL INFO Trees [0] 462/-1/-1->461->460 [1] 462/468/-1->461->460
438: hkn0731:1379244:1379355 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 29: hkn0411:2308366:2308483 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/44/-1->29->28
 29: hkn0411:2308366:2308483 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 42: hkn0414:1974071:1974185 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41
187: hkn0527:1341441:1341554 [3] NCCL INFO Trees [0] -1/-1/-1->187->186 [1] -1/-1/-1->187->186
 19: hkn0408:2883195:2883322 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
441: hkn0732:1204159:1204268 [1] NCCL INFO Trees [0] 442/436/-1->441->440 [1] 442/-1/-1->441->440
441: hkn0732:1204159:1204268 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
454: hkn0736:1500869:1500964 [2] NCCL INFO Trees [0] 455/-1/-1->454->453 [1] 455/-1/-1->454->453
454: hkn0736:1500869:1500964 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 44: hkn0415:2488950:2489094 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/36/-1->44->29
 23: hkn0409:2578181:2578301 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22
176: hkn0525:979338:979432 [0] NCCL INFO Trees [0] 177/184/-1->176->160 [1] 177/-1/-1->176->180
176: hkn0525:979338:979432 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
118: hkn0506:830582:830669 [2] NCCL INFO Trees [0] 119/-1/-1->118->117 [1] 119/-1/-1->118->117
118: hkn0506:830582:830669 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
120: hkn0507:3179581:3179694 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
168: hkn0523:1540548:1540665 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 50: hkn0417:2260187:2260291 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49
113: hkn0505:2296285:2296401 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
175: hkn0524:1126280:1126395 [3] NCCL INFO Trees [0] -1/-1/-1->175->174 [1] -1/-1/-1->175->174
175: hkn0524:1126280:1126395 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
167: hkn0521:1190314:1190440 [3] NCCL INFO Trees [0] -1/-1/-1->167->166 [1] -1/-1/-1->167->166
449: hkn0734:1149097:1149191 [1] NCCL INFO Trees [0] 450/416/-1->449->448 [1] 450/-1/-1->449->448
 35: hkn0412:2254928:2255011 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
445: hkn0733:1381907:1382020 [1] NCCL INFO Trees [0] 446/-1/-1->445->444 [1] 446/476/-1->445->444
457: hkn0801:2232468:2232617 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 38: hkn0413:2359203:2359295 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
111: hkn0504:33333:33445 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
180: hkn0526:1420918:1421023 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
461: hkn0802:1192842:1192951 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
436: hkn0731:1379234:1379347 [0] NCCL INFO Trees [0] 437/-1/-1->436->441 [1] 437/432/-1->436->429
436: hkn0731:1379234:1379347 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 30: hkn0411:2308367:2308482 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29
 30: hkn0411:2308367:2308482 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 42: hkn0414:1974071:1974185 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
184: hkn0527:1341449:1341560 [0] NCCL INFO Trees [0] 185/188/-1->184->176 [1] 185/-1/-1->184->181
184: hkn0527:1341449:1341560 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 17: hkn0408:2883223:2883320 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] 18/-1/-1->17->16
442: hkn0732:1204151:1204273 [2] NCCL INFO Trees [0] 443/-1/-1->442->441 [1] 443/-1/-1->442->441
442: hkn0732:1204151:1204273 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
455: hkn0736:1500858:1500966 [3] NCCL INFO Trees [0] -1/-1/-1->455->454 [1] -1/-1/-1->455->454
455: hkn0736:1500858:1500966 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 44: hkn0415:2488950:2489094 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 22: hkn0409:2578209:2578305 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
177: hkn0525:979326:979436 [1] NCCL INFO Trees [0] 178/168/-1->177->176 [1] 178/-1/-1->177->176
119: hkn0506:830554:830666 [3] NCCL INFO Trees [0] -1/-1/-1->119->118 [1] -1/-1/-1->119->118
 50: hkn0417:2260187:2260291 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
172: hkn0524:1126300:1126401 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
167: hkn0521:1190314:1190440 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
450: hkn0734:1149069:1149195 [2] NCCL INFO Trees [0] 451/-1/-1->450->449 [1] 451/-1/-1->450->449
450: hkn0734:1149069:1149195 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 32: hkn0412:2254916:2255009 [0] NCCL INFO Trees [0] 33/48/-1->32->65 [1] 33/-1/-1->32->36
445: hkn0733:1381907:1382020 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
435: hkn0730:1394249:1394347 [3] NCCL INFO Trees [0] -1/-1/-1->435->434 [1] -1/-1/-1->435->434
458: hkn0801:2232476:2232619 [2] NCCL INFO Trees [0] 459/-1/-1->458->457 [1] 459/-1/-1->458->457
458: hkn0801:2232476:2232619 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 14: hkn0407:1808755:1808914 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
 37: hkn0413:2359194:2359299 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/40/-1->37->36
181: hkn0526:1420907:1421018 [1] NCCL INFO Trees [0] 182/-1/-1->181->180 [1] 182/184/-1->181->180
192: hkn0529:1533356:1533475 [0] NCCL INFO Trees [0] 193/224/-1->192->128 [1] 193/-1/-1->192->196
463: hkn0802:1192840:1192948 [3] NCCL INFO Trees [0] -1/-1/-1->463->462 [1] -1/-1/-1->463->462
437: hkn0731:1379256:1379351 [1] NCCL INFO Trees [0] 438/-1/-1->437->436 [1] 438/440/-1->437->436
437: hkn0731:1379256:1379351 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 28: hkn0411:2308375:2308484 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 41: hkn0414:1974079:1974183 [1] NCCL INFO Trees [0] 42/36/-1->41->40 [1] 42/-1/-1->41->40
 41: hkn0414:1974079:1974183 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  7: hkn0404:1331852:1331996 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
187: hkn0527:1341441:1341554 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 17: hkn0408:2883223:2883320 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
443: hkn0732:1204148:1204274 [3] NCCL INFO Trees [0] -1/-1/-1->443->442 [1] -1/-1/-1->443->442
452: hkn0736:1500850:1500969 [0] NCCL INFO Trees [0] 453/-1/-1->452->457 [1] 453/448/-1->452->460
 23: hkn0409:2578181:2578301 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
178: hkn0525:979310:979433 [2] NCCL INFO Trees [0] 179/-1/-1->178->177 [1] 179/-1/-1->178->177
178: hkn0525:979310:979433 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
119: hkn0506:830554:830666 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
174: hkn0524:1126288:1126393 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 10: hkn0405:3199307:3199411 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
449: hkn0734:1149097:1149191 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 34: hkn0412:2254908:2255016 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33
 34: hkn0412:2254908:2255016 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
446: hkn0733:1381899:1382018 [2] NCCL INFO Trees [0] 447/-1/-1->446->445 [1] 447/-1/-1->446->445
  3: hkn0403:1751336:1751695 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
435: hkn0730:1394249:1394347 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
459: hkn0801:2232488:2232616 [3] NCCL INFO Trees [0] -1/-1/-1->459->458 [1] -1/-1/-1->459->458
 14: hkn0407:1808755:1808914 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 39: hkn0413:2359214:2359301 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38
181: hkn0526:1420907:1421018 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
192: hkn0529:1533356:1533475 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
463: hkn0802:1192840:1192948 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 40: hkn0414:1974091:1974182 [0] NCCL INFO Trees [0] 41/44/-1->40->49 [1] 41/-1/-1->40->37
  7: hkn0404:1331852:1331996 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
185: hkn0527:1341461:1341561 [1] NCCL INFO Trees [0] 186/180/-1->185->184 [1] 186/-1/-1->185->184
185: hkn0527:1341461:1341561 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
 18: hkn0408:2883203:2883321 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17
443: hkn0732:1204148:1204274 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
452: hkn0736:1500850:1500969 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 20: hkn0409:2578189:2578309 [0] NCCL INFO Trees [0] 21/-1/-1->20->25 [1] 21/16/-1->20->13
177: hkn0525:979326:979436 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
188: hkn0528:1294198:1294318 [0] NCCL INFO Trees [0] 189/-1/-1->188->184 [1] 189/156/-1->188->125
 10: hkn0405:3199307:3199411 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
451: hkn0734:1149077:1149192 [3] NCCL INFO Trees [0] -1/-1/-1->451->450 [1] -1/-1/-1->451->450
451: hkn0734:1149077:1149192 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 32: hkn0412:2254916:2255009 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
467: hkn0803:869056:869160 [3] NCCL INFO Trees [0] -1/-1/-1->467->466 [1] -1/-1/-1->467->466
446: hkn0733:1381899:1382018 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 00/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
469: hkn0804:1198123:1198240 [1] NCCL INFO Trees [0] 470/-1/-1->469->468 [1] 470/472/-1->469->468
456: hkn0801:2232460:2232615 [0] NCCL INFO Trees [0] 457/460/-1->456->465 [1] 457/-1/-1->456->453
 12: hkn0407:1808763:1808908 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/4/-1->12->28
 37: hkn0413:2359194:2359299 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
182: hkn0526:1420936:1421020 [2] NCCL INFO Trees [0] 183/-1/-1->182->181 [1] 183/-1/-1->182->181
182: hkn0526:1420936:1421020 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
194: hkn0529:1533376:1533479 [2] NCCL INFO Trees [0] 195/-1/-1->194->193 [1] 195/-1/-1->194->193
460: hkn0802:1192854:1192947 [0] NCCL INFO Trees [0] 461/-1/-1->460->456 [1] 461/452/-1->460->476
511: hkn0816:368147:368244 [3] NCCL INFO Trees [0] -1/-1/-1->511->510 [1] -1/-1/-1->511->510
 40: hkn0414:1974091:1974182 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  6: hkn0404:1331844:1331992 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
 18: hkn0408:2883203:2883321 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 20: hkn0409:2578189:2578309 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
188: hkn0528:1294198:1294318 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  9: hkn0405:3199291:3199417 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/-1/-1->9->8
467: hkn0803:869056:869160 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
444: hkn0733:1381919:1382019 [0] NCCL INFO Trees [0] 445/-1/-1->444->440 [1] 445/412/-1->444->381
473: hkn0805:1104610:1104724 [1] NCCL INFO Trees [0] 474/468/-1->473->472 [1] 474/-1/-1->473->472
  3: hkn0403:1751336:1751695 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
469: hkn0804:1198123:1198240 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
459: hkn0801:2232488:2232616 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 12: hkn0407:1808763:1808908 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 39: hkn0413:2359214:2359301 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
194: hkn0529:1533376:1533479 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
462: hkn0802:1192841:1192950 [2] NCCL INFO Trees [0] 463/-1/-1->462->461 [1] 463/-1/-1->462->461
511: hkn0816:368147:368244 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  6: hkn0404:1331844:1331992 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 16: hkn0408:2883211:2883325 [0] NCCL INFO Trees [0] 17/24/-1->16->33 [1] 17/-1/-1->16->20
477: hkn0806:1046851:1046947 [1] NCCL INFO Trees [0] 478/-1/-1->477->476 [1] 478/492/-1->477->476
480: hkn0807:1011577:1011693 [0] NCCL INFO Trees [0] 481/496/-1->480->448 [1] 481/-1/-1->480->484
189: hkn0528:1294214:1294319 [1] NCCL INFO Trees [0] 190/-1/-1->189->188 [1] 190/220/-1->189->188
 11: hkn0405:3199299:3199420 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10
464: hkn0803:869028:869155 [0] NCCL INFO Trees [0] 465/472/-1->464->481 [1] 465/-1/-1->464->468
464: hkn0803:869028:869155 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
444: hkn0733:1381919:1382019 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
473: hkn0805:1104610:1104724 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  2: hkn0403:1751321:1751698 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
471: hkn0804:1198115:1198243 [3] NCCL INFO Trees [0] -1/-1/-1->471->470 [1] -1/-1/-1->471->470
471: hkn0804:1198115:1198243 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
456: hkn0801:2232460:2232615 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 15: hkn0407:1808771:1808909 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
195: hkn0529:1533364:1533476 [3] NCCL INFO Trees [0] -1/-1/-1->195->194 [1] -1/-1/-1->195->194
460: hkn0802:1192854:1192947 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  4: hkn0404:1331872:1331990 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/0/-1->4->12
 16: hkn0408:2883211:2883325 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
476: hkn0806:1046831:1046950 [0] NCCL INFO Trees [0] 477/-1/-1->476->472 [1] 477/460/-1->476->445
483: hkn0807:1011596:1011696 [3] NCCL INFO Trees [0] -1/-1/-1->483->482 [1] -1/-1/-1->483->482
483: hkn0807:1011596:1011696 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
270: hkn0616:397349:397480 [2] NCCL INFO Trees [0] 271/-1/-1->270->269 [1] 271/-1/-1->270->269
196: hkn0530:1250671:1250770 [0] NCCL INFO Trees [0] 197/-1/-1->196->201 [1] 197/192/-1->196->204
196: hkn0530:1250671:1250770 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
189: hkn0528:1294214:1294319 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
  9: hkn0405:3199291:3199417 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
273: hkn0617:2287153:2287277 [1] NCCL INFO Trees [0] 274/264/-1->273->272 [1] 274/-1/-1->273->272
273: hkn0617:2287153:2287277 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
465: hkn0803:869036:869157 [1] NCCL INFO Trees [0] 466/456/-1->465->464 [1] 466/-1/-1->465->464
465: hkn0803:869036:869157 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
474: hkn0805:1104630:1104729 [2] NCCL INFO Trees [0] 475/-1/-1->474->473 [1] 475/-1/-1->474->473
  2: hkn0403:1751321:1751698 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
434: hkn0730:1394229:1394348 [2] NCCL INFO Trees [0] 435/-1/-1->434->433 [1] 435/-1/-1->434->433
468: hkn0804:1198143:1198246 [0] NCCL INFO Trees [0] 469/-1/-1->468->473 [1] 469/464/-1->468->461
 15: hkn0407:1808771:1808909 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
195: hkn0529:1533364:1533476 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
462: hkn0802:1192841:1192950 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
510: hkn0816:368135:368243 [2] NCCL INFO Trees [0] 511/-1/-1->510->509 [1] 511/-1/-1->510->509
  4: hkn0404:1331872:1331990 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
477: hkn0806:1046851:1046947 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
200: hkn0531:1223086:1223206 [0] NCCL INFO Trees [0] 201/204/-1->200->209 [1] 201/-1/-1->200->197
480: hkn0807:1011577:1011693 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
277: hkn0621:1984016:1984143 [1] NCCL INFO Trees [0] 278/-1/-1->277->276 [1] 278/280/-1->277->276
270: hkn0616:397349:397480 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
198: hkn0530:1250651:1250763 [2] NCCL INFO Trees [0] 199/-1/-1->198->197 [1] 199/-1/-1->198->197
198: hkn0530:1250651:1250763 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
190: hkn0528:1294206:1294325 [2] NCCL INFO Trees [0] 191/-1/-1->190->189 [1] 191/-1/-1->190->189
190: hkn0528:1294206:1294325 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
 11: hkn0405:3199299:3199420 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
274: hkn0617:2287161:2287275 [2] NCCL INFO Trees [0] 275/-1/-1->274->273 [1] 275/-1/-1->274->273
274: hkn0617:2287161:2287275 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
466: hkn0803:869044:869156 [2] NCCL INFO Trees [0] 467/-1/-1->466->465 [1] 467/-1/-1->466->465
466: hkn0803:869044:869156 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
475: hkn0805:1104618:1104726 [3] NCCL INFO Trees [0] -1/-1/-1->475->474 [1] -1/-1/-1->475->474
  1: hkn0403:1751324:1751696 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
470: hkn0804:1198131:1198247 [2] NCCL INFO Trees [0] 471/-1/-1->470->469 [1] 471/-1/-1->470->469
505: hkn0815:387660:387783 [1] NCCL INFO Trees [0] 506/500/-1->505->504 [1] 506/-1/-1->505->504
 13: hkn0407:1808783:1808911 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/20/-1->13->12
193: hkn0529:1533348:1533477 [1] NCCL INFO Trees [0] 194/160/-1->193->192 [1] 194/-1/-1->193->192
510: hkn0816:368135:368243 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
478: hkn0806:1046839:1046949 [2] NCCL INFO Trees [0] 479/-1/-1->478->477 [1] 479/-1/-1->478->477
200: hkn0531:1223086:1223206 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
482: hkn0807:1011569:1011689 [2] NCCL INFO Trees [0] 483/-1/-1->482->481 [1] 483/-1/-1->482->481
482: hkn0807:1011569:1011689 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
277: hkn0621:1984016:1984143 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
271: hkn0616:397365:397472 [3] NCCL INFO Trees [0] -1/-1/-1->271->270 [1] -1/-1/-1->271->270
199: hkn0530:1250659:1250771 [3] NCCL INFO Trees [0] -1/-1/-1->199->198 [1] -1/-1/-1->199->198
258: hkn0612:909479:909575 [2] NCCL INFO Trees [0] 259/-1/-1->258->257 [1] 259/-1/-1->258->257
191: hkn0528:1294226:1294323 [3] NCCL INFO Trees [0] -1/-1/-1->191->190 [1] -1/-1/-1->191->190
191: hkn0528:1294226:1294323 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  8: hkn0405:3199319:3199416 [0] NCCL INFO Trees [0] 9/12/-1->8->17 [1] 9/-1/-1->8->5
233: hkn0605:704610:704720 [1] NCCL INFO Trees [0] 234/228/-1->233->232 [1] 234/-1/-1->233->232
275: hkn0617:2287181:2287280 [3] NCCL INFO Trees [0] -1/-1/-1->275->274 [1] -1/-1/-1->275->274
484: hkn0808:963191:963307 [0] NCCL INFO Trees [0] 485/-1/-1->484->489 [1] 485/480/-1->484->492
474: hkn0805:1104630:1104729 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  1: hkn0403:1751324:1751696 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
434: hkn0730:1394229:1394348 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
468: hkn0804:1198143:1198246 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
506: hkn0815:387640:387788 [2] NCCL INFO Trees [0] 507/-1/-1->506->505 [1] 507/-1/-1->506->505
 13: hkn0407:1808783:1808911 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
193: hkn0529:1533348:1533477 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
509: hkn0816:368127:368238 [1] NCCL INFO Trees [0] 510/-1/-1->509->508 [1] 510/-1/-1->509->508
479: hkn0806:1046823:1046948 [3] NCCL INFO Trees [0] -1/-1/-1->479->478 [1] -1/-1/-1->479->478
479: hkn0806:1046823:1046948 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
201: hkn0531:1223094:1223197 [1] NCCL INFO Trees [0] 202/196/-1->201->200 [1] 202/-1/-1->201->200
201: hkn0531:1223094:1223197 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
481: hkn0807:1011585:1011697 [1] NCCL INFO Trees [0] 482/464/-1->481->480 [1] 482/-1/-1->481->480
481: hkn0807:1011585:1011697 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
278: hkn0621:1984032:1984138 [2] NCCL INFO Trees [0] 279/-1/-1->278->277 [1] 279/-1/-1->278->277
278: hkn0621:1984032:1984138 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
271: hkn0616:397365:397472 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
199: hkn0530:1250659:1250771 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
258: hkn0612:909479:909575 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  8: hkn0405:3199319:3199416 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
263: hkn0613:895167:895298 [3] NCCL INFO Trees [0] -1/-1/-1->263->262 [1] -1/-1/-1->263->262
263: hkn0613:895167:895298 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
272: hkn0617:2287169:2287282 [0] NCCL INFO Trees [0] 273/280/-1->272->289 [1] 273/-1/-1->272->276
484: hkn0808:963191:963307 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
492: hkn0810:932042:932160 [0] NCCL INFO Trees [0] 493/-1/-1->492->488 [1] 493/484/-1->492->477
475: hkn0805:1104618:1104726 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
499: hkn0812:686277:686393 [3] NCCL INFO Trees [0] -1/-1/-1->499->498 [1] -1/-1/-1->499->498
503: hkn0814:668359:668454 [3] NCCL INFO Trees [0] -1/-1/-1->503->502 [1] -1/-1/-1->503->502
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 01/02 :    0   3   2   1   4   7   6   5   8  11  10   9  12  15  14  13  16  19  18  17
433: hkn0730:1394237:1394350 [1] NCCL INFO Trees [0] 434/424/-1->433->432 [1] 434/-1/-1->433->432
470: hkn0804:1198131:1198247 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
507: hkn0815:387648:387785 [3] NCCL INFO Trees [0] -1/-1/-1->507->506 [1] -1/-1/-1->507->506
509: hkn0816:368127:368238 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
476: hkn0806:1046831:1046950 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
202: hkn0531:1223078:1223201 [2] NCCL INFO Trees [0] 203/-1/-1->202->201 [1] 203/-1/-1->202->201
202: hkn0531:1223078:1223201 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
279: hkn0621:1984024:1984141 [3] NCCL INFO Trees [0] -1/-1/-1->279->278 [1] -1/-1/-1->279->278
279: hkn0621:1984024:1984141 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
268: hkn0616:397357:397478 [0] NCCL INFO Trees [0] 269/-1/-1->268->264 [1] 269/260/-1->268->284
197: hkn0530:1250643:1250765 [1] NCCL INFO Trees [0] 198/-1/-1->197->196 [1] 198/200/-1->197->196
280: hkn0622:2012990:2013090 [0] NCCL INFO Trees [0] 281/284/-1->280->272 [1] 281/-1/-1->280->277
257: hkn0612:909451:909581 [1] NCCL INFO Trees [0] 258/128/-1->257->256 [1] 258/-1/-1->257->256
257: hkn0612:909451:909581 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
239: hkn0606:2364542:2364663 [3] NCCL INFO Trees [0] -1/-1/-1->239->238 [1] -1/-1/-1->239->238
233: hkn0605:704610:704720 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
275: hkn0617:2287181:2287280 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
486: hkn0808:963183:963303 [2] NCCL INFO Trees [0] 487/-1/-1->486->485 [1] 487/-1/-1->486->485
492: hkn0810:932042:932160 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
472: hkn0805:1104602:1104720 [0] NCCL INFO Trees [0] 473/476/-1->472->464 [1] 473/-1/-1->472->469
472: hkn0805:1104602:1104720 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
499: hkn0812:686277:686393 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
503: hkn0814:668359:668454 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
  0: hkn0403:1751320:1751689 [0] NCCL INFO Trees [0] 1/256/-1->0->-1 [1] 1/-1/-1->0->4
433: hkn0730:1394237:1394350 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
505: hkn0815:387660:387783 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
508: hkn0816:368125:368237 [0] NCCL INFO Trees [0] 509/-1/-1->508->504 [1] 509/252/-1->508->-1
478: hkn0806:1046839:1046949 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
203: hkn0531:1223106:1223204 [3] NCCL INFO Trees [0] -1/-1/-1->203->202 [1] -1/-1/-1->203->202
203: hkn0531:1223106:1223204 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
265: hkn0615:406807:406907 [1] NCCL INFO Trees [0] 266/260/-1->265->264 [1] 266/-1/-1->265->264
255: hkn0611:702317:702419 [3] NCCL INFO Trees [0] -1/-1/-1->255->254 [1] -1/-1/-1->255->254
276: hkn0621:1984044:1984134 [0] NCCL INFO Trees [0] 277/-1/-1->276->281 [1] 277/272/-1->276->269
268: hkn0616:397357:397478 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
197: hkn0530:1250643:1250765 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
280: hkn0622:2012990:2013090 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
259: hkn0612:909467:909577 [3] NCCL INFO Trees [0] -1/-1/-1->259->258 [1] -1/-1/-1->259->258
248: hkn0609:703361:703450 [0] NCCL INFO Trees [0] 249/252/-1->248->240 [1] 249/-1/-1->248->245
239: hkn0606:2364542:2364663 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
262: hkn0613:895183:895295 [2] NCCL INFO Trees [0] 263/-1/-1->262->261 [1] 263/-1/-1->262->261
232: hkn0605:704594:704721 [0] NCCL INFO Trees [0] 233/236/-1->232->241 [1] 233/-1/-1->232->229
272: hkn0617:2287169:2287282 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
486: hkn0808:963183:963303 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
495: hkn0810:932034:932161 [3] NCCL INFO Trees [0] -1/-1/-1->495->494 [1] -1/-1/-1->495->494
497: hkn0812:686297:686395 [1] NCCL INFO Trees [0] 498/488/-1->497->496 [1] 498/-1/-1->497->496
500: hkn0814:668339:668453 [0] NCCL INFO Trees [0] 501/-1/-1->500->505 [1] 501/496/-1->500->493
500: hkn0814:668339:668453 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  0: hkn0403:1751320:1751689 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
432: hkn0730:1394221:1394352 [0] NCCL INFO Trees [0] 433/440/-1->432->416 [1] 433/-1/-1->432->436
506: hkn0815:387640:387788 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
508: hkn0816:368125:368237 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
  5: hkn0404:1331860:1331998 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/8/-1->5->4
266: hkn0615:406787:406911 [2] NCCL INFO Trees [0] 267/-1/-1->266->265 [1] 267/-1/-1->266->265
266: hkn0615:406787:406911 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
205: hkn0532:916650:916971 [1] NCCL INFO Trees [0] 206/-1/-1->205->204 [1] 206/212/-1->205->204
255: hkn0611:702317:702419 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
276: hkn0621:1984044:1984134 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
269: hkn0616:397377:397476 [1] NCCL INFO Trees [0] 270/-1/-1->269->268 [1] 270/276/-1->269->268
281: hkn0622:2012970:2013094 [1] NCCL INFO Trees [0] 282/276/-1->281->280 [1] 282/-1/-1->281->280
259: hkn0612:909467:909577 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
248: hkn0609:703361:703450 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
238: hkn0606:2364570:2364670 [2] NCCL INFO Trees [0] 239/-1/-1->238->237 [1] 239/-1/-1->238->237
261: hkn0613:895175:895292 [1] NCCL INFO Trees [0] 262/-1/-1->261->260 [1] 262/264/-1->261->260
261: hkn0613:895175:895292 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
231: hkn0604:681764:681862 [3] NCCL INFO Trees [0] -1/-1/-1->231->230 [1] -1/-1/-1->231->230
231: hkn0604:681764:681862 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
235: hkn0605:704602:704724 [3] NCCL INFO Trees [0] -1/-1/-1->235->234 [1] -1/-1/-1->235->234
245: hkn0608:478274:478386 [1] NCCL INFO Trees [0] 246/-1/-1->245->244 [1] 246/248/-1->245->244
485: hkn0808:963203:963306 [1] NCCL INFO Trees [0] 486/-1/-1->485->484 [1] 486/488/-1->485->484
485: hkn0808:963203:963306 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
494: hkn0810:932062:932167 [2] NCCL INFO Trees [0] 495/-1/-1->494->493 [1] 495/-1/-1->494->493
489: hkn0809:929888:930005 [1] NCCL INFO Trees [0] 490/484/-1->489->488 [1] 490/-1/-1->489->488
497: hkn0812:686297:686395 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
501: hkn0814:668331:668452 [1] NCCL INFO Trees [0] 502/-1/-1->501->500 [1] 502/504/-1->501->500
501: hkn0814:668331:668452 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
431: hkn0728:1316457:1316577 [3] NCCL INFO Trees [0] -1/-1/-1->431->430 [1] -1/-1/-1->431->430
431: hkn0728:1316457:1316577 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
432: hkn0730:1394221:1394352 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
507: hkn0815:387648:387785 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
427: hkn0727:1338271:1338389 [3] NCCL INFO Trees [0] -1/-1/-1->427->426 [1] -1/-1/-1->427->426
267: hkn0615:406795:406908 [3] NCCL INFO Trees [0] -1/-1/-1->267->266 [1] -1/-1/-1->267->266
267: hkn0615:406795:406908 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
205: hkn0532:916650:916971 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
253: hkn0611:702329:702425 [1] NCCL INFO Trees [0] 254/-1/-1->253->252 [1] 254/380/-1->253->252
208: hkn0534:1140908:1141032 [0] NCCL INFO Trees [0] 209/216/-1->208->225 [1] 209/-1/-1->208->212
269: hkn0616:397377:397476 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
281: hkn0622:2012970:2013094 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
256: hkn0612:909459:909583 [0] NCCL INFO Trees [0] 257/384/-1->256->0 [1] 257/-1/-1->256->260
237: hkn0606:2364558:2364669 [1] NCCL INFO Trees [0] 238/-1/-1->237->236 [1] 238/244/-1->237->236
262: hkn0613:895183:895295 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
241: hkn0607:896873:896982 [1] NCCL INFO Trees [0] 242/232/-1->241->240 [1] 242/-1/-1->241->240
232: hkn0605:704594:704721 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
245: hkn0608:478274:478386 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
487: hkn0808:963175:963302 [3] NCCL INFO Trees [0] -1/-1/-1->487->486 [1] -1/-1/-1->487->486
487: hkn0808:963175:963302 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
495: hkn0810:932034:932161 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
490: hkn0809:929907:930004 [2] NCCL INFO Trees [0] 491/-1/-1->490->489 [1] 491/-1/-1->490->489
490: hkn0809:929907:930004 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
498: hkn0812:686269:686396 [2] NCCL INFO Trees [0] 499/-1/-1->498->497 [1] 499/-1/-1->498->497
502: hkn0814:668347:668457 [2] NCCL INFO Trees [0] 503/-1/-1->502->501 [1] 503/-1/-1->502->501
502: hkn0814:668347:668457 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
504: hkn0815:387632:387784 [0] NCCL INFO Trees [0] 505/508/-1->504->496 [1] 505/-1/-1->504->501
  5: hkn0404:1331860:1331998 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
265: hkn0615:406807:406907 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
204: hkn0532:916658:916970 [0] NCCL INFO Trees [0] 205/-1/-1->204->200 [1] 205/196/-1->204->220
254: hkn0611:702301:702422 [2] NCCL INFO Trees [0] 255/-1/-1->254->253 [1] 255/-1/-1->254->253
208: hkn0534:1140908:1141032 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
282: hkn0622:2012978:2013091 [2] NCCL INFO Trees [0] 283/-1/-1->282->281 [1] 283/-1/-1->282->281
256: hkn0612:909459:909583 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
249: hkn0609:703333:703446 [1] NCCL INFO Trees [0] 250/244/-1->249->248 [1] 250/-1/-1->249->248
249: hkn0609:703333:703446 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
238: hkn0606:2364570:2364670 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
260: hkn0613:895195:895293 [0] NCCL INFO Trees [0] 261/-1/-1->260->265 [1] 261/256/-1->260->268
260: hkn0613:895195:895293 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
243: hkn0607:896857:896978 [3] NCCL INFO Trees [0] -1/-1/-1->243->242 [1] -1/-1/-1->243->242
243: hkn0607:896857:896978 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
234: hkn0605:704621:704722 [2] NCCL INFO Trees [0] 235/-1/-1->234->233 [1] 235/-1/-1->234->233
247: hkn0608:478286:478382 [3] NCCL INFO Trees [0] -1/-1/-1->247->246 [1] -1/-1/-1->247->246
213: hkn0535:2391499:2391618 [1] NCCL INFO Trees [0] 214/-1/-1->213->212 [1] 214/216/-1->213->212
494: hkn0810:932062:932167 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
489: hkn0809:929888:930005 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
498: hkn0812:686269:686396 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
429: hkn0728:1316473:1316578 [1] NCCL INFO Trees [0] 430/-1/-1->429->428 [1] 430/436/-1->429->428
504: hkn0815:387632:387784 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
427: hkn0727:1338271:1338389 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
264: hkn0615:406779:406906 [0] NCCL INFO Trees [0] 265/268/-1->264->273 [1] 265/-1/-1->264->261
264: hkn0615:406779:406906 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
206: hkn0532:916669:916966 [2] NCCL INFO Trees [0] 207/-1/-1->206->205 [1] 207/-1/-1->206->205
206: hkn0532:916669:916966 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
290: hkn0624:1765428:1765554 [2] NCCL INFO Trees [0] 291/-1/-1->290->289 [1] 291/-1/-1->290->289
253: hkn0611:702329:702425 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
211: hkn0534:1140916:1141035 [3] NCCL INFO Trees [0] -1/-1/-1->211->210 [1] -1/-1/-1->211->210
223: hkn0602:3353954:3354221 [3] NCCL INFO Trees [0] -1/-1/-1->223->222 [1] -1/-1/-1->223->222
282: hkn0622:2012978:2013091 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
286: hkn0623:1865246:1865351 [2] NCCL INFO Trees [0] 287/-1/-1->286->285 [1] 287/-1/-1->286->285
286: hkn0623:1865246:1865351 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
250: hkn0609:703349:703447 [2] NCCL INFO Trees [0] 251/-1/-1->250->249 [1] 251/-1/-1->250->249
250: hkn0609:703349:703447 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
237: hkn0606:2364558:2364669 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
229: hkn0604:681744:681864 [1] NCCL INFO Trees [0] 230/-1/-1->229->228 [1] 230/232/-1->229->228
240: hkn0607:896885:896985 [0] NCCL INFO Trees [0] 241/248/-1->240->224 [1] 241/-1/-1->240->244
240: hkn0607:896885:896985 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
235: hkn0605:704602:704724 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
247: hkn0608:478286:478382 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
422: hkn0726:1540606:1540728 [2] NCCL INFO Trees [0] 423/-1/-1->422->421 [1] 423/-1/-1->422->421
493: hkn0810:932050:932165 [1] NCCL INFO Trees [0] 494/-1/-1->493->492 [1] 494/500/-1->493->492
488: hkn0809:929896:930007 [0] NCCL INFO Trees [0] 489/492/-1->488->497 [1] 489/-1/-1->488->485
496: hkn0812:686285:686394 [0] NCCL INFO Trees [0] 497/504/-1->496->480 [1] 497/-1/-1->496->500
429: hkn0728:1316473:1316578 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
425: hkn0727:1338287:1338387 [1] NCCL INFO Trees [0] 426/420/-1->425->424 [1] 426/-1/-1->425->424
207: hkn0532:916642:916973 [3] NCCL INFO Trees [0] -1/-1/-1->207->206 [1] -1/-1/-1->207->206
290: hkn0624:1765428:1765554 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
254: hkn0611:702301:702422 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
218: hkn0601:110156:110284 [2] NCCL INFO Trees [0] 219/-1/-1->218->217 [1] 219/-1/-1->218->217
218: hkn0601:110156:110284 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
211: hkn0534:1140916:1141035 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
221: hkn0602:3353962:3354225 [1] NCCL INFO Trees [0] 222/-1/-1->221->220 [1] 222/236/-1->221->220
283: hkn0622:2012962:2013089 [3] NCCL INFO Trees [0] -1/-1/-1->283->282 [1] -1/-1/-1->283->282
287: hkn0623:1865238:1865357 [3] NCCL INFO Trees [0] -1/-1/-1->287->286 [1] -1/-1/-1->287->286
251: hkn0609:703341:703443 [3] NCCL INFO Trees [0] -1/-1/-1->251->250 [1] -1/-1/-1->251->250
251: hkn0609:703341:703443 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
236: hkn0606:2364550:2364664 [0] NCCL INFO Trees [0] 237/-1/-1->236->232 [1] 237/228/-1->236->221
228: hkn0604:681736:681856 [0] NCCL INFO Trees [0] 229/-1/-1->228->233 [1] 229/224/-1->228->236
241: hkn0607:896873:896982 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
234: hkn0605:704621:704722 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
244: hkn0608:478258:478384 [0] NCCL INFO Trees [0] 245/-1/-1->244->249 [1] 245/240/-1->244->237
227: hkn0603:1405656:1405782 [3] NCCL INFO Trees [0] -1/-1/-1->227->226 [1] -1/-1/-1->227->226
214: hkn0535:2391519:2391622 [2] NCCL INFO Trees [0] 215/-1/-1->214->213 [1] 215/-1/-1->214->213
423: hkn0726:1540634:1540730 [3] NCCL INFO Trees [0] -1/-1/-1->423->422 [1] -1/-1/-1->423->422
493: hkn0810:932050:932165 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
491: hkn0809:929880:930000 [3] NCCL INFO Trees [0] -1/-1/-1->491->490 [1] -1/-1/-1->491->490
496: hkn0812:686285:686394 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
428: hkn0728:1316465:1316582 [0] NCCL INFO Trees [0] 429/-1/-1->428->424 [1] 429/420/-1->428->413
425: hkn0727:1338287:1338387 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
204: hkn0532:916658:916970 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
252: hkn0611:702309:702428 [0] NCCL INFO Trees [0] 253/-1/-1->252->248 [1] 253/124/-1->252->508
219: hkn0601:110164:110279 [3] NCCL INFO Trees [0] -1/-1/-1->219->218 [1] -1/-1/-1->219->218
209: hkn0534:1140924:1141030 [1] NCCL INFO Trees [0] 210/200/-1->209->208 [1] 210/-1/-1->209->208
209: hkn0534:1140924:1141030 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
223: hkn0602:3353954:3354221 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
283: hkn0622:2012962:2013089 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
287: hkn0623:1865238:1865357 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
236: hkn0606:2364550:2364664 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
229: hkn0604:681744:681864 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
242: hkn0607:896865:896980 [2] NCCL INFO Trees [0] 243/-1/-1->242->241 [1] 243/-1/-1->242->241
242: hkn0607:896865:896980 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
246: hkn0608:478266:478383 [2] NCCL INFO Trees [0] 247/-1/-1->246->245 [1] 247/-1/-1->246->245
246: hkn0608:478266:478383 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
227: hkn0603:1405656:1405782 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
213: hkn0535:2391499:2391618 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
422: hkn0726:1540606:1540728 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
488: hkn0809:929896:930007 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
428: hkn0728:1316465:1316582 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
424: hkn0727:1338299:1338383 [0] NCCL INFO Trees [0] 425/428/-1->424->433 [1] 425/-1/-1->424->421
424: hkn0727:1338299:1338383 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
207: hkn0532:916642:916973 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
288: hkn0624:1765444:1765555 [0] NCCL INFO Trees [0] 289/304/-1->288->321 [1] 289/-1/-1->288->292
252: hkn0611:702309:702428 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
219: hkn0601:110164:110279 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
210: hkn0534:1140936:1141031 [2] NCCL INFO Trees [0] 211/-1/-1->210->209 [1] 211/-1/-1->210->209
210: hkn0534:1140936:1141031 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
221: hkn0602:3353962:3354225 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
293: hkn0626:1290947:1291055 [1] NCCL INFO Trees [0] 294/-1/-1->293->292 [1] 294/296/-1->293->292
285: hkn0623:1865230:1865352 [1] NCCL INFO Trees [0] 286/-1/-1->285->284 [1] 286/300/-1->285->284
228: hkn0604:681736:681856 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
244: hkn0608:478258:478384 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
225: hkn0603:1405664:1405775 [1] NCCL INFO Trees [0] 226/208/-1->225->224 [1] 226/-1/-1->225->224
214: hkn0535:2391519:2391622 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
423: hkn0726:1540634:1540730 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
491: hkn0809:929880:930000 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
430: hkn0728:1316485:1316584 [2] NCCL INFO Trees [0] 431/-1/-1->430->429 [1] 431/-1/-1->430->429
426: hkn0727:1338279:1338380 [2] NCCL INFO Trees [0] 427/-1/-1->426->425 [1] 427/-1/-1->426->425
426: hkn0727:1338279:1338380 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
289: hkn0624:1765436:1765548 [1] NCCL INFO Trees [0] 290/272/-1->289->288 [1] 290/-1/-1->289->288
289: hkn0624:1765436:1765548 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
217: hkn0601:110184:110286 [1] NCCL INFO Trees [0] 218/212/-1->217->216 [1] 218/-1/-1->217->216
220: hkn0602:3353946:3354226 [0] NCCL INFO Trees [0] 221/-1/-1->220->216 [1] 221/204/-1->220->189
293: hkn0626:1290947:1291055 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
285: hkn0623:1865230:1865352 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
297: hkn0627:1780434:1780527 [1] NCCL INFO Trees [0] 298/292/-1->297->296 [1] 298/-1/-1->297->296
230: hkn0604:681752:681859 [2] NCCL INFO Trees [0] 231/-1/-1->230->229 [1] 231/-1/-1->230->229
301: hkn0628:664357:664467 [1] NCCL INFO Trees [0] 302/-1/-1->301->300 [1] 302/308/-1->301->300
224: hkn0603:1405683:1405780 [0] NCCL INFO Trees [0] 225/240/-1->224->192 [1] 225/-1/-1->224->228
215: hkn0535:2391507:2391619 [3] NCCL INFO Trees [0] -1/-1/-1->215->214 [1] -1/-1/-1->215->214
419: hkn0725:3104454:3104536 [3] NCCL INFO Trees [0] -1/-1/-1->419->418 [1] -1/-1/-1->419->418
421: hkn0726:1540614:1540729 [1] NCCL INFO Trees [0] 422/-1/-1->421->420 [1] 422/424/-1->421->420
421: hkn0726:1540614:1540729 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
430: hkn0728:1316485:1316584 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
291: hkn0624:1765456:1765549 [3] NCCL INFO Trees [0] -1/-1/-1->291->290 [1] -1/-1/-1->291->290
291: hkn0624:1765456:1765549 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
217: hkn0601:110184:110286 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
220: hkn0602:3353946:3354226 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
294: hkn0626:1290959:1291053 [2] NCCL INFO Trees [0] 295/-1/-1->294->293 [1] 295/-1/-1->294->293
284: hkn0623:1865258:1865355 [0] NCCL INFO Trees [0] 285/-1/-1->284->280 [1] 285/268/-1->284->316
322: hkn0633:1518843:1518959 [2] NCCL INFO Trees [0] 323/-1/-1->322->321 [1] 323/-1/-1->322->321
322: hkn0633:1518843:1518959 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
230: hkn0604:681752:681859 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
301: hkn0628:664357:664467 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
307: hkn0629:1584544:1584671 [3] NCCL INFO Trees [0] -1/-1/-1->307->306 [1] -1/-1/-1->307->306
225: hkn0603:1405664:1405775 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
215: hkn0535:2391507:2391619 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
417: hkn0725:3104434:3104541 [1] NCCL INFO Trees [0] 418/400/-1->417->416 [1] 418/-1/-1->417->416
420: hkn0726:1540622:1540733 [0] NCCL INFO Trees [0] 421/-1/-1->420->425 [1] 421/416/-1->420->428
288: hkn0624:1765444:1765555 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
216: hkn0601:110172:110280 [0] NCCL INFO Trees [0] 217/220/-1->216->208 [1] 217/-1/-1->216->213
327: hkn0634:1513369:1513478 [3] NCCL INFO Trees [0] -1/-1/-1->327->326 [1] -1/-1/-1->327->326
222: hkn0602:3353974:3354228 [2] NCCL INFO Trees [0] 223/-1/-1->222->221 [1] 223/-1/-1->222->221
318: hkn0632:1751099:1751227 [2] NCCL INFO Trees [0] 319/-1/-1->318->317 [1] 319/-1/-1->318->317
294: hkn0626:1290959:1291053 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
284: hkn0623:1865258:1865355 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
297: hkn0627:1780434:1780527 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
323: hkn0633:1518851:1518965 [3] NCCL INFO Trees [0] -1/-1/-1->323->322 [1] -1/-1/-1->323->322
323: hkn0633:1518851:1518965 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
302: hkn0628:664349:664472 [2] NCCL INFO Trees [0] 303/-1/-1->302->301 [1] 303/-1/-1->302->301
307: hkn0629:1584544:1584671 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
224: hkn0603:1405683:1405780 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
212: hkn0535:2391491:2391620 [0] NCCL INFO Trees [0] 213/-1/-1->212->217 [1] 213/208/-1->212->205
418: hkn0725:3104426:3104537 [2] NCCL INFO Trees [0] 419/-1/-1->418->417 [1] 419/-1/-1->418->417
418: hkn0725:3104426:3104537 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
420: hkn0726:1540622:1540733 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
216: hkn0601:110172:110280 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
327: hkn0634:1513369:1513478 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
222: hkn0602:3353974:3354228 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
318: hkn0632:1751099:1751227 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
292: hkn0626:1290939:1291061 [0] NCCL INFO Trees [0] 293/-1/-1->292->297 [1] 293/288/-1->292->300
299: hkn0627:1780422:1780529 [3] NCCL INFO Trees [0] -1/-1/-1->299->298 [1] -1/-1/-1->299->298
320: hkn0633:1518863:1518964 [0] NCCL INFO Trees [0] 321/352/-1->320->385 [1] 321/-1/-1->320->324
320: hkn0633:1518863:1518964 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
312: hkn0631:1014294:1014414 [0] NCCL INFO Trees [0] 313/316/-1->312->304 [1] 313/-1/-1->312->309
303: hkn0628:664365:664474 [3] NCCL INFO Trees [0] -1/-1/-1->303->302 [1] -1/-1/-1->303->302
303: hkn0628:664365:664474 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
306: hkn0629:1584560:1584666 [2] NCCL INFO Trees [0] 307/-1/-1->306->305 [1] 307/-1/-1->306->305
306: hkn0629:1584560:1584666 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
328: hkn0635:1218095:1218212 [0] NCCL INFO Trees [0] 329/332/-1->328->337 [1] 329/-1/-1->328->325
354: hkn0707:4012451:4012539 [2] NCCL INFO Trees [0] 355/-1/-1->354->353 [1] 355/-1/-1->354->353
212: hkn0535:2391491:2391620 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
419: hkn0725:3104454:3104536 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
414: hkn0724:1708491:1708600 [2] NCCL INFO Trees [0] 415/-1/-1->414->413 [1] 415/-1/-1->414->413
411: hkn0723:200377:200540 [3] NCCL INFO Trees [0] -1/-1/-1->411->410 [1] -1/-1/-1->411->410
324: hkn0634:1513353:1513483 [0] NCCL INFO Trees [0] 325/-1/-1->324->329 [1] 325/320/-1->324->332
324: hkn0634:1513353:1513483 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
295: hkn0626:1290931:1291060 [3] NCCL INFO Trees [0] -1/-1/-1->295->294 [1] -1/-1/-1->295->294
309: hkn0630:1590958:1591101 [1] NCCL INFO Trees [0] 310/-1/-1->309->308 [1] 310/312/-1->309->308
309: hkn0630:1590958:1591101 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
299: hkn0627:1780422:1780529 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
321: hkn0633:1518835:1518968 [1] NCCL INFO Trees [0] 322/288/-1->321->320 [1] 322/-1/-1->321->320
350: hkn0706:744766:744917 [2] NCCL INFO Trees [0] 351/-1/-1->350->349 [1] 351/-1/-1->350->349
312: hkn0631:1014294:1014414 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
300: hkn0628:664377:664476 [0] NCCL INFO Trees [0] 301/-1/-1->300->296 [1] 301/292/-1->300->285
304: hkn0629:1584552:1584670 [0] NCCL INFO Trees [0] 305/312/-1->304->288 [1] 305/-1/-1->304->308
329: hkn0635:1218103:1218214 [1] NCCL INFO Trees [0] 330/324/-1->329->328 [1] 330/-1/-1->329->328
354: hkn0707:4012451:4012539 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
417: hkn0725:3104434:3104541 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
415: hkn0724:1708503:1708602 [3] NCCL INFO Trees [0] -1/-1/-1->415->414 [1] -1/-1/-1->415->414
411: hkn0723:200377:200540 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
363: hkn0710:348029:348129 [3] NCCL INFO Trees [0] -1/-1/-1->363->362 [1] -1/-1/-1->363->362
326: hkn0634:1513361:1513475 [2] NCCL INFO Trees [0] 327/-1/-1->326->325 [1] 327/-1/-1->326->325
319: hkn0632:1751115:1751226 [3] NCCL INFO Trees [0] -1/-1/-1->319->318 [1] -1/-1/-1->319->318
292: hkn0626:1290939:1291061 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
366: hkn0711:576395:576516 [2] NCCL INFO Trees [0] 367/-1/-1->366->365 [1] 367/-1/-1->366->365
310: hkn0630:1590942:1591100 [2] NCCL INFO Trees [0] 311/-1/-1->310->309 [1] 311/-1/-1->310->309
310: hkn0630:1590942:1591100 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
298: hkn0627:1780406:1780532 [2] NCCL INFO Trees [0] 299/-1/-1->298->297 [1] 299/-1/-1->298->297
321: hkn0633:1518835:1518968 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
357: hkn0708:405731:405869 [1] NCCL INFO Trees [0] 358/-1/-1->357->356 [1] 358/360/-1->357->356
357: hkn0708:405731:405869 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
375: hkn0713:462751:462876 [3] NCCL INFO Trees [0] -1/-1/-1->375->374 [1] -1/-1/-1->375->374
350: hkn0706:744766:744917 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
313: hkn0631:1014302:1014419 [1] NCCL INFO Trees [0] 314/308/-1->313->312 [1] 314/-1/-1->313->312
302: hkn0628:664349:664472 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
377: hkn0714:424551:424658 [1] NCCL INFO Trees [0] 378/372/-1->377->376 [1] 378/-1/-1->377->376
305: hkn0629:1584572:1584665 [1] NCCL INFO Trees [0] 306/296/-1->305->304 [1] 306/-1/-1->305->304
305: hkn0629:1584572:1584665 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
328: hkn0635:1218095:1218212 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
353: hkn0707:4012439:4012533 [1] NCCL INFO Trees [0] 354/336/-1->353->352 [1] 354/-1/-1->353->352
416: hkn0725:3104442:3104538 [0] NCCL INFO Trees [0] 417/432/-1->416->449 [1] 417/-1/-1->416->420
416: hkn0725:3104442:3104538 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
414: hkn0724:1708491:1708600 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
410: hkn0723:200364:200541 [2] NCCL INFO Trees [0] 411/-1/-1->410->409 [1] 411/-1/-1->410->409
410: hkn0723:200364:200541 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
386: hkn0716:101020:101119 [2] NCCL INFO Trees [0] 387/-1/-1->386->385 [1] 387/-1/-1->386->385
407: hkn0721:2291511:2291619 [3] NCCL INFO Trees [0] -1/-1/-1->407->406 [1] -1/-1/-1->407->406
407: hkn0721:2291511:2291619 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
337: hkn0703:733504:733651 [1] NCCL INFO Trees [0] 338/328/-1->337->336 [1] 338/-1/-1->337->336
363: hkn0710:348029:348129 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
325: hkn0634:1513380:1513484 [1] NCCL INFO Trees [0] 326/-1/-1->325->324 [1] 326/328/-1->325->324
325: hkn0634:1513380:1513484 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
317: hkn0632:1751107:1751230 [1] NCCL INFO Trees [0] 318/-1/-1->317->316 [1] 318/348/-1->317->316
317: hkn0632:1751107:1751230 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
295: hkn0626:1290931:1291060 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
367: hkn0711:576403:576515 [3] NCCL INFO Trees [0] -1/-1/-1->367->366 [1] -1/-1/-1->367->366
334: hkn0636:1646736:1646844 [2] NCCL INFO Trees [0] 335/-1/-1->334->333 [1] 335/-1/-1->334->333
369: hkn0712:287543:287667 [1] NCCL INFO Trees [0] 370/360/-1->369->368 [1] 370/-1/-1->369->368
369: hkn0712:287543:287667 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
311: hkn0630:1590970:1591099 [3] NCCL INFO Trees [0] -1/-1/-1->311->310 [1] -1/-1/-1->311->310
311: hkn0630:1590970:1591099 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
296: hkn0627:1780414:1780535 [0] NCCL INFO Trees [0] 297/300/-1->296->305 [1] 297/-1/-1->296->293
381: hkn0715:394422:394551 [1] NCCL INFO Trees [0] 382/-1/-1->381->380 [1] 382/444/-1->381->380
358: hkn0708:405723:405866 [2] NCCL INFO Trees [0] 359/-1/-1->358->357 [1] 359/-1/-1->358->357
358: hkn0708:405723:405866 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
375: hkn0713:462751:462876 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
351: hkn0706:744774:744912 [3] NCCL INFO Trees [0] -1/-1/-1->351->350 [1] -1/-1/-1->351->350
351: hkn0706:744774:744912 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
314: hkn0631:1014322:1014417 [2] NCCL INFO Trees [0] 315/-1/-1->314->313 [1] 315/-1/-1->314->313
314: hkn0631:1014322:1014417 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
300: hkn0628:664377:664476 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
377: hkn0714:424551:424658 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
304: hkn0629:1584552:1584670 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
329: hkn0635:1218103:1218214 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
353: hkn0707:4012439:4012533 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
390: hkn0717:4180120:4180224 [2] NCCL INFO Trees [0] 391/-1/-1->390->389 [1] 391/-1/-1->390->389
342: hkn0704:784530:784630 [2] NCCL INFO Trees [0] 343/-1/-1->342->341 [1] 343/-1/-1->342->341
399: hkn0719:1298195:1298344 [3] NCCL INFO Trees [0] -1/-1/-1->399->398 [1] -1/-1/-1->399->398
415: hkn0724:1708503:1708602 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
409: hkn0723:200369:200533 [1] NCCL INFO Trees [0] 410/404/-1->409->408 [1] 410/-1/-1->409->408
409: hkn0723:200369:200533 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
386: hkn0716:101020:101119 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
401: hkn0720:4190323:4190580 [1] NCCL INFO Trees [0] 402/392/-1->401->400 [1] 402/-1/-1->401->400
406: hkn0721:2291495:2291615 [2] NCCL INFO Trees [0] 407/-1/-1->406->405 [1] 407/-1/-1->406->405
406: hkn0721:2291495:2291615 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
338: hkn0703:733524:733645 [2] NCCL INFO Trees [0] 339/-1/-1->338->337 [1] 339/-1/-1->338->337
361: hkn0710:348021:348124 [1] NCCL INFO Trees [0] 362/356/-1->361->360 [1] 362/-1/-1->361->360
326: hkn0634:1513361:1513475 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
319: hkn0632:1751115:1751226 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
366: hkn0711:576395:576516 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
332: hkn0636:1646720:1646839 [0] NCCL INFO Trees [0] 333/-1/-1->332->328 [1] 333/324/-1->332->348
332: hkn0636:1646720:1646839 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
370: hkn0712:287559:287664 [2] NCCL INFO Trees [0] 371/-1/-1->370->369 [1] 371/-1/-1->370->369
370: hkn0712:287559:287664 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
308: hkn0630:1590950:1591102 [0] NCCL INFO Trees [0] 309/-1/-1->308->313 [1] 309/304/-1->308->301
308: hkn0630:1590950:1591102 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
298: hkn0627:1780406:1780532 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
382: hkn0715:394402:394547 [2] NCCL INFO Trees [0] 383/-1/-1->382->381 [1] 383/-1/-1->382->381
382: hkn0715:394402:394547 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
359: hkn0708:405743:405863 [3] NCCL INFO Trees [0] -1/-1/-1->359->358 [1] -1/-1/-1->359->358
373: hkn0713:462731:462877 [1] NCCL INFO Trees [0] 374/-1/-1->373->372 [1] 374/376/-1->373->372
349: hkn0706:744786:744914 [1] NCCL INFO Trees [0] 350/-1/-1->349->348 [1] 350/364/-1->349->348
315: hkn0631:1014310:1014411 [3] NCCL INFO Trees [0] -1/-1/-1->315->314 [1] -1/-1/-1->315->314
378: hkn0714:424535:424664 [2] NCCL INFO Trees [0] 379/-1/-1->378->377 [1] 379/-1/-1->378->377
330: hkn0635:1218111:1218207 [2] NCCL INFO Trees [0] 331/-1/-1->330->329 [1] 331/-1/-1->330->329
355: hkn0707:4012431:4012540 [3] NCCL INFO Trees [0] -1/-1/-1->355->354 [1] -1/-1/-1->355->354
355: hkn0707:4012431:4012540 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
390: hkn0717:4180120:4180224 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
342: hkn0704:784530:784630 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
393: hkn0718:3909494:3909650 [1] NCCL INFO Trees [0] 394/388/-1->393->392 [1] 394/-1/-1->393->392
346: hkn0705:775721:775863 [2] NCCL INFO Trees [0] 347/-1/-1->346->345 [1] 347/-1/-1->346->345
399: hkn0719:1298195:1298344 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
412: hkn0724:1708475:1708596 [0] NCCL INFO Trees [0] 413/-1/-1->412->408 [1] 413/396/-1->412->444
408: hkn0723:200389:200535 [0] NCCL INFO Trees [0] 409/412/-1->408->400 [1] 409/-1/-1->408->405
408: hkn0723:200389:200535 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
387: hkn0716:100997:101122 [3] NCCL INFO Trees [0] -1/-1/-1->387->386 [1] -1/-1/-1->387->386
403: hkn0720:4190335:4190579 [3] NCCL INFO Trees [0] -1/-1/-1->403->402 [1] -1/-1/-1->403->402
404: hkn0721:2291503:2291621 [0] NCCL INFO Trees [0] 405/-1/-1->404->409 [1] 405/400/-1->404->397
337: hkn0703:733504:733651 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
361: hkn0710:348021:348124 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
316: hkn0632:1751127:1751225 [0] NCCL INFO Trees [0] 317/-1/-1->316->312 [1] 317/284/-1->316->380
316: hkn0632:1751127:1751225 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
367: hkn0711:576403:576515 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
333: hkn0636:1646748:1646841 [1] NCCL INFO Trees [0] 334/-1/-1->333->332 [1] 334/340/-1->333->332
333: hkn0636:1646748:1646841 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
368: hkn0712:287551:287669 [0] NCCL INFO Trees [0] 369/376/-1->368->352 [1] 369/-1/-1->368->372
368: hkn0712:287551:287669 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
296: hkn0627:1780414:1780535 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
381: hkn0715:394422:394551 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
356: hkn0708:405715:405864 [0] NCCL INFO Trees [0] 357/-1/-1->356->361 [1] 357/352/-1->356->364
356: hkn0708:405715:405864 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
373: hkn0713:462731:462877 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
349: hkn0706:744786:744914 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
313: hkn0631:1014302:1014419 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
378: hkn0714:424535:424664 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
331: hkn0635:1218123:1218208 [3] NCCL INFO Trees [0] -1/-1/-1->331->330 [1] -1/-1/-1->331->330
352: hkn0707:4012423:4012534 [0] NCCL INFO Trees [0] 353/368/-1->352->320 [1] 353/-1/-1->352->356
352: hkn0707:4012423:4012534 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
388: hkn0717:4180092:4180225 [0] NCCL INFO Trees [0] 389/-1/-1->388->393 [1] 389/384/-1->388->396
388: hkn0717:4180092:4180225 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
340: hkn0704:784518:784625 [0] NCCL INFO Trees [0] 341/-1/-1->340->345 [1] 341/336/-1->340->333
226: hkn0603:1405672:1405779 [2] NCCL INFO Trees [0] 227/-1/-1->226->225 [1] 227/-1/-1->226->225
394: hkn0718:3909522:3909643 [2] NCCL INFO Trees [0] 395/-1/-1->394->393 [1] 395/-1/-1->394->393
346: hkn0705:775721:775863 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
398: hkn0719:1298217:1298339 [2] NCCL INFO Trees [0] 399/-1/-1->398->397 [1] 399/-1/-1->398->397
413: hkn0724:1708483:1708593 [1] NCCL INFO Trees [0] 414/-1/-1->413->412 [1] 414/428/-1->413->412
387: hkn0716:100997:101122 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
401: hkn0720:4190323:4190580 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
405: hkn0721:2291522:2291616 [1] NCCL INFO Trees [0] 406/-1/-1->405->404 [1] 406/408/-1->405->404
405: hkn0721:2291522:2291616 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
338: hkn0703:733524:733645 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
362: hkn0710:348041:348125 [2] NCCL INFO Trees [0] 363/-1/-1->362->361 [1] 363/-1/-1->362->361
364: hkn0711:576387:576519 [0] NCCL INFO Trees [0] 365/-1/-1->364->360 [1] 365/356/-1->364->349
334: hkn0636:1646736:1646844 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
371: hkn0712:287571:287663 [3] NCCL INFO Trees [0] -1/-1/-1->371->370 [1] -1/-1/-1->371->370
380: hkn0715:394410:394546 [0] NCCL INFO Trees [0] 381/-1/-1->380->376 [1] 381/316/-1->380->253
359: hkn0708:405743:405863 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
374: hkn0713:462739:462878 [2] NCCL INFO Trees [0] 375/-1/-1->374->373 [1] 375/-1/-1->374->373
374: hkn0713:462739:462878 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
348: hkn0706:744758:744910 [0] NCCL INFO Trees [0] 349/-1/-1->348->344 [1] 349/332/-1->348->317
315: hkn0631:1014310:1014411 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
379: hkn0714:424543:424659 [3] NCCL INFO Trees [0] -1/-1/-1->379->378 [1] -1/-1/-1->379->378
330: hkn0635:1218111:1218207 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
389: hkn0717:4180100:4180219 [1] NCCL INFO Trees [0] 390/-1/-1->389->388 [1] 390/392/-1->389->388
341: hkn0704:784510:784629 [1] NCCL INFO Trees [0] 342/-1/-1->341->340 [1] 342/344/-1->341->340
341: hkn0704:784510:784629 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
226: hkn0603:1405672:1405779 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
395: hkn0718:3909510:3909645 [3] NCCL INFO Trees [0] -1/-1/-1->395->394 [1] -1/-1/-1->395->394
344: hkn0705:775713:775862 [0] NCCL INFO Trees [0] 345/348/-1->344->336 [1] 345/-1/-1->344->341
397: hkn0719:1298203:1298338 [1] NCCL INFO Trees [0] 398/-1/-1->397->396 [1] 398/404/-1->397->396
412: hkn0724:1708475:1708596 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
384: hkn0716:101008:101117 [0] NCCL INFO Trees [0] 385/448/-1->384->256 [1] 385/-1/-1->384->388
402: hkn0720:4190312:4190585 [2] NCCL INFO Trees [0] 403/-1/-1->402->401 [1] 403/-1/-1->402->401
404: hkn0721:2291503:2291621 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
339: hkn0703:733496:733654 [3] NCCL INFO Trees [0] -1/-1/-1->339->338 [1] -1/-1/-1->339->338
339: hkn0703:733496:733654 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
362: hkn0710:348041:348125 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
365: hkn0711:576415:576512 [1] NCCL INFO Trees [0] 366/-1/-1->365->364 [1] 366/372/-1->365->364
365: hkn0711:576415:576512 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
335: hkn0636:1646728:1646847 [3] NCCL INFO Trees [0] -1/-1/-1->335->334 [1] -1/-1/-1->335->334
335: hkn0636:1646728:1646847 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
371: hkn0712:287571:287663 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
380: hkn0715:394410:394546 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
372: hkn0713:462723:462881 [0] NCCL INFO Trees [0] 373/-1/-1->372->377 [1] 373/368/-1->372->365
372: hkn0713:462723:462881 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
348: hkn0706:744758:744910 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
379: hkn0714:424543:424659 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
331: hkn0635:1218123:1218208 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
391: hkn0717:4180108:4180218 [3] NCCL INFO Trees [0] -1/-1/-1->391->390 [1] -1/-1/-1->391->390
343: hkn0704:784502:784626 [3] NCCL INFO Trees [0] -1/-1/-1->343->342 [1] -1/-1/-1->343->342
343: hkn0704:784502:784626 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
393: hkn0718:3909494:3909650 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
344: hkn0705:775713:775862 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
398: hkn0719:1298217:1298339 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
413: hkn0724:1708483:1708593 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
385: hkn0716:101000:101120 [1] NCCL INFO Trees [0] 386/320/-1->385->384 [1] 386/-1/-1->385->384
385: hkn0716:101000:101120 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
403: hkn0720:4190335:4190579 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
336: hkn0703:733512:733649 [0] NCCL INFO Trees [0] 337/344/-1->336->353 [1] 337/-1/-1->336->340
360: hkn0710:348013:348131 [0] NCCL INFO Trees [0] 361/364/-1->360->369 [1] 361/-1/-1->360->357
364: hkn0711:576387:576519 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
383: hkn0715:394394:394548 [3] NCCL INFO Trees [0] -1/-1/-1->383->382 [1] -1/-1/-1->383->382
383: hkn0715:394394:394548 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
376: hkn0714:424562:424665 [0] NCCL INFO Trees [0] 377/380/-1->376->368 [1] 377/-1/-1->376->373
389: hkn0717:4180100:4180219 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
340: hkn0704:784518:784625 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
394: hkn0718:3909522:3909643 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
345: hkn0705:775705:775864 [1] NCCL INFO Trees [0] 346/340/-1->345->344 [1] 346/-1/-1->345->344
345: hkn0705:775705:775864 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
396: hkn0719:1298187:1298341 [0] NCCL INFO Trees [0] 397/-1/-1->396->392 [1] 397/388/-1->396->412
384: hkn0716:101008:101117 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
402: hkn0720:4190312:4190585 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,fffc0000,00000fff,ffffffc0,00000000
336: hkn0703:733512:733649 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
360: hkn0710:348013:348131 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
376: hkn0714:424562:424665 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
391: hkn0717:4180108:4180218 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
395: hkn0718:3909510:3909645 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
347: hkn0705:775733:775855 [3] NCCL INFO Trees [0] -1/-1/-1->347->346 [1] -1/-1/-1->347->346
347: hkn0705:775733:775855 [3] NCCL INFO Setting affinity for GPU 3 to ffffff,fffc0000,00000fff,ffffffc0,00000000
397: hkn0719:1298203:1298338 [1] NCCL INFO Setting affinity for GPU 1 to 03ffff,fffff000,0000003f,ffffffff
400: hkn0720:4190315:4190586 [0] NCCL INFO Trees [0] 401/408/-1->400->417 [1] 401/-1/-1->400->404
400: hkn0720:4190315:4190586 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
392: hkn0718:3909502:3909648 [0] NCCL INFO Trees [0] 393/396/-1->392->401 [1] 393/-1/-1->392->389
396: hkn0719:1298187:1298341 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
392: hkn0718:3909502:3909648 [0] NCCL INFO Setting affinity for GPU 0 to 03ffff,fffff000,0000003f,ffffffff
 66: hkn0421:2172265:2172522 [2] NCCL INFO Channel 00 : 66[ca000] -> 65[4b000] via P2P/IPC/read
 70: hkn0422:4145499:4145645 [2] NCCL INFO Channel 00 : 70[ca000] -> 69[4b000] via P2P/IPC/read
 62: hkn0420:3202701:3202824 [2] NCCL INFO Channel 00 : 62[ca000] -> 61[4b000] via P2P/IPC/read
154: hkn0515:2889281:2889407 [2] NCCL INFO Channel 00 : 154[ca000] -> 153[4b000] via P2P/IPC/read
126: hkn0508:3131648:3131731 [2] NCCL INFO Channel 00 : 126[ca000] -> 125[4b000] via P2P/IPC/read
 78: hkn0424:2940433:2940564 [2] NCCL INFO Channel 00 : 78[ca000] -> 77[4b000] via P2P/IPC/read
150: hkn0514:2943226:2943345 [2] NCCL INFO Channel 00 : 150[ca000] -> 149[4b000] via P2P/IPC/read
130: hkn0509:3116904:3117014 [2] NCCL INFO Channel 00 : 130[ca000] -> 129[4b000] via P2P/IPC/read
134: hkn0510:2754583:2754692 [2] NCCL INFO Channel 00 : 134[ca000] -> 133[4b000] via P2P/IPC/read
162: hkn0520:2705389:2705480 [2] NCCL INFO Channel 00 : 162[ca000] -> 161[4b000] via P2P/IPC/read
138: hkn0511:3058850:3058979 [2] NCCL INFO Channel 00 : 138[ca000] -> 137[4b000] via P2P/IPC/read
 70: hkn0422:4145499:4145645 [2] NCCL INFO Channel 01 : 70[ca000] -> 69[4b000] via P2P/IPC/read
 74: hkn0423:1697354:1697472 [2] NCCL INFO Channel 00 : 74[ca000] -> 73[4b000] via P2P/IPC/read
110: hkn0504:33345:33443 [2] NCCL INFO Channel 00 : 110[ca000] -> 109[4b000] via P2P/IPC/read
142: hkn0512:3036655:3036775 [2] NCCL INFO Channel 00 : 142[ca000] -> 141[4b000] via P2P/IPC/read
 98: hkn0501:1320364:1320480 [2] NCCL INFO Channel 00 : 98[ca000] -> 97[4b000] via P2P/IPC/read
 86: hkn0426:806587:806697 [2] NCCL INFO Channel 00 : 86[ca000] -> 85[4b000] via P2P/IPC/read
174: hkn0524:1126288:1126393 [2] NCCL INFO Channel 00 : 174[ca000] -> 173[4b000] via P2P/IPC/read
 26: hkn0410:1152222:1152317 [2] NCCL INFO Channel 00 : 26[ca000] -> 25[4b000] via P2P/IPC/read
158: hkn0516:2908472:2908599 [2] NCCL INFO Channel 00 : 158[ca000] -> 157[4b000] via P2P/IPC/read
102: hkn0502:221554:221671 [2] NCCL INFO Channel 00 : 102[ca000] -> 101[4b000] via P2P/IPC/read
 66: hkn0421:2172265:2172522 [2] NCCL INFO Channel 01 : 66[ca000] -> 65[4b000] via P2P/IPC/read
126: hkn0508:3131648:3131731 [2] NCCL INFO Channel 01 : 126[ca000] -> 125[4b000] via P2P/IPC/read
106: hkn0503:2892182:2892286 [2] NCCL INFO Channel 00 : 106[ca000] -> 105[4b000] via P2P/IPC/read
130: hkn0509:3116904:3117014 [2] NCCL INFO Channel 01 : 130[ca000] -> 129[4b000] via P2P/IPC/read
118: hkn0506:830582:830669 [2] NCCL INFO Channel 00 : 118[ca000] -> 117[4b000] via P2P/IPC/read
134: hkn0510:2754583:2754692 [2] NCCL INFO Channel 01 : 134[ca000] -> 133[4b000] via P2P/IPC/read
 90: hkn0427:1127651:1127785 [2] NCCL INFO Channel 00 : 90[ca000] -> 89[4b000] via P2P/IPC/read
438: hkn0731:1379244:1379355 [2] NCCL INFO Channel 00 : 438[ca000] -> 437[4b000] via P2P/IPC/read
 22: hkn0409:2578209:2578305 [2] NCCL INFO Channel 00 : 22[ca000] -> 21[4b000] via P2P/IPC/read
154: hkn0515:2889281:2889407 [2] NCCL INFO Channel 01 : 154[ca000] -> 153[4b000] via P2P/IPC/read
 62: hkn0420:3202701:3202824 [2] NCCL INFO Channel 01 : 62[ca000] -> 61[4b000] via P2P/IPC/read
 50: hkn0417:2260187:2260291 [2] NCCL INFO Channel 00 : 50[ca000] -> 49[4b000] via P2P/IPC/read
114: hkn0505:2296288:2296402 [2] NCCL INFO Channel 00 : 114[ca000] -> 113[4b000] via P2P/IPC/read
 82: hkn0425:2076510:2076599 [2] NCCL INFO Channel 00 : 82[ca000] -> 81[4b000] via P2P/IPC/read
 18: hkn0408:2883203:2883321 [2] NCCL INFO Channel 00 : 18[ca000] -> 17[4b000] via P2P/IPC/read
 46: hkn0415:2488942:2489091 [2] NCCL INFO Channel 00 : 46[ca000] -> 45[4b000] via P2P/IPC/read
146: hkn0513:3005437:3005564 [2] NCCL INFO Channel 00 : 146[ca000] -> 145[4b000] via P2P/IPC/read
138: hkn0511:3058850:3058979 [2] NCCL INFO Channel 01 : 138[ca000] -> 137[4b000] via P2P/IPC/read
182: hkn0526:1420936:1421020 [2] NCCL INFO Channel 00 : 182[ca000] -> 181[4b000] via P2P/IPC/read
446: hkn0733:1381899:1382018 [2] NCCL INFO Channel 00 : 446[ca000] -> 445[4b000] via P2P/IPC/read
170: hkn0523:1540556:1540660 [2] NCCL INFO Channel 00 : 170[ca000] -> 169[4b000] via P2P/IPC/read
 74: hkn0423:1697354:1697472 [2] NCCL INFO Channel 01 : 74[ca000] -> 73[4b000] via P2P/IPC/read
 98: hkn0501:1320364:1320480 [2] NCCL INFO Channel 01 : 98[ca000] -> 97[4b000] via P2P/IPC/read
 78: hkn0424:2940433:2940564 [2] NCCL INFO Channel 01 : 78[ca000] -> 77[4b000] via P2P/IPC/read
442: hkn0732:1204151:1204273 [2] NCCL INFO Channel 00 : 442[ca000] -> 441[4b000] via P2P/IPC/read
178: hkn0525:979310:979433 [2] NCCL INFO Channel 00 : 178[ca000] -> 177[4b000] via P2P/IPC/read
 26: hkn0410:1152222:1152317 [2] NCCL INFO Channel 01 : 26[ca000] -> 25[4b000] via P2P/IPC/read
158: hkn0516:2908472:2908599 [2] NCCL INFO Channel 01 : 158[ca000] -> 157[4b000] via P2P/IPC/read
 30: hkn0411:2308367:2308482 [2] NCCL INFO Channel 00 : 30[ca000] -> 29[4b000] via P2P/IPC/read
142: hkn0512:3036655:3036775 [2] NCCL INFO Channel 01 : 142[ca000] -> 141[4b000] via P2P/IPC/read
162: hkn0520:2705389:2705480 [2] NCCL INFO Channel 01 : 162[ca000] -> 161[4b000] via P2P/IPC/read
166: hkn0521:1190294:1190442 [2] NCCL INFO Channel 00 : 166[ca000] -> 165[4b000] via P2P/IPC/read
110: hkn0504:33345:33443 [2] NCCL INFO Channel 01 : 110[ca000] -> 109[4b000] via P2P/IPC/read
462: hkn0802:1192841:1192950 [2] NCCL INFO Channel 00 : 462[ca000] -> 461[4b000] via P2P/IPC/read
510: hkn0816:368135:368243 [2] NCCL INFO Channel 00 : 510[ca000] -> 509[4b000] via P2P/IPC/read
434: hkn0730:1394229:1394348 [2] NCCL INFO Channel 00 : 434[ca000] -> 433[4b000] via P2P/IPC/read
 86: hkn0426:806587:806697 [2] NCCL INFO Channel 01 : 86[ca000] -> 85[4b000] via P2P/IPC/read
 90: hkn0427:1127651:1127785 [2] NCCL INFO Channel 01 : 90[ca000] -> 89[4b000] via P2P/IPC/read
150: hkn0514:2943226:2943345 [2] NCCL INFO Channel 01 : 150[ca000] -> 149[4b000] via P2P/IPC/read
 42: hkn0414:1974071:1974185 [2] NCCL INFO Channel 00 : 42[ca000] -> 41[4b000] via P2P/IPC/read
454: hkn0736:1500869:1500964 [2] NCCL INFO Channel 00 : 454[ca000] -> 453[4b000] via P2P/IPC/read
 34: hkn0412:2254908:2255016 [2] NCCL INFO Channel 00 : 34[ca000] -> 33[4b000] via P2P/IPC/read
438: hkn0731:1379244:1379355 [2] NCCL INFO Channel 01 : 438[ca000] -> 437[4b000] via P2P/IPC/read
 46: hkn0415:2488942:2489091 [2] NCCL INFO Channel 01 : 46[ca000] -> 45[4b000] via P2P/IPC/read
 50: hkn0417:2260187:2260291 [2] NCCL INFO Channel 01 : 50[ca000] -> 49[4b000] via P2P/IPC/read
114: hkn0505:2296288:2296402 [2] NCCL INFO Channel 01 : 114[ca000] -> 113[4b000] via P2P/IPC/read
174: hkn0524:1126288:1126393 [2] NCCL INFO Channel 01 : 174[ca000] -> 173[4b000] via P2P/IPC/read
 18: hkn0408:2883203:2883321 [2] NCCL INFO Channel 01 : 18[ca000] -> 17[4b000] via P2P/IPC/read
118: hkn0506:830582:830669 [2] NCCL INFO Channel 01 : 118[ca000] -> 117[4b000] via P2P/IPC/read
170: hkn0523:1540556:1540660 [2] NCCL INFO Channel 01 : 170[ca000] -> 169[4b000] via P2P/IPC/read
450: hkn0734:1149069:1149195 [2] NCCL INFO Channel 00 : 450[ca000] -> 449[4b000] via P2P/IPC/read
458: hkn0801:2232476:2232619 [2] NCCL INFO Channel 00 : 458[ca000] -> 457[4b000] via P2P/IPC/read
 14: hkn0407:1808755:1808914 [2] NCCL INFO Channel 00 : 14[ca000] -> 13[4b000] via P2P/IPC/read
186: hkn0527:1341433:1341555 [2] NCCL INFO Channel 00 : 186[ca000] -> 185[4b000] via P2P/IPC/read
122: hkn0507:3179573:3179686 [2] NCCL INFO Channel 00 : 122[ca000] -> 121[4b000] via P2P/IPC/read
474: hkn0805:1104630:1104729 [2] NCCL INFO Channel 00 : 474[ca000] -> 473[4b000] via P2P/IPC/read
 30: hkn0411:2308367:2308482 [2] NCCL INFO Channel 01 : 30[ca000] -> 29[4b000] via P2P/IPC/read
102: hkn0502:221554:221671 [2] NCCL INFO Channel 01 : 102[ca000] -> 101[4b000] via P2P/IPC/read
178: hkn0525:979310:979433 [2] NCCL INFO Channel 01 : 178[ca000] -> 177[4b000] via P2P/IPC/read
466: hkn0803:869044:869156 [2] NCCL INFO Channel 00 : 466[ca000] -> 465[4b000] via P2P/IPC/read
 22: hkn0409:2578209:2578305 [2] NCCL INFO Channel 01 : 22[ca000] -> 21[4b000] via P2P/IPC/read
 94: hkn0428:659895:659982 [2] NCCL INFO Channel 00 : 94[ca000] -> 93[4b000] via P2P/IPC/read
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
202: hkn0531:1223078:1223201 [2] NCCL INFO Channel 00 : 202[ca000] -> 201[4b000] via P2P/IPC/read
278: hkn0621:1984032:1984138 [2] NCCL INFO Channel 00 : 278[ca000] -> 277[4b000] via P2P/IPC/read
106: hkn0503:2892182:2892286 [2] NCCL INFO Channel 01 : 106[ca000] -> 105[4b000] via P2P/IPC/read
166: hkn0521:1190294:1190442 [2] NCCL INFO Channel 01 : 166[ca000] -> 165[4b000] via P2P/IPC/read
 38: hkn0413:2359203:2359295 [2] NCCL INFO Channel 00 : 38[ca000] -> 37[4b000] via P2P/IPC/read
 82: hkn0425:2076510:2076599 [2] NCCL INFO Channel 01 : 82[ca000] -> 81[4b000] via P2P/IPC/read
470: hkn0804:1198131:1198247 [2] NCCL INFO Channel 00 : 470[ca000] -> 469[4b000] via P2P/IPC/read
  6: hkn0404:1331844:1331992 [2] NCCL INFO Channel 00 : 6[ca000] -> 5[4b000] via P2P/IPC/read
442: hkn0732:1204151:1204273 [2] NCCL INFO Channel 01 : 442[ca000] -> 441[4b000] via P2P/IPC/read
190: hkn0528:1294206:1294325 [2] NCCL INFO Channel 00 : 190[ca000] -> 189[4b000] via P2P/IPC/read
462: hkn0802:1192841:1192950 [2] NCCL INFO Channel 01 : 462[ca000] -> 461[4b000] via P2P/IPC/read
510: hkn0816:368135:368243 [2] NCCL INFO Channel 01 : 510[ca000] -> 509[4b000] via P2P/IPC/read
482: hkn0807:1011569:1011689 [2] NCCL INFO Channel 00 : 482[ca000] -> 481[4b000] via P2P/IPC/read
 10: hkn0405:3199307:3199411 [2] NCCL INFO Channel 00 : 10[ca000] -> 9[4b000] via P2P/IPC/read
234: hkn0605:704621:704722 [2] NCCL INFO Channel 00 : 234[ca000] -> 233[4b000] via P2P/IPC/read
274: hkn0617:2287161:2287275 [2] NCCL INFO Channel 00 : 274[ca000] -> 273[4b000] via P2P/IPC/read
446: hkn0733:1381899:1382018 [2] NCCL INFO Channel 01 : 446[ca000] -> 445[4b000] via P2P/IPC/read
486: hkn0808:963183:963303 [2] NCCL INFO Channel 00 : 486[ca000] -> 485[4b000] via P2P/IPC/read
434: hkn0730:1394229:1394348 [2] NCCL INFO Channel 01 : 434[ca000] -> 433[4b000] via P2P/IPC/read
182: hkn0526:1420936:1421020 [2] NCCL INFO Channel 01 : 182[ca000] -> 181[4b000] via P2P/IPC/read
 54: hkn0418:1861675:1861787 [2] NCCL INFO Channel 00 : 54[ca000] -> 53[4b000] via P2P/IPC/read
 42: hkn0414:1974071:1974185 [2] NCCL INFO Channel 01 : 42[ca000] -> 41[4b000] via P2P/IPC/read
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
270: hkn0616:397349:397480 [2] NCCL INFO Channel 00 : 270[ca000] -> 269[4b000] via P2P/IPC/read
 34: hkn0412:2254908:2255016 [2] NCCL INFO Channel 01 : 34[ca000] -> 33[4b000] via P2P/IPC/read
506: hkn0815:387640:387788 [2] NCCL INFO Channel 00 : 506[ca000] -> 505[4b000] via P2P/IPC/read
254: hkn0611:702301:702422 [2] NCCL INFO Channel 00 : 254[ca000] -> 253[4b000] via P2P/IPC/read
210: hkn0534:1140936:1141031 [2] NCCL INFO Channel 00 : 210[ca000] -> 209[4b000] via P2P/IPC/read
198: hkn0530:1250651:1250763 [2] NCCL INFO Channel 00 : 198[ca000] -> 197[4b000] via P2P/IPC/read
250: hkn0609:703349:703447 [2] NCCL INFO Channel 00 : 250[ca000] -> 249[4b000] via P2P/IPC/read
230: hkn0604:681752:681859 [2] NCCL INFO Channel 00 : 230[ca000] -> 229[4b000] via P2P/IPC/read
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
 58: hkn0419:1536809:1536916 [2] NCCL INFO Channel 00 : 58[ca000] -> 57[4b000] via P2P/IPC/read
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
242: hkn0607:896865:896980 [2] NCCL INFO Channel 00 : 242[ca000] -> 241[4b000] via P2P/IPC/read
450: hkn0734:1149069:1149195 [2] NCCL INFO Channel 01 : 450[ca000] -> 449[4b000] via P2P/IPC/read
498: hkn0812:686269:686396 [2] NCCL INFO Channel 00 : 498[ca000] -> 497[4b000] via P2P/IPC/read
458: hkn0801:2232476:2232619 [2] NCCL INFO Channel 01 : 458[ca000] -> 457[4b000] via P2P/IPC/read
206: hkn0532:916669:916966 [2] NCCL INFO Channel 00 : 206[ca000] -> 205[4b000] via P2P/IPC/read
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
282: hkn0622:2012978:2013091 [2] NCCL INFO Channel 00 : 282[ca000] -> 281[4b000] via P2P/IPC/read
258: hkn0612:909479:909575 [2] NCCL INFO Channel 00 : 258[ca000] -> 257[4b000] via P2P/IPC/read
  2: hkn0403:1751321:1751698 [2] NCCL INFO Channel 00 : 2[ca000] -> 1[4b000] via P2P/IPC/read
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 00 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
194: hkn0529:1533376:1533479 [2] NCCL INFO Channel 00 : 194[ca000] -> 193[4b000] via P2P/IPC/read
266: hkn0615:406787:406911 [2] NCCL INFO Channel 00 : 266[ca000] -> 265[4b000] via P2P/IPC/read
146: hkn0513:3005437:3005564 [2] NCCL INFO Channel 01 : 146[ca000] -> 145[4b000] via P2P/IPC/read
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 00 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
246: hkn0608:478266:478383 [2] NCCL INFO Channel 00 : 246[ca000] -> 245[4b000] via P2P/IPC/read
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 00 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
466: hkn0803:869044:869156 [2] NCCL INFO Channel 01 : 466[ca000] -> 465[4b000] via P2P/IPC/read
149: hkn0514:2943234:2943343 [1] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
478: hkn0806:1046839:1046949 [2] NCCL INFO Channel 00 : 478[ca000] -> 477[4b000] via P2P/IPC/read
426: hkn0727:1338279:1338380 [2] NCCL INFO Channel 00 : 426[ca000] -> 425[4b000] via P2P/IPC/read
 69: hkn0422:4145507:4145651 [1] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
262: hkn0613:895183:895295 [2] NCCL INFO Channel 00 : 262[ca000] -> 261[4b000] via P2P/IPC/read
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
  6: hkn0404:1331844:1331992 [2] NCCL INFO Channel 01 : 6[ca000] -> 5[4b000] via P2P/IPC/read
238: hkn0606:2364570:2364670 [2] NCCL INFO Channel 00 : 238[ca000] -> 237[4b000] via P2P/IPC/read
486: hkn0808:963183:963303 [2] NCCL INFO Channel 01 : 486[ca000] -> 485[4b000] via P2P/IPC/read
474: hkn0805:1104630:1104729 [2] NCCL INFO Channel 01 : 474[ca000] -> 473[4b000] via P2P/IPC/read
 14: hkn0407:1808755:1808914 [2] NCCL INFO Channel 01 : 14[ca000] -> 13[4b000] via P2P/IPC/read
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
454: hkn0736:1500869:1500964 [2] NCCL INFO Channel 01 : 454[ca000] -> 453[4b000] via P2P/IPC/read
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
250: hkn0609:703349:703447 [2] NCCL INFO Channel 01 : 250[ca000] -> 249[4b000] via P2P/IPC/read
234: hkn0605:704621:704722 [2] NCCL INFO Channel 01 : 234[ca000] -> 233[4b000] via P2P/IPC/read
190: hkn0528:1294206:1294325 [2] NCCL INFO Channel 01 : 190[ca000] -> 189[4b000] via P2P/IPC/read
 10: hkn0405:3199307:3199411 [2] NCCL INFO Channel 01 : 10[ca000] -> 9[4b000] via P2P/IPC/read
502: hkn0814:668347:668457 [2] NCCL INFO Channel 00 : 502[ca000] -> 501[4b000] via P2P/IPC/read
430: hkn0728:1316485:1316584 [2] NCCL INFO Channel 00 : 430[ca000] -> 429[4b000] via P2P/IPC/read
470: hkn0804:1198131:1198247 [2] NCCL INFO Channel 01 : 470[ca000] -> 469[4b000] via P2P/IPC/read
506: hkn0815:387640:387788 [2] NCCL INFO Channel 01 : 506[ca000] -> 505[4b000] via P2P/IPC/read
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 00 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
254: hkn0611:702301:702422 [2] NCCL INFO Channel 01 : 254[ca000] -> 253[4b000] via P2P/IPC/read
270: hkn0616:397349:397480 [2] NCCL INFO Channel 01 : 270[ca000] -> 269[4b000] via P2P/IPC/read
198: hkn0530:1250651:1250763 [2] NCCL INFO Channel 01 : 198[ca000] -> 197[4b000] via P2P/IPC/read
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
230: hkn0604:681752:681859 [2] NCCL INFO Channel 01 : 230[ca000] -> 229[4b000] via P2P/IPC/read
302: hkn0628:664349:664472 [2] NCCL INFO Channel 00 : 302[ca000] -> 301[4b000] via P2P/IPC/read
 54: hkn0418:1861675:1861787 [2] NCCL INFO Channel 01 : 54[ca000] -> 53[4b000] via P2P/IPC/read
133: hkn0510:2754575:2754694 [1] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
278: hkn0621:1984032:1984138 [2] NCCL INFO Channel 01 : 278[ca000] -> 277[4b000] via P2P/IPC/read
258: hkn0612:909479:909575 [2] NCCL INFO Channel 01 : 258[ca000] -> 257[4b000] via P2P/IPC/read
494: hkn0810:932062:932167 [2] NCCL INFO Channel 00 : 494[ca000] -> 493[4b000] via P2P/IPC/read
  2: hkn0403:1751321:1751698 [2] NCCL INFO Channel 01 : 2[ca000] -> 1[4b000] via P2P/IPC/read
 58: hkn0419:1536809:1536916 [2] NCCL INFO Channel 01 : 58[ca000] -> 57[4b000] via P2P/IPC/read
482: hkn0807:1011569:1011689 [2] NCCL INFO Channel 01 : 482[ca000] -> 481[4b000] via P2P/IPC/read
222: hkn0602:3353974:3354228 [2] NCCL INFO Channel 00 : 222[ca000] -> 221[4b000] via P2P/IPC/read
298: hkn0627:1780406:1780532 [2] NCCL INFO Channel 00 : 298[ca000] -> 297[4b000] via P2P/IPC/read
322: hkn0633:1518843:1518959 [2] NCCL INFO Channel 00 : 322[ca000] -> 321[4b000] via P2P/IPC/read
314: hkn0631:1014322:1014417 [2] NCCL INFO Channel 00 : 314[ca000] -> 313[4b000] via P2P/IPC/read
330: hkn0635:1218111:1218207 [2] NCCL INFO Channel 00 : 330[ca000] -> 329[4b000] via P2P/IPC/read
226: hkn0603:1405672:1405779 [2] NCCL INFO Channel 00 : 226[ca000] -> 225[4b000] via P2P/IPC/read
274: hkn0617:2287161:2287275 [2] NCCL INFO Channel 01 : 274[ca000] -> 273[4b000] via P2P/IPC/read
214: hkn0535:2391519:2391622 [2] NCCL INFO Channel 00 : 214[ca000] -> 213[4b000] via P2P/IPC/read
194: hkn0529:1533376:1533479 [2] NCCL INFO Channel 01 : 194[ca000] -> 193[4b000] via P2P/IPC/read
 53: hkn0418:1861667:1861790 [1] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
186: hkn0527:1341433:1341555 [2] NCCL INFO Channel 01 : 186[ca000] -> 185[4b000] via P2P/IPC/read
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
453: hkn0736:1500847:1500961 [1] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
266: hkn0615:406787:406911 [2] NCCL INFO Channel 01 : 266[ca000] -> 265[4b000] via P2P/IPC/read
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
122: hkn0507:3179573:3179686 [2] NCCL INFO Channel 01 : 122[ca000] -> 121[4b000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
318: hkn0632:1751099:1751227 [2] NCCL INFO Channel 00 : 318[ca000] -> 317[4b000] via P2P/IPC/read
286: hkn0623:1865246:1865351 [2] NCCL INFO Channel 00 : 286[ca000] -> 285[4b000] via P2P/IPC/read
310: hkn0630:1590942:1591100 [2] NCCL INFO Channel 00 : 310[ca000] -> 309[4b000] via P2P/IPC/read
262: hkn0613:895183:895295 [2] NCCL INFO Channel 01 : 262[ca000] -> 261[4b000] via P2P/IPC/read
242: hkn0607:896865:896980 [2] NCCL INFO Channel 01 : 242[ca000] -> 241[4b000] via P2P/IPC/read
306: hkn0629:1584560:1584666 [2] NCCL INFO Channel 00 : 306[ca000] -> 305[4b000] via P2P/IPC/read
422: hkn0726:1540606:1540728 [2] NCCL INFO Channel 00 : 422[ca000] -> 421[4b000] via P2P/IPC/read
 38: hkn0413:2359203:2359295 [2] NCCL INFO Channel 01 : 38[ca000] -> 37[4b000] via P2P/IPC/read
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
 21: hkn0409:2578197:2578308 [1] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
206: hkn0532:916669:916966 [2] NCCL INFO Channel 01 : 206[ca000] -> 205[4b000] via P2P/IPC/read
290: hkn0624:1765428:1765554 [2] NCCL INFO Channel 00 : 290[ca000] -> 289[4b000] via P2P/IPC/read
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 00 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
210: hkn0534:1140936:1141031 [2] NCCL INFO Channel 01 : 210[ca000] -> 209[4b000] via P2P/IPC/read
294: hkn0626:1290959:1291053 [2] NCCL INFO Channel 00 : 294[ca000] -> 293[4b000] via P2P/IPC/read
498: hkn0812:686269:686396 [2] NCCL INFO Channel 01 : 498[ca000] -> 497[4b000] via P2P/IPC/read
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
 94: hkn0428:659895:659982 [2] NCCL INFO Channel 01 : 94[ca000] -> 93[4b000] via P2P/IPC/read
202: hkn0531:1223078:1223201 [2] NCCL INFO Channel 01 : 202[ca000] -> 201[4b000] via P2P/IPC/read
218: hkn0601:110156:110284 [2] NCCL INFO Channel 00 : 218[ca000] -> 217[4b000] via P2P/IPC/read
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
238: hkn0606:2364570:2364670 [2] NCCL INFO Channel 01 : 238[ca000] -> 237[4b000] via P2P/IPC/read
370: hkn0712:287559:287664 [2] NCCL INFO Channel 00 : 370[ca000] -> 369[4b000] via P2P/IPC/read
246: hkn0608:478266:478383 [2] NCCL INFO Channel 01 : 246[ca000] -> 245[4b000] via P2P/IPC/read
100: hkn0502:221575:221672 [0] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 00 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
478: hkn0806:1046839:1046949 [2] NCCL INFO Channel 01 : 478[ca000] -> 477[4b000] via P2P/IPC/read
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 00 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
502: hkn0814:668347:668457 [2] NCCL INFO Channel 01 : 502[ca000] -> 501[4b000] via P2P/IPC/read
410: hkn0723:200364:200541 [2] NCCL INFO Channel 00 : 410[ca000] -> 409[4b000] via P2P/IPC/read
109: hkn0504:33317:33440 [1] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 00 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
117: hkn0506:830562:830672 [1] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
362: hkn0710:348041:348125 [2] NCCL INFO Channel 00 : 362[ca000] -> 361[4b000] via P2P/IPC/read
326: hkn0634:1513361:1513475 [2] NCCL INFO Channel 00 : 326[ca000] -> 325[4b000] via P2P/IPC/read
378: hkn0714:424535:424664 [2] NCCL INFO Channel 00 : 378[ca000] -> 377[4b000] via P2P/IPC/read
354: hkn0707:4012451:4012539 [2] NCCL INFO Channel 00 : 354[ca000] -> 353[4b000] via P2P/IPC/read
430: hkn0728:1316485:1316584 [2] NCCL INFO Channel 01 : 430[ca000] -> 429[4b000] via P2P/IPC/read
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 00 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
426: hkn0727:1338279:1338380 [2] NCCL INFO Channel 01 : 426[ca000] -> 425[4b000] via P2P/IPC/read
406: hkn0721:2291495:2291615 [2] NCCL INFO Channel 00 : 406[ca000] -> 405[4b000] via P2P/IPC/read
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
374: hkn0713:462739:462878 [2] NCCL INFO Channel 00 : 374[ca000] -> 373[4b000] via P2P/IPC/read
390: hkn0717:4180120:4180224 [2] NCCL INFO Channel 00 : 390[ca000] -> 389[4b000] via P2P/IPC/read
418: hkn0725:3104426:3104537 [2] NCCL INFO Channel 00 : 418[ca000] -> 417[4b000] via P2P/IPC/read
414: hkn0724:1708491:1708600 [2] NCCL INFO Channel 00 : 414[ca000] -> 413[4b000] via P2P/IPC/read
101: hkn0502:221555:221670 [1] NCCL INFO Channel 00 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 00 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
366: hkn0711:576395:576516 [2] NCCL INFO Channel 00 : 366[ca000] -> 365[4b000] via P2P/IPC/read
382: hkn0715:394402:394547 [2] NCCL INFO Channel 00 : 382[ca000] -> 381[4b000] via P2P/IPC/read
350: hkn0706:744766:744917 [2] NCCL INFO Channel 00 : 350[ca000] -> 349[4b000] via P2P/IPC/read
306: hkn0629:1584560:1584666 [2] NCCL INFO Channel 01 : 306[ca000] -> 305[4b000] via P2P/IPC/read
226: hkn0603:1405672:1405779 [2] NCCL INFO Channel 01 : 226[ca000] -> 225[4b000] via P2P/IPC/read
398: hkn0719:1298217:1298339 [2] NCCL INFO Channel 00 : 398[ca000] -> 397[4b000] via P2P/IPC/read
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 00 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 00 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
 85: hkn0426:806571:806694 [1] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
310: hkn0630:1590942:1591100 [2] NCCL INFO Channel 01 : 310[ca000] -> 309[4b000] via P2P/IPC/read
302: hkn0628:664349:664472 [2] NCCL INFO Channel 01 : 302[ca000] -> 301[4b000] via P2P/IPC/read
402: hkn0720:4190312:4190585 [2] NCCL INFO Channel 00 : 402[ca000] -> 401[4b000] via P2P/IPC/read
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
116: hkn0506:830570:830664 [0] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
290: hkn0624:1765428:1765554 [2] NCCL INFO Channel 01 : 290[ca000] -> 289[4b000] via P2P/IPC/read
318: hkn0632:1751099:1751227 [2] NCCL INFO Channel 01 : 318[ca000] -> 317[4b000] via P2P/IPC/read
286: hkn0623:1865246:1865351 [2] NCCL INFO Channel 01 : 286[ca000] -> 285[4b000] via P2P/IPC/read
358: hkn0708:405723:405866 [2] NCCL INFO Channel 00 : 358[ca000] -> 357[4b000] via P2P/IPC/read
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 00 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 00 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
294: hkn0626:1290959:1291053 [2] NCCL INFO Channel 01 : 294[ca000] -> 293[4b000] via P2P/IPC/read
298: hkn0627:1780406:1780532 [2] NCCL INFO Channel 01 : 298[ca000] -> 297[4b000] via P2P/IPC/read
394: hkn0718:3909522:3909643 [2] NCCL INFO Channel 00 : 394[ca000] -> 393[4b000] via P2P/IPC/read
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
469: hkn0804:1198123:1198240 [1] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
386: hkn0716:101020:101119 [2] NCCL INFO Channel 00 : 386[ca000] -> 385[4b000] via P2P/IPC/read
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 00 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
218: hkn0601:110156:110284 [2] NCCL INFO Channel 01 : 218[ca000] -> 217[4b000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 00 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
282: hkn0622:2012978:2013091 [2] NCCL INFO Channel 01 : 282[ca000] -> 281[4b000] via P2P/IPC/read
322: hkn0633:1518843:1518959 [2] NCCL INFO Channel 01 : 322[ca000] -> 321[4b000] via P2P/IPC/read
314: hkn0631:1014322:1014417 [2] NCCL INFO Channel 01 : 314[ca000] -> 313[4b000] via P2P/IPC/read
342: hkn0704:784530:784630 [2] NCCL INFO Channel 00 : 342[ca000] -> 341[4b000] via P2P/IPC/read
346: hkn0705:775721:775863 [2] NCCL INFO Channel 00 : 346[ca000] -> 345[4b000] via P2P/IPC/read
422: hkn0726:1540606:1540728 [2] NCCL INFO Channel 01 : 422[ca000] -> 421[4b000] via P2P/IPC/read
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 00 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 00 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
326: hkn0634:1513361:1513475 [2] NCCL INFO Channel 01 : 326[ca000] -> 325[4b000] via P2P/IPC/read
334: hkn0636:1646736:1646844 [2] NCCL INFO Channel 00 : 334[ca000] -> 333[4b000] via P2P/IPC/read
214: hkn0535:2391519:2391622 [2] NCCL INFO Channel 01 : 214[ca000] -> 213[4b000] via P2P/IPC/read
494: hkn0810:932062:932167 [2] NCCL INFO Channel 01 : 494[ca000] -> 493[4b000] via P2P/IPC/read
490: hkn0809:929907:930004 [2] NCCL INFO Channel 00 : 490[ca000] -> 489[4b000] via P2P/IPC/read
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
410: hkn0723:200364:200541 [2] NCCL INFO Channel 01 : 410[ca000] -> 409[4b000] via P2P/IPC/read
222: hkn0602:3353974:3354228 [2] NCCL INFO Channel 01 : 222[ca000] -> 221[4b000] via P2P/IPC/read
370: hkn0712:287559:287664 [2] NCCL INFO Channel 01 : 370[ca000] -> 369[4b000] via P2P/IPC/read
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 00 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
414: hkn0724:1708491:1708600 [2] NCCL INFO Channel 01 : 414[ca000] -> 413[4b000] via P2P/IPC/read
492: hkn0810:932042:932160 [0] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
 37: hkn0413:2359194:2359299 [1] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
181: hkn0526:1420907:1421018 [1] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
366: hkn0711:576395:576516 [2] NCCL INFO Channel 01 : 366[ca000] -> 365[4b000] via P2P/IPC/read
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 00 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
350: hkn0706:744766:744917 [2] NCCL INFO Channel 01 : 350[ca000] -> 349[4b000] via P2P/IPC/read
418: hkn0725:3104426:3104537 [2] NCCL INFO Channel 01 : 418[ca000] -> 417[4b000] via P2P/IPC/read
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 00 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
176: hkn0525:979338:979432 [0] NCCL INFO Channel 00 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
398: hkn0719:1298217:1298339 [2] NCCL INFO Channel 01 : 398[ca000] -> 397[4b000] via P2P/IPC/read
437: hkn0731:1379256:1379351 [1] NCCL INFO Channel 00 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
402: hkn0720:4190312:4190585 [2] NCCL INFO Channel 01 : 402[ca000] -> 401[4b000] via P2P/IPC/read
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 00 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 00 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
354: hkn0707:4012451:4012539 [2] NCCL INFO Channel 01 : 354[ca000] -> 353[4b000] via P2P/IPC/read
346: hkn0705:775721:775863 [2] NCCL INFO Channel 01 : 346[ca000] -> 345[4b000] via P2P/IPC/read
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 00 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
406: hkn0721:2291495:2291615 [2] NCCL INFO Channel 01 : 406[ca000] -> 405[4b000] via P2P/IPC/read
382: hkn0715:394402:394547 [2] NCCL INFO Channel 01 : 382[ca000] -> 381[4b000] via P2P/IPC/read
358: hkn0708:405723:405866 [2] NCCL INFO Channel 01 : 358[ca000] -> 357[4b000] via P2P/IPC/read
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 00 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
277: hkn0621:1984016:1984143 [1] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
362: hkn0710:348041:348125 [2] NCCL INFO Channel 01 : 362[ca000] -> 361[4b000] via P2P/IPC/read
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 00 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
374: hkn0713:462739:462878 [2] NCCL INFO Channel 01 : 374[ca000] -> 373[4b000] via P2P/IPC/read
378: hkn0714:424535:424664 [2] NCCL INFO Channel 01 : 378[ca000] -> 377[4b000] via P2P/IPC/read
330: hkn0635:1218111:1218207 [2] NCCL INFO Channel 01 : 330[ca000] -> 329[4b000] via P2P/IPC/read
390: hkn0717:4180120:4180224 [2] NCCL INFO Channel 01 : 390[ca000] -> 389[4b000] via P2P/IPC/read
394: hkn0718:3909522:3909643 [2] NCCL INFO Channel 01 : 394[ca000] -> 393[4b000] via P2P/IPC/read
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
386: hkn0716:101020:101119 [2] NCCL INFO Channel 01 : 386[ca000] -> 385[4b000] via P2P/IPC/read
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 00 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 00 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
177: hkn0525:979326:979436 [1] NCCL INFO Channel 00 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
342: hkn0704:784530:784630 [2] NCCL INFO Channel 01 : 342[ca000] -> 341[4b000] via P2P/IPC/read
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
497: hkn0812:686297:686395 [1] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 00 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 00 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 00 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 00 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
334: hkn0636:1646736:1646844 [2] NCCL INFO Channel 01 : 334[ca000] -> 333[4b000] via P2P/IPC/read
245: hkn0608:478274:478386 [1] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 00 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
465: hkn0803:869036:869157 [1] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
490: hkn0809:929907:930004 [2] NCCL INFO Channel 01 : 490[ca000] -> 489[4b000] via P2P/IPC/read
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 00 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 00 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 00 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 00 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
338: hkn0703:733524:733645 [2] NCCL INFO Channel 00 : 338[ca000] -> 337[4b000] via P2P/IPC/read
213: hkn0535:2391499:2391618 [1] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 00 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
253: hkn0611:702329:702425 [1] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
205: hkn0532:916650:916971 [1] NCCL INFO Channel 00 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
268: hkn0616:397357:397478 [0] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 00 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
248: hkn0609:703361:703450 [0] NCCL INFO Channel 00 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
269: hkn0616:397377:397476 [1] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
165: hkn0521:1190302:1190437 [1] NCCL INFO Channel 00 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
241: hkn0607:896873:896982 [1] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
244: hkn0608:478258:478384 [0] NCCL INFO Channel 00 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
493: hkn0810:932050:932165 [1] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 00 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
249: hkn0609:703333:703446 [1] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 00 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
240: hkn0607:896885:896985 [0] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 00 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
257: hkn0612:909451:909581 [1] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
232: hkn0605:704594:704721 [0] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
  5: hkn0404:1331860:1331998 [1] NCCL INFO Channel 00 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
301: hkn0628:664357:664467 [1] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 00 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 00 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
256: hkn0612:909459:909583 [0] NCCL INFO Channel 00 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
260: hkn0613:895195:895293 [0] NCCL INFO Channel 00 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
233: hkn0605:704610:704720 [1] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 00 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
204: hkn0532:916658:916970 [0] NCCL INFO Channel 00 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
361: hkn0710:348021:348124 [1] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 00 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
504: hkn0815:387632:387784 [0] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 00 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 00 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
229: hkn0604:681744:681864 [1] NCCL INFO Channel 00 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
300: hkn0628:664377:664476 [0] NCCL INFO Channel 00 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 00 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
228: hkn0604:681736:681856 [0] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
377: hkn0714:424551:424658 [1] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
484: hkn0808:963191:963307 [0] NCCL INFO Channel 00 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
265: hkn0615:406807:406907 [1] NCCL INFO Channel 00 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
500: hkn0814:668339:668453 [0] NCCL INFO Channel 00 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
508: hkn0816:368125:368237 [0] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
485: hkn0808:963203:963306 [1] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 00 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
  1: hkn0403:1751324:1751696 [1] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
338: hkn0703:733524:733645 [2] NCCL INFO Channel 01 : 338[ca000] -> 337[4b000] via P2P/IPC/read
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 00 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
381: hkn0715:394422:394551 [1] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 00 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 00 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
509: hkn0816:368127:368238 [1] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 00 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
337: hkn0703:733504:733651 [1] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
197: hkn0530:1250643:1250765 [1] NCCL INFO Channel 00 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 00 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 00 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
505: hkn0815:387660:387783 [1] NCCL INFO Channel 00 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 00 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
369: hkn0712:287543:287667 [1] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
372: hkn0713:462723:462881 [0] NCCL INFO Channel 00 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 00 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
293: hkn0626:1290947:1291055 [1] NCCL INFO Channel 00 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 00 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
368: hkn0712:287551:287669 [0] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
380: hkn0715:394410:394546 [0] NCCL INFO Channel 00 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
349: hkn0706:744786:744914 [1] NCCL INFO Channel 00 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 00 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
421: hkn0726:1540614:1540729 [1] NCCL INFO Channel 00 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 00 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
217: hkn0601:110184:110286 [1] NCCL INFO Channel 00 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 00 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
357: hkn0708:405731:405869 [1] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
373: hkn0713:462731:462877 [1] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
336: hkn0703:733512:733649 [0] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
216: hkn0601:110172:110280 [0] NCCL INFO Channel 00 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
356: hkn0708:405715:405864 [0] NCCL INFO Channel 00 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
389: hkn0717:4180100:4180219 [1] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 00 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 00 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
408: hkn0723:200389:200535 [0] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
360: hkn0710:348013:348131 [0] NCCL INFO Channel 00 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
309: hkn0630:1590958:1591101 [1] NCCL INFO Channel 00 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
464: hkn0803:869028:869155 [0] NCCL INFO Channel 00 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
496: hkn0812:686285:686394 [0] NCCL INFO Channel 00 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
409: hkn0723:200369:200533 [1] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
385: hkn0716:101000:101120 [1] NCCL INFO Channel 00 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
365: hkn0711:576415:576512 [1] NCCL INFO Channel 00 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 00 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 00 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 00 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 00 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 00 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 00 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
384: hkn0716:101008:101117 [0] NCCL INFO Channel 00 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
325: hkn0634:1513380:1513484 [1] NCCL INFO Channel 00 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
364: hkn0711:576387:576519 [0] NCCL INFO Channel 00 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 00 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 00 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 00 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 00 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 00 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 00 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
341: hkn0704:784510:784629 [1] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 00 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 00 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
340: hkn0704:784518:784625 [0] NCCL INFO Channel 00 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
345: hkn0705:775705:775864 [1] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 00 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [receive] via NET/IBext/0
344: hkn0705:775713:775862 [0] NCCL INFO Channel 00 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [receive] via NET/IBext/0
261: hkn0613:895175:895292 [1] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [send] via NET/IBext/0
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [send] via NET/IBext/0
489: hkn0809:929888:930005 [1] NCCL INFO Channel 00 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
488: hkn0809:929896:930007 [0] NCCL INFO Channel 00 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 00 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 01 : 77[4b000] -> 80[31000] [receive] via NET/IBext/0
501: hkn0814:668331:668452 [1] NCCL INFO Channel 00 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 00 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
252: hkn0611:702309:702428 [0] NCCL INFO Channel 00 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 00 : 68[31000] -> 71[e3000] via P2P/IPC/read
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [receive] via NET/IBext/0
149: hkn0514:2943234:2943343 [1] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [send] via NET/IBext/0
 69: hkn0422:4145507:4145651 [1] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [send] via NET/IBext/0
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [receive] via NET/IBext/0
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 00 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [receive] via NET/IBext/0
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 01 : 61[4b000] -> 64[31000] [send] via NET/IBext/0
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 00 : 140[31000] -> 143[e3000] via P2P/IPC/read
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 01 : 65[4b000] -> 68[31000] [send] via NET/IBext/0
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 01 : 149[4b000] -> 152[31000] [receive] via NET/IBext/0
264: hkn0615:406779:406906 [0] NCCL INFO Channel 00 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [receive] via NET/IBext/0
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [receive] via NET/IBext/0
453: hkn0736:1500847:1500961 [1] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [send] via NET/IBext/0
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [send] via NET/IBext/0
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [receive] via NET/IBext/0
376: hkn0714:424562:424665 [0] NCCL INFO Channel 00 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [receive] via NET/IBext/0
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 00 : 80[31000] -> 83[e3000] via P2P/IPC/read
 21: hkn0409:2578197:2578308 [1] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [send] via NET/IBext/0
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [receive] via NET/IBext/0
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 01 : 68[31000] -> 71[e3000] via P2P/IPC/read
133: hkn0510:2754575:2754694 [1] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [send] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [receive] via NET/IBext/0
 53: hkn0418:1861667:1861790 [1] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [send] via NET/IBext/0
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 01 : 140[31000] -> 143[e3000] via P2P/IPC/read
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 01 : 81[4b000] -> 84[31000] [send] via NET/IBext/0
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [receive] via NET/IBext/0
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 00 : 64[31000] -> 67[e3000] via P2P/IPC/read
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [receive] via NET/IBext/0
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [send] via NET/IBext/0
117: hkn0506:830562:830672 [1] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [send] via NET/IBext/0
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [send] via NET/IBext/0
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [send] via NET/IBext/0
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 00 : 104[31000] -> 107[e3000] via P2P/IPC/read
109: hkn0504:33317:33440 [1] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [send] via NET/IBext/0
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 00 : 148[31000] -> 151[e3000] via P2P/IPC/read
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [receive] via NET/IBext/0
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 00 : 160[31000] -> 163[e3000] via P2P/IPC/read
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 00 : 440[31000] -> 443[e3000] via P2P/IPC/read
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [receive] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [receive] via NET/IBext/0
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 00 : 60[31000] -> 63[e3000] via P2P/IPC/read
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [receive] via NET/IBext/0
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 01 : 57[4b000] -> 60[31000] [send] via NET/IBext/0
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 00 : 152[31000] -> 155[e3000] via P2P/IPC/read
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 01 : 145[4b000] -> 148[31000] [send] via NET/IBext/0
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [receive] via NET/IBext/0
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 01 : 157[4b000] -> 160[31000] [send] via NET/IBext/0
 85: hkn0426:806571:806694 [1] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [send] via NET/IBext/0
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [receive] via NET/IBext/0
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [send] via NET/IBext/0
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 01 : 53[4b000] -> 56[31000] [receive] via NET/IBext/0
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 01 : 129[4b000] -> 132[31000] [receive] via NET/IBext/0
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [receive] via NET/IBext/0
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 01 : 153[4b000] -> 156[31000] [receive] via NET/IBext/0
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 00 : 84[31000] -> 87[e3000] via P2P/IPC/read
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [receive] via NET/IBext/0
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [receive] via NET/IBext/0
100: hkn0502:221575:221672 [0] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [receive] via NET/IBext/0
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [receive] via NET/IBext/0
116: hkn0506:830570:830664 [0] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [receive] via NET/IBext/0
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [receive] via NET/IBext/0
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 01 : 80[31000] -> 83[e3000] via P2P/IPC/read
469: hkn0804:1198123:1198240 [1] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [send] via NET/IBext/0
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 00 : 36[31000] -> 39[e3000] via P2P/IPC/read
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 01 : 21[4b000] -> 24[31000] [receive] via NET/IBext/0
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [receive] via NET/IBext/0
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 01 : 64[31000] -> 67[e3000] via P2P/IPC/read
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [send] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO Channel 00 : 108[31000] -> 111[e3000] via P2P/IPC/read
101: hkn0502:221555:221670 [1] NCCL INFO Channel 01 : 101[4b000] -> 104[31000] [send] via NET/IBext/0
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 01 : 137[4b000] -> 140[31000] [send] via NET/IBext/0
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 01 : 104[31000] -> 107[e3000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO Channel 00 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
492: hkn0810:932042:932160 [0] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [receive] via NET/IBext/0
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [send] via NET/IBext/0
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 01 : 148[31000] -> 151[e3000] via P2P/IPC/read
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 01 : 49[4b000] -> 52[31000] [send] via NET/IBext/0
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 01 : 160[31000] -> 163[e3000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 01 : 133[4b000] -> 136[31000] [receive] via NET/IBext/0
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [send] via NET/IBext/0
 37: hkn0413:2359194:2359299 [1] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [send] via NET/IBext/0
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 00 : 52[31000] -> 55[e3000] via P2P/IPC/read
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 01 : 89[4b000] -> 92[31000] [send] via NET/IBext/0
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 01 : 440[31000] -> 443[e3000] via P2P/IPC/read
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 01 : 60[31000] -> 63[e3000] via P2P/IPC/read
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 01 : 85[4b000] -> 88[31000] [receive] via NET/IBext/0
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 01 : 152[31000] -> 155[e3000] via P2P/IPC/read
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 01 : 117[4b000] -> 120[31000] [receive] via NET/IBext/0
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 00 : 92[31000] -> 95[e3000] via P2P/IPC/read
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [receive] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 00 : 124[31000] -> 127[e3000] via P2P/IPC/read
465: hkn0803:869036:869157 [1] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [send] via NET/IBext/0
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [receive] via NET/IBext/0
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 00 : 192[31000] -> 195[e3000] via P2P/IPC/read
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [receive] via NET/IBext/0
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 01 : 45[4b000] -> 48[31000] [send] via NET/IBext/0
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 00 : 144[31000] -> 147[e3000] via P2P/IPC/read
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 01 : 84[31000] -> 87[e3000] via P2P/IPC/read
181: hkn0526:1420907:1421018 [1] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [send] via NET/IBext/0
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 00 : 452[31000] -> 455[e3000] via P2P/IPC/read
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 00 : 56[31000] -> 59[e3000] via P2P/IPC/read
176: hkn0525:979338:979432 [0] NCCL INFO Channel 01 : 173[4b000] -> 176[31000] [receive] via NET/IBext/0
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 01 : 121[4b000] -> 124[31000] [send] via NET/IBext/0
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 00 : 172[31000] -> 175[e3000] via P2P/IPC/read
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 01 : 73[4b000] -> 76[31000] [send] via NET/IBext/0
245: hkn0608:478274:478386 [1] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [send] via NET/IBext/0
497: hkn0812:686297:686395 [1] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [send] via NET/IBext/0
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 01 : 36[31000] -> 39[e3000] via P2P/IPC/read
437: hkn0731:1379256:1379351 [1] NCCL INFO Channel 01 : 437[4b000] -> 440[31000] [send] via NET/IBext/0
100: hkn0502:221575:221672 [0] NCCL INFO Channel 00 : 100[31000] -> 103[e3000] via P2P/IPC/read
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 00 : 44[31000] -> 47[e3000] via P2P/IPC/read
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 00 : 20[31000] -> 23[e3000] via P2P/IPC/read
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [send] via NET/IBext/0
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 00 : 132[31000] -> 135[e3000] via P2P/IPC/read
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [send] via NET/IBext/0
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 01 : 433[4b000] -> 436[31000] [send] via NET/IBext/0
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [send] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO Channel 01 : 108[31000] -> 111[e3000] via P2P/IPC/read
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 00 : 24[31000] -> 27[e3000] via P2P/IPC/read
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 00 : 156[31000] -> 159[e3000] via P2P/IPC/read
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 00 : 180[31000] -> 183[e3000] via P2P/IPC/read
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [send] via NET/IBext/0
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 01 : 181[4b000] -> 184[31000] [receive] via NET/IBext/0
116: hkn0506:830570:830664 [0] NCCL INFO Channel 00 : 116[31000] -> 119[e3000] via P2P/IPC/read
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 00 : 200[31000] -> 203[e3000] via P2P/IPC/read
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 00 : 48[31000] -> 51[e3000] via P2P/IPC/read
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 01 : 109[4b000] -> 112[31000] [receive] via NET/IBext/0
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 01 : 69[4b000] -> 72[31000] [receive] via NET/IBext/0
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 01 : 465[4b000] -> 468[31000] [receive] via NET/IBext/0
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 01 : 52[31000] -> 55[e3000] via P2P/IPC/read
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 00 : 76[31000] -> 79[e3000] via P2P/IPC/read
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 01 : 25[4b000] -> 28[31000] [receive] via NET/IBext/0
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 01 : 41[4b000] -> 44[31000] [send] via NET/IBext/0
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [send] via NET/IBext/0
177: hkn0525:979326:979436 [1] NCCL INFO Channel 01 : 177[4b000] -> 180[31000] [send] via NET/IBext/0
253: hkn0611:702329:702425 [1] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [send] via NET/IBext/0
277: hkn0621:1984016:1984143 [1] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [send] via NET/IBext/0
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [receive] via NET/IBext/0
213: hkn0535:2391499:2391618 [1] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [send] via NET/IBext/0
492: hkn0810:932042:932160 [0] NCCL INFO Channel 00 : 492[31000] -> 495[e3000] via P2P/IPC/read
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 00 : 12[31000] -> 15[e3000] via P2P/IPC/read
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 01 : 37[4b000] -> 40[31000] [receive] via NET/IBext/0
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 01 : 92[31000] -> 95[e3000] via P2P/IPC/read
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 01 : 273[4b000] -> 276[31000] [receive] via NET/IBext/0
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 01 : 97[4b000] -> 100[31000] [send] via NET/IBext/0
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [send] via NET/IBext/0
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [send] via NET/IBext/0
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 01 : 144[31000] -> 147[e3000] via P2P/IPC/read
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 01 : 113[4b000] -> 116[31000] [send] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 01 : 124[31000] -> 127[e3000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 00 : 136[31000] -> 139[e3000] via P2P/IPC/read
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [send] via NET/IBext/0
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 01 : 192[31000] -> 195[e3000] via P2P/IPC/read
  5: hkn0404:1331860:1331998 [1] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [send] via NET/IBext/0
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [receive] via NET/IBext/0
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 01 : 452[31000] -> 455[e3000] via P2P/IPC/read
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 00 : 480[31000] -> 483[e3000] via P2P/IPC/read
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 00 : 120[31000] -> 123[e3000] via P2P/IPC/read
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 01 : 169[4b000] -> 172[31000] [send] via NET/IBext/0
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [send] via NET/IBext/0
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 01 : 449[4b000] -> 452[31000] [send] via NET/IBext/0
493: hkn0810:932050:932165 [1] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [send] via NET/IBext/0
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [receive] via NET/IBext/0
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [send] via NET/IBext/0
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 00 : 88[31000] -> 91[e3000] via P2P/IPC/read
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 00 : 436[31000] -> 439[e3000] via P2P/IPC/read
100: hkn0502:221575:221672 [0] NCCL INFO Channel 01 : 100[31000] -> 103[e3000] via P2P/IPC/read
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 01 : 20[31000] -> 23[e3000] via P2P/IPC/read
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 01 : 56[31000] -> 59[e3000] via P2P/IPC/read
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 01 : 200[31000] -> 203[e3000] via P2P/IPC/read
205: hkn0532:916650:916971 [1] NCCL INFO Channel 01 : 205[4b000] -> 208[31000] [send] via NET/IBext/0
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [receive] via NET/IBext/0
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 01 : 172[31000] -> 175[e3000] via P2P/IPC/read
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 01 : 277[4b000] -> 280[31000] [receive] via NET/IBext/0
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 01 : 445[4b000] -> 448[31000] [receive] via NET/IBext/0
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 01 : 93[4b000] -> 96[31000] [receive] via NET/IBext/0
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 01 : 24[31000] -> 27[e3000] via P2P/IPC/read
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 01 : 156[31000] -> 159[e3000] via P2P/IPC/read
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 01 : 180[31000] -> 183[e3000] via P2P/IPC/read
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 01 : 44[31000] -> 47[e3000] via P2P/IPC/read
176: hkn0525:979338:979432 [0] NCCL INFO Channel 00 : 176[31000] -> 179[e3000] via P2P/IPC/read
116: hkn0506:830570:830664 [0] NCCL INFO Channel 01 : 116[31000] -> 119[e3000] via P2P/IPC/read
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 01 : 132[31000] -> 135[e3000] via P2P/IPC/read
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 01 : 48[31000] -> 51[e3000] via P2P/IPC/read
361: hkn0710:348021:348124 [1] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [send] via NET/IBext/0
268: hkn0616:397357:397478 [0] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [receive] via NET/IBext/0
248: hkn0609:703361:703450 [0] NCCL INFO Channel 01 : 245[4b000] -> 248[31000] [receive] via NET/IBext/0
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 01 : 5[4b000] -> 8[31000] [receive] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [receive] via NET/IBext/0
244: hkn0608:478258:478384 [0] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [receive] via NET/IBext/0
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 00 : 444[31000] -> 447[e3000] via P2P/IPC/read
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 01 : 469[4b000] -> 472[31000] [receive] via NET/IBext/0
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 01 : 12[31000] -> 15[e3000] via P2P/IPC/read
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [send] via NET/IBext/0
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 01 : 76[31000] -> 79[e3000] via P2P/IPC/read
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 00 : 184[31000] -> 187[e3000] via P2P/IPC/read
265: hkn0615:406807:406907 [1] NCCL INFO Channel 01 : 265[4b000] -> 268[31000] [send] via NET/IBext/0
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [send] via NET/IBext/0
269: hkn0616:397377:397476 [1] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [send] via NET/IBext/0
257: hkn0612:909451:909581 [1] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [send] via NET/IBext/0
249: hkn0609:703333:703446 [1] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [send] via NET/IBext/0
260: hkn0613:895195:895293 [0] NCCL INFO Channel 01 : 257[4b000] -> 260[31000] [receive] via NET/IBext/0
241: hkn0607:896873:896982 [1] NCCL INFO Channel 01 : 241[4b000] -> 244[31000] [send] via NET/IBext/0
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [receive] via NET/IBext/0
232: hkn0605:704594:704721 [0] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [receive] via NET/IBext/0
377: hkn0714:424551:424658 [1] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [send] via NET/IBext/0
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [send] via NET/IBext/0
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 01 : 269[4b000] -> 272[31000] [receive] via NET/IBext/0
492: hkn0810:932042:932160 [0] NCCL INFO Channel 01 : 492[31000] -> 495[e3000] via P2P/IPC/read
500: hkn0814:668339:668453 [0] NCCL INFO Channel 01 : 497[4b000] -> 500[31000] [receive] via NET/IBext/0
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 00 : 468[31000] -> 471[e3000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 01 : 457[4b000] -> 460[31000] [receive] via NET/IBext/0
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 00 : 28[31000] -> 31[e3000] via P2P/IPC/read
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 01 : 17[4b000] -> 20[31000] [send] via NET/IBext/0
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [receive] via NET/IBext/0
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 01 : 480[31000] -> 483[e3000] via P2P/IPC/read
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 00 : 276[31000] -> 279[e3000] via P2P/IPC/read
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 00 : 112[31000] -> 115[e3000] via P2P/IPC/read
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 00 : 208[31000] -> 211[e3000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 01 : 136[31000] -> 139[e3000] via P2P/IPC/read
256: hkn0612:909459:909583 [0] NCCL INFO Channel 01 : 253[4b000] -> 256[31000] [receive] via NET/IBext/0
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 00 : 72[31000] -> 75[e3000] via P2P/IPC/read
240: hkn0607:896885:896985 [0] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [receive] via NET/IBext/0
300: hkn0628:664377:664476 [0] NCCL INFO Channel 01 : 297[4b000] -> 300[31000] [receive] via NET/IBext/0
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [receive] via NET/IBext/0
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 01 : 209[4b000] -> 212[31000] [receive] via NET/IBext/0
504: hkn0815:387632:387784 [0] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [receive] via NET/IBext/0
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 01 : 88[31000] -> 91[e3000] via P2P/IPC/read
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 00 : 40[31000] -> 43[e3000] via P2P/IPC/read
204: hkn0532:916658:916970 [0] NCCL INFO Channel 01 : 201[4b000] -> 204[31000] [receive] via NET/IBext/0
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 01 : 120[31000] -> 123[e3000] via P2P/IPC/read
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [send] via NET/IBext/0
165: hkn0521:1190302:1190437 [1] NCCL INFO Channel 01 : 165[4b000] -> 168[31000] [send] via NET/IBext/0
229: hkn0604:681744:681864 [1] NCCL INFO Channel 01 : 229[4b000] -> 232[31000] [send] via NET/IBext/0
301: hkn0628:664357:664467 [1] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [send] via NET/IBext/0
233: hkn0605:704610:704720 [1] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [send] via NET/IBext/0
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [send] via NET/IBext/0
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [receive] via NET/IBext/0
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 01 : 13[4b000] -> 16[31000] [send] via NET/IBext/0
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 01 : 436[31000] -> 439[e3000] via P2P/IPC/read
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 01 : 125[4b000] -> 128[31000] [receive] via NET/IBext/0
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 01 : 473[4b000] -> 476[31000] [receive] via NET/IBext/0
337: hkn0703:733504:733651 [1] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [send] via NET/IBext/0
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 01 : 189[4b000] -> 192[31000] [send] via NET/IBext/0
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 01 : 161[4b000] -> 164[31000] [receive] via NET/IBext/0
228: hkn0604:681736:681856 [0] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [receive] via NET/IBext/0
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 00 : 448[31000] -> 451[e3000] via P2P/IPC/read
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 01 : 444[31000] -> 447[e3000] via P2P/IPC/read
484: hkn0808:963191:963307 [0] NCCL INFO Channel 01 : 481[4b000] -> 484[31000] [receive] via NET/IBext/0
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 00 : 432[31000] -> 435[e3000] via P2P/IPC/read
176: hkn0525:979338:979432 [0] NCCL INFO Channel 01 : 176[31000] -> 179[e3000] via P2P/IPC/read
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 01 : 477[4b000] -> 480[31000] [send] via NET/IBext/0
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 00 : 168[31000] -> 171[e3000] via P2P/IPC/read
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 00 : 280[31000] -> 283[e3000] via P2P/IPC/read
248: hkn0609:703361:703450 [0] NCCL INFO Channel 00 : 248[31000] -> 251[e3000] via P2P/IPC/read
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 01 : 185[4b000] -> 188[31000] [receive] via NET/IBext/0
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [receive] via NET/IBext/0
381: hkn0715:394422:394551 [1] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [send] via NET/IBext/0
485: hkn0808:963203:963306 [1] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [send] via NET/IBext/0
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 01 : 425[4b000] -> 428[31000] [receive] via NET/IBext/0
  1: hkn0403:1751324:1751696 [1] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [send] via NET/IBext/0
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 01 : 184[31000] -> 187[e3000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 00 : 16[31000] -> 19[e3000] via P2P/IPC/read
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 01 : 285[4b000] -> 288[31000] [receive] via NET/IBext/0
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 01 : 112[31000] -> 115[e3000] via P2P/IPC/read
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 01 : 208[31000] -> 211[e3000] via P2P/IPC/read
268: hkn0616:397357:397478 [0] NCCL INFO Channel 00 : 268[31000] -> 271[e3000] via P2P/IPC/read
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [receive] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 00 : 320[31000] -> 323[e3000] via P2P/IPC/read
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 01 : 72[31000] -> 75[e3000] via P2P/IPC/read
372: hkn0713:462723:462881 [0] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [receive] via NET/IBext/0
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 00 : 312[31000] -> 315[e3000] via P2P/IPC/read
244: hkn0608:478258:478384 [0] NCCL INFO Channel 00 : 244[31000] -> 247[e3000] via P2P/IPC/read
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 01 : 225[4b000] -> 228[31000] [send] via NET/IBext/0
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 01 : 429[4b000] -> 432[31000] [send] via NET/IBext/0
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 01 : 468[31000] -> 471[e3000] via P2P/IPC/read
505: hkn0815:387660:387783 [1] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [send] via NET/IBext/0
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 00 : 96[31000] -> 99[e3000] via P2P/IPC/read
508: hkn0816:368125:368237 [0] NCCL INFO Channel 01 : 505[4b000] -> 508[31000] [receive] via NET/IBext/0
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 01 : 28[31000] -> 31[e3000] via P2P/IPC/read
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 01 : 276[31000] -> 279[e3000] via P2P/IPC/read
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 01 : 317[4b000] -> 320[31000] [send] via NET/IBext/0
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 00 : 8[31000] -> 11[e3000] via P2P/IPC/read
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [send] via NET/IBext/0
260: hkn0613:895195:895293 [0] NCCL INFO Channel 00 : 260[31000] -> 263[e3000] via P2P/IPC/read
240: hkn0607:896885:896985 [0] NCCL INFO Channel 00 : 240[31000] -> 243[e3000] via P2P/IPC/read
349: hkn0706:744786:744914 [1] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [send] via NET/IBext/0
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 01 : 313[4b000] -> 316[31000] [send] via NET/IBext/0
232: hkn0605:704594:704721 [0] NCCL INFO Channel 00 : 232[31000] -> 235[e3000] via P2P/IPC/read
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [receive] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [receive] via NET/IBext/0
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 00 : 472[31000] -> 475[e3000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 00 : 460[31000] -> 463[e3000] via P2P/IPC/read
509: hkn0816:368127:368238 [1] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [send] via NET/IBext/0
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 01 : 40[31000] -> 43[e3000] via P2P/IPC/read
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 01 : 193[4b000] -> 196[31000] [receive] via NET/IBext/0
369: hkn0712:287543:287667 [1] NCCL INFO Channel 01 : 369[4b000] -> 372[31000] [send] via NET/IBext/0
300: hkn0628:664377:664476 [0] NCCL INFO Channel 00 : 300[31000] -> 303[e3000] via P2P/IPC/read
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 00 : 328[31000] -> 331[e3000] via P2P/IPC/read
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 01 : 349[4b000] -> 352[31000] [receive] via NET/IBext/0
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 00 : 272[31000] -> 275[e3000] via P2P/IPC/read
421: hkn0726:1540614:1540729 [1] NCCL INFO Channel 01 : 421[4b000] -> 424[31000] [send] via NET/IBext/0
500: hkn0814:668339:668453 [0] NCCL INFO Channel 00 : 500[31000] -> 503[e3000] via P2P/IPC/read
504: hkn0815:387632:387784 [0] NCCL INFO Channel 00 : 504[31000] -> 507[e3000] via P2P/IPC/read
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 00 : 424[31000] -> 427[e3000] via P2P/IPC/read
405: hkn0721:2291522:2291616 [1] NCCL INFO Channel 00 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
197: hkn0530:1250643:1250765 [1] NCCL INFO Channel 01 : 197[4b000] -> 200[31000] [send] via NET/IBext/0
256: hkn0612:909459:909583 [0] NCCL INFO Channel 00 : 256[31000] -> 259[e3000] via P2P/IPC/read
368: hkn0712:287551:287669 [0] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [receive] via NET/IBext/0
380: hkn0715:394410:394546 [0] NCCL INFO Channel 01 : 377[4b000] -> 380[31000] [receive] via NET/IBext/0
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 01 : 448[31000] -> 451[e3000] via P2P/IPC/read
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 00 : 212[31000] -> 215[e3000] via P2P/IPC/read
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 00 : 420[31000] -> 423[e3000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 01 : 16[31000] -> 19[e3000] via P2P/IPC/read
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 00 : 476[31000] -> 479[e3000] via P2P/IPC/read
204: hkn0532:916658:916970 [0] NCCL INFO Channel 00 : 204[31000] -> 207[e3000] via P2P/IPC/read
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 01 : 168[31000] -> 171[e3000] via P2P/IPC/read
268: hkn0616:397357:397478 [0] NCCL INFO Channel 01 : 268[31000] -> 271[e3000] via P2P/IPC/read
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 01 : 280[31000] -> 283[e3000] via P2P/IPC/read
248: hkn0609:703361:703450 [0] NCCL INFO Channel 01 : 248[31000] -> 251[e3000] via P2P/IPC/read
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 01 : 320[31000] -> 323[e3000] via P2P/IPC/read
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 00 : 164[31000] -> 167[e3000] via P2P/IPC/read
228: hkn0604:681736:681856 [0] NCCL INFO Channel 00 : 228[31000] -> 231[e3000] via P2P/IPC/read
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 01 : 432[31000] -> 435[e3000] via P2P/IPC/read
 39: hkn0413:2359214:2359301 [3] NCCL INFO Channel 00 : 39[e3000] -> 38[ca000] via P2P/IPC/read
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 01 : 96[31000] -> 99[e3000] via P2P/IPC/read
360: hkn0710:348013:348131 [0] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [receive] via NET/IBext/0
293: hkn0626:1290947:1291055 [1] NCCL INFO Channel 01 : 293[4b000] -> 296[31000] [send] via NET/IBext/0
373: hkn0713:462731:462877 [1] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [send] via NET/IBext/0
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 01 : 312[31000] -> 315[e3000] via P2P/IPC/read
244: hkn0608:478258:478384 [0] NCCL INFO Channel 01 : 244[31000] -> 247[e3000] via P2P/IPC/read
484: hkn0808:963191:963307 [0] NCCL INFO Channel 00 : 484[31000] -> 487[e3000] via P2P/IPC/read
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 00 : 428[31000] -> 431[e3000] via P2P/IPC/read
111: hkn0504:33333:33445 [3] NCCL INFO Channel 00 : 111[e3000] -> 110[ca000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [receive] via NET/IBext/0
217: hkn0601:110184:110286 [1] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [send] via NET/IBext/0
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 00 : 188[31000] -> 191[e3000] via P2P/IPC/read
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 01 : 8[31000] -> 11[e3000] via P2P/IPC/read
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 00 : 296[31000] -> 299[e3000] via P2P/IPC/read
260: hkn0613:895195:895293 [0] NCCL INFO Channel 01 : 260[31000] -> 263[e3000] via P2P/IPC/read
240: hkn0607:896885:896985 [0] NCCL INFO Channel 01 : 240[31000] -> 243[e3000] via P2P/IPC/read
372: hkn0713:462723:462881 [0] NCCL INFO Channel 00 : 372[31000] -> 375[e3000] via P2P/IPC/read
232: hkn0605:704594:704721 [0] NCCL INFO Channel 01 : 232[31000] -> 235[e3000] via P2P/IPC/read
389: hkn0717:4180100:4180219 [1] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [send] via NET/IBext/0
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 01 : 472[31000] -> 475[e3000] via P2P/IPC/read
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 00 : 128[31000] -> 131[e3000] via P2P/IPC/read
 71: hkn0422:4145519:4145652 [3] NCCL INFO Channel 00 : 71[e3000] -> 70[ca000] via P2P/IPC/read
216: hkn0601:110172:110280 [0] NCCL INFO Channel 01 : 213[4b000] -> 216[31000] [receive] via NET/IBext/0
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 00 : 316[31000] -> 319[e3000] via P2P/IPC/read
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [receive] via NET/IBext/0
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 01 : 233[4b000] -> 236[31000] [receive] via NET/IBext/0
300: hkn0628:664377:664476 [0] NCCL INFO Channel 01 : 300[31000] -> 303[e3000] via P2P/IPC/read
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 01 : 328[31000] -> 331[e3000] via P2P/IPC/read
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 01 : 272[31000] -> 275[e3000] via P2P/IPC/read
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [receive] via NET/IBext/0
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [receive] via NET/IBext/0
504: hkn0815:387632:387784 [0] NCCL INFO Channel 01 : 504[31000] -> 507[e3000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 01 : 460[31000] -> 463[e3000] via P2P/IPC/read
508: hkn0816:368125:368237 [0] NCCL INFO Channel 00 : 508[31000] -> 511[e3000] via P2P/IPC/read
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 00 : 288[31000] -> 291[e3000] via P2P/IPC/read
256: hkn0612:909459:909583 [0] NCCL INFO Channel 01 : 256[31000] -> 259[e3000] via P2P/IPC/read
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 01 : 237[4b000] -> 240[31000] [send] via NET/IBext/0
357: hkn0708:405731:405869 [1] NCCL INFO Channel 01 : 357[4b000] -> 360[31000] [send] via NET/IBext/0
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 00 : 388[31000] -> 391[e3000] via P2P/IPC/read
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 00 : 224[31000] -> 227[e3000] via P2P/IPC/read
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 01 : 212[31000] -> 215[e3000] via P2P/IPC/read
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 01 : 417[4b000] -> 420[31000] [send] via NET/IBext/0
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 01 : 420[31000] -> 423[e3000] via P2P/IPC/read
500: hkn0814:668339:668453 [0] NCCL INFO Channel 01 : 500[31000] -> 503[e3000] via P2P/IPC/read
408: hkn0723:200389:200535 [0] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [receive] via NET/IBext/0
385: hkn0716:101000:101120 [1] NCCL INFO Channel 01 : 385[4b000] -> 388[31000] [send] via NET/IBext/0
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 01 : 424[31000] -> 427[e3000] via P2P/IPC/read
204: hkn0532:916658:916970 [0] NCCL INFO Channel 01 : 204[31000] -> 207[e3000] via P2P/IPC/read
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 01 : 221[4b000] -> 224[31000] [send] via NET/IBext/0
364: hkn0711:576387:576519 [0] NCCL INFO Channel 01 : 361[4b000] -> 364[31000] [receive] via NET/IBext/0
309: hkn0630:1590958:1591101 [1] NCCL INFO Channel 01 : 309[4b000] -> 312[31000] [send] via NET/IBext/0
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 01 : 164[31000] -> 167[e3000] via P2P/IPC/read
356: hkn0708:405715:405864 [0] NCCL INFO Channel 01 : 353[4b000] -> 356[31000] [receive] via NET/IBext/0
228: hkn0604:681736:681856 [0] NCCL INFO Channel 01 : 228[31000] -> 231[e3000] via P2P/IPC/read
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 00 : 352[31000] -> 355[e3000] via P2P/IPC/read
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [send] via NET/IBext/0
409: hkn0723:200369:200533 [1] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [send] via NET/IBext/0
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [receive] via NET/IBext/0
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 01 : 476[31000] -> 479[e3000] via P2P/IPC/read
147: hkn0513:3005453:3005555 [3] NCCL INFO Channel 00 : 147[e3000] -> 146[ca000] via P2P/IPC/read
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 00 : 196[31000] -> 199[e3000] via P2P/IPC/read
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 01 : 217[4b000] -> 220[31000] [receive] via NET/IBext/0
368: hkn0712:287551:287669 [0] NCCL INFO Channel 00 : 368[31000] -> 371[e3000] via P2P/IPC/read
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [receive] via NET/IBext/0
384: hkn0716:101008:101117 [0] NCCL INFO Channel 01 : 381[4b000] -> 384[31000] [receive] via NET/IBext/0
111: hkn0504:33333:33445 [3] NCCL INFO Channel 01 : 111[e3000] -> 110[ca000] via P2P/IPC/read
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 01 : 401[4b000] -> 404[31000] [send] via NET/IBext/0
143: hkn0512:3036675:3036769 [3] NCCL INFO Channel 00 : 143[e3000] -> 142[ca000] via P2P/IPC/read
 67: hkn0421:2172249:2172523 [3] NCCL INFO Channel 00 : 67[e3000] -> 66[ca000] via P2P/IPC/read
365: hkn0711:576415:576512 [1] NCCL INFO Channel 01 : 365[4b000] -> 368[31000] [send] via NET/IBext/0
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 01 : 333[4b000] -> 336[31000] [send] via NET/IBext/0
380: hkn0715:394410:394546 [0] NCCL INFO Channel 00 : 380[31000] -> 383[e3000] via P2P/IPC/read
484: hkn0808:963191:963307 [0] NCCL INFO Channel 01 : 484[31000] -> 487[e3000] via P2P/IPC/read
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 01 : 428[31000] -> 431[e3000] via P2P/IPC/read
 39: hkn0413:2359214:2359301 [3] NCCL INFO Channel 01 : 39[e3000] -> 38[ca000] via P2P/IPC/read
 71: hkn0422:4145519:4145652 [3] NCCL INFO Channel 01 : 71[e3000] -> 70[ca000] via P2P/IPC/read
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 01 : 316[31000] -> 319[e3000] via P2P/IPC/read
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 01 : 188[31000] -> 191[e3000] via P2P/IPC/read
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 01 : 329[4b000] -> 332[31000] [receive] via NET/IBext/0
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 01 : 296[31000] -> 299[e3000] via P2P/IPC/read
372: hkn0713:462723:462881 [0] NCCL INFO Channel 01 : 372[31000] -> 375[e3000] via P2P/IPC/read
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 01 : 305[4b000] -> 308[31000] [send] via NET/IBext/0
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 01 : 389[4b000] -> 392[31000] [receive] via NET/IBext/0
 83: hkn0425:2076482:2076596 [3] NCCL INFO Channel 00 : 83[e3000] -> 82[ca000] via P2P/IPC/read
 15: hkn0407:1808771:1808909 [3] NCCL INFO Channel 00 : 15[e3000] -> 14[ca000] via P2P/IPC/read
508: hkn0816:368125:368237 [0] NCCL INFO Channel 01 : 508[31000] -> 511[e3000] via P2P/IPC/read
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 01 : 128[31000] -> 131[e3000] via P2P/IPC/read
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 01 : 141[4b000] -> 144[31000] [send] via NET/IBext/0
155: hkn0515:2889309:2889405 [3] NCCL INFO Channel 00 : 155[e3000] -> 154[ca000] via P2P/IPC/read
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 01 : 288[31000] -> 291[e3000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 00 : 336[31000] -> 339[e3000] via P2P/IPC/read
360: hkn0710:348013:348131 [0] NCCL INFO Channel 00 : 360[31000] -> 363[e3000] via P2P/IPC/read
325: hkn0634:1513380:1513484 [1] NCCL INFO Channel 01 : 325[4b000] -> 328[31000] [send] via NET/IBext/0
163: hkn0520:2705377:2705478 [3] NCCL INFO Channel 00 : 163[e3000] -> 162[ca000] via P2P/IPC/read
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 01 : 301[4b000] -> 304[31000] [receive] via NET/IBext/0
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 01 : 388[31000] -> 391[e3000] via P2P/IPC/read
341: hkn0704:784510:784629 [1] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [send] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 01 : 224[31000] -> 227[e3000] via P2P/IPC/read
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 01 : 393[4b000] -> 396[31000] [send] via NET/IBext/0
345: hkn0705:775705:775864 [1] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [send] via NET/IBext/0
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 01 : 409[4b000] -> 412[31000] [receive] via NET/IBext/0
408: hkn0723:200389:200535 [0] NCCL INFO Channel 00 : 408[31000] -> 411[e3000] via P2P/IPC/read
 63: hkn0420:3202717:3202827 [3] NCCL INFO Channel 00 : 63[e3000] -> 62[ca000] via P2P/IPC/read
151: hkn0514:2943246:2943339 [3] NCCL INFO Channel 00 : 151[e3000] -> 150[ca000] via P2P/IPC/read
147: hkn0513:3005453:3005555 [3] NCCL INFO Channel 01 : 147[e3000] -> 146[ca000] via P2P/IPC/read
216: hkn0601:110172:110280 [0] NCCL INFO Channel 00 : 216[31000] -> 219[e3000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 01 : 321[4b000] -> 324[31000] [receive] via NET/IBext/0
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 00 : 220[31000] -> 223[e3000] via P2P/IPC/read
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 00 : 292[31000] -> 295[e3000] via P2P/IPC/read
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 00 : 236[31000] -> 239[e3000] via P2P/IPC/read
368: hkn0712:287551:287669 [0] NCCL INFO Channel 01 : 368[31000] -> 371[e3000] via P2P/IPC/read
356: hkn0708:405715:405864 [0] NCCL INFO Channel 00 : 356[31000] -> 359[e3000] via P2P/IPC/read
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 01 : 352[31000] -> 355[e3000] via P2P/IPC/read
340: hkn0704:784518:784625 [0] NCCL INFO Channel 01 : 337[4b000] -> 340[31000] [receive] via NET/IBext/0
344: hkn0705:775713:775862 [0] NCCL INFO Channel 01 : 341[4b000] -> 344[31000] [receive] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 00 : 416[31000] -> 419[e3000] via P2P/IPC/read
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 00 : 396[31000] -> 399[e3000] via P2P/IPC/read
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 01 : 413[4b000] -> 416[31000] [send] via NET/IBext/0
489: hkn0809:929888:930005 [1] NCCL INFO Channel 01 : 489[4b000] -> 492[31000] [send] via NET/IBext/0
384: hkn0716:101008:101117 [0] NCCL INFO Channel 00 : 384[31000] -> 387[e3000] via P2P/IPC/read
 87: hkn0426:806598:806692 [3] NCCL INFO Channel 00 : 87[e3000] -> 86[ca000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 01 : 397[4b000] -> 400[31000] [receive] via NET/IBext/0
443: hkn0732:1204148:1204274 [3] NCCL INFO Channel 00 : 443[e3000] -> 442[ca000] via P2P/IPC/read
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 00 : 404[31000] -> 407[e3000] via P2P/IPC/read
143: hkn0512:3036675:3036769 [3] NCCL INFO Channel 01 : 143[e3000] -> 142[ca000] via P2P/IPC/read
360: hkn0710:348013:348131 [0] NCCL INFO Channel 01 : 360[31000] -> 363[e3000] via P2P/IPC/read
163: hkn0520:2705377:2705478 [3] NCCL INFO Channel 01 : 163[e3000] -> 162[ca000] via P2P/IPC/read
 67: hkn0421:2172249:2172523 [3] NCCL INFO Channel 01 : 67[e3000] -> 66[ca000] via P2P/IPC/read
364: hkn0711:576387:576519 [0] NCCL INFO Channel 00 : 364[31000] -> 367[e3000] via P2P/IPC/read
107: hkn0503:2892154:2892277 [3] NCCL INFO Channel 00 : 107[e3000] -> 106[ca000] via P2P/IPC/read
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 00 : 332[31000] -> 335[e3000] via P2P/IPC/read
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 00 : 308[31000] -> 311[e3000] via P2P/IPC/read
380: hkn0715:394410:394546 [0] NCCL INFO Channel 01 : 380[31000] -> 383[e3000] via P2P/IPC/read
 83: hkn0425:2076482:2076596 [3] NCCL INFO Channel 01 : 83[e3000] -> 82[ca000] via P2P/IPC/read
488: hkn0809:929896:930007 [0] NCCL INFO Channel 01 : 485[4b000] -> 488[31000] [receive] via NET/IBext/0
 15: hkn0407:1808771:1808909 [3] NCCL INFO Channel 01 : 15[e3000] -> 14[ca000] via P2P/IPC/read
 63: hkn0420:3202717:3202827 [3] NCCL INFO Channel 01 : 63[e3000] -> 62[ca000] via P2P/IPC/read
195: hkn0529:1533364:1533476 [3] NCCL INFO Channel 00 : 195[e3000] -> 194[ca000] via P2P/IPC/read
151: hkn0514:2943246:2943339 [3] NCCL INFO Channel 01 : 151[e3000] -> 150[ca000] via P2P/IPC/read
155: hkn0515:2889309:2889405 [3] NCCL INFO Channel 01 : 155[e3000] -> 154[ca000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 01 : 336[31000] -> 339[e3000] via P2P/IPC/read
216: hkn0601:110172:110280 [0] NCCL INFO Channel 01 : 216[31000] -> 219[e3000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 00 : 324[31000] -> 327[e3000] via P2P/IPC/read
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 01 : 196[31000] -> 199[e3000] via P2P/IPC/read
127: hkn0508:3131628:3131736 [3] NCCL INFO Channel 00 : 127[e3000] -> 126[ca000] via P2P/IPC/read
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 01 : 292[31000] -> 295[e3000] via P2P/IPC/read
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 01 : 236[31000] -> 239[e3000] via P2P/IPC/read
356: hkn0708:405715:405864 [0] NCCL INFO Channel 01 : 356[31000] -> 359[e3000] via P2P/IPC/read
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 00 : 304[31000] -> 307[e3000] via P2P/IPC/read
340: hkn0704:784518:784625 [0] NCCL INFO Channel 00 : 340[31000] -> 343[e3000] via P2P/IPC/read
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 00 : 392[31000] -> 395[e3000] via P2P/IPC/read
464: hkn0803:869028:869155 [0] NCCL INFO Channel 01 : 461[4b000] -> 464[31000] [receive] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 01 : 416[31000] -> 419[e3000] via P2P/IPC/read
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 01 : 396[31000] -> 399[e3000] via P2P/IPC/read
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 00 : 412[31000] -> 415[e3000] via P2P/IPC/read
496: hkn0812:686285:686394 [0] NCCL INFO Channel 01 : 493[4b000] -> 496[31000] [receive] via NET/IBext/0
408: hkn0723:200389:200535 [0] NCCL INFO Channel 01 : 408[31000] -> 411[e3000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 01 : 453[4b000] -> 456[31000] [receive] via NET/IBext/0
384: hkn0716:101008:101117 [0] NCCL INFO Channel 01 : 384[31000] -> 387[e3000] via P2P/IPC/read
111: hkn0504:33333:33445 [3] NCCL INFO Connected all rings
 27: hkn0410:1152209:1152320 [3] NCCL INFO Channel 00 : 27[e3000] -> 26[ca000] via P2P/IPC/read
 87: hkn0426:806598:806692 [3] NCCL INFO Channel 01 : 87[e3000] -> 86[ca000] via P2P/IPC/read
183: hkn0526:1420898:1421019 [3] NCCL INFO Channel 00 : 183[e3000] -> 182[ca000] via P2P/IPC/read
 55: hkn0418:1861683:1861785 [3] NCCL INFO Channel 00 : 55[e3000] -> 54[ca000] via P2P/IPC/read
455: hkn0736:1500858:1500966 [3] NCCL INFO Channel 00 : 455[e3000] -> 454[ca000] via P2P/IPC/read
 47: hkn0415:2488934:2489087 [3] NCCL INFO Channel 00 : 47[e3000] -> 46[ca000] via P2P/IPC/read
 23: hkn0409:2578181:2578301 [3] NCCL INFO Channel 00 : 23[e3000] -> 22[ca000] via P2P/IPC/read
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 01 : 404[31000] -> 407[e3000] via P2P/IPC/read
 59: hkn0419:1536808:1536921 [3] NCCL INFO Channel 00 : 59[e3000] -> 58[ca000] via P2P/IPC/read
119: hkn0506:830554:830666 [3] NCCL INFO Channel 00 : 119[e3000] -> 118[ca000] via P2P/IPC/read
203: hkn0531:1223106:1223204 [3] NCCL INFO Channel 00 : 203[e3000] -> 202[ca000] via P2P/IPC/read
135: hkn0510:2754567:2754688 [3] NCCL INFO Channel 00 : 135[e3000] -> 134[ca000] via P2P/IPC/read
 51: hkn0417:2260175:2260285 [3] NCCL INFO Channel 00 : 51[e3000] -> 50[ca000] via P2P/IPC/read
175: hkn0524:1126280:1126395 [3] NCCL INFO Channel 00 : 175[e3000] -> 174[ca000] via P2P/IPC/read
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 01 : 220[31000] -> 223[e3000] via P2P/IPC/read
364: hkn0711:576387:576519 [0] NCCL INFO Channel 01 : 364[31000] -> 367[e3000] via P2P/IPC/read
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 01 : 105[4b000] -> 108[31000] [send] via NET/IBext/0
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 01 : 308[31000] -> 311[e3000] via P2P/IPC/read
344: hkn0705:775713:775862 [0] NCCL INFO Channel 00 : 344[31000] -> 347[e3000] via P2P/IPC/read
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 01 : 509[4b000] -> 0[31000] [receive] via NET/IBext/0
 39: hkn0413:2359214:2359301 [3] NCCL INFO Connected all rings
159: hkn0516:2908480:2908594 [3] NCCL INFO Channel 00 : 159[e3000] -> 158[ca000] via P2P/IPC/read
 79: hkn0424:2940441:2940558 [3] NCCL INFO Channel 00 : 79[e3000] -> 78[ca000] via P2P/IPC/read
103: hkn0502:221563:221675 [3] NCCL INFO Channel 00 : 103[e3000] -> 102[ca000] via P2P/IPC/read
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 01 : 1[4b000] -> 4[31000] [receive] via NET/IBext/0
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 00 : 400[31000] -> 403[e3000] via P2P/IPC/read
443: hkn0732:1204148:1204274 [3] NCCL INFO Channel 01 : 443[e3000] -> 442[ca000] via P2P/IPC/read
 95: hkn0428:659881:659973 [3] NCCL INFO Channel 00 : 95[e3000] -> 94[ca000] via P2P/IPC/read
 71: hkn0422:4145519:4145652 [3] NCCL INFO Connected all rings
127: hkn0508:3131628:3131736 [3] NCCL INFO Channel 01 : 127[e3000] -> 126[ca000] via P2P/IPC/read
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 01 : 392[31000] -> 395[e3000] via P2P/IPC/read
447: hkn0733:1381891:1382017 [3] NCCL INFO Channel 00 : 447[e3000] -> 446[ca000] via P2P/IPC/read
488: hkn0809:929896:930007 [0] NCCL INFO Channel 00 : 488[31000] -> 491[e3000] via P2P/IPC/read
195: hkn0529:1533364:1533476 [3] NCCL INFO Channel 01 : 195[e3000] -> 194[ca000] via P2P/IPC/read
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 01 : 441[4b000] -> 444[31000] [send] via NET/IBext/0
483: hkn0807:1011596:1011696 [3] NCCL INFO Channel 00 : 483[e3000] -> 482[ca000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 01 : 324[31000] -> 327[e3000] via P2P/IPC/read
175: hkn0524:1126280:1126395 [3] NCCL INFO Channel 01 : 175[e3000] -> 174[ca000] via P2P/IPC/read
139: hkn0511:3058858:3058978 [3] NCCL INFO Channel 00 : 139[e3000] -> 138[ca000] via P2P/IPC/read
107: hkn0503:2892154:2892277 [3] NCCL INFO Channel 01 : 107[e3000] -> 106[ca000] via P2P/IPC/read
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 01 : 304[31000] -> 307[e3000] via P2P/IPC/read
340: hkn0704:784518:784625 [0] NCCL INFO Channel 01 : 340[31000] -> 343[e3000] via P2P/IPC/read
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 01 : 412[31000] -> 415[e3000] via P2P/IPC/read
 91: hkn0427:1127642:1127790 [3] NCCL INFO Channel 00 : 91[e3000] -> 90[ca000] via P2P/IPC/read
439: hkn0731:1379236:1379354 [3] NCCL INFO Channel 00 : 439[e3000] -> 438[ca000] via P2P/IPC/read
119: hkn0506:830554:830666 [3] NCCL INFO Channel 01 : 119[e3000] -> 118[ca000] via P2P/IPC/read
123: hkn0507:3179565:3179693 [3] NCCL INFO Channel 00 : 123[e3000] -> 122[ca000] via P2P/IPC/read
344: hkn0705:775713:775862 [0] NCCL INFO Channel 01 : 344[31000] -> 347[e3000] via P2P/IPC/read
507: hkn0815:387648:387785 [3] NCCL INFO Channel 00 : 507[e3000] -> 506[ca000] via P2P/IPC/read
 27: hkn0410:1152209:1152320 [3] NCCL INFO Channel 01 : 27[e3000] -> 26[ca000] via P2P/IPC/read
183: hkn0526:1420898:1421019 [3] NCCL INFO Channel 01 : 183[e3000] -> 182[ca000] via P2P/IPC/read
455: hkn0736:1500858:1500966 [3] NCCL INFO Channel 01 : 455[e3000] -> 454[ca000] via P2P/IPC/read
 47: hkn0415:2488934:2489087 [3] NCCL INFO Channel 01 : 47[e3000] -> 46[ca000] via P2P/IPC/read
 23: hkn0409:2578181:2578301 [3] NCCL INFO Channel 01 : 23[e3000] -> 22[ca000] via P2P/IPC/read
 59: hkn0419:1536808:1536921 [3] NCCL INFO Channel 01 : 59[e3000] -> 58[ca000] via P2P/IPC/read
203: hkn0531:1223106:1223204 [3] NCCL INFO Channel 01 : 203[e3000] -> 202[ca000] via P2P/IPC/read
135: hkn0510:2754567:2754688 [3] NCCL INFO Channel 01 : 135[e3000] -> 134[ca000] via P2P/IPC/read
 51: hkn0417:2260175:2260285 [3] NCCL INFO Channel 01 : 51[e3000] -> 50[ca000] via P2P/IPC/read
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 01 : 33[4b000] -> 36[31000] [send] via NET/IBext/0
495: hkn0810:932034:932161 [3] NCCL INFO Channel 00 : 495[e3000] -> 494[ca000] via P2P/IPC/read
496: hkn0812:686285:686394 [0] NCCL INFO Channel 00 : 496[31000] -> 499[e3000] via P2P/IPC/read
 79: hkn0424:2940441:2940558 [3] NCCL INFO Channel 01 : 79[e3000] -> 78[ca000] via P2P/IPC/read
 95: hkn0428:659881:659973 [3] NCCL INFO Channel 01 : 95[e3000] -> 94[ca000] via P2P/IPC/read
143: hkn0512:3036675:3036769 [3] NCCL INFO Connected all rings
179: hkn0525:979318:979438 [3] NCCL INFO Channel 00 : 179[e3000] -> 178[ca000] via P2P/IPC/read
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 01 : 332[31000] -> 335[e3000] via P2P/IPC/read
 83: hkn0425:2076482:2076596 [3] NCCL INFO Connected all rings
488: hkn0809:929896:930007 [0] NCCL INFO Channel 01 : 488[31000] -> 491[e3000] via P2P/IPC/read
 55: hkn0418:1861683:1861785 [3] NCCL INFO Channel 01 : 55[e3000] -> 54[ca000] via P2P/IPC/read
115: hkn0505:2296296:2296404 [3] NCCL INFO Channel 00 : 115[e3000] -> 114[ca000] via P2P/IPC/read
 67: hkn0421:2172249:2172523 [3] NCCL INFO Connected all rings
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 01 : 29[4b000] -> 32[31000] [receive] via NET/IBext/0
464: hkn0803:869028:869155 [0] NCCL INFO Channel 00 : 464[31000] -> 467[e3000] via P2P/IPC/read
103: hkn0502:221563:221675 [3] NCCL INFO Channel 01 : 103[e3000] -> 102[ca000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 01 : 400[31000] -> 403[e3000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Channel 01 : 249[4b000] -> 252[31000] [receive] via NET/IBext/0
163: hkn0520:2705377:2705478 [3] NCCL INFO Connected all rings
139: hkn0511:3058858:3058978 [3] NCCL INFO Channel 01 : 139[e3000] -> 138[ca000] via P2P/IPC/read
 75: hkn0423:1697362:1697475 [3] NCCL INFO Channel 00 : 75[e3000] -> 74[ca000] via P2P/IPC/read
 15: hkn0407:1808771:1808909 [3] NCCL INFO Connected all rings
 63: hkn0420:3202717:3202827 [3] NCCL INFO Connected all rings
159: hkn0516:2908480:2908594 [3] NCCL INFO Channel 01 : 159[e3000] -> 158[ca000] via P2P/IPC/read
 31: hkn0411:2308387:2308486 [3] NCCL INFO Channel 00 : 31[e3000] -> 30[ca000] via P2P/IPC/read
155: hkn0515:2889309:2889405 [3] NCCL INFO Connected all rings
279: hkn0621:1984024:1984141 [3] NCCL INFO Channel 00 : 279[e3000] -> 278[ca000] via P2P/IPC/read
211: hkn0534:1140916:1141035 [3] NCCL INFO Channel 00 : 211[e3000] -> 210[ca000] via P2P/IPC/read
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 00 : 0[31000] -> 3[e3000] via P2P/IPC/read
471: hkn0804:1198115:1198243 [3] NCCL INFO Channel 00 : 471[e3000] -> 470[ca000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 00 : 456[31000] -> 459[e3000] via P2P/IPC/read
 91: hkn0427:1127642:1127790 [3] NCCL INFO Channel 01 : 91[e3000] -> 90[ca000] via P2P/IPC/read
439: hkn0731:1379236:1379354 [3] NCCL INFO Channel 01 : 439[e3000] -> 438[ca000] via P2P/IPC/read
483: hkn0807:1011596:1011696 [3] NCCL INFO Channel 01 : 483[e3000] -> 482[ca000] via P2P/IPC/read
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 01 : 281[4b000] -> 284[31000] [receive] via NET/IBext/0
151: hkn0514:2943246:2943339 [3] NCCL INFO Connected all rings
 43: hkn0414:1974063:1974188 [3] NCCL INFO Channel 00 : 43[e3000] -> 42[ca000] via P2P/IPC/read
123: hkn0507:3179565:3179693 [3] NCCL INFO Channel 01 : 123[e3000] -> 122[ca000] via P2P/IPC/read
507: hkn0815:387648:387785 [3] NCCL INFO Channel 01 : 507[e3000] -> 506[ca000] via P2P/IPC/read
 87: hkn0426:806598:806692 [3] NCCL INFO Connected all rings
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 00 : 4[31000] -> 7[e3000] via P2P/IPC/read
264: hkn0615:406779:406906 [0] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [receive] via NET/IBext/0
251: hkn0609:703341:703443 [3] NCCL INFO Channel 00 : 251[e3000] -> 250[ca000] via P2P/IPC/read
179: hkn0525:979318:979438 [3] NCCL INFO Channel 01 : 179[e3000] -> 178[ca000] via P2P/IPC/read
451: hkn0734:1149077:1149192 [3] NCCL INFO Channel 00 : 451[e3000] -> 450[ca000] via P2P/IPC/read
496: hkn0812:686285:686394 [0] NCCL INFO Channel 01 : 496[31000] -> 499[e3000] via P2P/IPC/read
435: hkn0730:1394249:1394347 [3] NCCL INFO Channel 00 : 435[e3000] -> 434[ca000] via P2P/IPC/read
171: hkn0523:1540540:1540658 [3] NCCL INFO Channel 00 : 171[e3000] -> 170[ca000] via P2P/IPC/read
271: hkn0616:397365:397472 [3] NCCL INFO Channel 00 : 271[e3000] -> 270[ca000] via P2P/IPC/read
283: hkn0622:2012962:2013089 [3] NCCL INFO Channel 00 : 283[e3000] -> 282[ca000] via P2P/IPC/read
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 01 : 9[4b000] -> 12[31000] [send] via NET/IBext/0
261: hkn0613:895175:895292 [1] NCCL INFO Channel 01 : 261[4b000] -> 264[31000] [send] via NET/IBext/0
376: hkn0714:424562:424665 [0] NCCL INFO Channel 01 : 373[4b000] -> 376[31000] [receive] via NET/IBext/0
247: hkn0608:478286:478382 [3] NCCL INFO Channel 00 : 247[e3000] -> 246[ca000] via P2P/IPC/read
 99: hkn0501:1320348:1320478 [3] NCCL INFO Channel 00 : 99[e3000] -> 98[ca000] via P2P/IPC/read
187: hkn0527:1341441:1341554 [3] NCCL INFO Channel 00 : 187[e3000] -> 186[ca000] via P2P/IPC/read
443: hkn0732:1204148:1204274 [3] NCCL INFO Connected all rings
115: hkn0505:2296296:2296404 [3] NCCL INFO Channel 01 : 115[e3000] -> 114[ca000] via P2P/IPC/read
323: hkn0633:1518851:1518965 [3] NCCL INFO Channel 00 : 323[e3000] -> 322[ca000] via P2P/IPC/read
 75: hkn0423:1697362:1697475 [3] NCCL INFO Channel 01 : 75[e3000] -> 74[ca000] via P2P/IPC/read
235: hkn0605:704602:704724 [3] NCCL INFO Channel 00 : 235[e3000] -> 234[ca000] via P2P/IPC/read
 19: hkn0408:2883195:2883322 [3] NCCL INFO Channel 00 : 19[e3000] -> 18[ca000] via P2P/IPC/read
279: hkn0621:1984024:1984141 [3] NCCL INFO Channel 01 : 279[e3000] -> 278[ca000] via P2P/IPC/read
211: hkn0534:1140916:1141035 [3] NCCL INFO Channel 01 : 211[e3000] -> 210[ca000] via P2P/IPC/read
107: hkn0503:2892154:2892277 [3] NCCL INFO Connected all rings
315: hkn0631:1014310:1014411 [3] NCCL INFO Channel 00 : 315[e3000] -> 314[ca000] via P2P/IPC/read
464: hkn0803:869028:869155 [0] NCCL INFO Channel 01 : 464[31000] -> 467[e3000] via P2P/IPC/read
495: hkn0810:932034:932161 [3] NCCL INFO Channel 01 : 495[e3000] -> 494[ca000] via P2P/IPC/read
475: hkn0805:1104618:1104726 [3] NCCL INFO Channel 00 : 475[e3000] -> 474[ca000] via P2P/IPC/read
501: hkn0814:668331:668452 [1] NCCL INFO Channel 01 : 501[4b000] -> 504[31000] [send] via NET/IBext/0
471: hkn0804:1198115:1198243 [3] NCCL INFO Channel 01 : 471[e3000] -> 470[ca000] via P2P/IPC/read
463: hkn0802:1192840:1192948 [3] NCCL INFO Channel 00 : 463[e3000] -> 462[ca000] via P2P/IPC/read
 31: hkn0411:2308387:2308486 [3] NCCL INFO Channel 01 : 31[e3000] -> 30[ca000] via P2P/IPC/read
127: hkn0508:3131628:3131736 [3] NCCL INFO Connected all rings
303: hkn0628:664365:664474 [3] NCCL INFO Channel 00 : 303[e3000] -> 302[ca000] via P2P/IPC/read
331: hkn0635:1218123:1218208 [3] NCCL INFO Channel 00 : 331[e3000] -> 330[ca000] via P2P/IPC/read
423: hkn0726:1540634:1540730 [3] NCCL INFO Channel 00 : 423[e3000] -> 422[ca000] via P2P/IPC/read
 43: hkn0414:1974063:1974188 [3] NCCL INFO Channel 01 : 43[e3000] -> 42[ca000] via P2P/IPC/read
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 01 : 289[4b000] -> 292[31000] [send] via NET/IBext/0
147: hkn0513:3005453:3005555 [3] NCCL INFO Connected all rings
295: hkn0626:1290931:1291060 [3] NCCL INFO Channel 00 : 295[e3000] -> 294[ca000] via P2P/IPC/read
259: hkn0612:909467:909577 [3] NCCL INFO Channel 00 : 259[e3000] -> 258[ca000] via P2P/IPC/read
243: hkn0607:896857:896978 [3] NCCL INFO Channel 00 : 243[e3000] -> 242[ca000] via P2P/IPC/read
275: hkn0617:2287181:2287280 [3] NCCL INFO Channel 00 : 275[e3000] -> 274[ca000] via P2P/IPC/read
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 00 : 32[31000] -> 35[e3000] via P2P/IPC/read
447: hkn0733:1381891:1382017 [3] NCCL INFO Channel 01 : 447[e3000] -> 446[ca000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 01 : 456[31000] -> 459[e3000] via P2P/IPC/read
195: hkn0529:1533364:1533476 [3] NCCL INFO Connected all rings
207: hkn0532:916642:916973 [3] NCCL INFO Channel 00 : 207[e3000] -> 206[ca000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Channel 00 : 252[31000] -> 255[e3000] via P2P/IPC/read
175: hkn0524:1126280:1126395 [3] NCCL INFO Connected all rings
251: hkn0609:703341:703443 [3] NCCL INFO Channel 01 : 251[e3000] -> 250[ca000] via P2P/IPC/read
167: hkn0521:1190314:1190440 [3] NCCL INFO Channel 00 : 167[e3000] -> 166[ca000] via P2P/IPC/read
451: hkn0734:1149077:1149192 [3] NCCL INFO Channel 01 : 451[e3000] -> 450[ca000] via P2P/IPC/read
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 01 : 0[31000] -> 3[e3000] via P2P/IPC/read
435: hkn0730:1394249:1394347 [3] NCCL INFO Channel 01 : 435[e3000] -> 434[ca000] via P2P/IPC/read
 27: hkn0410:1152209:1152320 [3] NCCL INFO Connected all rings
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 01 : 4[31000] -> 7[e3000] via P2P/IPC/read
427: hkn0727:1338271:1338389 [3] NCCL INFO Channel 00 : 427[e3000] -> 426[ca000] via P2P/IPC/read
455: hkn0736:1500858:1500966 [3] NCCL INFO Connected all rings
 23: hkn0409:2578181:2578301 [3] NCCL INFO Connected all rings
119: hkn0506:830554:830666 [3] NCCL INFO Connected all rings
479: hkn0806:1046823:1046948 [3] NCCL INFO Channel 00 : 479[e3000] -> 478[ca000] via P2P/IPC/read
203: hkn0531:1223106:1223204 [3] NCCL INFO Connected all rings
135: hkn0510:2754567:2754688 [3] NCCL INFO Connected all rings
171: hkn0523:1540540:1540658 [3] NCCL INFO Channel 01 : 171[e3000] -> 170[ca000] via P2P/IPC/read
 51: hkn0417:2260175:2260285 [3] NCCL INFO Connected all rings
271: hkn0616:397365:397472 [3] NCCL INFO Channel 01 : 271[e3000] -> 270[ca000] via P2P/IPC/read
283: hkn0622:2012962:2013089 [3] NCCL INFO Channel 01 : 283[e3000] -> 282[ca000] via P2P/IPC/read
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 00 : 284[31000] -> 287[e3000] via P2P/IPC/read
323: hkn0633:1518851:1518965 [3] NCCL INFO Channel 01 : 323[e3000] -> 322[ca000] via P2P/IPC/read
231: hkn0604:681764:681862 [3] NCCL INFO Channel 00 : 231[e3000] -> 230[ca000] via P2P/IPC/read
247: hkn0608:478286:478382 [3] NCCL INFO Channel 01 : 247[e3000] -> 246[ca000] via P2P/IPC/read
215: hkn0535:2391507:2391619 [3] NCCL INFO Channel 00 : 215[e3000] -> 214[ca000] via P2P/IPC/read
 99: hkn0501:1320348:1320478 [3] NCCL INFO Channel 01 : 99[e3000] -> 98[ca000] via P2P/IPC/read
183: hkn0526:1420898:1421019 [3] NCCL INFO Connected all rings
 79: hkn0424:2940441:2940558 [3] NCCL INFO Connected all rings
187: hkn0527:1341441:1341554 [3] NCCL INFO Channel 01 : 187[e3000] -> 186[ca000] via P2P/IPC/read
 19: hkn0408:2883195:2883322 [3] NCCL INFO Channel 01 : 19[e3000] -> 18[ca000] via P2P/IPC/read
 47: hkn0415:2488934:2489087 [3] NCCL INFO Connected all rings
 59: hkn0419:1536808:1536921 [3] NCCL INFO Connected all rings
319: hkn0632:1751115:1751226 [3] NCCL INFO Channel 00 : 319[e3000] -> 318[ca000] via P2P/IPC/read
191: hkn0528:1294226:1294323 [3] NCCL INFO Channel 00 : 191[e3000] -> 190[ca000] via P2P/IPC/read
 11: hkn0405:3199299:3199420 [3] NCCL INFO Channel 00 : 11[e3000] -> 10[ca000] via P2P/IPC/read
299: hkn0627:1780422:1780529 [3] NCCL INFO Channel 00 : 299[e3000] -> 298[ca000] via P2P/IPC/read
263: hkn0613:895167:895298 [3] NCCL INFO Channel 00 : 263[e3000] -> 262[ca000] via P2P/IPC/read
315: hkn0631:1014310:1014411 [3] NCCL INFO Channel 01 : 315[e3000] -> 314[ca000] via P2P/IPC/read
235: hkn0605:704602:704724 [3] NCCL INFO Channel 01 : 235[e3000] -> 234[ca000] via P2P/IPC/read
487: hkn0808:963175:963302 [3] NCCL INFO Channel 00 : 487[e3000] -> 486[ca000] via P2P/IPC/read
475: hkn0805:1104618:1104726 [3] NCCL INFO Channel 01 : 475[e3000] -> 474[ca000] via P2P/IPC/read
431: hkn0728:1316457:1316577 [3] NCCL INFO Channel 00 : 431[e3000] -> 430[ca000] via P2P/IPC/read
463: hkn0802:1192840:1192948 [3] NCCL INFO Channel 01 : 463[e3000] -> 462[ca000] via P2P/IPC/read
103: hkn0502:221563:221675 [3] NCCL INFO Connected all rings
131: hkn0509:3116888:3117013 [3] NCCL INFO Channel 00 : 131[e3000] -> 130[ca000] via P2P/IPC/read
 95: hkn0428:659881:659973 [3] NCCL INFO Connected all rings
264: hkn0615:406779:406906 [0] NCCL INFO Channel 00 : 264[31000] -> 267[e3000] via P2P/IPC/read
375: hkn0713:462751:462876 [3] NCCL INFO Channel 00 : 375[e3000] -> 374[ca000] via P2P/IPC/read
303: hkn0628:664365:664474 [3] NCCL INFO Channel 01 : 303[e3000] -> 302[ca000] via P2P/IPC/read
376: hkn0714:424562:424665 [0] NCCL INFO Channel 00 : 376[31000] -> 379[e3000] via P2P/IPC/read
331: hkn0635:1218123:1218208 [3] NCCL INFO Channel 01 : 331[e3000] -> 330[ca000] via P2P/IPC/read
391: hkn0717:4180108:4180218 [3] NCCL INFO Channel 00 : 391[e3000] -> 390[ca000] via P2P/IPC/read
423: hkn0726:1540634:1540730 [3] NCCL INFO Channel 01 : 423[e3000] -> 422[ca000] via P2P/IPC/read
139: hkn0511:3058858:3058978 [3] NCCL INFO Connected all rings
259: hkn0612:909467:909577 [3] NCCL INFO Channel 01 : 259[e3000] -> 258[ca000] via P2P/IPC/read
243: hkn0607:896857:896978 [3] NCCL INFO Channel 01 : 243[e3000] -> 242[ca000] via P2P/IPC/read
227: hkn0603:1405656:1405782 [3] NCCL INFO Channel 00 : 227[e3000] -> 226[ca000] via P2P/IPC/read
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 01 : 32[31000] -> 35[e3000] via P2P/IPC/read
159: hkn0516:2908480:2908594 [3] NCCL INFO Connected all rings
511: hkn0816:368147:368244 [3] NCCL INFO Channel 00 : 511[e3000] -> 510[ca000] via P2P/IPC/read
 91: hkn0427:1127642:1127790 [3] NCCL INFO Connected all rings
207: hkn0532:916642:916973 [3] NCCL INFO Channel 01 : 207[e3000] -> 206[ca000] via P2P/IPC/read
355: hkn0707:4012431:4012540 [3] NCCL INFO Channel 00 : 355[e3000] -> 354[ca000] via P2P/IPC/read
275: hkn0617:2287181:2287280 [3] NCCL INFO Channel 01 : 275[e3000] -> 274[ca000] via P2P/IPC/read
503: hkn0814:668359:668454 [3] NCCL INFO Channel 00 : 503[e3000] -> 502[ca000] via P2P/IPC/read
439: hkn0731:1379236:1379354 [3] NCCL INFO Connected all rings
167: hkn0521:1190314:1190440 [3] NCCL INFO Channel 01 : 167[e3000] -> 166[ca000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO Channel 01 : 345[4b000] -> 348[31000] [receive] via NET/IBext/0
 55: hkn0418:1861683:1861785 [3] NCCL INFO Connected all rings
427: hkn0727:1338271:1338389 [3] NCCL INFO Channel 01 : 427[e3000] -> 426[ca000] via P2P/IPC/read
483: hkn0807:1011596:1011696 [3] NCCL INFO Connected all rings
371: hkn0712:287571:287663 [3] NCCL INFO Channel 00 : 371[e3000] -> 370[ca000] via P2P/IPC/read
231: hkn0604:681764:681862 [3] NCCL INFO Channel 01 : 231[e3000] -> 230[ca000] via P2P/IPC/read
179: hkn0525:979318:979438 [3] NCCL INFO Connected all rings
479: hkn0806:1046823:1046948 [3] NCCL INFO Channel 01 : 479[e3000] -> 478[ca000] via P2P/IPC/read
123: hkn0507:3179565:3179693 [3] NCCL INFO Connected all rings
383: hkn0715:394394:394548 [3] NCCL INFO Channel 00 : 383[e3000] -> 382[ca000] via P2P/IPC/read
215: hkn0535:2391507:2391619 [3] NCCL INFO Channel 01 : 215[e3000] -> 214[ca000] via P2P/IPC/read
487: hkn0808:963175:963302 [3] NCCL INFO Channel 01 : 487[e3000] -> 486[ca000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Channel 01 : 252[31000] -> 255[e3000] via P2P/IPC/read
 11: hkn0405:3199299:3199420 [3] NCCL INFO Channel 01 : 11[e3000] -> 10[ca000] via P2P/IPC/read
263: hkn0613:895167:895298 [3] NCCL INFO Channel 01 : 263[e3000] -> 262[ca000] via P2P/IPC/read
431: hkn0728:1316457:1316577 [3] NCCL INFO Channel 01 : 431[e3000] -> 430[ca000] via P2P/IPC/read
363: hkn0710:348029:348129 [3] NCCL INFO Channel 00 : 363[e3000] -> 362[ca000] via P2P/IPC/read
319: hkn0632:1751115:1751226 [3] NCCL INFO Channel 01 : 319[e3000] -> 318[ca000] via P2P/IPC/read
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 01 : 284[31000] -> 287[e3000] via P2P/IPC/read
191: hkn0528:1294226:1294323 [3] NCCL INFO Channel 01 : 191[e3000] -> 190[ca000] via P2P/IPC/read
299: hkn0627:1780422:1780529 [3] NCCL INFO Channel 01 : 299[e3000] -> 298[ca000] via P2P/IPC/read
375: hkn0713:462751:462876 [3] NCCL INFO Channel 01 : 375[e3000] -> 374[ca000] via P2P/IPC/read
131: hkn0509:3116888:3117013 [3] NCCL INFO Channel 01 : 131[e3000] -> 130[ca000] via P2P/IPC/read
291: hkn0624:1765456:1765549 [3] NCCL INFO Channel 00 : 291[e3000] -> 290[ca000] via P2P/IPC/read
 75: hkn0423:1697362:1697475 [3] NCCL INFO Connected all rings
391: hkn0717:4180108:4180218 [3] NCCL INFO Channel 01 : 391[e3000] -> 390[ca000] via P2P/IPC/read
279: hkn0621:1984024:1984141 [3] NCCL INFO Connected all rings
339: hkn0703:733496:733654 [3] NCCL INFO Channel 00 : 339[e3000] -> 338[ca000] via P2P/IPC/read
115: hkn0505:2296296:2296404 [3] NCCL INFO Connected all rings
227: hkn0603:1405656:1405782 [3] NCCL INFO Channel 01 : 227[e3000] -> 226[ca000] via P2P/IPC/read
507: hkn0815:387648:387785 [3] NCCL INFO Connected all rings
511: hkn0816:368147:368244 [3] NCCL INFO Channel 01 : 511[e3000] -> 510[ca000] via P2P/IPC/read
 31: hkn0411:2308387:2308486 [3] NCCL INFO Connected all rings
264: hkn0615:406779:406906 [0] NCCL INFO Channel 01 : 264[31000] -> 267[e3000] via P2P/IPC/read
211: hkn0534:1140916:1141035 [3] NCCL INFO Connected all rings
199: hkn0530:1250659:1250771 [3] NCCL INFO Channel 00 : 199[e3000] -> 198[ca000] via P2P/IPC/read
503: hkn0814:668359:668454 [3] NCCL INFO Channel 01 : 503[e3000] -> 502[ca000] via P2P/IPC/read
471: hkn0804:1198115:1198243 [3] NCCL INFO Connected all rings
359: hkn0708:405743:405863 [3] NCCL INFO Channel 00 : 359[e3000] -> 358[ca000] via P2P/IPC/read
376: hkn0714:424562:424665 [0] NCCL INFO Channel 01 : 376[31000] -> 379[e3000] via P2P/IPC/read
355: hkn0707:4012431:4012540 [3] NCCL INFO Channel 01 : 355[e3000] -> 354[ca000] via P2P/IPC/read
419: hkn0725:3104454:3104536 [3] NCCL INFO Channel 00 : 419[e3000] -> 418[ca000] via P2P/IPC/read
495: hkn0810:932034:932161 [3] NCCL INFO Connected all rings
 43: hkn0414:1974063:1974188 [3] NCCL INFO Connected all rings
223: hkn0602:3353954:3354221 [3] NCCL INFO Channel 00 : 223[e3000] -> 222[ca000] via P2P/IPC/read
239: hkn0606:2364542:2364663 [3] NCCL INFO Channel 00 : 239[e3000] -> 238[ca000] via P2P/IPC/read
371: hkn0712:287571:287663 [3] NCCL INFO Channel 01 : 371[e3000] -> 370[ca000] via P2P/IPC/read
219: hkn0601:110164:110279 [3] NCCL INFO Channel 00 : 219[e3000] -> 218[ca000] via P2P/IPC/read
399: hkn0719:1298195:1298344 [3] NCCL INFO Channel 00 : 399[e3000] -> 398[ca000] via P2P/IPC/read
383: hkn0715:394394:394548 [3] NCCL INFO Channel 01 : 383[e3000] -> 382[ca000] via P2P/IPC/read
367: hkn0711:576403:576515 [3] NCCL INFO Channel 00 : 367[e3000] -> 366[ca000] via P2P/IPC/read
311: hkn0630:1590970:1591099 [3] NCCL INFO Channel 00 : 311[e3000] -> 310[ca000] via P2P/IPC/read
451: hkn0734:1149077:1149192 [3] NCCL INFO Connected all rings
387: hkn0716:100997:101122 [3] NCCL INFO Channel 00 : 387[e3000] -> 386[ca000] via P2P/IPC/read
171: hkn0523:1540540:1540658 [3] NCCL INFO Connected all rings
251: hkn0609:703341:703443 [3] NCCL INFO Connected all rings
323: hkn0633:1518851:1518965 [3] NCCL INFO Connected all rings
247: hkn0608:478286:478382 [3] NCCL INFO Connected all rings
435: hkn0730:1394249:1394347 [3] NCCL INFO Connected all rings
 99: hkn0501:1320348:1320478 [3] NCCL INFO Connected all rings
363: hkn0710:348029:348129 [3] NCCL INFO Channel 01 : 363[e3000] -> 362[ca000] via P2P/IPC/read
235: hkn0605:704602:704724 [3] NCCL INFO Connected all rings
447: hkn0733:1381891:1382017 [3] NCCL INFO Connected all rings
291: hkn0624:1765456:1765549 [3] NCCL INFO Channel 01 : 291[e3000] -> 290[ca000] via P2P/IPC/read
283: hkn0622:2012962:2013089 [3] NCCL INFO Connected all rings
315: hkn0631:1014310:1014411 [3] NCCL INFO Connected all rings
339: hkn0703:733496:733654 [3] NCCL INFO Channel 01 : 339[e3000] -> 338[ca000] via P2P/IPC/read
475: hkn0805:1104618:1104726 [3] NCCL INFO Connected all rings
411: hkn0723:200377:200540 [3] NCCL INFO Channel 00 : 411[e3000] -> 410[ca000] via P2P/IPC/read
199: hkn0530:1250659:1250771 [3] NCCL INFO Channel 01 : 199[e3000] -> 198[ca000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO Channel 00 : 348[31000] -> 351[e3000] via P2P/IPC/read
 19: hkn0408:2883195:2883322 [3] NCCL INFO Connected all rings
271: hkn0616:397365:397472 [3] NCCL INFO Connected all rings
331: hkn0635:1218123:1218208 [3] NCCL INFO Connected all rings
395: hkn0718:3909510:3909645 [3] NCCL INFO Channel 00 : 395[e3000] -> 394[ca000] via P2P/IPC/read
463: hkn0802:1192840:1192948 [3] NCCL INFO Connected all rings
187: hkn0527:1341441:1341554 [3] NCCL INFO Connected all rings
295: hkn0626:1290931:1291060 [3] NCCL INFO Channel 01 : 295[e3000] -> 294[ca000] via P2P/IPC/read
259: hkn0612:909467:909577 [3] NCCL INFO Connected all rings
239: hkn0606:2364542:2364663 [3] NCCL INFO Channel 01 : 239[e3000] -> 238[ca000] via P2P/IPC/read
359: hkn0708:405743:405863 [3] NCCL INFO Channel 01 : 359[e3000] -> 358[ca000] via P2P/IPC/read
307: hkn0629:1584544:1584671 [3] NCCL INFO Channel 00 : 307[e3000] -> 306[ca000] via P2P/IPC/read
419: hkn0725:3104454:3104536 [3] NCCL INFO Channel 01 : 419[e3000] -> 418[ca000] via P2P/IPC/read
423: hkn0726:1540634:1540730 [3] NCCL INFO Connected all rings
207: hkn0532:916642:916973 [3] NCCL INFO Connected all rings
219: hkn0601:110164:110279 [3] NCCL INFO Channel 01 : 219[e3000] -> 218[ca000] via P2P/IPC/read
327: hkn0634:1513369:1513478 [3] NCCL INFO Channel 00 : 327[e3000] -> 326[ca000] via P2P/IPC/read
223: hkn0602:3353954:3354221 [3] NCCL INFO Channel 01 : 223[e3000] -> 222[ca000] via P2P/IPC/read
243: hkn0607:896857:896978 [3] NCCL INFO Connected all rings
303: hkn0628:664365:664474 [3] NCCL INFO Connected all rings
343: hkn0704:784502:784626 [3] NCCL INFO Channel 00 : 343[e3000] -> 342[ca000] via P2P/IPC/read
275: hkn0617:2287181:2287280 [3] NCCL INFO Connected all rings
347: hkn0705:775733:775855 [3] NCCL INFO Channel 00 : 347[e3000] -> 346[ca000] via P2P/IPC/read
399: hkn0719:1298195:1298344 [3] NCCL INFO Channel 01 : 399[e3000] -> 398[ca000] via P2P/IPC/read
415: hkn0724:1708503:1708602 [3] NCCL INFO Channel 00 : 415[e3000] -> 414[ca000] via P2P/IPC/read
387: hkn0716:100997:101122 [3] NCCL INFO Channel 01 : 387[e3000] -> 386[ca000] via P2P/IPC/read
427: hkn0727:1338271:1338389 [3] NCCL INFO Connected all rings
407: hkn0721:2291511:2291619 [3] NCCL INFO Channel 00 : 407[e3000] -> 406[ca000] via P2P/IPC/read
367: hkn0711:576403:576515 [3] NCCL INFO Channel 01 : 367[e3000] -> 366[ca000] via P2P/IPC/read
311: hkn0630:1590970:1591099 [3] NCCL INFO Channel 01 : 311[e3000] -> 310[ca000] via P2P/IPC/read
167: hkn0521:1190314:1190440 [3] NCCL INFO Connected all rings
231: hkn0604:681764:681862 [3] NCCL INFO Connected all rings
479: hkn0806:1046823:1046948 [3] NCCL INFO Connected all rings
335: hkn0636:1646728:1646847 [3] NCCL INFO Channel 00 : 335[e3000] -> 334[ca000] via P2P/IPC/read
215: hkn0535:2391507:2391619 [3] NCCL INFO Connected all rings
487: hkn0808:963175:963302 [3] NCCL INFO Connected all rings
491: hkn0809:929880:930000 [3] NCCL INFO Channel 00 : 491[e3000] -> 490[ca000] via P2P/IPC/read
431: hkn0728:1316457:1316577 [3] NCCL INFO Connected all rings
411: hkn0723:200377:200540 [3] NCCL INFO Channel 01 : 411[e3000] -> 410[ca000] via P2P/IPC/read
319: hkn0632:1751115:1751226 [3] NCCL INFO Connected all rings
191: hkn0528:1294226:1294323 [3] NCCL INFO Connected all rings
 11: hkn0405:3199299:3199420 [3] NCCL INFO Connected all rings
263: hkn0613:895167:895298 [3] NCCL INFO Connected all rings
375: hkn0713:462751:462876 [3] NCCL INFO Connected all rings
131: hkn0509:3116888:3117013 [3] NCCL INFO Connected all rings
299: hkn0627:1780422:1780529 [3] NCCL INFO Connected all rings
395: hkn0718:3909510:3909645 [3] NCCL INFO Channel 01 : 395[e3000] -> 394[ca000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO Channel 01 : 348[31000] -> 351[e3000] via P2P/IPC/read
307: hkn0629:1584544:1584671 [3] NCCL INFO Channel 01 : 307[e3000] -> 306[ca000] via P2P/IPC/read
415: hkn0724:1708503:1708602 [3] NCCL INFO Channel 01 : 415[e3000] -> 414[ca000] via P2P/IPC/read
403: hkn0720:4190335:4190579 [3] NCCL INFO Channel 00 : 403[e3000] -> 402[ca000] via P2P/IPC/read
391: hkn0717:4180108:4180218 [3] NCCL INFO Connected all rings
227: hkn0603:1405656:1405782 [3] NCCL INFO Connected all rings
347: hkn0705:775733:775855 [3] NCCL INFO Channel 01 : 347[e3000] -> 346[ca000] via P2P/IPC/read
511: hkn0816:368147:368244 [3] NCCL INFO Connected all rings
327: hkn0634:1513369:1513478 [3] NCCL INFO Channel 01 : 327[e3000] -> 326[ca000] via P2P/IPC/read
343: hkn0704:784502:784626 [3] NCCL INFO Channel 01 : 343[e3000] -> 342[ca000] via P2P/IPC/read
503: hkn0814:668359:668454 [3] NCCL INFO Connected all rings
355: hkn0707:4012431:4012540 [3] NCCL INFO Connected all rings
371: hkn0712:287571:287663 [3] NCCL INFO Connected all rings
407: hkn0721:2291511:2291619 [3] NCCL INFO Channel 01 : 407[e3000] -> 406[ca000] via P2P/IPC/read
335: hkn0636:1646728:1646847 [3] NCCL INFO Channel 01 : 335[e3000] -> 334[ca000] via P2P/IPC/read
383: hkn0715:394394:394548 [3] NCCL INFO Connected all rings
491: hkn0809:929880:930000 [3] NCCL INFO Channel 01 : 491[e3000] -> 490[ca000] via P2P/IPC/read
363: hkn0710:348029:348129 [3] NCCL INFO Connected all rings
291: hkn0624:1765456:1765549 [3] NCCL INFO Connected all rings
339: hkn0703:733496:733654 [3] NCCL INFO Connected all rings
199: hkn0530:1250659:1250771 [3] NCCL INFO Connected all rings
403: hkn0720:4190335:4190579 [3] NCCL INFO Channel 01 : 403[e3000] -> 402[ca000] via P2P/IPC/read
405: hkn0721:2291522:2291616 [1] NCCL INFO Channel 01 : 405[4b000] -> 408[31000] [send] via NET/IBext/0
467: hkn0803:869056:869160 [3] NCCL INFO Channel 00 : 467[e3000] -> 466[ca000] via P2P/IPC/read
295: hkn0626:1290931:1291060 [3] NCCL INFO Connected all rings
239: hkn0606:2364542:2364663 [3] NCCL INFO Connected all rings
359: hkn0708:405743:405863 [3] NCCL INFO Connected all rings
419: hkn0725:3104454:3104536 [3] NCCL INFO Connected all rings
499: hkn0812:686277:686393 [3] NCCL INFO Channel 00 : 499[e3000] -> 498[ca000] via P2P/IPC/read
223: hkn0602:3353954:3354221 [3] NCCL INFO Connected all rings
219: hkn0601:110164:110279 [3] NCCL INFO Connected all rings
311: hkn0630:1590970:1591099 [3] NCCL INFO Connected all rings
387: hkn0716:100997:101122 [3] NCCL INFO Connected all rings
367: hkn0711:576403:576515 [3] NCCL INFO Connected all rings
399: hkn0719:1298195:1298344 [3] NCCL INFO Connected all rings
459: hkn0801:2232488:2232616 [3] NCCL INFO Channel 00 : 459[e3000] -> 458[ca000] via P2P/IPC/read
411: hkn0723:200377:200540 [3] NCCL INFO Connected all rings
395: hkn0718:3909510:3909645 [3] NCCL INFO Connected all rings
  3: hkn0403:1751336:1751695 [3] NCCL INFO Channel 00 : 3[e3000] -> 2[ca000] via P2P/IPC/read
467: hkn0803:869056:869160 [3] NCCL INFO Channel 01 : 467[e3000] -> 466[ca000] via P2P/IPC/read
  7: hkn0404:1331852:1331996 [3] NCCL INFO Channel 00 : 7[e3000] -> 6[ca000] via P2P/IPC/read
347: hkn0705:775733:775855 [3] NCCL INFO Connected all rings
415: hkn0724:1708503:1708602 [3] NCCL INFO Connected all rings
499: hkn0812:686277:686393 [3] NCCL INFO Channel 01 : 499[e3000] -> 498[ca000] via P2P/IPC/read
343: hkn0704:784502:784626 [3] NCCL INFO Connected all rings
307: hkn0629:1584544:1584671 [3] NCCL INFO Connected all rings
 35: hkn0412:2254928:2255011 [3] NCCL INFO Channel 00 : 35[e3000] -> 34[ca000] via P2P/IPC/read
327: hkn0634:1513369:1513478 [3] NCCL INFO Connected all rings
459: hkn0801:2232488:2232616 [3] NCCL INFO Channel 01 : 459[e3000] -> 458[ca000] via P2P/IPC/read
407: hkn0721:2291511:2291619 [3] NCCL INFO Connected all rings
335: hkn0636:1646728:1646847 [3] NCCL INFO Connected all rings
491: hkn0809:929880:930000 [3] NCCL INFO Connected all rings
  3: hkn0403:1751336:1751695 [3] NCCL INFO Channel 01 : 3[e3000] -> 2[ca000] via P2P/IPC/read
255: hkn0611:702317:702419 [3] NCCL INFO Channel 00 : 255[e3000] -> 254[ca000] via P2P/IPC/read
  7: hkn0404:1331852:1331996 [3] NCCL INFO Channel 01 : 7[e3000] -> 6[ca000] via P2P/IPC/read
287: hkn0623:1865238:1865357 [3] NCCL INFO Channel 00 : 287[e3000] -> 286[ca000] via P2P/IPC/read
403: hkn0720:4190335:4190579 [3] NCCL INFO Connected all rings
 35: hkn0412:2254928:2255011 [3] NCCL INFO Channel 01 : 35[e3000] -> 34[ca000] via P2P/IPC/read
267: hkn0615:406795:406908 [3] NCCL INFO Channel 00 : 267[e3000] -> 266[ca000] via P2P/IPC/read
379: hkn0714:424543:424659 [3] NCCL INFO Channel 00 : 379[e3000] -> 378[ca000] via P2P/IPC/read
255: hkn0611:702317:702419 [3] NCCL INFO Channel 01 : 255[e3000] -> 254[ca000] via P2P/IPC/read
287: hkn0623:1865238:1865357 [3] NCCL INFO Channel 01 : 287[e3000] -> 286[ca000] via P2P/IPC/read
467: hkn0803:869056:869160 [3] NCCL INFO Connected all rings
267: hkn0615:406795:406908 [3] NCCL INFO Channel 01 : 267[e3000] -> 266[ca000] via P2P/IPC/read
499: hkn0812:686277:686393 [3] NCCL INFO Connected all rings
379: hkn0714:424543:424659 [3] NCCL INFO Channel 01 : 379[e3000] -> 378[ca000] via P2P/IPC/read
459: hkn0801:2232488:2232616 [3] NCCL INFO Connected all rings
  3: hkn0403:1751336:1751695 [3] NCCL INFO Connected all rings
  7: hkn0404:1331852:1331996 [3] NCCL INFO Connected all rings
351: hkn0706:744774:744912 [3] NCCL INFO Channel 00 : 351[e3000] -> 350[ca000] via P2P/IPC/read
 35: hkn0412:2254928:2255011 [3] NCCL INFO Connected all rings
 65: hkn0421:2172257:2172526 [1] NCCL INFO Connected all rings
255: hkn0611:702317:702419 [3] NCCL INFO Connected all rings
287: hkn0623:1865238:1865357 [3] NCCL INFO Connected all rings
 80: hkn0425:2076490:2076594 [0] NCCL INFO Connected all rings
351: hkn0706:744774:744912 [3] NCCL INFO Channel 01 : 351[e3000] -> 350[ca000] via P2P/IPC/read
101: hkn0502:221555:221670 [1] NCCL INFO Connected all rings
148: hkn0514:2943218:2943338 [0] NCCL INFO Connected all rings
379: hkn0714:424543:424659 [3] NCCL INFO Connected all rings
 64: hkn0421:2172277:2172524 [0] NCCL INFO Connected all rings
267: hkn0615:406795:406908 [3] NCCL INFO Connected all rings
 60: hkn0420:3202709:3202825 [0] NCCL INFO Connected all rings
152: hkn0515:2889297:2889406 [0] NCCL INFO Connected all rings
136: hkn0511:3058878:3058984 [0] NCCL INFO Connected all rings
145: hkn0513:3005445:3005561 [1] NCCL INFO Connected all rings
149: hkn0514:2943234:2943343 [1] NCCL INFO Connected all rings
 76: hkn0424:2940461:2940557 [0] NCCL INFO Connected all rings
156: hkn0516:2908500:2908590 [0] NCCL INFO Connected all rings
436: hkn0731:1379234:1379347 [0] NCCL INFO Connected all rings
 77: hkn0424:2940449:2940563 [1] NCCL INFO Connected all rings
 49: hkn0417:2260159:2260288 [1] NCCL INFO Connected all rings
157: hkn0516:2908488:2908596 [1] NCCL INFO Connected all rings
 88: hkn0427:1127643:1127786 [0] NCCL INFO Connected all rings
172: hkn0524:1126300:1126401 [0] NCCL INFO Connected all rings
137: hkn0511:3058866:3058981 [1] NCCL INFO Connected all rings
 52: hkn0418:1861695:1861793 [0] NCCL INFO Connected all rings
437: hkn0731:1379256:1379351 [1] NCCL INFO Connected all rings
 48: hkn0417:2260167:2260286 [0] NCCL INFO Connected all rings
 73: hkn0423:1697346:1697471 [1] NCCL INFO Connected all rings
 44: hkn0415:2488950:2489094 [0] NCCL INFO Connected all rings
 81: hkn0425:2076498:2076595 [1] NCCL INFO Connected all rings
 61: hkn0420:3202729:3202829 [1] NCCL INFO Connected all rings
153: hkn0515:2889289:2889409 [1] NCCL INFO Connected all rings
 57: hkn0419:1536822:1536917 [1] NCCL INFO Connected all rings
176: hkn0525:979338:979432 [0] NCCL INFO Connected all rings
100: hkn0502:221575:221672 [0] NCCL INFO Connected all rings
 68: hkn0422:4145491:4145646 [0] NCCL INFO Connected all rings
121: hkn0507:3179593:3179688 [1] NCCL INFO Connected all rings
 45: hkn0415:2488962:2489090 [1] NCCL INFO Connected all rings
 56: hkn0419:1536810:1536918 [0] NCCL INFO Connected all rings
120: hkn0507:3179581:3179694 [0] NCCL INFO Connected all rings
169: hkn0523:1540568:1540663 [1] NCCL INFO Connected all rings
112: hkn0505:2296308:2296407 [0] NCCL INFO Connected all rings
 84: hkn0426:806579:806691 [0] NCCL INFO Connected all rings
433: hkn0730:1394237:1394350 [1] NCCL INFO Connected all rings
113: hkn0505:2296285:2296401 [1] NCCL INFO Connected all rings
116: hkn0506:830570:830664 [0] NCCL INFO Connected all rings
351: hkn0706:744774:744912 [3] NCCL INFO Connected all rings
180: hkn0526:1420918:1421023 [0] NCCL INFO Connected all rings
109: hkn0504:33317:33440 [1] NCCL INFO Connected all rings
 89: hkn0427:1127663:1127792 [1] NCCL INFO Connected all rings
477: hkn0806:1046851:1046947 [1] NCCL INFO Connected all rings
 66: hkn0421:2172265:2172522 [2] NCCL INFO Connected all rings
 24: hkn0410:1152208:1152319 [0] NCCL INFO Connected all rings
 20: hkn0409:2578189:2578309 [0] NCCL INFO Connected all rings
132: hkn0510:2754595:2754687 [0] NCCL INFO Connected all rings
449: hkn0734:1149097:1149191 [1] NCCL INFO Connected all rings
129: hkn0509:3116896:3117018 [1] NCCL INFO Connected all rings
 21: hkn0409:2578197:2578308 [1] NCCL INFO Connected all rings
 72: hkn0423:1697374:1697469 [0] NCCL INFO Connected all rings
205: hkn0532:916650:916971 [1] NCCL INFO Connected all rings
 53: hkn0418:1861667:1861790 [1] NCCL INFO Connected all rings
432: hkn0730:1394221:1394352 [0] NCCL INFO Connected all rings
133: hkn0510:2754575:2754694 [1] NCCL INFO Connected all rings
244: hkn0608:478258:478384 [0] NCCL INFO Connected all rings
102: hkn0502:221554:221671 [2] NCCL INFO Connected all rings
144: hkn0513:3005464:3005559 [0] NCCL INFO Connected all rings
 97: hkn0501:1320356:1320474 [1] NCCL INFO Connected all rings
 41: hkn0414:1974079:1974183 [1] NCCL INFO Connected all rings
468: hkn0804:1198143:1198246 [0] NCCL INFO Connected all rings
168: hkn0523:1540548:1540665 [0] NCCL INFO Connected all rings
 40: hkn0414:1974091:1974182 [0] NCCL INFO Connected all rings
140: hkn0512:3036647:3036768 [0] NCCL INFO Connected all rings
117: hkn0506:830562:830672 [1] NCCL INFO Connected all rings
173: hkn0524:1126272:1126399 [1] NCCL INFO Connected all rings
429: hkn0728:1316473:1316578 [1] NCCL INFO Connected all rings
 85: hkn0426:806571:806694 [1] NCCL INFO Connected all rings
 96: hkn0501:1320376:1320475 [0] NCCL INFO Connected all rings
277: hkn0621:1984016:1984143 [1] NCCL INFO Connected all rings
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 00 : 64[31000] -> 65[4b000] via P2P/IPC/read
256: hkn0612:909459:909583 [0] NCCL INFO Connected all rings
448: hkn0734:1149085:1149196 [0] NCCL INFO Connected all rings
 37: hkn0413:2359194:2359299 [1] NCCL INFO Connected all rings
177: hkn0525:979326:979436 [1] NCCL INFO Connected all rings
200: hkn0531:1223086:1223206 [0] NCCL INFO Connected all rings
228: hkn0604:681736:681856 [0] NCCL INFO Connected all rings
 78: hkn0424:2940433:2940564 [2] NCCL INFO Connected all rings
 92: hkn0428:659865:659978 [0] NCCL INFO Connected all rings
 69: hkn0422:4145507:4145651 [1] NCCL INFO Connected all rings
276: hkn0621:1984044:1984134 [0] NCCL INFO Connected all rings
160: hkn0520:2705369:2705482 [0] NCCL INFO Connected all rings
197: hkn0530:1250643:1250765 [1] NCCL INFO Connected all rings
164: hkn0521:1190286:1190438 [0] NCCL INFO Connected all rings
208: hkn0534:1140908:1141032 [0] NCCL INFO Connected all rings
268: hkn0616:397357:397478 [0] NCCL INFO Connected all rings
189: hkn0528:1294214:1294319 [1] NCCL INFO Connected all rings
428: hkn0728:1316465:1316582 [0] NCCL INFO Connected all rings
424: hkn0727:1338299:1338383 [0] NCCL INFO Connected all rings
273: hkn0617:2287153:2287277 [1] NCCL INFO Connected all rings
 17: hkn0408:2883223:2883320 [1] NCCL INFO Connected all rings
146: hkn0513:3005437:3005564 [2] NCCL INFO Connected all rings
188: hkn0528:1294198:1294318 [0] NCCL INFO Connected all rings
245: hkn0608:478274:478386 [1] NCCL INFO Connected all rings
472: hkn0805:1104602:1104720 [0] NCCL INFO Connected all rings
122: hkn0507:3179573:3179686 [2] NCCL INFO Connected all rings
476: hkn0806:1046831:1046950 [0] NCCL INFO Connected all rings
150: hkn0514:2943226:2943345 [2] NCCL INFO Connected all rings
480: hkn0807:1011577:1011693 [0] NCCL INFO Connected all rings
425: hkn0727:1338287:1338387 [1] NCCL INFO Connected all rings
240: hkn0607:896885:896985 [0] NCCL INFO Connected all rings
445: hkn0733:1381907:1382020 [1] NCCL INFO Connected all rings
420: hkn0726:1540622:1540733 [0] NCCL INFO Connected all rings
158: hkn0516:2908472:2908599 [2] NCCL INFO Connected all rings
138: hkn0511:3058850:3058979 [2] NCCL INFO Connected all rings
104: hkn0503:2892170:2892284 [0] NCCL INFO Connected all rings
368: hkn0712:287551:287669 [0] NCCL INFO Connected all rings
 74: hkn0423:1697354:1697472 [2] NCCL INFO Connected all rings
225: hkn0603:1405664:1405775 [1] NCCL INFO Connected all rings
272: hkn0617:2287169:2287282 [0] NCCL INFO Connected all rings
 25: hkn0410:1152210:1152322 [1] NCCL INFO Connected all rings
438: hkn0731:1379244:1379355 [2] NCCL INFO Connected all rings
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 00 : 148[31000] -> 149[4b000] via P2P/IPC/read
316: hkn0632:1751127:1751225 [0] NCCL INFO Connected all rings
 82: hkn0425:2076510:2076599 [2] NCCL INFO Connected all rings
473: hkn0805:1104610:1104724 [1] NCCL INFO Connected all rings
181: hkn0526:1420907:1421018 [1] NCCL INFO Connected all rings
100: hkn0502:221575:221672 [0] NCCL INFO Channel 00 : 100[31000] -> 101[4b000] via P2P/IPC/read
 50: hkn0417:2260187:2260291 [2] NCCL INFO Connected all rings
317: hkn0632:1751107:1751230 [1] NCCL INFO Connected all rings
469: hkn0804:1198123:1198240 [1] NCCL INFO Connected all rings
 62: hkn0420:3202701:3202824 [2] NCCL INFO Connected all rings
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 00 : 76[31000] -> 77[4b000] via P2P/IPC/read
170: hkn0523:1540556:1540660 [2] NCCL INFO Connected all rings
124: hkn0508:3131620:3131734 [0] NCCL INFO Connected all rings
312: hkn0631:1014294:1014414 [0] NCCL INFO Connected all rings
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 00 : 80[31000] -> 81[4b000] via P2P/IPC/read
497: hkn0812:686297:686395 [1] NCCL INFO Connected all rings
 13: hkn0407:1808783:1808911 [1] NCCL INFO Connected all rings
 46: hkn0415:2488942:2489091 [2] NCCL INFO Connected all rings
128: hkn0509:3116916:3117017 [0] NCCL INFO Connected all rings
 58: hkn0419:1536809:1536916 [2] NCCL INFO Connected all rings
154: hkn0515:2889281:2889407 [2] NCCL INFO Connected all rings
257: hkn0612:909451:909581 [1] NCCL INFO Connected all rings
309: hkn0630:1590958:1591101 [1] NCCL INFO Connected all rings
297: hkn0627:1780434:1780527 [1] NCCL INFO Connected all rings
165: hkn0521:1190302:1190437 [1] NCCL INFO Connected all rings
434: hkn0730:1394229:1394348 [2] NCCL INFO Connected all rings
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 00 : 60[31000] -> 61[4b000] via P2P/IPC/read
192: hkn0529:1533356:1533475 [0] NCCL INFO Connected all rings
184: hkn0527:1341449:1341560 [0] NCCL INFO Connected all rings
 16: hkn0408:2883211:2883325 [0] NCCL INFO Connected all rings
440: hkn0732:1204171:1204267 [0] NCCL INFO Connected all rings
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 00 : 152[31000] -> 153[4b000] via P2P/IPC/read
114: hkn0505:2296288:2296402 [2] NCCL INFO Connected all rings
237: hkn0606:2364558:2364669 [1] NCCL INFO Connected all rings
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 00 : 156[31000] -> 157[4b000] via P2P/IPC/read
196: hkn0530:1250671:1250770 [0] NCCL INFO Connected all rings
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 00 : 136[31000] -> 137[4b000] via P2P/IPC/read
241: hkn0607:896873:896982 [1] NCCL INFO Connected all rings
421: hkn0726:1540614:1540729 [1] NCCL INFO Connected all rings
489: hkn0809:929888:930005 [1] NCCL INFO Connected all rings
 98: hkn0501:1320364:1320480 [2] NCCL INFO Connected all rings
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 00 : 436[31000] -> 437[4b000] via P2P/IPC/read
130: hkn0509:3116904:3117014 [2] NCCL INFO Connected all rings
481: hkn0807:1011585:1011697 [1] NCCL INFO Connected all rings
206: hkn0532:916669:916966 [2] NCCL INFO Connected all rings
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 00 : 120[31000] -> 121[4b000] via P2P/IPC/read
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 00 : 48[31000] -> 49[4b000] via P2P/IPC/read
161: hkn0520:2705368:2705469 [1] NCCL INFO Connected all rings
125: hkn0508:3131636:3131730 [1] NCCL INFO Connected all rings
220: hkn0602:3353946:3354226 [0] NCCL INFO Connected all rings
229: hkn0604:681744:681864 [1] NCCL INFO Connected all rings
417: hkn0725:3104434:3104541 [1] NCCL INFO Connected all rings
385: hkn0716:101000:101120 [1] NCCL INFO Connected all rings
110: hkn0504:33345:33443 [2] NCCL INFO Connected all rings
  5: hkn0404:1331860:1331998 [1] NCCL INFO Connected all rings
 93: hkn0428:659873:659979 [1] NCCL INFO Connected all rings
478: hkn0806:1046839:1046949 [2] NCCL INFO Connected all rings
209: hkn0534:1140924:1141030 [1] NCCL INFO Connected all rings
296: hkn0627:1780414:1780535 [0] NCCL INFO Connected all rings
356: hkn0708:405715:405864 [0] NCCL INFO Connected all rings
450: hkn0734:1149069:1149195 [2] NCCL INFO Connected all rings
465: hkn0803:869036:869157 [1] NCCL INFO Connected all rings
 90: hkn0427:1127651:1127785 [2] NCCL INFO Connected all rings
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 00 : 200[31000] -> 201[4b000] via P2P/IPC/read
320: hkn0633:1518863:1518964 [0] NCCL INFO Connected all rings
360: hkn0710:348013:348131 [0] NCCL INFO Connected all rings
308: hkn0630:1590950:1591102 [0] NCCL INFO Connected all rings
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 00 : 72[31000] -> 73[4b000] via P2P/IPC/read
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 00 : 44[31000] -> 45[4b000] via P2P/IPC/read
253: hkn0611:702329:702425 [1] NCCL INFO Connected all rings
357: hkn0708:405731:405869 [1] NCCL INFO Connected all rings
 22: hkn0409:2578209:2578305 [2] NCCL INFO Connected all rings
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 00 : 56[31000] -> 57[4b000] via P2P/IPC/read
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 01 : 64[31000] -> 65[4b000] via P2P/IPC/read
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 00 : 88[31000] -> 89[4b000] via P2P/IPC/read
178: hkn0525:979310:979433 [2] NCCL INFO Connected all rings
174: hkn0524:1126288:1126393 [2] NCCL INFO Connected all rings
221: hkn0602:3353962:3354225 [1] NCCL INFO Connected all rings
365: hkn0711:576415:576512 [1] NCCL INFO Connected all rings
313: hkn0631:1014302:1014419 [1] NCCL INFO Connected all rings
269: hkn0616:397377:397476 [1] NCCL INFO Connected all rings
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 00 : 104[31000] -> 105[4b000] via P2P/IPC/read
232: hkn0605:704594:704721 [0] NCCL INFO Connected all rings
388: hkn0717:4180092:4180225 [0] NCCL INFO Connected all rings
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 00 : 84[31000] -> 85[4b000] via P2P/IPC/read
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 00 : 144[31000] -> 145[4b000] via P2P/IPC/read
216: hkn0601:110172:110280 [0] NCCL INFO Connected all rings
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 00 : 112[31000] -> 113[4b000] via P2P/IPC/read
364: hkn0711:576387:576519 [0] NCCL INFO Connected all rings
369: hkn0712:287543:287667 [1] NCCL INFO Connected all rings
224: hkn0603:1405683:1405780 [0] NCCL INFO Connected all rings
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 00 : 432[31000] -> 433[4b000] via P2P/IPC/read
 36: hkn0413:2359195:2359304 [0] NCCL INFO Connected all rings
384: hkn0716:101008:101117 [0] NCCL INFO Connected all rings
193: hkn0529:1533348:1533477 [1] NCCL INFO Connected all rings
 54: hkn0418:1861675:1861787 [2] NCCL INFO Connected all rings
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 00 : 172[31000] -> 173[4b000] via P2P/IPC/read
190: hkn0528:1294206:1294325 [2] NCCL INFO Connected all rings
305: hkn0629:1584572:1584665 [1] NCCL INFO Connected all rings
 38: hkn0413:2359203:2359295 [2] NCCL INFO Connected all rings
 42: hkn0414:1974071:1974185 [2] NCCL INFO Connected all rings
265: hkn0615:406807:406907 [1] NCCL INFO Connected all rings
134: hkn0510:2754583:2754692 [2] NCCL INFO Connected all rings
324: hkn0634:1513353:1513483 [0] NCCL INFO Connected all rings
285: hkn0623:1865230:1865352 [1] NCCL INFO Connected all rings
300: hkn0628:664377:664476 [0] NCCL INFO Connected all rings
377: hkn0714:424551:424658 [1] NCCL INFO Connected all rings
392: hkn0718:3909502:3909648 [0] NCCL INFO Connected all rings
 28: hkn0411:2308375:2308484 [0] NCCL INFO Connected all rings
212: hkn0535:2391491:2391620 [0] NCCL INFO Connected all rings
430: hkn0728:1316485:1316584 [2] NCCL INFO Connected all rings
457: hkn0801:2232468:2232617 [1] NCCL INFO Connected all rings
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 00 : 52[31000] -> 53[4b000] via P2P/IPC/read
118: hkn0506:830582:830669 [2] NCCL INFO Connected all rings
278: hkn0621:1984032:1984138 [2] NCCL INFO Connected all rings
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 00 : 168[31000] -> 169[4b000] via P2P/IPC/read
393: hkn0718:3909494:3909650 [1] NCCL INFO Connected all rings
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 00 : 440[31000] -> 441[4b000] via P2P/IPC/read
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 00 : 20[31000] -> 21[4b000] via P2P/IPC/read
176: hkn0525:979338:979432 [0] NCCL INFO Channel 00 : 176[31000] -> 177[4b000] via P2P/IPC/read
198: hkn0530:1250651:1250763 [2] NCCL INFO Connected all rings
236: hkn0606:2364550:2364664 [0] NCCL INFO Connected all rings
396: hkn0719:1298187:1298341 [0] NCCL INFO Connected all rings
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 00 : 96[31000] -> 97[4b000] via P2P/IPC/read
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 01 : 148[31000] -> 149[4b000] via P2P/IPC/read
452: hkn0736:1500850:1500969 [0] NCCL INFO Connected all rings
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 00 : 132[31000] -> 133[4b000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Connected all rings
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 00 : 448[31000] -> 449[4b000] via P2P/IPC/read
 70: hkn0422:4145499:4145645 [2] NCCL INFO Connected all rings
116: hkn0506:830570:830664 [0] NCCL INFO Channel 00 : 116[31000] -> 117[4b000] via P2P/IPC/read
293: hkn0626:1290947:1291055 [1] NCCL INFO Connected all rings
304: hkn0629:1584552:1584670 [0] NCCL INFO Connected all rings
108: hkn0504:33325:33439 [0] NCCL INFO Connected all rings
 26: hkn0410:1152222:1152317 [2] NCCL INFO Connected all rings
100: hkn0502:221575:221672 [0] NCCL INFO Channel 01 : 100[31000] -> 101[4b000] via P2P/IPC/read
401: hkn0720:4190323:4190580 [1] NCCL INFO Connected all rings
274: hkn0617:2287161:2287275 [2] NCCL INFO Connected all rings
444: hkn0733:1381919:1382019 [0] NCCL INFO Connected all rings
484: hkn0808:963191:963307 [0] NCCL INFO Connected all rings
492: hkn0810:932042:932160 [0] NCCL INFO Connected all rings
 18: hkn0408:2883203:2883321 [2] NCCL INFO Connected all rings
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 00 : 68[31000] -> 69[4b000] via P2P/IPC/read
280: hkn0622:2012990:2013090 [0] NCCL INFO Connected all rings
333: hkn0636:1646748:1646841 [1] NCCL INFO Connected all rings
242: hkn0607:896865:896980 [2] NCCL INFO Connected all rings
 12: hkn0407:1808763:1808908 [0] NCCL INFO Connected all rings
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 01 : 76[31000] -> 77[4b000] via P2P/IPC/read
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 00 : 476[31000] -> 477[4b000] via P2P/IPC/read
217: hkn0601:110184:110286 [1] NCCL INFO Connected all rings
380: hkn0715:394410:394546 [0] NCCL INFO Connected all rings
352: hkn0707:4012423:4012534 [0] NCCL INFO Connected all rings
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 01 : 80[31000] -> 81[4b000] via P2P/IPC/read
213: hkn0535:2391499:2391618 [1] NCCL INFO Connected all rings
141: hkn0512:3036663:3036774 [1] NCCL INFO Connected all rings
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 00 : 65[4b000] -> 66[ca000] via P2P/IPC/read
332: hkn0636:1646720:1646839 [0] NCCL INFO Connected all rings
418: hkn0725:3104426:3104537 [2] NCCL INFO Connected all rings
446: hkn0733:1381899:1382018 [2] NCCL INFO Connected all rings
488: hkn0809:929896:930007 [0] NCCL INFO Connected all rings
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 01 : 60[31000] -> 61[4b000] via P2P/IPC/read
 86: hkn0426:806587:806697 [2] NCCL INFO Connected all rings
466: hkn0803:869044:869156 [2] NCCL INFO Connected all rings
412: hkn0724:1708475:1708596 [0] NCCL INFO Connected all rings
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 01 : 156[31000] -> 157[4b000] via P2P/IPC/read
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 00 : 40[31000] -> 41[4b000] via P2P/IPC/read
185: hkn0527:1341461:1341561 [1] NCCL INFO Connected all rings
426: hkn0727:1338279:1338380 [2] NCCL INFO Connected all rings
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 01 : 152[31000] -> 153[4b000] via P2P/IPC/read
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 00 : 188[31000] -> 189[4b000] via P2P/IPC/read
246: hkn0608:478266:478383 [2] NCCL INFO Connected all rings
353: hkn0707:4012439:4012533 [1] NCCL INFO Connected all rings
226: hkn0603:1405672:1405779 [2] NCCL INFO Connected all rings
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 00 : 24[31000] -> 25[4b000] via P2P/IPC/read
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 00 : 276[31000] -> 277[4b000] via P2P/IPC/read
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 01 : 48[31000] -> 49[4b000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 01 : 136[31000] -> 137[4b000] via P2P/IPC/read
340: hkn0704:784518:784625 [0] NCCL INFO Connected all rings
498: hkn0812:686269:686396 [2] NCCL INFO Connected all rings
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 00 : 428[31000] -> 429[4b000] via P2P/IPC/read
504: hkn0815:387632:387784 [0] NCCL INFO Connected all rings
 14: hkn0407:1808755:1808914 [2] NCCL INFO Connected all rings
182: hkn0526:1420936:1421020 [2] NCCL INFO Connected all rings
101: hkn0502:221555:221670 [1] NCCL INFO Channel 00 : 101[4b000] -> 102[ca000] via P2P/IPC/read
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 00 : 128[31000] -> 129[4b000] via P2P/IPC/read
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 01 : 120[31000] -> 121[4b000] via P2P/IPC/read
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 01 : 104[31000] -> 105[4b000] via P2P/IPC/read
248: hkn0609:703361:703450 [0] NCCL INFO Connected all rings
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 01 : 436[31000] -> 437[4b000] via P2P/IPC/read
381: hkn0715:394422:394551 [1] NCCL INFO Connected all rings
301: hkn0628:664357:664467 [1] NCCL INFO Connected all rings
244: hkn0608:478258:478384 [0] NCCL INFO Channel 00 : 244[31000] -> 245[4b000] via P2P/IPC/read
409: hkn0723:200369:200533 [1] NCCL INFO Connected all rings
400: hkn0720:4190315:4190586 [0] NCCL INFO Connected all rings
298: hkn0627:1780406:1780532 [2] NCCL INFO Connected all rings
233: hkn0605:704610:704720 [1] NCCL INFO Connected all rings
 33: hkn0412:2254900:2255017 [1] NCCL INFO Connected all rings
386: hkn0716:101020:101119 [2] NCCL INFO Connected all rings
318: hkn0632:1751099:1751227 [2] NCCL INFO Connected all rings
310: hkn0630:1590942:1591100 [2] NCCL INFO Connected all rings
416: hkn0725:3104442:3104538 [0] NCCL INFO Connected all rings
474: hkn0805:1104630:1104729 [2] NCCL INFO Connected all rings
470: hkn0804:1198131:1198247 [2] NCCL INFO Connected all rings
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 00 : 180[31000] -> 181[4b000] via P2P/IPC/read
349: hkn0706:744786:744914 [1] NCCL INFO Connected all rings
490: hkn0809:929907:930004 [2] NCCL INFO Connected all rings
505: hkn0815:387660:387783 [1] NCCL INFO Connected all rings
201: hkn0531:1223094:1223197 [1] NCCL INFO Connected all rings
238: hkn0606:2364570:2364670 [2] NCCL INFO Connected all rings
321: hkn0633:1518835:1518968 [1] NCCL INFO Connected all rings
166: hkn0521:1190294:1190442 [2] NCCL INFO Connected all rings
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 01 : 72[31000] -> 73[4b000] via P2P/IPC/read
341: hkn0704:784510:784629 [1] NCCL INFO Connected all rings
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 00 : 272[31000] -> 273[4b000] via P2P/IPC/read
  6: hkn0404:1331844:1331992 [2] NCCL INFO Connected all rings
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 00 : 424[31000] -> 425[4b000] via P2P/IPC/read
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 01 : 440[31000] -> 441[4b000] via P2P/IPC/read
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 01 : 44[31000] -> 45[4b000] via P2P/IPC/read
 66: hkn0421:2172265:2172522 [2] NCCL INFO Channel 00 : 66[ca000] -> 67[e3000] via P2P/IPC/read
258: hkn0612:909479:909575 [2] NCCL INFO Connected all rings
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 00 : 468[31000] -> 469[4b000] via P2P/IPC/read
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 01 : 88[31000] -> 89[4b000] via P2P/IPC/read
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 01 : 56[31000] -> 57[4b000] via P2P/IPC/read
337: hkn0703:733504:733651 [1] NCCL INFO Connected all rings
240: hkn0607:896885:896985 [0] NCCL INFO Channel 00 : 240[31000] -> 241[4b000] via P2P/IPC/read
500: hkn0814:668339:668453 [0] NCCL INFO Connected all rings
204: hkn0532:916658:916970 [0] NCCL INFO Connected all rings
162: hkn0520:2705389:2705480 [2] NCCL INFO Connected all rings
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 00 : 164[31000] -> 165[4b000] via P2P/IPC/read
230: hkn0604:681752:681859 [2] NCCL INFO Connected all rings
493: hkn0810:932050:932165 [1] NCCL INFO Connected all rings
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 01 : 84[31000] -> 85[4b000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 00 : 16[31000] -> 17[4b000] via P2P/IPC/read
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 01 : 112[31000] -> 113[4b000] via P2P/IPC/read
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 00 : 196[31000] -> 197[4b000] via P2P/IPC/read
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 01 : 172[31000] -> 173[4b000] via P2P/IPC/read
126: hkn0508:3131648:3131731 [2] NCCL INFO Connected all rings
256: hkn0612:909459:909583 [0] NCCL INFO Channel 00 : 256[31000] -> 257[4b000] via P2P/IPC/read
260: hkn0613:895195:895293 [0] NCCL INFO Connected all rings
328: hkn0635:1218095:1218212 [0] NCCL INFO Connected all rings
482: hkn0807:1011569:1011689 [2] NCCL INFO Connected all rings
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 01 : 144[31000] -> 145[4b000] via P2P/IPC/read
254: hkn0611:702301:702422 [2] NCCL INFO Connected all rings
210: hkn0534:1140936:1141031 [2] NCCL INFO Connected all rings
  8: hkn0405:3199319:3199416 [0] NCCL INFO Connected all rings
397: hkn0719:1298203:1298338 [1] NCCL INFO Connected all rings
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 00 : 472[31000] -> 473[4b000] via P2P/IPC/read
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 00 : 77[4b000] -> 78[ca000] via P2P/IPC/read
149: hkn0514:2943234:2943343 [1] NCCL INFO Channel 00 : 149[4b000] -> 150[ca000] via P2P/IPC/read
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 00 : 28[31000] -> 29[4b000] via P2P/IPC/read
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 00 : 160[31000] -> 161[4b000] via P2P/IPC/read
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 00 : 316[31000] -> 317[4b000] via P2P/IPC/read
329: hkn0635:1218103:1218214 [1] NCCL INFO Connected all rings
389: hkn0717:4180100:4180219 [1] NCCL INFO Connected all rings
413: hkn0724:1708483:1708593 [1] NCCL INFO Connected all rings
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 00 : 36[31000] -> 37[4b000] via P2P/IPC/read
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 00 : 480[31000] -> 481[4b000] via P2P/IPC/read
228: hkn0604:681736:681856 [0] NCCL INFO Channel 00 : 228[31000] -> 229[4b000] via P2P/IPC/read
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 01 : 52[31000] -> 53[4b000] via P2P/IPC/read
 94: hkn0428:659895:659982 [2] NCCL INFO Connected all rings
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 01 : 168[31000] -> 169[4b000] via P2P/IPC/read
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 01 : 65[4b000] -> 66[ca000] via P2P/IPC/read
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 00 : 420[31000] -> 421[4b000] via P2P/IPC/read
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 00 : 61[4b000] -> 62[ca000] via P2P/IPC/read
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 01 : 96[31000] -> 97[4b000] via P2P/IPC/read
102: hkn0502:221554:221671 [2] NCCL INFO Channel 00 : 102[ca000] -> 103[e3000] via P2P/IPC/read
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 01 : 20[31000] -> 21[4b000] via P2P/IPC/read
458: hkn0801:2232476:2232619 [2] NCCL INFO Connected all rings
437: hkn0731:1379256:1379351 [1] NCCL INFO Channel 00 : 437[4b000] -> 438[ca000] via P2P/IPC/read
108: hkn0504:33325:33439 [0] NCCL INFO Channel 00 : 108[31000] -> 109[4b000] via P2P/IPC/read
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 00 : 157[4b000] -> 158[ca000] via P2P/IPC/read
384: hkn0716:101008:101117 [0] NCCL INFO Channel 00 : 384[31000] -> 385[4b000] via P2P/IPC/read
109: hkn0504:33317:33440 [1] NCCL INFO Channel 00 : 109[4b000] -> 110[ca000] via P2P/IPC/read
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 01 : 432[31000] -> 433[4b000] via P2P/IPC/read
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 01 : 24[31000] -> 25[4b000] via P2P/IPC/read
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 00 : 433[4b000] -> 434[ca000] via P2P/IPC/read
158: hkn0516:2908472:2908599 [2] NCCL INFO Channel 00 : 158[ca000] -> 159[e3000] via P2P/IPC/read
194: hkn0529:1533376:1533479 [2] NCCL INFO Connected all rings
460: hkn0802:1192854:1192947 [0] NCCL INFO Connected all rings
  1: hkn0403:1751324:1751696 [1] NCCL INFO Connected all rings
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 00 : 12[31000] -> 13[4b000] via P2P/IPC/read
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 00 : 192[31000] -> 193[4b000] via P2P/IPC/read
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 00 : 89[4b000] -> 90[ca000] via P2P/IPC/read
 62: hkn0420:3202701:3202824 [2] NCCL INFO Channel 00 : 62[ca000] -> 63[e3000] via P2P/IPC/read
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 01 : 180[31000] -> 181[4b000] via P2P/IPC/read
  0: hkn0403:1751320:1751689 [0] NCCL INFO Connected all rings
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 00 : 97[4b000] -> 98[ca000] via P2P/IPC/read
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 01 : 61[4b000] -> 62[ca000] via P2P/IPC/read
 85: hkn0426:806571:806694 [1] NCCL INFO Channel 00 : 85[4b000] -> 86[ca000] via P2P/IPC/read
410: hkn0723:200364:200541 [2] NCCL INFO Connected all rings
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 01 : 468[31000] -> 469[4b000] via P2P/IPC/read
508: hkn0816:368125:368237 [0] NCCL INFO Connected all rings
438: hkn0731:1379244:1379355 [2] NCCL INFO Channel 00 : 438[ca000] -> 439[e3000] via P2P/IPC/read
 53: hkn0418:1861667:1861790 [1] NCCL INFO Channel 00 : 53[4b000] -> 54[ca000] via P2P/IPC/read
437: hkn0731:1379256:1379351 [1] NCCL INFO Channel 01 : 437[4b000] -> 438[ca000] via P2P/IPC/read
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 01 : 36[31000] -> 37[4b000] via P2P/IPC/read
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 01 : 157[4b000] -> 158[ca000] via P2P/IPC/read
434: hkn0730:1394229:1394348 [2] NCCL INFO Channel 00 : 434[ca000] -> 435[e3000] via P2P/IPC/read
 90: hkn0427:1127651:1127785 [2] NCCL INFO Channel 00 : 90[ca000] -> 91[e3000] via P2P/IPC/read
461: hkn0802:1192842:1192951 [1] NCCL INFO Connected all rings
 78: hkn0424:2940433:2940564 [2] NCCL INFO Channel 00 : 78[ca000] -> 79[e3000] via P2P/IPC/read
506: hkn0815:387640:387788 [2] NCCL INFO Connected all rings
 98: hkn0501:1320364:1320480 [2] NCCL INFO Channel 00 : 98[ca000] -> 99[e3000] via P2P/IPC/read
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 01 : 433[4b000] -> 434[ca000] via P2P/IPC/read
 37: hkn0413:2359194:2359299 [1] NCCL INFO Channel 00 : 37[4b000] -> 38[ca000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Connected all rings
384: hkn0716:101008:101117 [0] NCCL INFO Channel 01 : 384[31000] -> 385[4b000] via P2P/IPC/read
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 01 : 77[4b000] -> 78[ca000] via P2P/IPC/read
150: hkn0514:2943226:2943345 [2] NCCL INFO Channel 00 : 150[ca000] -> 151[e3000] via P2P/IPC/read
158: hkn0516:2908472:2908599 [2] NCCL INFO Channel 01 : 158[ca000] -> 159[e3000] via P2P/IPC/read
 29: hkn0411:2308366:2308483 [1] NCCL INFO Connected all rings
108: hkn0504:33325:33439 [0] NCCL INFO Channel 01 : 108[31000] -> 109[4b000] via P2P/IPC/read
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 00 : 25[4b000] -> 26[ca000] via P2P/IPC/read
110: hkn0504:33345:33443 [2] NCCL INFO Channel 00 : 110[ca000] -> 111[e3000] via P2P/IPC/read
509: hkn0816:368127:368238 [1] NCCL INFO Connected all rings
109: hkn0504:33317:33440 [1] NCCL INFO Channel 01 : 109[4b000] -> 110[ca000] via P2P/IPC/read
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 01 : 89[4b000] -> 90[ca000] via P2P/IPC/read
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 01 : 97[4b000] -> 98[ca000] via P2P/IPC/read
 78: hkn0424:2940433:2940564 [2] NCCL INFO Channel 01 : 78[ca000] -> 79[e3000] via P2P/IPC/read
 85: hkn0426:806571:806694 [1] NCCL INFO Channel 01 : 85[4b000] -> 86[ca000] via P2P/IPC/read
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 01 : 192[31000] -> 193[4b000] via P2P/IPC/read
149: hkn0514:2943234:2943343 [1] NCCL INFO Channel 01 : 149[4b000] -> 150[ca000] via P2P/IPC/read
101: hkn0502:221555:221670 [1] NCCL INFO Channel 01 : 101[4b000] -> 102[ca000] via P2P/IPC/read
181: hkn0526:1420907:1421018 [1] NCCL INFO Channel 00 : 181[4b000] -> 182[ca000] via P2P/IPC/read
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 01 : 40[31000] -> 41[4b000] via P2P/IPC/read
504: hkn0815:387632:387784 [0] NCCL INFO Channel 00 : 504[31000] -> 505[4b000] via P2P/IPC/read
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 01 : 12[31000] -> 13[4b000] via P2P/IPC/read
  2: hkn0403:1751321:1751698 [2] NCCL INFO Connected all rings
469: hkn0804:1198123:1198240 [1] NCCL INFO Channel 00 : 469[4b000] -> 470[ca000] via P2P/IPC/read
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 00 : 13[4b000] -> 14[ca000] via P2P/IPC/read
 26: hkn0410:1152222:1152317 [2] NCCL INFO Channel 00 : 26[ca000] -> 27[e3000] via P2P/IPC/read
 86: hkn0426:806587:806697 [2] NCCL INFO Channel 00 : 86[ca000] -> 87[e3000] via P2P/IPC/read
 54: hkn0418:1861675:1861787 [2] NCCL INFO Channel 00 : 54[ca000] -> 55[e3000] via P2P/IPC/read
 38: hkn0413:2359203:2359295 [2] NCCL INFO Channel 00 : 38[ca000] -> 39[e3000] via P2P/IPC/read
 53: hkn0418:1861667:1861790 [1] NCCL INFO Channel 01 : 53[4b000] -> 54[ca000] via P2P/IPC/read
 37: hkn0413:2359194:2359299 [1] NCCL INFO Channel 01 : 37[4b000] -> 38[ca000] via P2P/IPC/read
438: hkn0731:1379244:1379355 [2] NCCL INFO Channel 01 : 438[ca000] -> 439[e3000] via P2P/IPC/read
150: hkn0514:2943226:2943345 [2] NCCL INFO Channel 01 : 150[ca000] -> 151[e3000] via P2P/IPC/read
102: hkn0502:221554:221671 [2] NCCL INFO Channel 01 : 102[ca000] -> 103[e3000] via P2P/IPC/read
 62: hkn0420:3202701:3202824 [2] NCCL INFO Channel 01 : 62[ca000] -> 63[e3000] via P2P/IPC/read
182: hkn0526:1420936:1421020 [2] NCCL INFO Channel 00 : 182[ca000] -> 183[e3000] via P2P/IPC/read
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 00 : 41[4b000] -> 42[ca000] via P2P/IPC/read
  4: hkn0404:1331872:1331990 [0] NCCL INFO Connected all rings
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 01 : 25[4b000] -> 26[ca000] via P2P/IPC/read
 90: hkn0427:1127651:1127785 [2] NCCL INFO Channel 01 : 90[ca000] -> 91[e3000] via P2P/IPC/read
386: hkn0716:101020:101119 [2] NCCL INFO Channel 00 : 386[ca000] -> 387[e3000] via P2P/IPC/read
 42: hkn0414:1974071:1974185 [2] NCCL INFO Channel 00 : 42[ca000] -> 43[e3000] via P2P/IPC/read
385: hkn0716:101000:101120 [1] NCCL INFO Channel 00 : 385[4b000] -> 386[ca000] via P2P/IPC/read
 98: hkn0501:1320364:1320480 [2] NCCL INFO Channel 01 : 98[ca000] -> 99[e3000] via P2P/IPC/read
434: hkn0730:1394229:1394348 [2] NCCL INFO Channel 01 : 434[ca000] -> 435[e3000] via P2P/IPC/read
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 01 : 41[4b000] -> 42[ca000] via P2P/IPC/read
470: hkn0804:1198131:1198247 [2] NCCL INFO Channel 00 : 470[ca000] -> 471[e3000] via P2P/IPC/read
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 00 : 457[4b000] -> 458[ca000] via P2P/IPC/read
181: hkn0526:1420907:1421018 [1] NCCL INFO Channel 01 : 181[4b000] -> 182[ca000] via P2P/IPC/read
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 00 : 193[4b000] -> 194[ca000] via P2P/IPC/read
469: hkn0804:1198123:1198240 [1] NCCL INFO Channel 01 : 469[4b000] -> 470[ca000] via P2P/IPC/read
  5: hkn0404:1331860:1331998 [1] NCCL INFO Channel 00 : 5[4b000] -> 6[ca000] via P2P/IPC/read
409: hkn0723:200369:200533 [1] NCCL INFO Channel 00 : 409[4b000] -> 410[ca000] via P2P/IPC/read
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 00 : 4[31000] -> 5[4b000] via P2P/IPC/read
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via P2P/IPC/read
 14: hkn0407:1808755:1808914 [2] NCCL INFO Channel 00 : 14[ca000] -> 15[e3000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 00 : 456[31000] -> 457[4b000] via P2P/IPC/read
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 01 : 13[4b000] -> 14[ca000] via P2P/IPC/read
110: hkn0504:33345:33443 [2] NCCL INFO Channel 01 : 110[ca000] -> 111[e3000] via P2P/IPC/read
462: hkn0802:1192841:1192950 [2] NCCL INFO Connected all rings
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 01 : 28[31000] -> 29[4b000] via P2P/IPC/read
 42: hkn0414:1974071:1974185 [2] NCCL INFO Channel 01 : 42[ca000] -> 43[e3000] via P2P/IPC/read
 30: hkn0411:2308367:2308482 [2] NCCL INFO Connected all rings
186: hkn0527:1341433:1341555 [2] NCCL INFO Connected all rings
504: hkn0815:387632:387784 [0] NCCL INFO Channel 01 : 504[31000] -> 505[4b000] via P2P/IPC/read
 86: hkn0426:806587:806697 [2] NCCL INFO Channel 01 : 86[ca000] -> 87[e3000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 00 : 460[31000] -> 461[4b000] via P2P/IPC/read
  6: hkn0404:1331844:1331992 [2] NCCL INFO Channel 00 : 6[ca000] -> 7[e3000] via P2P/IPC/read
408: hkn0723:200389:200535 [0] NCCL INFO Connected all rings
386: hkn0716:101020:101119 [2] NCCL INFO Channel 01 : 386[ca000] -> 387[e3000] via P2P/IPC/read
385: hkn0716:101000:101120 [1] NCCL INFO Channel 01 : 385[4b000] -> 386[ca000] via P2P/IPC/read
 26: hkn0410:1152222:1152317 [2] NCCL INFO Channel 01 : 26[ca000] -> 27[e3000] via P2P/IPC/read
510: hkn0816:368135:368243 [2] NCCL INFO Connected all rings
  5: hkn0404:1331860:1331998 [1] NCCL INFO Channel 01 : 5[4b000] -> 6[ca000] via P2P/IPC/read
 38: hkn0413:2359203:2359295 [2] NCCL INFO Channel 01 : 38[ca000] -> 39[e3000] via P2P/IPC/read
194: hkn0529:1533376:1533479 [2] NCCL INFO Channel 00 : 194[ca000] -> 195[e3000] via P2P/IPC/read
182: hkn0526:1420936:1421020 [2] NCCL INFO Channel 01 : 182[ca000] -> 183[e3000] via P2P/IPC/read
 54: hkn0418:1861675:1861787 [2] NCCL INFO Channel 01 : 54[ca000] -> 55[e3000] via P2P/IPC/read
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 01 : 193[4b000] -> 194[ca000] via P2P/IPC/read
508: hkn0816:368125:368237 [0] NCCL INFO Channel 00 : 508[31000] -> 509[4b000] via P2P/IPC/read
103: hkn0502:221563:221675 [3] NCCL INFO Connected all trees
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 01 : 4[31000] -> 5[4b000] via P2P/IPC/read
410: hkn0723:200364:200541 [2] NCCL INFO Channel 00 : 410[ca000] -> 411[e3000] via P2P/IPC/read
103: hkn0502:221563:221675 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
458: hkn0801:2232476:2232619 [2] NCCL INFO Channel 00 : 458[ca000] -> 459[e3000] via P2P/IPC/read
103: hkn0502:221563:221675 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
409: hkn0723:200369:200533 [1] NCCL INFO Channel 01 : 409[4b000] -> 410[ca000] via P2P/IPC/read
505: hkn0815:387660:387783 [1] NCCL INFO Channel 00 : 505[4b000] -> 506[ca000] via P2P/IPC/read
 79: hkn0424:2940441:2940558 [3] NCCL INFO Connected all trees
 79: hkn0424:2940441:2940558 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 00 : 184[31000] -> 185[4b000] via P2P/IPC/read
 79: hkn0424:2940441:2940558 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 01 : 184[31000] -> 185[4b000] via P2P/IPC/read
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 01 : 457[4b000] -> 458[ca000] via P2P/IPC/read
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 00 : 185[4b000] -> 186[ca000] via P2P/IPC/read
470: hkn0804:1198131:1198247 [2] NCCL INFO Channel 01 : 470[ca000] -> 471[e3000] via P2P/IPC/read
159: hkn0516:2908480:2908594 [3] NCCL INFO Connected all trees
439: hkn0731:1379236:1379354 [3] NCCL INFO Connected all trees
151: hkn0514:2943246:2943339 [3] NCCL INFO Connected all trees
159: hkn0516:2908480:2908594 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
439: hkn0731:1379236:1379354 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 01 : 456[31000] -> 457[4b000] via P2P/IPC/read
 14: hkn0407:1808755:1808914 [2] NCCL INFO Channel 01 : 14[ca000] -> 15[e3000] via P2P/IPC/read
159: hkn0516:2908480:2908594 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
439: hkn0731:1379236:1379354 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via P2P/IPC/read
151: hkn0514:2943246:2943339 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:200389:200535 [0] NCCL INFO Channel 00 : 408[31000] -> 409[4b000] via P2P/IPC/read
 63: hkn0420:3202717:3202827 [3] NCCL INFO Connected all trees
 63: hkn0420:3202717:3202827 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 01 : 460[31000] -> 461[4b000] via P2P/IPC/read
 63: hkn0420:3202717:3202827 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
151: hkn0514:2943246:2943339 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1331844:1331992 [2] NCCL INFO Channel 01 : 6[ca000] -> 7[e3000] via P2P/IPC/read
186: hkn0527:1341433:1341555 [2] NCCL INFO Channel 00 : 186[ca000] -> 187[e3000] via P2P/IPC/read
410: hkn0723:200364:200541 [2] NCCL INFO Channel 01 : 410[ca000] -> 411[e3000] via P2P/IPC/read
506: hkn0815:387640:387788 [2] NCCL INFO Channel 00 : 506[ca000] -> 507[e3000] via P2P/IPC/read
435: hkn0730:1394249:1394347 [3] NCCL INFO Connected all trees
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 01 : 185[4b000] -> 186[ca000] via P2P/IPC/read
505: hkn0815:387660:387783 [1] NCCL INFO Channel 01 : 505[4b000] -> 506[ca000] via P2P/IPC/read
 91: hkn0427:1127642:1127790 [3] NCCL INFO Connected all trees
435: hkn0730:1394249:1394347 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 01 : 16[31000] -> 17[4b000] via P2P/IPC/read
435: hkn0730:1394249:1394347 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 91: hkn0427:1127642:1127790 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 99: hkn0501:1320348:1320478 [3] NCCL INFO Connected all trees
 91: hkn0427:1127642:1127790 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 00 : 17[4b000] -> 18[ca000] via P2P/IPC/read
402: hkn0720:4190312:4190585 [2] NCCL INFO Connected all rings
 99: hkn0501:1320348:1320478 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 18: hkn0408:2883203:2883321 [2] NCCL INFO Channel 00 : 18[ca000] -> 19[e3000] via P2P/IPC/read
 99: hkn0501:1320348:1320478 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
508: hkn0816:368125:368237 [0] NCCL INFO Channel 01 : 508[31000] -> 509[4b000] via P2P/IPC/read
111: hkn0504:33333:33445 [3] NCCL INFO Connected all trees
186: hkn0527:1341433:1341555 [2] NCCL INFO Channel 01 : 186[ca000] -> 187[e3000] via P2P/IPC/read
111: hkn0504:33333:33445 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
194: hkn0529:1533376:1533479 [2] NCCL INFO Channel 01 : 194[ca000] -> 195[e3000] via P2P/IPC/read
111: hkn0504:33333:33445 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 00 : 29[4b000] -> 30[ca000] via P2P/IPC/read
  1: hkn0403:1751324:1751696 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[ca000] via P2P/IPC/read
458: hkn0801:2232476:2232619 [2] NCCL INFO Channel 01 : 458[ca000] -> 459[e3000] via P2P/IPC/read
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 01 : 17[4b000] -> 18[ca000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 00 : 400[31000] -> 401[4b000] via P2P/IPC/read
 18: hkn0408:2883203:2883321 [2] NCCL INFO Channel 01 : 18[ca000] -> 19[e3000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 01 : 400[31000] -> 401[4b000] via P2P/IPC/read
 87: hkn0426:806598:806692 [3] NCCL INFO Connected all trees
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 00 : 401[4b000] -> 402[ca000] via P2P/IPC/read
 87: hkn0426:806598:806692 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:4190312:4190585 [2] NCCL INFO Channel 00 : 402[ca000] -> 403[e3000] via P2P/IPC/read
 87: hkn0426:806598:806692 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 43: hkn0414:1974063:1974188 [3] NCCL INFO Connected all trees
 43: hkn0414:1974063:1974188 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 01 : 401[4b000] -> 402[ca000] via P2P/IPC/read
 43: hkn0414:1974063:1974188 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
402: hkn0720:4190312:4190585 [2] NCCL INFO Channel 01 : 402[ca000] -> 403[e3000] via P2P/IPC/read
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 00 : 461[4b000] -> 462[ca000] via P2P/IPC/read
102: hkn0502:221554:221671 [2] NCCL INFO Connected all trees
 30: hkn0411:2308367:2308482 [2] NCCL INFO Channel 00 : 30[ca000] -> 31[e3000] via P2P/IPC/read
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 01 : 424[31000] -> 425[4b000] via P2P/IPC/read
 27: hkn0410:1152209:1152320 [3] NCCL INFO Connected all trees
441: hkn0732:1204159:1204268 [1] NCCL INFO Connected all rings
  2: hkn0403:1751321:1751698 [2] NCCL INFO Channel 00 : 2[ca000] -> 3[e3000] via P2P/IPC/read
 39: hkn0413:2359214:2359301 [3] NCCL INFO Connected all trees
 39: hkn0413:2359214:2359301 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 39: hkn0413:2359214:2359301 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 27: hkn0410:1152209:1152320 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 27: hkn0410:1152209:1152320 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
102: hkn0502:221554:221671 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 78: hkn0424:2940433:2940564 [2] NCCL INFO Connected all trees
102: hkn0502:221554:221671 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
387: hkn0716:100997:101122 [3] NCCL INFO Connected all trees
158: hkn0516:2908472:2908599 [2] NCCL INFO Connected all trees
183: hkn0526:1420898:1421019 [3] NCCL INFO Connected all trees
 78: hkn0424:2940433:2940564 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
158: hkn0516:2908472:2908599 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 78: hkn0424:2940433:2940564 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
158: hkn0516:2908472:2908599 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
183: hkn0526:1420898:1421019 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
387: hkn0716:100997:101122 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
183: hkn0526:1420898:1421019 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
387: hkn0716:100997:101122 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
509: hkn0816:368127:368238 [1] NCCL INFO Channel 00 : 509[4b000] -> 510[ca000] via P2P/IPC/read
  1: hkn0403:1751324:1751696 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[ca000] via P2P/IPC/read
506: hkn0815:387640:387788 [2] NCCL INFO Channel 01 : 506[ca000] -> 507[e3000] via P2P/IPC/read
438: hkn0731:1379244:1379355 [2] NCCL INFO Connected all trees
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 01 : 29[4b000] -> 30[ca000] via P2P/IPC/read
462: hkn0802:1192841:1192950 [2] NCCL INFO Channel 00 : 462[ca000] -> 463[e3000] via P2P/IPC/read
 55: hkn0418:1861683:1861785 [3] NCCL INFO Connected all trees
411: hkn0723:200377:200540 [3] NCCL INFO Connected all trees
471: hkn0804:1198115:1198243 [3] NCCL INFO Connected all trees
411: hkn0723:200377:200540 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
471: hkn0804:1198115:1198243 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
411: hkn0723:200377:200540 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
471: hkn0804:1198115:1198243 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:200389:200535 [0] NCCL INFO Channel 01 : 408[31000] -> 409[4b000] via P2P/IPC/read
 62: hkn0420:3202701:3202824 [2] NCCL INFO Connected all trees
 62: hkn0420:3202701:3202824 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 01 : 461[4b000] -> 462[ca000] via P2P/IPC/read
 62: hkn0420:3202701:3202824 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 55: hkn0418:1861683:1861785 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
510: hkn0816:368135:368243 [2] NCCL INFO Channel 00 : 510[ca000] -> 511[e3000] via P2P/IPC/read
 55: hkn0418:1861683:1861785 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
434: hkn0730:1394229:1394348 [2] NCCL INFO Connected all trees
 15: hkn0407:1808771:1808909 [3] NCCL INFO Connected all trees
434: hkn0730:1394229:1394348 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 15: hkn0407:1808771:1808909 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
434: hkn0730:1394229:1394348 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1808771:1808909 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 98: hkn0501:1320364:1320480 [2] NCCL INFO Connected all trees
509: hkn0816:368127:368238 [1] NCCL INFO Channel 01 : 509[4b000] -> 510[ca000] via P2P/IPC/read
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [receive] via NET/IBext/0
 90: hkn0427:1127651:1127785 [2] NCCL INFO Connected all trees
  2: hkn0403:1751321:1751698 [2] NCCL INFO Channel 01 : 2[ca000] -> 3[e3000] via P2P/IPC/read
 90: hkn0427:1127651:1127785 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 90: hkn0427:1127651:1127785 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 98: hkn0501:1320364:1320480 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
438: hkn0731:1379244:1379355 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 98: hkn0501:1320364:1320480 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
438: hkn0731:1379244:1379355 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [receive] via NET/IBext/0
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [receive] via NET/IBext/0
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 01 : 432[31000] -> 436[31000] [send] via NET/IBext/0
195: hkn0529:1533364:1533476 [3] NCCL INFO Connected all trees
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [receive] via NET/IBext/0
 86: hkn0426:806587:806697 [2] NCCL INFO Connected all trees
 86: hkn0426:806587:806697 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
195: hkn0529:1533364:1533476 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
110: hkn0504:33345:33443 [2] NCCL INFO Connected all trees
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [send] via NET/IBext/0
110: hkn0504:33345:33443 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 86: hkn0426:806587:806697 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 38: hkn0413:2359203:2359295 [2] NCCL INFO Connected all trees
 38: hkn0413:2359203:2359295 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:33325:33439 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [receive] via NET/IBext/0
459: hkn0801:2232488:2232616 [3] NCCL INFO Connected all trees
 38: hkn0413:2359203:2359295 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
459: hkn0801:2232488:2232616 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
110: hkn0504:33345:33443 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
459: hkn0801:2232488:2232616 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 26: hkn0410:1152222:1152317 [2] NCCL INFO Connected all trees
 26: hkn0410:1152222:1152317 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [receive] via NET/IBext/0
410: hkn0723:200364:200541 [2] NCCL INFO Connected all trees
 26: hkn0410:1152222:1152317 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
410: hkn0723:200364:200541 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [receive] via NET/IBext/0
410: hkn0723:200364:200541 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
386: hkn0716:101020:101119 [2] NCCL INFO Connected all trees
507: hkn0815:387648:387785 [3] NCCL INFO Connected all trees
386: hkn0716:101020:101119 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
507: hkn0815:387648:387785 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
386: hkn0716:101020:101119 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
507: hkn0815:387648:387785 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [send] via NET/IBext/0
182: hkn0526:1420936:1421020 [2] NCCL INFO Connected all trees
195: hkn0529:1533364:1533476 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
182: hkn0526:1420936:1421020 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
462: hkn0802:1192841:1192950 [2] NCCL INFO Channel 01 : 462[ca000] -> 463[e3000] via P2P/IPC/read
470: hkn0804:1198131:1198247 [2] NCCL INFO Connected all trees
182: hkn0526:1420936:1421020 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
470: hkn0804:1198131:1198247 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
510: hkn0816:368135:368243 [2] NCCL INFO Channel 01 : 510[ca000] -> 511[e3000] via P2P/IPC/read
470: hkn0804:1198131:1198247 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 14: hkn0407:1808755:1808914 [2] NCCL INFO Connected all trees
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [receive] via NET/IBext/0
 14: hkn0407:1808755:1808914 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 14: hkn0407:1808755:1808914 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [receive] via NET/IBext/0
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [receive] via NET/IBext/0
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [receive] via NET/IBext/0
 54: hkn0418:1861675:1861787 [2] NCCL INFO Connected all trees
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [send] via NET/IBext/0
 54: hkn0418:1861675:1861787 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
150: hkn0514:2943226:2943345 [2] NCCL INFO Connected all trees
 54: hkn0418:1861675:1861787 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
150: hkn0514:2943226:2943345 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
150: hkn0514:2943226:2943345 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 30: hkn0411:2308367:2308482 [2] NCCL INFO Channel 01 : 30[ca000] -> 31[e3000] via P2P/IPC/read
458: hkn0801:2232476:2232619 [2] NCCL INFO Connected all trees
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [send] via NET/IBext/0
  3: hkn0403:1751336:1751695 [3] NCCL INFO Connected all trees
458: hkn0801:2232476:2232619 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  3: hkn0403:1751336:1751695 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  3: hkn0403:1751336:1751695 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
458: hkn0801:2232476:2232619 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
194: hkn0529:1533376:1533479 [2] NCCL INFO Connected all trees
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [receive] via NET/IBext/0
194: hkn0529:1533376:1533479 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 31: hkn0411:2308387:2308486 [3] NCCL INFO Connected all trees
194: hkn0529:1533376:1533479 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
463: hkn0802:1192840:1192948 [3] NCCL INFO Connected all trees
463: hkn0802:1192840:1192948 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 31: hkn0411:2308387:2308486 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
463: hkn0802:1192840:1192948 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 31: hkn0411:2308387:2308486 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [send] via NET/IBext/0
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [send] via NET/IBext/0
149: hkn0514:2943234:2943343 [1] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [receive] via NET/IBext/0
100: hkn0502:221575:221672 [0] NCCL INFO Channel 01 : 96[31000] -> 100[31000] [receive] via NET/IBext/0
101: hkn0502:221555:221670 [1] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [receive] via NET/IBext/0
 42: hkn0414:1974071:1974185 [2] NCCL INFO Connected all trees
 42: hkn0414:1974071:1974185 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:387640:387788 [2] NCCL INFO Connected all trees
511: hkn0816:368147:368244 [3] NCCL INFO Connected all trees
506: hkn0815:387640:387788 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
511: hkn0816:368147:368244 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
506: hkn0815:387640:387788 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
511: hkn0816:368147:368244 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 42: hkn0414:1974071:1974185 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  7: hkn0404:1331852:1331996 [3] NCCL INFO Connected all trees
437: hkn0731:1379256:1379351 [1] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [receive] via NET/IBext/0
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [send] via NET/IBext/0
504: hkn0815:387632:387784 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [send] via NET/IBext/0
  7: hkn0404:1331852:1331996 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
384: hkn0716:101008:101117 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [send] via NET/IBext/0
  7: hkn0404:1331852:1331996 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1331844:1331992 [2] NCCL INFO Connected all trees
187: hkn0527:1341441:1341554 [3] NCCL INFO Connected all trees
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [send] via NET/IBext/0
  6: hkn0404:1331844:1331992 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  6: hkn0404:1331844:1331992 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
187: hkn0527:1341441:1341554 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [receive] via NET/IBext/0
187: hkn0527:1341441:1341554 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [receive] via NET/IBext/0
109: hkn0504:33317:33440 [1] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [send] via NET/IBext/0
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [send] via NET/IBext/0
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [receive] via NET/IBext/0
  2: hkn0403:1751321:1751698 [2] NCCL INFO Connected all trees
 30: hkn0411:2308367:2308482 [2] NCCL INFO Connected all trees
  2: hkn0403:1751321:1751698 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  2: hkn0403:1751321:1751698 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [receive] via NET/IBext/0
 30: hkn0411:2308367:2308482 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
186: hkn0527:1341433:1341555 [2] NCCL INFO Connected all trees
 30: hkn0411:2308367:2308482 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
186: hkn0527:1341433:1341555 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
186: hkn0527:1341433:1341555 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 19: hkn0408:2883195:2883322 [3] NCCL INFO Connected all trees
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [send] via NET/IBext/0
 19: hkn0408:2883195:2883322 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:806571:806694 [1] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [receive] via NET/IBext/0
 19: hkn0408:2883195:2883322 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 18: hkn0408:2883203:2883321 [2] NCCL INFO Connected all trees
403: hkn0720:4190335:4190579 [3] NCCL INFO Connected all trees
 18: hkn0408:2883203:2883321 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
403: hkn0720:4190335:4190579 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 37: hkn0413:2359194:2359299 [1] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [receive] via NET/IBext/0
462: hkn0802:1192841:1192950 [2] NCCL INFO Connected all trees
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [receive] via NET/IBext/0
462: hkn0802:1192841:1192950 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
462: hkn0802:1192841:1192950 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1861667:1861790 [1] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [receive] via NET/IBext/0
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 00 : 24[31000] -> 28[31000] [receive] via NET/IBext/0
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [receive] via NET/IBext/0
 18: hkn0408:2883203:2883321 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
403: hkn0720:4190335:4190579 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  1: hkn0403:1751324:1751696 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via P2P/IPC/read
469: hkn0804:1198123:1198240 [1] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [receive] via NET/IBext/0
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [send] via NET/IBext/0
385: hkn0716:101000:101120 [1] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [receive] via NET/IBext/0
181: hkn0526:1420907:1421018 [1] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [receive] via NET/IBext/0
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 00 : 456[31000] -> 460[31000] [receive] via NET/IBext/0
  1: hkn0403:1751324:1751696 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via P2P/IPC/read
510: hkn0816:368135:368243 [2] NCCL INFO Connected all trees
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 01 : 0[31000] -> 4[31000] [send] via NET/IBext/0
510: hkn0816:368135:368243 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
510: hkn0816:368135:368243 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  5: hkn0404:1331860:1331998 [1] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [receive] via NET/IBext/0
508: hkn0816:368125:368237 [0] NCCL INFO Channel 00 : 504[31000] -> 508[31000] [receive] via NET/IBext/0
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [send] via NET/IBext/0
509: hkn0816:368127:368238 [1] NCCL INFO Channel 00 : 509[4b000] -> 508[31000] via P2P/IPC/read
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [receive] via NET/IBext/0
402: hkn0720:4190312:4190585 [2] NCCL INFO Connected all trees
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 00 : 425[4b000] -> 426[ca000] via P2P/IPC/read
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [send] via NET/IBext/0
402: hkn0720:4190312:4190585 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:4190312:4190585 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
426: hkn0727:1338279:1338380 [2] NCCL INFO Channel 00 : 426[ca000] -> 427[e3000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [send] via NET/IBext/0
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 01 : 425[4b000] -> 426[ca000] via P2P/IPC/read
408: hkn0723:200389:200535 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [send] via NET/IBext/0
426: hkn0727:1338279:1338380 [2] NCCL INFO Channel 01 : 426[ca000] -> 427[e3000] via P2P/IPC/read
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [receive] via NET/IBext/0
427: hkn0727:1338271:1338389 [3] NCCL INFO Connected all trees
442: hkn0732:1204151:1204273 [2] NCCL INFO Connected all rings
453: hkn0736:1500847:1500961 [1] NCCL INFO Connected all rings
427: hkn0727:1338271:1338389 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 00 : 441[4b000] -> 442[ca000] via P2P/IPC/read
509: hkn0816:368127:368238 [1] NCCL INFO Channel 01 : 509[4b000] -> 508[31000] via P2P/IPC/read
427: hkn0727:1338271:1338389 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
426: hkn0727:1338279:1338380 [2] NCCL INFO Connected all trees
426: hkn0727:1338279:1338380 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
442: hkn0732:1204151:1204273 [2] NCCL INFO Channel 00 : 442[ca000] -> 443[e3000] via P2P/IPC/read
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [receive] via NET/IBext/0
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [send] via NET/IBext/0
426: hkn0727:1338279:1338380 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 01 : 441[4b000] -> 442[ca000] via P2P/IPC/read
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [send] via NET/IBext/0
442: hkn0732:1204151:1204273 [2] NCCL INFO Channel 01 : 442[ca000] -> 443[e3000] via P2P/IPC/read
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [receive] via NET/IBext/0
443: hkn0732:1204148:1204274 [3] NCCL INFO Connected all trees
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [receive] via NET/IBext/0
443: hkn0732:1204148:1204274 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
443: hkn0732:1204148:1204274 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 00 : 452[31000] -> 453[4b000] via P2P/IPC/read
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [send] via NET/IBext/0
442: hkn0732:1204151:1204273 [2] NCCL INFO Connected all trees
442: hkn0732:1204151:1204273 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
454: hkn0736:1500869:1500964 [2] NCCL INFO Connected all rings
442: hkn0732:1204151:1204273 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 01 : 452[31000] -> 453[4b000] via P2P/IPC/read
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [receive] via NET/IBext/0
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [send] via NET/IBext/0
453: hkn0736:1500847:1500961 [1] NCCL INFO Channel 00 : 453[4b000] -> 454[ca000] via P2P/IPC/read
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 00 : 45[4b000] -> 46[ca000] via P2P/IPC/read
409: hkn0723:200369:200533 [1] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [receive] via NET/IBext/0
454: hkn0736:1500869:1500964 [2] NCCL INFO Channel 00 : 454[ca000] -> 455[e3000] via P2P/IPC/read
453: hkn0736:1500847:1500961 [1] NCCL INFO Channel 01 : 453[4b000] -> 454[ca000] via P2P/IPC/read
 46: hkn0415:2488942:2489091 [2] NCCL INFO Channel 00 : 46[ca000] -> 47[e3000] via P2P/IPC/read
454: hkn0736:1500869:1500964 [2] NCCL INFO Channel 01 : 454[ca000] -> 455[e3000] via P2P/IPC/read
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 01 : 45[4b000] -> 46[ca000] via P2P/IPC/read
455: hkn0736:1500858:1500966 [3] NCCL INFO Connected all trees
 46: hkn0415:2488942:2489091 [2] NCCL INFO Channel 01 : 46[ca000] -> 47[e3000] via P2P/IPC/read
455: hkn0736:1500858:1500966 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 47: hkn0415:2488934:2489087 [3] NCCL INFO Connected all trees
455: hkn0736:1500858:1500966 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 47: hkn0415:2488934:2489087 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
454: hkn0736:1500869:1500964 [2] NCCL INFO Connected all trees
 47: hkn0415:2488934:2489087 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
505: hkn0815:387660:387783 [1] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [receive] via NET/IBext/0
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [send] via NET/IBext/0
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 00 : 424[31000] -> 433[4b000] [send] via NET/IBext/0
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [receive] via NET/IBext/0
454: hkn0736:1500869:1500964 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 46: hkn0415:2488942:2489091 [2] NCCL INFO Connected all trees
454: hkn0736:1500869:1500964 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 46: hkn0415:2488942:2489091 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [send] via NET/IBext/0
 46: hkn0415:2488942:2489091 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [receive] via NET/IBext/0
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [send] via NET/IBext/0
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [receive] via NET/IBext/0
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 00 : 40[31000] -> 44[31000] [receive] via NET/IBext/0
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [send] via NET/IBext/0
 21: hkn0409:2578197:2578308 [1] NCCL INFO Channel 00 : 21[4b000] -> 22[ca000] via P2P/IPC/read
 22: hkn0409:2578209:2578305 [2] NCCL INFO Channel 00 : 22[ca000] -> 23[e3000] via P2P/IPC/read
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 01 : 128[31000] -> 129[4b000] via P2P/IPC/read
 21: hkn0409:2578197:2578308 [1] NCCL INFO Channel 01 : 21[4b000] -> 22[ca000] via P2P/IPC/read
404: hkn0721:2291503:2291621 [0] NCCL INFO Connected all rings
 22: hkn0409:2578209:2578305 [2] NCCL INFO Channel 01 : 22[ca000] -> 23[e3000] via P2P/IPC/read
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 00 : 129[4b000] -> 130[ca000] via P2P/IPC/read
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [receive] via NET/IBext/0
 23: hkn0409:2578181:2578301 [3] NCCL INFO Connected all trees
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [send] via NET/IBext/0
453: hkn0736:1500847:1500961 [1] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [receive] via NET/IBext/0
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 00 : 84[31000] -> 89[4b000] [send] via NET/IBext/0
100: hkn0502:221575:221672 [0] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [send] via NET/IBext/0
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [send] via NET/IBext/0
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [receive] via NET/IBext/0
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [receive] via NET/IBext/0
 23: hkn0409:2578181:2578301 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [send] via NET/IBext/0
 23: hkn0409:2578181:2578301 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 22: hkn0409:2578209:2578305 [2] NCCL INFO Connected all trees
 22: hkn0409:2578209:2578305 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
130: hkn0509:3116904:3117014 [2] NCCL INFO Channel 00 : 130[ca000] -> 131[e3000] via P2P/IPC/read
 22: hkn0409:2578209:2578305 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 01 : 129[4b000] -> 130[ca000] via P2P/IPC/read
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 01 : 16[31000] -> 20[31000] [receive] via NET/IBext/0
130: hkn0509:3116904:3117014 [2] NCCL INFO Channel 01 : 130[ca000] -> 131[e3000] via P2P/IPC/read
 21: hkn0409:2578197:2578308 [1] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [receive] via NET/IBext/0
131: hkn0509:3116888:3117013 [3] NCCL INFO Connected all trees
131: hkn0509:3116888:3117013 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 00 : 404[31000] -> 405[4b000] via P2P/IPC/read
131: hkn0509:3116888:3117013 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 01 : 404[31000] -> 405[4b000] via P2P/IPC/read
130: hkn0509:3116904:3117014 [2] NCCL INFO Connected all trees
405: hkn0721:2291522:2291616 [1] NCCL INFO Connected all rings
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [receive] via NET/IBext/0
130: hkn0509:3116904:3117014 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [send] via NET/IBext/0
130: hkn0509:3116904:3117014 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [send] via NET/IBext/0
406: hkn0721:2291495:2291615 [2] NCCL INFO Connected all rings
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [receive] via NET/IBext/0
405: hkn0721:2291522:2291616 [1] NCCL INFO Channel 00 : 405[4b000] -> 406[ca000] via P2P/IPC/read
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [send] via NET/IBext/0
406: hkn0721:2291495:2291615 [2] NCCL INFO Channel 00 : 406[ca000] -> 407[e3000] via P2P/IPC/read
384: hkn0716:101008:101117 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [send] via NET/IBext/0
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 00 : 20[31000] -> 25[4b000] [send] via NET/IBext/0
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 00 : 180[31000] -> 185[4b000] [send] via NET/IBext/0
405: hkn0721:2291522:2291616 [1] NCCL INFO Channel 01 : 405[4b000] -> 406[ca000] via P2P/IPC/read
406: hkn0721:2291495:2291615 [2] NCCL INFO Channel 01 : 406[ca000] -> 407[e3000] via P2P/IPC/read
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 00 : 92[31000] -> 93[4b000] via P2P/IPC/read
407: hkn0721:2291511:2291619 [3] NCCL INFO Connected all trees
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 01 : 92[31000] -> 93[4b000] via P2P/IPC/read
407: hkn0721:2291511:2291619 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 00 : 93[4b000] -> 94[ca000] via P2P/IPC/read
407: hkn0721:2291511:2291619 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 94: hkn0428:659895:659982 [2] NCCL INFO Channel 00 : 94[ca000] -> 95[e3000] via P2P/IPC/read
406: hkn0721:2291495:2291615 [2] NCCL INFO Connected all trees
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 01 : 93[4b000] -> 94[ca000] via P2P/IPC/read
406: hkn0721:2291495:2291615 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 94: hkn0428:659895:659982 [2] NCCL INFO Channel 01 : 94[ca000] -> 95[e3000] via P2P/IPC/read
406: hkn0721:2291495:2291615 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 95: hkn0428:659881:659973 [3] NCCL INFO Connected all trees
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 01 : 400[31000] -> 404[31000] [receive] via NET/IBext/0
 95: hkn0428:659881:659973 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 95: hkn0428:659881:659973 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 00 : 57[4b000] -> 58[ca000] via P2P/IPC/read
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 00 : 88[31000] -> 92[31000] [receive] via NET/IBext/0
 58: hkn0419:1536809:1536916 [2] NCCL INFO Channel 00 : 58[ca000] -> 59[e3000] via P2P/IPC/read
 94: hkn0428:659895:659982 [2] NCCL INFO Connected all trees
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 01 : 57[4b000] -> 58[ca000] via P2P/IPC/read
 94: hkn0428:659895:659982 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 58: hkn0419:1536809:1536916 [2] NCCL INFO Channel 01 : 58[ca000] -> 59[e3000] via P2P/IPC/read
 94: hkn0428:659895:659982 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 59: hkn0419:1536808:1536921 [3] NCCL INFO Connected all trees
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [send] via NET/IBext/0
 59: hkn0419:1536808:1536921 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [receive] via NET/IBext/0
 59: hkn0419:1536808:1536921 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 58: hkn0419:1536809:1536916 [2] NCCL INFO Connected all trees
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 01 : 68[31000] -> 69[4b000] via P2P/IPC/read
 58: hkn0419:1536809:1536916 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 69: hkn0422:4145507:4145651 [1] NCCL INFO Channel 00 : 69[4b000] -> 70[ca000] via P2P/IPC/read
 58: hkn0419:1536809:1536916 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 70: hkn0422:4145499:4145645 [2] NCCL INFO Channel 00 : 70[ca000] -> 71[e3000] via P2P/IPC/read
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 00 : 56[31000] -> 60[31000] [send] via NET/IBext/0
 69: hkn0422:4145507:4145651 [1] NCCL INFO Channel 01 : 69[4b000] -> 70[ca000] via P2P/IPC/read
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 00 : 16[31000] -> 24[31000] [receive] via NET/IBext/0
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 00 : 52[31000] -> 57[4b000] [receive] via NET/IBext/0
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [receive] via NET/IBext/0
 70: hkn0422:4145499:4145645 [2] NCCL INFO Channel 01 : 70[ca000] -> 71[e3000] via P2P/IPC/read
 71: hkn0422:4145519:4145652 [3] NCCL INFO Connected all trees
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 00 : 140[31000] -> 141[4b000] via P2P/IPC/read
 71: hkn0422:4145519:4145652 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
142: hkn0512:3036655:3036775 [2] NCCL INFO Connected all rings
 71: hkn0422:4145519:4145652 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 01 : 140[31000] -> 141[4b000] via P2P/IPC/read
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [receive] via NET/IBext/0
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 00 : 141[4b000] -> 142[ca000] via P2P/IPC/read
 70: hkn0422:4145499:4145645 [2] NCCL INFO Connected all trees
142: hkn0512:3036655:3036775 [2] NCCL INFO Channel 00 : 142[ca000] -> 143[e3000] via P2P/IPC/read
504: hkn0815:387632:387784 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [receive] via NET/IBext/0
 70: hkn0422:4145499:4145645 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 00 : 432[31000] -> 440[31000] [receive] via NET/IBext/0
 70: hkn0422:4145499:4145645 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4145507:4145651 [1] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [receive] via NET/IBext/0
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 01 : 141[4b000] -> 142[ca000] via P2P/IPC/read
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [send] via NET/IBext/0
142: hkn0512:3036655:3036775 [2] NCCL INFO Channel 01 : 142[ca000] -> 143[e3000] via P2P/IPC/read
143: hkn0512:3036675:3036769 [3] NCCL INFO Connected all trees
176: hkn0525:979338:979432 [0] NCCL INFO Channel 01 : 176[31000] -> 177[4b000] via P2P/IPC/read
143: hkn0512:3036675:3036769 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:830570:830664 [0] NCCL INFO Channel 01 : 116[31000] -> 117[4b000] via P2P/IPC/read
143: hkn0512:3036675:3036769 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
177: hkn0525:979326:979436 [1] NCCL INFO Channel 00 : 177[4b000] -> 178[ca000] via P2P/IPC/read
142: hkn0512:3036655:3036775 [2] NCCL INFO Connected all trees
178: hkn0525:979310:979433 [2] NCCL INFO Channel 00 : 178[ca000] -> 179[e3000] via P2P/IPC/read
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 00 : 36[31000] -> 41[4b000] [send] via NET/IBext/0
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 00 : 452[31000] -> 457[4b000] [send] via NET/IBext/0
142: hkn0512:3036655:3036775 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
177: hkn0525:979326:979436 [1] NCCL INFO Channel 01 : 177[4b000] -> 178[ca000] via P2P/IPC/read
408: hkn0723:200389:200535 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [receive] via NET/IBext/0
142: hkn0512:3036655:3036775 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [receive] via NET/IBext/0
178: hkn0525:979310:979433 [2] NCCL INFO Channel 01 : 178[ca000] -> 179[e3000] via P2P/IPC/read
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [send] via NET/IBext/0
179: hkn0525:979318:979438 [3] NCCL INFO Connected all trees
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [receive] via NET/IBext/0
179: hkn0525:979318:979438 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
179: hkn0525:979318:979438 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
117: hkn0506:830562:830672 [1] NCCL INFO Channel 00 : 117[4b000] -> 118[ca000] via P2P/IPC/read
178: hkn0525:979310:979433 [2] NCCL INFO Connected all trees
118: hkn0506:830582:830669 [2] NCCL INFO Channel 00 : 118[ca000] -> 119[e3000] via P2P/IPC/read
178: hkn0525:979310:979433 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
117: hkn0506:830562:830672 [1] NCCL INFO Channel 01 : 117[4b000] -> 118[ca000] via P2P/IPC/read
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [receive] via NET/IBext/0
178: hkn0525:979310:979433 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 01 : 141[4b000] -> 148[31000] [receive] via NET/IBext/0
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [receive] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [receive] via NET/IBext/0
176: hkn0525:979338:979432 [0] NCCL INFO Channel 01 : 176[31000] -> 180[31000] [send] via NET/IBext/0
177: hkn0525:979326:979436 [1] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [receive] via NET/IBext/0
118: hkn0506:830582:830669 [2] NCCL INFO Channel 01 : 118[ca000] -> 119[e3000] via P2P/IPC/read
508: hkn0816:368125:368237 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [receive] via NET/IBext/0
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [receive] via NET/IBext/0
176: hkn0525:979338:979432 [0] NCCL INFO Channel 00 : 176[31000] -> 184[31000] [send] via NET/IBext/0
119: hkn0506:830554:830666 [3] NCCL INFO Connected all trees
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [receive] via NET/IBext/0
119: hkn0506:830554:830666 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [receive] via NET/IBext/0
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [send] via NET/IBext/0
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [send] via NET/IBext/0
177: hkn0525:979326:979436 [1] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [send] via NET/IBext/0
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [receive] via NET/IBext/0
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 01 : 77[4b000] -> 84[31000] [receive] via NET/IBext/0
119: hkn0506:830554:830666 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 01 : 476[31000] -> 477[4b000] via P2P/IPC/read
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 01 : 68[31000] -> 76[31000] [send] via NET/IBext/0
118: hkn0506:830582:830669 [2] NCCL INFO Connected all trees
118: hkn0506:830582:830669 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 00 : 477[4b000] -> 478[ca000] via P2P/IPC/read
118: hkn0506:830582:830669 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
478: hkn0806:1046839:1046949 [2] NCCL INFO Channel 00 : 478[ca000] -> 479[e3000] via P2P/IPC/read
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 01 : 45[4b000] -> 52[31000] [receive] via NET/IBext/0
116: hkn0506:830570:830664 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [receive] via NET/IBext/0
117: hkn0506:830562:830672 [1] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [receive] via NET/IBext/0
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 01 : 477[4b000] -> 478[ca000] via P2P/IPC/read
116: hkn0506:830570:830664 [0] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [send] via NET/IBext/0
478: hkn0806:1046839:1046949 [2] NCCL INFO Channel 01 : 478[ca000] -> 479[e3000] via P2P/IPC/read
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 00 : 436[31000] -> 441[4b000] [receive] via NET/IBext/0
116: hkn0506:830570:830664 [0] NCCL INFO Channel 01 : 109[4b000] -> 116[31000] [receive] via NET/IBext/0
479: hkn0806:1046823:1046948 [3] NCCL INFO Connected all trees
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 00 : 153[4b000] -> 154[ca000] via P2P/IPC/read
479: hkn0806:1046823:1046948 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 01 : 200[31000] -> 201[4b000] via P2P/IPC/read
479: hkn0806:1046823:1046948 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
154: hkn0515:2889281:2889407 [2] NCCL INFO Channel 00 : 154[ca000] -> 155[e3000] via P2P/IPC/read
478: hkn0806:1046839:1046949 [2] NCCL INFO Connected all trees
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 01 : 153[4b000] -> 154[ca000] via P2P/IPC/read
478: hkn0806:1046839:1046949 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
154: hkn0515:2889281:2889407 [2] NCCL INFO Channel 01 : 154[ca000] -> 155[e3000] via P2P/IPC/read
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 00 : 433[4b000] -> 424[31000] [send] via NET/IBext/0
176: hkn0525:979338:979432 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [receive] via NET/IBext/0
478: hkn0806:1046839:1046949 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
155: hkn0515:2889309:2889405 [3] NCCL INFO Connected all trees
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [receive] via NET/IBext/0
155: hkn0515:2889309:2889405 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 01 : 13[4b000] -> 20[31000] [receive] via NET/IBext/0
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [send] via NET/IBext/0
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [receive] via NET/IBext/0
155: hkn0515:2889309:2889405 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 00 : 152[31000] -> 156[31000] [send] via NET/IBext/0
202: hkn0531:1223078:1223201 [2] NCCL INFO Connected all rings
154: hkn0515:2889281:2889407 [2] NCCL INFO Connected all trees
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 00 : 201[4b000] -> 202[ca000] via P2P/IPC/read
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [receive] via NET/IBext/0
154: hkn0515:2889281:2889407 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
405: hkn0721:2291522:2291616 [1] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [receive] via NET/IBext/0
154: hkn0515:2889281:2889407 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 00 : 148[31000] -> 153[4b000] [receive] via NET/IBext/0
202: hkn0531:1223078:1223201 [2] NCCL INFO Channel 00 : 202[ca000] -> 203[e3000] via P2P/IPC/read
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [send] via NET/IBext/0
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [receive] via NET/IBext/0
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [send] via NET/IBext/0
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [send] via NET/IBext/0
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [send] via NET/IBext/0
177: hkn0525:979326:979436 [1] NCCL INFO Channel 00 : 177[4b000] -> 176[31000] via P2P/IPC/read
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [send] via NET/IBext/0
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [send] via NET/IBext/0
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 01 : 201[4b000] -> 202[ca000] via P2P/IPC/read
266: hkn0615:406787:406911 [2] NCCL INFO Connected all rings
202: hkn0531:1223078:1223201 [2] NCCL INFO Channel 01 : 202[ca000] -> 203[e3000] via P2P/IPC/read
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 01 : 480[31000] -> 481[4b000] via P2P/IPC/read
203: hkn0531:1223106:1223204 [3] NCCL INFO Connected all trees
265: hkn0615:406807:406907 [1] NCCL INFO Channel 00 : 265[4b000] -> 266[ca000] via P2P/IPC/read
203: hkn0531:1223106:1223204 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
264: hkn0615:406779:406906 [0] NCCL INFO Connected all rings
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 00 : 400[31000] -> 408[31000] [send] via NET/IBext/0
177: hkn0525:979326:979436 [1] NCCL INFO Channel 01 : 177[4b000] -> 176[31000] via P2P/IPC/read
203: hkn0531:1223106:1223204 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
266: hkn0615:406787:406911 [2] NCCL INFO Channel 00 : 266[ca000] -> 267[e3000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [send] via NET/IBext/0
202: hkn0531:1223078:1223201 [2] NCCL INFO Connected all trees
100: hkn0502:221575:221672 [0] NCCL INFO Channel 01 : 100[31000] -> 108[31000] [send] via NET/IBext/0
202: hkn0531:1223078:1223201 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
202: hkn0531:1223078:1223201 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:406807:406907 [1] NCCL INFO Channel 01 : 265[4b000] -> 266[ca000] via P2P/IPC/read
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [send] via NET/IBext/0
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [send] via NET/IBext/0
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [receive] via NET/IBext/0
264: hkn0615:406779:406906 [0] NCCL INFO Channel 00 : 264[31000] -> 265[4b000] via P2P/IPC/read
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [send] via NET/IBext/0
266: hkn0615:406787:406911 [2] NCCL INFO Channel 01 : 266[ca000] -> 267[e3000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [send] via NET/IBext/0
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [receive] via NET/IBext/0
264: hkn0615:406779:406906 [0] NCCL INFO Channel 01 : 264[31000] -> 265[4b000] via P2P/IPC/read
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 00 : 481[4b000] -> 482[ca000] via P2P/IPC/read
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [send] via NET/IBext/0
267: hkn0615:406795:406908 [3] NCCL INFO Connected all trees
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 00 : 433[4b000] -> 432[31000] via P2P/IPC/read
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [send] via NET/IBext/0
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [send] via NET/IBext/0
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [send] via NET/IBext/0
267: hkn0615:406795:406908 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
482: hkn0807:1011569:1011689 [2] NCCL INFO Channel 00 : 482[ca000] -> 483[e3000] via P2P/IPC/read
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [send] via NET/IBext/0
267: hkn0615:406795:406908 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
508: hkn0816:368125:368237 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [send] via NET/IBext/0
266: hkn0615:406787:406911 [2] NCCL INFO Connected all trees
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [receive] via NET/IBext/0
266: hkn0615:406787:406911 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
266: hkn0615:406787:406911 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 01 : 481[4b000] -> 482[ca000] via P2P/IPC/read
433: hkn0730:1394237:1394350 [1] NCCL INFO Channel 01 : 433[4b000] -> 432[31000] via P2P/IPC/read
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 01 : 452[31000] -> 460[31000] [send] via NET/IBext/0
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 01 : 36[31000] -> 44[31000] [send] via NET/IBext/0
265: hkn0615:406807:406907 [1] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [receive] via NET/IBext/0
264: hkn0615:406779:406906 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [send] via NET/IBext/0
482: hkn0807:1011569:1011689 [2] NCCL INFO Channel 01 : 482[ca000] -> 483[e3000] via P2P/IPC/read
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 00 : 404[31000] -> 409[4b000] [send] via NET/IBext/0
483: hkn0807:1011596:1011696 [3] NCCL INFO Connected all trees
483: hkn0807:1011596:1011696 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
205: hkn0532:916650:916971 [1] NCCL INFO Channel 00 : 205[4b000] -> 206[ca000] via P2P/IPC/read
483: hkn0807:1011596:1011696 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1765444:1765555 [0] NCCL INFO Connected all rings
482: hkn0807:1011569:1011689 [2] NCCL INFO Connected all trees
204: hkn0532:916658:916970 [0] NCCL INFO Channel 00 : 204[31000] -> 205[4b000] via P2P/IPC/read
482: hkn0807:1011569:1011689 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
206: hkn0532:916669:916966 [2] NCCL INFO Channel 00 : 206[ca000] -> 207[e3000] via P2P/IPC/read
482: hkn0807:1011569:1011689 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
205: hkn0532:916650:916971 [1] NCCL INFO Channel 01 : 205[4b000] -> 206[ca000] via P2P/IPC/read
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [send] via NET/IBext/0
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [send] via NET/IBext/0
264: hkn0615:406779:406906 [0] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [send] via NET/IBext/0
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [receive] via NET/IBext/0
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [send] via NET/IBext/0
204: hkn0532:916658:916970 [0] NCCL INFO Channel 01 : 204[31000] -> 205[4b000] via P2P/IPC/read
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [send] via NET/IBext/0
206: hkn0532:916669:916966 [2] NCCL INFO Channel 01 : 206[ca000] -> 207[e3000] via P2P/IPC/read
207: hkn0532:916642:916973 [3] NCCL INFO Connected all trees
289: hkn0624:1765436:1765548 [1] NCCL INFO Connected all rings
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [send] via NET/IBext/0
207: hkn0532:916642:916973 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
207: hkn0532:916642:916973 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 00 : 288[31000] -> 289[4b000] via P2P/IPC/read
206: hkn0532:916669:916966 [2] NCCL INFO Connected all trees
290: hkn0624:1765428:1765554 [2] NCCL INFO Connected all rings
206: hkn0532:916669:916966 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 01 : 288[31000] -> 289[4b000] via P2P/IPC/read
206: hkn0532:916669:916966 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 00 : 289[4b000] -> 290[ca000] via P2P/IPC/read
204: hkn0532:916658:916970 [0] NCCL INFO Channel 00 : 200[31000] -> 204[31000] [receive] via NET/IBext/0
290: hkn0624:1765428:1765554 [2] NCCL INFO Channel 00 : 290[ca000] -> 291[e3000] via P2P/IPC/read
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 00 : 401[4b000] -> 400[31000] via P2P/IPC/read
205: hkn0532:916650:916971 [1] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [send] via NET/IBext/0
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 01 : 461[4b000] -> 468[31000] [receive] via NET/IBext/0
204: hkn0532:916658:916970 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [receive] via NET/IBext/0
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 01 : 289[4b000] -> 290[ca000] via P2P/IPC/read
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 00 : 145[4b000] -> 146[ca000] via P2P/IPC/read
290: hkn0624:1765428:1765554 [2] NCCL INFO Channel 01 : 290[ca000] -> 291[e3000] via P2P/IPC/read
146: hkn0513:3005437:3005564 [2] NCCL INFO Channel 00 : 146[ca000] -> 147[e3000] via P2P/IPC/read
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [receive] via NET/IBext/0
291: hkn0624:1765456:1765549 [3] NCCL INFO Connected all trees
291: hkn0624:1765456:1765549 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 01 : 145[4b000] -> 146[ca000] via P2P/IPC/read
291: hkn0624:1765456:1765549 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
146: hkn0513:3005437:3005564 [2] NCCL INFO Channel 01 : 146[ca000] -> 147[e3000] via P2P/IPC/read
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [send] via NET/IBext/0
290: hkn0624:1765428:1765554 [2] NCCL INFO Connected all trees
290: hkn0624:1765428:1765554 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
147: hkn0513:3005453:3005555 [3] NCCL INFO Connected all trees
290: hkn0624:1765428:1765554 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
147: hkn0513:3005453:3005555 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [send] via NET/IBext/0
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [send] via NET/IBext/0
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [receive] via NET/IBext/0
147: hkn0513:3005453:3005555 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
401: hkn0720:4190323:4190580 [1] NCCL INFO Channel 01 : 401[4b000] -> 400[31000] via P2P/IPC/read
146: hkn0513:3005437:3005564 [2] NCCL INFO Connected all trees
146: hkn0513:3005437:3005564 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [send] via NET/IBext/0
146: hkn0513:3005437:3005564 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 01 : 144[31000] -> 148[31000] [send] via NET/IBext/0
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 01 : 132[31000] -> 133[4b000] via P2P/IPC/read
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [receive] via NET/IBext/0
133: hkn0510:2754575:2754694 [1] NCCL INFO Channel 00 : 133[4b000] -> 134[ca000] via P2P/IPC/read
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 00 : 144[31000] -> 152[31000] [send] via NET/IBext/0
134: hkn0510:2754583:2754692 [2] NCCL INFO Channel 00 : 134[ca000] -> 135[e3000] via P2P/IPC/read
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [send] via NET/IBext/0
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [send] via NET/IBext/0
109: hkn0504:33317:33440 [1] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [receive] via NET/IBext/0
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [send] via NET/IBext/0
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 00 : 145[4b000] -> 144[31000] via P2P/IPC/read
133: hkn0510:2754575:2754694 [1] NCCL INFO Channel 01 : 133[4b000] -> 134[ca000] via P2P/IPC/read
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [receive] via NET/IBext/0
134: hkn0510:2754583:2754692 [2] NCCL INFO Channel 01 : 134[ca000] -> 135[e3000] via P2P/IPC/read
145: hkn0513:3005445:3005561 [1] NCCL INFO Channel 01 : 145[4b000] -> 144[31000] via P2P/IPC/read
135: hkn0510:2754567:2754688 [3] NCCL INFO Connected all trees
135: hkn0510:2754567:2754688 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 00 : 121[4b000] -> 122[ca000] via P2P/IPC/read
135: hkn0510:2754567:2754688 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:702329:702425 [1] NCCL INFO Channel 00 : 253[4b000] -> 254[ca000] via P2P/IPC/read
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [receive] via NET/IBext/0
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [receive] via NET/IBext/0
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [receive] via NET/IBext/0
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 01 : 140[31000] -> 156[31000] [send] via NET/IBext/0
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [send] via NET/IBext/0
134: hkn0510:2754583:2754692 [2] NCCL INFO Connected all trees
134: hkn0510:2754583:2754692 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
122: hkn0507:3179573:3179686 [2] NCCL INFO Channel 00 : 122[ca000] -> 123[e3000] via P2P/IPC/read
134: hkn0510:2754583:2754692 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 01 : 121[4b000] -> 122[ca000] via P2P/IPC/read
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 01 : 128[31000] -> 132[31000] [receive] via NET/IBext/0
122: hkn0507:3179573:3179686 [2] NCCL INFO Channel 01 : 122[ca000] -> 123[e3000] via P2P/IPC/read
133: hkn0510:2754575:2754694 [1] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [receive] via NET/IBext/0
123: hkn0507:3179565:3179693 [3] NCCL INFO Connected all trees
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [send] via NET/IBext/0
123: hkn0507:3179565:3179693 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 01 : 132[31000] -> 140[31000] [send] via NET/IBext/0
123: hkn0507:3179565:3179693 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [receive] via NET/IBext/0
122: hkn0507:3179573:3179686 [2] NCCL INFO Connected all trees
122: hkn0507:3179573:3179686 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
254: hkn0611:702301:702422 [2] NCCL INFO Channel 00 : 254[ca000] -> 255[e3000] via P2P/IPC/read
122: hkn0507:3179573:3179686 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:702329:702425 [1] NCCL INFO Channel 01 : 253[4b000] -> 254[ca000] via P2P/IPC/read
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [send] via NET/IBext/0
254: hkn0611:702301:702422 [2] NCCL INFO Channel 01 : 254[ca000] -> 255[e3000] via P2P/IPC/read
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 00 : 116[31000] -> 121[4b000] [receive] via NET/IBext/0
255: hkn0611:702317:702419 [3] NCCL INFO Connected all trees
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [receive] via NET/IBext/0
255: hkn0611:702317:702419 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [send] via NET/IBext/0
255: hkn0611:702317:702419 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [receive] via NET/IBext/0
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [receive] via NET/IBext/0
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [send] via NET/IBext/0
254: hkn0611:702301:702422 [2] NCCL INFO Connected all trees
254: hkn0611:702301:702422 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
254: hkn0611:702301:702422 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 01 : 276[31000] -> 277[4b000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Connected all rings
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 00 : 169[4b000] -> 170[ca000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Channel 00 : 252[31000] -> 253[4b000] via P2P/IPC/read
277: hkn0621:1984016:1984143 [1] NCCL INFO Channel 00 : 277[4b000] -> 278[ca000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Channel 01 : 252[31000] -> 253[4b000] via P2P/IPC/read
278: hkn0621:1984032:1984138 [2] NCCL INFO Channel 00 : 278[ca000] -> 279[e3000] via P2P/IPC/read
253: hkn0611:702329:702425 [1] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [send] via NET/IBext/0
277: hkn0621:1984016:1984143 [1] NCCL INFO Channel 01 : 277[4b000] -> 278[ca000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [receive] via NET/IBext/0
278: hkn0621:1984032:1984138 [2] NCCL INFO Channel 01 : 278[ca000] -> 279[e3000] via P2P/IPC/read
252: hkn0611:702309:702428 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [receive] via NET/IBext/0
279: hkn0621:1984024:1984141 [3] NCCL INFO Connected all trees
279: hkn0621:1984024:1984141 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
170: hkn0523:1540556:1540660 [2] NCCL INFO Channel 00 : 170[ca000] -> 171[e3000] via P2P/IPC/read
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [receive] via NET/IBext/0
279: hkn0621:1984024:1984141 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 01 : 76[31000] -> 92[31000] [send] via NET/IBext/0
278: hkn0621:1984032:1984138 [2] NCCL INFO Connected all trees
278: hkn0621:1984032:1984138 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 01 : 169[4b000] -> 170[ca000] via P2P/IPC/read
278: hkn0621:1984032:1984138 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
170: hkn0523:1540556:1540660 [2] NCCL INFO Channel 01 : 170[ca000] -> 171[e3000] via P2P/IPC/read
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [receive] via NET/IBext/0
171: hkn0523:1540540:1540658 [3] NCCL INFO Connected all trees
277: hkn0621:1984016:1984143 [1] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [receive] via NET/IBext/0
171: hkn0523:1540540:1540658 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:830570:830664 [0] NCCL INFO Channel 01 : 116[31000] -> 109[4b000] [send] via NET/IBext/0
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [send] via NET/IBext/0
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [receive] via NET/IBext/0
171: hkn0523:1540540:1540658 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
170: hkn0523:1540556:1540660 [2] NCCL INFO Connected all trees
338: hkn0703:733524:733645 [2] NCCL INFO Connected all rings
170: hkn0523:1540556:1540660 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
336: hkn0703:733512:733649 [0] NCCL INFO Channel 00 : 336[31000] -> 337[4b000] via P2P/IPC/read
170: hkn0523:1540556:1540660 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
336: hkn0703:733512:733649 [0] NCCL INFO Channel 01 : 336[31000] -> 337[4b000] via P2P/IPC/read
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [send] via NET/IBext/0
337: hkn0703:733504:733651 [1] NCCL INFO Channel 00 : 337[4b000] -> 338[ca000] via P2P/IPC/read
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [receive] via NET/IBext/0
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [receive] via NET/IBext/0
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 00 : 168[31000] -> 177[4b000] [send] via NET/IBext/0
338: hkn0703:733524:733645 [2] NCCL INFO Channel 00 : 338[ca000] -> 339[e3000] via P2P/IPC/read
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 00 : 177[4b000] -> 168[31000] [receive] via NET/IBext/0
337: hkn0703:733504:733651 [1] NCCL INFO Channel 01 : 337[4b000] -> 338[ca000] via P2P/IPC/read
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 01 : 84[31000] -> 77[4b000] [send] via NET/IBext/0
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [send] via NET/IBext/0
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [send] via NET/IBext/0
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [send] via NET/IBext/0
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [receive] via NET/IBext/0
338: hkn0703:733524:733645 [2] NCCL INFO Channel 01 : 338[ca000] -> 339[e3000] via P2P/IPC/read
339: hkn0703:733496:733654 [3] NCCL INFO Connected all trees
218: hkn0601:110156:110284 [2] NCCL INFO Connected all rings
339: hkn0703:733496:733654 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
216: hkn0601:110172:110280 [0] NCCL INFO Channel 00 : 216[31000] -> 217[4b000] via P2P/IPC/read
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [receive] via NET/IBext/0
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [send] via NET/IBext/0
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 00 : 17[4b000] -> 16[31000] via P2P/IPC/read
339: hkn0703:733496:733654 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 01 : 20[31000] -> 13[4b000] [send] via NET/IBext/0
176: hkn0525:979338:979432 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [send] via NET/IBext/0
338: hkn0703:733524:733645 [2] NCCL INFO Connected all trees
216: hkn0601:110172:110280 [0] NCCL INFO Channel 01 : 216[31000] -> 217[4b000] via P2P/IPC/read
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 01 : 52[31000] -> 45[4b000] [send] via NET/IBext/0
100: hkn0502:221575:221672 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [receive] via NET/IBext/0
338: hkn0703:733524:733645 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
217: hkn0601:110184:110286 [1] NCCL INFO Channel 00 : 217[4b000] -> 218[ca000] via P2P/IPC/read
338: hkn0703:733524:733645 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
218: hkn0601:110156:110284 [2] NCCL INFO Channel 00 : 218[ca000] -> 219[e3000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [send] via NET/IBext/0
217: hkn0601:110184:110286 [1] NCCL INFO Channel 01 : 217[4b000] -> 218[ca000] via P2P/IPC/read
337: hkn0703:733504:733651 [1] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [receive] via NET/IBext/0
218: hkn0601:110156:110284 [2] NCCL INFO Channel 01 : 218[ca000] -> 219[e3000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [send] via NET/IBext/0
219: hkn0601:110164:110279 [3] NCCL INFO Connected all trees
219: hkn0601:110164:110279 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
219: hkn0601:110164:110279 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 00 : 49[4b000] -> 50[ca000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [receive] via NET/IBext/0
337: hkn0703:733504:733651 [1] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [send] via NET/IBext/0
337: hkn0703:733504:733651 [1] NCCL INFO Channel 00 : 337[4b000] -> 336[31000] via P2P/IPC/read
218: hkn0601:110156:110284 [2] NCCL INFO Connected all trees
 17: hkn0408:2883223:2883320 [1] NCCL INFO Channel 01 : 17[4b000] -> 16[31000] via P2P/IPC/read
337: hkn0703:733504:733651 [1] NCCL INFO Channel 01 : 337[4b000] -> 336[31000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [send] via NET/IBext/0
218: hkn0601:110156:110284 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
218: hkn0601:110156:110284 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 50: hkn0417:2260187:2260291 [2] NCCL INFO Channel 00 : 50[ca000] -> 51[e3000] via P2P/IPC/read
216: hkn0601:110172:110280 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [send] via NET/IBext/0
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 01 : 49[4b000] -> 50[ca000] via P2P/IPC/read
217: hkn0601:110184:110286 [1] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [receive] via NET/IBext/0
 50: hkn0417:2260187:2260291 [2] NCCL INFO Channel 01 : 50[ca000] -> 51[e3000] via P2P/IPC/read
216: hkn0601:110172:110280 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [receive] via NET/IBext/0
 51: hkn0417:2260175:2260285 [3] NCCL INFO Connected all trees
216: hkn0601:110172:110280 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [send] via NET/IBext/0
 51: hkn0417:2260175:2260285 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 51: hkn0417:2260175:2260285 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:348021:348124 [1] NCCL INFO Connected all rings
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [send] via NET/IBext/0
217: hkn0601:110184:110286 [1] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [send] via NET/IBext/0
 50: hkn0417:2260187:2260291 [2] NCCL INFO Connected all trees
 50: hkn0417:2260187:2260291 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:348013:348131 [0] NCCL INFO Channel 00 : 360[31000] -> 361[4b000] via P2P/IPC/read
204: hkn0532:916658:916970 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [send] via NET/IBext/0
 50: hkn0417:2260187:2260291 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 01 : 148[31000] -> 141[4b000] [send] via NET/IBext/0
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 01 : 48[31000] -> 52[31000] [send] via NET/IBext/0
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 00 : 40[31000] -> 49[4b000] [receive] via NET/IBext/0
362: hkn0710:348041:348125 [2] NCCL INFO Connected all rings
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 00 : 48[31000] -> 56[31000] [send] via NET/IBext/0
360: hkn0710:348013:348131 [0] NCCL INFO Channel 01 : 360[31000] -> 361[4b000] via P2P/IPC/read
265: hkn0615:406807:406907 [1] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [send] via NET/IBext/0
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [receive] via NET/IBext/0
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 00 : 49[4b000] -> 40[31000] [send] via NET/IBext/0
361: hkn0710:348021:348124 [1] NCCL INFO Channel 00 : 361[4b000] -> 362[ca000] via P2P/IPC/read
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [receive] via NET/IBext/0
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 00 : 49[4b000] -> 48[31000] via P2P/IPC/read
 49: hkn0417:2260159:2260288 [1] NCCL INFO Channel 01 : 49[4b000] -> 48[31000] via P2P/IPC/read
362: hkn0710:348041:348125 [2] NCCL INFO Channel 00 : 362[ca000] -> 363[e3000] via P2P/IPC/read
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [send] via NET/IBext/0
361: hkn0710:348021:348124 [1] NCCL INFO Channel 01 : 361[4b000] -> 362[ca000] via P2P/IPC/read
362: hkn0710:348041:348125 [2] NCCL INFO Channel 01 : 362[ca000] -> 363[e3000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 00 : 324[31000] -> 325[4b000] via P2P/IPC/read
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 01 : 4[31000] -> 12[31000] [send] via NET/IBext/0
363: hkn0710:348029:348129 [3] NCCL INFO Connected all trees
363: hkn0710:348029:348129 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1513380:1513484 [1] NCCL INFO Connected all rings
504: hkn0815:387632:387784 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [send] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO Channel 01 : 93[4b000] -> 108[31000] [receive] via NET/IBext/0
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [receive] via NET/IBext/0
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [receive] via NET/IBext/0
505: hkn0815:387660:387783 [1] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [send] via NET/IBext/0
363: hkn0710:348029:348129 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
362: hkn0710:348041:348125 [2] NCCL INFO Connected all trees
326: hkn0634:1513361:1513475 [2] NCCL INFO Connected all rings
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [receive] via NET/IBext/0
362: hkn0710:348041:348125 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:200389:200535 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [send] via NET/IBext/0
362: hkn0710:348041:348125 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:348013:348131 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [send] via NET/IBext/0
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 01 : 324[31000] -> 325[4b000] via P2P/IPC/read
361: hkn0710:348021:348124 [1] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [receive] via NET/IBext/0
325: hkn0634:1513380:1513484 [1] NCCL INFO Channel 00 : 325[4b000] -> 326[ca000] via P2P/IPC/read
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [send] via NET/IBext/0
360: hkn0710:348013:348131 [0] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [send] via NET/IBext/0
326: hkn0634:1513361:1513475 [2] NCCL INFO Channel 00 : 326[ca000] -> 327[e3000] via P2P/IPC/read
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 01 : 160[31000] -> 161[4b000] via P2P/IPC/read
360: hkn0710:348013:348131 [0] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [receive] via NET/IBext/0
325: hkn0634:1513380:1513484 [1] NCCL INFO Channel 01 : 325[4b000] -> 326[ca000] via P2P/IPC/read
361: hkn0710:348021:348124 [1] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [send] via NET/IBext/0
326: hkn0634:1513361:1513475 [2] NCCL INFO Channel 01 : 326[ca000] -> 327[e3000] via P2P/IPC/read
360: hkn0710:348013:348131 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [receive] via NET/IBext/0
327: hkn0634:1513369:1513478 [3] NCCL INFO Connected all trees
327: hkn0634:1513369:1513478 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 00 : 161[4b000] -> 162[ca000] via P2P/IPC/read
327: hkn0634:1513369:1513478 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
162: hkn0520:2705389:2705480 [2] NCCL INFO Channel 00 : 162[ca000] -> 163[e3000] via P2P/IPC/read
326: hkn0634:1513361:1513475 [2] NCCL INFO Connected all trees
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 01 : 161[4b000] -> 162[ca000] via P2P/IPC/read
326: hkn0634:1513361:1513475 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
162: hkn0520:2705389:2705480 [2] NCCL INFO Channel 01 : 162[ca000] -> 163[e3000] via P2P/IPC/read
326: hkn0634:1513361:1513475 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
163: hkn0520:2705377:2705478 [3] NCCL INFO Connected all trees
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 00 : 97[4b000] -> 96[31000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [receive] via NET/IBext/0
325: hkn0634:1513380:1513484 [1] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [receive] via NET/IBext/0
163: hkn0520:2705377:2705478 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [send] via NET/IBext/0
163: hkn0520:2705377:2705478 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
162: hkn0520:2705389:2705480 [2] NCCL INFO Connected all trees
162: hkn0520:2705389:2705480 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 00 : 113[4b000] -> 114[ca000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [send] via NET/IBext/0
162: hkn0520:2705389:2705480 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [receive] via NET/IBext/0
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [send] via NET/IBext/0
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 00 : 144[31000] -> 161[4b000] [receive] via NET/IBext/0
114: hkn0505:2296288:2296402 [2] NCCL INFO Channel 00 : 114[ca000] -> 115[e3000] via P2P/IPC/read
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 00 : 160[31000] -> 176[31000] [send] via NET/IBext/0
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 01 : 113[4b000] -> 114[ca000] via P2P/IPC/read
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 00 : 160[31000] -> 193[4b000] [send] via NET/IBext/0
114: hkn0505:2296288:2296402 [2] NCCL INFO Channel 01 : 114[ca000] -> 115[e3000] via P2P/IPC/read
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [send] via NET/IBext/0
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 00 : 161[4b000] -> 144[31000] [send] via NET/IBext/0
115: hkn0505:2296296:2296404 [3] NCCL INFO Connected all trees
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 00 : 208[31000] -> 209[4b000] via P2P/IPC/read
115: hkn0505:2296296:2296404 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 01 : 208[31000] -> 209[4b000] via P2P/IPC/read
 97: hkn0501:1320356:1320474 [1] NCCL INFO Channel 01 : 97[4b000] -> 96[31000] via P2P/IPC/read
115: hkn0505:2296296:2296404 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
114: hkn0505:2296288:2296402 [2] NCCL INFO Connected all trees
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 00 : 209[4b000] -> 210[ca000] via P2P/IPC/read
114: hkn0505:2296288:2296402 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
210: hkn0534:1140936:1141031 [2] NCCL INFO Channel 00 : 210[ca000] -> 211[e3000] via P2P/IPC/read
114: hkn0505:2296288:2296402 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
210: hkn0534:1140936:1141031 [2] NCCL INFO Channel 01 : 210[ca000] -> 211[e3000] via P2P/IPC/read
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 01 : 112[31000] -> 116[31000] [send] via NET/IBext/0
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 01 : 209[4b000] -> 210[ca000] via P2P/IPC/read
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [send] via NET/IBext/0
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [receive] via NET/IBext/0
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 00 : 112[31000] -> 120[31000] [send] via NET/IBext/0
211: hkn0534:1140916:1141035 [3] NCCL INFO Connected all trees
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 00 : 96[31000] -> 112[31000] [receive] via NET/IBext/0
211: hkn0534:1140916:1141035 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
109: hkn0504:33317:33440 [1] NCCL INFO Channel 00 : 109[4b000] -> 108[31000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [receive] via NET/IBext/0
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 01 : 29[4b000] -> 44[31000] [receive] via NET/IBext/0
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 00 : 161[4b000] -> 160[31000] via P2P/IPC/read
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [send] via NET/IBext/0
211: hkn0534:1140916:1141035 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [send] via NET/IBext/0
210: hkn0534:1140936:1141031 [2] NCCL INFO Connected all trees
409: hkn0723:200369:200533 [1] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [send] via NET/IBext/0
210: hkn0534:1140936:1141031 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 00 : 113[4b000] -> 112[31000] via P2P/IPC/read
210: hkn0534:1140936:1141031 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
113: hkn0505:2296285:2296401 [1] NCCL INFO Channel 01 : 113[4b000] -> 112[31000] via P2P/IPC/read
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [send] via NET/IBext/0
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 00 : 200[31000] -> 209[4b000] [receive] via NET/IBext/0
268: hkn0616:397357:397478 [0] NCCL INFO Channel 00 : 268[31000] -> 269[4b000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 01 : 460[31000] -> 476[31000] [send] via NET/IBext/0
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 00 : 208[31000] -> 216[31000] [send] via NET/IBext/0
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [send] via NET/IBext/0
270: hkn0616:397349:397480 [2] NCCL INFO Connected all rings
268: hkn0616:397357:397478 [0] NCCL INFO Channel 01 : 268[31000] -> 269[4b000] via P2P/IPC/read
 66: hkn0421:2172265:2172522 [2] NCCL INFO Channel 01 : 66[ca000] -> 67[e3000] via P2P/IPC/read
109: hkn0504:33317:33440 [1] NCCL INFO Channel 01 : 109[4b000] -> 108[31000] via P2P/IPC/read
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 00 : 209[4b000] -> 200[31000] [send] via NET/IBext/0
161: hkn0520:2705368:2705469 [1] NCCL INFO Channel 01 : 161[4b000] -> 160[31000] via P2P/IPC/read
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 00 : 209[4b000] -> 208[31000] via P2P/IPC/read
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [receive] via NET/IBext/0
209: hkn0534:1140924:1141030 [1] NCCL INFO Channel 01 : 209[4b000] -> 208[31000] via P2P/IPC/read
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [receive] via NET/IBext/0
269: hkn0616:397377:397476 [1] NCCL INFO Channel 00 : 269[4b000] -> 270[ca000] via P2P/IPC/read
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 00 : 77[4b000] -> 76[31000] via P2P/IPC/read
270: hkn0616:397349:397480 [2] NCCL INFO Channel 00 : 270[ca000] -> 271[e3000] via P2P/IPC/read
270: hkn0616:397349:397480 [2] NCCL INFO Channel 01 : 270[ca000] -> 271[e3000] via P2P/IPC/read
 67: hkn0421:2172249:2172523 [3] NCCL INFO Connected all trees
269: hkn0616:397377:397476 [1] NCCL INFO Channel 01 : 269[4b000] -> 270[ca000] via P2P/IPC/read
 67: hkn0421:2172249:2172523 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
271: hkn0616:397365:397472 [3] NCCL INFO Connected all trees
 67: hkn0421:2172249:2172523 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
271: hkn0616:397365:397472 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 66: hkn0421:2172265:2172522 [2] NCCL INFO Connected all trees
271: hkn0616:397365:397472 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 66: hkn0421:2172265:2172522 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
270: hkn0616:397349:397480 [2] NCCL INFO Connected all trees
 66: hkn0421:2172265:2172522 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 00 : 13[4b000] -> 12[31000] via P2P/IPC/read
270: hkn0616:397349:397480 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
270: hkn0616:397349:397480 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 01 : 64[31000] -> 68[31000] [send] via NET/IBext/0
268: hkn0616:397357:397478 [0] NCCL INFO Channel 00 : 264[31000] -> 268[31000] [receive] via NET/IBext/0
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [receive] via NET/IBext/0
269: hkn0616:397377:397476 [1] NCCL INFO Channel 01 : 269[4b000] -> 276[31000] [send] via NET/IBext/0
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 00 : 64[31000] -> 96[31000] [send] via NET/IBext/0
268: hkn0616:397357:397478 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [receive] via NET/IBext/0
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [send] via NET/IBext/0
 77: hkn0424:2940449:2940563 [1] NCCL INFO Channel 01 : 77[4b000] -> 76[31000] via P2P/IPC/read
269: hkn0616:397377:397476 [1] NCCL INFO Channel 01 : 276[31000] -> 269[4b000] [receive] via NET/IBext/0
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 00 : 64[31000] -> 129[4b000] [send] via NET/IBext/0
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 01 : 196[31000] -> 197[4b000] via P2P/IPC/read
197: hkn0530:1250643:1250765 [1] NCCL INFO Channel 00 : 197[4b000] -> 198[ca000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 00 : 173[4b000] -> 174[ca000] via P2P/IPC/read
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 00 : 45[4b000] -> 44[31000] via P2P/IPC/read
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [receive] via NET/IBext/0
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [receive] via NET/IBext/0
269: hkn0616:397377:397476 [1] NCCL INFO Channel 00 : 269[4b000] -> 268[31000] via P2P/IPC/read
198: hkn0530:1250651:1250763 [2] NCCL INFO Channel 00 : 198[ca000] -> 199[e3000] via P2P/IPC/read
174: hkn0524:1126288:1126393 [2] NCCL INFO Channel 00 : 174[ca000] -> 175[e3000] via P2P/IPC/read
264: hkn0615:406779:406906 [0] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [receive] via NET/IBext/0
197: hkn0530:1250643:1250765 [1] NCCL INFO Channel 01 : 197[4b000] -> 198[ca000] via P2P/IPC/read
198: hkn0530:1250651:1250763 [2] NCCL INFO Channel 01 : 198[ca000] -> 199[e3000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 01 : 173[4b000] -> 174[ca000] via P2P/IPC/read
 13: hkn0407:1808783:1808911 [1] NCCL INFO Channel 01 : 13[4b000] -> 12[31000] via P2P/IPC/read
199: hkn0530:1250659:1250771 [3] NCCL INFO Connected all trees
199: hkn0530:1250659:1250771 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
174: hkn0524:1126288:1126393 [2] NCCL INFO Channel 01 : 174[ca000] -> 175[e3000] via P2P/IPC/read
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 01 : 468[31000] -> 461[4b000] [send] via NET/IBext/0
199: hkn0530:1250659:1250771 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
198: hkn0530:1250651:1250763 [2] NCCL INFO Connected all trees
175: hkn0524:1126280:1126395 [3] NCCL INFO Connected all trees
198: hkn0530:1250651:1250763 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
175: hkn0524:1126280:1126395 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
198: hkn0530:1250651:1250763 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
175: hkn0524:1126280:1126395 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 01 : 192[31000] -> 196[31000] [receive] via NET/IBext/0
174: hkn0524:1126288:1126393 [2] NCCL INFO Connected all trees
 45: hkn0415:2488962:2489090 [1] NCCL INFO Channel 01 : 45[4b000] -> 44[31000] via P2P/IPC/read
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 00 : 289[4b000] -> 288[31000] via P2P/IPC/read
269: hkn0616:397377:397476 [1] NCCL INFO Channel 01 : 269[4b000] -> 268[31000] via P2P/IPC/read
197: hkn0530:1250643:1250765 [1] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [receive] via NET/IBext/0
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [receive] via NET/IBext/0
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 00 : 196[31000] -> 201[4b000] [send] via NET/IBext/0
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 01 : 196[31000] -> 204[31000] [send] via NET/IBext/0
174: hkn0524:1126288:1126393 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [receive] via NET/IBext/0
174: hkn0524:1126288:1126393 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 00 : 168[31000] -> 172[31000] [receive] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 00 : 124[31000] -> 125[4b000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 01 : 173[4b000] -> 180[31000] [send] via NET/IBext/0
222: hkn0602:3353974:3354228 [2] NCCL INFO Connected all rings
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [receive] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 01 : 124[31000] -> 125[4b000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 01 : 180[31000] -> 173[4b000] [receive] via NET/IBext/0
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 00 : 125[4b000] -> 126[ca000] via P2P/IPC/read
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 01 : 157[4b000] -> 172[31000] [receive] via NET/IBext/0
126: hkn0508:3131648:3131731 [2] NCCL INFO Channel 00 : 126[ca000] -> 127[e3000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 00 : 173[4b000] -> 172[31000] via P2P/IPC/read
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 01 : 125[4b000] -> 126[ca000] via P2P/IPC/read
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 00 : 141[4b000] -> 140[31000] via P2P/IPC/read
126: hkn0508:3131648:3131731 [2] NCCL INFO Channel 01 : 126[ca000] -> 127[e3000] via P2P/IPC/read
289: hkn0624:1765436:1765548 [1] NCCL INFO Channel 01 : 289[4b000] -> 288[31000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO Channel 01 : 173[4b000] -> 172[31000] via P2P/IPC/read
116: hkn0506:830570:830664 [0] NCCL INFO Channel 00 : 121[4b000] -> 116[31000] [receive] via NET/IBext/0
127: hkn0508:3131628:3131736 [3] NCCL INFO Connected all trees
205: hkn0532:916650:916971 [1] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [receive] via NET/IBext/0
127: hkn0508:3131628:3131736 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
127: hkn0508:3131628:3131736 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 00 : 220[31000] -> 221[4b000] via P2P/IPC/read
126: hkn0508:3131648:3131731 [2] NCCL INFO Connected all trees
126: hkn0508:3131648:3131731 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 01 : 220[31000] -> 221[4b000] via P2P/IPC/read
126: hkn0508:3131648:3131731 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 00 : 221[4b000] -> 222[ca000] via P2P/IPC/read
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [receive] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 00 : 120[31000] -> 124[31000] [receive] via NET/IBext/0
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [send] via NET/IBext/0
222: hkn0602:3353974:3354228 [2] NCCL INFO Channel 00 : 222[ca000] -> 223[e3000] via P2P/IPC/read
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 00 : 65[4b000] -> 64[31000] via P2P/IPC/read
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [receive] via NET/IBext/0
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 01 : 221[4b000] -> 222[ca000] via P2P/IPC/read
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 00 : 137[4b000] -> 138[ca000] via P2P/IPC/read
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [send] via NET/IBext/0
222: hkn0602:3353974:3354228 [2] NCCL INFO Channel 01 : 222[ca000] -> 223[e3000] via P2P/IPC/read
223: hkn0602:3353954:3354221 [3] NCCL INFO Connected all trees
138: hkn0511:3058850:3058979 [2] NCCL INFO Channel 00 : 138[ca000] -> 139[e3000] via P2P/IPC/read
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 00 : 89[4b000] -> 84[31000] [receive] via NET/IBext/0
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [send] via NET/IBext/0
223: hkn0602:3353954:3354221 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 01 : 137[4b000] -> 138[ca000] via P2P/IPC/read
141: hkn0512:3036663:3036774 [1] NCCL INFO Channel 01 : 141[4b000] -> 140[31000] via P2P/IPC/read
223: hkn0602:3353954:3354221 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3353974:3354228 [2] NCCL INFO Connected all trees
138: hkn0511:3058850:3058979 [2] NCCL INFO Channel 01 : 138[ca000] -> 139[e3000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [receive] via NET/IBext/0
222: hkn0602:3353974:3354228 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [send] via NET/IBext/0
222: hkn0602:3353974:3354228 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 00 : 216[31000] -> 220[31000] [receive] via NET/IBext/0
139: hkn0511:3058858:3058978 [3] NCCL INFO Connected all trees
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [send] via NET/IBext/0
139: hkn0511:3058858:3058978 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 65: hkn0421:2172257:2172526 [1] NCCL INFO Channel 01 : 65[4b000] -> 64[31000] via P2P/IPC/read
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 01 : 204[31000] -> 220[31000] [receive] via NET/IBext/0
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 00 : 25[4b000] -> 20[31000] [receive] via NET/IBext/0
139: hkn0511:3058858:3058978 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
138: hkn0511:3058850:3058979 [2] NCCL INFO Connected all trees
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 01 : 316[31000] -> 317[4b000] via P2P/IPC/read
138: hkn0511:3058850:3058979 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
294: hkn0626:1290959:1291053 [2] NCCL INFO Connected all rings
138: hkn0511:3058850:3058979 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 00 : 317[4b000] -> 318[ca000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 00 : 136[31000] -> 140[31000] [send] via NET/IBext/0
318: hkn0632:1751099:1751227 [2] NCCL INFO Channel 00 : 318[ca000] -> 319[e3000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [receive] via NET/IBext/0
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 00 : 132[31000] -> 137[4b000] [receive] via NET/IBext/0
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 00 : 57[4b000] -> 52[31000] [receive] via NET/IBext/0
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 00 : 136[31000] -> 145[4b000] [send] via NET/IBext/0
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [receive] via NET/IBext/0
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 00 : 145[4b000] -> 136[31000] [receive] via NET/IBext/0
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [send] via NET/IBext/0
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 01 : 317[4b000] -> 318[ca000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [receive] via NET/IBext/0
318: hkn0632:1751099:1751227 [2] NCCL INFO Channel 01 : 318[ca000] -> 319[e3000] via P2P/IPC/read
319: hkn0632:1751115:1751226 [3] NCCL INFO Connected all trees
292: hkn0626:1290939:1291061 [0] NCCL INFO Connected all rings
319: hkn0632:1751115:1751226 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 00 : 292[31000] -> 293[4b000] via P2P/IPC/read
319: hkn0632:1751115:1751226 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 01 : 292[31000] -> 293[4b000] via P2P/IPC/read
318: hkn0632:1751099:1751227 [2] NCCL INFO Connected all trees
293: hkn0626:1290947:1291055 [1] NCCL INFO Channel 00 : 293[4b000] -> 294[ca000] via P2P/IPC/read
318: hkn0632:1751099:1751227 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
294: hkn0626:1290959:1291053 [2] NCCL INFO Channel 00 : 294[ca000] -> 295[e3000] via P2P/IPC/read
318: hkn0632:1751099:1751227 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1290947:1291055 [1] NCCL INFO Channel 01 : 293[4b000] -> 294[ca000] via P2P/IPC/read
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [receive] via NET/IBext/0
294: hkn0626:1290959:1291053 [2] NCCL INFO Channel 01 : 294[ca000] -> 295[e3000] via P2P/IPC/read
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 00 : 153[4b000] -> 148[31000] [receive] via NET/IBext/0
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [send] via NET/IBext/0
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [receive] via NET/IBext/0
295: hkn0626:1290931:1291060 [3] NCCL INFO Connected all trees
295: hkn0626:1290931:1291060 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 00 : 280[31000] -> 281[4b000] via P2P/IPC/read
268: hkn0616:397357:397478 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [send] via NET/IBext/0
295: hkn0626:1290931:1291060 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 00 : 185[4b000] -> 180[31000] [receive] via NET/IBext/0
294: hkn0626:1290959:1291053 [2] NCCL INFO Connected all trees
294: hkn0626:1290959:1291053 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2012970:2013094 [1] NCCL INFO Connected all rings
294: hkn0626:1290959:1291053 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
282: hkn0622:2012978:2013091 [2] NCCL INFO Connected all rings
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 01 : 288[31000] -> 292[31000] [receive] via NET/IBext/0
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 01 : 280[31000] -> 281[4b000] via P2P/IPC/read
293: hkn0626:1290947:1291055 [1] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [receive] via NET/IBext/0
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 00 : 281[4b000] -> 282[ca000] via P2P/IPC/read
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 01 : 61[4b000] -> 92[31000] [receive] via NET/IBext/0
204: hkn0532:916658:916970 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [receive] via NET/IBext/0
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [send] via NET/IBext/0
282: hkn0622:2012978:2013091 [2] NCCL INFO Channel 00 : 282[ca000] -> 283[e3000] via P2P/IPC/read
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 01 : 281[4b000] -> 282[ca000] via P2P/IPC/read
256: hkn0612:909459:909583 [0] NCCL INFO Channel 01 : 256[31000] -> 257[4b000] via P2P/IPC/read
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [send] via NET/IBext/0
282: hkn0622:2012978:2013091 [2] NCCL INFO Channel 01 : 282[ca000] -> 283[e3000] via P2P/IPC/read
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [receive] via NET/IBext/0
283: hkn0622:2012962:2013089 [3] NCCL INFO Connected all trees
283: hkn0622:2012962:2013089 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:909451:909581 [1] NCCL INFO Channel 00 : 257[4b000] -> 258[ca000] via P2P/IPC/read
283: hkn0622:2012962:2013089 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
258: hkn0612:909479:909575 [2] NCCL INFO Channel 00 : 258[ca000] -> 259[e3000] via P2P/IPC/read
282: hkn0622:2012978:2013091 [2] NCCL INFO Connected all trees
257: hkn0612:909451:909581 [1] NCCL INFO Channel 01 : 257[4b000] -> 258[ca000] via P2P/IPC/read
282: hkn0622:2012978:2013091 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
258: hkn0612:909479:909575 [2] NCCL INFO Channel 01 : 258[ca000] -> 259[e3000] via P2P/IPC/read
282: hkn0622:2012978:2013091 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
259: hkn0612:909467:909577 [3] NCCL INFO Connected all trees
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [receive] via NET/IBext/0
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [send] via NET/IBext/0
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [send] via NET/IBext/0
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 00 : 276[31000] -> 281[4b000] [receive] via NET/IBext/0
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [receive] via NET/IBext/0
259: hkn0612:909467:909577 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [receive] via NET/IBext/0
259: hkn0612:909467:909577 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 00 : 281[4b000] -> 276[31000] [send] via NET/IBext/0
258: hkn0612:909479:909575 [2] NCCL INFO Connected all trees
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 00 : 121[4b000] -> 120[31000] via P2P/IPC/read
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [send] via NET/IBext/0
258: hkn0612:909479:909575 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
366: hkn0711:576395:576516 [2] NCCL INFO Connected all rings
258: hkn0612:909479:909575 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
364: hkn0711:576387:576519 [0] NCCL INFO Channel 00 : 364[31000] -> 365[4b000] via P2P/IPC/read
256: hkn0612:909459:909583 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [send] via NET/IBext/0
364: hkn0711:576387:576519 [0] NCCL INFO Channel 01 : 364[31000] -> 365[4b000] via P2P/IPC/read
257: hkn0612:909451:909581 [1] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [receive] via NET/IBext/0
365: hkn0711:576415:576512 [1] NCCL INFO Channel 00 : 365[4b000] -> 366[ca000] via P2P/IPC/read
256: hkn0612:909459:909583 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [send] via NET/IBext/0
366: hkn0711:576395:576516 [2] NCCL INFO Channel 00 : 366[ca000] -> 367[e3000] via P2P/IPC/read
365: hkn0711:576415:576512 [1] NCCL INFO Channel 01 : 365[4b000] -> 366[ca000] via P2P/IPC/read
286: hkn0623:1865246:1865351 [2] NCCL INFO Connected all rings
366: hkn0711:576395:576516 [2] NCCL INFO Channel 01 : 366[ca000] -> 367[e3000] via P2P/IPC/read
284: hkn0623:1865258:1865355 [0] NCCL INFO Connected all rings
367: hkn0711:576403:576515 [3] NCCL INFO Connected all trees
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 00 : 285[4b000] -> 286[ca000] via P2P/IPC/read
367: hkn0711:576403:576515 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 00 : 284[31000] -> 285[4b000] via P2P/IPC/read
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 00 : 461[4b000] -> 460[31000] via P2P/IPC/read
367: hkn0711:576403:576515 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 00 : 89[4b000] -> 88[31000] via P2P/IPC/read
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 00 : 152[31000] -> 144[31000] [receive] via NET/IBext/0
366: hkn0711:576395:576516 [2] NCCL INFO Connected all trees
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 01 : 285[4b000] -> 286[ca000] via P2P/IPC/read
121: hkn0507:3179593:3179688 [1] NCCL INFO Channel 01 : 121[4b000] -> 120[31000] via P2P/IPC/read
366: hkn0711:576395:576516 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
366: hkn0711:576395:576516 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
286: hkn0623:1865246:1865351 [2] NCCL INFO Channel 00 : 286[ca000] -> 287[e3000] via P2P/IPC/read
364: hkn0711:576387:576519 [0] NCCL INFO Channel 00 : 360[31000] -> 364[31000] [receive] via NET/IBext/0
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 01 : 284[31000] -> 285[4b000] via P2P/IPC/read
365: hkn0711:576415:576512 [1] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [send] via NET/IBext/0
286: hkn0623:1865246:1865351 [2] NCCL INFO Channel 01 : 286[ca000] -> 287[e3000] via P2P/IPC/read
108: hkn0504:33325:33439 [0] NCCL INFO Channel 01 : 108[31000] -> 93[4b000] [send] via NET/IBext/0
364: hkn0711:576387:576519 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [receive] via NET/IBext/0
287: hkn0623:1865238:1865357 [3] NCCL INFO Connected all trees
105: hkn0503:2892162:2892285 [1] NCCL INFO Connected all rings
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [receive] via NET/IBext/0
364: hkn0711:576387:576519 [0] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [receive] via NET/IBext/0
365: hkn0711:576415:576512 [1] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [receive] via NET/IBext/0
287: hkn0623:1865238:1865357 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 01 : 12[31000] -> 28[31000] [send] via NET/IBext/0
287: hkn0623:1865238:1865357 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
286: hkn0623:1865246:1865351 [2] NCCL INFO Connected all trees
106: hkn0503:2892182:2892286 [2] NCCL INFO Connected all rings
 89: hkn0427:1127663:1127792 [1] NCCL INFO Channel 01 : 89[4b000] -> 88[31000] via P2P/IPC/read
286: hkn0623:1865246:1865351 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
286: hkn0623:1865246:1865351 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 00 : 105[4b000] -> 106[ca000] via P2P/IPC/read
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 00 : 57[4b000] -> 56[31000] via P2P/IPC/read
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 00 : 281[4b000] -> 280[31000] via P2P/IPC/read
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 00 : 280[31000] -> 284[31000] [receive] via NET/IBext/0
106: hkn0503:2892182:2892286 [2] NCCL INFO Channel 00 : 106[ca000] -> 107[e3000] via P2P/IPC/read
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 00 : 25[4b000] -> 24[31000] via P2P/IPC/read
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [send] via NET/IBext/0
365: hkn0711:576415:576512 [1] NCCL INFO Channel 00 : 365[4b000] -> 364[31000] via P2P/IPC/read
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 01 : 268[31000] -> 284[31000] [receive] via NET/IBext/0
461: hkn0802:1192842:1192951 [1] NCCL INFO Channel 01 : 461[4b000] -> 460[31000] via P2P/IPC/read
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 01 : 105[4b000] -> 106[ca000] via P2P/IPC/read
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [send] via NET/IBext/0
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [receive] via NET/IBext/0
106: hkn0503:2892182:2892286 [2] NCCL INFO Channel 01 : 106[ca000] -> 107[e3000] via P2P/IPC/read
248: hkn0609:703361:703450 [0] NCCL INFO Channel 00 : 248[31000] -> 249[4b000] via P2P/IPC/read
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 00 : 153[4b000] -> 152[31000] via P2P/IPC/read
107: hkn0503:2892154:2892277 [3] NCCL INFO Connected all trees
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [receive] via NET/IBext/0
107: hkn0503:2892154:2892277 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 00 : 216[31000] -> 208[31000] [receive] via NET/IBext/0
107: hkn0503:2892154:2892277 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
106: hkn0503:2892182:2892286 [2] NCCL INFO Connected all trees
249: hkn0609:703333:703446 [1] NCCL INFO Connected all rings
106: hkn0503:2892182:2892286 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:703361:703450 [0] NCCL INFO Channel 01 : 248[31000] -> 249[4b000] via P2P/IPC/read
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [receive] via NET/IBext/0
 57: hkn0419:1536822:1536917 [1] NCCL INFO Channel 01 : 57[4b000] -> 56[31000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 00 : 24[31000] -> 16[31000] [receive] via NET/IBext/0
281: hkn0622:2012970:2013094 [1] NCCL INFO Channel 01 : 281[4b000] -> 280[31000] via P2P/IPC/read
 25: hkn0410:1152210:1152322 [1] NCCL INFO Channel 01 : 25[4b000] -> 24[31000] via P2P/IPC/read
106: hkn0503:2892182:2892286 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 00 : 193[4b000] -> 160[31000] [send] via NET/IBext/0
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 00 : 104[31000] -> 108[31000] [send] via NET/IBext/0
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 00 : 100[31000] -> 105[4b000] [receive] via NET/IBext/0
250: hkn0609:703349:703447 [2] NCCL INFO Connected all rings
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 00 : 104[31000] -> 113[4b000] [send] via NET/IBext/0
249: hkn0609:703333:703446 [1] NCCL INFO Channel 00 : 249[4b000] -> 250[ca000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [receive] via NET/IBext/0
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 00 : 113[4b000] -> 104[31000] [receive] via NET/IBext/0
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [receive] via NET/IBext/0
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 00 : 185[4b000] -> 184[31000] via P2P/IPC/read
153: hkn0515:2889289:2889409 [1] NCCL INFO Channel 01 : 153[4b000] -> 152[31000] via P2P/IPC/read
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [send] via NET/IBext/0
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [receive] via NET/IBext/0
250: hkn0609:703349:703447 [2] NCCL INFO Channel 00 : 250[ca000] -> 251[e3000] via P2P/IPC/read
249: hkn0609:703333:703446 [1] NCCL INFO Channel 01 : 249[4b000] -> 250[ca000] via P2P/IPC/read
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 00 : 236[31000] -> 237[4b000] via P2P/IPC/read
250: hkn0609:703349:703447 [2] NCCL INFO Channel 01 : 250[ca000] -> 251[e3000] via P2P/IPC/read
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 01 : 236[31000] -> 237[4b000] via P2P/IPC/read
251: hkn0609:703341:703443 [3] NCCL INFO Connected all trees
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 00 : 237[4b000] -> 238[ca000] via P2P/IPC/read
251: hkn0609:703341:703443 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
238: hkn0606:2364570:2364670 [2] NCCL INFO Channel 00 : 238[ca000] -> 239[e3000] via P2P/IPC/read
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 00 : 481[4b000] -> 480[31000] via P2P/IPC/read
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [receive] via NET/IBext/0
251: hkn0609:703341:703443 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 01 : 237[4b000] -> 238[ca000] via P2P/IPC/read
250: hkn0609:703349:703447 [2] NCCL INFO Connected all trees
238: hkn0606:2364570:2364670 [2] NCCL INFO Channel 01 : 238[ca000] -> 239[e3000] via P2P/IPC/read
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 00 : 128[31000] -> 192[31000] [receive] via NET/IBext/0
250: hkn0609:703349:703447 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
250: hkn0609:703349:703447 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
239: hkn0606:2364542:2364663 [3] NCCL INFO Connected all trees
185: hkn0527:1341461:1341561 [1] NCCL INFO Channel 01 : 185[4b000] -> 184[31000] via P2P/IPC/read
248: hkn0609:703361:703450 [0] NCCL INFO Channel 00 : 248[31000] -> 252[31000] [send] via NET/IBext/0
205: hkn0532:916650:916971 [1] NCCL INFO Channel 00 : 205[4b000] -> 204[31000] via P2P/IPC/read
249: hkn0609:703333:703446 [1] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [receive] via NET/IBext/0
248: hkn0609:703361:703450 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [receive] via NET/IBext/0
239: hkn0606:2364542:2364663 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
239: hkn0606:2364542:2364663 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 01 : 188[31000] -> 189[4b000] via P2P/IPC/read
249: hkn0609:703333:703446 [1] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [send] via NET/IBext/0
238: hkn0606:2364570:2364670 [2] NCCL INFO Connected all trees
248: hkn0609:703361:703450 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [send] via NET/IBext/0
238: hkn0606:2364570:2364670 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:703333:703446 [1] NCCL INFO Channel 00 : 249[4b000] -> 248[31000] via P2P/IPC/read
238: hkn0606:2364570:2364670 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
249: hkn0609:703333:703446 [1] NCCL INFO Channel 01 : 249[4b000] -> 248[31000] via P2P/IPC/read
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [receive] via NET/IBext/0
481: hkn0807:1011585:1011697 [1] NCCL INFO Channel 01 : 481[4b000] -> 480[31000] via P2P/IPC/read
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [send] via NET/IBext/0
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 01 : 172[31000] -> 157[4b000] [send] via NET/IBext/0
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [receive] via NET/IBext/0
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [receive] via NET/IBext/0
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [receive] via NET/IBext/0
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 00 : 189[4b000] -> 190[ca000] via P2P/IPC/read
  9: hkn0405:3199291:3199417 [1] NCCL INFO Connected all rings
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 01 : 221[4b000] -> 236[31000] [receive] via NET/IBext/0
190: hkn0528:1294206:1294325 [2] NCCL INFO Channel 00 : 190[ca000] -> 191[e3000] via P2P/IPC/read
205: hkn0532:916650:916971 [1] NCCL INFO Channel 01 : 205[4b000] -> 204[31000] via P2P/IPC/read
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 00 : 237[4b000] -> 236[31000] via P2P/IPC/read
364: hkn0711:576387:576519 [0] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [send] via NET/IBext/0
237: hkn0606:2364558:2364669 [1] NCCL INFO Channel 01 : 237[4b000] -> 236[31000] via P2P/IPC/read
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 01 : 44[31000] -> 29[4b000] [send] via NET/IBext/0
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 01 : 236[31000] -> 221[4b000] [send] via NET/IBext/0
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 01 : 189[4b000] -> 190[ca000] via P2P/IPC/read
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 00 : 8[31000] -> 9[4b000] via P2P/IPC/read
190: hkn0528:1294206:1294325 [2] NCCL INFO Channel 01 : 190[ca000] -> 191[e3000] via P2P/IPC/read
 10: hkn0405:3199307:3199411 [2] NCCL INFO Connected all rings
191: hkn0528:1294226:1294323 [3] NCCL INFO Connected all trees
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 01 : 8[31000] -> 9[4b000] via P2P/IPC/read
191: hkn0528:1294226:1294323 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 00 : 9[4b000] -> 10[ca000] via P2P/IPC/read
191: hkn0528:1294226:1294323 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 10: hkn0405:3199307:3199411 [2] NCCL INFO Channel 00 : 10[ca000] -> 11[e3000] via P2P/IPC/read
190: hkn0528:1294206:1294325 [2] NCCL INFO Connected all trees
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 01 : 9[4b000] -> 10[ca000] via P2P/IPC/read
190: hkn0528:1294206:1294325 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 10: hkn0405:3199307:3199411 [2] NCCL INFO Channel 01 : 10[ca000] -> 11[e3000] via P2P/IPC/read
190: hkn0528:1294206:1294325 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 11: hkn0405:3199299:3199420 [3] NCCL INFO Connected all trees
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 00 : 184[31000] -> 188[31000] [receive] via NET/IBext/0
 11: hkn0405:3199299:3199420 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 01 : 189[4b000] -> 220[31000] [send] via NET/IBext/0
 11: hkn0405:3199299:3199420 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [receive] via NET/IBext/0
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 01 : 156[31000] -> 188[31000] [receive] via NET/IBext/0
 10: hkn0405:3199307:3199411 [2] NCCL INFO Connected all trees
334: hkn0636:1646736:1646844 [2] NCCL INFO Connected all rings
 10: hkn0405:3199307:3199411 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 00 : 332[31000] -> 333[4b000] via P2P/IPC/read
 10: hkn0405:3199307:3199411 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 01 : 332[31000] -> 333[4b000] via P2P/IPC/read
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 00 : 8[31000] -> 12[31000] [send] via NET/IBext/0
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 00 : 333[4b000] -> 334[ca000] via P2P/IPC/read
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 00 : 4[31000] -> 9[4b000] [receive] via NET/IBext/0
334: hkn0636:1646736:1646844 [2] NCCL INFO Channel 00 : 334[ca000] -> 335[e3000] via P2P/IPC/read
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 00 : 8[31000] -> 17[4b000] [send] via NET/IBext/0
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 01 : 333[4b000] -> 334[ca000] via P2P/IPC/read
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [receive] via NET/IBext/0
334: hkn0636:1646736:1646844 [2] NCCL INFO Channel 01 : 334[ca000] -> 335[e3000] via P2P/IPC/read
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 00 : 17[4b000] -> 8[31000] [receive] via NET/IBext/0
335: hkn0636:1646728:1646847 [3] NCCL INFO Connected all trees
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [send] via NET/IBext/0
335: hkn0636:1646728:1646847 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 00 : 441[4b000] -> 436[31000] [receive] via NET/IBext/0
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [receive] via NET/IBext/0
335: hkn0636:1646728:1646847 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
370: hkn0712:287559:287664 [2] NCCL INFO Connected all rings
334: hkn0636:1646736:1646844 [2] NCCL INFO Connected all trees
368: hkn0712:287551:287669 [0] NCCL INFO Channel 00 : 368[31000] -> 369[4b000] via P2P/IPC/read
334: hkn0636:1646736:1646844 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:287551:287669 [0] NCCL INFO Channel 01 : 368[31000] -> 369[4b000] via P2P/IPC/read
334: hkn0636:1646736:1646844 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
369: hkn0712:287543:287667 [1] NCCL INFO Channel 00 : 369[4b000] -> 370[ca000] via P2P/IPC/read
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [receive] via NET/IBext/0
370: hkn0712:287559:287664 [2] NCCL INFO Channel 00 : 370[ca000] -> 371[e3000] via P2P/IPC/read
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 00 : 193[4b000] -> 192[31000] via P2P/IPC/read
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [send] via NET/IBext/0
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 01 : 324[31000] -> 332[31000] [receive] via NET/IBext/0
369: hkn0712:287543:287667 [1] NCCL INFO Channel 01 : 369[4b000] -> 370[ca000] via P2P/IPC/read
370: hkn0712:287559:287664 [2] NCCL INFO Channel 01 : 370[ca000] -> 371[e3000] via P2P/IPC/read
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 00 : 308[31000] -> 309[4b000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [receive] via NET/IBext/0
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [receive] via NET/IBext/0
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 00 : 129[4b000] -> 64[31000] [send] via NET/IBext/0
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 00 : 93[4b000] -> 92[31000] via P2P/IPC/read
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [receive] via NET/IBext/0
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [send] via NET/IBext/0
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 00 : 333[4b000] -> 332[31000] via P2P/IPC/read
371: hkn0712:287571:287663 [3] NCCL INFO Connected all trees
333: hkn0636:1646748:1646841 [1] NCCL INFO Channel 01 : 333[4b000] -> 332[31000] via P2P/IPC/read
371: hkn0712:287571:287663 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [receive] via NET/IBext/0
371: hkn0712:287571:287663 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
370: hkn0712:287559:287664 [2] NCCL INFO Connected all trees
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 01 : 308[31000] -> 309[4b000] via P2P/IPC/read
370: hkn0712:287559:287664 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
309: hkn0630:1590958:1591101 [1] NCCL INFO Channel 00 : 309[4b000] -> 310[ca000] via P2P/IPC/read
370: hkn0712:287559:287664 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
310: hkn0630:1590942:1591100 [2] NCCL INFO Channel 00 : 310[ca000] -> 311[e3000] via P2P/IPC/read
368: hkn0712:287551:287669 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [send] via NET/IBext/0
309: hkn0630:1590958:1591101 [1] NCCL INFO Channel 01 : 309[4b000] -> 310[ca000] via P2P/IPC/read
193: hkn0529:1533348:1533477 [1] NCCL INFO Channel 01 : 193[4b000] -> 192[31000] via P2P/IPC/read
369: hkn0712:287543:287667 [1] NCCL INFO Channel 00 : 360[31000] -> 369[4b000] [receive] via NET/IBext/0
368: hkn0712:287551:287669 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [send] via NET/IBext/0
310: hkn0630:1590942:1591100 [2] NCCL INFO Channel 01 : 310[ca000] -> 311[e3000] via P2P/IPC/read
311: hkn0630:1590970:1591099 [3] NCCL INFO Connected all trees
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 00 : 296[31000] -> 297[4b000] via P2P/IPC/read
369: hkn0712:287543:287667 [1] NCCL INFO Channel 00 : 369[4b000] -> 360[31000] [send] via NET/IBext/0
311: hkn0630:1590970:1591099 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 93: hkn0428:659873:659979 [1] NCCL INFO Channel 01 : 93[4b000] -> 92[31000] via P2P/IPC/read
369: hkn0712:287543:287667 [1] NCCL INFO Channel 00 : 369[4b000] -> 368[31000] via P2P/IPC/read
369: hkn0712:287543:287667 [1] NCCL INFO Channel 01 : 369[4b000] -> 368[31000] via P2P/IPC/read
311: hkn0630:1590970:1591099 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:287551:287669 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [receive] via NET/IBext/0
310: hkn0630:1590942:1591100 [2] NCCL INFO Connected all trees
368: hkn0712:287551:287669 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [send] via NET/IBext/0
310: hkn0630:1590942:1591100 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [receive] via NET/IBext/0
310: hkn0630:1590942:1591100 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [receive] via NET/IBext/0
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 01 : 296[31000] -> 297[4b000] via P2P/IPC/read
309: hkn0630:1590958:1591101 [1] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [receive] via NET/IBext/0
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 00 : 297[4b000] -> 298[ca000] via P2P/IPC/read
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [send] via NET/IBext/0
298: hkn0627:1780406:1780532 [2] NCCL INFO Channel 00 : 298[ca000] -> 299[e3000] via P2P/IPC/read
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [receive] via NET/IBext/0
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 01 : 297[4b000] -> 298[ca000] via P2P/IPC/read
116: hkn0506:830570:830664 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [send] via NET/IBext/0
298: hkn0627:1780406:1780532 [2] NCCL INFO Channel 01 : 298[ca000] -> 299[e3000] via P2P/IPC/read
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [send] via NET/IBext/0
299: hkn0627:1780422:1780529 [3] NCCL INFO Connected all trees
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [receive] via NET/IBext/0
268: hkn0616:397357:397478 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [receive] via NET/IBext/0
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [receive] via NET/IBext/0
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [receive] via NET/IBext/0
299: hkn0627:1780422:1780529 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 00 : 320[31000] -> 321[4b000] via P2P/IPC/read
299: hkn0627:1780422:1780529 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
322: hkn0633:1518843:1518959 [2] NCCL INFO Connected all rings
298: hkn0627:1780406:1780532 [2] NCCL INFO Connected all trees
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 01 : 320[31000] -> 321[4b000] via P2P/IPC/read
365: hkn0711:576415:576512 [1] NCCL INFO Channel 01 : 365[4b000] -> 364[31000] via P2P/IPC/read
298: hkn0627:1780406:1780532 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
298: hkn0627:1780406:1780532 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 00 : 321[4b000] -> 322[ca000] via P2P/IPC/read
 84: hkn0426:806579:806691 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [send] via NET/IBext/0
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [send] via NET/IBext/0
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 00 : 292[31000] -> 297[4b000] [receive] via NET/IBext/0
322: hkn0633:1518843:1518959 [2] NCCL INFO Channel 00 : 322[ca000] -> 323[e3000] via P2P/IPC/read
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [send] via NET/IBext/0
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 01 : 321[4b000] -> 322[ca000] via P2P/IPC/read
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [receive] via NET/IBext/0
322: hkn0633:1518843:1518959 [2] NCCL INFO Channel 01 : 322[ca000] -> 323[e3000] via P2P/IPC/read
323: hkn0633:1518851:1518965 [3] NCCL INFO Connected all trees
382: hkn0715:394402:394547 [2] NCCL INFO Connected all rings
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [send] via NET/IBext/0
323: hkn0633:1518851:1518965 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [receive] via NET/IBext/0
323: hkn0633:1518851:1518965 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
322: hkn0633:1518843:1518959 [2] NCCL INFO Connected all trees
380: hkn0715:394410:394546 [0] NCCL INFO Channel 00 : 380[31000] -> 381[4b000] via P2P/IPC/read
322: hkn0633:1518843:1518959 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:394410:394546 [0] NCCL INFO Channel 01 : 380[31000] -> 381[4b000] via P2P/IPC/read
322: hkn0633:1518843:1518959 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
381: hkn0715:394422:394551 [1] NCCL INFO Channel 00 : 381[4b000] -> 382[ca000] via P2P/IPC/read
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 01 : 320[31000] -> 324[31000] [send] via NET/IBext/0
381: hkn0715:394422:394551 [1] NCCL INFO Channel 01 : 381[4b000] -> 382[ca000] via P2P/IPC/read
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [receive] via NET/IBext/0
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 00 : 288[31000] -> 321[4b000] [receive] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [send] via NET/IBext/0
382: hkn0715:394402:394547 [2] NCCL INFO Channel 00 : 382[ca000] -> 383[e3000] via P2P/IPC/read
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 00 : 221[4b000] -> 220[31000] via P2P/IPC/read
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 00 : 321[4b000] -> 288[31000] [send] via NET/IBext/0
 20: hkn0409:2578189:2578309 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [send] via NET/IBext/0
382: hkn0715:394402:394547 [2] NCCL INFO Channel 01 : 382[ca000] -> 383[e3000] via P2P/IPC/read
276: hkn0621:1984044:1984134 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [send] via NET/IBext/0
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 00 : 321[4b000] -> 320[31000] via P2P/IPC/read
321: hkn0633:1518835:1518968 [1] NCCL INFO Channel 01 : 321[4b000] -> 320[31000] via P2P/IPC/read
383: hkn0715:394394:394548 [3] NCCL INFO Connected all trees
264: hkn0615:406779:406906 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [receive] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 00 : 320[31000] -> 385[4b000] [send] via NET/IBext/0
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 01 : 125[4b000] -> 188[31000] [receive] via NET/IBext/0
383: hkn0715:394394:394548 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1861695:1861793 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [send] via NET/IBext/0
383: hkn0715:394394:394548 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
382: hkn0715:394402:394547 [2] NCCL INFO Connected all trees
260: hkn0613:895195:895293 [0] NCCL INFO Channel 00 : 260[31000] -> 261[4b000] via P2P/IPC/read
382: hkn0715:394402:394547 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
260: hkn0613:895195:895293 [0] NCCL INFO Channel 01 : 260[31000] -> 261[4b000] via P2P/IPC/read
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 00 : 157[4b000] -> 156[31000] via P2P/IPC/read
382: hkn0715:394402:394547 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
108: hkn0504:33325:33439 [0] NCCL INFO Channel 01 : 108[31000] -> 100[31000] [send] via NET/IBext/0
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [receive] via NET/IBext/0
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 00 : 129[4b000] -> 128[31000] via P2P/IPC/read
380: hkn0715:394410:394546 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [receive] via NET/IBext/0
221: hkn0602:3353962:3354225 [1] NCCL INFO Channel 01 : 221[4b000] -> 220[31000] via P2P/IPC/read
381: hkn0715:394422:394551 [1] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [send] via NET/IBext/0
148: hkn0514:2943218:2943338 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [send] via NET/IBext/0
380: hkn0715:394410:394546 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [receive] via NET/IBext/0
261: hkn0613:895175:895292 [1] NCCL INFO Connected all rings
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 01 : 164[31000] -> 165[4b000] via P2P/IPC/read
262: hkn0613:895183:895295 [2] NCCL INFO Connected all rings
165: hkn0521:1190302:1190437 [1] NCCL INFO Channel 00 : 165[4b000] -> 166[ca000] via P2P/IPC/read
261: hkn0613:895175:895292 [1] NCCL INFO Channel 00 : 261[4b000] -> 262[ca000] via P2P/IPC/read
166: hkn0521:1190294:1190442 [2] NCCL INFO Channel 00 : 166[ca000] -> 167[e3000] via P2P/IPC/read
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 00 : 441[4b000] -> 440[31000] via P2P/IPC/read
262: hkn0613:895183:895295 [2] NCCL INFO Channel 00 : 262[ca000] -> 263[e3000] via P2P/IPC/read
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [receive] via NET/IBext/0
261: hkn0613:895175:895292 [1] NCCL INFO Channel 01 : 261[4b000] -> 262[ca000] via P2P/IPC/read
262: hkn0613:895183:895295 [2] NCCL INFO Channel 01 : 262[ca000] -> 263[e3000] via P2P/IPC/read
165: hkn0521:1190302:1190437 [1] NCCL INFO Channel 01 : 165[4b000] -> 166[ca000] via P2P/IPC/read
157: hkn0516:2908488:2908596 [1] NCCL INFO Channel 01 : 157[4b000] -> 156[31000] via P2P/IPC/read
263: hkn0613:895167:895298 [3] NCCL INFO Connected all trees
263: hkn0613:895167:895298 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
166: hkn0521:1190294:1190442 [2] NCCL INFO Channel 01 : 166[ca000] -> 167[e3000] via P2P/IPC/read
263: hkn0613:895167:895298 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
167: hkn0521:1190314:1190440 [3] NCCL INFO Connected all trees
262: hkn0613:895183:895295 [2] NCCL INFO Connected all trees
167: hkn0521:1190314:1190440 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
262: hkn0613:895183:895295 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
167: hkn0521:1190314:1190440 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
262: hkn0613:895183:895295 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
166: hkn0521:1190294:1190442 [2] NCCL INFO Connected all trees
260: hkn0613:895195:895293 [0] NCCL INFO Channel 01 : 256[31000] -> 260[31000] [receive] via NET/IBext/0
166: hkn0521:1190294:1190442 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
129: hkn0509:3116896:3117018 [1] NCCL INFO Channel 01 : 129[4b000] -> 128[31000] via P2P/IPC/read
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [receive] via NET/IBext/0
180: hkn0526:1420918:1421023 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [send] via NET/IBext/0
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 00 : 409[4b000] -> 404[31000] [receive] via NET/IBext/0
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [send] via NET/IBext/0
261: hkn0613:895175:895292 [1] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [receive] via NET/IBext/0
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 00 : 477[4b000] -> 476[31000] via P2P/IPC/read
217: hkn0601:110184:110286 [1] NCCL INFO Channel 00 : 217[4b000] -> 216[31000] via P2P/IPC/read
308: hkn0630:1590950:1591102 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [send] via NET/IBext/0
260: hkn0613:895195:895293 [0] NCCL INFO Channel 00 : 260[31000] -> 265[4b000] [send] via NET/IBext/0
505: hkn0815:387660:387783 [1] NCCL INFO Channel 00 : 505[4b000] -> 504[31000] via P2P/IPC/read
441: hkn0732:1204159:1204268 [1] NCCL INFO Channel 01 : 441[4b000] -> 440[31000] via P2P/IPC/read
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 01 : 92[31000] -> 61[4b000] [send] via NET/IBext/0
260: hkn0613:895195:895293 [0] NCCL INFO Channel 01 : 260[31000] -> 268[31000] [send] via NET/IBext/0
336: hkn0703:733512:733649 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [receive] via NET/IBext/0
260: hkn0613:895195:895293 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [receive] via NET/IBext/0
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [receive] via NET/IBext/0
166: hkn0521:1190294:1190442 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 01 : 160[31000] -> 164[31000] [receive] via NET/IBext/0
358: hkn0708:405723:405866 [2] NCCL INFO Connected all rings
165: hkn0521:1190302:1190437 [1] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [receive] via NET/IBext/0
356: hkn0708:405715:405864 [0] NCCL INFO Channel 00 : 356[31000] -> 357[4b000] via P2P/IPC/read
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 00 : 164[31000] -> 169[4b000] [send] via NET/IBext/0
356: hkn0708:405715:405864 [0] NCCL INFO Channel 01 : 356[31000] -> 357[4b000] via P2P/IPC/read
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 01 : 164[31000] -> 172[31000] [send] via NET/IBext/0
357: hkn0708:405731:405869 [1] NCCL INFO Channel 00 : 357[4b000] -> 358[ca000] via P2P/IPC/read
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [receive] via NET/IBext/0
358: hkn0708:405723:405866 [2] NCCL INFO Channel 00 : 358[ca000] -> 359[e3000] via P2P/IPC/read
357: hkn0708:405731:405869 [1] NCCL INFO Channel 01 : 357[4b000] -> 358[ca000] via P2P/IPC/read
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 00 : 73[4b000] -> 74[ca000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 00 : 408[31000] -> 400[31000] [receive] via NET/IBext/0
477: hkn0806:1046851:1046947 [1] NCCL INFO Channel 01 : 477[4b000] -> 476[31000] via P2P/IPC/read
216: hkn0601:110172:110280 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [receive] via NET/IBext/0
358: hkn0708:405723:405866 [2] NCCL INFO Channel 01 : 358[ca000] -> 359[e3000] via P2P/IPC/read
505: hkn0815:387660:387783 [1] NCCL INFO Channel 01 : 505[4b000] -> 504[31000] via P2P/IPC/read
359: hkn0708:405743:405863 [3] NCCL INFO Connected all trees
144: hkn0513:3005464:3005559 [0] NCCL INFO Channel 01 : 148[31000] -> 144[31000] [receive] via NET/IBext/0
217: hkn0601:110184:110286 [1] NCCL INFO Channel 01 : 217[4b000] -> 216[31000] via P2P/IPC/read
359: hkn0708:405743:405863 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 74: hkn0423:1697354:1697472 [2] NCCL INFO Channel 00 : 74[ca000] -> 75[e3000] via P2P/IPC/read
359: hkn0708:405743:405863 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 01 : 73[4b000] -> 74[ca000] via P2P/IPC/read
358: hkn0708:405723:405866 [2] NCCL INFO Connected all trees
 74: hkn0423:1697354:1697472 [2] NCCL INFO Channel 01 : 74[ca000] -> 75[e3000] via P2P/IPC/read
358: hkn0708:405723:405866 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 75: hkn0423:1697362:1697475 [3] NCCL INFO Connected all trees
 75: hkn0423:1697362:1697475 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [receive] via NET/IBext/0
358: hkn0708:405723:405866 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:405715:405864 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [receive] via NET/IBext/0
 75: hkn0423:1697362:1697475 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:405731:405869 [1] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [receive] via NET/IBext/0
 74: hkn0423:1697354:1697472 [2] NCCL INFO Connected all trees
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 00 : 128[31000] -> 257[4b000] [send] via NET/IBext/0
356: hkn0708:405715:405864 [0] NCCL INFO Channel 00 : 356[31000] -> 361[4b000] [send] via NET/IBext/0
 74: hkn0423:1697354:1697472 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:681736:681856 [0] NCCL INFO Channel 01 : 228[31000] -> 229[4b000] via P2P/IPC/read
356: hkn0708:405715:405864 [0] NCCL INFO Channel 01 : 356[31000] -> 364[31000] [send] via NET/IBext/0
 74: hkn0423:1697354:1697472 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 01 : 220[31000] -> 189[4b000] [send] via NET/IBext/0
356: hkn0708:405715:405864 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [receive] via NET/IBext/0
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 00 : 72[31000] -> 76[31000] [send] via NET/IBext/0
229: hkn0604:681744:681864 [1] NCCL INFO Channel 00 : 229[4b000] -> 230[ca000] via P2P/IPC/read
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 01 : 28[31000] -> 60[31000] [send] via NET/IBext/0
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 00 : 68[31000] -> 73[4b000] [receive] via NET/IBext/0
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [send] via NET/IBext/0
230: hkn0604:681752:681859 [2] NCCL INFO Channel 00 : 230[ca000] -> 231[e3000] via P2P/IPC/read
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [receive] via NET/IBext/0
229: hkn0604:681744:681864 [1] NCCL INFO Channel 01 : 229[4b000] -> 230[ca000] via P2P/IPC/read
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [send] via NET/IBext/0
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [send] via NET/IBext/0
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 01 : 172[31000] -> 164[31000] [send] via NET/IBext/0
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [receive] via NET/IBext/0
230: hkn0604:681752:681859 [2] NCCL INFO Channel 01 : 230[ca000] -> 231[e3000] via P2P/IPC/read
240: hkn0607:896885:896985 [0] NCCL INFO Channel 01 : 240[31000] -> 241[4b000] via P2P/IPC/read
231: hkn0604:681764:681862 [3] NCCL INFO Connected all trees
241: hkn0607:896873:896982 [1] NCCL INFO Channel 00 : 241[4b000] -> 242[ca000] via P2P/IPC/read
231: hkn0604:681764:681862 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
242: hkn0607:896865:896980 [2] NCCL INFO Channel 00 : 242[ca000] -> 243[e3000] via P2P/IPC/read
364: hkn0711:576387:576519 [0] NCCL INFO Channel 01 : 364[31000] -> 356[31000] [send] via NET/IBext/0
231: hkn0604:681764:681862 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 01 : 44[31000] -> 36[31000] [send] via NET/IBext/0
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 01 : 284[31000] -> 316[31000] [send] via NET/IBext/0
230: hkn0604:681752:681859 [2] NCCL INFO Connected all trees
241: hkn0607:896873:896982 [1] NCCL INFO Channel 01 : 241[4b000] -> 242[ca000] via P2P/IPC/read
230: hkn0604:681752:681859 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
242: hkn0607:896865:896980 [2] NCCL INFO Channel 01 : 242[ca000] -> 243[e3000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO Channel 01 : 20[31000] -> 16[31000] [receive] via NET/IBext/0
230: hkn0604:681752:681859 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:681736:681856 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [receive] via NET/IBext/0
243: hkn0607:896857:896978 [3] NCCL INFO Connected all trees
208: hkn0534:1140908:1141032 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [receive] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [receive] via NET/IBext/0
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 00 : 176[31000] -> 160[31000] [receive] via NET/IBext/0
229: hkn0604:681744:681864 [1] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [receive] via NET/IBext/0
228: hkn0604:681736:681856 [0] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [send] via NET/IBext/0
243: hkn0607:896857:896978 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:681736:681856 [0] NCCL INFO Channel 01 : 228[31000] -> 236[31000] [send] via NET/IBext/0
243: hkn0607:896857:896978 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 00 : 56[31000] -> 48[31000] [receive] via NET/IBext/0
228: hkn0604:681736:681856 [0] NCCL INFO Channel 01 : 236[31000] -> 228[31000] [receive] via NET/IBext/0
242: hkn0607:896865:896980 [2] NCCL INFO Connected all trees
372: hkn0713:462723:462881 [0] NCCL INFO Connected all rings
242: hkn0607:896865:896980 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
373: hkn0713:462731:462877 [1] NCCL INFO Connected all rings
242: hkn0607:896865:896980 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
372: hkn0713:462723:462881 [0] NCCL INFO Channel 00 : 372[31000] -> 373[4b000] via P2P/IPC/read
240: hkn0607:896885:896985 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [send] via NET/IBext/0
374: hkn0713:462739:462878 [2] NCCL INFO Connected all rings
241: hkn0607:896873:896982 [1] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [receive] via NET/IBext/0
372: hkn0713:462723:462881 [0] NCCL INFO Channel 01 : 372[31000] -> 373[4b000] via P2P/IPC/read
240: hkn0607:896885:896985 [0] NCCL INFO Channel 00 : 240[31000] -> 248[31000] [send] via NET/IBext/0
373: hkn0713:462731:462877 [1] NCCL INFO Channel 00 : 373[4b000] -> 374[ca000] via P2P/IPC/read
241: hkn0607:896873:896982 [1] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [send] via NET/IBext/0
374: hkn0713:462739:462878 [2] NCCL INFO Channel 00 : 374[ca000] -> 375[e3000] via P2P/IPC/read
241: hkn0607:896873:896982 [1] NCCL INFO Channel 00 : 241[4b000] -> 240[31000] via P2P/IPC/read
373: hkn0713:462731:462877 [1] NCCL INFO Channel 01 : 373[4b000] -> 374[ca000] via P2P/IPC/read
374: hkn0713:462739:462878 [2] NCCL INFO Channel 01 : 374[ca000] -> 375[e3000] via P2P/IPC/read
350: hkn0706:744766:744917 [2] NCCL INFO Connected all rings
241: hkn0607:896873:896982 [1] NCCL INFO Channel 01 : 241[4b000] -> 240[31000] via P2P/IPC/read
375: hkn0713:462751:462876 [3] NCCL INFO Connected all trees
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [send] via NET/IBext/0
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 00 : 285[4b000] -> 284[31000] via P2P/IPC/read
409: hkn0723:200369:200533 [1] NCCL INFO Channel 00 : 409[4b000] -> 408[31000] via P2P/IPC/read
240: hkn0607:896885:896985 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [receive] via NET/IBext/0
240: hkn0607:896885:896985 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [send] via NET/IBext/0
375: hkn0713:462751:462876 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
375: hkn0713:462751:462876 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:744758:744910 [0] NCCL INFO Connected all rings
374: hkn0713:462739:462878 [2] NCCL INFO Connected all trees
349: hkn0706:744786:744914 [1] NCCL INFO Channel 00 : 349[4b000] -> 350[ca000] via P2P/IPC/read
374: hkn0713:462739:462878 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
348: hkn0706:744758:744910 [0] NCCL INFO Channel 00 : 348[31000] -> 349[4b000] via P2P/IPC/read
374: hkn0713:462739:462878 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
350: hkn0706:744766:744917 [2] NCCL INFO Channel 00 : 350[ca000] -> 351[e3000] via P2P/IPC/read
372: hkn0713:462723:462881 [0] NCCL INFO Channel 01 : 368[31000] -> 372[31000] [receive] via NET/IBext/0
349: hkn0706:744786:744914 [1] NCCL INFO Channel 01 : 349[4b000] -> 350[ca000] via P2P/IPC/read
373: hkn0713:462731:462877 [1] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [receive] via NET/IBext/0
348: hkn0706:744758:744910 [0] NCCL INFO Channel 01 : 348[31000] -> 349[4b000] via P2P/IPC/read
350: hkn0706:744766:744917 [2] NCCL INFO Channel 01 : 350[ca000] -> 351[e3000] via P2P/IPC/read
314: hkn0631:1014322:1014417 [2] NCCL INFO Connected all rings
372: hkn0713:462723:462881 [0] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [send] via NET/IBext/0
351: hkn0706:744774:744912 [3] NCCL INFO Connected all trees
372: hkn0713:462723:462881 [0] NCCL INFO Channel 01 : 365[4b000] -> 372[31000] [receive] via NET/IBext/0
351: hkn0706:744774:744912 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:462723:462881 [0] NCCL INFO Channel 01 : 372[31000] -> 365[4b000] [send] via NET/IBext/0
351: hkn0706:744774:744912 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
285: hkn0623:1865230:1865352 [1] NCCL INFO Channel 01 : 285[4b000] -> 284[31000] via P2P/IPC/read
372: hkn0713:462723:462881 [0] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [receive] via NET/IBext/0
409: hkn0723:200369:200533 [1] NCCL INFO Channel 01 : 409[4b000] -> 408[31000] via P2P/IPC/read
350: hkn0706:744766:744917 [2] NCCL INFO Connected all trees
350: hkn0706:744766:744917 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 00 : 312[31000] -> 313[4b000] via P2P/IPC/read
350: hkn0706:744766:744917 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 01 : 312[31000] -> 313[4b000] via P2P/IPC/read
468: hkn0804:1198143:1198246 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [send] via NET/IBext/0
348: hkn0706:744758:744910 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [receive] via NET/IBext/0
349: hkn0706:744786:744914 [1] NCCL INFO Channel 01 : 349[4b000] -> 364[31000] [send] via NET/IBext/0
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 00 : 313[4b000] -> 314[ca000] via P2P/IPC/read
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 00 : 29[4b000] -> 28[31000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO Channel 01 : 332[31000] -> 348[31000] [receive] via NET/IBext/0
314: hkn0631:1014322:1014417 [2] NCCL INFO Channel 00 : 314[ca000] -> 315[e3000] via P2P/IPC/read
302: hkn0628:664349:664472 [2] NCCL INFO Connected all rings
349: hkn0706:744786:744914 [1] NCCL INFO Channel 01 : 364[31000] -> 349[4b000] [receive] via NET/IBext/0
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 01 : 313[4b000] -> 314[ca000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO Channel 01 : 317[4b000] -> 348[31000] [receive] via NET/IBext/0
314: hkn0631:1014322:1014417 [2] NCCL INFO Channel 01 : 314[ca000] -> 315[e3000] via P2P/IPC/read
349: hkn0706:744786:744914 [1] NCCL INFO Channel 00 : 349[4b000] -> 348[31000] via P2P/IPC/read
315: hkn0631:1014310:1014411 [3] NCCL INFO Connected all trees
349: hkn0706:744786:744914 [1] NCCL INFO Channel 01 : 349[4b000] -> 348[31000] via P2P/IPC/read
315: hkn0631:1014310:1014411 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
315: hkn0631:1014310:1014411 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
300: hkn0628:664377:664476 [0] NCCL INFO Channel 00 : 300[31000] -> 301[4b000] via P2P/IPC/read
314: hkn0631:1014322:1014417 [2] NCCL INFO Connected all trees
300: hkn0628:664377:664476 [0] NCCL INFO Channel 01 : 300[31000] -> 301[4b000] via P2P/IPC/read
314: hkn0631:1014322:1014417 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
301: hkn0628:664357:664467 [1] NCCL INFO Channel 00 : 301[4b000] -> 302[ca000] via P2P/IPC/read
314: hkn0631:1014322:1014417 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
302: hkn0628:664349:664472 [2] NCCL INFO Channel 00 : 302[ca000] -> 303[e3000] via P2P/IPC/read
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 00 : 312[31000] -> 316[31000] [send] via NET/IBext/0
301: hkn0628:664357:664467 [1] NCCL INFO Channel 01 : 301[4b000] -> 302[ca000] via P2P/IPC/read
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 00 : 308[31000] -> 313[4b000] [receive] via NET/IBext/0
302: hkn0628:664349:664472 [2] NCCL INFO Channel 01 : 302[ca000] -> 303[e3000] via P2P/IPC/read
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [receive] via NET/IBext/0
303: hkn0628:664365:664474 [3] NCCL INFO Connected all trees
303: hkn0628:664365:664474 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
303: hkn0628:664365:664474 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
234: hkn0605:704621:704722 [2] NCCL INFO Connected all rings
 29: hkn0411:2308366:2308483 [1] NCCL INFO Channel 01 : 29[4b000] -> 28[31000] via P2P/IPC/read
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [send] via NET/IBext/0
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 00 : 313[4b000] -> 308[31000] [send] via NET/IBext/0
302: hkn0628:664349:664472 [2] NCCL INFO Connected all trees
372: hkn0713:462723:462881 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [send] via NET/IBext/0
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 00 : 313[4b000] -> 312[31000] via P2P/IPC/read
313: hkn0631:1014302:1014419 [1] NCCL INFO Channel 01 : 313[4b000] -> 312[31000] via P2P/IPC/read
302: hkn0628:664349:664472 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 00 : 61[4b000] -> 60[31000] via P2P/IPC/read
302: hkn0628:664349:664472 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
300: hkn0628:664377:664476 [0] NCCL INFO Channel 00 : 296[31000] -> 300[31000] [receive] via NET/IBext/0
232: hkn0605:704594:704721 [0] NCCL INFO Channel 00 : 232[31000] -> 233[4b000] via P2P/IPC/read
301: hkn0628:664357:664467 [1] NCCL INFO Channel 01 : 301[4b000] -> 308[31000] [send] via NET/IBext/0
232: hkn0605:704594:704721 [0] NCCL INFO Channel 01 : 232[31000] -> 233[4b000] via P2P/IPC/read
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [send] via NET/IBext/0
300: hkn0628:664377:664476 [0] NCCL INFO Channel 01 : 292[31000] -> 300[31000] [receive] via NET/IBext/0
301: hkn0628:664357:664467 [1] NCCL INFO Channel 01 : 308[31000] -> 301[4b000] [receive] via NET/IBext/0
233: hkn0605:704610:704720 [1] NCCL INFO Channel 00 : 233[4b000] -> 234[ca000] via P2P/IPC/read
436: hkn0731:1379234:1379347 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [send] via NET/IBext/0
234: hkn0605:704621:704722 [2] NCCL INFO Channel 00 : 234[ca000] -> 235[e3000] via P2P/IPC/read
301: hkn0628:664357:664467 [1] NCCL INFO Channel 00 : 301[4b000] -> 300[31000] via P2P/IPC/read
233: hkn0605:704610:704720 [1] NCCL INFO Channel 01 : 233[4b000] -> 234[ca000] via P2P/IPC/read
301: hkn0628:664357:664467 [1] NCCL INFO Channel 01 : 301[4b000] -> 300[31000] via P2P/IPC/read
234: hkn0605:704621:704722 [2] NCCL INFO Channel 01 : 234[ca000] -> 235[e3000] via P2P/IPC/read
300: hkn0628:664377:664476 [0] NCCL INFO Channel 01 : 285[4b000] -> 300[31000] [receive] via NET/IBext/0
235: hkn0605:704602:704724 [3] NCCL INFO Connected all trees
300: hkn0628:664377:664476 [0] NCCL INFO Channel 01 : 300[31000] -> 285[4b000] [send] via NET/IBext/0
235: hkn0605:704602:704724 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
385: hkn0716:101000:101120 [1] NCCL INFO Channel 00 : 385[4b000] -> 320[31000] [send] via NET/IBext/0
235: hkn0605:704602:704724 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 00 : 96[31000] -> 64[31000] [receive] via NET/IBext/0
234: hkn0605:704621:704722 [2] NCCL INFO Connected all trees
234: hkn0605:704621:704722 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
378: hkn0714:424535:424664 [2] NCCL INFO Connected all rings
 61: hkn0420:3202729:3202829 [1] NCCL INFO Channel 01 : 61[4b000] -> 60[31000] via P2P/IPC/read
234: hkn0605:704621:704722 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
232: hkn0605:704594:704721 [0] NCCL INFO Channel 00 : 232[31000] -> 236[31000] [send] via NET/IBext/0
376: hkn0714:424562:424665 [0] NCCL INFO Connected all rings
300: hkn0628:664377:664476 [0] NCCL INFO Channel 01 : 300[31000] -> 292[31000] [send] via NET/IBext/0
233: hkn0605:704610:704720 [1] NCCL INFO Channel 00 : 228[31000] -> 233[4b000] [receive] via NET/IBext/0
232: hkn0605:704594:704721 [0] NCCL INFO Channel 00 : 232[31000] -> 241[4b000] [send] via NET/IBext/0
377: hkn0714:424551:424658 [1] NCCL INFO Channel 00 : 377[4b000] -> 378[ca000] via P2P/IPC/read
378: hkn0714:424535:424664 [2] NCCL INFO Channel 00 : 378[ca000] -> 379[e3000] via P2P/IPC/read
306: hkn0629:1584560:1584666 [2] NCCL INFO Connected all rings
232: hkn0605:704594:704721 [0] NCCL INFO Channel 00 : 241[4b000] -> 232[31000] [receive] via NET/IBext/0
376: hkn0714:424562:424665 [0] NCCL INFO Channel 00 : 376[31000] -> 377[4b000] via P2P/IPC/read
233: hkn0605:704610:704720 [1] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [send] via NET/IBext/0
377: hkn0714:424551:424658 [1] NCCL INFO Channel 01 : 377[4b000] -> 378[ca000] via P2P/IPC/read
232: hkn0605:704594:704721 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [receive] via NET/IBext/0
378: hkn0714:424535:424664 [2] NCCL INFO Channel 01 : 378[ca000] -> 379[e3000] via P2P/IPC/read
376: hkn0714:424562:424665 [0] NCCL INFO Channel 01 : 376[31000] -> 377[4b000] via P2P/IPC/read
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 00 : 304[31000] -> 305[4b000] via P2P/IPC/read
379: hkn0714:424543:424659 [3] NCCL INFO Connected all trees
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 01 : 304[31000] -> 305[4b000] via P2P/IPC/read
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 00 : 189[4b000] -> 188[31000] via P2P/IPC/read
379: hkn0714:424543:424659 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
379: hkn0714:424543:424659 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 00 : 305[4b000] -> 306[ca000] via P2P/IPC/read
378: hkn0714:424535:424664 [2] NCCL INFO Connected all trees
306: hkn0629:1584560:1584666 [2] NCCL INFO Channel 00 : 306[ca000] -> 307[e3000] via P2P/IPC/read
108: hkn0504:33325:33439 [0] NCCL INFO Channel 00 : 108[31000] -> 104[31000] [send] via NET/IBext/0
378: hkn0714:424535:424664 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
378: hkn0714:424535:424664 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 01 : 305[4b000] -> 306[ca000] via P2P/IPC/read
376: hkn0714:424562:424665 [0] NCCL INFO Channel 00 : 376[31000] -> 380[31000] [send] via NET/IBext/0
306: hkn0629:1584560:1584666 [2] NCCL INFO Channel 01 : 306[ca000] -> 307[e3000] via P2P/IPC/read
377: hkn0714:424551:424658 [1] NCCL INFO Channel 00 : 372[31000] -> 377[4b000] [receive] via NET/IBext/0
307: hkn0629:1584544:1584671 [3] NCCL INFO Connected all trees
376: hkn0714:424562:424665 [0] NCCL INFO Channel 00 : 368[31000] -> 376[31000] [receive] via NET/IBext/0
307: hkn0629:1584544:1584671 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
307: hkn0629:1584544:1584671 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
244: hkn0608:478258:478384 [0] NCCL INFO Channel 01 : 244[31000] -> 245[4b000] via P2P/IPC/read
377: hkn0714:424551:424658 [1] NCCL INFO Channel 00 : 377[4b000] -> 372[31000] [send] via NET/IBext/0
306: hkn0629:1584560:1584666 [2] NCCL INFO Connected all trees
376: hkn0714:424562:424665 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [send] via NET/IBext/0
306: hkn0629:1584560:1584666 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [receive] via NET/IBext/0
377: hkn0714:424551:424658 [1] NCCL INFO Channel 00 : 377[4b000] -> 376[31000] via P2P/IPC/read
377: hkn0714:424551:424658 [1] NCCL INFO Channel 01 : 377[4b000] -> 376[31000] via P2P/IPC/read
306: hkn0629:1584560:1584666 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1294214:1294319 [1] NCCL INFO Channel 01 : 189[4b000] -> 188[31000] via P2P/IPC/read
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 01 : 304[31000] -> 308[31000] [send] via NET/IBext/0
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 00 : 296[31000] -> 305[4b000] [receive] via NET/IBext/0
245: hkn0608:478274:478386 [1] NCCL INFO Channel 00 : 245[4b000] -> 246[ca000] via P2P/IPC/read
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 00 : 304[31000] -> 312[31000] [send] via NET/IBext/0
246: hkn0608:478266:478383 [2] NCCL INFO Channel 00 : 246[ca000] -> 247[e3000] via P2P/IPC/read
245: hkn0608:478274:478386 [1] NCCL INFO Channel 01 : 245[4b000] -> 246[ca000] via P2P/IPC/read
330: hkn0635:1218111:1218207 [2] NCCL INFO Connected all rings
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 00 : 288[31000] -> 304[31000] [receive] via NET/IBext/0
246: hkn0608:478266:478383 [2] NCCL INFO Channel 01 : 246[ca000] -> 247[e3000] via P2P/IPC/read
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 00 : 305[4b000] -> 296[31000] [send] via NET/IBext/0
247: hkn0608:478286:478382 [3] NCCL INFO Connected all trees
288: hkn0624:1765444:1765555 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [receive] via NET/IBext/0
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 00 : 305[4b000] -> 304[31000] via P2P/IPC/read
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [receive] via NET/IBext/0
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 00 : 304[31000] -> 288[31000] [send] via NET/IBext/0
305: hkn0629:1584572:1584665 [1] NCCL INFO Channel 01 : 305[4b000] -> 304[31000] via P2P/IPC/read
247: hkn0608:478286:478382 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 00 : 312[31000] -> 304[31000] [receive] via NET/IBext/0
247: hkn0608:478286:478382 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
246: hkn0608:478266:478383 [2] NCCL INFO Connected all trees
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 00 : 328[31000] -> 329[4b000] via P2P/IPC/read
384: hkn0716:101008:101117 [0] NCCL INFO Channel 00 : 256[31000] -> 384[31000] [receive] via NET/IBext/0
246: hkn0608:478266:478383 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
246: hkn0608:478266:478383 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 01 : 328[31000] -> 329[4b000] via P2P/IPC/read
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 01 : 92[31000] -> 76[31000] [send] via NET/IBext/0
244: hkn0608:478258:478384 [0] NCCL INFO Channel 01 : 240[31000] -> 244[31000] [receive] via NET/IBext/0
245: hkn0608:478274:478386 [1] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [receive] via NET/IBext/0
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 00 : 329[4b000] -> 330[ca000] via P2P/IPC/read
244: hkn0608:478258:478384 [0] NCCL INFO Channel 00 : 244[31000] -> 249[4b000] [send] via NET/IBext/0
330: hkn0635:1218111:1218207 [2] NCCL INFO Channel 00 : 330[ca000] -> 331[e3000] via P2P/IPC/read
244: hkn0608:478258:478384 [0] NCCL INFO Channel 01 : 237[4b000] -> 244[31000] [receive] via NET/IBext/0
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 01 : 329[4b000] -> 330[ca000] via P2P/IPC/read
244: hkn0608:478258:478384 [0] NCCL INFO Channel 01 : 244[31000] -> 237[4b000] [send] via NET/IBext/0
330: hkn0635:1218111:1218207 [2] NCCL INFO Channel 01 : 330[ca000] -> 331[e3000] via P2P/IPC/read
331: hkn0635:1218123:1218208 [3] NCCL INFO Connected all trees
354: hkn0707:4012451:4012539 [2] NCCL INFO Connected all rings
244: hkn0608:478258:478384 [0] NCCL INFO Channel 00 : 249[4b000] -> 244[31000] [receive] via NET/IBext/0
331: hkn0635:1218123:1218208 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
244: hkn0608:478258:478384 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [send] via NET/IBext/0
331: hkn0635:1218123:1218208 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
330: hkn0635:1218111:1218207 [2] NCCL INFO Connected all trees
330: hkn0635:1218111:1218207 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 00 : 352[31000] -> 353[4b000] via P2P/IPC/read
330: hkn0635:1218111:1218207 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 01 : 352[31000] -> 353[4b000] via P2P/IPC/read
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 00 : 328[31000] -> 332[31000] [send] via NET/IBext/0
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 00 : 353[4b000] -> 354[ca000] via P2P/IPC/read
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 00 : 324[31000] -> 329[4b000] [receive] via NET/IBext/0
354: hkn0707:4012451:4012539 [2] NCCL INFO Channel 00 : 354[ca000] -> 355[e3000] via P2P/IPC/read
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 00 : 328[31000] -> 337[4b000] [send] via NET/IBext/0
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 01 : 353[4b000] -> 354[ca000] via P2P/IPC/read
354: hkn0707:4012451:4012539 [2] NCCL INFO Channel 01 : 354[ca000] -> 355[e3000] via P2P/IPC/read
390: hkn0717:4180120:4180224 [2] NCCL INFO Connected all rings
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 00 : 337[4b000] -> 328[31000] [receive] via NET/IBext/0
355: hkn0707:4012431:4012540 [3] NCCL INFO Connected all trees
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [send] via NET/IBext/0
355: hkn0707:4012431:4012540 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
145: hkn0513:3005445:3005561 [1] NCCL INFO Connected all trees
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [receive] via NET/IBext/0
355: hkn0707:4012431:4012540 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 00 : 388[31000] -> 389[4b000] via P2P/IPC/read
145: hkn0513:3005445:3005561 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
354: hkn0707:4012451:4012539 [2] NCCL INFO Connected all trees
385: hkn0716:101000:101120 [1] NCCL INFO Channel 00 : 385[4b000] -> 384[31000] via P2P/IPC/read
145: hkn0513:3005445:3005561 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
408: hkn0723:200389:200535 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [receive] via NET/IBext/0
354: hkn0707:4012451:4012539 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
354: hkn0707:4012451:4012539 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 01 : 388[31000] -> 389[4b000] via P2P/IPC/read
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 01 : 352[31000] -> 356[31000] [send] via NET/IBext/0
389: hkn0717:4180100:4180219 [1] NCCL INFO Channel 00 : 389[4b000] -> 390[ca000] via P2P/IPC/read
100: hkn0502:221575:221672 [0] NCCL INFO Channel 00 : 105[4b000] -> 100[31000] [receive] via NET/IBext/0
144: hkn0513:3005464:3005559 [0] NCCL INFO Connected all trees
144: hkn0513:3005464:3005559 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 00 : 336[31000] -> 353[4b000] [receive] via NET/IBext/0
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 00 : 352[31000] -> 368[31000] [send] via NET/IBext/0
390: hkn0717:4180120:4180224 [2] NCCL INFO Channel 00 : 390[ca000] -> 391[e3000] via P2P/IPC/read
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [receive] via NET/IBext/0
144: hkn0513:3005464:3005559 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 00 : 320[31000] -> 352[31000] [receive] via NET/IBext/0
389: hkn0717:4180100:4180219 [1] NCCL INFO Channel 01 : 389[4b000] -> 390[ca000] via P2P/IPC/read
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 00 : 353[4b000] -> 336[31000] [send] via NET/IBext/0
390: hkn0717:4180120:4180224 [2] NCCL INFO Channel 01 : 390[ca000] -> 391[e3000] via P2P/IPC/read
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 00 : 353[4b000] -> 352[31000] via P2P/IPC/read
391: hkn0717:4180108:4180218 [3] NCCL INFO Connected all trees
391: hkn0717:4180108:4180218 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
353: hkn0707:4012439:4012533 [1] NCCL INFO Channel 01 : 353[4b000] -> 352[31000] via P2P/IPC/read
391: hkn0717:4180108:4180218 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [send] via NET/IBext/0
390: hkn0717:4180120:4180224 [2] NCCL INFO Connected all trees
385: hkn0716:101000:101120 [1] NCCL INFO Channel 01 : 385[4b000] -> 384[31000] via P2P/IPC/read
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [receive] via NET/IBext/0
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 01 : 220[31000] -> 204[31000] [send] via NET/IBext/0
390: hkn0717:4180120:4180224 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1126300:1126401 [0] NCCL INFO Channel 00 : 172[31000] -> 168[31000] [send] via NET/IBext/0
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 01 : 188[31000] -> 125[4b000] [send] via NET/IBext/0
145: hkn0513:3005445:3005561 [1] NCCL INFO comm 0x1465b8008fb0 rank 145 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
390: hkn0717:4180120:4180224 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 17: hkn0408:2883223:2883320 [1] NCCL INFO Connected all trees
 17: hkn0408:2883223:2883320 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
364: hkn0711:576387:576519 [0] NCCL INFO Channel 00 : 364[31000] -> 360[31000] [send] via NET/IBext/0
 17: hkn0408:2883223:2883320 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
146: hkn0513:3005437:3005564 [2] NCCL INFO comm 0x14a8d4008fb0 rank 146 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 44: hkn0415:2488950:2489094 [0] NCCL INFO Channel 00 : 44[31000] -> 40[31000] [send] via NET/IBext/0
144: hkn0513:3005464:3005559 [0] NCCL INFO comm 0x14a7a0008fb0 rank 144 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
404: hkn0721:2291503:2291621 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [send] via NET/IBext/0
147: hkn0513:3005453:3005555 [3] NCCL INFO comm 0x1493e4008fb0 rank 147 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
236: hkn0606:2364550:2364664 [0] NCCL INFO Channel 00 : 236[31000] -> 232[31000] [send] via NET/IBext/0
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 01 : 384[31000] -> 388[31000] [receive] via NET/IBext/0
389: hkn0717:4180100:4180219 [1] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [receive] via NET/IBext/0
342: hkn0704:784530:784630 [2] NCCL INFO Connected all rings
 16: hkn0408:2883211:2883325 [0] NCCL INFO Connected all trees
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [send] via NET/IBext/0
 16: hkn0408:2883211:2883325 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:784518:784625 [0] NCCL INFO Channel 00 : 340[31000] -> 341[4b000] via P2P/IPC/read
 16: hkn0408:2883211:2883325 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [send] via NET/IBext/0
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [receive] via NET/IBext/0
340: hkn0704:784518:784625 [0] NCCL INFO Channel 01 : 340[31000] -> 341[4b000] via P2P/IPC/read
341: hkn0704:784510:784629 [1] NCCL INFO Channel 00 : 341[4b000] -> 342[ca000] via P2P/IPC/read
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 01 : 448[31000] -> 449[4b000] via P2P/IPC/read
342: hkn0704:784530:784630 [2] NCCL INFO Channel 00 : 342[ca000] -> 343[e3000] via P2P/IPC/read
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 00 : 449[4b000] -> 450[ca000] via P2P/IPC/read
341: hkn0704:784510:784629 [1] NCCL INFO Channel 01 : 341[4b000] -> 342[ca000] via P2P/IPC/read
450: hkn0734:1149069:1149195 [2] NCCL INFO Channel 00 : 450[ca000] -> 451[e3000] via P2P/IPC/read
342: hkn0704:784530:784630 [2] NCCL INFO Channel 01 : 342[ca000] -> 343[e3000] via P2P/IPC/read
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 01 : 449[4b000] -> 450[ca000] via P2P/IPC/read
343: hkn0704:784502:784626 [3] NCCL INFO Connected all trees
450: hkn0734:1149069:1149195 [2] NCCL INFO Channel 01 : 450[ca000] -> 451[e3000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [receive] via NET/IBext/0
343: hkn0704:784502:784626 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
343: hkn0704:784502:784626 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
451: hkn0734:1149077:1149192 [3] NCCL INFO Connected all trees
176: hkn0525:979338:979432 [0] NCCL INFO Channel 00 : 184[31000] -> 176[31000] [receive] via NET/IBext/0
342: hkn0704:784530:784630 [2] NCCL INFO Connected all trees
 17: hkn0408:2883223:2883320 [1] NCCL INFO comm 0x14bcf8008fb0 rank 17 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
342: hkn0704:784530:784630 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
400: hkn0720:4190315:4190586 [0] NCCL INFO Channel 01 : 404[31000] -> 400[31000] [receive] via NET/IBext/0
342: hkn0704:784530:784630 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 18: hkn0408:2883203:2883321 [2] NCCL INFO comm 0x14f85c008fb0 rank 18 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [receive] via NET/IBext/0
 19: hkn0408:2883195:2883322 [3] NCCL INFO comm 0x153a18008fb0 rank 19 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
340: hkn0704:784518:784625 [0] NCCL INFO Channel 01 : 336[31000] -> 340[31000] [receive] via NET/IBext/0
 16: hkn0408:2883211:2883325 [0] NCCL INFO comm 0x14f43c008fb0 rank 16 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
341: hkn0704:784510:784629 [1] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [receive] via NET/IBext/0
340: hkn0704:784518:784625 [0] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [send] via NET/IBext/0
451: hkn0734:1149077:1149192 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
451: hkn0734:1149077:1149192 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 00 : 224[31000] -> 225[4b000] via P2P/IPC/read
340: hkn0704:784518:784625 [0] NCCL INFO Channel 01 : 333[4b000] -> 340[31000] [receive] via NET/IBext/0
450: hkn0734:1149069:1149195 [2] NCCL INFO Connected all trees
340: hkn0704:784518:784625 [0] NCCL INFO Channel 01 : 340[31000] -> 333[4b000] [send] via NET/IBext/0
450: hkn0734:1149069:1149195 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:784518:784625 [0] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [receive] via NET/IBext/0
450: hkn0734:1149069:1149195 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:784518:784625 [0] NCCL INFO Channel 01 : 340[31000] -> 336[31000] [send] via NET/IBext/0
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 01 : 448[31000] -> 452[31000] [send] via NET/IBext/0
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [receive] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 01 : 224[31000] -> 225[4b000] via P2P/IPC/read
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 00 : 448[31000] -> 480[31000] [send] via NET/IBext/0
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 00 : 225[4b000] -> 226[ca000] via P2P/IPC/read
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 00 : 440[31000] -> 432[31000] [receive] via NET/IBext/0
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [send] via NET/IBext/0
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 00 : 449[4b000] -> 448[31000] via P2P/IPC/read
226: hkn0603:1405672:1405779 [2] NCCL INFO Channel 00 : 226[ca000] -> 227[e3000] via P2P/IPC/read
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 01 : 60[31000] -> 124[31000] [send] via NET/IBext/0
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 01 : 225[4b000] -> 226[ca000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO Channel 01 : 348[31000] -> 317[4b000] [send] via NET/IBext/0
449: hkn0734:1149097:1149191 [1] NCCL INFO Channel 01 : 449[4b000] -> 448[31000] via P2P/IPC/read
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 00 : 384[31000] -> 448[31000] [receive] via NET/IBext/0
226: hkn0603:1405672:1405779 [2] NCCL INFO Channel 01 : 226[ca000] -> 227[e3000] via P2P/IPC/read
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [send] via NET/IBext/0
227: hkn0603:1405656:1405782 [3] NCCL INFO Connected all trees
227: hkn0603:1405656:1405782 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 01 : 272[31000] -> 273[4b000] via P2P/IPC/read
381: hkn0715:394422:394551 [1] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [receive] via NET/IBext/0
227: hkn0603:1405656:1405782 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
226: hkn0603:1405672:1405779 [2] NCCL INFO Connected all trees
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 00 : 273[4b000] -> 274[ca000] via P2P/IPC/read
109: hkn0504:33317:33440 [1] NCCL INFO Connected all trees
226: hkn0603:1405672:1405779 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 00 : 41[4b000] -> 36[31000] [receive] via NET/IBext/0
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 01 : 316[31000] -> 380[31000] [send] via NET/IBext/0
109: hkn0504:33317:33440 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
226: hkn0603:1405672:1405779 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
109: hkn0504:33317:33440 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:681736:681856 [0] NCCL INFO Channel 00 : 233[4b000] -> 228[31000] [receive] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 01 : 224[31000] -> 228[31000] [send] via NET/IBext/0
274: hkn0617:2287161:2287275 [2] NCCL INFO Channel 00 : 274[ca000] -> 275[e3000] via P2P/IPC/read
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 00 : 208[31000] -> 225[4b000] [receive] via NET/IBext/0
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 01 : 273[4b000] -> 274[ca000] via P2P/IPC/read
257: hkn0612:909451:909581 [1] NCCL INFO Channel 00 : 257[4b000] -> 128[31000] [send] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 00 : 224[31000] -> 240[31000] [send] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO Connected all trees
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 00 : 225[4b000] -> 208[31000] [send] via NET/IBext/0
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 00 : 169[4b000] -> 164[31000] [receive] via NET/IBext/0
274: hkn0617:2287161:2287275 [2] NCCL INFO Channel 01 : 274[ca000] -> 275[e3000] via P2P/IPC/read
108: hkn0504:33325:33439 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:405715:405864 [0] NCCL INFO Channel 00 : 361[4b000] -> 356[31000] [receive] via NET/IBext/0
108: hkn0504:33325:33439 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 00 : 225[4b000] -> 224[31000] via P2P/IPC/read
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 00 : 192[31000] -> 224[31000] [receive] via NET/IBext/0
275: hkn0617:2287181:2287280 [3] NCCL INFO Connected all trees
225: hkn0603:1405664:1405775 [1] NCCL INFO Channel 01 : 225[4b000] -> 224[31000] via P2P/IPC/read
275: hkn0617:2287181:2287280 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [send] via NET/IBext/0
275: hkn0617:2287181:2287280 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
274: hkn0617:2287161:2287275 [2] NCCL INFO Connected all trees
394: hkn0718:3909522:3909643 [2] NCCL INFO Connected all rings
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 00 : 105[4b000] -> 104[31000] via P2P/IPC/read
274: hkn0617:2287161:2287275 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
108: hkn0504:33325:33439 [0] NCCL INFO comm 0x14f4dc008fb0 rank 108 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
274: hkn0617:2287161:2287275 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 01 : 272[31000] -> 276[31000] [send] via NET/IBext/0
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 00 : 392[31000] -> 393[4b000] via P2P/IPC/read
109: hkn0504:33317:33440 [1] NCCL INFO comm 0x155350008fb0 rank 109 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
160: hkn0520:2705369:2705482 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [receive] via NET/IBext/0
111: hkn0504:33333:33445 [3] NCCL INFO comm 0x1474d8008fb0 rank 111 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 00 : 425[4b000] -> 424[31000] via P2P/IPC/read
110: hkn0504:33345:33443 [2] NCCL INFO comm 0x151ba0008fb0 rank 110 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [receive] via NET/IBext/0
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 00 : 264[31000] -> 273[4b000] [receive] via NET/IBext/0
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 01 : 392[31000] -> 393[4b000] via P2P/IPC/read
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 00 : 272[31000] -> 280[31000] [send] via NET/IBext/0
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 00 : 393[4b000] -> 394[ca000] via P2P/IPC/read
 48: hkn0417:2260167:2260286 [0] NCCL INFO Channel 01 : 52[31000] -> 48[31000] [receive] via NET/IBext/0
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 00 : 272[31000] -> 289[4b000] [send] via NET/IBext/0
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 00 : 289[4b000] -> 272[31000] [receive] via NET/IBext/0
394: hkn0718:3909522:3909643 [2] NCCL INFO Channel 00 : 394[ca000] -> 395[e3000] via P2P/IPC/read
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 00 : 273[4b000] -> 264[31000] [send] via NET/IBext/0
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 01 : 393[4b000] -> 394[ca000] via P2P/IPC/read
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 00 : 273[4b000] -> 272[31000] via P2P/IPC/read
394: hkn0718:3909522:3909643 [2] NCCL INFO Channel 01 : 394[ca000] -> 395[e3000] via P2P/IPC/read
273: hkn0617:2287153:2287277 [1] NCCL INFO Channel 01 : 273[4b000] -> 272[31000] via P2P/IPC/read
395: hkn0718:3909510:3909645 [3] NCCL INFO Connected all trees
105: hkn0503:2892162:2892285 [1] NCCL INFO Channel 01 : 105[4b000] -> 104[31000] via P2P/IPC/read
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 00 : 280[31000] -> 272[31000] [receive] via NET/IBext/0
272: hkn0617:2287169:2287282 [0] NCCL INFO Channel 01 : 276[31000] -> 272[31000] [receive] via NET/IBext/0
395: hkn0718:3909510:3909645 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
273: hkn0617:2287153:2287277 [1] NCCL INFO Connected all trees
395: hkn0718:3909510:3909645 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 01 : 476[31000] -> 460[31000] [send] via NET/IBext/0
273: hkn0617:2287153:2287277 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
425: hkn0727:1338287:1338387 [1] NCCL INFO Channel 01 : 425[4b000] -> 424[31000] via P2P/IPC/read
273: hkn0617:2287153:2287277 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
272: hkn0617:2287169:2287282 [0] NCCL INFO Connected all trees
394: hkn0718:3909522:3909643 [2] NCCL INFO Connected all trees
272: hkn0617:2287169:2287282 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
394: hkn0718:3909522:3909643 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
272: hkn0617:2287169:2287282 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
394: hkn0718:3909522:3909643 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [receive] via NET/IBext/0
275: hkn0617:2287181:2287280 [3] NCCL INFO comm 0x14c1a4008fb0 rank 275 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
273: hkn0617:2287153:2287277 [1] NCCL INFO comm 0x1476d0008fb0 rank 273 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [send] via NET/IBext/0
300: hkn0628:664377:664476 [0] NCCL INFO Channel 00 : 300[31000] -> 296[31000] [send] via NET/IBext/0
274: hkn0617:2287161:2287275 [2] NCCL INFO comm 0x150b34008fb0 rank 274 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
272: hkn0617:2287169:2287282 [0] NCCL INFO comm 0x14e9f4008fb0 rank 272 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 00 : 388[31000] -> 393[4b000] [receive] via NET/IBext/0
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 00 : 392[31000] -> 401[4b000] [send] via NET/IBext/0
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 00 : 81[4b000] -> 82[ca000] via P2P/IPC/read
 82: hkn0425:2076510:2076599 [2] NCCL INFO Channel 00 : 82[ca000] -> 83[e3000] via P2P/IPC/read
344: hkn0705:775713:775862 [0] NCCL INFO Connected all rings
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 00 : 401[4b000] -> 392[31000] [receive] via NET/IBext/0
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 01 : 81[4b000] -> 82[ca000] via P2P/IPC/read
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [send] via NET/IBext/0
 82: hkn0425:2076510:2076599 [2] NCCL INFO Channel 01 : 82[ca000] -> 83[e3000] via P2P/IPC/read
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [receive] via NET/IBext/0
 83: hkn0425:2076482:2076596 [3] NCCL INFO Connected all trees
 83: hkn0425:2076482:2076596 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 83: hkn0425:2076482:2076596 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
345: hkn0705:775705:775864 [1] NCCL INFO Connected all rings
 82: hkn0425:2076510:2076599 [2] NCCL INFO Connected all trees
 82: hkn0425:2076510:2076599 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
344: hkn0705:775713:775862 [0] NCCL INFO Channel 00 : 344[31000] -> 345[4b000] via P2P/IPC/read
209: hkn0534:1140924:1141030 [1] NCCL INFO Connected all trees
 82: hkn0425:2076510:2076599 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 00 : 112[31000] -> 96[31000] [receive] via NET/IBext/0
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 01 : 80[31000] -> 84[31000] [send] via NET/IBext/0
209: hkn0534:1140924:1141030 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 00 : 72[31000] -> 81[4b000] [receive] via NET/IBext/0
209: hkn0534:1140924:1141030 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 00 : 80[31000] -> 88[31000] [send] via NET/IBext/0
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 00 : 80[31000] -> 97[4b000] [send] via NET/IBext/0
346: hkn0705:775721:775863 [2] NCCL INFO Connected all rings
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 00 : 81[4b000] -> 72[31000] [send] via NET/IBext/0
344: hkn0705:775713:775862 [0] NCCL INFO Channel 01 : 344[31000] -> 345[4b000] via P2P/IPC/read
208: hkn0534:1140908:1141032 [0] NCCL INFO Connected all trees
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 00 : 81[4b000] -> 80[31000] via P2P/IPC/read
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 00 : 125[4b000] -> 124[31000] via P2P/IPC/read
 81: hkn0425:2076498:2076595 [1] NCCL INFO Channel 01 : 81[4b000] -> 80[31000] via P2P/IPC/read
208: hkn0534:1140908:1141032 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 00 : 97[4b000] -> 80[31000] [receive] via NET/IBext/0
208: hkn0534:1140908:1141032 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 00 : 88[31000] -> 80[31000] [receive] via NET/IBext/0
 80: hkn0425:2076490:2076594 [0] NCCL INFO Channel 01 : 84[31000] -> 80[31000] [receive] via NET/IBext/0
346: hkn0705:775721:775863 [2] NCCL INFO Channel 00 : 346[ca000] -> 347[e3000] via P2P/IPC/read
 80: hkn0425:2076490:2076594 [0] NCCL INFO Connected all trees
 80: hkn0425:2076490:2076594 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
345: hkn0705:775705:775864 [1] NCCL INFO Channel 00 : 345[4b000] -> 346[ca000] via P2P/IPC/read
 80: hkn0425:2076490:2076594 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
346: hkn0705:775721:775863 [2] NCCL INFO Channel 01 : 346[ca000] -> 347[e3000] via P2P/IPC/read
 81: hkn0425:2076498:2076595 [1] NCCL INFO Connected all trees
345: hkn0705:775705:775864 [1] NCCL INFO Channel 01 : 345[4b000] -> 346[ca000] via P2P/IPC/read
 81: hkn0425:2076498:2076595 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
347: hkn0705:775733:775855 [3] NCCL INFO Connected all trees
347: hkn0705:775733:775855 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
173: hkn0524:1126272:1126399 [1] NCCL INFO Connected all trees
173: hkn0524:1126272:1126399 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 81: hkn0425:2076498:2076595 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
173: hkn0524:1126272:1126399 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 80: hkn0425:2076490:2076594 [0] NCCL INFO comm 0x146f5c008fb0 rank 80 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 45: hkn0415:2488962:2489090 [1] NCCL INFO Connected all trees
208: hkn0534:1140908:1141032 [0] NCCL INFO comm 0x1494a4008fb0 rank 208 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 45: hkn0415:2488962:2489090 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 92: hkn0428:659865:659978 [0] NCCL INFO Channel 00 : 92[31000] -> 88[31000] [send] via NET/IBext/0
 45: hkn0415:2488962:2489090 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 00 : 169[4b000] -> 168[31000] via P2P/IPC/read
361: hkn0710:348021:348124 [1] NCCL INFO Channel 00 : 361[4b000] -> 360[31000] via P2P/IPC/read
210: hkn0534:1140936:1141031 [2] NCCL INFO comm 0x153470008fb0 rank 210 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 00 : 41[4b000] -> 40[31000] via P2P/IPC/read
211: hkn0534:1140916:1141035 [3] NCCL INFO comm 0x14c3c0008fb0 rank 211 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
209: hkn0534:1140924:1141030 [1] NCCL INFO comm 0x1521c4008fb0 rank 209 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
172: hkn0524:1126300:1126401 [0] NCCL INFO Connected all trees
 44: hkn0415:2488950:2489094 [0] NCCL INFO Connected all trees
125: hkn0508:3131636:3131730 [1] NCCL INFO Channel 01 : 125[4b000] -> 124[31000] via P2P/IPC/read
 44: hkn0415:2488950:2489094 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
172: hkn0524:1126300:1126401 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2488950:2489094 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
172: hkn0524:1126300:1126401 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
257: hkn0612:909451:909581 [1] NCCL INFO Channel 00 : 257[4b000] -> 256[31000] via P2P/IPC/read
365: hkn0711:576415:576512 [1] NCCL INFO Connected all trees
237: hkn0606:2364558:2364669 [1] NCCL INFO Connected all trees
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 00 : 352[31000] -> 320[31000] [receive] via NET/IBext/0
365: hkn0711:576415:576512 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
233: hkn0605:704610:704720 [1] NCCL INFO Channel 00 : 233[4b000] -> 232[31000] via P2P/IPC/read
365: hkn0711:576415:576512 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
237: hkn0606:2364558:2364669 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
169: hkn0523:1540568:1540663 [1] NCCL INFO Channel 01 : 169[4b000] -> 168[31000] via P2P/IPC/read
 64: hkn0421:2172277:2172524 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [receive] via NET/IBext/0
361: hkn0710:348021:348124 [1] NCCL INFO Channel 01 : 361[4b000] -> 360[31000] via P2P/IPC/read
173: hkn0524:1126272:1126399 [1] NCCL INFO comm 0x14a180008fb0 rank 173 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 41: hkn0414:1974079:1974183 [1] NCCL INFO Channel 01 : 41[4b000] -> 40[31000] via P2P/IPC/read
256: hkn0612:909459:909583 [0] NCCL INFO Channel 00 : 0[31000] -> 256[31000] [receive] via NET/IBext/0
364: hkn0711:576387:576519 [0] NCCL INFO Connected all trees
237: hkn0606:2364558:2364669 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 45: hkn0415:2488962:2489090 [1] NCCL INFO comm 0x152aa8008fb0 rank 45 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
257: hkn0612:909451:909581 [1] NCCL INFO Channel 01 : 257[4b000] -> 256[31000] via P2P/IPC/read
 47: hkn0415:2488934:2489087 [3] NCCL INFO comm 0x154500008fb0 rank 47 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
364: hkn0711:576387:576519 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 44: hkn0415:2488950:2489094 [0] NCCL INFO comm 0x149fc8008fb0 rank 44 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
174: hkn0524:1126288:1126393 [2] NCCL INFO comm 0x14d6bc008fb0 rank 174 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 00 : 317[4b000] -> 316[31000] via P2P/IPC/read
364: hkn0711:576387:576519 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
175: hkn0524:1126280:1126395 [3] NCCL INFO comm 0x151058008fb0 rank 175 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
366: hkn0711:576395:576516 [2] NCCL INFO comm 0x147fc4008fb0 rank 366 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
172: hkn0524:1126300:1126401 [0] NCCL INFO comm 0x14c79c008fb0 rank 172 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
236: hkn0606:2364550:2364664 [0] NCCL INFO Connected all trees
367: hkn0711:576403:576515 [3] NCCL INFO comm 0x14ec0c008fb0 rank 367 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
236: hkn0606:2364550:2364664 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
364: hkn0711:576387:576519 [0] NCCL INFO comm 0x148dec008fb0 rank 364 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
236: hkn0606:2364550:2364664 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
365: hkn0711:576415:576512 [1] NCCL INFO comm 0x1540a8008fb0 rank 365 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
236: hkn0606:2364550:2364664 [0] NCCL INFO comm 0x14e6d8008fb0 rank 236 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 46: hkn0415:2488942:2489091 [2] NCCL INFO comm 0x1519d8008fb0 rank 46 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
304: hkn0629:1584552:1584670 [0] NCCL INFO Channel 01 : 308[31000] -> 304[31000] [receive] via NET/IBext/0
239: hkn0606:2364542:2364663 [3] NCCL INFO comm 0x153038008fb0 rank 239 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
233: hkn0605:704610:704720 [1] NCCL INFO Channel 01 : 233[4b000] -> 232[31000] via P2P/IPC/read
237: hkn0606:2364558:2364669 [1] NCCL INFO comm 0x1479dc008fb0 rank 237 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 81: hkn0425:2076498:2076595 [1] NCCL INFO comm 0x155250008fb0 rank 81 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
238: hkn0606:2364570:2364670 [2] NCCL INFO comm 0x14aae8008fb0 rank 238 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 82: hkn0425:2076510:2076599 [2] NCCL INFO comm 0x1457b0008fb0 rank 82 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 83: hkn0425:2076482:2076596 [3] NCCL INFO comm 0x151760008fb0 rank 83 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
347: hkn0705:775733:775855 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
346: hkn0705:775721:775863 [2] NCCL INFO Connected all trees
 32: hkn0412:2254916:2255009 [0] NCCL INFO Connected all rings
346: hkn0705:775721:775863 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 34: hkn0412:2254908:2255016 [2] NCCL INFO Connected all rings
317: hkn0632:1751107:1751230 [1] NCCL INFO Channel 01 : 317[4b000] -> 316[31000] via P2P/IPC/read
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 00 : 297[4b000] -> 292[31000] [receive] via NET/IBext/0
104: hkn0503:2892170:2892284 [0] NCCL INFO Channel 01 : 104[31000] -> 101[4b000] [send] via NET/IBext/0
346: hkn0705:775721:775863 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3353946:3354226 [0] NCCL INFO Channel 00 : 220[31000] -> 216[31000] [send] via NET/IBext/0
344: hkn0705:775713:775862 [0] NCCL INFO Channel 00 : 344[31000] -> 348[31000] [send] via NET/IBext/0
345: hkn0705:775705:775864 [1] NCCL INFO Channel 00 : 340[31000] -> 345[4b000] [receive] via NET/IBext/0
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 00 : 32[31000] -> 33[4b000] via P2P/IPC/read
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 01 : 32[31000] -> 33[4b000] via P2P/IPC/read
214: hkn0535:2391519:2391622 [2] NCCL INFO Connected all rings
344: hkn0705:775713:775862 [0] NCCL INFO Channel 00 : 336[31000] -> 344[31000] [receive] via NET/IBext/0
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 00 : 33[4b000] -> 34[ca000] via P2P/IPC/read
424: hkn0727:1338299:1338383 [0] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [send] via NET/IBext/0
345: hkn0705:775705:775864 [1] NCCL INFO Channel 00 : 345[4b000] -> 340[31000] [send] via NET/IBext/0
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 01 : 188[31000] -> 156[31000] [send] via NET/IBext/0
344: hkn0705:775713:775862 [0] NCCL INFO Channel 00 : 344[31000] -> 336[31000] [send] via NET/IBext/0
345: hkn0705:775705:775864 [1] NCCL INFO Channel 00 : 345[4b000] -> 344[31000] via P2P/IPC/read
 34: hkn0412:2254908:2255016 [2] NCCL INFO Channel 00 : 34[ca000] -> 35[e3000] via P2P/IPC/read
384: hkn0716:101008:101117 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [send] via NET/IBext/0
345: hkn0705:775705:775864 [1] NCCL INFO Channel 01 : 345[4b000] -> 344[31000] via P2P/IPC/read
344: hkn0705:775713:775862 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [receive] via NET/IBext/0
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 01 : 33[4b000] -> 34[ca000] via P2P/IPC/read
337: hkn0703:733504:733651 [1] NCCL INFO Connected all trees
 34: hkn0412:2254908:2255016 [2] NCCL INFO Channel 01 : 34[ca000] -> 35[e3000] via P2P/IPC/read
 35: hkn0412:2254928:2255011 [3] NCCL INFO Connected all trees
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 00 : 212[31000] -> 213[4b000] via P2P/IPC/read
337: hkn0703:733504:733651 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 35: hkn0412:2254928:2255011 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
337: hkn0703:733504:733651 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 35: hkn0412:2254928:2255011 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 34: hkn0412:2254908:2255016 [2] NCCL INFO Connected all trees
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 01 : 212[31000] -> 213[4b000] via P2P/IPC/read
 34: hkn0412:2254908:2255016 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
213: hkn0535:2391499:2391618 [1] NCCL INFO Channel 00 : 213[4b000] -> 214[ca000] via P2P/IPC/read
 34: hkn0412:2254908:2255016 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
214: hkn0535:2391519:2391622 [2] NCCL INFO Channel 00 : 214[ca000] -> 215[e3000] via P2P/IPC/read
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 01 : 76[31000] -> 68[31000] [send] via NET/IBext/0
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 01 : 32[31000] -> 36[31000] [send] via NET/IBext/0
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 00 : 16[31000] -> 33[4b000] [receive] via NET/IBext/0
213: hkn0535:2391499:2391618 [1] NCCL INFO Channel 01 : 213[4b000] -> 214[ca000] via P2P/IPC/read
401: hkn0720:4190323:4190580 [1] NCCL INFO Connected all trees
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 00 : 32[31000] -> 48[31000] [send] via NET/IBext/0
214: hkn0535:2391519:2391622 [2] NCCL INFO Channel 01 : 214[ca000] -> 215[e3000] via P2P/IPC/read
464: hkn0803:869028:869155 [0] NCCL INFO Connected all rings
401: hkn0720:4190323:4190580 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 00 : 32[31000] -> 65[4b000] [send] via NET/IBext/0
401: hkn0720:4190323:4190580 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 00 : 65[4b000] -> 32[31000] [receive] via NET/IBext/0
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 00 : 33[4b000] -> 16[31000] [send] via NET/IBext/0
215: hkn0535:2391507:2391619 [3] NCCL INFO Connected all trees
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 00 : 33[4b000] -> 32[31000] via P2P/IPC/read
215: hkn0535:2391507:2391619 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
381: hkn0715:394422:394551 [1] NCCL INFO Channel 00 : 381[4b000] -> 380[31000] via P2P/IPC/read
 33: hkn0412:2254900:2255017 [1] NCCL INFO Channel 01 : 33[4b000] -> 32[31000] via P2P/IPC/read
400: hkn0720:4190315:4190586 [0] NCCL INFO Connected all trees
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 00 : 48[31000] -> 32[31000] [receive] via NET/IBext/0
 32: hkn0412:2254916:2255009 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [receive] via NET/IBext/0
215: hkn0535:2391507:2391619 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
400: hkn0720:4190315:4190586 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
214: hkn0535:2391519:2391622 [2] NCCL INFO Connected all trees
400: hkn0720:4190315:4190586 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
214: hkn0535:2391519:2391622 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
214: hkn0535:2391519:2391622 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:869036:869157 [1] NCCL INFO Channel 00 : 465[4b000] -> 466[ca000] via P2P/IPC/read
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 01 : 208[31000] -> 212[31000] [receive] via NET/IBext/0
464: hkn0803:869028:869155 [0] NCCL INFO Channel 00 : 464[31000] -> 465[4b000] via P2P/IPC/read
213: hkn0535:2391499:2391618 [1] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [receive] via NET/IBext/0
466: hkn0803:869044:869156 [2] NCCL INFO Channel 00 : 466[ca000] -> 467[e3000] via P2P/IPC/read
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 00 : 212[31000] -> 217[4b000] [send] via NET/IBext/0
465: hkn0803:869036:869157 [1] NCCL INFO Channel 01 : 465[4b000] -> 466[ca000] via P2P/IPC/read
464: hkn0803:869028:869155 [0] NCCL INFO Channel 01 : 464[31000] -> 465[4b000] via P2P/IPC/read
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 00 : 416[31000] -> 417[4b000] via P2P/IPC/read
401: hkn0720:4190323:4190580 [1] NCCL INFO comm 0x145da4008fb0 rank 401 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 01 : 205[4b000] -> 212[31000] [receive] via NET/IBext/0
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [receive] via NET/IBext/0
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 01 : 212[31000] -> 205[4b000] [send] via NET/IBext/0
400: hkn0720:4190315:4190586 [0] NCCL INFO comm 0x147bf0008fb0 rank 400 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 00 : 217[4b000] -> 212[31000] [receive] via NET/IBext/0
336: hkn0703:733512:733649 [0] NCCL INFO Connected all trees
381: hkn0715:394422:394551 [1] NCCL INFO Channel 01 : 381[4b000] -> 380[31000] via P2P/IPC/read
212: hkn0535:2391491:2391620 [0] NCCL INFO Channel 01 : 212[31000] -> 208[31000] [send] via NET/IBext/0
466: hkn0803:869044:869156 [2] NCCL INFO Channel 01 : 466[ca000] -> 467[e3000] via P2P/IPC/read
336: hkn0703:733512:733649 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
467: hkn0803:869056:869160 [3] NCCL INFO Connected all trees
336: hkn0703:733512:733649 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
467: hkn0803:869056:869160 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:221575:221672 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [send] via NET/IBext/0
467: hkn0803:869056:869160 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
466: hkn0803:869044:869156 [2] NCCL INFO Connected all trees
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 01 : 416[31000] -> 417[4b000] via P2P/IPC/read
300: hkn0628:664377:664476 [0] NCCL INFO Connected all trees
466: hkn0803:869044:869156 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
402: hkn0720:4190312:4190585 [2] NCCL INFO comm 0x153d54008fb0 rank 402 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [receive] via NET/IBext/0
204: hkn0532:916658:916970 [0] NCCL INFO Channel 01 : 204[31000] -> 196[31000] [send] via NET/IBext/0
360: hkn0710:348013:348131 [0] NCCL INFO Channel 01 : 360[31000] -> 357[4b000] [send] via NET/IBext/0
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [receive] via NET/IBext/0
300: hkn0628:664377:664476 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
338: hkn0703:733524:733645 [2] NCCL INFO comm 0x14e4e8008fb0 rank 338 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
300: hkn0628:664377:664476 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
168: hkn0523:1540548:1540665 [0] NCCL INFO Channel 01 : 168[31000] -> 165[4b000] [send] via NET/IBext/0
466: hkn0803:869044:869156 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
337: hkn0703:733504:733651 [1] NCCL INFO comm 0x14eef4008fb0 rank 337 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
464: hkn0803:869028:869155 [0] NCCL INFO Channel 01 : 464[31000] -> 468[31000] [send] via NET/IBext/0
403: hkn0720:4190335:4190579 [3] NCCL INFO comm 0x1539fc008fb0 rank 403 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
301: hkn0628:664357:664467 [1] NCCL INFO Connected all trees
336: hkn0703:733512:733649 [0] NCCL INFO comm 0x151178008fb0 rank 336 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
465: hkn0803:869036:869157 [1] NCCL INFO Channel 00 : 456[31000] -> 465[4b000] [receive] via NET/IBext/0
339: hkn0703:733496:733654 [3] NCCL INFO comm 0x14c4b0008fb0 rank 339 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
301: hkn0628:664357:664467 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
301: hkn0628:664357:664467 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
464: hkn0803:869028:869155 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [send] via NET/IBext/0
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 00 : 297[4b000] -> 296[31000] via P2P/IPC/read
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 00 : 417[4b000] -> 418[ca000] via P2P/IPC/read
464: hkn0803:869028:869155 [0] NCCL INFO Channel 00 : 464[31000] -> 481[4b000] [send] via NET/IBext/0
418: hkn0725:3104426:3104537 [2] NCCL INFO Channel 00 : 418[ca000] -> 419[e3000] via P2P/IPC/read
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [receive] via NET/IBext/0
465: hkn0803:869036:869157 [1] NCCL INFO Channel 00 : 465[4b000] -> 456[31000] [send] via NET/IBext/0
 40: hkn0414:1974091:1974182 [0] NCCL INFO Channel 01 : 40[31000] -> 37[4b000] [send] via NET/IBext/0
465: hkn0803:869036:869157 [1] NCCL INFO Channel 00 : 465[4b000] -> 464[31000] via P2P/IPC/read
232: hkn0605:704594:704721 [0] NCCL INFO Channel 01 : 232[31000] -> 229[4b000] [send] via NET/IBext/0
465: hkn0803:869036:869157 [1] NCCL INFO Channel 01 : 465[4b000] -> 464[31000] via P2P/IPC/read
300: hkn0628:664377:664476 [0] NCCL INFO comm 0x154998008fb0 rank 300 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
464: hkn0803:869028:869155 [0] NCCL INFO Channel 00 : 481[4b000] -> 464[31000] [receive] via NET/IBext/0
464: hkn0803:869028:869155 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [receive] via NET/IBext/0
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 01 : 417[4b000] -> 418[ca000] via P2P/IPC/read
301: hkn0628:664357:664467 [1] NCCL INFO comm 0x14efc8008fb0 rank 301 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
464: hkn0803:869028:869155 [0] NCCL INFO Channel 01 : 468[31000] -> 464[31000] [receive] via NET/IBext/0
418: hkn0725:3104426:3104537 [2] NCCL INFO Channel 01 : 418[ca000] -> 419[e3000] via P2P/IPC/read
398: hkn0719:1298217:1298339 [2] NCCL INFO Connected all rings
302: hkn0628:664349:664472 [2] NCCL INFO comm 0x14a324008fb0 rank 302 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
419: hkn0725:3104454:3104536 [3] NCCL INFO Connected all trees
419: hkn0725:3104454:3104536 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 00 : 396[31000] -> 397[4b000] via P2P/IPC/read
303: hkn0628:664365:664474 [3] NCCL INFO comm 0x14f4c8008fb0 rank 303 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
419: hkn0725:3104454:3104536 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 93: hkn0428:659873:659979 [1] NCCL INFO Connected all trees
 48: hkn0417:2260167:2260286 [0] NCCL INFO Connected all trees
 93: hkn0428:659873:659979 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 48: hkn0417:2260167:2260286 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 93: hkn0428:659873:659979 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 48: hkn0417:2260167:2260286 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
297: hkn0627:1780434:1780527 [1] NCCL INFO Channel 01 : 297[4b000] -> 296[31000] via P2P/IPC/read
418: hkn0725:3104426:3104537 [2] NCCL INFO Connected all trees
418: hkn0725:3104426:3104537 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 01 : 396[31000] -> 397[4b000] via P2P/IPC/read
418: hkn0725:3104426:3104537 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 00 : 397[4b000] -> 398[ca000] via P2P/IPC/read
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [send] via NET/IBext/0
398: hkn0719:1298217:1298339 [2] NCCL INFO Channel 00 : 398[ca000] -> 399[e3000] via P2P/IPC/read
 92: hkn0428:659865:659978 [0] NCCL INFO Connected all trees
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 00 : 400[31000] -> 417[4b000] [receive] via NET/IBext/0
 92: hkn0428:659865:659978 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:979338:979432 [0] NCCL INFO Channel 01 : 180[31000] -> 176[31000] [receive] via NET/IBext/0
 92: hkn0428:659865:659978 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 49: hkn0417:2260159:2260288 [1] NCCL INFO Connected all trees
 49: hkn0417:2260159:2260288 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 00 : 416[31000] -> 432[31000] [send] via NET/IBext/0
 49: hkn0417:2260159:2260288 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 00 : 416[31000] -> 449[4b000] [send] via NET/IBext/0
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 01 : 397[4b000] -> 398[ca000] via P2P/IPC/read
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 00 : 444[31000] -> 445[4b000] via P2P/IPC/read
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 01 : 124[31000] -> 252[31000] [send] via NET/IBext/0
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 00 : 417[4b000] -> 400[31000] [send] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 00 : 449[4b000] -> 416[31000] [receive] via NET/IBext/0
398: hkn0719:1298217:1298339 [2] NCCL INFO Channel 01 : 398[ca000] -> 399[e3000] via P2P/IPC/read
432: hkn0730:1394221:1394352 [0] NCCL INFO Channel 01 : 436[31000] -> 432[31000] [receive] via NET/IBext/0
476: hkn0806:1046831:1046950 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [send] via NET/IBext/0
 93: hkn0428:659873:659979 [1] NCCL INFO comm 0x1457f8008fb0 rank 93 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 00 : 417[4b000] -> 416[31000] via P2P/IPC/read
 94: hkn0428:659895:659982 [2] NCCL INFO comm 0x14c2c8008fb0 rank 94 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
417: hkn0725:3104434:3104541 [1] NCCL INFO Channel 01 : 417[4b000] -> 416[31000] via P2P/IPC/read
 49: hkn0417:2260159:2260288 [1] NCCL INFO comm 0x153e80008fb0 rank 49 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 00 : 432[31000] -> 416[31000] [receive] via NET/IBext/0
 48: hkn0417:2260167:2260286 [0] NCCL INFO comm 0x14f324008fb0 rank 48 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
256: hkn0612:909459:909583 [0] NCCL INFO Channel 00 : 256[31000] -> 0[31000] [send] via NET/IBext/0
 92: hkn0428:659865:659978 [0] NCCL INFO comm 0x149508008fb0 rank 92 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 51: hkn0417:2260175:2260285 [3] NCCL INFO comm 0x151d38008fb0 rank 51 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 00 : 192[31000] -> 128[31000] [receive] via NET/IBext/0
 95: hkn0428:659881:659973 [3] NCCL INFO comm 0x154904008fb0 rank 95 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 50: hkn0417:2260187:2260291 [2] NCCL INFO comm 0x14edb8008fb0 rank 50 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
228: hkn0604:681736:681856 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [send] via NET/IBext/0
 36: hkn0413:2359195:2359304 [0] NCCL INFO Channel 01 : 36[31000] -> 32[31000] [send] via NET/IBext/0
348: hkn0706:744758:744910 [0] NCCL INFO Channel 01 : 348[31000] -> 332[31000] [send] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [receive] via NET/IBext/0
399: hkn0719:1298195:1298344 [3] NCCL INFO Connected all trees
399: hkn0719:1298195:1298344 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 01 : 444[31000] -> 445[4b000] via P2P/IPC/read
101: hkn0502:221555:221670 [1] NCCL INFO Channel 00 : 101[4b000] -> 100[31000] via P2P/IPC/read
399: hkn0719:1298195:1298344 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1190286:1190438 [0] NCCL INFO Channel 01 : 164[31000] -> 160[31000] [send] via NET/IBext/0
398: hkn0719:1298217:1298339 [2] NCCL INFO Connected all trees
398: hkn0719:1298217:1298339 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 00 : 445[4b000] -> 446[ca000] via P2P/IPC/read
356: hkn0708:405715:405864 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [send] via NET/IBext/0
398: hkn0719:1298217:1298339 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2892162:2892285 [1] NCCL INFO Connected all trees
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 00 : 392[31000] -> 396[31000] [receive] via NET/IBext/0
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 00 : 120[31000] -> 112[31000] [receive] via NET/IBext/0
221: hkn0602:3353962:3354225 [1] NCCL INFO Connected all trees
105: hkn0503:2892162:2892285 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:394410:394546 [0] NCCL INFO Channel 01 : 253[4b000] -> 380[31000] [receive] via NET/IBext/0
221: hkn0602:3353962:3354225 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
105: hkn0503:2892162:2892285 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
221: hkn0602:3353962:3354225 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 01 : 397[4b000] -> 404[31000] [send] via NET/IBext/0
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 01 : 388[31000] -> 396[31000] [receive] via NET/IBext/0
446: hkn0733:1381899:1382018 [2] NCCL INFO Channel 00 : 446[ca000] -> 447[e3000] via P2P/IPC/read
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 01 : 445[4b000] -> 446[ca000] via P2P/IPC/read
485: hkn0808:963203:963306 [1] NCCL INFO Connected all rings
104: hkn0503:2892170:2892284 [0] NCCL INFO Connected all trees
104: hkn0503:2892170:2892284 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [send] via NET/IBext/0
101: hkn0502:221555:221670 [1] NCCL INFO Channel 01 : 101[4b000] -> 100[31000] via P2P/IPC/read
220: hkn0602:3353946:3354226 [0] NCCL INFO Connected all trees
220: hkn0602:3353946:3354226 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
104: hkn0503:2892170:2892284 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
220: hkn0602:3353946:3354226 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [receive] via NET/IBext/0
425: hkn0727:1338287:1338387 [1] NCCL INFO Connected all trees
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 01 : 404[31000] -> 397[4b000] [receive] via NET/IBext/0
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 00 : 397[4b000] -> 396[31000] via P2P/IPC/read
446: hkn0733:1381899:1382018 [2] NCCL INFO Channel 01 : 446[ca000] -> 447[e3000] via P2P/IPC/read
397: hkn0719:1298203:1298338 [1] NCCL INFO Channel 01 : 397[4b000] -> 396[31000] via P2P/IPC/read
447: hkn0733:1381891:1382017 [3] NCCL INFO Connected all trees
447: hkn0733:1381891:1382017 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
486: hkn0808:963183:963303 [2] NCCL INFO Connected all rings
425: hkn0727:1338287:1338387 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 00 : 368[31000] -> 352[31000] [receive] via NET/IBext/0
425: hkn0727:1338287:1338387 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
105: hkn0503:2892162:2892285 [1] NCCL INFO comm 0x154d5c008fb0 rank 105 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
220: hkn0602:3353946:3354226 [0] NCCL INFO comm 0x1486b0008fb0 rank 220 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
447: hkn0733:1381891:1382017 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
424: hkn0727:1338299:1338383 [0] NCCL INFO Connected all trees
107: hkn0503:2892154:2892277 [3] NCCL INFO comm 0x1463f8008fb0 rank 107 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
221: hkn0602:3353962:3354225 [1] NCCL INFO comm 0x154138008fb0 rank 221 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
106: hkn0503:2892182:2892286 [2] NCCL INFO comm 0x148c84008fb0 rank 106 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
104: hkn0503:2892170:2892284 [0] NCCL INFO comm 0x149edc008fb0 rank 104 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
446: hkn0733:1381899:1382018 [2] NCCL INFO Connected all trees
446: hkn0733:1381899:1382018 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:963191:963307 [0] NCCL INFO Channel 00 : 484[31000] -> 485[4b000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 01 : 460[31000] -> 452[31000] [send] via NET/IBext/0
424: hkn0727:1338299:1338383 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
424: hkn0727:1338299:1338383 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
222: hkn0602:3353974:3354228 [2] NCCL INFO comm 0x1467a0008fb0 rank 222 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
446: hkn0733:1381899:1382018 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:963191:963307 [0] NCCL INFO Channel 01 : 484[31000] -> 485[4b000] via P2P/IPC/read
223: hkn0602:3353954:3354221 [3] NCCL INFO comm 0x149c7c008fb0 rank 223 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 00 : 440[31000] -> 444[31000] [receive] via NET/IBext/0
425: hkn0727:1338287:1338387 [1] NCCL INFO comm 0x149cfc008fb0 rank 425 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
296: hkn0627:1780414:1780535 [0] NCCL INFO Channel 01 : 296[31000] -> 293[4b000] [send] via NET/IBext/0
305: hkn0629:1584572:1584665 [1] NCCL INFO Connected all trees
305: hkn0629:1584572:1584665 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 01 : 445[4b000] -> 476[31000] [send] via NET/IBext/0
305: hkn0629:1584572:1584665 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [receive] via NET/IBext/0
424: hkn0727:1338299:1338383 [0] NCCL INFO comm 0x146058008fb0 rank 424 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 01 : 381[4b000] -> 444[31000] [receive] via NET/IBext/0
426: hkn0727:1338279:1338380 [2] NCCL INFO comm 0x1480d0008fb0 rank 426 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
304: hkn0629:1584552:1584670 [0] NCCL INFO Connected all trees
427: hkn0727:1338271:1338389 [3] NCCL INFO comm 0x14be40008fb0 rank 427 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
304: hkn0629:1584552:1584670 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
357: hkn0708:405731:405869 [1] NCCL INFO Channel 00 : 357[4b000] -> 356[31000] via P2P/IPC/read
304: hkn0629:1584552:1584670 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:869036:869157 [1] NCCL INFO Connected all trees
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 01 : 476[31000] -> 445[4b000] [receive] via NET/IBext/0
465: hkn0803:869036:869157 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 00 : 445[4b000] -> 444[31000] via P2P/IPC/read
465: hkn0803:869036:869157 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
445: hkn0733:1381907:1382020 [1] NCCL INFO Channel 01 : 445[4b000] -> 444[31000] via P2P/IPC/read
307: hkn0629:1584544:1584671 [3] NCCL INFO comm 0x14c3c0008fb0 rank 307 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
464: hkn0803:869028:869155 [0] NCCL INFO Connected all trees
305: hkn0629:1584572:1584665 [1] NCCL INFO comm 0x14b1c0008fb0 rank 305 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
464: hkn0803:869028:869155 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
361: hkn0710:348021:348124 [1] NCCL INFO Connected all trees
304: hkn0629:1584552:1584670 [0] NCCL INFO comm 0x15045c008fb0 rank 304 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
361: hkn0710:348021:348124 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
306: hkn0629:1584560:1584666 [2] NCCL INFO comm 0x15136c008fb0 rank 306 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 96: hkn0501:1320376:1320475 [0] NCCL INFO Channel 01 : 100[31000] -> 96[31000] [receive] via NET/IBext/0
361: hkn0710:348021:348124 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
188: hkn0528:1294198:1294318 [0] NCCL INFO Channel 00 : 188[31000] -> 184[31000] [send] via NET/IBext/0
165: hkn0521:1190302:1190437 [1] NCCL INFO Channel 00 : 165[4b000] -> 164[31000] via P2P/IPC/read
320: hkn0633:1518863:1518964 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [receive] via NET/IBext/0
357: hkn0708:405731:405869 [1] NCCL INFO Channel 01 : 357[4b000] -> 356[31000] via P2P/IPC/read
 88: hkn0427:1127643:1127786 [0] NCCL INFO Channel 01 : 88[31000] -> 85[4b000] [send] via NET/IBext/0
169: hkn0523:1540568:1540663 [1] NCCL INFO Connected all trees
360: hkn0710:348013:348131 [0] NCCL INFO Connected all trees
464: hkn0803:869028:869155 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
169: hkn0523:1540568:1540663 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
360: hkn0710:348013:348131 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
169: hkn0523:1540568:1540663 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
360: hkn0710:348013:348131 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
465: hkn0803:869036:869157 [1] NCCL INFO comm 0x146400008fb0 rank 465 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 01 : 444[31000] -> 381[4b000] [send] via NET/IBext/0
168: hkn0523:1540548:1540665 [0] NCCL INFO Connected all trees
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [send] via NET/IBext/0
233: hkn0605:704610:704720 [1] NCCL INFO Connected all trees
467: hkn0803:869056:869160 [3] NCCL INFO comm 0x148fb8008fb0 rank 467 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
168: hkn0523:1540548:1540665 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
229: hkn0604:681744:681864 [1] NCCL INFO Channel 00 : 229[4b000] -> 228[31000] via P2P/IPC/read
 37: hkn0413:2359194:2359299 [1] NCCL INFO Channel 00 : 37[4b000] -> 36[31000] via P2P/IPC/read
 41: hkn0414:1974079:1974183 [1] NCCL INFO Connected all trees
 41: hkn0414:1974079:1974183 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
168: hkn0523:1540548:1540665 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 41: hkn0414:1974079:1974183 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
361: hkn0710:348021:348124 [1] NCCL INFO comm 0x14c358008fb0 rank 361 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
233: hkn0605:704610:704720 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
464: hkn0803:869028:869155 [0] NCCL INFO comm 0x153294008fb0 rank 464 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 76: hkn0424:2940461:2940557 [0] NCCL INFO Channel 00 : 76[31000] -> 72[31000] [send] via NET/IBext/0
362: hkn0710:348041:348125 [2] NCCL INFO comm 0x14b110008fb0 rank 362 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 40: hkn0414:1974091:1974182 [0] NCCL INFO Connected all trees
360: hkn0710:348013:348131 [0] NCCL INFO comm 0x148274008fb0 rank 360 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 40: hkn0414:1974091:1974182 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
168: hkn0523:1540548:1540665 [0] NCCL INFO comm 0x145a3c008fb0 rank 168 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 40: hkn0414:1974091:1974182 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
363: hkn0710:348029:348129 [3] NCCL INFO comm 0x14a710008fb0 rank 363 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
169: hkn0523:1540568:1540663 [1] NCCL INFO comm 0x147740008fb0 rank 169 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
165: hkn0521:1190302:1190437 [1] NCCL INFO Channel 01 : 165[4b000] -> 164[31000] via P2P/IPC/read
170: hkn0523:1540556:1540660 [2] NCCL INFO comm 0x14f3f4008fb0 rank 170 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
233: hkn0605:704610:704720 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
171: hkn0523:1540540:1540658 [3] NCCL INFO comm 0x150620008fb0 rank 171 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
229: hkn0604:681744:681864 [1] NCCL INFO Channel 01 : 229[4b000] -> 228[31000] via P2P/IPC/read
232: hkn0605:704594:704721 [0] NCCL INFO Connected all trees
466: hkn0803:869044:869156 [2] NCCL INFO comm 0x148220008fb0 rank 466 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
485: hkn0808:963203:963306 [1] NCCL INFO Channel 00 : 485[4b000] -> 486[ca000] via P2P/IPC/read
414: hkn0724:1708491:1708600 [2] NCCL INFO Connected all rings
232: hkn0605:704594:704721 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
486: hkn0808:963183:963303 [2] NCCL INFO Channel 00 : 486[ca000] -> 487[e3000] via P2P/IPC/read
232: hkn0605:704594:704721 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:963203:963306 [1] NCCL INFO Channel 01 : 485[4b000] -> 486[ca000] via P2P/IPC/read
 41: hkn0414:1974079:1974183 [1] NCCL INFO comm 0x1543d8008fb0 rank 41 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
233: hkn0605:704610:704720 [1] NCCL INFO comm 0x152fcc008fb0 rank 233 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 37: hkn0413:2359194:2359299 [1] NCCL INFO Channel 01 : 37[4b000] -> 36[31000] via P2P/IPC/read
 43: hkn0414:1974063:1974188 [3] NCCL INFO comm 0x14fbb4008fb0 rank 43 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 40: hkn0414:1974091:1974182 [0] NCCL INFO comm 0x14d51c008fb0 rank 40 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
234: hkn0605:704621:704722 [2] NCCL INFO comm 0x1505ec008fb0 rank 234 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 42: hkn0414:1974071:1974185 [2] NCCL INFO comm 0x149034008fb0 rank 42 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
477: hkn0806:1046851:1046947 [1] NCCL INFO Connected all trees
232: hkn0605:704594:704721 [0] NCCL INFO comm 0x151a0c008fb0 rank 232 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
486: hkn0808:963183:963303 [2] NCCL INFO Channel 01 : 486[ca000] -> 487[e3000] via P2P/IPC/read
477: hkn0806:1046851:1046947 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
235: hkn0605:704602:704724 [3] NCCL INFO comm 0x14fc18008fb0 rank 235 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
477: hkn0806:1046851:1046947 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
417: hkn0725:3104434:3104541 [1] NCCL INFO Connected all trees
487: hkn0808:963175:963302 [3] NCCL INFO Connected all trees
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 00 : 412[31000] -> 413[4b000] via P2P/IPC/read
417: hkn0725:3104434:3104541 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
487: hkn0808:963175:963302 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
476: hkn0806:1046831:1046950 [0] NCCL INFO Connected all trees
417: hkn0725:3104434:3104541 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
476: hkn0806:1046831:1046950 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
487: hkn0808:963175:963302 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 01 : 156[31000] -> 140[31000] [send] via NET/IBext/0
476: hkn0806:1046831:1046950 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
216: hkn0601:110172:110280 [0] NCCL INFO Channel 01 : 216[31000] -> 213[4b000] [send] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO Connected all trees
204: hkn0532:916658:916970 [0] NCCL INFO Channel 00 : 204[31000] -> 200[31000] [send] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
292: hkn0626:1290939:1291061 [0] NCCL INFO Channel 01 : 292[31000] -> 288[31000] [send] via NET/IBext/0
416: hkn0725:3104442:3104538 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
486: hkn0808:963183:963303 [2] NCCL INFO Connected all trees
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 01 : 412[31000] -> 413[4b000] via P2P/IPC/read
476: hkn0806:1046831:1046950 [0] NCCL INFO comm 0x153f18008fb0 rank 476 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
486: hkn0808:963183:963303 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
477: hkn0806:1046851:1046947 [1] NCCL INFO comm 0x1519a8008fb0 rank 477 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
417: hkn0725:3104434:3104541 [1] NCCL INFO comm 0x151210008fb0 rank 417 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
478: hkn0806:1046839:1046949 [2] NCCL INFO comm 0x14f8c8008fb0 rank 478 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
416: hkn0725:3104442:3104538 [0] NCCL INFO comm 0x14fe8c008fb0 rank 416 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
479: hkn0806:1046823:1046948 [3] NCCL INFO comm 0x1544a0008fb0 rank 479 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
486: hkn0808:963183:963303 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
418: hkn0725:3104426:3104537 [2] NCCL INFO comm 0x14f694008fb0 rank 418 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
484: hkn0808:963191:963307 [0] NCCL INFO Channel 01 : 480[31000] -> 484[31000] [receive] via NET/IBext/0
419: hkn0725:3104454:3104536 [3] NCCL INFO comm 0x14967c008fb0 rank 419 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
485: hkn0808:963203:963306 [1] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [receive] via NET/IBext/0
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 00 : 73[4b000] -> 68[31000] [receive] via NET/IBext/0
484: hkn0808:963191:963307 [0] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [send] via NET/IBext/0
165: hkn0521:1190302:1190437 [1] NCCL INFO Connected all trees
484: hkn0808:963191:963307 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [send] via NET/IBext/0
 36: hkn0413:2359195:2359304 [0] NCCL INFO Connected all trees
165: hkn0521:1190302:1190437 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 36: hkn0413:2359195:2359304 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
165: hkn0521:1190302:1190437 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 36: hkn0413:2359195:2359304 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1190286:1190438 [0] NCCL INFO Connected all trees
164: hkn0521:1190286:1190438 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:963191:963307 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [receive] via NET/IBext/0
 37: hkn0413:2359194:2359299 [1] NCCL INFO Connected all trees
176: hkn0525:979338:979432 [0] NCCL INFO Connected all trees
 37: hkn0413:2359194:2359299 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:979338:979432 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
433: hkn0730:1394237:1394350 [1] NCCL INFO Connected all trees
 37: hkn0413:2359194:2359299 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1394237:1394350 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
176: hkn0525:979338:979432 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
433: hkn0730:1394237:1394350 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
177: hkn0525:979326:979436 [1] NCCL INFO Connected all trees
 36: hkn0413:2359195:2359304 [0] NCCL INFO comm 0x146fb0008fb0 rank 36 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
177: hkn0525:979326:979436 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1394221:1394352 [0] NCCL INFO Connected all trees
 37: hkn0413:2359194:2359299 [1] NCCL INFO comm 0x151f20008fb0 rank 37 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
432: hkn0730:1394221:1394352 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 38: hkn0413:2359203:2359295 [2] NCCL INFO comm 0x14851c008fb0 rank 38 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
432: hkn0730:1394221:1394352 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 39: hkn0413:2359214:2359301 [3] NCCL INFO comm 0x14eda4008fb0 rank 39 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
177: hkn0525:979326:979436 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
161: hkn0520:2705368:2705469 [1] NCCL INFO Connected all trees
176: hkn0525:979338:979432 [0] NCCL INFO comm 0x1479bc008fb0 rank 176 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
161: hkn0520:2705368:2705469 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
432: hkn0730:1394221:1394352 [0] NCCL INFO comm 0x152df8008fb0 rank 432 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 00 : 224[31000] -> 192[31000] [receive] via NET/IBext/0
433: hkn0730:1394237:1394350 [1] NCCL INFO comm 0x14c7fc008fb0 rank 433 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
177: hkn0525:979326:979436 [1] NCCL INFO comm 0x149c90008fb0 rank 177 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
179: hkn0525:979318:979438 [3] NCCL INFO comm 0x14bde4008fb0 rank 179 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
161: hkn0520:2705368:2705469 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
434: hkn0730:1394229:1394348 [2] NCCL INFO comm 0x14c734008fb0 rank 434 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
178: hkn0525:979310:979433 [2] NCCL INFO comm 0x152a1c008fb0 rank 178 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
160: hkn0520:2705369:2705482 [0] NCCL INFO Connected all trees
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 00 : 201[4b000] -> 196[31000] [receive] via NET/IBext/0
435: hkn0730:1394249:1394347 [3] NCCL INFO comm 0x14cd88008fb0 rank 435 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 85: hkn0426:806571:806694 [1] NCCL INFO Channel 00 : 85[4b000] -> 84[31000] via P2P/IPC/read
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [receive] via NET/IBext/0
160: hkn0520:2705369:2705482 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:221575:221672 [0] NCCL INFO Connected all trees
160: hkn0520:2705369:2705482 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 89: hkn0427:1127663:1127792 [1] NCCL INFO Connected all trees
100: hkn0502:221575:221672 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 89: hkn0427:1127663:1127792 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:221575:221672 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 89: hkn0427:1127663:1127792 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
160: hkn0520:2705369:2705482 [0] NCCL INFO comm 0x14ed70008fb0 rank 160 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 88: hkn0427:1127643:1127786 [0] NCCL INFO Connected all trees
 88: hkn0427:1127643:1127786 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
101: hkn0502:221555:221670 [1] NCCL INFO Connected all trees
 85: hkn0426:806571:806694 [1] NCCL INFO Channel 01 : 85[4b000] -> 84[31000] via P2P/IPC/read
 88: hkn0427:1127643:1127786 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:702329:702425 [1] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [receive] via NET/IBext/0
162: hkn0520:2705389:2705480 [2] NCCL INFO comm 0x148980008fb0 rank 162 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
101: hkn0502:221555:221670 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
161: hkn0520:2705368:2705469 [1] NCCL INFO comm 0x145620008fb0 rank 161 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
101: hkn0502:221555:221670 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
163: hkn0520:2705377:2705478 [3] NCCL INFO comm 0x14c5f8008fb0 rank 163 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
460: hkn0802:1192854:1192947 [0] NCCL INFO Channel 00 : 460[31000] -> 456[31000] [send] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [receive] via NET/IBext/0
 88: hkn0427:1127643:1127786 [0] NCCL INFO comm 0x151750008fb0 rank 88 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 77: hkn0424:2940449:2940563 [1] NCCL INFO Connected all trees
 90: hkn0427:1127651:1127785 [2] NCCL INFO comm 0x150c54008fb0 rank 90 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 77: hkn0424:2940449:2940563 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 91: hkn0427:1127642:1127790 [3] NCCL INFO comm 0x154340008fb0 rank 91 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 77: hkn0424:2940449:2940563 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 89: hkn0427:1127663:1127792 [1] NCCL INFO comm 0x145808008fb0 rank 89 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 76: hkn0424:2940461:2940557 [0] NCCL INFO Connected all trees
 76: hkn0424:2940461:2940557 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
100: hkn0502:221575:221672 [0] NCCL INFO comm 0x151484008fb0 rank 100 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 76: hkn0424:2940461:2940557 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
101: hkn0502:221555:221670 [1] NCCL INFO comm 0x147e24008fb0 rank 101 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
103: hkn0502:221563:221675 [3] NCCL INFO comm 0x147668008fb0 rank 103 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
128: hkn0509:3116916:3117017 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [receive] via NET/IBext/0
102: hkn0502:221554:221671 [2] NCCL INFO comm 0x14ccb0008fb0 rank 102 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
293: hkn0626:1290947:1291055 [1] NCCL INFO Channel 00 : 293[4b000] -> 292[31000] via P2P/IPC/read
112: hkn0505:2296308:2296407 [0] NCCL INFO Channel 01 : 116[31000] -> 112[31000] [receive] via NET/IBext/0
293: hkn0626:1290947:1291055 [1] NCCL INFO Channel 01 : 293[4b000] -> 292[31000] via P2P/IPC/read
 77: hkn0424:2940449:2940563 [1] NCCL INFO comm 0x151328008fb0 rank 77 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
256: hkn0612:909459:909583 [0] NCCL INFO Channel 00 : 384[31000] -> 256[31000] [receive] via NET/IBext/0
 79: hkn0424:2940441:2940558 [3] NCCL INFO comm 0x14aa3c008fb0 rank 79 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
189: hkn0528:1294214:1294319 [1] NCCL INFO Connected all trees
 76: hkn0424:2940461:2940557 [0] NCCL INFO comm 0x146fcc008fb0 rank 76 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
189: hkn0528:1294214:1294319 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 97: hkn0501:1320356:1320474 [1] NCCL INFO Connected all trees
 78: hkn0424:2940433:2940564 [2] NCCL INFO comm 0x14b52c008fb0 rank 78 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 97: hkn0501:1320356:1320474 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 84: hkn0426:806579:806691 [0] NCCL INFO Connected all trees
 97: hkn0501:1320356:1320474 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 84: hkn0426:806579:806691 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 96: hkn0501:1320376:1320475 [0] NCCL INFO Connected all trees
 84: hkn0426:806579:806691 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
205: hkn0532:916650:916971 [1] NCCL INFO Connected all trees
217: hkn0601:110184:110286 [1] NCCL INFO Connected all trees
 85: hkn0426:806571:806694 [1] NCCL INFO Connected all trees
205: hkn0532:916650:916971 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 96: hkn0501:1320376:1320475 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 85: hkn0426:806571:806694 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 96: hkn0501:1320376:1320475 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 85: hkn0426:806571:806694 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 00 : 201[4b000] -> 200[31000] via P2P/IPC/read
205: hkn0532:916650:916971 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 98: hkn0501:1320364:1320480 [2] NCCL INFO comm 0x14c0f4008fb0 rank 98 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
204: hkn0532:916658:916970 [0] NCCL INFO Connected all trees
 96: hkn0501:1320376:1320475 [0] NCCL INFO comm 0x152850008fb0 rank 96 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 00 : 457[4b000] -> 452[31000] [receive] via NET/IBext/0
 99: hkn0501:1320348:1320478 [3] NCCL INFO comm 0x1544bc008fb0 rank 99 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 85: hkn0426:806571:806694 [1] NCCL INFO comm 0x14a724008fb0 rank 85 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 97: hkn0501:1320356:1320474 [1] NCCL INFO comm 0x153c98008fb0 rank 97 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 87: hkn0426:806598:806692 [3] NCCL INFO comm 0x14c11c008fb0 rank 87 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 84: hkn0426:806579:806691 [0] NCCL INFO comm 0x154900008fb0 rank 84 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
204: hkn0532:916658:916970 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 86: hkn0426:806587:806697 [2] NCCL INFO comm 0x151a68008fb0 rank 86 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
204: hkn0532:916658:916970 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
201: hkn0531:1223094:1223197 [1] NCCL INFO Channel 01 : 201[4b000] -> 200[31000] via P2P/IPC/read
205: hkn0532:916650:916971 [1] NCCL INFO comm 0x14eb34008fb0 rank 205 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
206: hkn0532:916669:916966 [2] NCCL INFO comm 0x14bae0008fb0 rank 206 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
217: hkn0601:110184:110286 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
207: hkn0532:916642:916973 [3] NCCL INFO comm 0x14f254008fb0 rank 207 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
217: hkn0601:110184:110286 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
204: hkn0532:916658:916970 [0] NCCL INFO comm 0x147be4008fb0 rank 204 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
252: hkn0611:702309:702428 [0] NCCL INFO Channel 01 : 508[31000] -> 252[31000] [receive] via NET/IBext/0
184: hkn0527:1341449:1341560 [0] NCCL INFO Channel 01 : 184[31000] -> 181[4b000] [send] via NET/IBext/0
216: hkn0601:110172:110280 [0] NCCL INFO Connected all trees
156: hkn0516:2908500:2908590 [0] NCCL INFO Channel 00 : 156[31000] -> 152[31000] [send] via NET/IBext/0
288: hkn0624:1765444:1765555 [0] NCCL INFO Connected all trees
288: hkn0624:1765444:1765555 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
216: hkn0601:110172:110280 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
288: hkn0624:1765444:1765555 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
216: hkn0601:110172:110280 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1751320:1751689 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [receive] via NET/IBext/0
289: hkn0624:1765436:1765548 [1] NCCL INFO Connected all trees
289: hkn0624:1765436:1765548 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
216: hkn0601:110172:110280 [0] NCCL INFO comm 0x154cec008fb0 rank 216 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
289: hkn0624:1765436:1765548 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
293: hkn0626:1290947:1291055 [1] NCCL INFO Connected all trees
219: hkn0601:110164:110279 [3] NCCL INFO comm 0x14ac0c008fb0 rank 219 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
189: hkn0528:1294214:1294319 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
217: hkn0601:110184:110286 [1] NCCL INFO comm 0x14874c008fb0 rank 217 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
293: hkn0626:1290947:1291055 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
218: hkn0601:110156:110284 [2] NCCL INFO comm 0x14908c008fb0 rank 218 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
293: hkn0626:1290947:1291055 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
289: hkn0624:1765436:1765548 [1] NCCL INFO comm 0x14913c008fb0 rank 289 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
292: hkn0626:1290939:1291061 [0] NCCL INFO Connected all trees
292: hkn0626:1290939:1291061 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
188: hkn0528:1294198:1294318 [0] NCCL INFO Connected all trees
291: hkn0624:1765456:1765549 [3] NCCL INFO comm 0x155274008fb0 rank 291 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
292: hkn0626:1290939:1291061 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
288: hkn0624:1765444:1765555 [0] NCCL INFO comm 0x148b0c008fb0 rank 288 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
292: hkn0626:1290939:1291061 [0] NCCL INFO comm 0x14daf4008fb0 rank 292 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
290: hkn0624:1765428:1765554 [2] NCCL INFO comm 0x14cbd8008fb0 rank 290 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
295: hkn0626:1290931:1291060 [3] NCCL INFO comm 0x151fd8008fb0 rank 295 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
294: hkn0626:1290959:1291053 [2] NCCL INFO comm 0x14b4e8008fb0 rank 294 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
188: hkn0528:1294198:1294318 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
293: hkn0626:1290947:1291055 [1] NCCL INFO comm 0x14ac24008fb0 rank 293 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
188: hkn0528:1294198:1294318 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
189: hkn0528:1294214:1294319 [1] NCCL INFO comm 0x14db04008fb0 rank 189 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 01 : 332[31000] -> 324[31000] [send] via NET/IBext/0
190: hkn0528:1294206:1294325 [2] NCCL INFO comm 0x145434008fb0 rank 190 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
368: hkn0712:287551:287669 [0] NCCL INFO Channel 00 : 376[31000] -> 368[31000] [receive] via NET/IBext/0
191: hkn0528:1294226:1294323 [3] NCCL INFO comm 0x14e4ac008fb0 rank 191 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
297: hkn0627:1780434:1780527 [1] NCCL INFO Connected all trees
297: hkn0627:1780434:1780527 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
188: hkn0528:1294198:1294318 [0] NCCL INFO comm 0x1474dc008fb0 rank 188 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
297: hkn0627:1780434:1780527 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
380: hkn0715:394410:394546 [0] NCCL INFO Channel 01 : 380[31000] -> 253[4b000] [send] via NET/IBext/0
164: hkn0521:1190286:1190438 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
296: hkn0627:1780414:1780535 [0] NCCL INFO Connected all trees
165: hkn0521:1190302:1190437 [1] NCCL INFO comm 0x14eb1c008fb0 rank 165 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
296: hkn0627:1780414:1780535 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 00 : 73[4b000] -> 72[31000] via P2P/IPC/read
296: hkn0627:1780414:1780535 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
164: hkn0521:1190286:1190438 [0] NCCL INFO comm 0x14c8cc008fb0 rank 164 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
299: hkn0627:1780422:1780529 [3] NCCL INFO comm 0x150f80008fb0 rank 299 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
166: hkn0521:1190294:1190442 [2] NCCL INFO comm 0x14d000008fb0 rank 166 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
297: hkn0627:1780434:1780527 [1] NCCL INFO comm 0x150f74008fb0 rank 297 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
167: hkn0521:1190314:1190440 [3] NCCL INFO comm 0x153890008fb0 rank 167 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
296: hkn0627:1780414:1780535 [0] NCCL INFO comm 0x14e574008fb0 rank 296 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 73: hkn0423:1697346:1697471 [1] NCCL INFO Channel 01 : 73[4b000] -> 72[31000] via P2P/IPC/read
469: hkn0804:1198123:1198240 [1] NCCL INFO Channel 00 : 469[4b000] -> 468[31000] via P2P/IPC/read
298: hkn0627:1780406:1780532 [2] NCCL INFO comm 0x147ac0008fb0 rank 298 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
461: hkn0802:1192842:1192951 [1] NCCL INFO Connected all trees
 72: hkn0423:1697374:1697469 [0] NCCL INFO Channel 01 : 72[31000] -> 69[4b000] [send] via NET/IBext/0
348: hkn0706:744758:744910 [0] NCCL INFO Channel 00 : 348[31000] -> 344[31000] [send] via NET/IBext/0
352: hkn0707:4012423:4012534 [0] NCCL INFO Channel 01 : 356[31000] -> 352[31000] [receive] via NET/IBext/0
461: hkn0802:1192842:1192951 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 33: hkn0412:2254900:2255017 [1] NCCL INFO Connected all trees
461: hkn0802:1192842:1192951 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
213: hkn0535:2391499:2391618 [1] NCCL INFO Channel 00 : 213[4b000] -> 212[31000] via P2P/IPC/read
 33: hkn0412:2254900:2255017 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
444: hkn0733:1381919:1382019 [0] NCCL INFO Channel 00 : 444[31000] -> 440[31000] [send] via NET/IBext/0
 33: hkn0412:2254900:2255017 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
213: hkn0535:2391499:2391618 [1] NCCL INFO Channel 01 : 213[4b000] -> 212[31000] via P2P/IPC/read
460: hkn0802:1192854:1192947 [0] NCCL INFO Connected all trees
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 01 : 140[31000] -> 132[31000] [send] via NET/IBext/0
 32: hkn0412:2254916:2255009 [0] NCCL INFO Connected all trees
212: hkn0535:2391491:2391620 [0] NCCL INFO Connected all trees
460: hkn0802:1192854:1192947 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 32: hkn0412:2254916:2255009 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
460: hkn0802:1192854:1192947 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2254916:2255009 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 33: hkn0412:2254900:2255017 [1] NCCL INFO comm 0x14f98c008fb0 rank 33 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
212: hkn0535:2391491:2391620 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
469: hkn0804:1198123:1198240 [1] NCCL INFO Channel 01 : 469[4b000] -> 468[31000] via P2P/IPC/read
 35: hkn0412:2254928:2255011 [3] NCCL INFO comm 0x14cfb8008fb0 rank 35 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 34: hkn0412:2254908:2255016 [2] NCCL INFO comm 0x1552c0008fb0 rank 34 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
212: hkn0535:2391491:2391620 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 32: hkn0412:2254916:2255009 [0] NCCL INFO comm 0x148620008fb0 rank 32 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
213: hkn0535:2391499:2391618 [1] NCCL INFO Connected all trees
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 00 : 457[4b000] -> 456[31000] via P2P/IPC/read
213: hkn0535:2391499:2391618 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
461: hkn0802:1192842:1192951 [1] NCCL INFO comm 0x14d284008fb0 rank 461 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
213: hkn0535:2391499:2391618 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:702329:702425 [1] NCCL INFO Channel 00 : 253[4b000] -> 252[31000] via P2P/IPC/read
213: hkn0535:2391499:2391618 [1] NCCL INFO comm 0x147510008fb0 rank 213 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
463: hkn0802:1192840:1192948 [3] NCCL INFO comm 0x148184008fb0 rank 463 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
200: hkn0531:1223086:1223206 [0] NCCL INFO Channel 01 : 200[31000] -> 197[4b000] [send] via NET/IBext/0
460: hkn0802:1192854:1192947 [0] NCCL INFO comm 0x148970008fb0 rank 460 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
215: hkn0535:2391507:2391619 [3] NCCL INFO comm 0x14a6fc008fb0 rank 215 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
462: hkn0802:1192841:1192950 [2] NCCL INFO comm 0x14c50c008fb0 rank 462 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
214: hkn0535:2391519:2391622 [2] NCCL INFO comm 0x14b80c008fb0 rank 214 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
212: hkn0535:2391491:2391620 [0] NCCL INFO comm 0x14b070008fb0 rank 212 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
445: hkn0733:1381907:1382020 [1] NCCL INFO Connected all trees
445: hkn0733:1381907:1382020 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:963191:963307 [0] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [receive] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 00 : 240[31000] -> 224[31000] [receive] via NET/IBext/0
445: hkn0733:1381907:1382020 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1381919:1382019 [0] NCCL INFO Connected all trees
484: hkn0808:963191:963307 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [send] via NET/IBext/0
444: hkn0733:1381919:1382019 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
485: hkn0808:963203:963306 [1] NCCL INFO Channel 00 : 485[4b000] -> 484[31000] via P2P/IPC/read
444: hkn0733:1381919:1382019 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
485: hkn0808:963203:963306 [1] NCCL INFO Channel 01 : 485[4b000] -> 484[31000] via P2P/IPC/read
445: hkn0733:1381907:1382020 [1] NCCL INFO comm 0x153fe0008fb0 rank 445 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 00 : 413[4b000] -> 414[ca000] via P2P/IPC/read
349: hkn0706:744786:744914 [1] NCCL INFO Connected all trees
446: hkn0733:1381899:1382018 [2] NCCL INFO comm 0x14ac58008fb0 rank 446 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
457: hkn0801:2232468:2232617 [1] NCCL INFO Channel 01 : 457[4b000] -> 456[31000] via P2P/IPC/read
 68: hkn0422:4145491:4145646 [0] NCCL INFO Channel 01 : 68[31000] -> 64[31000] [send] via NET/IBext/0
253: hkn0611:702329:702425 [1] NCCL INFO Channel 01 : 253[4b000] -> 252[31000] via P2P/IPC/read
349: hkn0706:744786:744914 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
349: hkn0706:744786:744914 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
444: hkn0733:1381919:1382019 [0] NCCL INFO comm 0x154144008fb0 rank 444 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
447: hkn0733:1381891:1382017 [3] NCCL INFO comm 0x14c574008fb0 rank 447 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
414: hkn0724:1708491:1708600 [2] NCCL INFO Channel 00 : 414[ca000] -> 415[e3000] via P2P/IPC/read
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 01 : 413[4b000] -> 414[ca000] via P2P/IPC/read
422: hkn0726:1540606:1540728 [2] NCCL INFO Connected all rings
414: hkn0724:1708491:1708600 [2] NCCL INFO Channel 01 : 414[ca000] -> 415[e3000] via P2P/IPC/read
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 01 : 420[31000] -> 421[4b000] via P2P/IPC/read
440: hkn0732:1204171:1204267 [0] NCCL INFO Channel 01 : 440[31000] -> 437[4b000] [send] via NET/IBext/0
415: hkn0724:1708503:1708602 [3] NCCL INFO Connected all trees
348: hkn0706:744758:744910 [0] NCCL INFO Connected all trees
415: hkn0724:1708503:1708602 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
415: hkn0724:1708503:1708602 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
421: hkn0726:1540614:1540729 [1] NCCL INFO Channel 00 : 421[4b000] -> 422[ca000] via P2P/IPC/read
348: hkn0706:744758:744910 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1708491:1708600 [2] NCCL INFO Connected all trees
357: hkn0708:405731:405869 [1] NCCL INFO Connected all trees
348: hkn0706:744758:744910 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
414: hkn0724:1708491:1708600 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
422: hkn0726:1540606:1540728 [2] NCCL INFO Channel 00 : 422[ca000] -> 423[e3000] via P2P/IPC/read
357: hkn0708:405731:405869 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1708491:1708600 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
357: hkn0708:405731:405869 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 00 : 408[31000] -> 412[31000] [receive] via NET/IBext/0
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [send] via NET/IBext/0
421: hkn0726:1540614:1540729 [1] NCCL INFO Channel 01 : 421[4b000] -> 422[ca000] via P2P/IPC/read
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 01 : 396[31000] -> 412[31000] [receive] via NET/IBext/0
422: hkn0726:1540606:1540728 [2] NCCL INFO Channel 01 : 422[ca000] -> 423[e3000] via P2P/IPC/read
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [receive] via NET/IBext/0
423: hkn0726:1540634:1540730 [3] NCCL INFO Connected all trees
468: hkn0804:1198143:1198246 [0] NCCL INFO Connected all trees
356: hkn0708:405715:405864 [0] NCCL INFO Connected all trees
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 01 : 412[31000] -> 444[31000] [send] via NET/IBext/0
423: hkn0726:1540634:1540730 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
468: hkn0804:1198143:1198246 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:405715:405864 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
468: hkn0804:1198143:1198246 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
356: hkn0708:405715:405864 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
349: hkn0706:744786:744914 [1] NCCL INFO comm 0x14f7dc008fb0 rank 349 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 00 : 413[4b000] -> 412[31000] via P2P/IPC/read
332: hkn0636:1646720:1646839 [0] NCCL INFO Channel 00 : 332[31000] -> 328[31000] [send] via NET/IBext/0
413: hkn0724:1708483:1708593 [1] NCCL INFO Channel 01 : 413[4b000] -> 412[31000] via P2P/IPC/read
350: hkn0706:744766:744917 [2] NCCL INFO comm 0x14911c008fb0 rank 350 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 01 : 444[31000] -> 412[31000] [receive] via NET/IBext/0
469: hkn0804:1198123:1198240 [1] NCCL INFO Connected all trees
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 01 : 412[31000] -> 396[31000] [send] via NET/IBext/0
351: hkn0706:744774:744912 [3] NCCL INFO comm 0x14636c008fb0 rank 351 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
412: hkn0724:1708475:1708596 [0] NCCL INFO Channel 00 : 412[31000] -> 408[31000] [send] via NET/IBext/0
469: hkn0804:1198123:1198240 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
356: hkn0708:405715:405864 [0] NCCL INFO comm 0x147740008fb0 rank 356 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
469: hkn0804:1198123:1198240 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
348: hkn0706:744758:744910 [0] NCCL INFO comm 0x1487d4008fb0 rank 348 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
357: hkn0708:405731:405869 [1] NCCL INFO comm 0x1493ec008fb0 rank 357 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
423: hkn0726:1540634:1540730 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:101008:101117 [0] NCCL INFO Channel 00 : 448[31000] -> 384[31000] [receive] via NET/IBext/0
422: hkn0726:1540606:1540728 [2] NCCL INFO Connected all trees
358: hkn0708:405723:405866 [2] NCCL INFO comm 0x14b0a8008fb0 rank 358 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
422: hkn0726:1540606:1540728 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1533356:1533475 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [receive] via NET/IBext/0
422: hkn0726:1540606:1540728 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1420907:1421018 [1] NCCL INFO Channel 00 : 181[4b000] -> 180[31000] via P2P/IPC/read
359: hkn0708:405743:405863 [3] NCCL INFO comm 0x1552c0008fb0 rank 359 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 01 : 416[31000] -> 420[31000] [receive] via NET/IBext/0
492: hkn0810:932042:932160 [0] NCCL INFO Channel 00 : 492[31000] -> 493[4b000] via P2P/IPC/read
469: hkn0804:1198123:1198240 [1] NCCL INFO comm 0x1456ac008fb0 rank 469 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
421: hkn0726:1540614:1540729 [1] NCCL INFO Channel 01 : 424[31000] -> 421[4b000] [receive] via NET/IBext/0
196: hkn0530:1250671:1250770 [0] NCCL INFO Channel 01 : 196[31000] -> 192[31000] [send] via NET/IBext/0
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 00 : 420[31000] -> 425[4b000] [send] via NET/IBext/0
468: hkn0804:1198143:1198246 [0] NCCL INFO comm 0x1478a4008fb0 rank 468 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [send] via NET/IBext/0
470: hkn0804:1198131:1198247 [2] NCCL INFO comm 0x14f858008fb0 rank 470 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
185: hkn0527:1341461:1341561 [1] NCCL INFO Connected all trees
185: hkn0527:1341461:1341561 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
185: hkn0527:1341461:1341561 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [receive] via NET/IBext/0
471: hkn0804:1198115:1198243 [3] NCCL INFO comm 0x14caa8008fb0 rank 471 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 00 : 425[4b000] -> 420[31000] [receive] via NET/IBext/0
113: hkn0505:2296285:2296401 [1] NCCL INFO Connected all trees
420: hkn0726:1540622:1540733 [0] NCCL INFO Channel 01 : 420[31000] -> 416[31000] [send] via NET/IBext/0
421: hkn0726:1540614:1540729 [1] NCCL INFO Channel 00 : 421[4b000] -> 420[31000] via P2P/IPC/read
494: hkn0810:932062:932167 [2] NCCL INFO Connected all rings
113: hkn0505:2296285:2296401 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
421: hkn0726:1540614:1540729 [1] NCCL INFO Channel 01 : 421[4b000] -> 420[31000] via P2P/IPC/read
113: hkn0505:2296285:2296401 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
421: hkn0726:1540614:1540729 [1] NCCL INFO Connected all trees
181: hkn0526:1420907:1421018 [1] NCCL INFO Channel 01 : 181[4b000] -> 180[31000] via P2P/IPC/read
184: hkn0527:1341449:1341560 [0] NCCL INFO Connected all trees
157: hkn0516:2908488:2908596 [1] NCCL INFO Connected all trees
157: hkn0516:2908488:2908596 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4012423:4012534 [0] NCCL INFO Connected all trees
157: hkn0516:2908488:2908596 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
184: hkn0527:1341449:1341560 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
184: hkn0527:1341449:1341560 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
112: hkn0505:2296308:2296407 [0] NCCL INFO Connected all trees
380: hkn0715:394410:394546 [0] NCCL INFO Channel 01 : 380[31000] -> 316[31000] [send] via NET/IBext/0
352: hkn0707:4012423:4012534 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
112: hkn0505:2296308:2296407 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
352: hkn0707:4012423:4012534 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
112: hkn0505:2296308:2296407 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
421: hkn0726:1540614:1540729 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
156: hkn0516:2908500:2908590 [0] NCCL INFO Connected all trees
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 01 : 396[31000] -> 388[31000] [send] via NET/IBext/0
421: hkn0726:1540614:1540729 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:932042:932160 [0] NCCL INFO Channel 01 : 492[31000] -> 493[4b000] via P2P/IPC/read
156: hkn0516:2908500:2908590 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
353: hkn0707:4012439:4012533 [1] NCCL INFO Connected all trees
156: hkn0516:2908500:2908590 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
186: hkn0527:1341433:1341555 [2] NCCL INFO comm 0x14c620008fb0 rank 186 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
353: hkn0707:4012439:4012533 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
420: hkn0726:1540622:1540733 [0] NCCL INFO Connected all trees
185: hkn0527:1341461:1341561 [1] NCCL INFO comm 0x14cd9c008fb0 rank 185 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
353: hkn0707:4012439:4012533 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
187: hkn0527:1341441:1341554 [3] NCCL INFO comm 0x14f188008fb0 rank 187 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
112: hkn0505:2296308:2296407 [0] NCCL INFO comm 0x14d338008fb0 rank 112 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
184: hkn0527:1341449:1341560 [0] NCCL INFO comm 0x14ba44008fb0 rank 184 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
420: hkn0726:1540622:1540733 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
113: hkn0505:2296285:2296401 [1] NCCL INFO comm 0x14e0cc008fb0 rank 113 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
420: hkn0726:1540622:1540733 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
115: hkn0505:2296296:2296404 [3] NCCL INFO comm 0x145730008fb0 rank 115 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
421: hkn0726:1540614:1540729 [1] NCCL INFO comm 0x14d814008fb0 rank 421 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
157: hkn0516:2908488:2908596 [1] NCCL INFO comm 0x149258008fb0 rank 157 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
114: hkn0505:2296288:2296402 [2] NCCL INFO comm 0x150c5c008fb0 rank 114 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
420: hkn0726:1540622:1540733 [0] NCCL INFO comm 0x1550cc008fb0 rank 420 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
493: hkn0810:932050:932165 [1] NCCL INFO Channel 00 : 493[4b000] -> 494[ca000] via P2P/IPC/read
158: hkn0516:2908472:2908599 [2] NCCL INFO comm 0x1520a8008fb0 rank 158 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
352: hkn0707:4012423:4012534 [0] NCCL INFO comm 0x153710008fb0 rank 352 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
159: hkn0516:2908480:2908594 [3] NCCL INFO comm 0x1510d8008fb0 rank 159 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
354: hkn0707:4012451:4012539 [2] NCCL INFO comm 0x14c7f4008fb0 rank 354 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
156: hkn0516:2908500:2908590 [0] NCCL INFO comm 0x149fd8008fb0 rank 156 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
256: hkn0612:909459:909583 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [receive] via NET/IBext/0
368: hkn0712:287551:287669 [0] NCCL INFO Channel 01 : 372[31000] -> 368[31000] [receive] via NET/IBext/0
 73: hkn0423:1697346:1697471 [1] NCCL INFO Connected all trees
 73: hkn0423:1697346:1697471 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
353: hkn0707:4012439:4012533 [1] NCCL INFO comm 0x14e470008fb0 rank 353 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 69: hkn0422:4145507:4145651 [1] NCCL INFO Channel 00 : 69[4b000] -> 68[31000] via P2P/IPC/read
 73: hkn0423:1697346:1697471 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
355: hkn0707:4012431:4012540 [3] NCCL INFO comm 0x147ccc008fb0 rank 355 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
344: hkn0705:775713:775862 [0] NCCL INFO Channel 01 : 344[31000] -> 341[4b000] [send] via NET/IBext/0
422: hkn0726:1540606:1540728 [2] NCCL INFO comm 0x14ead4008fb0 rank 422 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
494: hkn0810:932062:932167 [2] NCCL INFO Channel 00 : 494[ca000] -> 495[e3000] via P2P/IPC/read
423: hkn0726:1540634:1540730 [3] NCCL INFO comm 0x154110008fb0 rank 423 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
493: hkn0810:932050:932165 [1] NCCL INFO Channel 01 : 493[4b000] -> 494[ca000] via P2P/IPC/read
 72: hkn0423:1697374:1697469 [0] NCCL INFO Connected all trees
494: hkn0810:932062:932167 [2] NCCL INFO Channel 01 : 494[ca000] -> 495[e3000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 00 : 329[4b000] -> 324[31000] [receive] via NET/IBext/0
 72: hkn0423:1697374:1697469 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 72: hkn0423:1697374:1697469 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:424562:424665 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [receive] via NET/IBext/0
252: hkn0611:702309:702428 [0] NCCL INFO Channel 01 : 252[31000] -> 508[31000] [send] via NET/IBext/0
495: hkn0810:932034:932161 [3] NCCL INFO Connected all trees
495: hkn0810:932034:932161 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:929896:930007 [0] NCCL INFO Channel 00 : 488[31000] -> 489[4b000] via P2P/IPC/read
495: hkn0810:932034:932161 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
488: hkn0809:929896:930007 [0] NCCL INFO Channel 01 : 488[31000] -> 489[4b000] via P2P/IPC/read
181: hkn0526:1420907:1421018 [1] NCCL INFO Connected all trees
494: hkn0810:932062:932167 [2] NCCL INFO Connected all trees
494: hkn0810:932062:932167 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
489: hkn0809:929888:930005 [1] NCCL INFO Channel 00 : 489[4b000] -> 490[ca000] via P2P/IPC/read
181: hkn0526:1420907:1421018 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
494: hkn0810:932062:932167 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1420907:1421018 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:932042:932160 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [receive] via NET/IBext/0
 73: hkn0423:1697346:1697471 [1] NCCL INFO comm 0x14971c008fb0 rank 73 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
493: hkn0810:932050:932165 [1] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [send] via NET/IBext/0
 74: hkn0423:1697354:1697472 [2] NCCL INFO comm 0x14f394008fb0 rank 74 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
492: hkn0810:932042:932160 [0] NCCL INFO Channel 01 : 484[31000] -> 492[31000] [receive] via NET/IBext/0
180: hkn0526:1420918:1421023 [0] NCCL INFO Connected all trees
 72: hkn0423:1697374:1697469 [0] NCCL INFO comm 0x154524008fb0 rank 72 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
492: hkn0810:932042:932160 [0] NCCL INFO Channel 01 : 477[4b000] -> 492[31000] [receive] via NET/IBext/0
490: hkn0809:929907:930004 [2] NCCL INFO Channel 00 : 490[ca000] -> 491[e3000] via P2P/IPC/read
180: hkn0526:1420918:1421023 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:932050:932165 [1] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [receive] via NET/IBext/0
180: hkn0526:1420918:1421023 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:932042:932160 [0] NCCL INFO Channel 01 : 492[31000] -> 477[4b000] [send] via NET/IBext/0
 69: hkn0422:4145507:4145651 [1] NCCL INFO Channel 01 : 69[4b000] -> 68[31000] via P2P/IPC/read
 75: hkn0423:1697362:1697475 [3] NCCL INFO comm 0x14de58008fb0 rank 75 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
493: hkn0810:932050:932165 [1] NCCL INFO Channel 00 : 493[4b000] -> 492[31000] via P2P/IPC/read
489: hkn0809:929888:930005 [1] NCCL INFO Channel 01 : 489[4b000] -> 490[ca000] via P2P/IPC/read
201: hkn0531:1223094:1223197 [1] NCCL INFO Connected all trees
493: hkn0810:932050:932165 [1] NCCL INFO Channel 01 : 493[4b000] -> 492[31000] via P2P/IPC/read
492: hkn0810:932042:932160 [0] NCCL INFO Channel 01 : 492[31000] -> 484[31000] [send] via NET/IBext/0
490: hkn0809:929907:930004 [2] NCCL INFO Channel 01 : 490[ca000] -> 491[e3000] via P2P/IPC/read
201: hkn0531:1223094:1223197 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
492: hkn0810:932042:932160 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [send] via NET/IBext/0
180: hkn0526:1420918:1421023 [0] NCCL INFO comm 0x14ba44008fb0 rank 180 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
201: hkn0531:1223094:1223197 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
181: hkn0526:1420907:1421018 [1] NCCL INFO comm 0x1526d8008fb0 rank 181 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
197: hkn0530:1250643:1250765 [1] NCCL INFO Channel 00 : 197[4b000] -> 196[31000] via P2P/IPC/read
493: hkn0810:932050:932165 [1] NCCL INFO Connected all trees
491: hkn0809:929880:930000 [3] NCCL INFO Connected all trees
200: hkn0531:1223086:1223206 [0] NCCL INFO Connected all trees
493: hkn0810:932050:932165 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:932050:932165 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
491: hkn0809:929880:930000 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
182: hkn0526:1420936:1421020 [2] NCCL INFO comm 0x14a058008fb0 rank 182 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
200: hkn0531:1223086:1223206 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
200: hkn0531:1223086:1223206 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:932042:932160 [0] NCCL INFO Connected all trees
183: hkn0526:1420898:1421019 [3] NCCL INFO comm 0x151330008fb0 rank 183 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
492: hkn0810:932042:932160 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
492: hkn0810:932042:932160 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
491: hkn0809:929880:930000 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
492: hkn0810:932042:932160 [0] NCCL INFO comm 0x1545fc008fb0 rank 492 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
490: hkn0809:929907:930004 [2] NCCL INFO Connected all trees
494: hkn0810:932062:932167 [2] NCCL INFO comm 0x1493fc008fb0 rank 494 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
490: hkn0809:929907:930004 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
493: hkn0810:932050:932165 [1] NCCL INFO comm 0x14fffc008fb0 rank 493 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
490: hkn0809:929907:930004 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
200: hkn0531:1223086:1223206 [0] NCCL INFO comm 0x145dac008fb0 rank 200 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
488: hkn0809:929896:930007 [0] NCCL INFO Channel 00 : 488[31000] -> 492[31000] [send] via NET/IBext/0
437: hkn0731:1379256:1379351 [1] NCCL INFO Channel 00 : 437[4b000] -> 436[31000] via P2P/IPC/read
495: hkn0810:932034:932161 [3] NCCL INFO comm 0x14b7d8008fb0 rank 495 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
201: hkn0531:1223094:1223197 [1] NCCL INFO comm 0x152660008fb0 rank 201 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
489: hkn0809:929888:930005 [1] NCCL INFO Channel 00 : 484[31000] -> 489[4b000] [receive] via NET/IBext/0
203: hkn0531:1223106:1223204 [3] NCCL INFO comm 0x14f818008fb0 rank 203 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
412: hkn0724:1708475:1708596 [0] NCCL INFO Connected all trees
440: hkn0732:1204171:1204267 [0] NCCL INFO Connected all trees
202: hkn0531:1223078:1223201 [2] NCCL INFO comm 0x155030008fb0 rank 202 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
452: hkn0736:1500850:1500969 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [send] via NET/IBext/0
412: hkn0724:1708475:1708596 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
440: hkn0732:1204171:1204267 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
412: hkn0724:1708475:1708596 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
440: hkn0732:1204171:1204267 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
488: hkn0809:929896:930007 [0] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [send] via NET/IBext/0
488: hkn0809:929896:930007 [0] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [receive] via NET/IBext/0
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 01 : 472[31000] -> 473[4b000] via P2P/IPC/read
197: hkn0530:1250643:1250765 [1] NCCL INFO Channel 01 : 197[4b000] -> 196[31000] via P2P/IPC/read
489: hkn0809:929888:930005 [1] NCCL INFO Channel 00 : 489[4b000] -> 484[31000] [send] via NET/IBext/0
488: hkn0809:929896:930007 [0] NCCL INFO Channel 00 : 492[31000] -> 488[31000] [receive] via NET/IBext/0
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 00 : 473[4b000] -> 474[ca000] via P2P/IPC/read
413: hkn0724:1708483:1708593 [1] NCCL INFO Connected all trees
489: hkn0809:929888:930005 [1] NCCL INFO Channel 00 : 489[4b000] -> 488[31000] via P2P/IPC/read
456: hkn0801:2232460:2232615 [0] NCCL INFO Channel 01 : 456[31000] -> 453[4b000] [send] via NET/IBext/0
441: hkn0732:1204159:1204268 [1] NCCL INFO Connected all trees
437: hkn0731:1379256:1379351 [1] NCCL INFO Channel 01 : 437[4b000] -> 436[31000] via P2P/IPC/read
413: hkn0724:1708483:1708593 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
441: hkn0732:1204159:1204268 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
413: hkn0724:1708483:1708593 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
441: hkn0732:1204159:1204268 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 68: hkn0422:4145491:4145646 [0] NCCL INFO Connected all trees
 68: hkn0422:4145491:4145646 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
489: hkn0809:929888:930005 [1] NCCL INFO Channel 01 : 489[4b000] -> 488[31000] via P2P/IPC/read
 68: hkn0422:4145491:4145646 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
488: hkn0809:929896:930007 [0] NCCL INFO Channel 01 : 488[31000] -> 485[4b000] [send] via NET/IBext/0
489: hkn0809:929888:930005 [1] NCCL INFO Connected all trees
474: hkn0805:1104630:1104729 [2] NCCL INFO Channel 00 : 474[ca000] -> 475[e3000] via P2P/IPC/read
489: hkn0809:929888:930005 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 01 : 473[4b000] -> 474[ca000] via P2P/IPC/read
489: hkn0809:929888:930005 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
474: hkn0805:1104630:1104729 [2] NCCL INFO Channel 01 : 474[ca000] -> 475[e3000] via P2P/IPC/read
333: hkn0636:1646748:1646841 [1] NCCL INFO Connected all trees
413: hkn0724:1708483:1708593 [1] NCCL INFO comm 0x14a94c008fb0 rank 413 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
333: hkn0636:1646748:1646841 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:929896:930007 [0] NCCL INFO Connected all trees
 69: hkn0422:4145507:4145651 [1] NCCL INFO Connected all trees
333: hkn0636:1646748:1646841 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 69: hkn0422:4145507:4145651 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
414: hkn0724:1708491:1708600 [2] NCCL INFO comm 0x14ba04008fb0 rank 414 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 69: hkn0422:4145507:4145651 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
412: hkn0724:1708475:1708596 [0] NCCL INFO comm 0x14930c008fb0 rank 412 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
440: hkn0732:1204171:1204267 [0] NCCL INFO comm 0x14f388008fb0 rank 440 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
415: hkn0724:1708503:1708602 [3] NCCL INFO comm 0x1489c8008fb0 rank 415 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
140: hkn0512:3036647:3036768 [0] NCCL INFO Channel 00 : 140[31000] -> 136[31000] [send] via NET/IBext/0
332: hkn0636:1646720:1646839 [0] NCCL INFO Connected all trees
442: hkn0732:1204151:1204273 [2] NCCL INFO comm 0x14ac24008fb0 rank 442 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
488: hkn0809:929896:930007 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
332: hkn0636:1646720:1646839 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
488: hkn0809:929896:930007 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
332: hkn0636:1646720:1646839 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
489: hkn0809:929888:930005 [1] NCCL INFO comm 0x1480a0008fb0 rank 489 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
441: hkn0732:1204159:1204268 [1] NCCL INFO comm 0x149d9c008fb0 rank 441 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
490: hkn0809:929907:930004 [2] NCCL INFO comm 0x14744c008fb0 rank 490 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 68: hkn0422:4145491:4145646 [0] NCCL INFO comm 0x150d40008fb0 rank 68 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
488: hkn0809:929896:930007 [0] NCCL INFO comm 0x14c00c008fb0 rank 488 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
443: hkn0732:1204148:1204274 [3] NCCL INFO comm 0x14b358008fb0 rank 443 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 71: hkn0422:4145519:4145652 [3] NCCL INFO comm 0x154470008fb0 rank 71 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 69: hkn0422:4145507:4145651 [1] NCCL INFO comm 0x147700008fb0 rank 69 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
491: hkn0809:929880:930000 [3] NCCL INFO comm 0x14e184008fb0 rank 491 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 65: hkn0421:2172257:2172526 [1] NCCL INFO Connected all trees
475: hkn0805:1104618:1104726 [3] NCCL INFO Connected all trees
 65: hkn0421:2172257:2172526 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
475: hkn0805:1104618:1104726 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 65: hkn0421:2172257:2172526 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
475: hkn0805:1104618:1104726 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
334: hkn0636:1646736:1646844 [2] NCCL INFO comm 0x1519ec008fb0 rank 334 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
474: hkn0805:1104630:1104729 [2] NCCL INFO Connected all trees
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 00 : 329[4b000] -> 328[31000] via P2P/IPC/read
474: hkn0805:1104630:1104729 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 70: hkn0422:4145499:4145645 [2] NCCL INFO comm 0x15269c008fb0 rank 70 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
335: hkn0636:1646728:1646847 [3] NCCL INFO comm 0x153008008fb0 rank 335 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
474: hkn0805:1104630:1104729 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
496: hkn0812:686285:686394 [0] NCCL INFO Connected all rings
 64: hkn0421:2172277:2172524 [0] NCCL INFO Connected all trees
332: hkn0636:1646720:1646839 [0] NCCL INFO comm 0x14b428008fb0 rank 332 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 64: hkn0421:2172277:2172524 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
333: hkn0636:1646748:1646841 [1] NCCL INFO comm 0x14a61c008fb0 rank 333 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 64: hkn0421:2172277:2172524 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 00 : 472[31000] -> 476[31000] [send] via NET/IBext/0
436: hkn0731:1379234:1379347 [0] NCCL INFO Connected all trees
197: hkn0530:1250643:1250765 [1] NCCL INFO Connected all trees
240: hkn0607:896885:896985 [0] NCCL INFO Channel 00 : 248[31000] -> 240[31000] [receive] via NET/IBext/0
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 00 : 468[31000] -> 473[4b000] [receive] via NET/IBext/0
436: hkn0731:1379234:1379347 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
197: hkn0530:1250643:1250765 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
436: hkn0731:1379234:1379347 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
197: hkn0530:1250643:1250765 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
152: hkn0515:2889297:2889406 [0] NCCL INFO Channel 01 : 152[31000] -> 149[4b000] [send] via NET/IBext/0
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 00 : 464[31000] -> 472[31000] [receive] via NET/IBext/0
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 00 : 473[4b000] -> 468[31000] [send] via NET/IBext/0
497: hkn0812:686297:686395 [1] NCCL INFO Channel 00 : 497[4b000] -> 498[ca000] via P2P/IPC/read
196: hkn0530:1250671:1250770 [0] NCCL INFO Connected all trees
329: hkn0635:1218103:1218214 [1] NCCL INFO Channel 01 : 329[4b000] -> 328[31000] via P2P/IPC/read
 64: hkn0421:2172277:2172524 [0] NCCL INFO comm 0x152a28008fb0 rank 64 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 00 : 472[31000] -> 464[31000] [send] via NET/IBext/0
437: hkn0731:1379256:1379351 [1] NCCL INFO Connected all trees
196: hkn0530:1250671:1250770 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 66: hkn0421:2172265:2172522 [2] NCCL INFO comm 0x14c4b8008fb0 rank 66 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
196: hkn0530:1250671:1250770 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
437: hkn0731:1379256:1379351 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 67: hkn0421:2172249:2172523 [3] NCCL INFO comm 0x14d5c4008fb0 rank 67 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
437: hkn0731:1379256:1379351 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 65: hkn0421:2172257:2172526 [1] NCCL INFO comm 0x1496a8008fb0 rank 65 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 00 : 473[4b000] -> 472[31000] via P2P/IPC/read
496: hkn0812:686285:686394 [0] NCCL INFO Channel 00 : 496[31000] -> 497[4b000] via P2P/IPC/read
473: hkn0805:1104610:1104724 [1] NCCL INFO Channel 01 : 473[4b000] -> 472[31000] via P2P/IPC/read
498: hkn0812:686269:686396 [2] NCCL INFO Channel 00 : 498[ca000] -> 499[e3000] via P2P/IPC/read
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 00 : 476[31000] -> 472[31000] [receive] via NET/IBext/0
497: hkn0812:686297:686395 [1] NCCL INFO Channel 01 : 497[4b000] -> 498[ca000] via P2P/IPC/read
472: hkn0805:1104602:1104720 [0] NCCL INFO Channel 01 : 472[31000] -> 469[4b000] [send] via NET/IBext/0
496: hkn0812:686285:686394 [0] NCCL INFO Channel 01 : 496[31000] -> 497[4b000] via P2P/IPC/read
198: hkn0530:1250651:1250763 [2] NCCL INFO comm 0x150db8008fb0 rank 198 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
473: hkn0805:1104610:1104724 [1] NCCL INFO Connected all trees
192: hkn0529:1533356:1533475 [0] NCCL INFO Connected all trees
473: hkn0805:1104610:1104724 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
437: hkn0731:1379256:1379351 [1] NCCL INFO comm 0x154130008fb0 rank 437 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
197: hkn0530:1250643:1250765 [1] NCCL INFO comm 0x14f0fc008fb0 rank 197 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
192: hkn0529:1533356:1533475 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
199: hkn0530:1250659:1250771 [3] NCCL INFO comm 0x14d2b8008fb0 rank 199 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
192: hkn0529:1533356:1533475 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
438: hkn0731:1379244:1379355 [2] NCCL INFO comm 0x14a02c008fb0 rank 438 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
196: hkn0530:1250671:1250770 [0] NCCL INFO comm 0x14e478008fb0 rank 196 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
473: hkn0805:1104610:1104724 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
472: hkn0805:1104602:1104720 [0] NCCL INFO Connected all trees
498: hkn0812:686269:686396 [2] NCCL INFO Channel 01 : 498[ca000] -> 499[e3000] via P2P/IPC/read
344: hkn0705:775713:775862 [0] NCCL INFO Connected all trees
472: hkn0805:1104602:1104720 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
439: hkn0731:1379236:1379354 [3] NCCL INFO comm 0x150528008fb0 rank 439 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
472: hkn0805:1104602:1104720 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
436: hkn0731:1379234:1379347 [0] NCCL INFO comm 0x145488008fb0 rank 436 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
473: hkn0805:1104610:1104724 [1] NCCL INFO comm 0x14a8dc008fb0 rank 473 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
193: hkn0529:1533348:1533477 [1] NCCL INFO Connected all trees
475: hkn0805:1104618:1104726 [3] NCCL INFO comm 0x14a3e8008fb0 rank 475 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
344: hkn0705:775713:775862 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
472: hkn0805:1104602:1104720 [0] NCCL INFO comm 0x151f98008fb0 rank 472 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
193: hkn0529:1533348:1533477 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
344: hkn0705:775713:775862 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
193: hkn0529:1533348:1533477 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
474: hkn0805:1104630:1104729 [2] NCCL INFO comm 0x153068008fb0 rank 474 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
499: hkn0812:686277:686393 [3] NCCL INFO Connected all trees
501: hkn0814:668331:668452 [1] NCCL INFO Connected all rings
345: hkn0705:775705:775864 [1] NCCL INFO Connected all trees
499: hkn0812:686277:686393 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 00 : 480[31000] -> 448[31000] [receive] via NET/IBext/0
499: hkn0812:686277:686393 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
498: hkn0812:686269:686396 [2] NCCL INFO Connected all trees
500: hkn0814:668339:668453 [0] NCCL INFO Channel 00 : 500[31000] -> 501[4b000] via P2P/IPC/read
498: hkn0812:686269:686396 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
502: hkn0814:668347:668457 [2] NCCL INFO Connected all rings
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 00 : 137[4b000] -> 132[31000] [receive] via NET/IBext/0
345: hkn0705:775705:775864 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
192: hkn0529:1533356:1533475 [0] NCCL INFO comm 0x14f960008fb0 rank 192 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
345: hkn0705:775705:775864 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
498: hkn0812:686269:686396 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
500: hkn0814:668339:668453 [0] NCCL INFO Channel 01 : 500[31000] -> 501[4b000] via P2P/IPC/read
496: hkn0812:686285:686394 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [send] via NET/IBext/0
501: hkn0814:668331:668452 [1] NCCL INFO Channel 00 : 501[4b000] -> 502[ca000] via P2P/IPC/read
195: hkn0529:1533364:1533476 [3] NCCL INFO comm 0x14a078008fb0 rank 195 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
497: hkn0812:686297:686395 [1] NCCL INFO Channel 00 : 488[31000] -> 497[4b000] [receive] via NET/IBext/0
193: hkn0529:1533348:1533477 [1] NCCL INFO comm 0x14fc1c008fb0 rank 193 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
496: hkn0812:686285:686394 [0] NCCL INFO Channel 00 : 496[31000] -> 504[31000] [send] via NET/IBext/0
194: hkn0529:1533376:1533479 [2] NCCL INFO comm 0x1504c0008fb0 rank 194 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
345: hkn0705:775705:775864 [1] NCCL INFO comm 0x145de4008fb0 rank 345 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
497: hkn0812:686297:686395 [1] NCCL INFO Channel 00 : 497[4b000] -> 488[31000] [send] via NET/IBext/0
502: hkn0814:668347:668457 [2] NCCL INFO Channel 00 : 502[ca000] -> 503[e3000] via P2P/IPC/read
497: hkn0812:686297:686395 [1] NCCL INFO Channel 00 : 497[4b000] -> 496[31000] via P2P/IPC/read
501: hkn0814:668331:668452 [1] NCCL INFO Channel 01 : 501[4b000] -> 502[ca000] via P2P/IPC/read
497: hkn0812:686297:686395 [1] NCCL INFO Channel 01 : 497[4b000] -> 496[31000] via P2P/IPC/read
502: hkn0814:668347:668457 [2] NCCL INFO Channel 01 : 502[ca000] -> 503[e3000] via P2P/IPC/read
344: hkn0705:775713:775862 [0] NCCL INFO comm 0x14eff4008fb0 rank 344 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
496: hkn0812:686285:686394 [0] NCCL INFO Channel 00 : 480[31000] -> 496[31000] [receive] via NET/IBext/0
224: hkn0603:1405683:1405780 [0] NCCL INFO Channel 01 : 228[31000] -> 224[31000] [receive] via NET/IBext/0
396: hkn0719:1298187:1298341 [0] NCCL INFO Channel 00 : 396[31000] -> 392[31000] [send] via NET/IBext/0
496: hkn0812:686285:686394 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [send] via NET/IBext/0
503: hkn0814:668359:668454 [3] NCCL INFO Connected all trees
380: hkn0715:394410:394546 [0] NCCL INFO Channel 00 : 380[31000] -> 376[31000] [send] via NET/IBext/0
503: hkn0814:668359:668454 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
346: hkn0705:775721:775863 [2] NCCL INFO comm 0x150d6c008fb0 rank 346 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
503: hkn0814:668359:668454 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
347: hkn0705:775733:775855 [3] NCCL INFO comm 0x147f18008fb0 rank 347 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
502: hkn0814:668347:668457 [2] NCCL INFO Connected all trees
502: hkn0814:668347:668457 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 01 : 428[31000] -> 429[4b000] via P2P/IPC/read
502: hkn0814:668347:668457 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 00 : 429[4b000] -> 430[ca000] via P2P/IPC/read
500: hkn0814:668339:668453 [0] NCCL INFO Channel 01 : 496[31000] -> 500[31000] [receive] via NET/IBext/0
430: hkn0728:1316485:1316584 [2] NCCL INFO Channel 00 : 430[ca000] -> 431[e3000] via P2P/IPC/read
501: hkn0814:668331:668452 [1] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [receive] via NET/IBext/0
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 01 : 429[4b000] -> 430[ca000] via P2P/IPC/read
500: hkn0814:668339:668453 [0] NCCL INFO Channel 00 : 500[31000] -> 505[4b000] [send] via NET/IBext/0
430: hkn0728:1316485:1316584 [2] NCCL INFO Channel 01 : 430[ca000] -> 431[e3000] via P2P/IPC/read
408: hkn0723:200389:200535 [0] NCCL INFO Channel 01 : 408[31000] -> 405[4b000] [send] via NET/IBext/0
500: hkn0814:668339:668453 [0] NCCL INFO Channel 01 : 493[4b000] -> 500[31000] [receive] via NET/IBext/0
500: hkn0814:668339:668453 [0] NCCL INFO Channel 01 : 500[31000] -> 493[4b000] [send] via NET/IBext/0
431: hkn0728:1316457:1316577 [3] NCCL INFO Connected all trees
500: hkn0814:668339:668453 [0] NCCL INFO Channel 00 : 505[4b000] -> 500[31000] [receive] via NET/IBext/0
431: hkn0728:1316457:1316577 [3] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
500: hkn0814:668339:668453 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [send] via NET/IBext/0
431: hkn0728:1316457:1316577 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
341: hkn0704:784510:784629 [1] NCCL INFO Channel 00 : 341[4b000] -> 340[31000] via P2P/IPC/read
430: hkn0728:1316485:1316584 [2] NCCL INFO Connected all trees
430: hkn0728:1316485:1316584 [2] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
430: hkn0728:1316485:1316584 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 00 : 424[31000] -> 428[31000] [receive] via NET/IBext/0
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 01 : 429[4b000] -> 436[31000] [send] via NET/IBext/0
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 01 : 420[31000] -> 428[31000] [receive] via NET/IBext/0
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 01 : 413[4b000] -> 428[31000] [receive] via NET/IBext/0
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 01 : 436[31000] -> 429[4b000] [receive] via NET/IBext/0
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 01 : 428[31000] -> 413[4b000] [send] via NET/IBext/0
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 00 : 429[4b000] -> 428[31000] via P2P/IPC/read
429: hkn0728:1316473:1316578 [1] NCCL INFO Channel 01 : 429[4b000] -> 428[31000] via P2P/IPC/read
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 01 : 428[31000] -> 420[31000] [send] via NET/IBext/0
384: hkn0716:101008:101117 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [receive] via NET/IBext/0
453: hkn0736:1500847:1500961 [1] NCCL INFO Channel 00 : 453[4b000] -> 452[31000] via P2P/IPC/read
428: hkn0728:1316465:1316582 [0] NCCL INFO Channel 00 : 428[31000] -> 424[31000] [send] via NET/IBext/0
429: hkn0728:1316473:1316578 [1] NCCL INFO Connected all trees
429: hkn0728:1316473:1316578 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
429: hkn0728:1316473:1316578 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
428: hkn0728:1316465:1316582 [0] NCCL INFO Connected all trees
428: hkn0728:1316465:1316582 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
428: hkn0728:1316465:1316582 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
431: hkn0728:1316457:1316577 [3] NCCL INFO comm 0x153b80008fb0 rank 431 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
341: hkn0704:784510:784629 [1] NCCL INFO Channel 01 : 341[4b000] -> 340[31000] via P2P/IPC/read
428: hkn0728:1316465:1316582 [0] NCCL INFO comm 0x14842c008fb0 rank 428 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
429: hkn0728:1316473:1316578 [1] NCCL INFO comm 0x1495f0008fb0 rank 429 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
430: hkn0728:1316485:1316584 [2] NCCL INFO comm 0x150468008fb0 rank 430 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
453: hkn0736:1500847:1500961 [1] NCCL INFO Channel 01 : 453[4b000] -> 452[31000] via P2P/IPC/read
369: hkn0712:287543:287667 [1] NCCL INFO Connected all trees
369: hkn0712:287543:287667 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:287543:287667 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 01 : 316[31000] -> 284[31000] [send] via NET/IBext/0
328: hkn0635:1218095:1218212 [0] NCCL INFO Channel 01 : 328[31000] -> 325[4b000] [send] via NET/IBext/0
140: hkn0512:3036647:3036768 [0] NCCL INFO Connected all trees
140: hkn0512:3036647:3036768 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
140: hkn0512:3036647:3036768 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
368: hkn0712:287551:287669 [0] NCCL INFO Connected all trees
368: hkn0712:287551:287669 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
368: hkn0712:287551:287669 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
457: hkn0801:2232468:2232617 [1] NCCL INFO Connected all trees
457: hkn0801:2232468:2232617 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
369: hkn0712:287543:287667 [1] NCCL INFO comm 0x14e6f8008fb0 rank 369 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
457: hkn0801:2232468:2232617 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
141: hkn0512:3036663:3036774 [1] NCCL INFO Connected all trees
371: hkn0712:287571:287663 [3] NCCL INFO comm 0x14da7c008fb0 rank 371 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
370: hkn0712:287559:287664 [2] NCCL INFO comm 0x153620008fb0 rank 370 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
368: hkn0712:287551:287669 [0] NCCL INFO comm 0x14b928008fb0 rank 368 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
141: hkn0512:3036663:3036774 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 00 : 137[4b000] -> 136[31000] via P2P/IPC/read
141: hkn0512:3036663:3036774 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 00 : 393[4b000] -> 388[31000] [receive] via NET/IBext/0
456: hkn0801:2232460:2232615 [0] NCCL INFO Connected all trees
456: hkn0801:2232460:2232615 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
456: hkn0801:2232460:2232615 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
153: hkn0515:2889289:2889409 [1] NCCL INFO Connected all trees
340: hkn0704:784518:784625 [0] NCCL INFO Connected all trees
153: hkn0515:2889289:2889409 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
153: hkn0515:2889289:2889409 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
340: hkn0704:784518:784625 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
340: hkn0704:784518:784625 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
143: hkn0512:3036675:3036769 [3] NCCL INFO comm 0x150acc008fb0 rank 143 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
137: hkn0511:3058866:3058981 [1] NCCL INFO Channel 01 : 137[4b000] -> 136[31000] via P2P/IPC/read
152: hkn0515:2889297:2889406 [0] NCCL INFO Connected all trees
140: hkn0512:3036647:3036768 [0] NCCL INFO comm 0x151ae0008fb0 rank 140 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
141: hkn0512:3036663:3036774 [1] NCCL INFO comm 0x14fd6c008fb0 rank 141 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
152: hkn0515:2889297:2889406 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
341: hkn0704:784510:784629 [1] NCCL INFO Connected all trees
152: hkn0515:2889297:2889406 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
457: hkn0801:2232468:2232617 [1] NCCL INFO comm 0x149ad8008fb0 rank 457 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
149: hkn0514:2943234:2943343 [1] NCCL INFO Channel 00 : 149[4b000] -> 148[31000] via P2P/IPC/read
341: hkn0704:784510:784629 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
142: hkn0512:3036655:3036775 [2] NCCL INFO comm 0x14dbec008fb0 rank 142 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
341: hkn0704:784510:784629 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
456: hkn0801:2232460:2232615 [0] NCCL INFO comm 0x147dfc008fb0 rank 456 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
458: hkn0801:2232476:2232619 [2] NCCL INFO comm 0x14f6b0008fb0 rank 458 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
459: hkn0801:2232488:2232616 [3] NCCL INFO comm 0x154ae0008fb0 rank 459 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
153: hkn0515:2889289:2889409 [1] NCCL INFO comm 0x15533c008fb0 rank 153 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
155: hkn0515:2889309:2889405 [3] NCCL INFO comm 0x154b20008fb0 rank 155 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
340: hkn0704:784518:784625 [0] NCCL INFO comm 0x14dd10008fb0 rank 340 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
154: hkn0515:2889281:2889407 [2] NCCL INFO comm 0x146610008fb0 rank 154 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
152: hkn0515:2889297:2889406 [0] NCCL INFO comm 0x15075c008fb0 rank 152 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
342: hkn0704:784530:784630 [2] NCCL INFO comm 0x145728008fb0 rank 342 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
343: hkn0704:784502:784626 [3] NCCL INFO comm 0x14fedc008fb0 rank 343 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
341: hkn0704:784510:784629 [1] NCCL INFO comm 0x151dc8008fb0 rank 341 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
149: hkn0514:2943234:2943343 [1] NCCL INFO Channel 01 : 149[4b000] -> 148[31000] via P2P/IPC/read
324: hkn0634:1513353:1513483 [0] NCCL INFO Channel 01 : 324[31000] -> 320[31000] [send] via NET/IBext/0
508: hkn0816:368125:368237 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [send] via NET/IBext/0
381: hkn0715:394422:394551 [1] NCCL INFO Connected all trees
381: hkn0715:394422:394551 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
381: hkn0715:394422:394551 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
397: hkn0719:1298203:1298338 [1] NCCL INFO Connected all trees
397: hkn0719:1298203:1298338 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
397: hkn0719:1298203:1298338 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:681744:681864 [1] NCCL INFO Connected all trees
229: hkn0604:681744:681864 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
396: hkn0719:1298187:1298341 [0] NCCL INFO Connected all trees
396: hkn0719:1298187:1298341 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
229: hkn0604:681744:681864 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
396: hkn0719:1298187:1298341 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
409: hkn0723:200369:200533 [1] NCCL INFO Connected all trees
409: hkn0723:200369:200533 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
409: hkn0723:200369:200533 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
228: hkn0604:681736:681856 [0] NCCL INFO Connected all trees
228: hkn0604:681736:681856 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
228: hkn0604:681736:681856 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
148: hkn0514:2943218:2943338 [0] NCCL INFO Connected all trees
248: hkn0609:703361:703450 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [receive] via NET/IBext/0
408: hkn0723:200389:200535 [0] NCCL INFO Connected all trees
148: hkn0514:2943218:2943338 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
148: hkn0514:2943218:2943338 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 00 : 393[4b000] -> 392[31000] via P2P/IPC/read
396: hkn0719:1298187:1298341 [0] NCCL INFO comm 0x14c8b4008fb0 rank 396 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
408: hkn0723:200389:200535 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
408: hkn0723:200389:200535 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
399: hkn0719:1298195:1298344 [3] NCCL INFO comm 0x1489dc008fb0 rank 399 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
397: hkn0719:1298203:1298338 [1] NCCL INFO comm 0x14b240008fb0 rank 397 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
398: hkn0719:1298217:1298339 [2] NCCL INFO comm 0x14d8b4008fb0 rank 398 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
228: hkn0604:681736:681856 [0] NCCL INFO comm 0x14c760008fb0 rank 228 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
149: hkn0514:2943234:2943343 [1] NCCL INFO Connected all trees
405: hkn0721:2291522:2291616 [1] NCCL INFO Channel 00 : 405[4b000] -> 404[31000] via P2P/IPC/read
230: hkn0604:681752:681859 [2] NCCL INFO comm 0x151648008fb0 rank 230 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
149: hkn0514:2943234:2943343 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
380: hkn0715:394410:394546 [0] NCCL INFO Connected all trees
380: hkn0715:394410:394546 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
149: hkn0514:2943234:2943343 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
231: hkn0604:681764:681862 [3] NCCL INFO comm 0x1535f0008fb0 rank 231 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
409: hkn0723:200369:200533 [1] NCCL INFO comm 0x14a6c4008fb0 rank 409 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
380: hkn0715:394410:394546 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
229: hkn0604:681744:681864 [1] NCCL INFO comm 0x153c80008fb0 rank 229 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
410: hkn0723:200364:200541 [2] NCCL INFO comm 0x14ab24008fb0 rank 410 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
252: hkn0611:702309:702428 [0] NCCL INFO Channel 01 : 252[31000] -> 124[31000] [send] via NET/IBext/0
408: hkn0723:200389:200535 [0] NCCL INFO comm 0x14fca8008fb0 rank 408 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
411: hkn0723:200377:200540 [3] NCCL INFO comm 0x150b38008fb0 rank 411 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
393: hkn0718:3909494:3909650 [1] NCCL INFO Channel 01 : 393[4b000] -> 392[31000] via P2P/IPC/read
149: hkn0514:2943234:2943343 [1] NCCL INFO comm 0x14d3ac008fb0 rank 149 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
148: hkn0514:2943218:2943338 [0] NCCL INFO comm 0x14b3c8008fb0 rank 148 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
381: hkn0715:394422:394551 [1] NCCL INFO comm 0x147880008fb0 rank 381 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
150: hkn0514:2943226:2943345 [2] NCCL INFO comm 0x147b7c008fb0 rank 150 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
136: hkn0511:3058878:3058984 [0] NCCL INFO Channel 01 : 136[31000] -> 133[4b000] [send] via NET/IBext/0
383: hkn0715:394394:394548 [3] NCCL INFO comm 0x145844008fb0 rank 383 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
151: hkn0514:2943246:2943339 [3] NCCL INFO comm 0x146e2c008fb0 rank 151 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
382: hkn0715:394402:394547 [2] NCCL INFO comm 0x14c428008fb0 rank 382 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
380: hkn0715:394410:394546 [0] NCCL INFO comm 0x14fccc008fb0 rank 380 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
405: hkn0721:2291522:2291616 [1] NCCL INFO Channel 01 : 405[4b000] -> 404[31000] via P2P/IPC/read
225: hkn0603:1405664:1405775 [1] NCCL INFO Connected all trees
225: hkn0603:1405664:1405775 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
225: hkn0603:1405664:1405775 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
329: hkn0635:1218103:1218214 [1] NCCL INFO Connected all trees
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 00 : 496[31000] -> 480[31000] [receive] via NET/IBext/0
329: hkn0635:1218103:1218214 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1513380:1513484 [1] NCCL INFO Channel 00 : 325[4b000] -> 324[31000] via P2P/IPC/read
329: hkn0635:1218103:1218214 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
224: hkn0603:1405683:1405780 [0] NCCL INFO Connected all trees
328: hkn0635:1218095:1218212 [0] NCCL INFO Connected all trees
224: hkn0603:1405683:1405780 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
224: hkn0603:1405683:1405780 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
328: hkn0635:1218095:1218212 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
328: hkn0635:1218095:1218212 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:896885:896985 [0] NCCL INFO Channel 01 : 244[31000] -> 240[31000] [receive] via NET/IBext/0
226: hkn0603:1405672:1405779 [2] NCCL INFO comm 0x14d024008fb0 rank 226 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
328: hkn0635:1218095:1218212 [0] NCCL INFO comm 0x14c050008fb0 rank 328 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
227: hkn0603:1405656:1405782 [3] NCCL INFO comm 0x148914008fb0 rank 227 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
329: hkn0635:1218103:1218214 [1] NCCL INFO comm 0x151d54008fb0 rank 329 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
224: hkn0603:1405683:1405780 [0] NCCL INFO comm 0x1470f0008fb0 rank 224 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
330: hkn0635:1218111:1218207 [2] NCCL INFO comm 0x14f3b0008fb0 rank 330 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
225: hkn0603:1405664:1405775 [1] NCCL INFO comm 0x14c174008fb0 rank 225 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
331: hkn0635:1218123:1218208 [3] NCCL INFO comm 0x14b7ac008fb0 rank 331 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
325: hkn0634:1513380:1513484 [1] NCCL INFO Channel 01 : 325[4b000] -> 324[31000] via P2P/IPC/read
404: hkn0721:2291503:2291621 [0] NCCL INFO Connected all trees
404: hkn0721:2291503:2291621 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
404: hkn0721:2291503:2291621 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2754595:2754687 [0] NCCL INFO Channel 01 : 132[31000] -> 128[31000] [send] via NET/IBext/0
316: hkn0632:1751127:1751225 [0] NCCL INFO Channel 00 : 316[31000] -> 312[31000] [send] via NET/IBext/0
405: hkn0721:2291522:2291616 [1] NCCL INFO Connected all trees
405: hkn0721:2291522:2291616 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
405: hkn0721:2291522:2291616 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
448: hkn0734:1149085:1149196 [0] NCCL INFO Channel 01 : 452[31000] -> 448[31000] [receive] via NET/IBext/0
404: hkn0721:2291503:2291621 [0] NCCL INFO comm 0x149984008fb0 rank 404 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
406: hkn0721:2291495:2291615 [2] NCCL INFO comm 0x1498a4008fb0 rank 406 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
405: hkn0721:2291522:2291616 [1] NCCL INFO comm 0x149cd4008fb0 rank 405 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
325: hkn0634:1513380:1513484 [1] NCCL INFO Connected all trees
407: hkn0721:2291511:2291619 [3] NCCL INFO comm 0x14e6a8008fb0 rank 407 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
325: hkn0634:1513380:1513484 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
325: hkn0634:1513380:1513484 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1513353:1513483 [0] NCCL INFO Connected all trees
324: hkn0634:1513353:1513483 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3909502:3909648 [0] NCCL INFO Channel 01 : 392[31000] -> 389[4b000] [send] via NET/IBext/0
324: hkn0634:1513353:1513483 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
324: hkn0634:1513353:1513483 [0] NCCL INFO comm 0x153ad4008fb0 rank 324 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
325: hkn0634:1513380:1513484 [1] NCCL INFO comm 0x1534bc008fb0 rank 325 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
326: hkn0634:1513361:1513475 [2] NCCL INFO comm 0x14fe30008fb0 rank 326 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
327: hkn0634:1513369:1513478 [3] NCCL INFO comm 0x14e6b0008fb0 rank 327 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
321: hkn0633:1518835:1518968 [1] NCCL INFO Connected all trees
321: hkn0633:1518835:1518968 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
321: hkn0633:1518835:1518968 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 01 : 284[31000] -> 268[31000] [send] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO Connected all trees
376: hkn0714:424562:424665 [0] NCCL INFO Channel 01 : 376[31000] -> 373[4b000] [send] via NET/IBext/0
320: hkn0633:1518863:1518964 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
320: hkn0633:1518863:1518964 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
137: hkn0511:3058866:3058981 [1] NCCL INFO Connected all trees
320: hkn0633:1518863:1518964 [0] NCCL INFO comm 0x155374008fb0 rank 320 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
137: hkn0511:3058866:3058981 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
137: hkn0511:3058866:3058981 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
322: hkn0633:1518843:1518959 [2] NCCL INFO comm 0x14a850008fb0 rank 322 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
323: hkn0633:1518851:1518965 [3] NCCL INFO comm 0x14abd4008fb0 rank 323 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
321: hkn0633:1518835:1518968 [1] NCCL INFO comm 0x146408008fb0 rank 321 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
133: hkn0510:2754575:2754694 [1] NCCL INFO Channel 00 : 133[4b000] -> 132[31000] via P2P/IPC/read
136: hkn0511:3058878:3058984 [0] NCCL INFO Connected all trees
136: hkn0511:3058878:3058984 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
136: hkn0511:3058878:3058984 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
388: hkn0717:4180092:4180225 [0] NCCL INFO Channel 01 : 388[31000] -> 384[31000] [send] via NET/IBext/0
136: hkn0511:3058878:3058984 [0] NCCL INFO comm 0x15261c008fb0 rank 136 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
138: hkn0511:3058850:3058979 [2] NCCL INFO comm 0x14d208008fb0 rank 138 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
139: hkn0511:3058858:3058978 [3] NCCL INFO comm 0x149b68008fb0 rank 139 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
137: hkn0511:3058866:3058981 [1] NCCL INFO comm 0x146f20008fb0 rank 137 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
133: hkn0510:2754575:2754694 [1] NCCL INFO Channel 01 : 133[4b000] -> 132[31000] via P2P/IPC/read
317: hkn0632:1751107:1751230 [1] NCCL INFO Connected all trees
317: hkn0632:1751107:1751230 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
317: hkn0632:1751107:1751230 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
453: hkn0736:1500847:1500961 [1] NCCL INFO Connected all trees
453: hkn0736:1500847:1500961 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
453: hkn0736:1500847:1500961 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
452: hkn0736:1500850:1500969 [0] NCCL INFO Connected all trees
452: hkn0736:1500850:1500969 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
316: hkn0632:1751127:1751225 [0] NCCL INFO Connected all trees
316: hkn0632:1751127:1751225 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
452: hkn0736:1500850:1500969 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
316: hkn0632:1751127:1751225 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
132: hkn0510:2754595:2754687 [0] NCCL INFO Connected all trees
132: hkn0510:2754595:2754687 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
132: hkn0510:2754595:2754687 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
319: hkn0632:1751115:1751226 [3] NCCL INFO comm 0x149ca4008fb0 rank 319 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
133: hkn0510:2754575:2754694 [1] NCCL INFO Connected all trees
316: hkn0632:1751127:1751225 [0] NCCL INFO comm 0x145930008fb0 rank 316 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
133: hkn0510:2754575:2754694 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
241: hkn0607:896873:896982 [1] NCCL INFO Connected all trees
453: hkn0736:1500847:1500961 [1] NCCL INFO comm 0x149f08008fb0 rank 453 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
133: hkn0510:2754575:2754694 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
241: hkn0607:896873:896982 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
454: hkn0736:1500869:1500964 [2] NCCL INFO comm 0x14e0a0008fb0 rank 454 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
241: hkn0607:896873:896982 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
455: hkn0736:1500858:1500966 [3] NCCL INFO comm 0x148a84008fb0 rank 455 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
452: hkn0736:1500850:1500969 [0] NCCL INFO comm 0x151d70008fb0 rank 452 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
317: hkn0632:1751107:1751230 [1] NCCL INFO comm 0x14eddc008fb0 rank 317 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
318: hkn0632:1751099:1751227 [2] NCCL INFO comm 0x148a3c008fb0 rank 318 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
240: hkn0607:896885:896985 [0] NCCL INFO Connected all trees
240: hkn0607:896885:896985 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
240: hkn0607:896885:896985 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
133: hkn0510:2754575:2754694 [1] NCCL INFO comm 0x14aa48008fb0 rank 133 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
393: hkn0718:3909494:3909650 [1] NCCL INFO Connected all trees
134: hkn0510:2754583:2754692 [2] NCCL INFO comm 0x148430008fb0 rank 134 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
389: hkn0717:4180100:4180219 [1] NCCL INFO Channel 00 : 389[4b000] -> 388[31000] via P2P/IPC/read
132: hkn0510:2754595:2754687 [0] NCCL INFO comm 0x14b548008fb0 rank 132 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
393: hkn0718:3909494:3909650 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3909494:3909650 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
135: hkn0510:2754567:2754688 [3] NCCL INFO comm 0x145d5c008fb0 rank 135 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
128: hkn0509:3116916:3117017 [0] NCCL INFO Connected all trees
242: hkn0607:896865:896980 [2] NCCL INFO comm 0x145c54008fb0 rank 242 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
128: hkn0509:3116916:3117017 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
128: hkn0509:3116916:3117017 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
392: hkn0718:3909502:3909648 [0] NCCL INFO Connected all trees
252: hkn0611:702309:702428 [0] NCCL INFO Channel 00 : 252[31000] -> 248[31000] [send] via NET/IBext/0
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 01 : 124[31000] -> 60[31000] [send] via NET/IBext/0
243: hkn0607:896857:896978 [3] NCCL INFO comm 0x154f88008fb0 rank 243 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
448: hkn0734:1149085:1149196 [0] NCCL INFO Connected all trees
392: hkn0718:3909502:3909648 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
392: hkn0718:3909502:3909648 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
448: hkn0734:1149085:1149196 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
448: hkn0734:1149085:1149196 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
240: hkn0607:896885:896985 [0] NCCL INFO comm 0x14f46c008fb0 rank 240 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
241: hkn0607:896873:896982 [1] NCCL INFO comm 0x14ddac008fb0 rank 241 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
129: hkn0509:3116896:3117018 [1] NCCL INFO Connected all trees
129: hkn0509:3116896:3117018 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
129: hkn0509:3116896:3117018 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
449: hkn0734:1149097:1149191 [1] NCCL INFO Connected all trees
392: hkn0718:3909502:3909648 [0] NCCL INFO comm 0x14a2a8008fb0 rank 392 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
449: hkn0734:1149097:1149191 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
393: hkn0718:3909494:3909650 [1] NCCL INFO comm 0x14ca50008fb0 rank 393 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
449: hkn0734:1149097:1149191 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:462731:462877 [1] NCCL INFO Channel 00 : 373[4b000] -> 372[31000] via P2P/IPC/read
394: hkn0718:3909522:3909643 [2] NCCL INFO comm 0x150508008fb0 rank 394 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
395: hkn0718:3909510:3909645 [3] NCCL INFO comm 0x14e800008fb0 rank 395 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
128: hkn0509:3116916:3117017 [0] NCCL INFO comm 0x1519e4008fb0 rank 128 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
130: hkn0509:3116904:3117014 [2] NCCL INFO comm 0x1473cc008fb0 rank 130 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
450: hkn0734:1149069:1149195 [2] NCCL INFO comm 0x14b578008fb0 rank 450 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
449: hkn0734:1149097:1149191 [1] NCCL INFO comm 0x14f438008fb0 rank 449 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
131: hkn0509:3116888:3117013 [3] NCCL INFO comm 0x14ef44008fb0 rank 131 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
129: hkn0509:3116896:3117018 [1] NCCL INFO comm 0x14b7ac008fb0 rank 129 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
448: hkn0734:1149085:1149196 [0] NCCL INFO comm 0x14da2c008fb0 rank 448 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
451: hkn0734:1149077:1149192 [3] NCCL INFO comm 0x14809c008fb0 rank 451 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
373: hkn0713:462731:462877 [1] NCCL INFO Channel 01 : 373[4b000] -> 372[31000] via P2P/IPC/read
389: hkn0717:4180100:4180219 [1] NCCL INFO Channel 01 : 389[4b000] -> 388[31000] via P2P/IPC/read
377: hkn0714:424551:424658 [1] NCCL INFO Connected all trees
377: hkn0714:424551:424658 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
377: hkn0714:424551:424658 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
376: hkn0714:424562:424665 [0] NCCL INFO Connected all trees
376: hkn0714:424562:424665 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
376: hkn0714:424562:424665 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
480: hkn0807:1011577:1011693 [0] NCCL INFO Channel 01 : 484[31000] -> 480[31000] [receive] via NET/IBext/0
496: hkn0812:686285:686394 [0] NCCL INFO Channel 00 : 504[31000] -> 496[31000] [receive] via NET/IBext/0
312: hkn0631:1014294:1014414 [0] NCCL INFO Channel 01 : 312[31000] -> 309[4b000] [send] via NET/IBext/0
379: hkn0714:424543:424659 [3] NCCL INFO comm 0x1545e4008fb0 rank 379 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
377: hkn0714:424551:424658 [1] NCCL INFO comm 0x1511b8008fb0 rank 377 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
378: hkn0714:424535:424664 [2] NCCL INFO comm 0x14bea0008fb0 rank 378 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
376: hkn0714:424562:424665 [0] NCCL INFO comm 0x14e7b4008fb0 rank 376 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
388: hkn0717:4180092:4180225 [0] NCCL INFO Connected all trees
388: hkn0717:4180092:4180225 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
373: hkn0713:462731:462877 [1] NCCL INFO Connected all trees
388: hkn0717:4180092:4180225 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:462731:462877 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
373: hkn0713:462731:462877 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
372: hkn0713:462723:462881 [0] NCCL INFO Connected all trees
389: hkn0717:4180100:4180219 [1] NCCL INFO Connected all trees
389: hkn0717:4180100:4180219 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
372: hkn0713:462723:462881 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
389: hkn0717:4180100:4180219 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1865258:1865355 [0] NCCL INFO Channel 00 : 284[31000] -> 280[31000] [send] via NET/IBext/0
372: hkn0713:462723:462881 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
385: hkn0716:101000:101120 [1] NCCL INFO Connected all trees
385: hkn0716:101000:101120 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
385: hkn0716:101000:101120 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
384: hkn0716:101008:101117 [0] NCCL INFO Connected all trees
372: hkn0713:462723:462881 [0] NCCL INFO comm 0x153b6c008fb0 rank 372 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
388: hkn0717:4180092:4180225 [0] NCCL INFO comm 0x150844008fb0 rank 388 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
374: hkn0713:462739:462878 [2] NCCL INFO comm 0x147d30008fb0 rank 374 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
389: hkn0717:4180100:4180219 [1] NCCL INFO comm 0x151e74008fb0 rank 389 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
375: hkn0713:462751:462876 [3] NCCL INFO comm 0x14ee50008fb0 rank 375 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
384: hkn0716:101008:101117 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
390: hkn0717:4180120:4180224 [2] NCCL INFO comm 0x145b44008fb0 rank 390 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
384: hkn0716:101008:101117 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
373: hkn0713:462731:462877 [1] NCCL INFO comm 0x146a90008fb0 rank 373 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
391: hkn0717:4180108:4180218 [3] NCCL INFO comm 0x14a39c008fb0 rank 391 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
385: hkn0716:101000:101120 [1] NCCL INFO comm 0x151f20008fb0 rank 385 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
384: hkn0716:101008:101117 [0] NCCL INFO comm 0x14b0d8008fb0 rank 384 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
386: hkn0716:101020:101119 [2] NCCL INFO comm 0x14a67c008fb0 rank 386 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
387: hkn0716:100997:101122 [3] NCCL INFO comm 0x152f68008fb0 rank 387 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
268: hkn0616:397357:397478 [0] NCCL INFO Channel 01 : 268[31000] -> 260[31000] [send] via NET/IBext/0
253: hkn0611:702329:702425 [1] NCCL INFO Connected all trees
253: hkn0611:702329:702425 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
253: hkn0611:702329:702425 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
252: hkn0611:702309:702428 [0] NCCL INFO Connected all trees
252: hkn0611:702309:702428 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
252: hkn0611:702309:702428 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
253: hkn0611:702329:702425 [1] NCCL INFO comm 0x14dfd8008fb0 rank 253 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
254: hkn0611:702301:702422 [2] NCCL INFO comm 0x146674008fb0 rank 254 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
255: hkn0611:702317:702419 [3] NCCL INFO comm 0x14662c008fb0 rank 255 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
252: hkn0611:702309:702428 [0] NCCL INFO comm 0x1490b0008fb0 rank 252 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
485: hkn0808:963203:963306 [1] NCCL INFO Connected all trees
485: hkn0808:963203:963306 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
485: hkn0808:963203:963306 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3131620:3131734 [0] NCCL INFO Channel 00 : 124[31000] -> 120[31000] [send] via NET/IBext/0
313: hkn0631:1014302:1014419 [1] NCCL INFO Connected all trees
484: hkn0808:963191:963307 [0] NCCL INFO Connected all trees
313: hkn0631:1014302:1014419 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
313: hkn0631:1014302:1014419 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
484: hkn0808:963191:963307 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
484: hkn0808:963191:963307 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
309: hkn0630:1590958:1591101 [1] NCCL INFO Channel 00 : 309[4b000] -> 308[31000] via P2P/IPC/read
312: hkn0631:1014294:1014414 [0] NCCL INFO Connected all trees
312: hkn0631:1014294:1014414 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
312: hkn0631:1014294:1014414 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
486: hkn0808:963183:963303 [2] NCCL INFO comm 0x147078008fb0 rank 486 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
487: hkn0808:963175:963302 [3] NCCL INFO comm 0x150920008fb0 rank 487 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
484: hkn0808:963191:963307 [0] NCCL INFO comm 0x1495e0008fb0 rank 484 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
485: hkn0808:963203:963306 [1] NCCL INFO comm 0x1496ec008fb0 rank 485 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
309: hkn0630:1590958:1591101 [1] NCCL INFO Channel 01 : 309[4b000] -> 308[31000] via P2P/IPC/read
314: hkn0631:1014322:1014417 [2] NCCL INFO comm 0x154698008fb0 rank 314 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
313: hkn0631:1014302:1014419 [1] NCCL INFO comm 0x148a8c008fb0 rank 313 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
315: hkn0631:1014310:1014411 [3] NCCL INFO comm 0x149c28008fb0 rank 315 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
312: hkn0631:1014294:1014414 [0] NCCL INFO comm 0x153940008fb0 rank 312 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
285: hkn0623:1865230:1865352 [1] NCCL INFO Connected all trees
285: hkn0623:1865230:1865352 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
285: hkn0623:1865230:1865352 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
480: hkn0807:1011577:1011693 [0] NCCL INFO Connected all trees
480: hkn0807:1011577:1011693 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
480: hkn0807:1011577:1011693 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
284: hkn0623:1865258:1865355 [0] NCCL INFO Connected all trees
284: hkn0623:1865258:1865355 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
284: hkn0623:1865258:1865355 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:703361:703450 [0] NCCL INFO Channel 01 : 248[31000] -> 245[4b000] [send] via NET/IBext/0
481: hkn0807:1011585:1011697 [1] NCCL INFO Connected all trees
481: hkn0807:1011585:1011697 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
481: hkn0807:1011585:1011697 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
286: hkn0623:1865246:1865351 [2] NCCL INFO comm 0x145e58008fb0 rank 286 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
285: hkn0623:1865230:1865352 [1] NCCL INFO comm 0x153304008fb0 rank 285 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
284: hkn0623:1865258:1865355 [0] NCCL INFO comm 0x14d09c008fb0 rank 284 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
504: hkn0815:387632:387784 [0] NCCL INFO Channel 00 : 508[31000] -> 504[31000] [receive] via NET/IBext/0
481: hkn0807:1011585:1011697 [1] NCCL INFO comm 0x149350008fb0 rank 481 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
480: hkn0807:1011577:1011693 [0] NCCL INFO comm 0x145d50008fb0 rank 480 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
483: hkn0807:1011596:1011696 [3] NCCL INFO comm 0x155354008fb0 rank 483 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
482: hkn0807:1011569:1011689 [2] NCCL INFO comm 0x152828008fb0 rank 482 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
309: hkn0630:1590958:1591101 [1] NCCL INFO Connected all trees
287: hkn0623:1865238:1865357 [3] NCCL INFO comm 0x155098008fb0 rank 287 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
309: hkn0630:1590958:1591101 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 01 : 60[31000] -> 28[31000] [send] via NET/IBext/0
309: hkn0630:1590958:1591101 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
308: hkn0630:1590950:1591102 [0] NCCL INFO Connected all trees
308: hkn0630:1590950:1591102 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
308: hkn0630:1590950:1591102 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
311: hkn0630:1590970:1591099 [3] NCCL INFO comm 0x1454f8008fb0 rank 311 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
309: hkn0630:1590958:1591101 [1] NCCL INFO comm 0x1521ac008fb0 rank 309 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
308: hkn0630:1590950:1591102 [0] NCCL INFO comm 0x150b98008fb0 rank 308 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
310: hkn0630:1590942:1591100 [2] NCCL INFO comm 0x146f80008fb0 rank 310 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
268: hkn0616:397357:397478 [0] NCCL INFO Channel 00 : 268[31000] -> 264[31000] [send] via NET/IBext/0
280: hkn0622:2012990:2013090 [0] NCCL INFO Channel 01 : 280[31000] -> 277[4b000] [send] via NET/IBext/0
125: hkn0508:3131636:3131730 [1] NCCL INFO Connected all trees
125: hkn0508:3131636:3131730 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
125: hkn0508:3131636:3131730 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3131620:3131734 [0] NCCL INFO Connected all trees
124: hkn0508:3131620:3131734 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
124: hkn0508:3131620:3131734 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
124: hkn0508:3131620:3131734 [0] NCCL INFO comm 0x1525ec008fb0 rank 124 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
125: hkn0508:3131636:3131730 [1] NCCL INFO comm 0x153028008fb0 rank 125 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
127: hkn0508:3131628:3131736 [3] NCCL INFO comm 0x146520008fb0 rank 127 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
496: hkn0812:686285:686394 [0] NCCL INFO Channel 01 : 500[31000] -> 496[31000] [receive] via NET/IBext/0
126: hkn0508:3131648:3131731 [2] NCCL INFO comm 0x14d620008fb0 rank 126 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
245: hkn0608:478274:478386 [1] NCCL INFO Channel 00 : 245[4b000] -> 244[31000] via P2P/IPC/read
249: hkn0609:703333:703446 [1] NCCL INFO Connected all trees
249: hkn0609:703333:703446 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
249: hkn0609:703333:703446 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
248: hkn0609:703361:703450 [0] NCCL INFO Connected all trees
245: hkn0608:478274:478386 [1] NCCL INFO Channel 01 : 245[4b000] -> 244[31000] via P2P/IPC/read
248: hkn0609:703361:703450 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
248: hkn0609:703361:703450 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
249: hkn0609:703333:703446 [1] NCCL INFO comm 0x1521bc008fb0 rank 249 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
248: hkn0609:703361:703450 [0] NCCL INFO comm 0x14889c008fb0 rank 248 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
260: hkn0613:895195:895293 [0] NCCL INFO Channel 00 : 265[4b000] -> 260[31000] [receive] via NET/IBext/0
509: hkn0816:368127:368238 [1] NCCL INFO Connected all trees
509: hkn0816:368127:368238 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
509: hkn0816:368127:368238 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
250: hkn0609:703349:703447 [2] NCCL INFO comm 0x1453e0008fb0 rank 250 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
251: hkn0609:703341:703443 [3] NCCL INFO comm 0x14bad4008fb0 rank 251 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
508: hkn0816:368125:368237 [0] NCCL INFO Connected all trees
508: hkn0816:368125:368237 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
508: hkn0816:368125:368237 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
509: hkn0816:368127:368238 [1] NCCL INFO comm 0x149b2c008fb0 rank 509 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
244: hkn0608:478258:478384 [0] NCCL INFO Connected all trees
508: hkn0816:368125:368237 [0] NCCL INFO comm 0x151014008fb0 rank 508 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
244: hkn0608:478258:478384 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
244: hkn0608:478258:478384 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
510: hkn0816:368135:368243 [2] NCCL INFO comm 0x152608008fb0 rank 510 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
511: hkn0816:368147:368244 [3] NCCL INFO comm 0x153be8008fb0 rank 511 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
245: hkn0608:478274:478386 [1] NCCL INFO Connected all trees
245: hkn0608:478274:478386 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
245: hkn0608:478274:478386 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:397357:397478 [0] NCCL INFO Connected all trees
268: hkn0616:397357:397478 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
268: hkn0616:397357:397478 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
244: hkn0608:478258:478384 [0] NCCL INFO comm 0x14a87c008fb0 rank 244 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
245: hkn0608:478274:478386 [1] NCCL INFO comm 0x15539c008fb0 rank 245 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
246: hkn0608:478266:478383 [2] NCCL INFO comm 0x153e28008fb0 rank 246 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
247: hkn0608:478286:478382 [3] NCCL INFO comm 0x14d878008fb0 rank 247 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 60: hkn0420:3202709:3202825 [0] NCCL INFO Channel 00 : 60[31000] -> 56[31000] [send] via NET/IBext/0
120: hkn0507:3179581:3179694 [0] NCCL INFO Channel 01 : 120[31000] -> 117[4b000] [send] via NET/IBext/0
269: hkn0616:397377:397476 [1] NCCL INFO Connected all trees
269: hkn0616:397377:397476 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
269: hkn0616:397377:397476 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
281: hkn0622:2012970:2013094 [1] NCCL INFO Connected all trees
281: hkn0622:2012970:2013094 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
281: hkn0622:2012970:2013094 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
268: hkn0616:397357:397478 [0] NCCL INFO comm 0x14a0a0008fb0 rank 268 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
280: hkn0622:2012990:2013090 [0] NCCL INFO Connected all trees
269: hkn0616:397377:397476 [1] NCCL INFO comm 0x14fc9c008fb0 rank 269 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
280: hkn0622:2012990:2013090 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
271: hkn0616:397365:397472 [3] NCCL INFO comm 0x151510008fb0 rank 271 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
280: hkn0622:2012990:2013090 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:1984016:1984143 [1] NCCL INFO Channel 00 : 277[4b000] -> 276[31000] via P2P/IPC/read
270: hkn0616:397349:397480 [2] NCCL INFO comm 0x14e43c008fb0 rank 270 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
281: hkn0622:2012970:2013094 [1] NCCL INFO comm 0x14e4f8008fb0 rank 281 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
280: hkn0622:2012990:2013090 [0] NCCL INFO comm 0x152a60008fb0 rank 280 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
283: hkn0622:2012962:2013089 [3] NCCL INFO comm 0x14567c008fb0 rank 283 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
282: hkn0622:2012978:2013091 [2] NCCL INFO comm 0x14c494008fb0 rank 282 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
277: hkn0621:1984016:1984143 [1] NCCL INFO Channel 01 : 277[4b000] -> 276[31000] via P2P/IPC/read
504: hkn0815:387632:387784 [0] NCCL INFO Channel 01 : 504[31000] -> 501[4b000] [send] via NET/IBext/0
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 01 : 28[31000] -> 12[31000] [send] via NET/IBext/0
265: hkn0615:406807:406907 [1] NCCL INFO Channel 00 : 265[4b000] -> 264[31000] via P2P/IPC/read
277: hkn0621:1984016:1984143 [1] NCCL INFO Connected all trees
277: hkn0621:1984016:1984143 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
277: hkn0621:1984016:1984143 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:406807:406907 [1] NCCL INFO Channel 01 : 265[4b000] -> 264[31000] via P2P/IPC/read
276: hkn0621:1984044:1984134 [0] NCCL INFO Connected all trees
276: hkn0621:1984044:1984134 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
276: hkn0621:1984044:1984134 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
277: hkn0621:1984016:1984143 [1] NCCL INFO comm 0x14e3ac008fb0 rank 277 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
279: hkn0621:1984024:1984141 [3] NCCL INFO comm 0x14fa64008fb0 rank 279 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
276: hkn0621:1984044:1984134 [0] NCCL INFO comm 0x14f8e8008fb0 rank 276 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
278: hkn0621:1984032:1984138 [2] NCCL INFO comm 0x14e80c008fb0 rank 278 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
497: hkn0812:686297:686395 [1] NCCL INFO Connected all trees
497: hkn0812:686297:686395 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
497: hkn0812:686297:686395 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 61: hkn0420:3202729:3202829 [1] NCCL INFO Connected all trees
 61: hkn0420:3202729:3202829 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 61: hkn0420:3202729:3202829 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
496: hkn0812:686285:686394 [0] NCCL INFO Connected all trees
121: hkn0507:3179593:3179688 [1] NCCL INFO Connected all trees
496: hkn0812:686285:686394 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 60: hkn0420:3202709:3202825 [0] NCCL INFO Connected all trees
496: hkn0812:686285:686394 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
121: hkn0507:3179593:3179688 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 60: hkn0420:3202709:3202825 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 60: hkn0420:3202709:3202825 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
121: hkn0507:3179593:3179688 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
120: hkn0507:3179581:3179694 [0] NCCL INFO Connected all trees
120: hkn0507:3179581:3179694 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
120: hkn0507:3179581:3179694 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 60: hkn0420:3202709:3202825 [0] NCCL INFO comm 0x149358008fb0 rank 60 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
497: hkn0812:686297:686395 [1] NCCL INFO comm 0x151400008fb0 rank 497 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 61: hkn0420:3202729:3202829 [1] NCCL INFO comm 0x14baa0008fb0 rank 61 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 62: hkn0420:3202701:3202824 [2] NCCL INFO comm 0x1489c8008fb0 rank 62 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
498: hkn0812:686269:686396 [2] NCCL INFO comm 0x149ad8008fb0 rank 498 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
496: hkn0812:686285:686394 [0] NCCL INFO comm 0x14d014008fb0 rank 496 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 63: hkn0420:3202717:3202827 [3] NCCL INFO comm 0x154b00008fb0 rank 63 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
117: hkn0506:830562:830672 [1] NCCL INFO Channel 00 : 117[4b000] -> 116[31000] via P2P/IPC/read
499: hkn0812:686277:686393 [3] NCCL INFO comm 0x14c118008fb0 rank 499 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
121: hkn0507:3179593:3179688 [1] NCCL INFO comm 0x153d64008fb0 rank 121 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
122: hkn0507:3179573:3179686 [2] NCCL INFO comm 0x14ae0c008fb0 rank 122 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
123: hkn0507:3179565:3179693 [3] NCCL INFO comm 0x151000008fb0 rank 123 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
120: hkn0507:3179581:3179694 [0] NCCL INFO comm 0x153b48008fb0 rank 120 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
117: hkn0506:830562:830672 [1] NCCL INFO Channel 01 : 117[4b000] -> 116[31000] via P2P/IPC/read
505: hkn0815:387660:387783 [1] NCCL INFO Connected all trees
505: hkn0815:387660:387783 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
505: hkn0815:387660:387783 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
504: hkn0815:387632:387784 [0] NCCL INFO Connected all trees
504: hkn0815:387632:387784 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
504: hkn0815:387632:387784 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
264: hkn0615:406779:406906 [0] NCCL INFO Channel 01 : 264[31000] -> 261[4b000] [send] via NET/IBext/0
501: hkn0814:668331:668452 [1] NCCL INFO Channel 00 : 501[4b000] -> 500[31000] via P2P/IPC/read
260: hkn0613:895195:895293 [0] NCCL INFO Channel 01 : 260[31000] -> 256[31000] [send] via NET/IBext/0
504: hkn0815:387632:387784 [0] NCCL INFO comm 0x14a44c008fb0 rank 504 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
507: hkn0815:387648:387785 [3] NCCL INFO comm 0x152d58008fb0 rank 507 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
505: hkn0815:387660:387783 [1] NCCL INFO comm 0x14eb18008fb0 rank 505 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
501: hkn0814:668331:668452 [1] NCCL INFO Channel 01 : 501[4b000] -> 500[31000] via P2P/IPC/read
116: hkn0506:830570:830664 [0] NCCL INFO Connected all trees
116: hkn0506:830570:830664 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
116: hkn0506:830570:830664 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
117: hkn0506:830562:830672 [1] NCCL INFO Connected all trees
117: hkn0506:830562:830672 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
117: hkn0506:830562:830672 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
506: hkn0815:387640:387788 [2] NCCL INFO comm 0x1500c4008fb0 rank 506 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
118: hkn0506:830582:830669 [2] NCCL INFO comm 0x14eb78008fb0 rank 118 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
119: hkn0506:830554:830666 [3] NCCL INFO comm 0x153304008fb0 rank 119 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
116: hkn0506:830570:830664 [0] NCCL INFO comm 0x14ad70008fb0 rank 116 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
117: hkn0506:830562:830672 [1] NCCL INFO comm 0x147e48008fb0 rank 117 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 28: hkn0411:2308375:2308484 [0] NCCL INFO Channel 00 : 28[31000] -> 24[31000] [send] via NET/IBext/0
500: hkn0814:668339:668453 [0] NCCL INFO Connected all trees
500: hkn0814:668339:668453 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
500: hkn0814:668339:668453 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
501: hkn0814:668331:668452 [1] NCCL INFO Connected all trees
501: hkn0814:668331:668452 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
501: hkn0814:668331:668452 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 56: hkn0419:1536810:1536918 [0] NCCL INFO Channel 01 : 56[31000] -> 53[4b000] [send] via NET/IBext/0
500: hkn0814:668339:668453 [0] NCCL INFO comm 0x149fc8008fb0 rank 500 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
503: hkn0814:668359:668454 [3] NCCL INFO comm 0x14d930008fb0 rank 503 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
501: hkn0814:668331:668452 [1] NCCL INFO comm 0x150ad8008fb0 rank 501 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
502: hkn0814:668347:668457 [2] NCCL INFO comm 0x147e78008fb0 rank 502 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 01 : 12[31000] -> 4[31000] [send] via NET/IBext/0
261: hkn0613:895175:895292 [1] NCCL INFO Channel 00 : 261[4b000] -> 260[31000] via P2P/IPC/read
265: hkn0615:406807:406907 [1] NCCL INFO Connected all trees
265: hkn0615:406807:406907 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
265: hkn0615:406807:406907 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
261: hkn0613:895175:895292 [1] NCCL INFO Channel 01 : 261[4b000] -> 260[31000] via P2P/IPC/read
264: hkn0615:406779:406906 [0] NCCL INFO Connected all trees
264: hkn0615:406779:406906 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
264: hkn0615:406779:406906 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
265: hkn0615:406807:406907 [1] NCCL INFO comm 0x14b4b8008fb0 rank 265 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
266: hkn0615:406787:406911 [2] NCCL INFO comm 0x154edc008fb0 rank 266 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
264: hkn0615:406779:406906 [0] NCCL INFO comm 0x14fc34008fb0 rank 264 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 29: hkn0411:2308366:2308483 [1] NCCL INFO Connected all trees
267: hkn0615:406795:406908 [3] NCCL INFO comm 0x15086c008fb0 rank 267 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 29: hkn0411:2308366:2308483 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 29: hkn0411:2308366:2308483 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 28: hkn0411:2308375:2308484 [0] NCCL INFO Connected all trees
 28: hkn0411:2308375:2308484 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 28: hkn0411:2308375:2308484 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
260: hkn0613:895195:895293 [0] NCCL INFO Connected all trees
 28: hkn0411:2308375:2308484 [0] NCCL INFO comm 0x153b7c008fb0 rank 28 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
260: hkn0613:895195:895293 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 31: hkn0411:2308387:2308486 [3] NCCL INFO comm 0x14666c008fb0 rank 31 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
260: hkn0613:895195:895293 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 29: hkn0411:2308366:2308483 [1] NCCL INFO comm 0x148ff0008fb0 rank 29 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
257: hkn0612:909451:909581 [1] NCCL INFO Connected all trees
 30: hkn0411:2308367:2308482 [2] NCCL INFO comm 0x155134008fb0 rank 30 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
257: hkn0612:909451:909581 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
257: hkn0612:909451:909581 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
261: hkn0613:895175:895292 [1] NCCL INFO Connected all trees
256: hkn0612:909459:909583 [0] NCCL INFO Connected all trees
261: hkn0613:895175:895292 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
261: hkn0613:895175:895292 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:909459:909583 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
256: hkn0612:909459:909583 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 57: hkn0419:1536822:1536917 [1] NCCL INFO Connected all trees
 57: hkn0419:1536822:1536917 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 57: hkn0419:1536822:1536917 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 56: hkn0419:1536810:1536918 [0] NCCL INFO Connected all trees
 56: hkn0419:1536810:1536918 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 56: hkn0419:1536810:1536918 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
256: hkn0612:909459:909583 [0] NCCL INFO comm 0x1497d4008fb0 rank 256 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
262: hkn0613:895183:895295 [2] NCCL INFO comm 0x14d990008fb0 rank 262 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
259: hkn0612:909467:909577 [3] NCCL INFO comm 0x146278008fb0 rank 259 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
260: hkn0613:895195:895293 [0] NCCL INFO comm 0x154c64008fb0 rank 260 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
257: hkn0612:909451:909581 [1] NCCL INFO comm 0x1477b4008fb0 rank 257 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
258: hkn0612:909479:909575 [2] NCCL INFO comm 0x14e4a8008fb0 rank 258 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
263: hkn0613:895167:895298 [3] NCCL INFO comm 0x146938008fb0 rank 263 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
261: hkn0613:895175:895292 [1] NCCL INFO comm 0x154a38008fb0 rank 261 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 53: hkn0418:1861667:1861790 [1] NCCL INFO Channel 00 : 53[4b000] -> 52[31000] via P2P/IPC/read
 56: hkn0419:1536810:1536918 [0] NCCL INFO comm 0x14bdc4008fb0 rank 56 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 59: hkn0419:1536808:1536921 [3] NCCL INFO comm 0x153124008fb0 rank 59 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 57: hkn0419:1536822:1536917 [1] NCCL INFO comm 0x14f964008fb0 rank 57 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 58: hkn0419:1536809:1536916 [2] NCCL INFO comm 0x1483a4008fb0 rank 58 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 53: hkn0418:1861667:1861790 [1] NCCL INFO Channel 01 : 53[4b000] -> 52[31000] via P2P/IPC/read
 52: hkn0418:1861695:1861793 [0] NCCL INFO Connected all trees
 52: hkn0418:1861695:1861793 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 52: hkn0418:1861695:1861793 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 53: hkn0418:1861667:1861790 [1] NCCL INFO Connected all trees
 53: hkn0418:1861667:1861790 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 53: hkn0418:1861667:1861790 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 24: hkn0410:1152208:1152319 [0] NCCL INFO Channel 01 : 24[31000] -> 21[4b000] [send] via NET/IBext/0
 53: hkn0418:1861667:1861790 [1] NCCL INFO comm 0x147374008fb0 rank 53 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 12: hkn0407:1808763:1808908 [0] NCCL INFO Channel 00 : 12[31000] -> 8[31000] [send] via NET/IBext/0
 52: hkn0418:1861695:1861793 [0] NCCL INFO comm 0x152ac4008fb0 rank 52 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 55: hkn0418:1861683:1861785 [3] NCCL INFO comm 0x1531f0008fb0 rank 55 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 54: hkn0418:1861675:1861787 [2] NCCL INFO comm 0x14c1a4008fb0 rank 54 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 13: hkn0407:1808783:1808911 [1] NCCL INFO Connected all trees
 24: hkn0410:1152208:1152319 [0] NCCL INFO Connected all trees
 24: hkn0410:1152208:1152319 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 24: hkn0410:1152208:1152319 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 13: hkn0407:1808783:1808911 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 13: hkn0407:1808783:1808911 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 12: hkn0407:1808763:1808908 [0] NCCL INFO Connected all trees
 12: hkn0407:1808763:1808908 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 12: hkn0407:1808763:1808908 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 25: hkn0410:1152210:1152322 [1] NCCL INFO Connected all trees
 25: hkn0410:1152210:1152322 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 25: hkn0410:1152210:1152322 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 15: hkn0407:1808771:1808909 [3] NCCL INFO comm 0x147784008fb0 rank 15 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 21: hkn0409:2578197:2578308 [1] NCCL INFO Channel 00 : 21[4b000] -> 20[31000] via P2P/IPC/read
 12: hkn0407:1808763:1808908 [0] NCCL INFO comm 0x15030c008fb0 rank 12 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 13: hkn0407:1808783:1808911 [1] NCCL INFO comm 0x149e48008fb0 rank 13 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 14: hkn0407:1808755:1808914 [2] NCCL INFO comm 0x14bc10008fb0 rank 14 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 24: hkn0410:1152208:1152319 [0] NCCL INFO comm 0x14f6f8008fb0 rank 24 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 27: hkn0410:1152209:1152320 [3] NCCL INFO comm 0x14767c008fb0 rank 27 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 00 : 9[4b000] -> 4[31000] [receive] via NET/IBext/0
 25: hkn0410:1152210:1152322 [1] NCCL INFO comm 0x14be04008fb0 rank 25 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 26: hkn0410:1152222:1152317 [2] NCCL INFO comm 0x1485c0008fb0 rank 26 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 21: hkn0409:2578197:2578308 [1] NCCL INFO Channel 01 : 21[4b000] -> 20[31000] via P2P/IPC/read
 20: hkn0409:2578189:2578309 [0] NCCL INFO Connected all trees
 20: hkn0409:2578189:2578309 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 20: hkn0409:2578189:2578309 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 21: hkn0409:2578197:2578308 [1] NCCL INFO Connected all trees
 21: hkn0409:2578197:2578308 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
 21: hkn0409:2578197:2578308 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
 20: hkn0409:2578189:2578309 [0] NCCL INFO comm 0x1475a4008fb0 rank 20 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 21: hkn0409:2578197:2578308 [1] NCCL INFO comm 0x1474d4008fb0 rank 21 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
 22: hkn0409:2578209:2578305 [2] NCCL INFO comm 0x147590008fb0 rank 22 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
 23: hkn0409:2578181:2578301 [3] NCCL INFO comm 0x14c6a8008fb0 rank 23 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 00 : 9[4b000] -> 8[31000] via P2P/IPC/read
  8: hkn0405:3199319:3199416 [0] NCCL INFO Channel 01 : 8[31000] -> 5[4b000] [send] via NET/IBext/0
  9: hkn0405:3199291:3199417 [1] NCCL INFO Channel 01 : 9[4b000] -> 8[31000] via P2P/IPC/read
  5: hkn0404:1331860:1331998 [1] NCCL INFO Channel 00 : 5[4b000] -> 4[31000] via P2P/IPC/read
  9: hkn0405:3199291:3199417 [1] NCCL INFO Connected all trees
  9: hkn0405:3199291:3199417 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  5: hkn0404:1331860:1331998 [1] NCCL INFO Channel 01 : 5[4b000] -> 4[31000] via P2P/IPC/read
  9: hkn0405:3199291:3199417 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  8: hkn0405:3199319:3199416 [0] NCCL INFO Connected all trees
  8: hkn0405:3199319:3199416 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  8: hkn0405:3199319:3199416 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  8: hkn0405:3199319:3199416 [0] NCCL INFO comm 0x145d70008fb0 rank 8 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
 11: hkn0405:3199299:3199420 [3] NCCL INFO comm 0x150f98008fb0 rank 11 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
 10: hkn0405:3199307:3199411 [2] NCCL INFO comm 0x14b5a8008fb0 rank 10 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  9: hkn0405:3199291:3199417 [1] NCCL INFO comm 0x15320c008fb0 rank 9 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  4: hkn0404:1331872:1331990 [0] NCCL INFO Channel 01 : 4[31000] -> 0[31000] [send] via NET/IBext/0
  5: hkn0404:1331860:1331998 [1] NCCL INFO Connected all trees
  5: hkn0404:1331860:1331998 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  5: hkn0404:1331860:1331998 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  4: hkn0404:1331872:1331990 [0] NCCL INFO Connected all trees
  4: hkn0404:1331872:1331990 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  4: hkn0404:1331872:1331990 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  6: hkn0404:1331844:1331992 [2] NCCL INFO comm 0x14ef40008fb0 rank 6 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  1: hkn0403:1751324:1751696 [1] NCCL INFO Connected all trees
  4: hkn0404:1331872:1331990 [0] NCCL INFO comm 0x148834008fb0 rank 4 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  1: hkn0403:1751324:1751696 [1] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  5: hkn0404:1331860:1331998 [1] NCCL INFO comm 0x14f928008fb0 rank 5 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  1: hkn0403:1751324:1751696 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  7: hkn0404:1331852:1331996 [3] NCCL INFO comm 0x14ac18008fb0 rank 7 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  0: hkn0403:1751320:1751689 [0] NCCL INFO Connected all trees
  0: hkn0403:1751320:1751689 [0] NCCL INFO threadThresholds 8/8/64 | 4096/8/64 | 8/8/512
  0: hkn0403:1751320:1751689 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
  0: hkn0403:1751320:1751689 [0] NCCL INFO comm 0x152e88008fb0 rank 0 nranks 512 cudaDev 0 busId 31000 - Init COMPLETE
  1: hkn0403:1751324:1751696 [1] NCCL INFO comm 0x14dc58008fb0 rank 1 nranks 512 cudaDev 1 busId 4b000 - Init COMPLETE
  2: hkn0403:1751321:1751698 [2] NCCL INFO comm 0x14b41c008fb0 rank 2 nranks 512 cudaDev 2 busId ca000 - Init COMPLETE
  3: hkn0403:1751336:1751695 [3] NCCL INFO comm 0x1534ac008fb0 rank 3 nranks 512 cudaDev 3 busId e3000 - Init COMPLETE
  0: hkn0403:1751320:1751320 [0] NCCL INFO Launch mode Parallel
  0: :::MLLOG {"namespace": "", "time_ms": 1633413525947, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "deepcam", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 55}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413526011, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "HelmholtzAI", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 58}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413526011, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 61}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413526011, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 64}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413526011, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "HoreKa", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/mlperf_log_utils.py", "lineno": 67}}
469: hdf5!!
370: hdf5!!
374: hdf5!!
 40: hdf5!!
480: hdf5!!
337: hdf5!!
 11: hdf5!!
378: hdf5!!
449: hdf5!!
 32: hdf5!!
467: hdf5!!
468: hdf5!!
 12: hdf5!!
387: hdf5!!
 99: hdf5!!
508: hdf5!!
 89: hdf5!!
 30: hdf5!!
 45: hdf5!!
406: hdf5!!
 94: hdf5!!
 58: hdf5!!
483: hdf5!!
338: hdf5!!
 48: hdf5!!
360: hdf5!!
327: hdf5!!
160: hdf5!!
 65: hdf5!!
126: hdf5!!
257: hdf5!!
  9: hdf5!!
368: hdf5!!
375: hdf5!!
351: hdf5!!
314: hdf5!!
377: hdf5!!
354: hdf5!!
451: hdf5!!
394: hdf5!!
397: hdf5!!
473: hdf5!!
496: hdf5!!
410: hdf5!!
435: hdf5!!
505: hdf5!!
 14: hdf5!!
 63: hdf5!!
180: hdf5!!
509: hdf5!!
 88: hdf5!!
 31: hdf5!!
 41: hdf5!!
  7: hdf5!!
184: hdf5!!
 16: hdf5!!
424: hdf5!!
440: hdf5!!
 47: hdf5!!
130: hdf5!!
405: hdf5!!
 92: hdf5!!
 59: hdf5!!
 71: hdf5!!
178: hdf5!!
479: hdf5!!
200: hdf5!!
482: hdf5!!
206: hdf5!!
291: hdf5!!
120: hdf5!!
276: hdf5!!
170: hdf5!!
339: hdf5!!
 50: hdf5!!
361: hdf5!!
325: hdf5!!
163: hdf5!!
115: hdf5!!
208: hdf5!!
 64: hdf5!!
199: hdf5!!
125: hdf5!!
281: hdf5!!
258: hdf5!!
365: hdf5!!
104: hdf5!!
 10: hdf5!!
334: hdf5!!
369: hdf5!!
381: hdf5!!
166: hdf5!!
356: hdf5!!
242: hdf5!!
373: hdf5!!
348: hdf5!!
304: hdf5!!
328: hdf5!!
355: hdf5!!
388: hdf5!!
342: hdf5!!
450: hdf5!!
224: hdf5!!
392: hdf5!!
 34: hdf5!!
465: hdf5!!
396: hdf5!!
485: hdf5!!
415: hdf5!!
421: hdf5!!
488: hdf5!!
499: hdf5!!
501: hdf5!!
430: hdf5!!
411: hdf5!!
433: hdf5!!
470: hdf5!!
506: hdf5!!
 13: hdf5!!
 36: hdf5!!
 62: hdf5!!
384: hdf5!!
110: hdf5!!
 98: hdf5!!
 26: hdf5!!
158: hdf5!!
 84: hdf5!!
181: hdf5!!
195: hdf5!!
461: hdf5!!
510: hdf5!!
 90: hdf5!!
 78: hdf5!!
 28: hdf5!!
102: hdf5!!
 43: hdf5!!
  4: hdf5!!
185: hdf5!!
 18: hdf5!!
425: hdf5!!
441: hdf5!!
453: hdf5!!
 44: hdf5!!
 20: hdf5!!
131: hdf5!!
 95: hdf5!!
 56: hdf5!!
 70: hdf5!!
140: hdf5!!
179: hdf5!!
119: hdf5!!
478: hdf5!!
153: hdf5!!
203: hdf5!!
265: hdf5!!
481: hdf5!!
204: hdf5!!
290: hdf5!!
146: hdf5!!
132: hdf5!!
121: hdf5!!
253: hdf5!!
279: hdf5!!
336: hdf5!!
219: hdf5!!
 51: hdf5!!
363: hdf5!!
326: hdf5!!
161: hdf5!!
114: hdf5!!
211: hdf5!!
268: hdf5!!
 66: hdf5!!
198: hdf5!!
172: hdf5!!
124: hdf5!!
138: hdf5!!
316: hdf5!!
293: hdf5!!
259: hdf5!!
367: hdf5!!
287: hdf5!!
107: hdf5!!
237: hdf5!!
191: hdf5!!
335: hdf5!!
371: hdf5!!
308: hdf5!!
296: hdf5!!
382: hdf5!!
261: hdf5!!
167: hdf5!!
 72: hdf5!!
231: hdf5!!
241: hdf5!!
372: hdf5!!
312: hdf5!!
233: hdf5!!
376: hdf5!!
306: hdf5!!
247: hdf5!!
329: hdf5!!
353: hdf5!!
389: hdf5!!
448: hdf5!!
227: hdf5!!
275: hdf5!!
393: hdf5!!
345: hdf5!!
 35: hdf5!!
213: hdf5!!
466: hdf5!!
419: hdf5!!
398: hdf5!!
445: hdf5!!
486: hdf5!!
422: hdf5!!
489: hdf5!!
475: hdf5!!
497: hdf5!!
502: hdf5!!
428: hdf5!!
  1: hdf5!!
408: hdf5!!
434: hdf5!!
471: hdf5!!
459: hdf5!!
507: hdf5!!
 15: hdf5!!
 38: hdf5!!
 61: hdf5!!
385: hdf5!!
109: hdf5!!
 97: hdf5!!
 24: hdf5!!
157: hdf5!!
 87: hdf5!!
183: hdf5!!
192: hdf5!!
463: hdf5!!
511: hdf5!!
 55: hdf5!!
 91: hdf5!!
437: hdf5!!
 77: hdf5!!
148: hdf5!!
 29: hdf5!!
103: hdf5!!
 42: hdf5!!
  5: hdf5!!
186: hdf5!!
 19: hdf5!!
402: hdf5!!
427: hdf5!!
442: hdf5!!
454: hdf5!!
 46: hdf5!!
 21: hdf5!!
129: hdf5!!
404: hdf5!!
 93: hdf5!!
 57: hdf5!!
 68: hdf5!!
141: hdf5!!
177: hdf5!!
118: hdf5!!
477: hdf5!!
152: hdf5!!
202: hdf5!!
266: hdf5!!
207: hdf5!!
288: hdf5!!
145: hdf5!!
133: hdf5!!
122: hdf5!!
254: hdf5!!
278: hdf5!!
171: hdf5!!
 49: hdf5!!
362: hdf5!!
324: hdf5!!
162: hdf5!!
113: hdf5!!
209: hdf5!!
270: hdf5!!
 67: hdf5!!
196: hdf5!!
174: hdf5!!
127: hdf5!!
222: hdf5!!
137: hdf5!!
317: hdf5!!
294: hdf5!!
283: hdf5!!
256: hdf5!!
366: hdf5!!
284: hdf5!!
106: hdf5!!
248: hdf5!!
239: hdf5!!
189: hdf5!!
  8: hdf5!!
332: hdf5!!
309: hdf5!!
297: hdf5!!
320: hdf5!!
383: hdf5!!
263: hdf5!!
164: hdf5!!
357: hdf5!!
 73: hdf5!!
229: hdf5!!
243: hdf5!!
349: hdf5!!
315: hdf5!!
303: hdf5!!
235: hdf5!!
379: hdf5!!
307: hdf5!!
246: hdf5!!
330: hdf5!!
352: hdf5!!
391: hdf5!!
343: hdf5!!
226: hdf5!!
274: hdf5!!
395: hdf5!!
 82: hdf5!!
346: hdf5!!
 33: hdf5!!
214: hdf5!!
418: hdf5!!
399: hdf5!!
447: hdf5!!
484: hdf5!!
413: hdf5!!
420: hdf5!!
493: hdf5!!
490: hdf5!!
474: hdf5!!
498: hdf5!!
503: hdf5!!
431: hdf5!!
  2: hdf5!!
409: hdf5!!
432: hdf5!!
458: hdf5!!
504: hdf5!!
 39: hdf5!!
 60: hdf5!!
386: hdf5!!
108: hdf5!!
 96: hdf5!!
 27: hdf5!!
 85: hdf5!!
182: hdf5!!
193: hdf5!!
462: hdf5!!
 53: hdf5!!
439: hdf5!!
 79: hdf5!!
149: hdf5!!
100: hdf5!!
  6: hdf5!!
187: hdf5!!
 17: hdf5!!
403: hdf5!!
426: hdf5!!
443: hdf5!!
455: hdf5!!
 22: hdf5!!
407: hdf5!!
 69: hdf5!!
142: hdf5!!
176: hdf5!!
117: hdf5!!
476: hdf5!!
154: hdf5!!
201: hdf5!!
264: hdf5!!
205: hdf5!!
289: hdf5!!
147: hdf5!!
134: hdf5!!
123: hdf5!!
255: hdf5!!
277: hdf5!!
168: hdf5!!
218: hdf5!!
112: hdf5!!
210: hdf5!!
271: hdf5!!
197: hdf5!!
175: hdf5!!
221: hdf5!!
136: hdf5!!
319: hdf5!!
292: hdf5!!
282: hdf5!!
364: hdf5!!
285: hdf5!!
105: hdf5!!
251: hdf5!!
236: hdf5!!
333: hdf5!!
311: hdf5!!
298: hdf5!!
322: hdf5!!
380: hdf5!!
260: hdf5!!
165: hdf5!!
359: hdf5!!
 75: hdf5!!
240: hdf5!!
350: hdf5!!
313: hdf5!!
302: hdf5!!
234: hdf5!!
305: hdf5!!
245: hdf5!!
331: hdf5!!
390: hdf5!!
341: hdf5!!
225: hdf5!!
272: hdf5!!
 80: hdf5!!
347: hdf5!!
215: hdf5!!
464: hdf5!!
416: hdf5!!
446: hdf5!!
487: hdf5!!
412: hdf5!!
423: hdf5!!
495: hdf5!!
491: hdf5!!
472: hdf5!!
500: hdf5!!
429: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633413529612, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 98}}
457: hdf5!!
 37: hdf5!!
111: hdf5!!
 25: hdf5!!
156: hdf5!!
 86: hdf5!!
194: hdf5!!
460: hdf5!!
 54: hdf5!!
438: hdf5!!
 76: hdf5!!
151: hdf5!!
101: hdf5!!
401: hdf5!!
452: hdf5!!
 23: hdf5!!
143: hdf5!!
116: hdf5!!
155: hdf5!!
267: hdf5!!
144: hdf5!!
135: hdf5!!
252: hdf5!!
169: hdf5!!
217: hdf5!!
269: hdf5!!
173: hdf5!!
223: hdf5!!
139: hdf5!!
318: hdf5!!
295: hdf5!!
280: hdf5!!
249: hdf5!!
238: hdf5!!
188: hdf5!!
310: hdf5!!
299: hdf5!!
321: hdf5!!
262: hdf5!!
358: hdf5!!
 74: hdf5!!
230: hdf5!!
301: hdf5!!
244: hdf5!!
340: hdf5!!
273: hdf5!!
 81: hdf5!!
344: hdf5!!
417: hdf5!!
444: hdf5!!
414: hdf5!!
494: hdf5!!
 52: hdf5!!
150: hdf5!!
216: hdf5!!
220: hdf5!!
 83: hdf5!!
232: hdf5!!
286: hdf5!!
  3: hdf5!!
128: hdf5!!
492: hdf5!!
400: hdf5!!
250: hdf5!!
300: hdf5!!
323: hdf5!!
228: hdf5!!
456: hdf5!!
159: hdf5!!
190: hdf5!!
212: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633413529614, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 99}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413529614, "event_type": "POINT_IN_TIME", "key": "seed", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 103}}
  0: hdf5!!
436: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
260: root_dir: /tmp/deepcam/instance0
124: root_dir: /tmp/deepcam/instance0
 93: root_dir: /tmp/deepcam/instance0
217: root_dir: /tmp/deepcam/instance0
427: root_dir: /tmp/deepcam/instance0
471: root_dir: /tmp/deepcam/instance0
421: root_dir: /tmp/deepcam/instance0
 49: root_dir: /tmp/deepcam/instance0
211: root_dir: /tmp/deepcam/instance0
171: root_dir: /tmp/deepcam/instance0
 15: root_dir: /tmp/deepcam/instance0
231: root_dir: /tmp/deepcam/instance0
343: root_dir: /tmp/deepcam/instance0
308: root_dir: /tmp/deepcam/instance0
255: root_dir: /tmp/deepcam/instance0
396: root_dir: /tmp/deepcam/instance0
295: root_dir: /tmp/deepcam/instance0
190: root_dir: /tmp/deepcam/instance0
 30: root_dir: /tmp/deepcam/instance0
266: root_dir: /tmp/deepcam/instance0
 27: root_dir: /tmp/deepcam/instance0
151: root_dir: /tmp/deepcam/instance0
274: root_dir: /tmp/deepcam/instance0
402: root_dir: /tmp/deepcam/instance0
 84: root_dir: /tmp/deepcam/instance0
 75: root_dir: /tmp/deepcam/instance0
407: root_dir: /tmp/deepcam/instance0
401: root_dir: /tmp/deepcam/instance0
264: root_dir: /tmp/deepcam/instance0
165: root_dir: /tmp/deepcam/instance0
305: root_dir: /tmp/deepcam/instance0
468: root_dir: /tmp/deepcam/instance0
416: root_dir: /tmp/deepcam/instance0
 60: root_dir: /tmp/deepcam/instance0
 98: root_dir: /tmp/deepcam/instance0
191: root_dir: /tmp/deepcam/instance0
104: root_dir: /tmp/deepcam/instance0
 99: root_dir: /tmp/deepcam/instance0
 31: root_dir: /tmp/deepcam/instance0
193: root_dir: /tmp/deepcam/instance0
278: root_dir: /tmp/deepcam/instance0
355: root_dir: /tmp/deepcam/instance0
507: root_dir: /tmp/deepcam/instance0
 83: root_dir: /tmp/deepcam/instance0
137: root_dir: /tmp/deepcam/instance0
138: root_dir: /tmp/deepcam/instance0
435: root_dir: /tmp/deepcam/instance0
331: root_dir: /tmp/deepcam/instance0
352: root_dir: /tmp/deepcam/instance0
210: root_dir: /tmp/deepcam/instance0
332: root_dir: /tmp/deepcam/instance0
 45: root_dir: /tmp/deepcam/instance0
 16: root_dir: /tmp/deepcam/instance0
134: root_dir: /tmp/deepcam/instance0
 91: root_dir: /tmp/deepcam/instance0
334: root_dir: /tmp/deepcam/instance0
496: root_dir: /tmp/deepcam/instance0
493: root_dir: /tmp/deepcam/instance0
330: root_dir: /tmp/deepcam/instance0
408: root_dir: /tmp/deepcam/instance0
103: root_dir: /tmp/deepcam/instance0
320: root_dir: /tmp/deepcam/instance0
128: root_dir: /tmp/deepcam/instance0
148: root_dir: /tmp/deepcam/instance0
144: root_dir: /tmp/deepcam/instance0
494: root_dir: /tmp/deepcam/instance0
 20: root_dir: /tmp/deepcam/instance0
307: root_dir: /tmp/deepcam/instance0
497: root_dir: /tmp/deepcam/instance0
379: root_dir: /tmp/deepcam/instance0
452: root_dir: /tmp/deepcam/instance0
 68: root_dir: /tmp/deepcam/instance0
462: root_dir: /tmp/deepcam/instance0
451: root_dir: /tmp/deepcam/instance0
390: root_dir: /tmp/deepcam/instance0
391: root_dir: /tmp/deepcam/instance0
  3: root_dir: /tmp/deepcam/instance0
105: root_dir: /tmp/deepcam/instance0
365: root_dir: /tmp/deepcam/instance0
187: root_dir: /tmp/deepcam/instance0
  7: root_dir: /tmp/deepcam/instance0
 10: root_dir: /tmp/deepcam/instance0
467: root_dir: /tmp/deepcam/instance0
491: root_dir: /tmp/deepcam/instance0
346: root_dir: /tmp/deepcam/instance0
443: root_dir: /tmp/deepcam/instance0
377: root_dir: /tmp/deepcam/instance0
 54: root_dir: /tmp/deepcam/instance0
213: root_dir: /tmp/deepcam/instance0
243: root_dir: /tmp/deepcam/instance0
121: root_dir: /tmp/deepcam/instance0
463: root_dir: /tmp/deepcam/instance0
233: root_dir: /tmp/deepcam/instance0
212: root_dir: /tmp/deepcam/instance0
 21: root_dir: /tmp/deepcam/instance0
395: root_dir: /tmp/deepcam/instance0
356: root_dir: /tmp/deepcam/instance0
340: root_dir: /tmp/deepcam/instance0
282: root_dir: /tmp/deepcam/instance0
473: root_dir: /tmp/deepcam/instance0
 33: root_dir: /tmp/deepcam/instance0
454: root_dir: /tmp/deepcam/instance0
350: root_dir: /tmp/deepcam/instance0
375: root_dir: /tmp/deepcam/instance0
374: root_dir: /tmp/deepcam/instance0
206: root_dir: /tmp/deepcam/instance0
288: root_dir: /tmp/deepcam/instance0
359: root_dir: /tmp/deepcam/instance0
441: root_dir: /tmp/deepcam/instance0
202: root_dir: /tmp/deepcam/instance0
196: root_dir: /tmp/deepcam/instance0
354: root_dir: /tmp/deepcam/instance0
 39: root_dir: /tmp/deepcam/instance0
429: root_dir: /tmp/deepcam/instance0
110: root_dir: /tmp/deepcam/instance0
117: root_dir: /tmp/deepcam/instance0
344: root_dir: /tmp/deepcam/instance0
382: root_dir: /tmp/deepcam/instance0
207: root_dir: /tmp/deepcam/instance0
 35: root_dir: /tmp/deepcam/instance0
482: root_dir: /tmp/deepcam/instance0
122: root_dir: /tmp/deepcam/instance0
197: root_dir: /tmp/deepcam/instance0
116: root_dir: /tmp/deepcam/instance0
373: root_dir: /tmp/deepcam/instance0
  1: root_dir: /tmp/deepcam/instance0
347: root_dir: /tmp/deepcam/instance0
244: root_dir: /tmp/deepcam/instance0
378: root_dir: /tmp/deepcam/instance0
 25: root_dir: /tmp/deepcam/instance0
364: root_dir: /tmp/deepcam/instance0
433: root_dir: /tmp/deepcam/instance0
464: root_dir: /tmp/deepcam/instance0
448: root_dir: /tmp/deepcam/instance0
184: root_dir: /tmp/deepcam/instance0
338: root_dir: /tmp/deepcam/instance0
180: root_dir: /tmp/deepcam/instance0
200: root_dir: /tmp/deepcam/instance0
162: root_dir: /tmp/deepcam/instance0
  6: root_dir: /tmp/deepcam/instance0
444: root_dir: /tmp/deepcam/instance0
120: root_dir: /tmp/deepcam/instance0
251: root_dir: /tmp/deepcam/instance0
183: root_dir: /tmp/deepcam/instance0
412: root_dir: /tmp/deepcam/instance0
214: root_dir: /tmp/deepcam/instance0
483: root_dir: /tmp/deepcam/instance0
235: root_dir: /tmp/deepcam/instance0
383: root_dir: /tmp/deepcam/instance0
327: root_dir: /tmp/deepcam/instance0
245: root_dir: /tmp/deepcam/instance0
238: root_dir: /tmp/deepcam/instance0
449: root_dir: /tmp/deepcam/instance0
  5: root_dir: /tmp/deepcam/instance0
140: root_dir: /tmp/deepcam/instance0
369: root_dir: /tmp/deepcam/instance0
508: root_dir: /tmp/deepcam/instance0
195: root_dir: /tmp/deepcam/instance0
225: root_dir: /tmp/deepcam/instance0
465: root_dir: /tmp/deepcam/instance0
325: root_dir: /tmp/deepcam/instance0
175: root_dir: /tmp/deepcam/instance0
322: root_dir: /tmp/deepcam/instance0
349: root_dir: /tmp/deepcam/instance0
159: root_dir: /tmp/deepcam/instance0
299: root_dir: /tmp/deepcam/instance0
459: root_dir: /tmp/deepcam/instance0
413: root_dir: /tmp/deepcam/instance0
485: root_dir: /tmp/deepcam/instance0
261: root_dir: /tmp/deepcam/instance0
 17: root_dir: /tmp/deepcam/instance0
318: root_dir: /tmp/deepcam/instance0
 66: root_dir: /tmp/deepcam/instance0
114: root_dir: /tmp/deepcam/instance0
194: root_dir: /tmp/deepcam/instance0
392: root_dir: /tmp/deepcam/instance0
254: root_dir: /tmp/deepcam/instance0
303: root_dir: /tmp/deepcam/instance0
445: root_dir: /tmp/deepcam/instance0
370: root_dir: /tmp/deepcam/instance0
371: root_dir: /tmp/deepcam/instance0
 34: root_dir: /tmp/deepcam/instance0
186: root_dir: /tmp/deepcam/instance0
438: root_dir: /tmp/deepcam/instance0
 57: root_dir: /tmp/deepcam/instance0
204: root_dir: /tmp/deepcam/instance0
 67: root_dir: /tmp/deepcam/instance0
 42: root_dir: /tmp/deepcam/instance0
492: root_dir: /tmp/deepcam/instance0
 77: root_dir: /tmp/deepcam/instance0
486: root_dir: /tmp/deepcam/instance0
284: root_dir: /tmp/deepcam/instance0
111: root_dir: /tmp/deepcam/instance0
241: root_dir: /tmp/deepcam/instance0
447: root_dir: /tmp/deepcam/instance0
484: root_dir: /tmp/deepcam/instance0
500: root_dir: /tmp/deepcam/instance0
250: root_dir: /tmp/deepcam/instance0
446: root_dir: /tmp/deepcam/instance0
510: root_dir: /tmp/deepcam/instance0
476: root_dir: /tmp/deepcam/instance0
348: root_dir: /tmp/deepcam/instance0
287: root_dir: /tmp/deepcam/instance0
141: root_dir: /tmp/deepcam/instance0
118: root_dir: /tmp/deepcam/instance0
107: root_dir: /tmp/deepcam/instance0
185: root_dir: /tmp/deepcam/instance0
301: root_dir: /tmp/deepcam/instance0
423: root_dir: /tmp/deepcam/instance0
 76: root_dir: /tmp/deepcam/instance0
487: root_dir: /tmp/deepcam/instance0
489: root_dir: /tmp/deepcam/instance0
270: root_dir: /tmp/deepcam/instance0
176: root_dir: /tmp/deepcam/instance0
302: root_dir: /tmp/deepcam/instance0
236: root_dir: /tmp/deepcam/instance0
437: root_dir: /tmp/deepcam/instance0
215: root_dir: /tmp/deepcam/instance0
293: root_dir: /tmp/deepcam/instance0
179: root_dir: /tmp/deepcam/instance0
256: root_dir: /tmp/deepcam/instance0
511: root_dir: /tmp/deepcam/instance0
246: root_dir: /tmp/deepcam/instance0
 58: root_dir: /tmp/deepcam/instance0
174: root_dir: /tmp/deepcam/instance0
239: root_dir: /tmp/deepcam/instance0
387: root_dir: /tmp/deepcam/instance0
509: root_dir: /tmp/deepcam/instance0
439: root_dir: /tmp/deepcam/instance0
502: root_dir: /tmp/deepcam/instance0
112: root_dir: /tmp/deepcam/instance0
142: root_dir: /tmp/deepcam/instance0
237: root_dir: /tmp/deepcam/instance0
478: root_dir: /tmp/deepcam/instance0
477: root_dir: /tmp/deepcam/instance0
501: root_dir: /tmp/deepcam/instance0
156: root_dir: /tmp/deepcam/instance0
224: root_dir: /tmp/deepcam/instance0
481: root_dir: /tmp/deepcam/instance0
222: root_dir: /tmp/deepcam/instance0
272: root_dir: /tmp/deepcam/instance0
283: root_dir: /tmp/deepcam/instance0
143: root_dir: /tmp/deepcam/instance0
399: root_dir: /tmp/deepcam/instance0
351: root_dir: /tmp/deepcam/instance0
386: root_dir: /tmp/deepcam/instance0
506: root_dir: /tmp/deepcam/instance0
431: root_dir: /tmp/deepcam/instance0
440: root_dir: /tmp/deepcam/instance0
361: root_dir: /tmp/deepcam/instance0
458: root_dir: /tmp/deepcam/instance0
220: root_dir: /tmp/deepcam/instance0
108: root_dir: /tmp/deepcam/instance0
248: root_dir: /tmp/deepcam/instance0
381: root_dir: /tmp/deepcam/instance0
146: root_dir: /tmp/deepcam/instance0
362: root_dir: /tmp/deepcam/instance0
363: root_dir: /tmp/deepcam/instance0
313: root_dir: /tmp/deepcam/instance0
290: root_dir: /tmp/deepcam/instance0
257: root_dir: /tmp/deepcam/instance0
198: root_dir: /tmp/deepcam/instance0
155: root_dir: /tmp/deepcam/instance0
384: root_dir: /tmp/deepcam/instance0
221: root_dir: /tmp/deepcam/instance0
 41: root_dir: /tmp/deepcam/instance0
 62: root_dir: /tmp/deepcam/instance0
 65: root_dir: /tmp/deepcam/instance0
314: root_dir: /tmp/deepcam/instance0
453: root_dir: /tmp/deepcam/instance0
 64: root_dir: /tmp/deepcam/instance0
479: root_dir: /tmp/deepcam/instance0
 69: root_dir: /tmp/deepcam/instance0
216: root_dir: /tmp/deepcam/instance0
385: root_dir: /tmp/deepcam/instance0
228: root_dir: /tmp/deepcam/instance0
258: root_dir: /tmp/deepcam/instance0
223: root_dir: /tmp/deepcam/instance0
286: root_dir: /tmp/deepcam/instance0
315: root_dir: /tmp/deepcam/instance0
259: root_dir: /tmp/deepcam/instance0
 79: root_dir: /tmp/deepcam/instance0
 72: root_dir: /tmp/deepcam/instance0
230: root_dir: /tmp/deepcam/instance0
199: root_dir: /tmp/deepcam/instance0
380: root_dir: /tmp/deepcam/instance0
276: root_dir: /tmp/deepcam/instance0
147: root_dir: /tmp/deepcam/instance0
316: root_dir: /tmp/deepcam/instance0
177: root_dir: /tmp/deepcam/instance0
249: root_dir: /tmp/deepcam/instance0
 47: root_dir: /tmp/deepcam/instance0
178: root_dir: /tmp/deepcam/instance0
488: root_dir: /tmp/deepcam/instance0
242: root_dir: /tmp/deepcam/instance0
226: root_dir: /tmp/deepcam/instance0
170: root_dir: /tmp/deepcam/instance0
123: root_dir: /tmp/deepcam/instance0
324: root_dir: /tmp/deepcam/instance0
457: root_dir: /tmp/deepcam/instance0
150: root_dir: /tmp/deepcam/instance0
 85: root_dir: /tmp/deepcam/instance0
188: root_dir: /tmp/deepcam/instance0
339: root_dir: /tmp/deepcam/instance0
 56: root_dir: /tmp/deepcam/instance0
 96: root_dir: /tmp/deepcam/instance0
 51: root_dir: /tmp/deepcam/instance0
280: root_dir: /tmp/deepcam/instance0
430: root_dir: /tmp/deepcam/instance0
182: root_dir: /tmp/deepcam/instance0
161: root_dir: /tmp/deepcam/instance0
 26: root_dir: /tmp/deepcam/instance0
456: root_dir: /tmp/deepcam/instance0
125: root_dir: /tmp/deepcam/instance0
503: root_dir: /tmp/deepcam/instance0
480: root_dir: /tmp/deepcam/instance0
436: root_dir: /tmp/deepcam/instance0
 78: root_dir: /tmp/deepcam/instance0
312: root_dir: /tmp/deepcam/instance0
376: root_dir: /tmp/deepcam/instance0
167: root_dir: /tmp/deepcam/instance0
499: root_dir: /tmp/deepcam/instance0
372: root_dir: /tmp/deepcam/instance0
368: root_dir: /tmp/deepcam/instance0
366: root_dir: /tmp/deepcam/instance0
 74: root_dir: /tmp/deepcam/instance0
323: root_dir: /tmp/deepcam/instance0
164: root_dir: /tmp/deepcam/instance0
424: root_dir: /tmp/deepcam/instance0
 38: root_dir: /tmp/deepcam/instance0
152: root_dir: /tmp/deepcam/instance0
 13: root_dir: /tmp/deepcam/instance0
168: root_dir: /tmp/deepcam/instance0
  9: root_dir: /tmp/deepcam/instance0
 95: root_dir: /tmp/deepcam/instance0
495: root_dir: /tmp/deepcam/instance0
393: root_dir: /tmp/deepcam/instance0
428: root_dir: /tmp/deepcam/instance0
253: root_dir: /tmp/deepcam/instance0
269: root_dir: /tmp/deepcam/instance0
466: root_dir: /tmp/deepcam/instance0
 80: root_dir: /tmp/deepcam/instance0
201: root_dir: /tmp/deepcam/instance0
 86: root_dir: /tmp/deepcam/instance0
388: root_dir: /tmp/deepcam/instance0
172: root_dir: /tmp/deepcam/instance0
417: root_dir: /tmp/deepcam/instance0
277: root_dir: /tmp/deepcam/instance0
345: root_dir: /tmp/deepcam/instance0
410: root_dir: /tmp/deepcam/instance0
158: root_dir: /tmp/deepcam/instance0
115: root_dir: /tmp/deepcam/instance0
432: root_dir: /tmp/deepcam/instance0
418: root_dir: /tmp/deepcam/instance0
240: root_dir: /tmp/deepcam/instance0
400: root_dir: /tmp/deepcam/instance0
133: root_dir: /tmp/deepcam/instance0
 36: root_dir: /tmp/deepcam/instance0
455: root_dir: /tmp/deepcam/instance0
157: root_dir: /tmp/deepcam/instance0
469: root_dir: /tmp/deepcam/instance0
 70: root_dir: /tmp/deepcam/instance0
 18: root_dir: /tmp/deepcam/instance0
109: root_dir: /tmp/deepcam/instance0
203: root_dir: /tmp/deepcam/instance0
229: root_dir: /tmp/deepcam/instance0
265: root_dir: /tmp/deepcam/instance0
360: root_dir: /tmp/deepcam/instance0
336: root_dir: /tmp/deepcam/instance0
300: root_dir: /tmp/deepcam/instance0
262: root_dir: /tmp/deepcam/instance0
252: root_dir: /tmp/deepcam/instance0
335: root_dir: /tmp/deepcam/instance0
 50: root_dir: /tmp/deepcam/instance0
113: root_dir: /tmp/deepcam/instance0
419: root_dir: /tmp/deepcam/instance0
 40: root_dir: /tmp/deepcam/instance0
160: root_dir: /tmp/deepcam/instance0
342: root_dir: /tmp/deepcam/instance0
 94: root_dir: /tmp/deepcam/instance0
173: root_dir: /tmp/deepcam/instance0
397: root_dir: /tmp/deepcam/instance0
166: root_dir: /tmp/deepcam/instance0
219: root_dir: /tmp/deepcam/instance0
319: root_dir: /tmp/deepcam/instance0
 19: root_dir: /tmp/deepcam/instance0
  4: root_dir: /tmp/deepcam/instance0
460: root_dir: /tmp/deepcam/instance0
329: root_dir: /tmp/deepcam/instance0
490: root_dir: /tmp/deepcam/instance0
 88: root_dir: /tmp/deepcam/instance0
285: root_dir: /tmp/deepcam/instance0
209: root_dir: /tmp/deepcam/instance0
297: root_dir: /tmp/deepcam/instance0
169: root_dir: /tmp/deepcam/instance0
498: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
504: root_dir: /tmp/deepcam/instance0
333: root_dir: /tmp/deepcam/instance0
311: root_dir: /tmp/deepcam/instance0
 28: root_dir: /tmp/deepcam/instance0
505: root_dir: /tmp/deepcam/instance0
 32: root_dir: /tmp/deepcam/instance0
275: root_dir: /tmp/deepcam/instance0
  2: root_dir: /tmp/deepcam/instance0
 24: root_dir: /tmp/deepcam/instance0
309: root_dir: /tmp/deepcam/instance0
181: root_dir: /tmp/deepcam/instance0
 89: root_dir: /tmp/deepcam/instance0
 63: root_dir: /tmp/deepcam/instance0
341: root_dir: /tmp/deepcam/instance0
426: root_dir: /tmp/deepcam/instance0
273: root_dir: /tmp/deepcam/instance0
271: root_dir: /tmp/deepcam/instance0
208: root_dir: /tmp/deepcam/instance0
 23: root_dir: /tmp/deepcam/instance0
 73: root_dir: /tmp/deepcam/instance0
130: root_dir: /tmp/deepcam/instance0
153: root_dir: /tmp/deepcam/instance0
 22: root_dir: /tmp/deepcam/instance0
326: root_dir: /tmp/deepcam/instance0
131: root_dir: /tmp/deepcam/instance0
 59: root_dir: /tmp/deepcam/instance0
 43: root_dir: /tmp/deepcam/instance0
234: root_dir: /tmp/deepcam/instance0
475: root_dir: /tmp/deepcam/instance0
145: root_dir: /tmp/deepcam/instance0
 48: root_dir: /tmp/deepcam/instance0
263: root_dir: /tmp/deepcam/instance0
294: root_dir: /tmp/deepcam/instance0
268: root_dir: /tmp/deepcam/instance0
321: root_dir: /tmp/deepcam/instance0
 71: root_dir: /tmp/deepcam/instance0
136: root_dir: /tmp/deepcam/instance0
163: root_dir: /tmp/deepcam/instance0
 14: root_dir: /tmp/deepcam/instance0
434: root_dir: /tmp/deepcam/instance0
119: root_dir: /tmp/deepcam/instance0
474: root_dir: /tmp/deepcam/instance0
415: root_dir: /tmp/deepcam/instance0
  8: root_dir: /tmp/deepcam/instance0
403: root_dir: /tmp/deepcam/instance0
279: root_dir: /tmp/deepcam/instance0
 61: root_dir: /tmp/deepcam/instance0
232: root_dir: /tmp/deepcam/instance0
 37: root_dir: /tmp/deepcam/instance0
296: root_dir: /tmp/deepcam/instance0
404: root_dir: /tmp/deepcam/instance0
306: root_dir: /tmp/deepcam/instance0
247: root_dir: /tmp/deepcam/instance0
127: root_dir: /tmp/deepcam/instance0
409: root_dir: /tmp/deepcam/instance0
192: root_dir: /tmp/deepcam/instance0
 46: root_dir: /tmp/deepcam/instance0
461: root_dir: /tmp/deepcam/instance0
398: root_dir: /tmp/deepcam/instance0
414: root_dir: /tmp/deepcam/instance0
154: root_dir: /tmp/deepcam/instance0
 81: root_dir: /tmp/deepcam/instance0
406: root_dir: /tmp/deepcam/instance0
 92: root_dir: /tmp/deepcam/instance0
405: root_dir: /tmp/deepcam/instance0
 11: root_dir: /tmp/deepcam/instance0
 87: root_dir: /tmp/deepcam/instance0
 44: root_dir: /tmp/deepcam/instance0
367: root_dir: /tmp/deepcam/instance0
425: root_dir: /tmp/deepcam/instance0
 12: root_dir: /tmp/deepcam/instance0
205: root_dir: /tmp/deepcam/instance0
 53: root_dir: /tmp/deepcam/instance0
353: root_dir: /tmp/deepcam/instance0
357: root_dir: /tmp/deepcam/instance0
 97: root_dir: /tmp/deepcam/instance0
291: root_dir: /tmp/deepcam/instance0
106: root_dir: /tmp/deepcam/instance0
394: root_dir: /tmp/deepcam/instance0
149: root_dir: /tmp/deepcam/instance0
227: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
132: root_dir: /tmp/deepcam/instance0
442: root_dir: /tmp/deepcam/instance0
126: root_dir: /tmp/deepcam/instance0
129: root_dir: /tmp/deepcam/instance0
472: root_dir: /tmp/deepcam/instance0
292: root_dir: /tmp/deepcam/instance0
101: root_dir: /tmp/deepcam/instance0
450: root_dir: /tmp/deepcam/instance0
298: root_dir: /tmp/deepcam/instance0
389: root_dir: /tmp/deepcam/instance0
 55: root_dir: /tmp/deepcam/instance0
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
 90: root_dir: /tmp/deepcam/instance0
218: root_dir: /tmp/deepcam/instance0
267: root_dir: /tmp/deepcam/instance0
420: root_dir: /tmp/deepcam/instance0
  0: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641370, "event_type": "POINT_IN_TIME", "key": "number_of_ranks", "value": 512, "metadata": {"file": "./train_instance.py", "lineno": 211}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641370, "event_type": "POINT_IN_TIME", "key": "number_of_nodes", "value": 128, "metadata": {"file": "./train_instance.py", "lineno": 212}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "accelerators_per_node", "value": 4, "metadata": {"file": "./train_instance.py", "lineno": 213}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "instance_id", "value": 0, "metadata": {"file": "./train_instance.py", "lineno": 215}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "checkpoint", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 217}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1024, "metadata": {"file": "./train_instance.py", "lineno": 218}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "batchnorm_group_size", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 219}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_frequency", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "data_format", "value": "dali-numpy/hdf5", "metadata": {"file": "./train_instance.py", "lineno": 222}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "shuffle_mode", "value": "global", "metadata": {"file": "./train_instance.py", "lineno": 223}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641371, "event_type": "POINT_IN_TIME", "key": "data_oversampling_factor", "value": 1, "metadata": {"file": "./train_instance.py", "lineno": 224}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "stage_dir_prefix", "value": "/tmp/deepcam", "metadata": {"file": "./train_instance.py", "lineno": 226}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "stage_mode", "value": "node", "metadata": {"file": "./train_instance.py", "lineno": 227}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "stage_batch_size", "value": -1, "metadata": {"file": "./train_instance.py", "lineno": 228}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "stage_verify", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 229}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "stage_full_data_per_node", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "stage_use_direct_io", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 231}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "precision_mode", "value": "amp", "metadata": {"file": "./train_instance.py", "lineno": 233}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641378, "event_type": "POINT_IN_TIME", "key": "enable_nhwc", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 234}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641379, "event_type": "POINT_IN_TIME", "key": "enable_graph", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 235}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641379, "event_type": "POINT_IN_TIME", "key": "enable_jit", "value": true, "metadata": {"file": "./train_instance.py", "lineno": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413641379, "event_type": "POINT_IN_TIME", "key": "disable_comm_overlap", "value": false, "metadata": {"file": "./train_instance.py", "lineno": 237}}
  0: Constructing DeepLabv3+ model...
  0: Number of output channels: 3
  0: Output stride: 16
  0: Number of Input Channels: 16
 29: root_dir: /tmp/deepcam/instance0
358: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642106, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "LAMB", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 144}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642113, "event_type": "POINT_IN_TIME", "key": "opt_lr", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642113, "event_type": "POINT_IN_TIME", "key": "opt_bias_correction", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642114, "event_type": "POINT_IN_TIME", "key": "opt_betas", "value": [0.9, 0.999], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642114, "event_type": "POINT_IN_TIME", "key": "opt_eps", "value": 1e-06, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642114, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.01, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642114, "event_type": "POINT_IN_TIME", "key": "opt_grad_averaging", "value": true, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642114, "event_type": "POINT_IN_TIME", "key": "opt_max_grad_norm", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 147}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642115, "event_type": "POINT_IN_TIME", "key": "scheduler_type", "value": "multistep", "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642115, "event_type": "POINT_IN_TIME", "key": "scheduler_milestones", "value": [1100, 4096], "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642115, "event_type": "POINT_IN_TIME", "key": "scheduler_decay_rate", "value": 0.1, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642115, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_steps", "value": 200, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642115, "event_type": "POINT_IN_TIME", "key": "scheduler_lr_warmup_factor", "value": 1.0, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/utils/optimizer_helpers.py", "lineno": 108}}
  0: DeepLabv3_plus(
  0:   (xception_features): Xception(
  0:     (relu): ReLU()
  0:     (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  0:     (bn1): Sequential(
  0:       (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:     (bn2): Sequential(
  0:       (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (block1): Block(
  0:       (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
  0:           (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Seque
  0: ntial(
  0:           (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block2): Block(
  0:       (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
  0:       (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1):
  0:  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
  0:           (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block3): Block(
  0:       (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), 
  0: bias=False)
  0:       (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
  0:           (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (2): ReLU()
  0:         (3): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (4): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (5): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2
  0: d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (block4): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size
  0: =(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block5): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm
  0: 2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block6): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), 
  0: padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block7): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, mome
  0: ntum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block8): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=
  0: 728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block
  0: 9): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d
  0: (728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block10): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU
  0: ()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block11): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_siz
  0: e=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block12): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (
  0: 2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block13): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1
  0: ), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block14): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_s
  0: ame(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchN
  0: orm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block15): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kern
  0: el_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block16): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): B
  0: atchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block17): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), strid
  0: e=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block18): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1
  0: e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0:     (block19): Block(
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 
  0: 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (4): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       )
  0:     )
  0: 
  0:     (block20): Block(
  0:       (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (relu): ReLU()
  0:       (rep): Sequential(
  0:         (0): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (1): Sequential(
  0:           (0): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:           (1): ReLU()
  0:         )
  0:         (2): SeparableConv2d_same(
  0:           (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
  0:           (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:         (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (4): SeparableConv2d_same(
  0:        
  0:    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
  0:           (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         )
  0:       )
  0:     )
  0:     (conv3): SeparableConv2d_same(
  0:       (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1024, bias=False)
  0:       (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn3): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv4): SeparableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn4): Sequential(
  0:       (0): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:     (conv5): Separ
  0: ableConv2d_same(
  0:       (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1536, bias=False)
  0:       (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     )
  0:     (bn5): Sequential(
  0:       (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (bottleneck): Bottleneck(
  0:     (aspp1): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp2): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp3): ASPP_module(
  0:       (atrous_co
  0: nvolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (aspp4): ASPP_module(
  0:       (atrous_convolution): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)
  0:       (bn): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (global_avg_pool): GlobalAveragePool(
  0:       (global_average_pool): Sequential(
  0:         (0): AdaptiveAvgPool2d(output_size=(1, 1))
  0:         (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:         (2): TrainableAffine()
  0:         (3): ReLU(inplace=True)
  0:       )
  0:     )
  0:     (tiling): Tiling()
  0:     (conv): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:     (bn): Sequential(
  0:       (0): BatchNorm2d(256, eps=1e-05, 
  0: momentum=0.1, affine=True, track_running_stats=True)
  0:       (1): ReLU()
  0:     )
  0:   )
  0:   (conv2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
  0:   (bn2): Sequential(
  0:     (0): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:     (1): ReLU()
  0:   )
  0:   (upsample): DeconvUpsampler(
  0:     (deconv1): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (conv1): Sequential(
  0:       (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0: 
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  0:       (3): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:       (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  0:     )
  0:     (deconv2): Sequential(
  0:       (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:       (1): Sequential(
  0:         (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  0:         (1): ReLU()
  0:       )
  0:     )
  0:     (last_deconv): Sequential(
  0:       (0): ConvTranspose2d(256, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)
  0:     )
  0:   )
  0: )
  0: Number of trainable parameters: 56454720
328: root_dir: /tmp/deepcam/instance0
  0: Creating Dataloaders
337: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642823, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 121266, "metadata": {"file": "./train_instance.py", "lineno": 353}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413642823, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 15158, "metadata": {"file": "./train_instance.py", "lineno": 354}}
  0: Number of steps per epoch 118
  0: Creating Trainer
  0: Creating Validator
289: root_dir: /tmp/deepcam/instance0
100: root_dir: /tmp/deepcam/instance0
310: root_dir: /tmp/deepcam/instance0
304: root_dir: /tmp/deepcam/instance0
317: root_dir: /tmp/deepcam/instance0
135: root_dir: /tmp/deepcam/instance0
411: root_dir: /tmp/deepcam/instance0
470: root_dir: /tmp/deepcam/instance0
139: root_dir: /tmp/deepcam/instance0
189: root_dir: /tmp/deepcam/instance0
281: root_dir: /tmp/deepcam/instance0
 82: root_dir: /tmp/deepcam/instance0
102: root_dir: /tmp/deepcam/instance0
422: root_dir: /tmp/deepcam/instance0
 52: root_dir: /tmp/deepcam/instance0
  0: :::MLLOG {"namespace": "", "time_ms": 1633413689710, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 398}}
  1: hdf5!!
  2: hdf5!!
  3: hdf5!!
304: hdf5!!
448: hdf5!!
224: hdf5!!
 32: hdf5!!
408: hdf5!!
456: hdf5!!
193: hdf5!!
436: hdf5!!
100: hdf5!!
400: hdf5!!
424: hdf5!!
440: hdf5!!
140: hdf5!!
176: hdf5!!
120: hdf5!!
216: hdf5!!
 64: hdf5!!
220: hdf5!!
368: hdf5!!
320: hdf5!!
272: hdf5!!
484: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633413689711, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 401}}
432: hdf5!!
468: hdf5!!
457: hdf5!!
504: hdf5!!
 12: hdf5!!
 37: hdf5!!
 60: hdf5!!
108: hdf5!!
 96: hdf5!!
 24: hdf5!!
156: hdf5!!
 84: hdf5!!
180: hdf5!!
194: hdf5!!
460: hdf5!!
 52: hdf5!!
 88: hdf5!!
 76: hdf5!!
148: hdf5!!
 28: hdf5!!
 40: hdf5!!
  5: hdf5!!
184: hdf5!!
 17: hdf5!!
401: hdf5!!
425: hdf5!!
452: hdf5!!
 44: hdf5!!
 20: hdf5!!
128: hdf5!!
404: hdf5!!
 92: hdf5!!
 56: hdf5!!
 68: hdf5!!
141: hdf5!!
116: hdf5!!
476: hdf5!!
152: hdf5!!
200: hdf5!!
264: hdf5!!
480: hdf5!!
204: hdf5!!
288: hdf5!!
144: hdf5!!
132: hdf5!!
252: hdf5!!
276: hdf5!!
168: hdf5!!
336: hdf5!!
217: hdf5!!
 48: hdf5!!
360: hdf5!!
324: hdf5!!
160: hdf5!!
112: hdf5!!
208: hdf5!!
268: hdf5!!
 65: hdf5!!
196: hdf5!!
124: hdf5!!
136: hdf5!!
316: hdf5!!
280: hdf5!!
256: hdf5!!
284: hdf5!!
104: hdf5!!
248: hdf5!!
236: hdf5!!
188: hdf5!!
  8: hdf5!!
332: hdf5!!
369: hdf5!!
308: hdf5!!
260: hdf5!!
356: hdf5!!
 72: hdf5!!
228: hdf5!!
240: hdf5!!
372: hdf5!!
348: hdf5!!
312: hdf5!!
301: hdf5!!
232: hdf5!!
376: hdf5!!
244: hdf5!!
328: hdf5!!
353: hdf5!!
388: hdf5!!
340: hdf5!!
449: hdf5!!
225: hdf5!!
392: hdf5!!
 80: hdf5!!
 33: hdf5!!
465: hdf5!!
416: hdf5!!
396: hdf5!!
444: hdf5!!
485: hdf5!!
412: hdf5!!
420: hdf5!!
492: hdf5!!
488: hdf5!!
472: hdf5!!
497: hdf5!!
500: hdf5!!
428: hdf5!!
  0: :::MLLOG {"namespace": "", "time_ms": 1633413689712, "event_type": "INTERVAL_START", "key": "staging_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 405}}
410: hdf5!!
433: hdf5!!
469: hdf5!!
458: hdf5!!
505: hdf5!!
 13: hdf5!!
 38: hdf5!!
 61: hdf5!!
384: hdf5!!
109: hdf5!!
 97: hdf5!!
 25: hdf5!!
157: hdf5!!
 85: hdf5!!
181: hdf5!!
195: hdf5!!
461: hdf5!!
508: hdf5!!
 53: hdf5!!
 89: hdf5!!
437: hdf5!!
 77: hdf5!!
149: hdf5!!
 29: hdf5!!
101: hdf5!!
 42: hdf5!!
  6: hdf5!!
185: hdf5!!
 18: hdf5!!
402: hdf5!!
426: hdf5!!
441: hdf5!!
453: hdf5!!
 45: hdf5!!
 21: hdf5!!
129: hdf5!!
405: hdf5!!
 93: hdf5!!
 57: hdf5!!
 69: hdf5!!
142: hdf5!!
177: hdf5!!
117: hdf5!!
477: hdf5!!
153: hdf5!!
201: hdf5!!
265: hdf5!!
481: hdf5!!
205: hdf5!!
289: hdf5!!
145: hdf5!!
133: hdf5!!
121: hdf5!!
253: hdf5!!
277: hdf5!!
169: hdf5!!
337: hdf5!!
218: hdf5!!
 49: hdf5!!
361: hdf5!!
325: hdf5!!
161: hdf5!!
113: hdf5!!
209: hdf5!!
269: hdf5!!
 66: hdf5!!
197: hdf5!!
172: hdf5!!
125: hdf5!!
221: hdf5!!
137: hdf5!!
317: hdf5!!
292: hdf5!!
281: hdf5!!
257: hdf5!!
364: hdf5!!
285: hdf5!!
105: hdf5!!
249: hdf5!!
237: hdf5!!
189: hdf5!!
  9: hdf5!!
333: hdf5!!
371: hdf5!!
309: hdf5!!
296: hdf5!!
321: hdf5!!
380: hdf5!!
261: hdf5!!
164: hdf5!!
357: hdf5!!
 73: hdf5!!
229: hdf5!!
241: hdf5!!
373: hdf5!!
349: hdf5!!
313: hdf5!!
302: hdf5!!
233: hdf5!!
377: hdf5!!
305: hdf5!!
245: hdf5!!
329: hdf5!!
354: hdf5!!
389: hdf5!!
341: hdf5!!
450: hdf5!!
226: hdf5!!
273: hdf5!!
393: hdf5!!
 81: hdf5!!
344: hdf5!!
 34: hdf5!!
212: hdf5!!
466: hdf5!!
417: hdf5!!
397: hdf5!!
445: hdf5!!
486: hdf5!!
413: hdf5!!
422: hdf5!!
493: hdf5!!
489: hdf5!!
473: hdf5!!
498: hdf5!!
501: hdf5!!
430: hdf5!!
  0: hdf5!!
411: hdf5!!
434: hdf5!!
470: hdf5!!
459: hdf5!!
506: hdf5!!
 14: hdf5!!
 39: hdf5!!
 62: hdf5!!
385: hdf5!!
110: hdf5!!
 98: hdf5!!
 26: hdf5!!
158: hdf5!!
 86: hdf5!!
182: hdf5!!
192: hdf5!!
462: hdf5!!
509: hdf5!!
 54: hdf5!!
 90: hdf5!!
438: hdf5!!
 78: hdf5!!
150: hdf5!!
 30: hdf5!!
102: hdf5!!
 43: hdf5!!
  7: hdf5!!
186: hdf5!!
 19: hdf5!!
403: hdf5!!
427: hdf5!!
442: hdf5!!
454: hdf5!!
 46: hdf5!!
 22: hdf5!!
130: hdf5!!
406: hdf5!!
 94: hdf5!!
 58: hdf5!!
 70: hdf5!!
143: hdf5!!
178: hdf5!!
118: hdf5!!
478: hdf5!!
154: hdf5!!
202: hdf5!!
266: hdf5!!
482: hdf5!!
206: hdf5!!
290: hdf5!!
146: hdf5!!
134: hdf5!!
122: hdf5!!
254: hdf5!!
278: hdf5!!
170: hdf5!!
338: hdf5!!
219: hdf5!!
 50: hdf5!!
362: hdf5!!
326: hdf5!!
162: hdf5!!
114: hdf5!!
210: hdf5!!
270: hdf5!!
 67: hdf5!!
198: hdf5!!
174: hdf5!!
126: hdf5!!
223: hdf5!!
138: hdf5!!
318: hdf5!!
293: hdf5!!
282: hdf5!!
258: hdf5!!
365: hdf5!!
286: hdf5!!
106: hdf5!!
250: hdf5!!
238: hdf5!!
190: hdf5!!
 10: hdf5!!
334: hdf5!!
370: hdf5!!
310: hdf5!!
297: hdf5!!
322: hdf5!!
381: hdf5!!
262: hdf5!!
165: hdf5!!
358: hdf5!!
 74: hdf5!!
230: hdf5!!
242: hdf5!!
374: hdf5!!
350: hdf5!!
314: hdf5!!
303: hdf5!!
234: hdf5!!
378: hdf5!!
306: hdf5!!
246: hdf5!!
330: hdf5!!
355: hdf5!!
390: hdf5!!
342: hdf5!!
451: hdf5!!
227: hdf5!!
274: hdf5!!
395: hdf5!!
 82: hdf5!!
345: hdf5!!
 35: hdf5!!
213: hdf5!!
467: hdf5!!
418: hdf5!!
398: hdf5!!
446: hdf5!!
487: hdf5!!
414: hdf5!!
423: hdf5!!
494: hdf5!!
490: hdf5!!
474: hdf5!!
499: hdf5!!
502: hdf5!!
429: hdf5!!
409: hdf5!!
435: hdf5!!
471: hdf5!!
507: hdf5!!
 15: hdf5!!
 36: hdf5!!
 63: hdf5!!
386: hdf5!!
111: hdf5!!
 99: hdf5!!
 27: hdf5!!
159: hdf5!!
 87: hdf5!!
183: hdf5!!
463: hdf5!!
510: hdf5!!
 55: hdf5!!
 91: hdf5!!
439: hdf5!!
 79: hdf5!!
151: hdf5!!
 31: hdf5!!
103: hdf5!!
 41: hdf5!!
  4: hdf5!!
187: hdf5!!
 16: hdf5!!
443: hdf5!!
455: hdf5!!
 47: hdf5!!
 23: hdf5!!
131: hdf5!!
407: hdf5!!
 95: hdf5!!
 59: hdf5!!
 71: hdf5!!
179: hdf5!!
119: hdf5!!
479: hdf5!!
155: hdf5!!
203: hdf5!!
267: hdf5!!
483: hdf5!!
207: hdf5!!
291: hdf5!!
147: hdf5!!
135: hdf5!!
123: hdf5!!
255: hdf5!!
279: hdf5!!
171: hdf5!!
339: hdf5!!
 51: hdf5!!
363: hdf5!!
327: hdf5!!
163: hdf5!!
115: hdf5!!
211: hdf5!!
271: hdf5!!
199: hdf5!!
175: hdf5!!
127: hdf5!!
222: hdf5!!
139: hdf5!!
319: hdf5!!
294: hdf5!!
283: hdf5!!
259: hdf5!!
366: hdf5!!
287: hdf5!!
107: hdf5!!
251: hdf5!!
239: hdf5!!
191: hdf5!!
 11: hdf5!!
335: hdf5!!
311: hdf5!!
298: hdf5!!
323: hdf5!!
382: hdf5!!
263: hdf5!!
166: hdf5!!
359: hdf5!!
 75: hdf5!!
231: hdf5!!
243: hdf5!!
375: hdf5!!
351: hdf5!!
315: hdf5!!
300: hdf5!!
235: hdf5!!
379: hdf5!!
307: hdf5!!
247: hdf5!!
331: hdf5!!
352: hdf5!!
391: hdf5!!
343: hdf5!!
275: hdf5!!
394: hdf5!!
 83: hdf5!!
346: hdf5!!
214: hdf5!!
464: hdf5!!
419: hdf5!!
399: hdf5!!
447: hdf5!!
415: hdf5!!
421: hdf5!!
495: hdf5!!
491: hdf5!!
475: hdf5!!
496: hdf5!!
503: hdf5!!
431: hdf5!!
387: hdf5!!
511: hdf5!!
173: hdf5!!
295: hdf5!!
367: hdf5!!
299: hdf5!!
383: hdf5!!
167: hdf5!!
347: hdf5!!
215: hdf5!!
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 train.h5/labels
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/data
  0: Preparing file lists for /tmp/deepcam/instance0 validation.h5/labels
  0: :::MLLOG {"namespace": "", "time_ms": 1633413803474, "event_type": "INTERVAL_END", "key": "staging_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 425}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413803477, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 1, "step_num": 0}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413809172, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00017999999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413809173, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.1618470400571823, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413809173, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.4767545461654663, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413811145, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00038, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413811146, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.1954425424337387, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413811146, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.1298000812530518, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 20}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413812095, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00058, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413812095, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.26680368185043335, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413812096, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.7706170678138733, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 30}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413813030, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0007800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413813030, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3190421164035797, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413813030, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.44526079297065735, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 40}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413813985, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00098, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413813985, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3284119963645935, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413813985, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.22618085145950317, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 50}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413814915, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00118, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413814916, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.3319093585014343, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413814916, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.12452597916126251, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 60}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413815847, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00138, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413815848, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.36418578028678894, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413815848, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.07978930324316025, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 70}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413816783, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00158, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413816783, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.44958066940307617, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413816783, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0616040974855423, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 80}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413817710, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0017800000000000001, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413817710, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.4951942265033722, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413817710, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.04779032990336418, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 90}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413818652, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00198, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413818652, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.49214601516723633, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413818652, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0414762869477272, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413819585, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00218, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413819586, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5094982981681824, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413819586, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03704814612865448, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 1, "step_num": 110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413820338, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 1}}
  0: EVAL: first data load time: 0.36127405893057585
  0: EVAL: step 1 time -> 0.033225889317691326
  0: EVAL: step 2 time -> 0.14546495489776134
  0: EVAL: step 3 time -> 0.01212401781231165
  0: EVAL: step 4 time -> 0.012197262607514858
  0: EVAL: full eval time -> 1.0141549343243241
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821365, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.509799996031386, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821366, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.04567325811993873, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821366, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 1}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821385, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 1, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821404, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 2, "step_num": 118}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821609, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0023799999999999997, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821609, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5318692922592163, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413821609, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03675619885325432, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413822540, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0025800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413822541, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5439916849136353, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413822541, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.036195870488882065, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413823487, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00278, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413823487, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5438591241836548, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413823487, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.03300345689058304, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413824420, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00298, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413824421, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.550331175327301, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413824421, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.034802116453647614, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413825354, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00318, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413825354, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5762812495231628, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413825354, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02903621643781662, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413826297, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0033799999999999998, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413826297, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5857822895050049, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413826297, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.028189877048134804, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413827229, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0035800000000000003, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413827230, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.581609308719635, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413827230, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0308342557400465, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413828163, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00378, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413828164, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5883045792579651, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413828164, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.027865801006555557, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413829105, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.00398, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413829105, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5564780831336975, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413829106, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.033407460898160934, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413830046, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413830046, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.5863906741142273, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413830046, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02692246064543724, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413830988, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413830989, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.603033185005188, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413830989, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.025189151987433434, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413831922, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413831922, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6104207634925842, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413831923, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.025357652455568314, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 2, "step_num": 230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413832489, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 2}}
  0: EVAL: first data load time: 0.0015368936583399773
  0: EVAL: step 1 time -> 0.033528528176248074
  0: EVAL: step 2 time -> 0.03244004026055336
  0: EVAL: step 3 time -> 0.03227812144905329
  0: EVAL: step 4 time -> 0.13008778635412455
  0: EVAL: full eval time -> 1.0679108137264848
  0: :::MLLOG {"namespace": "", "time_ms": 1633413833560, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5853802189850245, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413833560, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.031331415776606204, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413833560, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 2}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413833561, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 2, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413833580, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 3, "step_num": 236}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413834837, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413834838, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6210447549819946, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413834838, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.024425935000181198, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413836569, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413836569, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6276525259017944, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413836569, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02308495342731476, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413837630, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413837630, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6264576315879822, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413837630, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021743284538388252, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413838571, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413838572, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6299586296081543, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413838572, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.023130683228373528, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413839510, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413839511, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6371954083442688, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413839511, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.022210564464330673, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413840442, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413840442, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6355800032615662, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413840442, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.021102169528603554, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413841383, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413841383, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6410515904426575, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413841383, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020742742344737053, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413842315, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413842316, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6341526508331299, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413842316, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.02022644504904747, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413843249, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413843249, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6449941992759705, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413843249, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019685884937644005, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413844198, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413844198, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6481837630271912, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413844198, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.020320340991020203, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413845130, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413845131, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6460933089256287, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413845131, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01964731700718403, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413846060, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413846060, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6502158641815186, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413846060, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019212933257222176, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 3, "step_num": 350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413846431, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 3}}
  0: EVAL: first data load time: 0.0023864246904850006
  0: EVAL: step 1 time -> 0.013448139652609825
  0: EVAL: step 2 time -> 0.012395652011036873
  0: EVAL: step 3 time -> 0.01242082193493843
  0: EVAL: step 4 time -> 0.011771895922720432
  0: EVAL: full eval time -> 0.7486295681446791
  0: :::MLLOG {"namespace": "", "time_ms": 1633413847183, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5171047260522497, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413847183, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.0736796208839804, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413847183, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 3}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413847203, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 3, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413847226, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 4, "step_num": 354}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413849081, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413849081, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6382985711097717, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413849081, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019327206537127495, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413850636, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413850636, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6559610366821289, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413850636, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01798010617494583, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413851797, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413851797, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6635364890098572, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413851797, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017926638945937157, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413852727, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413852727, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6739994883537292, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413852727, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01673637330532074, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413853664, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413853664, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6640089154243469, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413853665, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017019297927618027, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413854608, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413854608, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.652895450592041, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413854608, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.019248396158218384, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413855548, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413855549, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6725389361381531, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413855549, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017062397673726082, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 420}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413856493, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413856493, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6632861495018005, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413856493, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017725182697176933, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 430}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413857435, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413857435, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6443878412246704, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413857435, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01808715984225273, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 440}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413858370, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413858370, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6556615233421326, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413858370, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017300143837928772, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 450}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413859326, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413859326, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6744197010993958, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413859327, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.016628559678792953, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 460}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413860255, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413860256, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6769809722900391, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413860256, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.017383480444550514, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 4, "step_num": 470}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413860447, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 4}}
  0: EVAL: first data load time: 0.0012905094772577286
  0: EVAL: step 1 time -> 0.014528807252645493
  0: EVAL: step 2 time -> 0.012345765717327595
  0: EVAL: step 3 time -> 0.012384396977722645
  0: EVAL: step 4 time -> 0.011717718094587326
  0: EVAL: full eval time -> 0.747874315828085
  0: :::MLLOG {"namespace": "", "time_ms": 1633413861198, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6568579839235057, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413861199, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.019192717889790045, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413861199, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 4}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413861218, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 4, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413861243, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 5, "step_num": 472}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413863671, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413863671, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6798406839370728, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413863672, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015146126970648766, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 480}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413864847, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413864847, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6817509531974792, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413864848, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01566159538924694, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 490}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413865896, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413865896, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6817348003387451, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413865897, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015013119205832481, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 500}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413866852, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413866852, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6915941834449768, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413866852, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01494062040001154, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 510}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413867863, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413867864, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6851989030838013, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413867864, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015443815849721432, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 520}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413868793, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413868793, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6963650584220886, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413868793, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01499316655099392, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 530}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413869734, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413869734, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6866692900657654, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413869734, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014473202638328075, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 540}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413870676, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413870677, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.690375030040741, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413870677, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.015520952641963959, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 550}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413871611, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413871612, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6897146105766296, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413871612, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014972093515098095, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 560}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413872551, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413872552, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.6965871453285217, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413872552, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014103339985013008, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 570}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413873498, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413873498, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7035646438598633, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413873498, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.014206798747181892, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 580}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413874445, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413874445, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7118691802024841, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413874446, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013610116206109524, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413874448, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 5}}
  0: EVAL: first data load time: 0.002507990226149559
  0: EVAL: step 1 time -> 0.013202566653490067
  0: EVAL: step 2 time -> 0.012264852412045002
  0: EVAL: step 3 time -> 0.012266875244677067
  0: EVAL: step 4 time -> 0.011743078008294106
  0: EVAL: full eval time -> 0.5361776510253549
  0: :::MLLOG {"namespace": "", "time_ms": 1633413874987, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7016637640808484, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413874988, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.014485056316306777, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413874988, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 5}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413875007, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 5, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413875031, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 6, "step_num": 590}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413877804, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413877804, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7359604835510254, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413877805, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01218384224921465, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 600}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413879011, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413879011, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7034581303596497, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413879011, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013637111522257328, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 610}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413879983, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413879984, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7172886729240417, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413879984, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013752075843513012, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 620}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413880923, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413880923, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7199043035507202, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413880923, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013548064976930618, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 630}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413881860, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413881861, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7170836329460144, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413881861, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01266564056277275, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 640}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413882795, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413882796, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7074565887451172, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413882796, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013393771834671497, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 650}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413883736, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413883737, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7279291152954102, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413883737, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013095272704958916, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 660}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413884681, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413884681, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7279038429260254, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413884681, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012414516881108284, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 670}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413885614, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413885615, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7216619253158569, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413885615, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012632159516215324, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 680}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413886548, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413886548, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7094706296920776, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413886548, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013207009062170982, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 690}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413887483, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413887483, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7149083018302917, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413887484, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.013103972189128399, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 6, "step_num": 700}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413888238, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 6}}
  0: EVAL: first data load time: 0.001196371391415596
  0: EVAL: step 1 time -> 0.013648628257215023
  0: EVAL: step 2 time -> 0.01242581382393837
  0: EVAL: step 3 time -> 0.012493637390434742
  0: EVAL: step 4 time -> 0.011899198405444622
  0: EVAL: full eval time -> 0.6283048177137971
  0: :::MLLOG {"namespace": "", "time_ms": 1633413888870, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6665726483127722, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413888870, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.02044555325828358, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413888870, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 6}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413888890, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 6, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413888913, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 7, "step_num": 708}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413889524, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413889524, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7263491153717041, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413889525, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012246521189808846, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 710}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413891721, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413891721, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7480646967887878, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413891721, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011576002463698387, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 720}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413892652, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413892653, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7501542568206787, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413892653, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012343932874500751, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 730}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413893588, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413893589, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7491893768310547, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413893589, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011439056135714054, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 740}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413894532, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413894532, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7533783316612244, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413894532, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011895264498889446, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 750}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413895482, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413895482, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7488561272621155, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413895482, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011571765877306461, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 760}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413896419, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413896419, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7520655393600464, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413896420, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.012386618182063103, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 770}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413897353, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413897354, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7432065606117249, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413897354, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011976953595876694, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 780}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413898286, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413898286, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7577827572822571, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413898286, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011902973055839539, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 790}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413899214, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413899215, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7526975274085999, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413899215, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011536072008311749, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 800}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413900157, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413900157, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7395600080490112, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413900158, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01169880386441946, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 810}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413901084, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413901085, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7612151503562927, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413901085, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011456838808953762, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 7, "step_num": 820}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413901644, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 7}}
  0: EVAL: first data load time: 0.003045317716896534
  0: EVAL: step 1 time -> 0.01389667484909296
  0: EVAL: step 2 time -> 0.01247700210660696
  0: EVAL: step 3 time -> 0.012510079890489578
  0: EVAL: step 4 time -> 0.012036658823490143
  0: EVAL: full eval time -> 0.5436533186584711
  0: :::MLLOG {"namespace": "", "time_ms": 1633413902191, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7467410979350838, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413902191, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.012523515728725136, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413902191, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 7}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413902211, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 7, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413902235, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 8, "step_num": 826}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413903476, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413903477, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7673197984695435, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413903477, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011148912832140923, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 830}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413905380, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413905381, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7732657194137573, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413905381, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010636813007295132, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 840}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413906443, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413906443, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7777524590492249, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413906443, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010439122095704079, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 850}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413907390, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413907390, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7721657156944275, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413907390, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010449289344251156, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 860}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413908329, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413908329, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7818581461906433, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413908330, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010169771499931812, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 870}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413909271, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413909271, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7741581797599792, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413909272, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010333186015486717, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 880}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413910215, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413910215, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7566290497779846, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413910215, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011081329546868801, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 890}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413911144, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413911145, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7735088467597961, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413911145, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010485176928341389, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 900}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413912084, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413912084, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.777362048625946, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413912084, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010312985628843307, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 910}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413913027, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413913028, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7621483206748962, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413913028, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010326020419597626, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 920}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413914238, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413914238, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7752257585525513, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413914238, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.011079668998718262, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 930}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413916984, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413916985, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.773246169090271, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413916985, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00987665168941021, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 8, "step_num": 940}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413917421, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 8}}
  0: EVAL: first data load time: 0.007058809511363506
  0: EVAL: step 1 time -> 0.013222630135715008
  0: EVAL: step 2 time -> 0.01233261451125145
  0: EVAL: step 3 time -> 0.012423667125403881
  0: EVAL: step 4 time -> 0.012058881111443043
  0: EVAL: full eval time -> 0.53801579028368
  0: :::MLLOG {"namespace": "", "time_ms": 1633413917963, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.689488236925221, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413917963, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.017606375604053964, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413917963, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 8}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413917983, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 8, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413918008, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 9, "step_num": 944}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413919822, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413919823, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7749676704406738, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413919823, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009037517011165619, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 950}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413921418, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413921418, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7585916519165039, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413921418, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009948949329555035, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 960}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413922461, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413922462, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7945262789726257, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413922462, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.01042350847274065, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 970}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413923398, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413923398, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.784423291683197, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413923398, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010128653608262539, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 980}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413924346, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413924346, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7848589420318604, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413924347, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009381919167935848, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 990}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413925305, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413925305, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7973483204841614, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413925305, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009602261707186699, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1000}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413926271, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413926271, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.796636164188385, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413926271, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009292409755289555, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1010}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413927214, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413927214, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7777725458145142, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413927214, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009685236029326916, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1020}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413928150, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413928150, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7953705191612244, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413928150, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009371516294777393, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1030}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413929088, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413929088, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7592533230781555, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413929089, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.010678227990865707, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1040}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413930025, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413930025, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7903341054916382, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413930025, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009739580564200878, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1050}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413930969, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413930969, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7867645621299744, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413930970, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009793683886528015, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 9, "step_num": 1060}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413931160, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 9}}
  0: EVAL: first data load time: 0.006239734590053558
  0: EVAL: step 1 time -> 0.013646291568875313
  0: EVAL: step 2 time -> 0.01246084924787283
  0: EVAL: step 3 time -> 0.012485004030168056
  0: EVAL: step 4 time -> 0.011998568661510944
  0: EVAL: full eval time -> 0.541593081317842
  0: :::MLLOG {"namespace": "", "time_ms": 1633413931704, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7214757162059638, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413931705, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01584323752695565, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413931705, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 9}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413931724, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 9, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413931748, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 10, "step_num": 1062}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413934338, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413934338, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7953221201896667, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413934338, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00921220239251852, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1070}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413935510, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413935510, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.811382532119751, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413935510, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00902572926133871, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1080}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413936570, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413936571, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7858172059059143, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413936571, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.0092389527708292, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1090}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413937520, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413937521, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8064627647399902, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413937521, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008498471230268478, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1100}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413938459, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413938459, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.807658851146698, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413938459, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00871276669204235, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1110}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413939396, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413939397, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7954701781272888, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413939397, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008791864849627018, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1120}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413940339, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413940339, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8013207316398621, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413940339, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009352458640933037, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1130}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413941285, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413941286, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7817096710205078, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413941286, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009247824549674988, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1140}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413942229, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413942229, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.788917064666748, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413942229, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009255871176719666, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1150}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413943161, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413943161, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7939360737800598, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413943161, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008859830908477306, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1160}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413944102, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413944103, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7989001274108887, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413944103, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009261435829102993, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1170}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945035, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945035, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8010302782058716, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945036, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009099142625927925, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945038, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 10}}
  0: EVAL: first data load time: 0.0012215236201882362
  0: EVAL: step 1 time -> 0.013593815267086029
  0: EVAL: step 2 time -> 0.01230605598539114
  0: EVAL: step 3 time -> 0.012432725168764591
  0: EVAL: step 4 time -> 0.011967829428613186
  0: EVAL: full eval time -> 0.3204842461273074
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945362, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7353371311766064, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945362, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01569592447830766, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 10}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945382, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 10, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413945387, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 11, "step_num": 1180}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413946333, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413946333, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.807669997215271, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413946333, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008878455497324467, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1190}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413947274, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413947274, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8076974153518677, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413947274, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008373584598302841, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1200}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413948214, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413948214, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7997302412986755, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413948214, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008791284635663033, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1210}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413949149, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413949149, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8087344765663147, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413949150, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007743756286799908, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1220}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413950085, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413950085, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8131119012832642, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413950085, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00841766782104969, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1230}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413951034, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413951035, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.808803379535675, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413951035, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008400716818869114, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1240}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413951974, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413951975, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8061820268630981, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413951975, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.008354351855814457, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1250}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413952913, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413952914, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.791637659072876, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413952914, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009419024921953678, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1260}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413953849, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413953850, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.779685914516449, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413953850, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009708013385534286, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1270}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413954794, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413954794, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7981310486793518, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413954794, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.009339733980596066, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1280}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413955730, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413955731, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.7981711030006409, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413955731, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00862844567745924, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 11, "step_num": 1290}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413956482, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 11}}
  0: EVAL: first data load time: 0.0031460868194699287
  0: EVAL: step 1 time -> 0.013290640898048878
  0: EVAL: step 2 time -> 0.012348005548119545
  0: EVAL: step 3 time -> 0.012336970306932926
  0: EVAL: step 4 time -> 0.011804906651377678
  0: EVAL: full eval time -> 0.5296575017273426
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957016, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.763100033810529, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957016, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.01146575992159926, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957016, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 11}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957036, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 11, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957059, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 460, "epoch_num": 12, "step_num": 1298}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957683, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957683, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8050491213798523, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413957683, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.007952891290187836, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1300}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413960077, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413960078, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8233790397644043, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413960078, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006545041222125292, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1310}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413961011, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413961012, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8397074937820435, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413961012, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.006074320990592241, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1320}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413961948, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413961948, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8470842838287354, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413961948, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005666349083185196, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1330}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413962889, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413962889, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8488504886627197, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413962889, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005588585045188665, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1340}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413963823, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413963824, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8431996703147888, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413963824, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005443606525659561, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1350}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413964763, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413964763, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8498175144195557, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413964763, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005585432052612305, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1360}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413965705, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413965705, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8549322485923767, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413965706, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005354605615139008, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1370}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413966652, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413966652, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8482750654220581, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413966653, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00551681499928236, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1380}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413967595, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413967595, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8532548546791077, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413967595, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005339664872735739, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1390}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413968531, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413968531, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8554049730300903, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413968532, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.00519165163859725, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1400}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413969483, "event_type": "POINT_IN_TIME", "key": "learning_rate", "value": 0.0004, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 405, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413969484, "event_type": "POINT_IN_TIME", "key": "train_accuracy", "value": 0.8502345681190491, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 406, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413969484, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 0.005260090343654156, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/trainer.py", "lineno": 407, "epoch_num": 12, "step_num": 1410}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413970057, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 358, "epoch_num": 12}}
  0: EVAL: first data load time: 0.0019506905227899551
  0: EVAL: step 1 time -> 0.013728576712310314
  0: EVAL: step 2 time -> 0.012362457811832428
  0: EVAL: step 3 time -> 0.012368807569146156
  0: EVAL: step 4 time -> 0.011968068778514862
  0: EVAL: full eval time -> 0.5413697343319654
  0: :::MLLOG {"namespace": "", "time_ms": 1633413970601, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8200392712387848, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 364, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413970601, "event_type": "POINT_IN_TIME", "key": "eval_loss", "value": 0.010429896721976431, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 365, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413970601, "event_type": "POINT_IN_TIME", "key": "target_accuracy_reached", "value": 0.82, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 374, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413970601, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/hkfs/work/workspace/scratch/qv2382-mlperf-combined/MLPerf/benchmarks-closed/deepcam/image-src/driver/validation.py", "lineno": 377, "epoch_num": 12}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413970621, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 486, "epoch_num": 12, "step_num": 1416}}
  0: :::MLLOG {"namespace": "", "time_ms": 1633413970645, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "./train_instance.py", "lineno": 507, "status": "success"}}
232: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
232: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
440: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
440: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
  0: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  0: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
108: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
108: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
179: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
179: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
131: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
131: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
312: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
312: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
245: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
245: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
342: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 21: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
342: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 21: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
467: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
467: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 36: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 36: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
281: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
263: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
281: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
263: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
346: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
346: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
248: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
248: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
286: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
286: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 31: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 31: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
258: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
258: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
153: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
153: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
227: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
227: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
180: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
200: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
180: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
200: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
290: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
290: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
219: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
219: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
  7: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  7: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 84: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 84: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 50: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 50: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
453: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
453: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
336: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
336: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
140: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
140: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 58: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 58: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
445: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
445: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
415: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
415: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
277: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
277: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
381: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
381: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
361: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
361: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
122: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
122: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
307: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
307: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
321: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
321: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
454: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
454: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
297: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
297: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
104: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
104: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
124: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
124: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
327: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
327: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
371: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
371: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
446: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
446: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
420: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
420: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
483: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
483: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
390: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
390: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 80: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 80: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
406: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
406: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
376: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
376: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
167: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
167: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
425: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
425: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 90: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 90: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
284: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
284: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
276: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
276: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
330: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 20: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
330: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 20: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
344: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
344: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
128: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
128: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
193: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
193: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
497: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
497: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
138: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
138: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
176: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
176: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 65: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 65: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
244: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
244: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 95: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 95: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
224: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
224: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 27: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 27: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
208: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
208: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
337: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
337: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
256: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
256: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
271: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
271: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
367: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
367: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
288: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
288: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
280: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
280: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
216: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
216: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 77: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 77: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
316: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
316: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
331: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
331: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
340: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
340: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
  3: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  3: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
375: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
375: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
478: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
478: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
410: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
410: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
166: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
166: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
403: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
403: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
389: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
389: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 28: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 28: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 56: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 56: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
314: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
314: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
464: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
464: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
353: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
353: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
448: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
448: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 76: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 76: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 68: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 68: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 25: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 25: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
435: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
435: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
  4: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  4: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
379: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
379: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
384: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
384: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
442: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
442: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
428: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
428: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 32: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 32: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
363: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
363: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 38: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 38: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
250: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
250: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
471: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
471: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
269: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
269: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
380: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
380: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
304: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
304: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
401: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
432: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
401: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
432: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 48: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 48: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
460: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
460: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
493: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
412: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
412: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
493: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
235: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
235: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
310: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
310: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
354: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
354: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
211: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
211: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
320: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
320: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 42: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 42: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
223: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
223: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
160: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
160: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
267: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
267: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
476: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
476: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
170: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
170: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 34: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 34: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
296: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
296: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
399: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
399: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
496: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
372: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
496: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
372: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 70: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 70: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
203: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
203: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
149: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
149: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
273: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
273: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
509: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
272: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
509: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
272: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 10: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 10: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
368: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
368: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
230: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
230: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
255: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
255: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
252: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
252: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
136: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
136: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
473: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
473: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
242: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
242: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
468: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
468: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 87: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 87: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
495: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
495: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
423: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
423: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
351: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
351: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
241: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
152: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
241: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
152: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
186: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
186: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
285: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
130: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
285: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
130: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
350: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
350: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
207: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
207: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 18: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 18: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
115: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
115: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
480: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
480: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
405: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
405: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 88: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 88: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
236: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
236: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
146: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
146: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
228: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
228: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
102: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
102: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 66: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 66: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
178: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
178: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
424: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
424: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 14: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 14: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
106: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
106: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
111: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
111: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 46: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 46: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
247: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
247: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 96: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 96: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 83: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 83: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
226: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
226: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
156: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
156: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
419: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
419: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
408: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
408: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
147: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
147: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
352: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
352: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
192: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
192: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
100: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
100: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
188: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
188: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
328: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
328: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
127: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
127: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
360: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
360: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 45: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 45: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
112: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
112: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
301: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
301: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
  2: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  2: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 22: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
283: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
283: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 22: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
394: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
394: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
347: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
347: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
488: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
488: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
291: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
291: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
143: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
143: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
504: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
504: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
343: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
343: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 94: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 94: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
181: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
181: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
182: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
249: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
182: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
249: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:16 AM
338: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
338: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
358: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
358: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 59: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 59: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
213: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
213: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
212: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
212: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
315: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
315: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
391: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
391: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
466: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
466: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 79: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 79: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
173: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
173: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
392: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 29: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
392: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 29: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 72: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 72: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
261: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
261: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
500: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
500: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
443: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
443: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
308: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
308: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
218: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
218: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
434: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
434: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
378: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
378: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 40: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 40: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
332: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
319: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
485: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
332: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
319: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
485: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
259: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
259: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
187: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
187: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
383: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
383: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
220: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
220: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 53: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 53: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
264: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
264: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
133: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
133: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 37: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 37: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
278: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
278: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
  6: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  6: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
292: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
292: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
364: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
364: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
199: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
199: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:16 AM
 35: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
438: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 35: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
438: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
  8: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  8: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
396: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
396: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
305: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
305: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
210: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
210: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
498: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
498: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
470: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
470: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
472: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
472: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
119: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
119: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
120: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
120: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 51: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 51: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
414: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
414: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
270: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
270: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
275: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
275: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
348: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
348: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 26: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 26: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
322: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
322: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 19: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 19: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
253: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
253: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
463: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
463: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
154: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
154: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
202: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
202: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
407: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
407: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
387: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
387: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 75: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 75: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
421: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 85: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
421: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 85: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
374: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
374: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
370: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
370: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
508: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
508: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
234: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
234: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
457: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
457: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 12: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 12: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 71: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 71: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
163: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
163: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
205: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
205: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
426: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
426: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 92: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 92: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
299: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
299: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
215: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
215: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
325: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
325: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
494: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
494: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 67: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 67: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
484: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
484: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
137: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
137: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
243: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
243: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
172: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
172: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
481: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
481: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 91: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 91: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
105: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
105: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
126: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
126: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
144: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
144: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
416: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
110: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
416: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
110: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 60: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 60: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
184: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
184: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
151: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
431: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
151: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
431: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
238: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
238: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
116: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
116: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
411: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
411: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
195: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
195: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 44: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 44: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:16 AM
365: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
365: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
479: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
479: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 55: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 55: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
260: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
260: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
317: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
317: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
101: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
101: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 43: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 43: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
231: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
311: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
311: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
231: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
490: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
490: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
189: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
189: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
503: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
503: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
222: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
222: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 82: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 82: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
265: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
265: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 97: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 97: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
121: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
121: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 74: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 74: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
141: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
141: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
324: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
324: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
204: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
204: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 11: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 11: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
398: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
398: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
295: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
295: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
113: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
113: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
303: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
303: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
161: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
161: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
449: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
449: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
451: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
451: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
462: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
462: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
356: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
356: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
475: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
475: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
507: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
507: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
386: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
386: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
456: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
456: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
511: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
511: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
196: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
196: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 17: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 17: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
487: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
487: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 15: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 15: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
335: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
335: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
171: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
171: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
239: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
239: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
437: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
437: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
429: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
429: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
393: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
393: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
417: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
417: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
118: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
118: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
132: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
132: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
452: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
452: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
159: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
159: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 54: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 54: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
190: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
190: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
174: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
174: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 62: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 62: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 99: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 99: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
501: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
501: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
302: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
302: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
148: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
148: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
294: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
294: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
491: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
491: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
506: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
506: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
436: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
436: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
168: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
168: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
359: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
359: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
447: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
447: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
334: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
334: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
164: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
164: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
157: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
157: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
134: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
134: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
197: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
197: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 61: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 61: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
458: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
458: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
129: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
129: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
400: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
400: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 23: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 23: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
465: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
465: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
441: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
441: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 86: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 86: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
251: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
251: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
257: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
257: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
177: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
177: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
217: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
217: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
282: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
282: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
339: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
339: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
225: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
225: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
413: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
413: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
289: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
289: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
201: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
201: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 49: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 49: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
246: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
246: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
382: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
382: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 57: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 57: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
422: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
422: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
362: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
362: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
125: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
125: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
298: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
298: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
404: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
404: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
109: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
109: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
155: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
155: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
107: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
107: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
262: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
262: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 30: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 30: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
279: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
279: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
482: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
482: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
326: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
326: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
427: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
427: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
  5: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  5: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
  1: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  1: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 81: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 81: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
366: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
366: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
341: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
341: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
183: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
183: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
409: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
409: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 39: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 39: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
450: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
450: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
329: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
329: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
499: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
499: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
162: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
162: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
123: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
123: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 78: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 78: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
313: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
313: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 64: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 64: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
214: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
214: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
318: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
318: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
345: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
345: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
240: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
240: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
433: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
433: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
373: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
373: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
385: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
385: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
309: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
309: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
233: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
233: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 33: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 33: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
268: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
268: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
355: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
355: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
266: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
266: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 89: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 89: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
254: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
254: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
221: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
221: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
323: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
323: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
306: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
306: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
430: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
430: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
492: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
492: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
349: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
349: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
418: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
418: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 24: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 24: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
229: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
229: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
194: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
194: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
300: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
300: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
510: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
510: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
  9: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
  9: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 93: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 93: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
397: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
397: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
388: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
388: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 41: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 41: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
502: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
502: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
191: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
191: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 69: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 69: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
274: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
150: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
274: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
150: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
377: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
377: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
395: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
395: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
461: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
461: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
175: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
175: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
287: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
287: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
477: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
477: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
142: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
142: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
489: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
489: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
135: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
135: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
333: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
333: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
145: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
145: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
198: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
198: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
369: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
369: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
444: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
444: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 52: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 52: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
158: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
158: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
474: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
474: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
169: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
169: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
237: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
237: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
486: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 47: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
486: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 47: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
114: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
114: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
139: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
139: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 63: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 63: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
357: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
357: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
505: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
505: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
209: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 16: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
209: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 16: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
165: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
165: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
293: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
293: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 73: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 73: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
439: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
439: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
469: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
117: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
117: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
469: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
206: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
206: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
455: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
455: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
 13: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 13: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
 98: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
 98: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
402: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
402: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
103: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
103: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:15 AM
459: ENDING TIMING RUN AT 2021-10-05 08:06:16 AM
459: RESULT,DEEPCAM_HPC,,480,qv2382,2021-10-05 07:58:16 AM
185: ENDING TIMING RUN AT 2021-10-05 08:06:17 AM
185: RESULT,DEEPCAM_HPC,,481,qv2382,2021-10-05 07:58:16 AM
